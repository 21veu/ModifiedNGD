/nishome/yui/ModifiedNGD/utils/readData.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)
/nishome/yui/anaconda3/envs/ng/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /opt/conda/conda-bld/pytorch_1716905971214/work/torch/csrc/autograd/engine.cpp:1203.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Train info: 
 train data shape: torch.Size([512, 2]), 
 train lable shape: torch.Size([512, 1]), 
 positive / negative: -0.02499326691031456 / 1.0249933004379272
Test info: 
 test data shape: torch.Size([128, 2]), 
 test lable shape: torch.Size([128, 1]), , 
 positive / negative: -0.006046447902917862 / 1.0060464143753052
Valid info: 
 valid data shape: torch.Size([128, 2]), valid lable shape: torch.Size([128, 1]), 
 positive / negative: 0.050523675978183746 / 0.9494763016700745
torch.Size([512, 2]) torch.Size([512])
seed is  2190
---------------------------------------- MNGD ----------------------------------------
OUTPUT CHECK:  torch.Size([512]) tensor(-0.0934, device='cuda:0', grad_fn=<MaxBackward1>) tensor(-0.1214, device='cuda:0', grad_fn=<MinBackward1>) 
TARGET:  torch.Size([512]) tensor(0.5000, device='cuda:0') tensor(-0.5000, device='cuda:0')
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch:   1
Test train Loss:  0.06703334301710129
Test train Acc:  0.0
Test Loss:  0.07140271365642548
Test Acc:  0.0
Valid Loss:  0.08514202386140823
Valid Acc:  0.0
max of grad d_p:  tensor(0.0067, device='cuda:0')
min of grad d_p:  tensor(-0.0852, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0023, device='cuda:0') mean:  tensor(-3.1503e-06, device='cuda:0') min:  tensor(-0.0022, device='cuda:0') norm:  tensor(0.0614, device='cuda:0') MSE:  tensor(2.3039e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.8077e-05, device='cuda:0') mean:  tensor(6.1226e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.3268e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0204, device='cuda:0')
min of d_p_list:  tensor(-0.0074, device='cuda:0')
Epoch:  1  
Training Loss: 0.06257871827983763
Test Loss:  0.06626077741384506
Test Acc:  0.0
Valid Loss:  0.07920993119478226
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
  0%|          | 1/1000 [00:03<1:00:36,  3.64s/it]Epoch:   2
max of grad d_p:  tensor(0.0059, device='cuda:0')
min of grad d_p:  tensor(-0.0850, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0028, device='cuda:0') mean:  tensor(-5.3926e-06, device='cuda:0') min:  tensor(-0.0033, device='cuda:0') norm:  tensor(0.0635, device='cuda:0') MSE:  tensor(2.3853e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.3366e-05, device='cuda:0') mean:  tensor(2.9553e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.1437e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0033, device='cuda:0')
min of d_p_list:  tensor(-0.0041, device='cuda:0')
Epoch:  2  
Training Loss: 0.061651621013879776
Test Loss:  0.06548731029033661
Test Acc:  0.0
Valid Loss:  0.0781988799571991
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
  0%|          | 2/1000 [00:07<1:02:24,  3.75s/it]Epoch:   3
max of grad d_p:  tensor(0.0058, device='cuda:0')
min of grad d_p:  tensor(-0.0845, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0028, device='cuda:0') mean:  tensor(-5.3936e-06, device='cuda:0') min:  tensor(-0.0039, device='cuda:0') norm:  tensor(0.0599, device='cuda:0') MSE:  tensor(2.2469e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.6718e-05, device='cuda:0') mean:  tensor(3.2833e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.2861e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0528, device='cuda:0')
min of d_p_list:  tensor(-0.0409, device='cuda:0')
Epoch:  3  
Training Loss: 0.058730997145175934
Test Loss:  0.06329488009214401
Test Acc:  0.0
Valid Loss:  0.07485443353652954
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  2
  0%|          | 3/1000 [00:11<1:02:07,  3.74s/it]Epoch:   4
max of grad d_p:  tensor(0.0151, device='cuda:0')
min of grad d_p:  tensor(-0.0820, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0140, device='cuda:0') mean:  tensor(-7.1145e-06, device='cuda:0') min:  tensor(-0.0068, device='cuda:0') norm:  tensor(0.0934, device='cuda:0') MSE:  tensor(3.5070e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.2502e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.1934e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0482, device='cuda:0')
min of d_p_list:  tensor(-0.0120, device='cuda:0')
Epoch:  4  
Training Loss: 0.05425383523106575
Test Loss:  0.05806794762611389
Test Acc:  0.0
Valid Loss:  0.06880711764097214
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  2
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
  0%|          | 4/1000 [00:15<1:03:54,  3.85s/it]Epoch:   5
max of grad d_p:  tensor(0.0161, device='cuda:0')
min of grad d_p:  tensor(-0.0806, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0113, device='cuda:0') mean:  tensor(-9.7837e-06, device='cuda:0') min:  tensor(-0.0109, device='cuda:0') norm:  tensor(0.0921, device='cuda:0') MSE:  tensor(3.4575e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(8.4397e-07, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.6325e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0120, device='cuda:0')
min of d_p_list:  tensor(-0.0078, device='cuda:0')
Epoch:  5  
Training Loss: 0.05364259332418442
Test Loss:  0.05755239725112915
Test Acc:  0.0
Valid Loss:  0.06807833164930344
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
  0%|          | 5/1000 [00:18<1:02:30,  3.77s/it]Epoch:   6
max of grad d_p:  tensor(0.0162, device='cuda:0')
min of grad d_p:  tensor(-0.0800, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0126, device='cuda:0') mean:  tensor(-9.0609e-06, device='cuda:0') min:  tensor(-0.0125, device='cuda:0') norm:  tensor(0.0935, device='cuda:0') MSE:  tensor(3.5110e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(2.0178e-06, device='cuda:0') min:  tensor(3.6380e-12, device='cuda:0') norm:  tensor(0.0022, device='cuda:0') MSE:  tensor(8.2401e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0539, device='cuda:0')
min of d_p_list:  tensor(-0.1009, device='cuda:0')
Epoch:  6  
Training Loss: 0.05302530527114868
Test Loss:  0.05641299486160278
Test Acc:  0.0
Valid Loss:  0.06670533120632172
Valid Acc:  0.0
std:  0.0033619686208053046 
thres:  5.6260870397090916e-05
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
  1%|          | 6/1000 [00:22<1:02:42,  3.79s/it]Epoch:   7
max of grad d_p:  tensor(0.0145, device='cuda:0')
min of grad d_p:  tensor(-0.0762, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0143, device='cuda:0') mean:  tensor(-1.0781e-05, device='cuda:0') min:  tensor(-0.0177, device='cuda:0') norm:  tensor(0.1032, device='cuda:0') MSE:  tensor(3.8752e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(8.4416e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.7088e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0455, device='cuda:0')
min of d_p_list:  tensor(-0.0179, device='cuda:0')
Epoch:  7  
Training Loss: 0.0490516722202301
Test Loss:  0.05209283158183098
Test Acc:  0.0
Valid Loss:  0.06149212270975113
Valid Acc:  0.0
std:  0.0030878720587719476 
thres:  5.3740880638360984e-05
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  1%|          | 7/1000 [00:26<1:02:28,  3.77s/it]Epoch:   8
max of grad d_p:  tensor(0.0161, device='cuda:0')
min of grad d_p:  tensor(-0.0743, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0111, device='cuda:0') mean:  tensor(-1.1091e-05, device='cuda:0') min:  tensor(-0.0221, device='cuda:0') norm:  tensor(0.0969, device='cuda:0') MSE:  tensor(3.6366e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(2.7660e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0030, device='cuda:0') MSE:  tensor(1.1406e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1121, device='cuda:0')
min of d_p_list:  tensor(-0.0977, device='cuda:0')
Epoch:  8  
Training Loss: 0.045290157198905945
Test Loss:  0.04795835539698601
Test Acc:  0.0
Valid Loss:  0.055639319121837616
Valid Acc:  0.0
std:  0.0034075503653809933 
thres:  5.1052712649106975e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
  1%|          | 8/1000 [00:30<1:03:46,  3.86s/it]Epoch:   9
max of grad d_p:  tensor(0.0117, device='cuda:0')
min of grad d_p:  tensor(-0.0458, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0130, device='cuda:0') mean:  tensor(-1.3543e-05, device='cuda:0') min:  tensor(-0.0253, device='cuda:0') norm:  tensor(0.1063, device='cuda:0') MSE:  tensor(3.9884e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0019, device='cuda:0') mean:  tensor(9.9908e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0114, device='cuda:0') MSE:  tensor(4.2893e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0097, device='cuda:0')
min of d_p_list:  tensor(-0.0069, device='cuda:0')
Epoch:  9  
Training Loss: 0.04482879862189293
Test Loss:  0.04734998196363449
Test Acc:  0.0
Valid Loss:  0.05491647124290466
Valid Acc:  0.0
std:  0.0037089258412542187 
thres:  4.9167705327272417e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
  1%|          | 9/1000 [00:34<1:03:16,  3.83s/it]Epoch:   10
max of grad d_p:  tensor(0.0119, device='cuda:0')
min of grad d_p:  tensor(-0.0451, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0179, device='cuda:0') mean:  tensor(-1.4206e-05, device='cuda:0') min:  tensor(-0.0258, device='cuda:0') norm:  tensor(0.1116, device='cuda:0') MSE:  tensor(4.1878e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.7489e-05, device='cuda:0') mean:  tensor(5.8410e-07, device='cuda:0') min:  tensor(4.5475e-13, device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.4508e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0105, device='cuda:0')
min of d_p_list:  tensor(-0.0083, device='cuda:0')
Epoch:  10  
Training Loss: 0.044377632439136505
Test Loss:  0.046797238290309906
Test Acc:  0.0
Valid Loss:  0.054307207465171814
Valid Acc:  0.0
std:  0.0033025120780421258 
thres:  4.731471315026283e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  1%|          | 10/1000 [00:37<1:01:10,  3.71s/it]Epoch:   11
max of grad d_p:  tensor(0.0127, device='cuda:0')
min of grad d_p:  tensor(-0.0448, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0116, device='cuda:0') mean:  tensor(-1.2875e-05, device='cuda:0') min:  tensor(-0.0237, device='cuda:0') norm:  tensor(0.1043, device='cuda:0') MSE:  tensor(3.9169e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(2.0904e-06, device='cuda:0') min:  tensor(7.2760e-12, device='cuda:0') norm:  tensor(0.0024, device='cuda:0') MSE:  tensor(9.0733e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0202, device='cuda:0')
min of d_p_list:  tensor(-0.0181, device='cuda:0')
Epoch:  11  
Training Loss: 0.04114675521850586
Test Loss:  0.04299551993608475
Test Acc:  0.0
Valid Loss:  0.05000773444771767
Valid Acc:  0.0
std:  0.002519753263089172 
thres:  4.493900313973427e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
  1%|          | 11/1000 [00:41<1:01:03,  3.70s/it]Epoch:   12
max of grad d_p:  tensor(0.0131, device='cuda:0')
min of grad d_p:  tensor(-0.0451, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0179, device='cuda:0') mean:  tensor(-1.4022e-05, device='cuda:0') min:  tensor(-0.0246, device='cuda:0') norm:  tensor(0.1070, device='cuda:0') MSE:  tensor(4.0182e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.9742e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.5721e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0043, device='cuda:0')
min of d_p_list:  tensor(-0.0051, device='cuda:0')
Epoch:  12  
Training Loss: 0.04078592732548714
Test Loss:  0.042563870549201965
Test Acc:  0.0
Valid Loss:  0.04950282722711563
Valid Acc:  0.0
std:  0.0019191282684837296 
thres:  4.328585416078568e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
  1%|          | 12/1000 [00:45<1:02:45,  3.81s/it]Epoch:   13
max of grad d_p:  tensor(0.0136, device='cuda:0')
min of grad d_p:  tensor(-0.0448, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0162, device='cuda:0') mean:  tensor(-1.5620e-05, device='cuda:0') min:  tensor(-0.0275, device='cuda:0') norm:  tensor(0.1171, device='cuda:0') MSE:  tensor(4.3949e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(7.0162e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(3.0165e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0476, device='cuda:0')
min of d_p_list:  tensor(-0.0293, device='cuda:0')
Epoch:  13  
Training Loss: 0.04036738723516464
Test Loss:  0.04220263287425041
Test Acc:  0.0
Valid Loss:  0.04888801649212837
Valid Acc:  0.0
std:  0.001900986704772541 
thres:  4.230130016803742e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
  1%|▏         | 13/1000 [00:49<1:02:58,  3.83s/it]Epoch:   14
max of grad d_p:  tensor(0.0114, device='cuda:0')
min of grad d_p:  tensor(-0.0433, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0179, device='cuda:0') mean:  tensor(-1.6636e-05, device='cuda:0') min:  tensor(-0.0291, device='cuda:0') norm:  tensor(0.1293, device='cuda:0') MSE:  tensor(4.8553e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(7.2471e-07, device='cuda:0') min:  tensor(2.2737e-13, device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.2422e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0086, device='cuda:0')
min of d_p_list:  tensor(-0.0058, device='cuda:0')
Epoch:  14  
Training Loss: 0.03989732265472412
Test Loss:  0.041610877960920334
Test Acc:  0.0
Valid Loss:  0.04821073263883591
Valid Acc:  0.0
std:  0.0015871811910384438 
thres:  4.131500497460365e-05
Preserved_eigens number check:  4
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
  1%|▏         | 14/1000 [00:52<1:01:59,  3.77s/it]Epoch:   15
max of grad d_p:  tensor(0.0119, device='cuda:0')
min of grad d_p:  tensor(-0.0427, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0144, device='cuda:0') mean:  tensor(-1.6043e-05, device='cuda:0') min:  tensor(-0.0415, device='cuda:0') norm:  tensor(0.1336, device='cuda:0') MSE:  tensor(5.0132e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.6085e-06, device='cuda:0') min:  tensor(4.5475e-13, device='cuda:0') norm:  tensor(0.0020, device='cuda:0') MSE:  tensor(7.4899e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0483, device='cuda:0')
min of d_p_list:  tensor(-0.0346, device='cuda:0')
Epoch:  15  
Training Loss: 0.03704997897148132
Test Loss:  0.03830878064036369
Test Acc:  0.0
Valid Loss:  0.04439608380198479
Valid Acc:  0.0
std:  0.0014606559771775127 
thres:  3.984947428107262e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  2%|▏         | 15/1000 [00:56<1:02:28,  3.81s/it]Epoch:   16
max of grad d_p:  tensor(0.0103, device='cuda:0')
min of grad d_p:  tensor(-0.0424, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0166, device='cuda:0') mean:  tensor(-1.7318e-05, device='cuda:0') min:  tensor(-0.0312, device='cuda:0') norm:  tensor(0.1286, device='cuda:0') MSE:  tensor(4.8276e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.9239e-05, device='cuda:0') mean:  tensor(7.1208e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(3.0860e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  16  
Training Loss: 0.03677276521921158
Test Loss:  0.03793073445558548
Test Acc:  0.0
Valid Loss:  0.0439867228269577
Valid Acc:  0.0
std:  0.0017102293727010334 
thres:  3.897467628121376e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
  2%|▏         | 16/1000 [01:00<1:03:21,  3.86s/it]Epoch:   17
max of grad d_p:  tensor(0.0102, device='cuda:0')
min of grad d_p:  tensor(-0.0422, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0162, device='cuda:0') mean:  tensor(-1.5476e-05, device='cuda:0') min:  tensor(-0.0285, device='cuda:0') norm:  tensor(0.1195, device='cuda:0') MSE:  tensor(4.4869e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(2.3830e-06, device='cuda:0') min:  tensor(2.9843e-12, device='cuda:0') norm:  tensor(0.0026, device='cuda:0') MSE:  tensor(9.9145e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0316, device='cuda:0')
min of d_p_list:  tensor(-0.0408, device='cuda:0')
Epoch:  17  
Training Loss: 0.0364907830953598
Test Loss:  0.0377361886203289
Test Acc:  0.0
Valid Loss:  0.043626535683870316
Valid Acc:  0.0
std:  0.0016627606417087188 
thres:  3.811564743518829e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
  2%|▏         | 17/1000 [01:04<1:03:31,  3.88s/it]Epoch:   18
max of grad d_p:  tensor(0.0124, device='cuda:0')
min of grad d_p:  tensor(-0.0403, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0184, device='cuda:0') mean:  tensor(-1.7046e-05, device='cuda:0') min:  tensor(-0.0306, device='cuda:0') norm:  tensor(0.1358, device='cuda:0') MSE:  tensor(5.0985e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.5456e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.7994e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0046, device='cuda:0')
min of d_p_list:  tensor(-0.0050, device='cuda:0')
Epoch:  18  
Training Loss: 0.036214157938957214
Test Loss:  0.037416793406009674
Test Acc:  0.0
Valid Loss:  0.04325208067893982
Valid Acc:  0.0
std:  0.0013356146314100052 
thres:  3.728500157594681e-05
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
  2%|▏         | 18/1000 [01:08<1:03:33,  3.88s/it]Epoch:   19
max of grad d_p:  tensor(0.0120, device='cuda:0')
min of grad d_p:  tensor(-0.0401, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0241, device='cuda:0') mean:  tensor(-1.8123e-05, device='cuda:0') min:  tensor(-0.0294, device='cuda:0') norm:  tensor(0.1411, device='cuda:0') MSE:  tensor(5.2975e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(8.8151e-07, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.0083e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2060, device='cuda:0')
min of d_p_list:  tensor(-0.5133, device='cuda:0')
Epoch:  19  
Training Loss: 0.055140748620033264
Test Loss:  0.049331218004226685
Test Acc:  0.0
Valid Loss:  0.04957877844572067
Valid Acc:  0.0
std:  0.007408784060424331 
thres:  4.0333686769008634e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  2%|▏         | 19/1000 [01:12<1:03:26,  3.88s/it]Epoch:   20
max of grad d_p:  tensor(0.2305, device='cuda:0')
min of grad d_p:  tensor(-0.0581, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0433, device='cuda:0') mean:  tensor(-2.4665e-05, device='cuda:0') min:  tensor(-0.1019, device='cuda:0') norm:  tensor(0.3073, device='cuda:0') MSE:  tensor(1.1536e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0008, device='cuda:0') mean:  tensor(2.5010e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0036, device='cuda:0') MSE:  tensor(1.3681e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.3338, device='cuda:0')
min of d_p_list:  tensor(-0.1780, device='cuda:0')
Epoch:  20  
Training Loss: 0.10243988037109375
Test Loss:  0.09186719357967377
Test Acc:  0.0
Valid Loss:  0.08873322606086731
Valid Acc:  0.0
std:  0.025556522111194697 
thres:  5.341166704893112e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
  2%|▏         | 20/1000 [01:16<1:04:19,  3.94s/it]Epoch:   21
max of grad d_p:  tensor(0.4391, device='cuda:0')
min of grad d_p:  tensor(-0.1485, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0211, device='cuda:0') mean:  tensor(-1.6961e-05, device='cuda:0') min:  tensor(-0.0730, device='cuda:0') norm:  tensor(0.2903, device='cuda:0') MSE:  tensor(1.0898e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(2.0780e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0030, device='cuda:0') MSE:  tensor(1.1268e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0139, device='cuda:0')
min of d_p_list:  tensor(-0.0132, device='cuda:0')
Epoch:  21  
Training Loss: 0.10150978714227676
Test Loss:  0.09099186956882477
Test Acc:  0.0
Valid Loss:  0.08790253102779388
Valid Acc:  0.0
std:  0.029880022801267368 
thres:  6.635907143354417e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
  2%|▏         | 21/1000 [01:20<1:03:31,  3.89s/it]Epoch:   22
max of grad d_p:  tensor(0.4378, device='cuda:0')
min of grad d_p:  tensor(-0.1445, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0211, device='cuda:0') mean:  tensor(-1.8094e-05, device='cuda:0') min:  tensor(-0.1109, device='cuda:0') norm:  tensor(0.3039, device='cuda:0') MSE:  tensor(1.1409e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0008, device='cuda:0') mean:  tensor(1.6958e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0028, device='cuda:0') MSE:  tensor(1.0361e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0089, device='cuda:0')
min of d_p_list:  tensor(-0.0082, device='cuda:0')
Epoch:  22  
Training Loss: 0.09996730089187622
Test Loss:  0.08969292044639587
Test Acc:  0.0
Valid Loss:  0.08635347336530685
Valid Acc:  0.0
std:  0.02791280562672973 
thres:  7.905437499284744e-05
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
  2%|▏         | 22/1000 [01:24<1:03:31,  3.90s/it]Epoch:   23
max of grad d_p:  tensor(0.4360, device='cuda:0')
min of grad d_p:  tensor(-0.1446, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0171, device='cuda:0') mean:  tensor(-1.6322e-05, device='cuda:0') min:  tensor(-0.1042, device='cuda:0') norm:  tensor(0.2628, device='cuda:0') MSE:  tensor(9.8655e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0774, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(4.6566e-10, device='cuda:0') norm:  tensor(0.5346, device='cuda:0') MSE:  tensor(2.0067e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0094, device='cuda:0')
min of d_p_list:  tensor(-0.0119, device='cuda:0')
Epoch:  23  
Training Loss: 0.09839658439159393
Test Loss:  0.08855068683624268
Test Acc:  0.0
Valid Loss:  0.08494001626968384
Valid Acc:  0.0
std:  0.018227065726940196 
thres:  9.149086028337479e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
  2%|▏         | 23/1000 [01:28<1:03:43,  3.91s/it]Epoch:   24
max of grad d_p:  tensor(0.4354, device='cuda:0')
min of grad d_p:  tensor(-0.1436, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0262, device='cuda:0') mean:  tensor(-2.0515e-05, device='cuda:0') min:  tensor(-0.1462, device='cuda:0') norm:  tensor(0.3442, device='cuda:0') MSE:  tensor(1.2919e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0011, device='cuda:0') mean:  tensor(3.9516e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0060, device='cuda:0') MSE:  tensor(2.2461e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0204, device='cuda:0')
min of d_p_list:  tensor(-0.0395, device='cuda:0')
Epoch:  24  
Training Loss: 0.09679075330495834
Test Loss:  0.08737016469240189
Test Acc:  0.0
Valid Loss:  0.0835697203874588
Valid Acc:  0.0
std:  0.002046621368156113 
thres:  9.98208612203598e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
  2%|▏         | 24/1000 [01:32<1:03:40,  3.91s/it]Epoch:   25
max of grad d_p:  tensor(0.4326, device='cuda:0')
min of grad d_p:  tensor(-0.1432, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0214, device='cuda:0') mean:  tensor(-1.6706e-05, device='cuda:0') min:  tensor(-0.1181, device='cuda:0') norm:  tensor(0.2822, device='cuda:0') MSE:  tensor(1.0594e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(1.6708e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0023, device='cuda:0') MSE:  tensor(8.8031e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0775, device='cuda:0')
min of d_p_list:  tensor(-0.0428, device='cuda:0')
Epoch:  25  
Training Loss: 0.09430211782455444
Test Loss:  0.08472245931625366
Test Acc:  0.0
Valid Loss:  0.08098985254764557
Valid Acc:  0.0
std:  0.0025018363906150424 
thres:  9.819330871105195e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
  2%|▎         | 25/1000 [01:35<1:02:58,  3.88s/it]Epoch:   26
max of grad d_p:  tensor(0.4534, device='cuda:0')
min of grad d_p:  tensor(-0.1396, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0191, device='cuda:0') mean:  tensor(-1.3562e-05, device='cuda:0') min:  tensor(-0.1294, device='cuda:0') norm:  tensor(0.2859, device='cuda:0') MSE:  tensor(1.0733e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0076, device='cuda:0') mean:  tensor(3.0672e-05, device='cuda:0') min:  tensor(5.8208e-11, device='cuda:0') norm:  tensor(0.0455, device='cuda:0') MSE:  tensor(1.7082e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0128, device='cuda:0')
min of d_p_list:  tensor(-0.0069, device='cuda:0')
Epoch:  26  
Training Loss: 0.09289804100990295
Test Loss:  0.08379790186882019
Test Acc:  0.0
Valid Loss:  0.07996264100074768
Valid Acc:  0.0
std:  0.002588602834711794 
thres:  9.647095948457717e-05
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
  3%|▎         | 26/1000 [01:39<1:01:52,  3.81s/it]Epoch:   27
max of grad d_p:  tensor(0.4548, device='cuda:0')
min of grad d_p:  tensor(-0.1383, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0197, device='cuda:0') mean:  tensor(-1.4735e-05, device='cuda:0') min:  tensor(-0.1317, device='cuda:0') norm:  tensor(0.3013, device='cuda:0') MSE:  tensor(1.1309e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(1.4345e-06, device='cuda:0') min:  tensor(7.9581e-13, device='cuda:0') norm:  tensor(0.0022, device='cuda:0') MSE:  tensor(8.4037e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0302, device='cuda:0')
min of d_p_list:  tensor(-0.0319, device='cuda:0')
Epoch:  27  
Training Loss: 0.09295202791690826
Test Loss:  0.08344705402851105
Test Acc:  0.0
Valid Loss:  0.07983401417732239
Valid Acc:  0.0
std:  0.0021826583946311655 
thres:  9.506790488958358e-05
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
  3%|▎         | 27/1000 [01:43<1:01:32,  3.80s/it]Epoch:   28
max of grad d_p:  tensor(0.4544, device='cuda:0')
min of grad d_p:  tensor(-0.1335, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0172, device='cuda:0') mean:  tensor(-1.3802e-05, device='cuda:0') min:  tensor(-0.1173, device='cuda:0') norm:  tensor(0.2852, device='cuda:0') MSE:  tensor(1.0704e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0008, device='cuda:0') mean:  tensor(2.7142e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0042, device='cuda:0') MSE:  tensor(1.5597e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.4330, device='cuda:0')
min of d_p_list:  tensor(-0.3932, device='cuda:0')
Epoch:  28  
Training Loss: 0.3307651877403259
Test Loss:  0.3233991861343384
Test Acc:  0.0
Valid Loss:  0.3057396411895752
Valid Acc:  0.0
std:  0.09462231814945768 
thres:  0.00014154162555932997
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
  3%|▎         | 28/1000 [01:47<1:02:01,  3.83s/it]Epoch:   29
max of grad d_p:  tensor(1.2586, device='cuda:0')
min of grad d_p:  tensor(-0.4032, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0358, device='cuda:0') mean:  tensor(-1.9272e-05, device='cuda:0') min:  tensor(-0.1009, device='cuda:0') norm:  tensor(0.3789, device='cuda:0') MSE:  tensor(1.4223e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0009, device='cuda:0') mean:  tensor(2.0247e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0031, device='cuda:0') MSE:  tensor(1.1613e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0083, device='cuda:0')
min of d_p_list:  tensor(-0.0101, device='cuda:0')
Epoch:  29  
Training Loss: 0.32720574736595154
Test Loss:  0.32014989852905273
Test Acc:  0.0
Valid Loss:  0.3026924133300781
Valid Acc:  0.0
std:  0.1154272299944492 
thres:  0.00018762462437152863
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
  3%|▎         | 29/1000 [01:50<1:00:01,  3.71s/it]Epoch:   30
max of grad d_p:  tensor(1.2303, device='cuda:0')
min of grad d_p:  tensor(-0.4019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0351, device='cuda:0') mean:  tensor(-1.4163e-05, device='cuda:0') min:  tensor(-0.0822, device='cuda:0') norm:  tensor(0.3339, device='cuda:0') MSE:  tensor(1.2532e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0014, device='cuda:0') mean:  tensor(3.8082e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0066, device='cuda:0') MSE:  tensor(2.4616e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0277, device='cuda:0')
min of d_p_list:  tensor(-0.0104, device='cuda:0')
Epoch:  30  
Training Loss: 0.3239699602127075
Test Loss:  0.3170628547668457
Test Acc:  0.0
Valid Loss:  0.300088107585907
Valid Acc:  0.0
std:  0.11484661417120251 
thres:  0.00023355819284915925
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
  3%|▎         | 30/1000 [01:54<1:00:27,  3.74s/it]Epoch:   31
max of grad d_p:  tensor(1.2656, device='cuda:0')
min of grad d_p:  tensor(-0.3932, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0400, device='cuda:0') mean:  tensor(-1.6579e-05, device='cuda:0') min:  tensor(-0.0897, device='cuda:0') norm:  tensor(0.3684, device='cuda:0') MSE:  tensor(1.3830e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(9.2261e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.8641e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0179, device='cuda:0')
min of d_p_list:  tensor(-0.0129, device='cuda:0')
Epoch:  31  
Training Loss: 0.3208375573158264
Test Loss:  0.31404709815979004
Test Acc:  0.0
Valid Loss:  0.29752451181411743
Valid Acc:  0.0
std:  0.09315562082929005 
thres:  0.00027914609611034394
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  37
  3%|▎         | 31/1000 [01:58<1:00:25,  3.74s/it]Epoch:   32
max of grad d_p:  tensor(1.2106, device='cuda:0')
min of grad d_p:  tensor(-0.3917, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0426, device='cuda:0') mean:  tensor(-1.4786e-05, device='cuda:0') min:  tensor(-0.0730, device='cuda:0') norm:  tensor(0.3519, device='cuda:0') MSE:  tensor(1.3208e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0083, device='cuda:0') mean:  tensor(1.9534e-05, device='cuda:0') min:  tensor(2.9104e-11, device='cuda:0') norm:  tensor(0.0328, device='cuda:0') MSE:  tensor(1.2314e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0694, device='cuda:0')
min of d_p_list:  tensor(-0.0489, device='cuda:0')
Epoch:  32  
Training Loss: 0.3192768096923828
Test Loss:  0.31364956498146057
Test Acc:  0.0
Valid Loss:  0.296021044254303
Valid Acc:  0.0
std:  0.004183544752740605 
thres:  0.0003244110524654388
Preserved_eigens number check:  37
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
  3%|▎         | 32/1000 [02:02<1:01:36,  3.82s/it]Epoch:   33
max of grad d_p:  tensor(1.1793, device='cuda:0')
min of grad d_p:  tensor(-0.3696, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0400, device='cuda:0') mean:  tensor(-1.2701e-05, device='cuda:0') min:  tensor(-0.0658, device='cuda:0') norm:  tensor(0.3120, device='cuda:0') MSE:  tensor(1.1712e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(1.9040e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0028, device='cuda:0') MSE:  tensor(1.0565e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0081, device='cuda:0')
min of d_p_list:  tensor(-0.0057, device='cuda:0')
Epoch:  33  
Training Loss: 0.31624269485473633
Test Loss:  0.31057509779930115
Test Acc:  0.0
Valid Loss:  0.29325413703918457
Valid Acc:  0.0
std:  0.0037862040233794707 
thres:  0.00032150655388832095
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  3%|▎         | 33/1000 [02:06<1:02:02,  3.85s/it]Epoch:   34
max of grad d_p:  tensor(1.1798, device='cuda:0')
min of grad d_p:  tensor(-0.3669, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0425, device='cuda:0') mean:  tensor(-1.4076e-05, device='cuda:0') min:  tensor(-0.0722, device='cuda:0') norm:  tensor(0.3348, device='cuda:0') MSE:  tensor(1.2567e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0009, device='cuda:0') mean:  tensor(3.0410e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0048, device='cuda:0') MSE:  tensor(1.7924e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0857, device='cuda:0')
min of d_p_list:  tensor(-0.0481, device='cuda:0')
Epoch:  34  
Training Loss: 0.31165987253189087
Test Loss:  0.30614370107650757
Test Acc:  0.0
Valid Loss:  0.2883196473121643
Valid Acc:  0.0
std:  0.004190899356978598 
thres:  0.00031839737892150875
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
  3%|▎         | 34/1000 [02:09<1:01:22,  3.81s/it]Epoch:   35
max of grad d_p:  tensor(1.0726, device='cuda:0')
min of grad d_p:  tensor(-0.3429, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0408, device='cuda:0') mean:  tensor(-1.6224e-05, device='cuda:0') min:  tensor(-0.0745, device='cuda:0') norm:  tensor(0.3254, device='cuda:0') MSE:  tensor(1.2216e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(2.0927e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0030, device='cuda:0') MSE:  tensor(1.1306e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0087, device='cuda:0')
min of d_p_list:  tensor(-0.0119, device='cuda:0')
Epoch:  35  
Training Loss: 0.3087712526321411
Test Loss:  0.3036426901817322
Test Acc:  0.0
Valid Loss:  0.2857465445995331
Valid Acc:  0.0
std:  0.0045437141144561944 
thres:  0.00031535763740539555
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
  4%|▎         | 35/1000 [02:13<1:01:32,  3.83s/it]Epoch:   36
max of grad d_p:  tensor(1.0760, device='cuda:0')
min of grad d_p:  tensor(-0.3401, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0381, device='cuda:0') mean:  tensor(-1.4874e-05, device='cuda:0') min:  tensor(-0.0783, device='cuda:0') norm:  tensor(0.3201, device='cuda:0') MSE:  tensor(1.2014e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(9.2758e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.9937e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0060, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  36  
Training Loss: 0.3057813048362732
Test Loss:  0.3008609414100647
Test Acc:  0.0
Valid Loss:  0.283240407705307
Valid Acc:  0.0
std:  0.0048900954034380014 
thres:  0.00031234638690948483
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
  4%|▎         | 36/1000 [02:17<1:01:51,  3.85s/it]Epoch:   37
max of grad d_p:  tensor(1.0685, device='cuda:0')
min of grad d_p:  tensor(-0.3399, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-1.7867e-05, device='cuda:0') min:  tensor(-0.0816, device='cuda:0') norm:  tensor(0.3121, device='cuda:0') MSE:  tensor(1.1716e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(9.8747e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0014, device='cuda:0') MSE:  tensor(5.2984e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0076, device='cuda:0')
min of d_p_list:  tensor(-0.0079, device='cuda:0')
Epoch:  37  
Training Loss: 0.30282503366470337
Test Loss:  0.29785585403442383
Test Acc:  0.0
Valid Loss:  0.2803773283958435
Valid Acc:  0.0
std:  0.004648836113326472 
thres:  0.00030905603170394897
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
  4%|▎         | 37/1000 [02:21<1:01:47,  3.85s/it]Epoch:   38
max of grad d_p:  tensor(1.0688, device='cuda:0')
min of grad d_p:  tensor(-0.3351, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0355, device='cuda:0') mean:  tensor(-1.7472e-05, device='cuda:0') min:  tensor(-0.0679, device='cuda:0') norm:  tensor(0.3064, device='cuda:0') MSE:  tensor(1.1502e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0083, device='cuda:0') mean:  tensor(1.6660e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0298, device='cuda:0') MSE:  tensor(1.1177e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0074, device='cuda:0')
min of d_p_list:  tensor(-0.0059, device='cuda:0')
Epoch:  38  
Training Loss: 0.29988834261894226
Test Loss:  0.2948395013809204
Test Acc:  0.0
Valid Loss:  0.2776581943035126
Valid Acc:  0.0
std:  0.0041704631529081715 
thres:  0.0003057851612567902
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
  4%|▍         | 38/1000 [02:25<1:02:14,  3.88s/it]Epoch:   39
max of grad d_p:  tensor(1.0591, device='cuda:0')
min of grad d_p:  tensor(-0.3337, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0408, device='cuda:0') mean:  tensor(-1.7264e-05, device='cuda:0') min:  tensor(-0.0694, device='cuda:0') norm:  tensor(0.3311, device='cuda:0') MSE:  tensor(1.2427e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.5254e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0021, device='cuda:0') MSE:  tensor(7.8274e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0029, device='cuda:0')
min of d_p_list:  tensor(-0.0030, device='cuda:0')
Epoch:  39  
Training Loss: 0.29696717858314514
Test Loss:  0.2918541431427002
Test Acc:  0.0
Valid Loss:  0.2749078869819641
Valid Acc:  0.0
std:  0.004172130135109172 
thres:  0.000302846622467041
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
  4%|▍         | 39/1000 [02:29<1:01:37,  3.85s/it]Epoch:   40
max of grad d_p:  tensor(1.0605, device='cuda:0')
min of grad d_p:  tensor(-0.3326, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0380, device='cuda:0') mean:  tensor(-1.6335e-05, device='cuda:0') min:  tensor(-0.0769, device='cuda:0') norm:  tensor(0.3151, device='cuda:0') MSE:  tensor(1.1830e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(3.6927e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0054, device='cuda:0') MSE:  tensor(2.0250e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0077, device='cuda:0')
min of d_p_list:  tensor(-0.0088, device='cuda:0')
Epoch:  40  
Training Loss: 0.2940675616264343
Test Loss:  0.28932803869247437
Test Acc:  0.0
Valid Loss:  0.27223628759384155
Valid Acc:  0.0
std:  0.0041416013843205545 
thres:  0.00029990588426589965
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  4%|▍         | 40/1000 [02:33<1:02:38,  3.92s/it]Epoch:   41
max of grad d_p:  tensor(1.0624, device='cuda:0')
min of grad d_p:  tensor(-0.3289, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0349, device='cuda:0') mean:  tensor(-1.5964e-05, device='cuda:0') min:  tensor(-0.0749, device='cuda:0') norm:  tensor(0.3080, device='cuda:0') MSE:  tensor(1.1561e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(1.3490e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0020, device='cuda:0') MSE:  tensor(7.6392e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0098, device='cuda:0')
min of d_p_list:  tensor(-0.0080, device='cuda:0')
Epoch:  41  
Training Loss: 0.29127249121665955
Test Loss:  0.2867790460586548
Test Acc:  0.0
Valid Loss:  0.26939988136291504
Valid Acc:  0.0
std:  0.004090918827529859 
thres:  0.0002970041215419769
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  4%|▍         | 41/1000 [02:37<1:02:04,  3.88s/it]Epoch:   42
max of grad d_p:  tensor(1.0505, device='cuda:0')
min of grad d_p:  tensor(-0.3252, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0374, device='cuda:0') mean:  tensor(-1.6225e-05, device='cuda:0') min:  tensor(-0.0756, device='cuda:0') norm:  tensor(0.3091, device='cuda:0') MSE:  tensor(1.1603e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(2.3349e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0037, device='cuda:0') MSE:  tensor(1.3856e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0103, device='cuda:0')
min of d_p_list:  tensor(-0.0036, device='cuda:0')
Epoch:  42  
Training Loss: 0.28842583298683167
Test Loss:  0.2840924859046936
Test Acc:  0.0
Valid Loss:  0.2665453553199768
Valid Acc:  0.0
std:  0.004047584584161269 
thres:  0.00029412428140640257
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
  4%|▍         | 42/1000 [02:40<1:01:48,  3.87s/it]Epoch:   43
max of grad d_p:  tensor(1.0457, device='cuda:0')
min of grad d_p:  tensor(-0.3209, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0399, device='cuda:0') mean:  tensor(-1.5383e-05, device='cuda:0') min:  tensor(-0.0711, device='cuda:0') norm:  tensor(0.3153, device='cuda:0') MSE:  tensor(1.1834e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0016, device='cuda:0') mean:  tensor(5.7203e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0086, device='cuda:0') MSE:  tensor(3.2237e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0049, device='cuda:0')
min of d_p_list:  tensor(-0.0045, device='cuda:0')
Epoch:  43  
Training Loss: 0.2856556475162506
Test Loss:  0.281388521194458
Test Acc:  0.0
Valid Loss:  0.26393574476242065
Valid Acc:  0.0
std:  0.003997352652843866 
thres:  0.00029127774238586426
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
  4%|▍         | 43/1000 [02:44<1:00:53,  3.82s/it]Epoch:   44
max of grad d_p:  tensor(1.0585, device='cuda:0')
min of grad d_p:  tensor(-0.3182, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0336, device='cuda:0') mean:  tensor(-1.8494e-05, device='cuda:0') min:  tensor(-0.0819, device='cuda:0') norm:  tensor(0.3218, device='cuda:0') MSE:  tensor(1.2079e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.2319e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0019, device='cuda:0') MSE:  tensor(7.1565e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0054, device='cuda:0')
min of d_p_list:  tensor(-0.0025, device='cuda:0')
Epoch:  44  
Training Loss: 0.28288745880126953
Test Loss:  0.2786788046360016
Test Acc:  0.0
Valid Loss:  0.2612784206867218
Valid Acc:  0.0
std:  0.0039566049516157505 
thres:  0.00028846179842948914
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
  4%|▍         | 44/1000 [02:48<1:01:21,  3.85s/it]Epoch:   45
max of grad d_p:  tensor(1.0665, device='cuda:0')
min of grad d_p:  tensor(-0.3141, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0403, device='cuda:0') mean:  tensor(-1.5882e-05, device='cuda:0') min:  tensor(-0.0742, device='cuda:0') norm:  tensor(0.3187, device='cuda:0') MSE:  tensor(1.1962e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(1.6145e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0023, device='cuda:0') MSE:  tensor(8.7796e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0082, device='cuda:0')
min of d_p_list:  tensor(-0.0124, device='cuda:0')
Epoch:  45  
Training Loss: 0.28008610010147095
Test Loss:  0.27596473693847656
Test Acc:  0.0
Valid Loss:  0.25887295603752136
Valid Acc:  0.0
std:  0.003947280124406846 
thres:  0.0002856655061244965
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
  4%|▍         | 45/1000 [02:52<1:00:28,  3.80s/it]Epoch:   46
max of grad d_p:  tensor(1.0688, device='cuda:0')
min of grad d_p:  tensor(-0.3098, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0250, device='cuda:0') mean:  tensor(-1.6261e-05, device='cuda:0') min:  tensor(-0.1088, device='cuda:0') norm:  tensor(0.2958, device='cuda:0') MSE:  tensor(1.1104e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(2.0122e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0030, device='cuda:0') MSE:  tensor(1.1279e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0107, device='cuda:0')
min of d_p_list:  tensor(-0.0134, device='cuda:0')
Epoch:  46  
Training Loss: 0.27748826146125793
Test Loss:  0.2734677791595459
Test Acc:  0.0
Valid Loss:  0.25650790333747864
Valid Acc:  0.0
std:  0.003881575772066562 
thres:  0.00028290866017341616
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
  5%|▍         | 46/1000 [02:56<1:00:51,  3.83s/it]Epoch:   47
max of grad d_p:  tensor(1.0857, device='cuda:0')
min of grad d_p:  tensor(-0.3059, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0319, device='cuda:0') mean:  tensor(-1.5018e-05, device='cuda:0') min:  tensor(-0.0765, device='cuda:0') norm:  tensor(0.3013, device='cuda:0') MSE:  tensor(1.1309e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(2.5048e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0043, device='cuda:0') MSE:  tensor(1.6041e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0061, device='cuda:0')
min of d_p_list:  tensor(-0.0082, device='cuda:0')
Epoch:  47  
Training Loss: 0.27345767617225647
Test Loss:  0.26942506432533264
Test Acc:  0.0
Valid Loss:  0.25328654050827026
Valid Acc:  0.0
std:  0.004228614700428794 
thres:  0.0002799150288105011
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  5%|▍         | 47/1000 [02:59<1:00:38,  3.82s/it]Epoch:   48
max of grad d_p:  tensor(1.0796, device='cuda:0')
min of grad d_p:  tensor(-0.3055, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0361, device='cuda:0') mean:  tensor(-1.7047e-05, device='cuda:0') min:  tensor(-0.0895, device='cuda:0') norm:  tensor(0.3231, device='cuda:0') MSE:  tensor(1.2127e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(1.6026e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0024, device='cuda:0') MSE:  tensor(8.8727e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0376, device='cuda:0')
min of d_p_list:  tensor(-0.0199, device='cuda:0')
Epoch:  48  
Training Loss: 0.27253055572509766
Test Loss:  0.268243670463562
Test Acc:  0.0
Valid Loss:  0.2528671622276306
Valid Acc:  0.0
std:  0.003912238339938429 
thres:  0.00027729001045227053
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
  5%|▍         | 48/1000 [03:03<59:33,  3.75s/it]  Epoch:   49
max of grad d_p:  tensor(1.0671, device='cuda:0')
min of grad d_p:  tensor(-0.3062, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0315, device='cuda:0') mean:  tensor(-1.6090e-05, device='cuda:0') min:  tensor(-0.0887, device='cuda:0') norm:  tensor(0.3016, device='cuda:0') MSE:  tensor(1.1320e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0044, device='cuda:0') mean:  tensor(1.5822e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0238, device='cuda:0') MSE:  tensor(8.9443e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0036, device='cuda:0')
min of d_p_list:  tensor(-0.0038, device='cuda:0')
Epoch:  49  
Training Loss: 0.2699017822742462
Test Loss:  0.2656729817390442
Test Acc:  0.0
Valid Loss:  0.2503672242164612
Valid Acc:  0.0
std:  0.003634748210271638 
thres:  0.0002746928751468659
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
  5%|▍         | 49/1000 [03:06<57:59,  3.66s/it]Epoch:   50
max of grad d_p:  tensor(1.0725, device='cuda:0')
min of grad d_p:  tensor(-0.3034, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0366, device='cuda:0') mean:  tensor(-1.5054e-05, device='cuda:0') min:  tensor(-0.0839, device='cuda:0') norm:  tensor(0.3189, device='cuda:0') MSE:  tensor(1.1972e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0038, device='cuda:0') mean:  tensor(1.6270e-05, device='cuda:0') min:  tensor(8.6402e-12, device='cuda:0') norm:  tensor(0.0251, device='cuda:0') MSE:  tensor(9.4120e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0249, device='cuda:0')
min of d_p_list:  tensor(-0.0232, device='cuda:0')
Epoch:  50  
Training Loss: 0.2681184709072113
Test Loss:  0.263464093208313
Test Acc:  0.0
Valid Loss:  0.24857142567634583
Valid Acc:  0.0
std:  0.0032108584132445835 
thres:  0.0002722993493080139
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
  5%|▌         | 50/1000 [03:10<58:15,  3.68s/it]Epoch:   51
max of grad d_p:  tensor(1.0671, device='cuda:0')
min of grad d_p:  tensor(-0.3032, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0351, device='cuda:0') mean:  tensor(-1.5065e-05, device='cuda:0') min:  tensor(-0.0760, device='cuda:0') norm:  tensor(0.3067, device='cuda:0') MSE:  tensor(1.1514e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(1.8412e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0025, device='cuda:0') MSE:  tensor(9.5549e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0197, device='cuda:0')
min of d_p_list:  tensor(-0.0155, device='cuda:0')
Epoch:  51  
Training Loss: 0.2654704749584198
Test Loss:  0.2608177959918976
Test Acc:  0.0
Valid Loss:  0.24616584181785583
Valid Acc:  0.0
std:  0.0029110594570506084 
thres:  0.0002698957920074463
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
  5%|▌         | 51/1000 [03:14<59:04,  3.74s/it]Epoch:   52
max of grad d_p:  tensor(1.0804, device='cuda:0')
min of grad d_p:  tensor(-0.2978, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0321, device='cuda:0') mean:  tensor(-1.4902e-05, device='cuda:0') min:  tensor(-0.0828, device='cuda:0') norm:  tensor(0.3184, device='cuda:0') MSE:  tensor(1.1951e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(2.2915e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0033, device='cuda:0') MSE:  tensor(1.2368e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0125, device='cuda:0')
min of d_p_list:  tensor(-0.0069, device='cuda:0')
Epoch:  52  
Training Loss: 0.26287561655044556
Test Loss:  0.2582690715789795
Test Acc:  0.0
Valid Loss:  0.243804931640625
Valid Acc:  0.0
std:  0.003363664171348164 
thres:  0.0002677793800830841
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  5%|▌         | 52/1000 [03:18<59:24,  3.76s/it]Epoch:   53
max of grad d_p:  tensor(1.1038, device='cuda:0')
min of grad d_p:  tensor(-0.2976, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0372, device='cuda:0') mean:  tensor(-1.4254e-05, device='cuda:0') min:  tensor(-0.0880, device='cuda:0') norm:  tensor(0.3268, device='cuda:0') MSE:  tensor(1.2267e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0893, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(5.7480e-10, device='cuda:0') norm:  tensor(0.3505, device='cuda:0') MSE:  tensor(1.3157e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0109, device='cuda:0')
min of d_p_list:  tensor(-0.0055, device='cuda:0')
Epoch:  53  
Training Loss: 0.2593884766101837
Test Loss:  0.25619953870773315
Test Acc:  0.0
Valid Loss:  0.240960955619812
Valid Acc:  0.0
std:  0.0037379653745264734 
thres:  0.0002651509642601013
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
  5%|▌         | 53/1000 [03:22<1:00:44,  3.85s/it]Epoch:   54
max of grad d_p:  tensor(1.1424, device='cuda:0')
min of grad d_p:  tensor(-0.2920, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0207, device='cuda:0') mean:  tensor(-1.4841e-05, device='cuda:0') min:  tensor(-0.1403, device='cuda:0') norm:  tensor(0.2990, device='cuda:0') MSE:  tensor(1.1222e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0010, device='cuda:0') mean:  tensor(3.1666e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0048, device='cuda:0') MSE:  tensor(1.7867e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0466, device='cuda:0')
min of d_p_list:  tensor(-0.0377, device='cuda:0')
Epoch:  54  
Training Loss: 0.2592514753341675
Test Loss:  0.2568577826023102
Test Acc:  0.0
Valid Loss:  0.24097982048988342
Valid Acc:  0.0
std:  0.003447022364473682 
thres:  0.00026302090287208557
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
  5%|▌         | 54/1000 [03:26<59:57,  3.80s/it]  Epoch:   55
max of grad d_p:  tensor(1.2178, device='cuda:0')
min of grad d_p:  tensor(-0.2711, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0230, device='cuda:0') mean:  tensor(-1.3787e-05, device='cuda:0') min:  tensor(-0.1309, device='cuda:0') norm:  tensor(0.2859, device='cuda:0') MSE:  tensor(1.0733e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0023, device='cuda:0') mean:  tensor(2.6233e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0052, device='cuda:0') MSE:  tensor(1.9335e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.7599, device='cuda:0')
min of d_p_list:  tensor(-0.8688, device='cuda:0')
Epoch:  55  
Training Loss: 1.4736146926879883
Test Loss:  1.304227352142334
Test Acc:  0.0
Valid Loss:  1.2954026460647583
Valid Acc:  0.0
std:  0.4847528278228643 
thres:  0.0005041201472282409
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
  6%|▌         | 55/1000 [03:30<1:00:41,  3.85s/it]Epoch:   56
max of grad d_p:  tensor(1.8857, device='cuda:0')
min of grad d_p:  tensor(-1.7254, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0463, device='cuda:0') mean:  tensor(-2.6427e-05, device='cuda:0') min:  tensor(-0.1958, device='cuda:0') norm:  tensor(0.5039, device='cuda:0') MSE:  tensor(1.8916e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0014, device='cuda:0') mean:  tensor(3.2924e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0047, device='cuda:0') MSE:  tensor(1.7666e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0572, device='cuda:0')
min of d_p_list:  tensor(-0.0354, device='cuda:0')
Epoch:  56  
Training Loss: 1.4626855850219727
Test Loss:  1.2955758571624756
Test Acc:  0.0
Valid Loss:  1.2895795106887817
Valid Acc:  0.0
std:  0.5916343040961395 
thres:  0.0007435631692409516
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
  6%|▌         | 56/1000 [03:33<1:00:54,  3.87s/it]Epoch:   57
max of grad d_p:  tensor(1.8463, device='cuda:0')
min of grad d_p:  tensor(-1.6560, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0559, device='cuda:0') mean:  tensor(-3.0108e-05, device='cuda:0') min:  tensor(-0.2137, device='cuda:0') norm:  tensor(0.5277, device='cuda:0') MSE:  tensor(1.9807e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(8.0317e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.0653e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0187, device='cuda:0')
min of d_p_list:  tensor(-0.0147, device='cuda:0')
Epoch:  57  
Training Loss: 1.4481914043426514
Test Loss:  1.2819077968597412
Test Acc:  0.0
Valid Loss:  1.2757068872451782
Valid Acc:  0.0
std:  0.5889994010098267 
thres:  0.0009806263267993927
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
  6%|▌         | 57/1000 [03:37<59:07,  3.76s/it]  Epoch:   58
max of grad d_p:  tensor(1.8259, device='cuda:0')
min of grad d_p:  tensor(-1.6252, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0548, device='cuda:0') mean:  tensor(-2.1423e-05, device='cuda:0') min:  tensor(-0.1756, device='cuda:0') norm:  tensor(0.4516, device='cuda:0') MSE:  tensor(1.6952e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0009, device='cuda:0') mean:  tensor(1.7685e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0028, device='cuda:0') MSE:  tensor(1.0641e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0321, device='cuda:0')
min of d_p_list:  tensor(-0.0174, device='cuda:0')
Epoch:  58  
Training Loss: 1.436102032661438
Test Loss:  1.2711410522460938
Test Acc:  0.0
Valid Loss:  1.2647044658660889
Valid Acc:  0.0
std:  0.47852786657324187 
thres:  0.0012159690380096435
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
  6%|▌         | 58/1000 [03:41<57:55,  3.69s/it]Epoch:   59
max of grad d_p:  tensor(1.8541, device='cuda:0')
min of grad d_p:  tensor(-1.6029, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0550, device='cuda:0') mean:  tensor(-2.3720e-05, device='cuda:0') min:  tensor(-0.1992, device='cuda:0') norm:  tensor(0.4754, device='cuda:0') MSE:  tensor(1.7844e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0183, device='cuda:0') mean:  tensor(3.1963e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0510, device='cuda:0') MSE:  tensor(1.9157e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0281, device='cuda:0')
min of d_p_list:  tensor(-0.0205, device='cuda:0')
Epoch:  59  
Training Loss: 1.422356128692627
Test Loss:  1.2581472396850586
Test Acc:  0.0
Valid Loss:  1.2507984638214111
Valid Acc:  0.0
std:  0.018271535084682235 
thres:  0.0014485899686813356
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
  6%|▌         | 59/1000 [03:44<58:04,  3.70s/it]Epoch:   60
max of grad d_p:  tensor(1.8138, device='cuda:0')
min of grad d_p:  tensor(-1.5751, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0557, device='cuda:0') mean:  tensor(-2.1530e-05, device='cuda:0') min:  tensor(-0.1801, device='cuda:0') norm:  tensor(0.4289, device='cuda:0') MSE:  tensor(1.6100e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(3.8961e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0048, device='cuda:0') MSE:  tensor(1.7887e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0429, device='cuda:0')
min of d_p_list:  tensor(-0.0714, device='cuda:0')
Epoch:  60  
Training Loss: 1.409350872039795
Test Loss:  1.253908395767212
Test Acc:  0.0
Valid Loss:  1.2442395687103271
Valid Acc:  0.0
std:  0.018744317200304988 
thres:  0.0014357372045516968
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
  6%|▌         | 60/1000 [03:48<57:36,  3.68s/it]Epoch:   61
max of grad d_p:  tensor(1.8282, device='cuda:0')
min of grad d_p:  tensor(-1.5556, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0663, device='cuda:0') mean:  tensor(-2.6852e-05, device='cuda:0') min:  tensor(-0.1803, device='cuda:0') norm:  tensor(0.4518, device='cuda:0') MSE:  tensor(1.6958e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(3.2255e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0042, device='cuda:0') MSE:  tensor(1.5820e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0137, device='cuda:0')
min of d_p_list:  tensor(-0.0202, device='cuda:0')
Epoch:  61  
Training Loss: 1.395036220550537
Test Loss:  1.2430059909820557
Test Acc:  0.0
Valid Loss:  1.2319788932800293
Valid Acc:  0.0
std:  0.018824530392773844 
thres:  0.0014222073316574099
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
  6%|▌         | 61/1000 [03:52<57:29,  3.67s/it]Epoch:   62
max of grad d_p:  tensor(1.8684, device='cuda:0')
min of grad d_p:  tensor(-1.5227, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0499, device='cuda:0') mean:  tensor(-2.4958e-05, device='cuda:0') min:  tensor(-0.1991, device='cuda:0') norm:  tensor(0.4845, device='cuda:0') MSE:  tensor(1.8186e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.1689e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0017, device='cuda:0') MSE:  tensor(6.5119e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0100, device='cuda:0')
min of d_p_list:  tensor(-0.0143, device='cuda:0')
Epoch:  62  
Training Loss: 1.3801677227020264
Test Loss:  1.2300937175750732
Test Acc:  0.0
Valid Loss:  1.221708059310913
Valid Acc:  0.0
std:  0.019690236959279746 
thres:  0.0014086025953292847
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
  6%|▌         | 62/1000 [03:56<59:13,  3.79s/it]Epoch:   63
max of grad d_p:  tensor(1.8179, device='cuda:0')
min of grad d_p:  tensor(-1.4979, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0503, device='cuda:0') mean:  tensor(-2.4858e-05, device='cuda:0') min:  tensor(-0.1915, device='cuda:0') norm:  tensor(0.4848, device='cuda:0') MSE:  tensor(1.8198e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.0015e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.7105e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0083, device='cuda:0')
min of d_p_list:  tensor(-0.0065, device='cuda:0')
Epoch:  63  
Training Loss: 1.3662493228912354
Test Loss:  1.217793583869934
Test Acc:  0.0
Valid Loss:  1.2097101211547852
Valid Acc:  0.0
std:  0.020001137856339564 
thres:  0.0013946320533752441
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
  6%|▋         | 63/1000 [03:59<59:29,  3.81s/it]Epoch:   64
max of grad d_p:  tensor(1.8151, device='cuda:0')
min of grad d_p:  tensor(-1.4835, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0421, device='cuda:0') mean:  tensor(-2.7000e-05, device='cuda:0') min:  tensor(-0.2063, device='cuda:0') norm:  tensor(0.4706, device='cuda:0') MSE:  tensor(1.7666e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(7.4841e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.5965e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0541, device='cuda:0')
min of d_p_list:  tensor(-0.0458, device='cuda:0')
Epoch:  64  
Training Loss: 1.357922077178955
Test Loss:  1.213536262512207
Test Acc:  0.0
Valid Loss:  1.2041136026382446
Valid Acc:  0.0
std:  0.01870227889309957 
thres:  0.0013817452430725098
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
  6%|▋         | 64/1000 [04:03<59:48,  3.83s/it]Epoch:   65
max of grad d_p:  tensor(1.8014, device='cuda:0')
min of grad d_p:  tensor(-1.4777, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0450, device='cuda:0') mean:  tensor(-2.6220e-05, device='cuda:0') min:  tensor(-0.1813, device='cuda:0') norm:  tensor(0.4570, device='cuda:0') MSE:  tensor(1.7154e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(9.6324e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.8867e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0231, device='cuda:0')
min of d_p_list:  tensor(-0.0114, device='cuda:0')
Epoch:  65  
Training Loss: 1.3441660404205322
Test Loss:  1.1993227005004883
Test Acc:  0.0
Valid Loss:  1.1904228925704956
Valid Acc:  0.0
std:  0.017602212620060266 
thres:  0.0013687082767486571
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
  6%|▋         | 65/1000 [04:07<59:40,  3.83s/it]Epoch:   66
max of grad d_p:  tensor(1.7740, device='cuda:0')
min of grad d_p:  tensor(-1.4543, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0509, device='cuda:0') mean:  tensor(-2.8594e-05, device='cuda:0') min:  tensor(-0.2108, device='cuda:0') norm:  tensor(0.4737, device='cuda:0') MSE:  tensor(1.7781e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0274, device='cuda:0') mean:  tensor(6.1294e-05, device='cuda:0') min:  tensor(5.8208e-11, device='cuda:0') norm:  tensor(0.0857, device='cuda:0') MSE:  tensor(3.2182e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0099, device='cuda:0')
min of d_p_list:  tensor(-0.0135, device='cuda:0')
Epoch:  66  
Training Loss: 1.329630732536316
Test Loss:  1.1856975555419922
Test Acc:  0.0
Valid Loss:  1.1766045093536377
Valid Acc:  0.0
std:  0.017478602403887464 
thres:  0.001355627179145813
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
  7%|▋         | 66/1000 [04:11<1:00:18,  3.87s/it]Epoch:   67
max of grad d_p:  tensor(1.7650, device='cuda:0')
min of grad d_p:  tensor(-1.4332, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0756, device='cuda:0') mean:  tensor(-2.9730e-05, device='cuda:0') min:  tensor(-0.1952, device='cuda:0') norm:  tensor(0.5013, device='cuda:0') MSE:  tensor(1.8819e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.3266e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0016, device='cuda:0') MSE:  tensor(6.1318e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1125, device='cuda:0')
min of d_p_list:  tensor(-0.0835, device='cuda:0')
Epoch:  67  
Training Loss: 1.3228849172592163
Test Loss:  1.177717685699463
Test Acc:  0.0
Valid Loss:  1.1710494756698608
Valid Acc:  0.0
std:  0.016377186483045324 
thres:  0.001344170618057251
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
  7%|▋         | 67/1000 [04:15<59:57,  3.86s/it]  Epoch:   68
max of grad d_p:  tensor(1.8463, device='cuda:0')
min of grad d_p:  tensor(-1.4599, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1042, device='cuda:0') mean:  tensor(-3.1075e-05, device='cuda:0') min:  tensor(-0.1597, device='cuda:0') norm:  tensor(0.4777, device='cuda:0') MSE:  tensor(1.7930e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(7.5136e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.0184e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0232, device='cuda:0')
min of d_p_list:  tensor(-0.0079, device='cuda:0')
Epoch:  68  
Training Loss: 1.3088641166687012
Test Loss:  1.1667842864990234
Test Acc:  0.0
Valid Loss:  1.1589919328689575
Valid Acc:  0.0
std:  0.01697956795690115 
thres:  0.001332693576812744
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
  7%|▋         | 68/1000 [04:19<59:50,  3.85s/it]Epoch:   69
max of grad d_p:  tensor(1.8971, device='cuda:0')
min of grad d_p:  tensor(-1.4252, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0974, device='cuda:0') mean:  tensor(-2.6313e-05, device='cuda:0') min:  tensor(-0.1380, device='cuda:0') norm:  tensor(0.4357, device='cuda:0') MSE:  tensor(1.6353e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.2141e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0016, device='cuda:0') MSE:  tensor(5.8380e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0077, device='cuda:0')
min of d_p_list:  tensor(-0.0082, device='cuda:0')
Epoch:  69  
Training Loss: 1.2956167459487915
Test Loss:  1.1557857990264893
Test Acc:  0.0
Valid Loss:  1.147618293762207
Valid Acc:  0.0
std:  0.01675322020544879 
thres:  0.0013202325105667115
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
  7%|▋         | 69/1000 [04:22<58:48,  3.79s/it]Epoch:   70
max of grad d_p:  tensor(1.9002, device='cuda:0')
min of grad d_p:  tensor(-1.4027, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1103, device='cuda:0') mean:  tensor(-2.6664e-05, device='cuda:0') min:  tensor(-0.1426, device='cuda:0') norm:  tensor(0.4443, device='cuda:0') MSE:  tensor(1.6677e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(1.6168e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0024, device='cuda:0') MSE:  tensor(8.8791e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0128, device='cuda:0')
min of d_p_list:  tensor(-0.0200, device='cuda:0')
Epoch:  70  
Training Loss: 1.2828668355941772
Test Loss:  1.1453635692596436
Test Acc:  0.0
Valid Loss:  1.1369935274124146
Valid Acc:  0.0
std:  0.017176805574273344 
thres:  0.0013079726696014404
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
  7%|▋         | 70/1000 [04:26<58:49,  3.80s/it]Epoch:   71
max of grad d_p:  tensor(1.9394, device='cuda:0')
min of grad d_p:  tensor(-1.3893, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0916, device='cuda:0') mean:  tensor(-3.0435e-05, device='cuda:0') min:  tensor(-0.1509, device='cuda:0') norm:  tensor(0.4640, device='cuda:0') MSE:  tensor(1.7417e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0009, device='cuda:0') mean:  tensor(2.8905e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0045, device='cuda:0') MSE:  tensor(1.6751e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0174, device='cuda:0')
min of d_p_list:  tensor(-0.0124, device='cuda:0')
Epoch:  71  
Training Loss: 1.269087553024292
Test Loss:  1.1336742639541626
Test Acc:  0.0
Valid Loss:  1.1247977018356323
Valid Acc:  0.0
std:  0.018894965110972314 
thres:  0.0012958640336990356
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  36
  7%|▋         | 71/1000 [04:30<58:52,  3.80s/it]Epoch:   72
max of grad d_p:  tensor(1.9503, device='cuda:0')
min of grad d_p:  tensor(-1.3775, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0829, device='cuda:0') mean:  tensor(-2.7417e-05, device='cuda:0') min:  tensor(-0.1495, device='cuda:0') norm:  tensor(0.4480, device='cuda:0') MSE:  tensor(1.6817e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0011, device='cuda:0') mean:  tensor(3.3920e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0046, device='cuda:0') MSE:  tensor(1.7335e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0375, device='cuda:0')
min of d_p_list:  tensor(-0.0357, device='cuda:0')
Epoch:  72  
Training Loss: 1.1522380113601685
Test Loss:  1.0306942462921143
Test Acc:  0.0
Valid Loss:  1.018690586090088
Valid Acc:  0.0
std:  0.056319324176791294 
thres:  0.0012617346525192262
Preserved_eigens number check:  36
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
  7%|▋         | 72/1000 [04:34<57:57,  3.75s/it]Epoch:   73
max of grad d_p:  tensor(1.8041, device='cuda:0')
min of grad d_p:  tensor(-1.2728, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0945, device='cuda:0') mean:  tensor(-2.5927e-05, device='cuda:0') min:  tensor(-0.1573, device='cuda:0') norm:  tensor(0.4568, device='cuda:0') MSE:  tensor(1.7147e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(2.4401e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0035, device='cuda:0') MSE:  tensor(1.3075e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0129, device='cuda:0')
min of d_p_list:  tensor(-0.0065, device='cuda:0')
Epoch:  73  
Training Loss: 1.1400734186172485
Test Loss:  1.0206208229064941
Test Acc:  0.0
Valid Loss:  1.008075475692749
Valid Acc:  0.0
std:  0.06744114600516252 
thres:  0.0012279765129089356
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
  7%|▋         | 73/1000 [04:38<58:16,  3.77s/it]Epoch:   74
max of grad d_p:  tensor(1.8227, device='cuda:0')
min of grad d_p:  tensor(-1.2475, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1007, device='cuda:0') mean:  tensor(-2.5635e-05, device='cuda:0') min:  tensor(-0.1612, device='cuda:0') norm:  tensor(0.4499, device='cuda:0') MSE:  tensor(1.6887e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0014, device='cuda:0') mean:  tensor(6.4809e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0083, device='cuda:0') MSE:  tensor(3.1224e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0152, device='cuda:0')
min of d_p_list:  tensor(-0.0107, device='cuda:0')
Epoch:  74  
Training Loss: 1.1277503967285156
Test Loss:  1.0105550289154053
Test Acc:  0.0
Valid Loss:  0.9991805553436279
Valid Acc:  0.0
std:  0.06719492818846454 
thres:  0.0011944032430648804
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
  7%|▋         | 74/1000 [04:41<58:57,  3.82s/it]Epoch:   75
max of grad d_p:  tensor(1.8813, device='cuda:0')
min of grad d_p:  tensor(-1.2176, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1037, device='cuda:0') mean:  tensor(-2.4501e-05, device='cuda:0') min:  tensor(-0.1592, device='cuda:0') norm:  tensor(0.4503, device='cuda:0') MSE:  tensor(1.6905e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0009, device='cuda:0') mean:  tensor(2.4374e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0036, device='cuda:0') MSE:  tensor(1.3526e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0111, device='cuda:0')
min of d_p_list:  tensor(-0.0044, device='cuda:0')
Epoch:  75  
Training Loss: 1.116027593612671
Test Loss:  1.000853180885315
Test Acc:  0.0
Valid Loss:  0.9890444278717041
Valid Acc:  0.0
std:  0.055363635289128105 
thres:  0.0011610353946685792
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
  8%|▊         | 75/1000 [04:45<58:56,  3.82s/it]Epoch:   76
max of grad d_p:  tensor(1.8838, device='cuda:0')
min of grad d_p:  tensor(-1.2013, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0868, device='cuda:0') mean:  tensor(-2.1864e-05, device='cuda:0') min:  tensor(-0.1526, device='cuda:0') norm:  tensor(0.4193, device='cuda:0') MSE:  tensor(1.5740e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(8.6399e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.6704e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0240, device='cuda:0')
min of d_p_list:  tensor(-0.0187, device='cuda:0')
Epoch:  76  
Training Loss: 1.103833556175232
Test Loss:  0.9909672737121582
Test Acc:  0.0
Valid Loss:  0.9775831699371338
Valid Acc:  0.0
std:  0.01709190023906671 
thres:  0.0011279845952987672
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
  8%|▊         | 76/1000 [04:49<58:20,  3.79s/it]Epoch:   77
max of grad d_p:  tensor(1.9190, device='cuda:0')
min of grad d_p:  tensor(-1.1884, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0898, device='cuda:0') mean:  tensor(-2.3967e-05, device='cuda:0') min:  tensor(-0.1623, device='cuda:0') norm:  tensor(0.4569, device='cuda:0') MSE:  tensor(1.7153e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(2.3901e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0032, device='cuda:0') MSE:  tensor(1.1870e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0179, device='cuda:0')
min of d_p_list:  tensor(-0.0122, device='cuda:0')
Epoch:  77  
Training Loss: 1.0921416282653809
Test Loss:  0.9811040163040161
Test Acc:  0.0
Valid Loss:  0.967008113861084
Valid Acc:  0.0
std:  0.01694013171026081 
thres:  0.0011159653186798096
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
  8%|▊         | 77/1000 [04:53<57:11,  3.72s/it]Epoch:   78
max of grad d_p:  tensor(1.9314, device='cuda:0')
min of grad d_p:  tensor(-1.1684, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1157, device='cuda:0') mean:  tensor(-2.2283e-05, device='cuda:0') min:  tensor(-0.1482, device='cuda:0') norm:  tensor(0.4301, device='cuda:0') MSE:  tensor(1.6145e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.9773e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.2079e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0898, device='cuda:0')
min of d_p_list:  tensor(-0.1846, device='cuda:0')
Epoch:  78  
Training Loss: 1.0708378553390503
Test Loss:  0.9644467830657959
Test Acc:  0.0
Valid Loss:  0.9482427835464478
Valid Acc:  0.0
std:  0.019654084218263992 
thres:  0.00110211820602417
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
  8%|▊         | 78/1000 [04:57<58:29,  3.81s/it]Epoch:   79
max of grad d_p:  tensor(1.6901, device='cuda:0')
min of grad d_p:  tensor(-1.1467, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1185, device='cuda:0') mean:  tensor(-2.0553e-05, device='cuda:0') min:  tensor(-0.1760, device='cuda:0') norm:  tensor(0.4699, device='cuda:0') MSE:  tensor(1.7638e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(2.1084e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0031, device='cuda:0') MSE:  tensor(1.1452e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0294, device='cuda:0')
min of d_p_list:  tensor(-0.0353, device='cuda:0')
Epoch:  79  
Training Loss: 1.058434247970581
Test Loss:  0.9543008804321289
Test Acc:  0.0
Valid Loss:  0.9373639822006226
Valid Acc:  0.0
std:  0.021079603542241542 
thres:  0.001088254976272583
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
  8%|▊         | 79/1000 [05:00<57:31,  3.75s/it]Epoch:   80
max of grad d_p:  tensor(1.7097, device='cuda:0')
min of grad d_p:  tensor(-1.1220, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1270, device='cuda:0') mean:  tensor(-1.9998e-05, device='cuda:0') min:  tensor(-0.1631, device='cuda:0') norm:  tensor(0.4477, device='cuda:0') MSE:  tensor(1.6806e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(1.7543e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0024, device='cuda:0') MSE:  tensor(9.1727e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0107, device='cuda:0')
min of d_p_list:  tensor(-0.0048, device='cuda:0')
Epoch:  80  
Training Loss: 1.0481442213058472
Test Loss:  0.9448967576026917
Test Acc:  0.0
Valid Loss:  0.9282277226448059
Valid Acc:  0.0
std:  0.02067690678231933 
thres:  0.0010746783018112183
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
  8%|▊         | 80/1000 [05:04<58:08,  3.79s/it]Epoch:   81
max of grad d_p:  tensor(1.7388, device='cuda:0')
min of grad d_p:  tensor(-1.1103, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1213, device='cuda:0') mean:  tensor(-1.8270e-05, device='cuda:0') min:  tensor(-0.1539, device='cuda:0') norm:  tensor(0.4255, device='cuda:0') MSE:  tensor(1.5974e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(9.8660e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.8111e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0067, device='cuda:0')
min of d_p_list:  tensor(-0.0057, device='cuda:0')
Epoch:  81  
Training Loss: 1.03780198097229
Test Loss:  0.9356666207313538
Test Acc:  0.0
Valid Loss:  0.9193253517150879
Valid Acc:  0.0
std:  0.018843952702405593 
thres:  0.0010614719867706299
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
  8%|▊         | 81/1000 [05:08<58:02,  3.79s/it]Epoch:   82
max of grad d_p:  tensor(1.7538, device='cuda:0')
min of grad d_p:  tensor(-1.0974, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1166, device='cuda:0') mean:  tensor(-1.7303e-05, device='cuda:0') min:  tensor(-0.1418, device='cuda:0') norm:  tensor(0.4352, device='cuda:0') MSE:  tensor(1.6337e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(8.4606e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.4690e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0250, device='cuda:0')
min of d_p_list:  tensor(-0.0233, device='cuda:0')
Epoch:  82  
Training Loss: 1.0278642177581787
Test Loss:  0.9265100955963135
Test Acc:  0.0
Valid Loss:  0.9102299213409424
Valid Acc:  0.0
std:  0.015086489953119918 
thres:  0.0010486165046691895
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
  8%|▊         | 82/1000 [05:12<59:23,  3.88s/it]Epoch:   83
max of grad d_p:  tensor(1.7607, device='cuda:0')
min of grad d_p:  tensor(-1.0943, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1310, device='cuda:0') mean:  tensor(-1.6825e-05, device='cuda:0') min:  tensor(-0.1373, device='cuda:0') norm:  tensor(0.4062, device='cuda:0') MSE:  tensor(1.5248e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.4998e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0021, device='cuda:0') MSE:  tensor(7.9184e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0119, device='cuda:0')
min of d_p_list:  tensor(-0.0098, device='cuda:0')
Epoch:  83  
Training Loss: 1.0173687934875488
Test Loss:  0.9170384407043457
Test Acc:  0.0
Valid Loss:  0.9005116820335388
Valid Acc:  0.0
std:  0.014483465116955313 
thres:  0.0010379226922988892
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
  8%|▊         | 83/1000 [05:16<59:04,  3.87s/it]Epoch:   84
max of grad d_p:  tensor(1.7918, device='cuda:0')
min of grad d_p:  tensor(-1.0608, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1383, device='cuda:0') mean:  tensor(-1.8933e-05, device='cuda:0') min:  tensor(-0.1479, device='cuda:0') norm:  tensor(0.4247, device='cuda:0') MSE:  tensor(1.5943e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(7.5069e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(3.9480e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0093, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  84  
Training Loss: 1.0072386264801025
Test Loss:  0.9079089760780334
Test Acc:  0.0
Valid Loss:  0.8914279937744141
Valid Acc:  0.0
std:  0.01445989941949633 
thres:  0.0010276835680007935
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
  8%|▊         | 84/1000 [05:19<58:17,  3.82s/it]Epoch:   85
max of grad d_p:  tensor(1.7847, device='cuda:0')
min of grad d_p:  tensor(-1.0449, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1194, device='cuda:0') mean:  tensor(-1.6509e-05, device='cuda:0') min:  tensor(-0.1455, device='cuda:0') norm:  tensor(0.4354, device='cuda:0') MSE:  tensor(1.6344e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.2131e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(3.1100e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0167, device='cuda:0')
min of d_p_list:  tensor(-0.0089, device='cuda:0')
Epoch:  85  
Training Loss: 0.9971091747283936
Test Loss:  0.8986096382141113
Test Acc:  0.0
Valid Loss:  0.8821315169334412
Valid Acc:  0.0
std:  0.014426943200712661 
thres:  0.0010174765586853027
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
  8%|▊         | 85/1000 [05:23<58:17,  3.82s/it]Epoch:   86
max of grad d_p:  tensor(1.7761, device='cuda:0')
min of grad d_p:  tensor(-1.0253, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1183, device='cuda:0') mean:  tensor(-1.9814e-05, device='cuda:0') min:  tensor(-0.1587, device='cuda:0') norm:  tensor(0.4389, device='cuda:0') MSE:  tensor(1.6477e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0008, device='cuda:0') mean:  tensor(1.3295e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0021, device='cuda:0') MSE:  tensor(8.0334e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0959, device='cuda:0')
min of d_p_list:  tensor(-0.1287, device='cuda:0')
Epoch:  86  
Training Loss: 0.9484590291976929
Test Loss:  0.8525871634483337
Test Acc:  0.0
Valid Loss:  0.8391056060791016
Valid Acc:  0.0
std:  0.027548311852642022 
thres:  0.0009996079683303833
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
  9%|▊         | 86/1000 [05:27<58:03,  3.81s/it]Epoch:   87
max of grad d_p:  tensor(1.5721, device='cuda:0')
min of grad d_p:  tensor(-1.0201, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1040, device='cuda:0') mean:  tensor(-2.3564e-05, device='cuda:0') min:  tensor(-0.1777, device='cuda:0') norm:  tensor(0.4185, device='cuda:0') MSE:  tensor(1.5711e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0578, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(1.6553e-10, device='cuda:0') norm:  tensor(0.2930, device='cuda:0') MSE:  tensor(1.0997e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0071, device='cuda:0')
min of d_p_list:  tensor(-0.0064, device='cuda:0')
Epoch:  87  
Training Loss: 0.9389212131500244
Test Loss:  0.8446402549743652
Test Acc:  0.0
Valid Loss:  0.8309138417243958
Valid Acc:  0.0
std:  0.03192755060602639 
thres:  0.0009818193674087524
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
  9%|▊         | 87/1000 [05:31<57:54,  3.81s/it]Epoch:   88
max of grad d_p:  tensor(1.5801, device='cuda:0')
min of grad d_p:  tensor(-1.0073, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1241, device='cuda:0') mean:  tensor(-2.4418e-05, device='cuda:0') min:  tensor(-0.1995, device='cuda:0') norm:  tensor(0.4720, device='cuda:0') MSE:  tensor(1.7718e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.4089e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.5947e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0084, device='cuda:0')
min of d_p_list:  tensor(-0.0054, device='cuda:0')
Epoch:  88  
Training Loss: 0.9296079277992249
Test Loss:  0.8363145589828491
Test Acc:  0.0
Valid Loss:  0.8226419687271118
Valid Acc:  0.0
std:  0.031681923113335814 
thres:  0.0009642671942710877
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
  9%|▉         | 88/1000 [05:35<57:47,  3.80s/it]Epoch:   89
max of grad d_p:  tensor(1.5796, device='cuda:0')
min of grad d_p:  tensor(-0.9964, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1058, device='cuda:0') mean:  tensor(-2.4936e-05, device='cuda:0') min:  tensor(-0.1862, device='cuda:0') norm:  tensor(0.4736, device='cuda:0') MSE:  tensor(1.7778e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0013, device='cuda:0') mean:  tensor(3.9403e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0062, device='cuda:0') MSE:  tensor(2.3223e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0091, device='cuda:0')
min of d_p_list:  tensor(-0.0110, device='cuda:0')
Epoch:  89  
Training Loss: 0.9192349910736084
Test Loss:  0.8256708979606628
Test Acc:  0.0
Valid Loss:  0.8140254616737366
Valid Acc:  0.0
std:  0.02702276311027382 
thres:  0.0009466664671897889
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
  9%|▉         | 89/1000 [05:39<57:53,  3.81s/it]Epoch:   90
max of grad d_p:  tensor(1.5761, device='cuda:0')
min of grad d_p:  tensor(-0.9780, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1114, device='cuda:0') mean:  tensor(-2.0405e-05, device='cuda:0') min:  tensor(-0.1826, device='cuda:0') norm:  tensor(0.4100, device='cuda:0') MSE:  tensor(1.5392e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.4928e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0021, device='cuda:0') MSE:  tensor(7.8992e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0232, device='cuda:0')
min of d_p_list:  tensor(-0.0143, device='cuda:0')
Epoch:  90  
Training Loss: 0.9098118543624878
Test Loss:  0.8170384168624878
Test Acc:  0.0
Valid Loss:  0.8050249218940735
Valid Acc:  0.0
std:  0.01371699635329405 
thres:  0.0009292070031166077
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
  9%|▉         | 90/1000 [05:42<57:39,  3.80s/it]Epoch:   91
max of grad d_p:  tensor(1.6215, device='cuda:0')
min of grad d_p:  tensor(-0.9460, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1205, device='cuda:0') mean:  tensor(-2.1927e-05, device='cuda:0') min:  tensor(-0.2104, device='cuda:0') norm:  tensor(0.4533, device='cuda:0') MSE:  tensor(1.7014e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.2403e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0016, device='cuda:0') MSE:  tensor(5.9913e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0126, device='cuda:0')
min of d_p_list:  tensor(-0.0145, device='cuda:0')
Epoch:  91  
Training Loss: 0.9005359411239624
Test Loss:  0.8077521920204163
Test Acc:  0.0
Valid Loss:  0.796034574508667
Valid Acc:  0.0
std:  0.013659024549624536 
thres:  0.0009196223855018616
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
  9%|▉         | 91/1000 [05:46<58:22,  3.85s/it]Epoch:   92
max of grad d_p:  tensor(1.6485, device='cuda:0')
min of grad d_p:  tensor(-0.9319, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1050, device='cuda:0') mean:  tensor(-2.0767e-05, device='cuda:0') min:  tensor(-0.1814, device='cuda:0') norm:  tensor(0.4389, device='cuda:0') MSE:  tensor(1.6475e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.1916e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0017, device='cuda:0') MSE:  tensor(6.4262e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0084, device='cuda:0')
min of d_p_list:  tensor(-0.0064, device='cuda:0')
Epoch:  92  
Training Loss: 0.8916483521461487
Test Loss:  0.7997395992279053
Test Acc:  0.0
Valid Loss:  0.7879104614257812
Valid Acc:  0.0
std:  0.013386574426125009 
thres:  0.0009101678133010864
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
  9%|▉         | 92/1000 [05:50<57:48,  3.82s/it]Epoch:   93
max of grad d_p:  tensor(1.6510, device='cuda:0')
min of grad d_p:  tensor(-0.9229, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1272, device='cuda:0') mean:  tensor(-1.9801e-05, device='cuda:0') min:  tensor(-0.1669, device='cuda:0') norm:  tensor(0.4337, device='cuda:0') MSE:  tensor(1.6280e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(1.8694e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0026, device='cuda:0') MSE:  tensor(9.9371e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0079, device='cuda:0')
min of d_p_list:  tensor(-0.0040, device='cuda:0')
Epoch:  93  
Training Loss: 0.8824541568756104
Test Loss:  0.7919400930404663
Test Acc:  0.0
Valid Loss:  0.7792062759399414
Valid Acc:  0.0
std:  0.012972547572748983 
thres:  0.0009007370591163635
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
  9%|▉         | 93/1000 [05:54<58:12,  3.85s/it]Epoch:   94
max of grad d_p:  tensor(1.6646, device='cuda:0')
min of grad d_p:  tensor(-0.9114, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1034, device='cuda:0') mean:  tensor(-2.0178e-05, device='cuda:0') min:  tensor(-0.1869, device='cuda:0') norm:  tensor(0.4042, device='cuda:0') MSE:  tensor(1.5174e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.6086e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0022, device='cuda:0') MSE:  tensor(8.2183e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0188, device='cuda:0')
min of d_p_list:  tensor(-0.0264, device='cuda:0')
Epoch:  94  
Training Loss: 0.8756680488586426
Test Loss:  0.7851951718330383
Test Acc:  0.0
Valid Loss:  0.7730333805084229
Valid Acc:  0.0
std:  0.012231934029012749 
thres:  0.0008920236706733704
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
  9%|▉         | 94/1000 [05:58<58:45,  3.89s/it]Epoch:   95
max of grad d_p:  tensor(1.5846, device='cuda:0')
min of grad d_p:  tensor(-0.9169, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1197, device='cuda:0') mean:  tensor(-2.0214e-05, device='cuda:0') min:  tensor(-0.1772, device='cuda:0') norm:  tensor(0.4018, device='cuda:0') MSE:  tensor(1.5082e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(3.3608e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0046, device='cuda:0') MSE:  tensor(1.7337e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0060, device='cuda:0')
min of d_p_list:  tensor(-0.0040, device='cuda:0')
Epoch:  95  
Training Loss: 0.8669735789299011
Test Loss:  0.7774076461791992
Test Acc:  0.0
Valid Loss:  0.7653672695159912
Valid Acc:  0.0
std:  0.011765756239540327 
thres:  0.0008834560155868531
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 10%|▉         | 95/1000 [06:02<58:18,  3.87s/it]Epoch:   96
max of grad d_p:  tensor(1.5897, device='cuda:0')
min of grad d_p:  tensor(-0.9082, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1292, device='cuda:0') mean:  tensor(-2.1407e-05, device='cuda:0') min:  tensor(-0.1815, device='cuda:0') norm:  tensor(0.4393, device='cuda:0') MSE:  tensor(1.6490e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.3106e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0019, device='cuda:0') MSE:  tensor(7.3036e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0110, device='cuda:0')
min of d_p_list:  tensor(-0.0060, device='cuda:0')
Epoch:  96  
Training Loss: 0.8581761717796326
Test Loss:  0.7698085904121399
Test Acc:  0.0
Valid Loss:  0.7575414180755615
Valid Acc:  0.0
std:  0.011667405317590602 
thres:  0.000874984061717987
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 10%|▉         | 96/1000 [06:06<58:03,  3.85s/it]Epoch:   97
max of grad d_p:  tensor(1.6005, device='cuda:0')
min of grad d_p:  tensor(-0.8910, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1065, device='cuda:0') mean:  tensor(-1.9365e-05, device='cuda:0') min:  tensor(-0.1709, device='cuda:0') norm:  tensor(0.4005, device='cuda:0') MSE:  tensor(1.5035e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0059, device='cuda:0') mean:  tensor(1.3300e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0203, device='cuda:0') MSE:  tensor(7.6109e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0320, device='cuda:0')
min of d_p_list:  tensor(-0.0284, device='cuda:0')
Epoch:  97  
Training Loss: 0.8488883972167969
Test Loss:  0.7618429660797119
Test Acc:  0.0
Valid Loss:  0.7492163777351379
Valid Acc:  0.0
std:  0.01198535869631966 
thres:  0.0008664320707321168
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 10%|▉         | 97/1000 [06:09<56:52,  3.78s/it]Epoch:   98
max of grad d_p:  tensor(1.6232, device='cuda:0')
min of grad d_p:  tensor(-0.8659, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1342, device='cuda:0') mean:  tensor(-2.0143e-05, device='cuda:0') min:  tensor(-0.1726, device='cuda:0') norm:  tensor(0.4488, device='cuda:0') MSE:  tensor(1.6847e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.8639e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.7993e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0095, device='cuda:0')
min of d_p_list:  tensor(-0.0055, device='cuda:0')
Epoch:  98  
Training Loss: 0.8402785658836365
Test Loss:  0.7546936869621277
Test Acc:  0.0
Valid Loss:  0.7413657903671265
Valid Acc:  0.0
std:  0.012568107190525708 
thres:  0.0008579969525337219
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 10%|▉         | 98/1000 [06:13<57:23,  3.82s/it]Epoch:   99
max of grad d_p:  tensor(1.6138, device='cuda:0')
min of grad d_p:  tensor(-0.8595, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1086, device='cuda:0') mean:  tensor(-1.6760e-05, device='cuda:0') min:  tensor(-0.1562, device='cuda:0') norm:  tensor(0.3779, device='cuda:0') MSE:  tensor(1.4185e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(9.0399e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0014, device='cuda:0') MSE:  tensor(5.1469e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0089, device='cuda:0')
min of d_p_list:  tensor(-0.0055, device='cuda:0')
Epoch:  99  
Training Loss: 0.8320293426513672
Test Loss:  0.7474022507667542
Test Acc:  0.0
Valid Loss:  0.7342494130134583
Valid Acc:  0.0
std:  0.012417474570550036 
thres:  0.0008492692112922668
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 10%|▉         | 99/1000 [06:17<57:34,  3.83s/it]Epoch:   100
max of grad d_p:  tensor(1.6211, device='cuda:0')
min of grad d_p:  tensor(-0.8460, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1216, device='cuda:0') mean:  tensor(-2.0762e-05, device='cuda:0') min:  tensor(-0.1851, device='cuda:0') norm:  tensor(0.4267, device='cuda:0') MSE:  tensor(1.6018e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(8.2798e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.2173e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.3611, device='cuda:0')
min of d_p_list:  tensor(-0.3659, device='cuda:0')
Epoch:  100  
Training Loss: 0.8576873540878296
Test Loss:  0.7062051296234131
Test Acc:  0.0
Valid Loss:  0.693560779094696
Valid Acc:  0.0
std:  0.010110806830968098 
thres:  0.0008474119663238525
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 10%|█         | 100/1000 [06:21<57:08,  3.81s/it]Epoch:   101
max of grad d_p:  tensor(2.1035, device='cuda:0')
min of grad d_p:  tensor(-0.7184, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0521, device='cuda:0') mean:  tensor(-7.7599e-06, device='cuda:0') min:  tensor(-0.1892, device='cuda:0') norm:  tensor(0.4407, device='cuda:0') MSE:  tensor(1.6542e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0010, device='cuda:0') mean:  tensor(3.4821e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0050, device='cuda:0') MSE:  tensor(1.8782e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0168, device='cuda:0')
min of d_p_list:  tensor(-0.0217, device='cuda:0')
Epoch:  101  
Training Loss: 0.8461872339248657
Test Loss:  0.6965968608856201
Test Acc:  0.0
Valid Loss:  0.6867974996566772
Valid Acc:  0.0
std:  0.008579358927606967 
thres:  0.0008450141787528993
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 10%|█         | 101/1000 [06:25<57:19,  3.83s/it]Epoch:   102
max of grad d_p:  tensor(2.1143, device='cuda:0')
min of grad d_p:  tensor(-0.7093, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0277, device='cuda:0') mean:  tensor(-9.4629e-06, device='cuda:0') min:  tensor(-0.1836, device='cuda:0') norm:  tensor(0.4291, device='cuda:0') MSE:  tensor(1.6106e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.1454e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0016, device='cuda:0') MSE:  tensor(6.0638e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0164, device='cuda:0')
min of d_p_list:  tensor(-0.0119, device='cuda:0')
Epoch:  102  
Training Loss: 0.8341659307479858
Test Loss:  0.684773862361908
Test Acc:  0.0
Valid Loss:  0.6795133352279663
Valid Acc:  0.0
std:  0.009245017147940765 
thres:  0.000842069685459137
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 10%|█         | 102/1000 [06:29<57:56,  3.87s/it]Epoch:   103
max of grad d_p:  tensor(2.1003, device='cuda:0')
min of grad d_p:  tensor(-0.6930, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0326, device='cuda:0') mean:  tensor(-1.2444e-05, device='cuda:0') min:  tensor(-0.1984, device='cuda:0') norm:  tensor(0.4894, device='cuda:0') MSE:  tensor(1.8372e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0009, device='cuda:0') mean:  tensor(2.0706e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0031, device='cuda:0') MSE:  tensor(1.1735e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0185, device='cuda:0')
min of d_p_list:  tensor(-0.0279, device='cuda:0')
Epoch:  103  
Training Loss: 0.8254884481430054
Test Loss:  0.6779481768608093
Test Acc:  0.0
Valid Loss:  0.6725655794143677
Valid Acc:  0.0
std:  0.011448419239112283 
thres:  0.0008391116619110107
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 10%|█         | 103/1000 [06:32<57:54,  3.87s/it]Epoch:   104
max of grad d_p:  tensor(2.0909, device='cuda:0')
min of grad d_p:  tensor(-0.6782, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0452, device='cuda:0') mean:  tensor(-8.0196e-06, device='cuda:0') min:  tensor(-0.1408, device='cuda:0') norm:  tensor(0.4287, device='cuda:0') MSE:  tensor(1.6093e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(1.2344e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0019, device='cuda:0') MSE:  tensor(7.1104e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0963, device='cuda:0')
min of d_p_list:  tensor(-0.1086, device='cuda:0')
Epoch:  104  
Training Loss: 0.8287420272827148
Test Loss:  0.6766073107719421
Test Acc:  0.0
Valid Loss:  0.6714068651199341
Valid Acc:  0.0
std:  0.011920908548719106 
thres:  0.0008384541988372803
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 10%|█         | 104/1000 [06:36<56:34,  3.79s/it]Epoch:   105
max of grad d_p:  tensor(2.1666, device='cuda:0')
min of grad d_p:  tensor(-0.6688, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0449, device='cuda:0') mean:  tensor(-1.0155e-05, device='cuda:0') min:  tensor(-0.1670, device='cuda:0') norm:  tensor(0.4354, device='cuda:0') MSE:  tensor(1.6342e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0075, device='cuda:0') mean:  tensor(2.3804e-05, device='cuda:0') min:  tensor(2.9104e-11, device='cuda:0') norm:  tensor(0.0366, device='cuda:0') MSE:  tensor(1.3734e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0123, device='cuda:0')
min of d_p_list:  tensor(-0.0091, device='cuda:0')
Epoch:  105  
Training Loss: 0.8204975724220276
Test Loss:  0.6698569059371948
Test Acc:  0.0
Valid Loss:  0.6644448041915894
Valid Acc:  0.0
std:  0.008791478856140582 
thres:  0.0008310162425041199
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 10%|█         | 105/1000 [06:40<56:42,  3.80s/it]Epoch:   106
max of grad d_p:  tensor(2.1608, device='cuda:0')
min of grad d_p:  tensor(-0.6554, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0663, device='cuda:0') mean:  tensor(-8.6270e-06, device='cuda:0') min:  tensor(-0.1763, device='cuda:0') norm:  tensor(0.4830, device='cuda:0') MSE:  tensor(1.8132e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0046, device='cuda:0') mean:  tensor(1.4555e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0249, device='cuda:0') MSE:  tensor(9.3647e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0075, device='cuda:0')
min of d_p_list:  tensor(-0.0050, device='cuda:0')
Epoch:  106  
Training Loss: 0.8122317790985107
Test Loss:  0.6628257036209106
Test Acc:  0.0
Valid Loss:  0.6575680375099182
Valid Acc:  0.0
std:  0.007463953438295716 
thres:  0.0008242251515388489
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 11%|█         | 106/1000 [06:43<55:59,  3.76s/it]Epoch:   107
max of grad d_p:  tensor(2.1277, device='cuda:0')
min of grad d_p:  tensor(-0.6441, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0526, device='cuda:0') mean:  tensor(-1.0223e-05, device='cuda:0') min:  tensor(-0.1934, device='cuda:0') norm:  tensor(0.4540, device='cuda:0') MSE:  tensor(1.7044e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(1.3674e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0021, device='cuda:0') MSE:  tensor(7.8286e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0056, device='cuda:0')
min of d_p_list:  tensor(-0.0074, device='cuda:0')
Epoch:  107  
Training Loss: 0.8041103482246399
Test Loss:  0.6563370227813721
Test Acc:  0.0
Valid Loss:  0.650705099105835
Valid Acc:  0.0
std:  0.008985228072410891 
thres:  0.0008182140350341797
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 11%|█         | 107/1000 [06:47<56:39,  3.81s/it]Epoch:   108
max of grad d_p:  tensor(2.1260, device='cuda:0')
min of grad d_p:  tensor(-0.6396, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0370, device='cuda:0') mean:  tensor(-8.8077e-06, device='cuda:0') min:  tensor(-0.1502, device='cuda:0') norm:  tensor(0.4153, device='cuda:0') MSE:  tensor(1.5591e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0015, device='cuda:0') mean:  tensor(5.2315e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0079, device='cuda:0') MSE:  tensor(2.9828e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0178, device='cuda:0')
min of d_p_list:  tensor(-0.0228, device='cuda:0')
Epoch:  108  
Training Loss: 0.7976565361022949
Test Loss:  0.6507833003997803
Test Acc:  0.0
Valid Loss:  0.6451796889305115
Valid Acc:  0.0
std:  0.011121530724270138 
thres:  0.0008126476526260375
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 11%|█         | 108/1000 [06:51<55:54,  3.76s/it]Epoch:   109
max of grad d_p:  tensor(2.1575, device='cuda:0')
min of grad d_p:  tensor(-0.6391, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0448, device='cuda:0') mean:  tensor(-8.2058e-06, device='cuda:0') min:  tensor(-0.1377, device='cuda:0') norm:  tensor(0.4049, device='cuda:0') MSE:  tensor(1.5200e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(2.4164e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0039, device='cuda:0') MSE:  tensor(1.4478e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0097, device='cuda:0')
min of d_p_list:  tensor(-0.0068, device='cuda:0')
Epoch:  109  
Training Loss: 0.7896454334259033
Test Loss:  0.6443530321121216
Test Acc:  0.0
Valid Loss:  0.6385701298713684
Valid Acc:  0.0
std:  0.010796357631674304 
thres:  0.0008048283338546754
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 11%|█         | 109/1000 [06:55<56:32,  3.81s/it]Epoch:   110
max of grad d_p:  tensor(2.1578, device='cuda:0')
min of grad d_p:  tensor(-0.6297, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0530, device='cuda:0') mean:  tensor(-7.4316e-06, device='cuda:0') min:  tensor(-0.1684, device='cuda:0') norm:  tensor(0.4494, device='cuda:0') MSE:  tensor(1.6868e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0008, device='cuda:0') mean:  tensor(2.1430e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0033, device='cuda:0') MSE:  tensor(1.2399e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0089, device='cuda:0')
min of d_p_list:  tensor(-0.0049, device='cuda:0')
Epoch:  110  
Training Loss: 0.7815356254577637
Test Loss:  0.6377485990524292
Test Acc:  0.0
Valid Loss:  0.6320719718933105
Valid Acc:  0.0
std:  0.01073522478096098 
thres:  0.0007970359444618225
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 11%|█         | 110/1000 [06:59<56:38,  3.82s/it]Epoch:   111
max of grad d_p:  tensor(2.1283, device='cuda:0')
min of grad d_p:  tensor(-0.6191, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0425, device='cuda:0') mean:  tensor(-7.3666e-06, device='cuda:0') min:  tensor(-0.1551, device='cuda:0') norm:  tensor(0.4097, device='cuda:0') MSE:  tensor(1.5379e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(2.1748e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0034, device='cuda:0') MSE:  tensor(1.2802e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0117, device='cuda:0')
min of d_p_list:  tensor(-0.0128, device='cuda:0')
Epoch:  111  
Training Loss: 0.7736877202987671
Test Loss:  0.6319944858551025
Test Acc:  0.0
Valid Loss:  0.6255722045898438
Valid Acc:  0.0
std:  0.01089332403814268 
thres:  0.0007893271327018738
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 11%|█         | 111/1000 [07:03<57:30,  3.88s/it]Epoch:   112
max of grad d_p:  tensor(2.1187, device='cuda:0')
min of grad d_p:  tensor(-0.6027, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0762, device='cuda:0') mean:  tensor(-3.4017e-06, device='cuda:0') min:  tensor(-0.1224, device='cuda:0') norm:  tensor(0.4270, device='cuda:0') MSE:  tensor(1.6028e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0009, device='cuda:0') mean:  tensor(2.6306e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0042, device='cuda:0') MSE:  tensor(1.5600e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0219, device='cuda:0')
min of d_p_list:  tensor(-0.0231, device='cuda:0')
Epoch:  112  
Training Loss: 0.7642737627029419
Test Loss:  0.6245315074920654
Test Acc:  0.0
Valid Loss:  0.6205343008041382
Valid Acc:  0.0
std:  0.011705210129726003 
thres:  0.0007813598155975342
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 11%|█         | 112/1000 [07:07<57:22,  3.88s/it]Epoch:   113
max of grad d_p:  tensor(2.0819, device='cuda:0')
min of grad d_p:  tensor(-0.6053, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0398, device='cuda:0') mean:  tensor(-8.3511e-06, device='cuda:0') min:  tensor(-0.1433, device='cuda:0') norm:  tensor(0.4315, device='cuda:0') MSE:  tensor(1.6199e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0009, device='cuda:0') mean:  tensor(3.3675e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0053, device='cuda:0') MSE:  tensor(1.9867e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0233, device='cuda:0')
min of d_p_list:  tensor(-0.0100, device='cuda:0')
Epoch:  113  
Training Loss: 0.7573791146278381
Test Loss:  0.6183288097381592
Test Acc:  0.0
Valid Loss:  0.6144521236419678
Valid Acc:  0.0
std:  0.011576670545253383 
thres:  0.0007733043313026429
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 11%|█▏        | 113/1000 [07:11<57:02,  3.86s/it]Epoch:   114
max of grad d_p:  tensor(2.0649, device='cuda:0')
min of grad d_p:  tensor(-0.5890, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0369, device='cuda:0') mean:  tensor(-8.1244e-06, device='cuda:0') min:  tensor(-0.1642, device='cuda:0') norm:  tensor(0.4412, device='cuda:0') MSE:  tensor(1.6560e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0013, device='cuda:0') mean:  tensor(4.6319e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0074, device='cuda:0') MSE:  tensor(2.7865e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0272, device='cuda:0')
min of d_p_list:  tensor(-0.0166, device='cuda:0')
Epoch:  114  
Training Loss: 0.7512149214744568
Test Loss:  0.6131699085235596
Test Acc:  0.0
Valid Loss:  0.6091188788414001
Valid Acc:  0.0
std:  0.01091444971358029 
thres:  0.0007656182289123535
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 11%|█▏        | 114/1000 [07:14<55:36,  3.77s/it]Epoch:   115
max of grad d_p:  tensor(2.1187, device='cuda:0')
min of grad d_p:  tensor(-0.5651, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0354, device='cuda:0') mean:  tensor(-6.2211e-06, device='cuda:0') min:  tensor(-0.1405, device='cuda:0') norm:  tensor(0.4341, device='cuda:0') MSE:  tensor(1.6296e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0009, device='cuda:0') mean:  tensor(3.9590e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0057, device='cuda:0') MSE:  tensor(2.1247e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1276, device='cuda:0')
min of d_p_list:  tensor(-0.1140, device='cuda:0')
Epoch:  115  
Training Loss: 0.7546626329421997
Test Loss:  0.6122167706489563
Test Acc:  0.0
Valid Loss:  0.6088862419128418
Valid Acc:  0.0
std:  0.007973156058681758 
thres:  0.0007602436304092407
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 12%|█▏        | 115/1000 [07:18<56:55,  3.86s/it]Epoch:   116
max of grad d_p:  tensor(2.0841, device='cuda:0')
min of grad d_p:  tensor(-0.5836, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0291, device='cuda:0') mean:  tensor(-9.2938e-06, device='cuda:0') min:  tensor(-0.1424, device='cuda:0') norm:  tensor(0.4077, device='cuda:0') MSE:  tensor(1.5305e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0352, device='cuda:0') mean:  tensor(5.7229e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1000, device='cuda:0') MSE:  tensor(3.7545e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0078, device='cuda:0')
min of d_p_list:  tensor(-0.0093, device='cuda:0')
Epoch:  116  
Training Loss: 0.7472209930419922
Test Loss:  0.6061975359916687
Test Acc:  0.0
Valid Loss:  0.6029775142669678
Valid Acc:  0.0
std:  0.005772418702498262 
thres:  0.0007549502849578857
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 12%|█▏        | 116/1000 [07:22<56:25,  3.83s/it]Epoch:   117
max of grad d_p:  tensor(2.0848, device='cuda:0')
min of grad d_p:  tensor(-0.5783, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0886, device='cuda:0') mean:  tensor(-5.2220e-06, device='cuda:0') min:  tensor(-0.1672, device='cuda:0') norm:  tensor(0.4112, device='cuda:0') MSE:  tensor(1.5437e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0026, device='cuda:0') mean:  tensor(8.8435e-06, device='cuda:0') min:  tensor(1.8190e-11, device='cuda:0') norm:  tensor(0.0130, device='cuda:0') MSE:  tensor(4.8944e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1146, device='cuda:0')
min of d_p_list:  tensor(-0.1051, device='cuda:0')
Epoch:  117  
Training Loss: 0.7313862442970276
Test Loss:  0.5918622016906738
Test Acc:  0.0
Valid Loss:  0.5905188918113708
Valid Acc:  0.0
std:  0.009150115737070292 
thres:  0.0007483727812767029
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 12%|█▏        | 117/1000 [07:26<55:42,  3.79s/it]Epoch:   118
max of grad d_p:  tensor(1.8342, device='cuda:0')
min of grad d_p:  tensor(-0.5473, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1026, device='cuda:0') mean:  tensor(-8.8802e-06, device='cuda:0') min:  tensor(-0.1965, device='cuda:0') norm:  tensor(0.4567, device='cuda:0') MSE:  tensor(1.7142e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(2.0670e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0031, device='cuda:0') MSE:  tensor(1.1618e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0154, device='cuda:0')
min of d_p_list:  tensor(-0.0152, device='cuda:0')
Epoch:  118  
Training Loss: 0.7240268588066101
Test Loss:  0.5862154960632324
Test Acc:  0.0
Valid Loss:  0.5851557850837708
Valid Acc:  0.0
std:  0.011897549300792802 
thres:  0.0007417023301124572
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 12%|█▏        | 118/1000 [07:29<55:37,  3.78s/it]Epoch:   119
max of grad d_p:  tensor(1.8492, device='cuda:0')
min of grad d_p:  tensor(-0.5402, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0873, device='cuda:0') mean:  tensor(-6.3527e-06, device='cuda:0') min:  tensor(-0.1465, device='cuda:0') norm:  tensor(0.4333, device='cuda:0') MSE:  tensor(1.6265e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.0345e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0015, device='cuda:0') MSE:  tensor(5.8033e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0148, device='cuda:0')
min of d_p_list:  tensor(-0.0126, device='cuda:0')
Epoch:  119  
Training Loss: 0.7167392373085022
Test Loss:  0.5806370973587036
Test Acc:  0.0
Valid Loss:  0.5795705318450928
Valid Acc:  0.0
std:  0.01416128839477773 
thres:  0.0007348071932792664
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 12%|█▏        | 119/1000 [07:33<56:19,  3.84s/it]Epoch:   120
max of grad d_p:  tensor(1.8650, device='cuda:0')
min of grad d_p:  tensor(-0.5267, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0482, device='cuda:0') mean:  tensor(-8.9140e-06, device='cuda:0') min:  tensor(-0.1707, device='cuda:0') norm:  tensor(0.4253, device='cuda:0') MSE:  tensor(1.5965e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.4799e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0023, device='cuda:0') MSE:  tensor(8.5423e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0081, device='cuda:0')
min of d_p_list:  tensor(-0.0127, device='cuda:0')
Epoch:  120  
Training Loss: 0.7095864415168762
Test Loss:  0.5749689340591431
Test Acc:  0.0
Valid Loss:  0.5739636421203613
Valid Acc:  0.0
std:  0.012947475997811845 
thres:  0.0007257919549942017
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 12%|█▏        | 120/1000 [07:37<56:26,  3.85s/it]Epoch:   121
max of grad d_p:  tensor(1.8505, device='cuda:0')
min of grad d_p:  tensor(-0.5274, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0982, device='cuda:0') mean:  tensor(-9.7264e-06, device='cuda:0') min:  tensor(-0.1573, device='cuda:0') norm:  tensor(0.4442, device='cuda:0') MSE:  tensor(1.6674e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.4241e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0023, device='cuda:0') MSE:  tensor(8.4921e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0100, device='cuda:0')
min of d_p_list:  tensor(-0.0059, device='cuda:0')
Epoch:  121  
Training Loss: 0.7009986639022827
Test Loss:  0.565989077091217
Test Acc:  0.0
Valid Loss:  0.5666652917861938
Valid Acc:  0.0
std:  0.010643200109596882 
thres:  0.0007165474891662598
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 12%|█▏        | 121/1000 [07:41<56:17,  3.84s/it]Epoch:   122
max of grad d_p:  tensor(1.8470, device='cuda:0')
min of grad d_p:  tensor(-0.5115, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0993, device='cuda:0') mean:  tensor(-8.0993e-06, device='cuda:0') min:  tensor(-0.1667, device='cuda:0') norm:  tensor(0.4434, device='cuda:0') MSE:  tensor(1.6645e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0088, device='cuda:0') mean:  tensor(3.2230e-05, device='cuda:0') min:  tensor(5.8208e-11, device='cuda:0') norm:  tensor(0.0514, device='cuda:0') MSE:  tensor(1.9281e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0127, device='cuda:0')
min of d_p_list:  tensor(-0.0077, device='cuda:0')
Epoch:  122  
Training Loss: 0.6940679550170898
Test Loss:  0.560205340385437
Test Acc:  0.0
Valid Loss:  0.5609556436538696
Valid Acc:  0.0
std:  0.010705124022085876 
thres:  0.0007090838313102722
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 12%|█▏        | 122/1000 [07:45<55:28,  3.79s/it]Epoch:   123
max of grad d_p:  tensor(1.8418, device='cuda:0')
min of grad d_p:  tensor(-0.5077, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0937, device='cuda:0') mean:  tensor(-7.5393e-06, device='cuda:0') min:  tensor(-0.1646, device='cuda:0') norm:  tensor(0.4419, device='cuda:0') MSE:  tensor(1.6586e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(1.6113e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0028, device='cuda:0') MSE:  tensor(1.0325e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0323, device='cuda:0')
min of d_p_list:  tensor(-0.0463, device='cuda:0')
Epoch:  123  
Training Loss: 0.6867121458053589
Test Loss:  0.5548250079154968
Test Acc:  0.0
Valid Loss:  0.5555247068405151
Valid Acc:  0.0
std:  0.010693166808223745 
thres:  0.0007016208887100219
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 12%|█▏        | 123/1000 [07:49<56:15,  3.85s/it]Epoch:   124
max of grad d_p:  tensor(1.8610, device='cuda:0')
min of grad d_p:  tensor(-0.5096, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1396, device='cuda:0') mean:  tensor(-5.5425e-06, device='cuda:0') min:  tensor(-0.1505, device='cuda:0') norm:  tensor(0.4410, device='cuda:0') MSE:  tensor(1.6555e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.6936e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0026, device='cuda:0') MSE:  tensor(9.7363e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0087, device='cuda:0')
min of d_p_list:  tensor(-0.0086, device='cuda:0')
Epoch:  124  
Training Loss: 0.6786624193191528
Test Loss:  0.5464398264884949
Test Acc:  0.0
Valid Loss:  0.548844575881958
Valid Acc:  0.0
std:  0.010772902308384572 
thres:  0.0006940055251121521
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  31
 12%|█▏        | 124/1000 [07:53<56:06,  3.84s/it]Epoch:   125
max of grad d_p:  tensor(1.8219, device='cuda:0')
min of grad d_p:  tensor(-0.4915, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0886, device='cuda:0') mean:  tensor(-4.6894e-06, device='cuda:0') min:  tensor(-0.1370, device='cuda:0') norm:  tensor(0.4219, device='cuda:0') MSE:  tensor(1.5836e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(1.8488e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0029, device='cuda:0') MSE:  tensor(1.0856e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0214, device='cuda:0')
min of d_p_list:  tensor(-0.0220, device='cuda:0')
Epoch:  125  
Training Loss: 0.6381023526191711
Test Loss:  0.5085564851760864
Test Acc:  0.0
Valid Loss:  0.5125243663787842
Valid Acc:  0.0
std:  0.022093808482884836 
thres:  0.0006797087073326111
Preserved_eigens number check:  31
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 12%|█▎        | 125/1000 [07:56<55:58,  3.84s/it]Epoch:   126
max of grad d_p:  tensor(1.7818, device='cuda:0')
min of grad d_p:  tensor(-0.4631, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0532, device='cuda:0') mean:  tensor(-8.3327e-06, device='cuda:0') min:  tensor(-0.1418, device='cuda:0') norm:  tensor(0.4110, device='cuda:0') MSE:  tensor(1.5428e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0014, device='cuda:0') mean:  tensor(4.2162e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0073, device='cuda:0') MSE:  tensor(2.7438e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0601, device='cuda:0')
min of d_p_list:  tensor(-0.0682, device='cuda:0')
Epoch:  126  
Training Loss: 0.6307846307754517
Test Loss:  0.5029274225234985
Test Acc:  0.0
Valid Loss:  0.5063368082046509
Valid Acc:  0.0
std:  0.02605756240724414 
thres:  0.0006656659007072449
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 13%|█▎        | 126/1000 [08:00<56:10,  3.86s/it]Epoch:   127
max of grad d_p:  tensor(1.7383, device='cuda:0')
min of grad d_p:  tensor(-0.4533, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0789, device='cuda:0') mean:  tensor(-6.3803e-06, device='cuda:0') min:  tensor(-0.1390, device='cuda:0') norm:  tensor(0.4193, device='cuda:0') MSE:  tensor(1.5740e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(1.1813e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0021, device='cuda:0') MSE:  tensor(7.7189e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0843, device='cuda:0')
min of d_p_list:  tensor(-0.0543, device='cuda:0')
Epoch:  127  
Training Loss: 0.6291604042053223
Test Loss:  0.5015727281570435
Test Acc:  0.0
Valid Loss:  0.5046769380569458
Valid Acc:  0.0
std:  0.0248127360377415 
thres:  0.0006526843905448914
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 13%|█▎        | 127/1000 [08:04<56:48,  3.90s/it]Epoch:   128
max of grad d_p:  tensor(1.6692, device='cuda:0')
min of grad d_p:  tensor(-0.4495, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0752, device='cuda:0') mean:  tensor(-8.2608e-06, device='cuda:0') min:  tensor(-0.1520, device='cuda:0') norm:  tensor(0.4222, device='cuda:0') MSE:  tensor(1.5848e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(1.4267e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0025, device='cuda:0') MSE:  tensor(9.3836e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0279, device='cuda:0')
min of d_p_list:  tensor(-0.0433, device='cuda:0')
Epoch:  128  
Training Loss: 0.6239379644393921
Test Loss:  0.4978189468383789
Test Acc:  0.0
Valid Loss:  0.5011281371116638
Valid Acc:  0.0
std:  0.01979246657156391 
thres:  0.000640129554271698
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 13%|█▎        | 128/1000 [08:08<56:29,  3.89s/it]Epoch:   129
max of grad d_p:  tensor(1.6287, device='cuda:0')
min of grad d_p:  tensor(-0.4636, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1165, device='cuda:0') mean:  tensor(-7.5615e-06, device='cuda:0') min:  tensor(-0.1411, device='cuda:0') norm:  tensor(0.4294, device='cuda:0') MSE:  tensor(1.6118e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(1.3935e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0022, device='cuda:0') MSE:  tensor(8.1867e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0178, device='cuda:0')
min of d_p_list:  tensor(-0.0316, device='cuda:0')
Epoch:  129  
Training Loss: 0.6182724237442017
Test Loss:  0.4936060905456543
Test Acc:  0.0
Valid Loss:  0.49750345945358276
Valid Acc:  0.0
std:  0.0066673955628040425 
thres:  0.0006280515551567077
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 13%|█▎        | 129/1000 [08:12<56:38,  3.90s/it]Epoch:   130
max of grad d_p:  tensor(1.5902, device='cuda:0')
min of grad d_p:  tensor(-0.4657, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1072, device='cuda:0') mean:  tensor(-6.6789e-06, device='cuda:0') min:  tensor(-0.1361, device='cuda:0') norm:  tensor(0.4350, device='cuda:0') MSE:  tensor(1.6327e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0013, device='cuda:0') mean:  tensor(1.5858e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0029, device='cuda:0') MSE:  tensor(1.0781e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0262, device='cuda:0')
min of d_p_list:  tensor(-0.0358, device='cuda:0')
Epoch:  130  
Training Loss: 0.6094830632209778
Test Loss:  0.48418858647346497
Test Acc:  0.0
Valid Loss:  0.4898262023925781
Valid Acc:  0.0
std:  0.007774682449576904 
thres:  0.0006223276972770691
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 13%|█▎        | 130/1000 [08:16<56:57,  3.93s/it]Epoch:   131
max of grad d_p:  tensor(1.5034, device='cuda:0')
min of grad d_p:  tensor(-0.4406, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0912, device='cuda:0') mean:  tensor(-9.1888e-06, device='cuda:0') min:  tensor(-0.1595, device='cuda:0') norm:  tensor(0.4261, device='cuda:0') MSE:  tensor(1.5996e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0020, device='cuda:0') mean:  tensor(4.3741e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0077, device='cuda:0') MSE:  tensor(2.8954e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0155, device='cuda:0')
min of d_p_list:  tensor(-0.0088, device='cuda:0')
Epoch:  131  
Training Loss: 0.6034226417541504
Test Loss:  0.4797624349594116
Test Acc:  0.0
Valid Loss:  0.4853653907775879
Valid Acc:  0.0
std:  0.009363483832922521 
thres:  0.0006168552994728088
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 13%|█▎        | 131/1000 [08:20<56:14,  3.88s/it]Epoch:   132
max of grad d_p:  tensor(1.4927, device='cuda:0')
min of grad d_p:  tensor(-0.4362, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0840, device='cuda:0') mean:  tensor(-8.1864e-06, device='cuda:0') min:  tensor(-0.1409, device='cuda:0') norm:  tensor(0.4345, device='cuda:0') MSE:  tensor(1.6310e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(1.1867e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0020, device='cuda:0') MSE:  tensor(7.5296e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0138, device='cuda:0')
min of d_p_list:  tensor(-0.0183, device='cuda:0')
Epoch:  132  
Training Loss: 0.5962164998054504
Test Loss:  0.472528874874115
Test Acc:  0.0
Valid Loss:  0.4797649383544922
Valid Acc:  0.0
std:  0.009958498172482205 
thres:  0.0006102665185928344
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 13%|█▎        | 132/1000 [08:24<55:50,  3.86s/it]Epoch:   133
max of grad d_p:  tensor(1.4847, device='cuda:0')
min of grad d_p:  tensor(-0.4253, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0718, device='cuda:0') mean:  tensor(-8.1195e-06, device='cuda:0') min:  tensor(-0.1362, device='cuda:0') norm:  tensor(0.4178, device='cuda:0') MSE:  tensor(1.5683e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.0726e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0018, device='cuda:0') MSE:  tensor(6.5830e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0435, device='cuda:0')
min of d_p_list:  tensor(-0.0348, device='cuda:0')
Epoch:  133  
Training Loss: 0.5894235372543335
Test Loss:  0.4665466547012329
Test Acc:  0.0
Valid Loss:  0.4731035828590393
Valid Acc:  0.0
std:  0.010051176369120752 
thres:  0.0006033636331558228
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 13%|█▎        | 133/1000 [08:27<55:35,  3.85s/it]Epoch:   134
max of grad d_p:  tensor(1.4914, device='cuda:0')
min of grad d_p:  tensor(-0.4063, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0842, device='cuda:0') mean:  tensor(-8.8243e-06, device='cuda:0') min:  tensor(-0.1388, device='cuda:0') norm:  tensor(0.4133, device='cuda:0') MSE:  tensor(1.5513e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0009, device='cuda:0') mean:  tensor(1.9120e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0036, device='cuda:0') MSE:  tensor(1.3411e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.9551, device='cuda:0')
min of d_p_list:  tensor(-2.3946, device='cuda:0')
Epoch:  134  
Training Loss: 12.447507858276367
Test Loss:  15.173857688903809
Test Acc:  0.0
Valid Loss:  15.401934623718262
Valid Acc:  0.0
std:  4.739153365128275 
thres:  0.002969210720062256
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 13%|█▎        | 134/1000 [08:32<56:27,  3.91s/it]Epoch:   135
max of grad d_p:  tensor(7.8105, device='cuda:0')
min of grad d_p:  tensor(-24.0340, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1125, device='cuda:0') mean:  tensor(2.1418e-05, device='cuda:0') min:  tensor(-0.4172, device='cuda:0') norm:  tensor(1.1599, device='cuda:0') MSE:  tensor(4.3541e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0061, device='cuda:0') mean:  tensor(1.1077e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0179, device='cuda:0') MSE:  tensor(6.7028e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2441, device='cuda:0')
min of d_p_list:  tensor(-0.4414, device='cuda:0')
Epoch:  135  
Training Loss: 12.329862594604492
Test Loss:  15.00600814819336
Test Acc:  0.0
Valid Loss:  15.298589706420898
Valid Acc:  0.0
std:  5.7771602491363865 
thres:  0.005313286626338959
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 14%|█▎        | 135/1000 [08:35<56:03,  3.89s/it]Epoch:   136
max of grad d_p:  tensor(7.8840, device='cuda:0')
min of grad d_p:  tensor(-24.6457, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1477, device='cuda:0') mean:  tensor(2.8590e-05, device='cuda:0') min:  tensor(-0.4223, device='cuda:0') norm:  tensor(1.1307, device='cuda:0') MSE:  tensor(4.2445e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0042, device='cuda:0') mean:  tensor(1.6179e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0266, device='cuda:0') MSE:  tensor(9.9973e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0153, device='cuda:0')
min of d_p_list:  tensor(-0.0143, device='cuda:0')
Epoch:  136  
Training Loss: 12.206524848937988
Test Loss:  14.852291107177734
Test Acc:  0.0
Valid Loss:  15.139986038208008
Valid Acc:  0.0
std:  5.749529041498064 
thres:  0.0076339070677757265
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 14%|█▎        | 136/1000 [08:39<55:45,  3.87s/it]Epoch:   137
max of grad d_p:  tensor(7.8075, device='cuda:0')
min of grad d_p:  tensor(-24.4776, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1606, device='cuda:0') mean:  tensor(4.3214e-05, device='cuda:0') min:  tensor(-0.5821, device='cuda:0') norm:  tensor(1.3163, device='cuda:0') MSE:  tensor(4.9410e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0093, device='cuda:0') mean:  tensor(2.2354e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0374, device='cuda:0') MSE:  tensor(1.4032e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0327, device='cuda:0')
min of d_p_list:  tensor(-0.0527, device='cuda:0')
Epoch:  137  
Training Loss: 12.088932037353516
Test Loss:  14.708623886108398
Test Acc:  0.0
Valid Loss:  14.994643211364746
Valid Acc:  0.0
std:  4.673052061743209 
thres:  0.009932450175285339
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 14%|█▎        | 137/1000 [08:43<56:04,  3.90s/it]Epoch:   138
max of grad d_p:  tensor(7.7767, device='cuda:0')
min of grad d_p:  tensor(-24.4487, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1667, device='cuda:0') mean:  tensor(3.4322e-05, device='cuda:0') min:  tensor(-0.4453, device='cuda:0') norm:  tensor(1.2019, device='cuda:0') MSE:  tensor(4.5117e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0008, device='cuda:0') mean:  tensor(2.8596e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0042, device='cuda:0') MSE:  tensor(1.5702e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0214, device='cuda:0')
min of d_p_list:  tensor(-0.0119, device='cuda:0')
Epoch:  138  
Training Loss: 11.963443756103516
Test Loss:  14.546586990356445
Test Acc:  0.0
Valid Loss:  14.830768585205078
Valid Acc:  0.0
std:  0.1709963961152281 
thres:  0.012207254219055177
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 14%|█▍        | 138/1000 [08:47<56:41,  3.95s/it]Epoch:   139
max of grad d_p:  tensor(7.6858, device='cuda:0')
min of grad d_p:  tensor(-24.2341, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1645, device='cuda:0') mean:  tensor(3.2921e-05, device='cuda:0') min:  tensor(-0.4422, device='cuda:0') norm:  tensor(1.0992, device='cuda:0') MSE:  tensor(4.1261e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0011, device='cuda:0') mean:  tensor(4.0189e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0064, device='cuda:0') MSE:  tensor(2.4108e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0133, device='cuda:0')
min of d_p_list:  tensor(-0.0184, device='cuda:0')
Epoch:  139  
Training Loss: 11.843141555786133
Test Loss:  14.398529052734375
Test Acc:  0.0
Valid Loss:  14.680235862731934
Valid Acc:  0.0
std:  0.17204844218921925 
thres:  0.012086380958557129
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 14%|█▍        | 139/1000 [08:51<56:22,  3.93s/it]Epoch:   140
max of grad d_p:  tensor(7.6602, device='cuda:0')
min of grad d_p:  tensor(-24.0404, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1294, device='cuda:0') mean:  tensor(1.9904e-05, device='cuda:0') min:  tensor(-0.3948, device='cuda:0') norm:  tensor(1.1065, device='cuda:0') MSE:  tensor(4.1535e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0076, device='cuda:0') mean:  tensor(1.6189e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0275, device='cuda:0') MSE:  tensor(1.0309e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0112, device='cuda:0')
min of d_p_list:  tensor(-0.0071, device='cuda:0')
Epoch:  140  
Training Loss: 11.723873138427734
Test Loss:  14.249161720275879
Test Acc:  0.0
Valid Loss:  14.528203010559082
Valid Acc:  0.0
std:  0.17128181494943928 
thres:  0.011965183067321779
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 14%|█▍        | 140/1000 [08:55<56:17,  3.93s/it]Epoch:   141
max of grad d_p:  tensor(7.6417, device='cuda:0')
min of grad d_p:  tensor(-23.8827, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1849, device='cuda:0') mean:  tensor(4.0220e-05, device='cuda:0') min:  tensor(-0.5094, device='cuda:0') norm:  tensor(1.2306, device='cuda:0') MSE:  tensor(4.6193e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0010, device='cuda:0') mean:  tensor(4.4393e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0065, device='cuda:0') MSE:  tensor(2.4377e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1062, device='cuda:0')
min of d_p_list:  tensor(-0.1828, device='cuda:0')
Epoch:  141  
Training Loss: 11.705793380737305
Test Loss:  14.255823135375977
Test Acc:  0.0
Valid Loss:  14.493121147155762
Valid Acc:  0.0
std:  0.14531211509388436 
thres:  0.011865036773681642
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 14%|█▍        | 141/1000 [08:59<56:23,  3.94s/it]Epoch:   142
max of grad d_p:  tensor(7.5051, device='cuda:0')
min of grad d_p:  tensor(-23.3488, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1790, device='cuda:0') mean:  tensor(2.6175e-05, device='cuda:0') min:  tensor(-0.6106, device='cuda:0') norm:  tensor(1.3189, device='cuda:0') MSE:  tensor(4.9510e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0017, device='cuda:0') mean:  tensor(4.5851e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0078, device='cuda:0') MSE:  tensor(2.9329e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0478, device='cuda:0')
min of d_p_list:  tensor(-0.0371, device='cuda:0')
Epoch:  142  
Training Loss: 11.578886032104492
Test Loss:  14.093986511230469
Test Acc:  0.0
Valid Loss:  14.32387638092041
Valid Acc:  0.0
std:  0.1306153331593559 
thres:  0.011763027572631837
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 14%|█▍        | 142/1000 [09:03<55:18,  3.87s/it]Epoch:   143
max of grad d_p:  tensor(7.5998, device='cuda:0')
min of grad d_p:  tensor(-23.4298, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1557, device='cuda:0') mean:  tensor(2.3177e-05, device='cuda:0') min:  tensor(-0.5411, device='cuda:0') norm:  tensor(1.2225, device='cuda:0') MSE:  tensor(4.5890e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0022, device='cuda:0') mean:  tensor(5.2702e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0091, device='cuda:0') MSE:  tensor(3.4020e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0488, device='cuda:0')
min of d_p_list:  tensor(-0.0382, device='cuda:0')
Epoch:  143  
Training Loss: 11.465387344360352
Test Loss:  13.968803405761719
Test Acc:  0.0
Valid Loss:  14.19100570678711
Valid Acc:  0.0
std:  0.1297018483400293 
thres:  0.011663416290283203
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 14%|█▍        | 143/1000 [09:07<55:07,  3.86s/it]Epoch:   144
max of grad d_p:  tensor(7.4869, device='cuda:0')
min of grad d_p:  tensor(-23.1882, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1398, device='cuda:0') mean:  tensor(6.8795e-06, device='cuda:0') min:  tensor(-0.3961, device='cuda:0') norm:  tensor(1.1204, device='cuda:0') MSE:  tensor(4.2057e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0008, device='cuda:0') mean:  tensor(2.8201e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0042, device='cuda:0') MSE:  tensor(1.5731e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0077, device='cuda:0')
min of d_p_list:  tensor(-0.0106, device='cuda:0')
Epoch:  144  
Training Loss: 11.350914001464844
Test Loss:  13.826691627502441
Test Acc:  0.0
Valid Loss:  14.044673919677734
Valid Acc:  0.0
std:  0.14213498072191166 
thres:  0.011564970779418947
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 14%|█▍        | 144/1000 [09:10<55:04,  3.86s/it]Epoch:   145
max of grad d_p:  tensor(7.4084, device='cuda:0')
min of grad d_p:  tensor(-23.0147, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1400, device='cuda:0') mean:  tensor(2.0153e-05, device='cuda:0') min:  tensor(-0.5370, device='cuda:0') norm:  tensor(1.2133, device='cuda:0') MSE:  tensor(4.5546e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0074, device='cuda:0') mean:  tensor(2.0207e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0323, device='cuda:0') MSE:  tensor(1.2115e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1286, device='cuda:0')
min of d_p_list:  tensor(-0.1517, device='cuda:0')
Epoch:  145  
Training Loss: 11.301305770874023
Test Loss:  13.756792068481445
Test Acc:  0.0
Valid Loss:  13.937532424926758
Valid Acc:  0.0
std:  0.14803270228721221 
thres:  0.011480457305908203
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 14%|█▍        | 145/1000 [09:14<55:13,  3.88s/it]Epoch:   146
max of grad d_p:  tensor(7.4436, device='cuda:0')
min of grad d_p:  tensor(-22.5998, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1524, device='cuda:0') mean:  tensor(1.2645e-05, device='cuda:0') min:  tensor(-0.4652, device='cuda:0') norm:  tensor(1.0866, device='cuda:0') MSE:  tensor(4.0789e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0061, device='cuda:0') mean:  tensor(1.8378e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0285, device='cuda:0') MSE:  tensor(1.0709e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0352, device='cuda:0')
min of d_p_list:  tensor(-0.0380, device='cuda:0')
Epoch:  146  
Training Loss: 11.176982879638672
Test Loss:  13.602018356323242
Test Acc:  0.0
Valid Loss:  13.766448974609375
Valid Acc:  0.0
std:  0.1378119561562561 
thres:  0.011374695205688477
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 15%|█▍        | 146/1000 [09:18<54:38,  3.84s/it]Epoch:   147
max of grad d_p:  tensor(7.3223, device='cuda:0')
min of grad d_p:  tensor(-22.3499, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1418, device='cuda:0') mean:  tensor(1.8471e-05, device='cuda:0') min:  tensor(-0.4811, device='cuda:0') norm:  tensor(1.1236, device='cuda:0') MSE:  tensor(4.2177e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0013, device='cuda:0') mean:  tensor(4.2372e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0066, device='cuda:0') MSE:  tensor(2.4775e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0188, device='cuda:0')
min of d_p_list:  tensor(-0.0236, device='cuda:0')
Epoch:  147  
Training Loss: 11.065009117126465
Test Loss:  13.458332061767578
Test Acc:  0.0
Valid Loss:  13.62146282196045
Valid Acc:  0.0
std:  0.1388224473239001 
thres:  0.01127191982269287
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 15%|█▍        | 147/1000 [09:22<54:35,  3.84s/it]Epoch:   148
max of grad d_p:  tensor(7.2286, device='cuda:0')
min of grad d_p:  tensor(-22.1205, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1466, device='cuda:0') mean:  tensor(1.5822e-05, device='cuda:0') min:  tensor(-0.4615, device='cuda:0') norm:  tensor(1.0795, device='cuda:0') MSE:  tensor(4.0521e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0130, device='cuda:0') mean:  tensor(2.8364e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0478, device='cuda:0') MSE:  tensor(1.7956e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0166, device='cuda:0')
min of d_p_list:  tensor(-0.0131, device='cuda:0')
Epoch:  148  
Training Loss: 10.952667236328125
Test Loss:  13.308180809020996
Test Acc:  0.0
Valid Loss:  13.467411994934082
Valid Acc:  0.0
std:  0.1471560461070439 
thres:  0.011169375801086427
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 15%|█▍        | 148/1000 [09:26<54:52,  3.86s/it]Epoch:   149
max of grad d_p:  tensor(7.1254, device='cuda:0')
min of grad d_p:  tensor(-21.8940, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1635, device='cuda:0') mean:  tensor(3.2798e-05, device='cuda:0') min:  tensor(-0.5880, device='cuda:0') norm:  tensor(1.2917, device='cuda:0') MSE:  tensor(4.8487e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0041, device='cuda:0') mean:  tensor(9.3080e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0147, device='cuda:0') MSE:  tensor(5.5078e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0257, device='cuda:0')
min of d_p_list:  tensor(-0.0168, device='cuda:0')
Epoch:  149  
Training Loss: 10.838539123535156
Test Loss:  13.162500381469727
Test Acc:  0.0
Valid Loss:  13.320159912109375
Valid Acc:  0.0
std:  0.1626442101269687 
thres:  0.011066900825500488
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 15%|█▍        | 149/1000 [09:30<54:59,  3.88s/it]Epoch:   150
max of grad d_p:  tensor(7.1229, device='cuda:0')
min of grad d_p:  tensor(-21.7761, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1612, device='cuda:0') mean:  tensor(2.5699e-05, device='cuda:0') min:  tensor(-0.5033, device='cuda:0') norm:  tensor(1.1503, device='cuda:0') MSE:  tensor(4.3178e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0042, device='cuda:0') mean:  tensor(1.2269e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0184, device='cuda:0') MSE:  tensor(6.9253e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1725, device='cuda:0')
min of d_p_list:  tensor(-0.0695, device='cuda:0')
Epoch:  150  
Training Loss: 10.389944076538086
Test Loss:  12.550235748291016
Test Acc:  0.0
Valid Loss:  12.736066818237305
Valid Acc:  0.0
std:  0.2718361379245698 
thres:  0.0108846284866333
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 15%|█▌        | 150/1000 [09:33<53:25,  3.77s/it]Epoch:   151
max of grad d_p:  tensor(6.6541, device='cuda:0')
min of grad d_p:  tensor(-20.5023, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1842, device='cuda:0') mean:  tensor(3.4054e-05, device='cuda:0') min:  tensor(-0.5783, device='cuda:0') norm:  tensor(1.2521, device='cuda:0') MSE:  tensor(4.7001e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0019, device='cuda:0') mean:  tensor(4.6103e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0075, device='cuda:0') MSE:  tensor(2.8206e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1476, device='cuda:0')
min of d_p_list:  tensor(-0.1083, device='cuda:0')
Epoch:  151  
Training Loss: 10.308632850646973
Test Loss:  12.472993850708008
Test Acc:  0.0
Valid Loss:  12.65964412689209
Valid Acc:  0.0
std:  0.3049485059496135 
thres:  0.010710958480834962
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 15%|█▌        | 151/1000 [09:37<54:03,  3.82s/it]Epoch:   152
max of grad d_p:  tensor(6.4707, device='cuda:0')
min of grad d_p:  tensor(-19.9819, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1553, device='cuda:0') mean:  tensor(2.4960e-05, device='cuda:0') min:  tensor(-0.4618, device='cuda:0') norm:  tensor(1.0891, device='cuda:0') MSE:  tensor(4.0881e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0019, device='cuda:0') mean:  tensor(5.6253e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0090, device='cuda:0') MSE:  tensor(3.3828e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0201, device='cuda:0')
min of d_p_list:  tensor(-0.0172, device='cuda:0')
Epoch:  152  
Training Loss: 10.1998929977417
Test Loss:  12.327716827392578
Test Acc:  0.0
Valid Loss:  12.501094818115234
Valid Acc:  0.0
std:  0.3003727189182021 
thres:  0.010537935256958009
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 15%|█▌        | 152/1000 [09:41<53:16,  3.77s/it]Epoch:   153
max of grad d_p:  tensor(6.4053, device='cuda:0')
min of grad d_p:  tensor(-19.7776, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1617, device='cuda:0') mean:  tensor(2.1214e-05, device='cuda:0') min:  tensor(-0.3773, device='cuda:0') norm:  tensor(0.9990, device='cuda:0') MSE:  tensor(3.7501e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0093, device='cuda:0') mean:  tensor(1.3289e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0228, device='cuda:0') MSE:  tensor(8.5563e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0191, device='cuda:0')
min of d_p_list:  tensor(-0.0120, device='cuda:0')
Epoch:  153  
Training Loss: 10.096644401550293
Test Loss:  12.201409339904785
Test Acc:  0.0
Valid Loss:  12.374402046203613
Valid Acc:  0.0
std:  0.25585106486921977 
thres:  0.010366730690002442
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 15%|█▌        | 153/1000 [09:45<53:16,  3.77s/it]Epoch:   154
max of grad d_p:  tensor(6.3389, device='cuda:0')
min of grad d_p:  tensor(-19.5316, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1665, device='cuda:0') mean:  tensor(3.9064e-05, device='cuda:0') min:  tensor(-0.5189, device='cuda:0') norm:  tensor(1.1303, device='cuda:0') MSE:  tensor(4.2429e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0105, device='cuda:0') mean:  tensor(2.4622e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0406, device='cuda:0') MSE:  tensor(1.5246e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0087, device='cuda:0')
min of d_p_list:  tensor(-0.0133, device='cuda:0')
Epoch:  154  
Training Loss: 9.99581527709961
Test Loss:  12.080755233764648
Test Acc:  0.0
Valid Loss:  12.251561164855957
Valid Acc:  0.0
std:  0.14158897293195405 
thres:  0.010198185920715332
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 15%|█▌        | 154/1000 [09:48<53:20,  3.78s/it]Epoch:   155
max of grad d_p:  tensor(6.2952, device='cuda:0')
min of grad d_p:  tensor(-19.4389, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1198, device='cuda:0') mean:  tensor(4.4557e-06, device='cuda:0') min:  tensor(-0.3672, device='cuda:0') norm:  tensor(1.0467, device='cuda:0') MSE:  tensor(3.9291e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0025, device='cuda:0') mean:  tensor(4.1951e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0070, device='cuda:0') MSE:  tensor(2.6303e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0258, device='cuda:0')
min of d_p_list:  tensor(-0.0149, device='cuda:0')
Epoch:  155  
Training Loss: 9.89396858215332
Test Loss:  11.962684631347656
Test Acc:  0.0
Valid Loss:  12.125139236450195
Valid Acc:  0.0
std:  0.14616144965810624 
thres:  0.010098990821838379
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  40
 16%|█▌        | 155/1000 [09:52<53:53,  3.83s/it]Epoch:   156
max of grad d_p:  tensor(6.2184, device='cuda:0')
min of grad d_p:  tensor(-19.2420, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2124, device='cuda:0') mean:  tensor(2.8592e-05, device='cuda:0') min:  tensor(-0.4545, device='cuda:0') norm:  tensor(1.1133, device='cuda:0') MSE:  tensor(4.1791e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0887, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.4172, device='cuda:0') MSE:  tensor(1.5660e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0156, device='cuda:0')
min of d_p_list:  tensor(-0.0238, device='cuda:0')
Epoch:  156  
Training Loss: 9.35359001159668
Test Loss:  11.16010856628418
Test Acc:  0.0
Valid Loss:  11.335297584533691
Valid Acc:  0.0
std:  0.2953191729680094 
thres:  0.00990798225402832
Preserved_eigens number check:  40
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 16%|█▌        | 156/1000 [09:56<54:00,  3.84s/it]Epoch:   157
max of grad d_p:  tensor(6.2069, device='cuda:0')
min of grad d_p:  tensor(-18.1949, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1636, device='cuda:0') mean:  tensor(3.4101e-05, device='cuda:0') min:  tensor(-0.4977, device='cuda:0') norm:  tensor(1.1278, device='cuda:0') MSE:  tensor(4.2333e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0011, device='cuda:0') mean:  tensor(4.5436e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0069, device='cuda:0') MSE:  tensor(2.5827e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0089, device='cuda:0')
min of d_p_list:  tensor(-0.0077, device='cuda:0')
Epoch:  157  
Training Loss: 9.259380340576172
Test Loss:  11.047622680664062
Test Acc:  0.0
Valid Loss:  11.218696594238281
Valid Acc:  0.0
std:  0.34485556912809845 
thres:  0.009719879722595215
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 16%|█▌        | 157/1000 [10:00<53:37,  3.82s/it]Epoch:   158
max of grad d_p:  tensor(6.1503, device='cuda:0')
min of grad d_p:  tensor(-18.1239, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1373, device='cuda:0') mean:  tensor(1.1403e-05, device='cuda:0') min:  tensor(-0.3204, device='cuda:0') norm:  tensor(0.8904, device='cuda:0') MSE:  tensor(3.3421e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0040, device='cuda:0') mean:  tensor(1.0947e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0174, device='cuda:0') MSE:  tensor(6.5233e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2192, device='cuda:0')
min of d_p_list:  tensor(-0.3677, device='cuda:0')
Epoch:  158  
Training Loss: 9.519235610961914
Test Loss:  11.598457336425781
Test Acc:  0.0
Valid Loss:  11.673439025878906
Valid Acc:  0.0
std:  0.29197707845944687 
thres:  0.009604397964477538
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 16%|█▌        | 158/1000 [10:04<54:39,  3.90s/it]Epoch:   159
max of grad d_p:  tensor(7.1688, device='cuda:0')
min of grad d_p:  tensor(-19.2392, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1316, device='cuda:0') mean:  tensor(2.2338e-05, device='cuda:0') min:  tensor(-0.4143, device='cuda:0') norm:  tensor(1.0568, device='cuda:0') MSE:  tensor(3.9668e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0035, device='cuda:0') mean:  tensor(7.7334e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0126, device='cuda:0') MSE:  tensor(4.7189e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0328, device='cuda:0')
min of d_p_list:  tensor(-0.0210, device='cuda:0')
Epoch:  159  
Training Loss: 9.408062934875488
Test Loss:  11.4668607711792
Test Acc:  0.0
Valid Loss:  11.526222229003906
Valid Acc:  0.0
std:  0.22022826330838485 
thres:  0.009486847496032715
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 16%|█▌        | 159/1000 [10:08<54:15,  3.87s/it]Epoch:   160
max of grad d_p:  tensor(7.0912, device='cuda:0')
min of grad d_p:  tensor(-19.0998, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1324, device='cuda:0') mean:  tensor(2.6942e-05, device='cuda:0') min:  tensor(-0.4610, device='cuda:0') norm:  tensor(1.1484, device='cuda:0') MSE:  tensor(4.3108e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0013, device='cuda:0') mean:  tensor(3.2008e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0053, device='cuda:0') MSE:  tensor(2.0049e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0246, device='cuda:0')
min of d_p_list:  tensor(-0.0138, device='cuda:0')
Epoch:  160  
Training Loss: 9.315652847290039
Test Loss:  11.349323272705078
Test Acc:  0.0
Valid Loss:  11.408785820007324
Valid Acc:  0.0
std:  0.08851288149772525 
thres:  0.009371184349060058
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 16%|█▌        | 160/1000 [10:12<53:44,  3.84s/it]Epoch:   161
max of grad d_p:  tensor(6.9737, device='cuda:0')
min of grad d_p:  tensor(-19.0022, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1473, device='cuda:0') mean:  tensor(2.9603e-05, device='cuda:0') min:  tensor(-0.4710, device='cuda:0') norm:  tensor(1.1140, device='cuda:0') MSE:  tensor(4.1816e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0012, device='cuda:0') mean:  tensor(3.1339e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0055, device='cuda:0') MSE:  tensor(2.0533e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0222, device='cuda:0')
min of d_p_list:  tensor(-0.0167, device='cuda:0')
Epoch:  161  
Training Loss: 9.221385955810547
Test Loss:  11.225288391113281
Test Acc:  0.0
Valid Loss:  11.286275863647461
Valid Acc:  0.0
std:  0.10752401256579973 
thres:  0.009344743537902832
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 16%|█▌        | 161/1000 [10:16<54:08,  3.87s/it]Epoch:   162
max of grad d_p:  tensor(6.9755, device='cuda:0')
min of grad d_p:  tensor(-18.8170, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1080, device='cuda:0') mean:  tensor(1.7387e-05, device='cuda:0') min:  tensor(-0.3600, device='cuda:0') norm:  tensor(0.9406, device='cuda:0') MSE:  tensor(3.5307e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0019, device='cuda:0') mean:  tensor(3.0904e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0053, device='cuda:0') MSE:  tensor(1.9885e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1544, device='cuda:0')
min of d_p_list:  tensor(-0.0674, device='cuda:0')
Epoch:  162  
Training Loss: 9.078302383422852
Test Loss:  11.03506851196289
Test Acc:  0.0
Valid Loss:  11.1026029586792
Valid Acc:  0.0
std:  0.15162666943561204 
thres:  0.009308527946472168
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 16%|█▌        | 162/1000 [10:19<54:04,  3.87s/it]Epoch:   163
max of grad d_p:  tensor(7.0029, device='cuda:0')
min of grad d_p:  tensor(-18.3066, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1262, device='cuda:0') mean:  tensor(2.8117e-05, device='cuda:0') min:  tensor(-0.4389, device='cuda:0') norm:  tensor(1.0923, device='cuda:0') MSE:  tensor(4.1004e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0506, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1968, device='cuda:0') MSE:  tensor(7.3859e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.3623, device='cuda:0')
min of d_p_list:  tensor(-0.1628, device='cuda:0')
Epoch:  163  
Training Loss: 9.052791595458984
Test Loss:  11.052923202514648
Test Acc:  0.0
Valid Loss:  11.144027709960938
Valid Acc:  0.0
std:  0.13597249122951097 
thres:  0.009215239143371582
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 16%|█▋        | 163/1000 [10:23<53:26,  3.83s/it]Epoch:   164
max of grad d_p:  tensor(6.4501, device='cuda:0')
min of grad d_p:  tensor(-18.4774, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1363, device='cuda:0') mean:  tensor(4.1420e-05, device='cuda:0') min:  tensor(-0.4383, device='cuda:0') norm:  tensor(1.1368, device='cuda:0') MSE:  tensor(4.2673e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0149, device='cuda:0') mean:  tensor(3.4656e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0609, device='cuda:0') MSE:  tensor(2.2854e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0734, device='cuda:0')
min of d_p_list:  tensor(-0.1051, device='cuda:0')
Epoch:  164  
Training Loss: 8.944059371948242
Test Loss:  10.90768051147461
Test Acc:  0.0
Valid Loss:  10.999545097351074
Valid Acc:  0.0
std:  0.1309505131209759 
thres:  0.009122438430786133
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 16%|█▋        | 164/1000 [10:27<53:13,  3.82s/it]Epoch:   165
max of grad d_p:  tensor(6.3246, device='cuda:0')
min of grad d_p:  tensor(-17.9414, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1470, device='cuda:0') mean:  tensor(4.1159e-05, device='cuda:0') min:  tensor(-0.4195, device='cuda:0') norm:  tensor(1.0213, device='cuda:0') MSE:  tensor(3.8335e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0010, device='cuda:0') mean:  tensor(2.5989e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0042, device='cuda:0') MSE:  tensor(1.5587e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0237, device='cuda:0')
min of d_p_list:  tensor(-0.0288, device='cuda:0')
Epoch:  165  
Training Loss: 8.85608959197998
Test Loss:  10.79444408416748
Test Acc:  0.0
Valid Loss:  10.885177612304688
Valid Acc:  0.0
std:  0.12418566784894265 
thres:  0.009030525779724121
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 16%|█▋        | 165/1000 [10:31<54:01,  3.88s/it]Epoch:   166
max of grad d_p:  tensor(6.2794, device='cuda:0')
min of grad d_p:  tensor(-18.0901, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1363, device='cuda:0') mean:  tensor(2.4683e-05, device='cuda:0') min:  tensor(-0.3383, device='cuda:0') norm:  tensor(0.9779, device='cuda:0') MSE:  tensor(3.6707e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0012, device='cuda:0') mean:  tensor(2.9871e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0050, device='cuda:0') MSE:  tensor(1.8752e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0180, device='cuda:0')
min of d_p_list:  tensor(-0.0179, device='cuda:0')
Epoch:  166  
Training Loss: 8.768324851989746
Test Loss:  10.688520431518555
Test Acc:  0.0
Valid Loss:  10.779974937438965
Valid Acc:  0.0
std:  0.11694378771478248 
thres:  0.008939913558959962
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 17%|█▋        | 166/1000 [10:35<53:39,  3.86s/it]Epoch:   167
max of grad d_p:  tensor(6.2280, device='cuda:0')
min of grad d_p:  tensor(-18.0307, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1192, device='cuda:0') mean:  tensor(7.4219e-06, device='cuda:0') min:  tensor(-0.3446, device='cuda:0') norm:  tensor(0.8913, device='cuda:0') MSE:  tensor(3.3457e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0381, device='cuda:0') mean:  tensor(9.3795e-05, device='cuda:0') min:  tensor(3.4925e-10, device='cuda:0') norm:  tensor(0.1515, device='cuda:0') MSE:  tensor(5.6876e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0327, device='cuda:0')
min of d_p_list:  tensor(-0.0329, device='cuda:0')
Epoch:  167  
Training Loss: 8.678106307983398
Test Loss:  10.577016830444336
Test Acc:  0.0
Valid Loss:  10.666608810424805
Valid Acc:  0.0
std:  0.1309499427977397 
thres:  0.00885987434387207
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 17%|█▋        | 167/1000 [10:39<53:07,  3.83s/it]Epoch:   168
max of grad d_p:  tensor(6.3012, device='cuda:0')
min of grad d_p:  tensor(-17.8572, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1542, device='cuda:0') mean:  tensor(3.8100e-05, device='cuda:0') min:  tensor(-0.4095, device='cuda:0') norm:  tensor(1.0465, device='cuda:0') MSE:  tensor(3.9283e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0008, device='cuda:0') mean:  tensor(2.4688e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0039, device='cuda:0') MSE:  tensor(1.4621e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0248, device='cuda:0')
min of d_p_list:  tensor(-0.0112, device='cuda:0')
Epoch:  168  
Training Loss: 8.591567993164062
Test Loss:  10.474870681762695
Test Acc:  0.0
Valid Loss:  10.561434745788574
Valid Acc:  0.0
std:  0.12487211634410254 
thres:  0.008767629623413086
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 17%|█▋        | 168/1000 [10:42<52:58,  3.82s/it]Epoch:   169
max of grad d_p:  tensor(6.2362, device='cuda:0')
min of grad d_p:  tensor(-17.8319, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1355, device='cuda:0') mean:  tensor(4.2546e-05, device='cuda:0') min:  tensor(-0.4347, device='cuda:0') norm:  tensor(1.0618, device='cuda:0') MSE:  tensor(3.9856e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0013, device='cuda:0') mean:  tensor(2.7243e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0047, device='cuda:0') MSE:  tensor(1.7610e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1797, device='cuda:0')
min of d_p_list:  tensor(-0.1335, device='cuda:0')
Epoch:  169  
Training Loss: 8.457198143005371
Test Loss:  10.315515518188477
Test Acc:  0.0
Valid Loss:  10.382244110107422
Valid Acc:  0.0
std:  0.1384187153615217 
thres:  0.008670257377624512
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 17%|█▋        | 169/1000 [10:46<53:20,  3.85s/it]Epoch:   170
max of grad d_p:  tensor(6.0266, device='cuda:0')
min of grad d_p:  tensor(-18.4799, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0909, device='cuda:0') mean:  tensor(7.7364e-06, device='cuda:0') min:  tensor(-0.3383, device='cuda:0') norm:  tensor(0.8671, device='cuda:0') MSE:  tensor(3.2549e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0067, device='cuda:0') mean:  tensor(1.5598e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0237, device='cuda:0') MSE:  tensor(8.8911e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0266, device='cuda:0')
min of d_p_list:  tensor(-0.0237, device='cuda:0')
Epoch:  170  
Training Loss: 8.373190879821777
Test Loss:  10.207387924194336
Test Acc:  0.0
Valid Loss:  10.273433685302734
Valid Acc:  0.0
std:  0.14344013580263001 
thres:  0.00857367763519287
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 17%|█▋        | 170/1000 [10:50<53:27,  3.86s/it]Epoch:   171
max of grad d_p:  tensor(5.9708, device='cuda:0')
min of grad d_p:  tensor(-18.3141, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0977, device='cuda:0') mean:  tensor(1.9995e-05, device='cuda:0') min:  tensor(-0.3397, device='cuda:0') norm:  tensor(0.9022, device='cuda:0') MSE:  tensor(3.3865e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0017, device='cuda:0') mean:  tensor(4.5454e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0072, device='cuda:0') MSE:  tensor(2.7112e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.6984, device='cuda:0')
min of d_p_list:  tensor(-2.0754, device='cuda:0')
Epoch:  171  
Training Loss: 5.264313220977783
Test Loss:  7.6429877281188965
Test Acc:  0.0
Valid Loss:  7.408649444580078
Valid Acc:  0.0
std:  1.3085305611874998 
thres:  0.007872875308990479
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 17%|█▋        | 171/1000 [10:54<53:32,  3.87s/it]Epoch:   172
max of grad d_p:  tensor(3.2833, device='cuda:0')
min of grad d_p:  tensor(-25.4318, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1078, device='cuda:0') mean:  tensor(7.4215e-05, device='cuda:0') min:  tensor(-0.3269, device='cuda:0') norm:  tensor(1.2299, device='cuda:0') MSE:  tensor(4.6166e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0512, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1910, device='cuda:0') MSE:  tensor(7.1703e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0048, device='cuda:0')
min of d_p_list:  tensor(-0.0102, device='cuda:0')
Epoch:  172  
Training Loss: 5.211211204528809
Test Loss:  7.563319206237793
Test Acc:  0.0
Valid Loss:  7.3308186531066895
Valid Acc:  0.0
std:  1.587037974301654 
thres:  0.007179496288299561
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 17%|█▋        | 172/1000 [10:58<53:02,  3.84s/it]Epoch:   173
max of grad d_p:  tensor(3.2655, device='cuda:0')
min of grad d_p:  tensor(-25.2634, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0814, device='cuda:0') mean:  tensor(8.0317e-05, device='cuda:0') min:  tensor(-0.3420, device='cuda:0') norm:  tensor(1.1863, device='cuda:0') MSE:  tensor(4.4531e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0207, device='cuda:0') mean:  tensor(5.3908e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0768, device='cuda:0') MSE:  tensor(2.8820e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0236, device='cuda:0')
min of d_p_list:  tensor(-0.0153, device='cuda:0')
Epoch:  173  
Training Loss: 5.156822204589844
Test Loss:  7.481827259063721
Test Acc:  0.0
Valid Loss:  7.2516584396362305
Valid Acc:  0.0
std:  1.570427704937978 
thres:  0.006492547130584716
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 17%|█▋        | 173/1000 [11:02<53:56,  3.91s/it]Epoch:   174
max of grad d_p:  tensor(3.2081, device='cuda:0')
min of grad d_p:  tensor(-25.3069, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0890, device='cuda:0') mean:  tensor(5.6680e-05, device='cuda:0') min:  tensor(-0.3093, device='cuda:0') norm:  tensor(1.1266, device='cuda:0') MSE:  tensor(4.2290e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0510, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1681, device='cuda:0') MSE:  tensor(6.3094e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0919, device='cuda:0')
min of d_p_list:  tensor(-0.0822, device='cuda:0')
Epoch:  174  
Training Loss: 5.153595447540283
Test Loss:  7.545599937438965
Test Acc:  0.0
Valid Loss:  7.296576976776123
Valid Acc:  0.0
std:  1.2713296769295528 
thres:  0.005831826591491699
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  33
 17%|█▋        | 174/1000 [11:05<52:27,  3.81s/it]Epoch:   175
max of grad d_p:  tensor(3.0878, device='cuda:0')
min of grad d_p:  tensor(-25.3714, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1156, device='cuda:0') mean:  tensor(7.0843e-05, device='cuda:0') min:  tensor(-0.3855, device='cuda:0') norm:  tensor(1.2555, device='cuda:0') MSE:  tensor(4.7127e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0722, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(4.0927e-12, device='cuda:0') norm:  tensor(0.2828, device='cuda:0') MSE:  tensor(1.0617e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0246, device='cuda:0')
min of d_p_list:  tensor(-0.0196, device='cuda:0')
Epoch:  175  
Training Loss: 5.038706302642822
Test Loss:  7.364068984985352
Test Acc:  0.0
Valid Loss:  7.134703159332275
Valid Acc:  0.0
std:  0.07502746790932374 
thres:  0.005164929676055908
Preserved_eigens number check:  33
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 18%|█▊        | 175/1000 [11:09<52:45,  3.84s/it]Epoch:   176
max of grad d_p:  tensor(3.0233, device='cuda:0')
min of grad d_p:  tensor(-25.2277, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0930, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.5063, device='cuda:0') norm:  tensor(1.4006, device='cuda:0') MSE:  tensor(5.2574e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0022, device='cuda:0') mean:  tensor(7.0880e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0103, device='cuda:0') MSE:  tensor(3.8645e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0396, device='cuda:0')
min of d_p_list:  tensor(-0.0739, device='cuda:0')
Epoch:  176  
Training Loss: 4.994474411010742
Test Loss:  7.303131580352783
Test Acc:  0.0
Valid Loss:  7.071535110473633
Valid Acc:  0.0
std:  0.08094555752098653 
thres:  0.0051109619140625
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 18%|█▊        | 176/1000 [11:13<51:51,  3.78s/it]Epoch:   177
max of grad d_p:  tensor(2.9229, device='cuda:0')
min of grad d_p:  tensor(-25.0058, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0966, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.5067, device='cuda:0') norm:  tensor(1.4099, device='cuda:0') MSE:  tensor(5.2923e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0164, device='cuda:0') mean:  tensor(3.5621e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0566, device='cuda:0') MSE:  tensor(2.1251e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0245, device='cuda:0')
min of d_p_list:  tensor(-0.0421, device='cuda:0')
Epoch:  177  
Training Loss: 4.9444499015808105
Test Loss:  7.236858367919922
Test Acc:  0.0
Valid Loss:  7.00079345703125
Valid Acc:  0.0
std:  0.08509398089585182 
thres:  0.0050576096534729
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 18%|█▊        | 177/1000 [11:17<51:55,  3.79s/it]Epoch:   178
max of grad d_p:  tensor(2.9479, device='cuda:0')
min of grad d_p:  tensor(-25.1245, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0804, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4926, device='cuda:0') norm:  tensor(1.4040, device='cuda:0') MSE:  tensor(5.2701e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0047, device='cuda:0') mean:  tensor(1.6304e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0250, device='cuda:0') MSE:  tensor(9.3660e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0107, device='cuda:0')
min of d_p_list:  tensor(-0.0064, device='cuda:0')
Epoch:  178  
Training Loss: 4.893567085266113
Test Loss:  7.156992435455322
Test Acc:  0.0
Valid Loss:  6.921557426452637
Valid Acc:  0.0
std:  0.08878187904998854 
thres:  0.005004958629608154
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 18%|█▊        | 178/1000 [11:21<52:23,  3.82s/it]Epoch:   179
max of grad d_p:  tensor(2.9289, device='cuda:0')
min of grad d_p:  tensor(-24.9454, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1020, device='cuda:0') mean:  tensor(6.5970e-05, device='cuda:0') min:  tensor(-0.3471, device='cuda:0') norm:  tensor(1.1619, device='cuda:0') MSE:  tensor(4.3615e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1001, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.4946, device='cuda:0') MSE:  tensor(1.8567e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0125, device='cuda:0')
min of d_p_list:  tensor(-0.0097, device='cuda:0')
Epoch:  179  
Training Loss: 4.842743873596191
Test Loss:  7.078868865966797
Test Acc:  0.0
Valid Loss:  6.845967769622803
Valid Acc:  0.0
std:  0.0697224403711774 
thres:  0.0049427883148193364
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 18%|█▊        | 179/1000 [11:25<52:17,  3.82s/it]Epoch:   180
max of grad d_p:  tensor(2.8870, device='cuda:0')
min of grad d_p:  tensor(-24.7842, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0855, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4300, device='cuda:0') norm:  tensor(1.2565, device='cuda:0') MSE:  tensor(4.7165e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0050, device='cuda:0') mean:  tensor(1.5744e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0230, device='cuda:0') MSE:  tensor(8.6151e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0270, device='cuda:0')
min of d_p_list:  tensor(-0.0357, device='cuda:0')
Epoch:  180  
Training Loss: 4.663843154907227
Test Loss:  6.869441032409668
Test Acc:  0.0
Valid Loss:  6.625082969665527
Valid Acc:  0.0
std:  0.11385232487815077 
thres:  0.004867815685272217
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 18%|█▊        | 180/1000 [11:28<52:23,  3.83s/it]Epoch:   181
max of grad d_p:  tensor(2.7030, device='cuda:0')
min of grad d_p:  tensor(-25.2282, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0761, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4742, device='cuda:0') norm:  tensor(1.3469, device='cuda:0') MSE:  tensor(5.0560e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0114, device='cuda:0') mean:  tensor(2.2855e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0374, device='cuda:0') MSE:  tensor(1.4055e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0102, device='cuda:0')
min of d_p_list:  tensor(-0.0270, device='cuda:0')
Epoch:  181  
Training Loss: 4.615204334259033
Test Loss:  6.789222717285156
Test Acc:  0.0
Valid Loss:  6.549769401550293
Valid Acc:  0.0
std:  0.12947019968467596 
thres:  0.004791961669921875
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 18%|█▊        | 181/1000 [11:32<52:39,  3.86s/it]Epoch:   182
max of grad d_p:  tensor(2.6525, device='cuda:0')
min of grad d_p:  tensor(-25.0201, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0950, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.7262, device='cuda:0') norm:  tensor(1.7752, device='cuda:0') MSE:  tensor(6.6638e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0299, device='cuda:0') mean:  tensor(3.7600e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0667, device='cuda:0') MSE:  tensor(2.5027e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0145, device='cuda:0')
min of d_p_list:  tensor(-0.0235, device='cuda:0')
Epoch:  182  
Training Loss: 4.566686630249023
Test Loss:  6.713499069213867
Test Acc:  0.0
Valid Loss:  6.477805137634277
Valid Acc:  0.0
std:  0.12866066057939105 
thres:  0.004716409015655517
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 18%|█▊        | 182/1000 [11:36<52:27,  3.85s/it]Epoch:   183
max of grad d_p:  tensor(2.6120, device='cuda:0')
min of grad d_p:  tensor(-24.6565, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0932, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.5306, device='cuda:0') norm:  tensor(1.4499, device='cuda:0') MSE:  tensor(5.4425e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0039, device='cuda:0') mean:  tensor(1.6165e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0226, device='cuda:0') MSE:  tensor(8.4879e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0885, device='cuda:0')
min of d_p_list:  tensor(-0.1026, device='cuda:0')
Epoch:  183  
Training Loss: 4.539196014404297
Test Loss:  6.697362899780273
Test Acc:  0.0
Valid Loss:  6.4424285888671875
Valid Acc:  0.0
std:  0.10739787978837263 
thres:  0.004645534801483154
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 18%|█▊        | 183/1000 [11:40<52:27,  3.85s/it]Epoch:   184
max of grad d_p:  tensor(2.7062, device='cuda:0')
min of grad d_p:  tensor(-25.3052, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0763, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.5467, device='cuda:0') norm:  tensor(1.3966, device='cuda:0') MSE:  tensor(5.2425e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0274, device='cuda:0') mean:  tensor(7.8544e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1144, device='cuda:0') MSE:  tensor(4.2932e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0194, device='cuda:0')
min of d_p_list:  tensor(-0.0453, device='cuda:0')
Epoch:  184  
Training Loss: 4.49069881439209
Test Loss:  6.625931262969971
Test Acc:  0.0
Valid Loss:  6.3705034255981445
Valid Acc:  0.0
std:  0.05994521323335837 
thres:  0.0045751257896423335
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 18%|█▊        | 184/1000 [11:44<52:16,  3.84s/it]Epoch:   185
max of grad d_p:  tensor(2.6559, device='cuda:0')
min of grad d_p:  tensor(-25.0116, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0816, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.5097, device='cuda:0') norm:  tensor(1.4130, device='cuda:0') MSE:  tensor(5.3040e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0042, device='cuda:0') mean:  tensor(1.6900e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0250, device='cuda:0') MSE:  tensor(9.3804e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0106, device='cuda:0')
min of d_p_list:  tensor(-0.0151, device='cuda:0')
Epoch:  185  
Training Loss: 4.442751884460449
Test Loss:  6.552966117858887
Test Acc:  0.0
Valid Loss:  6.295515537261963
Valid Acc:  0.0
std:  0.05973768132086859 
thres:  0.004530907535552979
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 18%|█▊        | 185/1000 [11:48<52:32,  3.87s/it]Epoch:   186
max of grad d_p:  tensor(2.6343, device='cuda:0')
min of grad d_p:  tensor(-24.8489, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0888, device='cuda:0') mean:  tensor(8.5473e-05, device='cuda:0') min:  tensor(-0.4099, device='cuda:0') norm:  tensor(1.2365, device='cuda:0') MSE:  tensor(4.6413e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0125, device='cuda:0') mean:  tensor(2.4593e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0393, device='cuda:0') MSE:  tensor(1.4754e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0089, device='cuda:0')
min of d_p_list:  tensor(-0.0077, device='cuda:0')
Epoch:  186  
Training Loss: 4.3975019454956055
Test Loss:  6.484011650085449
Test Acc:  0.0
Valid Loss:  6.22797966003418
Valid Acc:  0.0
std:  0.06173360190329818 
thres:  0.004487367057800293
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 19%|█▊        | 186/1000 [11:52<52:16,  3.85s/it]Epoch:   187
max of grad d_p:  tensor(2.6131, device='cuda:0')
min of grad d_p:  tensor(-24.7334, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0700, device='cuda:0') mean:  tensor(9.9224e-05, device='cuda:0') min:  tensor(-0.4526, device='cuda:0') norm:  tensor(1.2828, device='cuda:0') MSE:  tensor(4.8151e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0141, device='cuda:0') mean:  tensor(2.2776e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0393, device='cuda:0') MSE:  tensor(1.4749e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0247, device='cuda:0')
min of d_p_list:  tensor(-0.0214, device='cuda:0')
Epoch:  187  
Training Loss: 4.353478908538818
Test Loss:  6.416562080383301
Test Acc:  0.0
Valid Loss:  6.163337707519531
Valid Acc:  0.0
std:  0.06572385174290496 
thres:  0.004444725513458252
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 19%|█▊        | 187/1000 [11:55<52:18,  3.86s/it]Epoch:   188
max of grad d_p:  tensor(2.5536, device='cuda:0')
min of grad d_p:  tensor(-24.5373, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0957, device='cuda:0') mean:  tensor(7.3807e-05, device='cuda:0') min:  tensor(-0.3605, device='cuda:0') norm:  tensor(1.1746, device='cuda:0') MSE:  tensor(4.4090e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0680, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.2733, device='cuda:0') MSE:  tensor(1.0259e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0221, device='cuda:0')
min of d_p_list:  tensor(-0.0150, device='cuda:0')
Epoch:  188  
Training Loss: 4.3088788986206055
Test Loss:  6.349752426147461
Test Acc:  0.0
Valid Loss:  6.09529972076416
Valid Acc:  0.0
std:  0.06406021524922359 
thres:  0.004398662090301514
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 19%|█▉        | 188/1000 [11:59<52:05,  3.85s/it]Epoch:   189
max of grad d_p:  tensor(2.5309, device='cuda:0')
min of grad d_p:  tensor(-24.5144, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0774, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.5181, device='cuda:0') norm:  tensor(1.4241, device='cuda:0') MSE:  tensor(5.3458e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0125, device='cuda:0') mean:  tensor(4.6300e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0672, device='cuda:0') MSE:  tensor(2.5234e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0729, device='cuda:0')
min of d_p_list:  tensor(-0.1367, device='cuda:0')
Epoch:  189  
Training Loss: 4.237918853759766
Test Loss:  6.2808966636657715
Test Acc:  0.0
Valid Loss:  6.018540859222412
Valid Acc:  0.0
std:  0.07086133459372598 
thres:  0.004348106098175049
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 19%|█▉        | 189/1000 [12:03<50:50,  3.76s/it]Epoch:   190
max of grad d_p:  tensor(2.5020, device='cuda:0')
min of grad d_p:  tensor(-25.1647, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0822, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4336, device='cuda:0') norm:  tensor(1.3531, device='cuda:0') MSE:  tensor(5.0794e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0026, device='cuda:0') mean:  tensor(6.6732e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0101, device='cuda:0') MSE:  tensor(3.7852e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0104, device='cuda:0')
min of d_p_list:  tensor(-0.0102, device='cuda:0')
Epoch:  190  
Training Loss: 4.193867206573486
Test Loss:  6.206284523010254
Test Acc:  0.0
Valid Loss:  5.948494911193848
Valid Acc:  0.0
std:  0.07422902120537135 
thres:  0.004298329162597656
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 19%|█▉        | 190/1000 [12:07<51:21,  3.80s/it]Epoch:   191
max of grad d_p:  tensor(2.4809, device='cuda:0')
min of grad d_p:  tensor(-25.0032, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0736, device='cuda:0') mean:  tensor(7.9032e-05, device='cuda:0') min:  tensor(-0.3569, device='cuda:0') norm:  tensor(1.1355, device='cuda:0') MSE:  tensor(4.2624e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0078, device='cuda:0') mean:  tensor(2.4556e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0370, device='cuda:0') MSE:  tensor(1.3901e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1238, device='cuda:0')
min of d_p_list:  tensor(-0.1655, device='cuda:0')
Epoch:  191  
Training Loss: 4.137480735778809
Test Loss:  6.14030647277832
Test Acc:  0.0
Valid Loss:  5.888596534729004
Valid Acc:  0.0
std:  0.07754290114174794 
thres:  0.004246324920654298
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 19%|█▉        | 191/1000 [12:11<51:31,  3.82s/it]Epoch:   192
max of grad d_p:  tensor(2.4658, device='cuda:0')
min of grad d_p:  tensor(-27.0361, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0766, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4157, device='cuda:0') norm:  tensor(1.2255, device='cuda:0') MSE:  tensor(4.6001e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0052, device='cuda:0') mean:  tensor(1.1858e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0183, device='cuda:0') MSE:  tensor(6.8823e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1139, device='cuda:0')
min of d_p_list:  tensor(-0.2909, device='cuda:0')
Epoch:  192  
Training Loss: 3.9140238761901855
Test Loss:  5.75166130065918
Test Acc:  0.0
Valid Loss:  5.56031608581543
Valid Acc:  0.0
std:  0.13444877800000266 
thres:  0.0041584339141845705
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 19%|█▉        | 192/1000 [12:15<51:46,  3.84s/it]Epoch:   193
max of grad d_p:  tensor(2.3138, device='cuda:0')
min of grad d_p:  tensor(-26.1490, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0816, device='cuda:0') mean:  tensor(9.5494e-05, device='cuda:0') min:  tensor(-0.4517, device='cuda:0') norm:  tensor(1.1860, device='cuda:0') MSE:  tensor(4.4520e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0042, device='cuda:0') mean:  tensor(1.4465e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0221, device='cuda:0') MSE:  tensor(8.2809e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0130, device='cuda:0')
min of d_p_list:  tensor(-0.0201, device='cuda:0')
Epoch:  193  
Training Loss: 3.87388277053833
Test Loss:  5.689389228820801
Test Acc:  0.0
Valid Loss:  5.501559257507324
Valid Acc:  0.0
std:  0.14891185530210824 
thres:  0.004071434688568115
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 19%|█▉        | 193/1000 [12:19<52:48,  3.93s/it]Epoch:   194
max of grad d_p:  tensor(2.2802, device='cuda:0')
min of grad d_p:  tensor(-26.0049, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1011, device='cuda:0') mean:  tensor(8.7517e-05, device='cuda:0') min:  tensor(-0.4318, device='cuda:0') norm:  tensor(1.1333, device='cuda:0') MSE:  tensor(4.2540e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0027, device='cuda:0') mean:  tensor(6.0163e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0094, device='cuda:0') MSE:  tensor(3.5337e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0359, device='cuda:0')
min of d_p_list:  tensor(-0.0496, device='cuda:0')
Epoch:  194  
Training Loss: 3.834599018096924
Test Loss:  5.631865501403809
Test Acc:  0.0
Valid Loss:  5.448360919952393
Valid Acc:  0.0
std:  0.14609208248754468 
thres:  0.003990770721435547
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 19%|█▉        | 194/1000 [12:22<52:25,  3.90s/it]Epoch:   195
max of grad d_p:  tensor(2.2867, device='cuda:0')
min of grad d_p:  tensor(-25.4620, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0727, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4709, device='cuda:0') norm:  tensor(1.2973, device='cuda:0') MSE:  tensor(4.8697e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0093, device='cuda:0') mean:  tensor(1.9171e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0309, device='cuda:0') MSE:  tensor(1.1608e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.5270, device='cuda:0')
min of d_p_list:  tensor(-0.3695, device='cuda:0')
Epoch:  195  
Training Loss: 4.871782302856445
Test Loss:  7.1730194091796875
Test Acc:  0.0
Valid Loss:  6.16506814956665
Valid Acc:  0.0
std:  0.387229629960425 
thres:  0.004126353740692139
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 20%|█▉        | 195/1000 [12:26<51:59,  3.87s/it]Epoch:   196
max of grad d_p:  tensor(3.3042, device='cuda:0')
min of grad d_p:  tensor(-28.9399, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1181, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4418, device='cuda:0') norm:  tensor(1.3430, device='cuda:0') MSE:  tensor(5.0413e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0345, device='cuda:0') mean:  tensor(5.3859e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0851, device='cuda:0') MSE:  tensor(3.1934e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0280, device='cuda:0')
min of d_p_list:  tensor(-0.0202, device='cuda:0')
Epoch:  196  
Training Loss: 4.81759786605835
Test Loss:  7.085023880004883
Test Acc:  0.0
Valid Loss:  6.09688663482666
Valid Acc:  0.0
std:  0.4764276860658167 
thres:  0.004262377166748047
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  31
 20%|█▉        | 196/1000 [12:30<51:48,  3.87s/it]Epoch:   197
max of grad d_p:  tensor(3.2880, device='cuda:0')
min of grad d_p:  tensor(-28.4955, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1455, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.5136, device='cuda:0') norm:  tensor(1.4367, device='cuda:0') MSE:  tensor(5.3930e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0032, device='cuda:0') mean:  tensor(7.6498e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0114, device='cuda:0') MSE:  tensor(4.2721e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0345, device='cuda:0')
min of d_p_list:  tensor(-0.0418, device='cuda:0')
Epoch:  197  
Training Loss: 4.7661356925964355
Test Loss:  7.001659393310547
Test Acc:  0.0
Valid Loss:  6.0233354568481445
Valid Acc:  0.0
std:  0.4737341929902806 
thres:  0.004432799530029297
Preserved_eigens number check:  31
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 20%|█▉        | 197/1000 [12:34<52:29,  3.92s/it]Epoch:   198
max of grad d_p:  tensor(3.3022, device='cuda:0')
min of grad d_p:  tensor(-28.2361, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1400, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.5472, device='cuda:0') norm:  tensor(1.5972, device='cuda:0') MSE:  tensor(5.9955e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0070, device='cuda:0') mean:  tensor(7.8715e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0139, device='cuda:0') MSE:  tensor(5.2194e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0799, device='cuda:0')
min of d_p_list:  tensor(-0.0626, device='cuda:0')
Epoch:  198  
Training Loss: 4.695290565490723
Test Loss:  6.892204284667969
Test Acc:  0.0
Valid Loss:  5.9321393966674805
Valid Acc:  0.0
std:  0.38566614437276703 
thres:  0.004597081089019776
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 20%|█▉        | 198/1000 [12:38<51:45,  3.87s/it]Epoch:   199
max of grad d_p:  tensor(3.2460, device='cuda:0')
min of grad d_p:  tensor(-27.7874, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1193, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4524, device='cuda:0') norm:  tensor(1.4062, device='cuda:0') MSE:  tensor(5.2786e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0044, device='cuda:0') mean:  tensor(9.7917e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0167, device='cuda:0') MSE:  tensor(6.2721e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0436, device='cuda:0')
min of d_p_list:  tensor(-0.0578, device='cuda:0')
Epoch:  199  
Training Loss: 4.639265537261963
Test Loss:  6.7991533279418945
Test Acc:  0.0
Valid Loss:  5.865828037261963
Valid Acc:  0.0
std:  0.08318034907169017 
thres:  0.004758014392852784
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 20%|█▉        | 199/1000 [12:42<51:49,  3.88s/it]Epoch:   200
max of grad d_p:  tensor(3.2136, device='cuda:0')
min of grad d_p:  tensor(-26.9415, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1154, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.5169, device='cuda:0') norm:  tensor(1.4708, device='cuda:0') MSE:  tensor(5.5208e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0516, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(1.7280e-11, device='cuda:0') norm:  tensor(0.1797, device='cuda:0') MSE:  tensor(6.7467e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2903, device='cuda:0')
min of d_p_list:  tensor(-0.6683, device='cuda:0')
Epoch:  200  
Training Loss: 4.429574489593506
Test Loss:  6.37469482421875
Test Acc:  0.0
Valid Loss:  5.595008850097656
Valid Acc:  0.0
std:  0.1344729973211314 
thres:  0.004669572830200195
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 20%|██        | 200/1000 [12:46<51:21,  3.85s/it]Epoch:   201
max of grad d_p:  tensor(3.6782, device='cuda:0')
min of grad d_p:  tensor(-24.3590, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1074, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.6422, device='cuda:0') norm:  tensor(1.6208, device='cuda:0') MSE:  tensor(6.0842e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0495, device='cuda:0') mean:  tensor(6.8876e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1100, device='cuda:0') MSE:  tensor(4.1295e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0168, device='cuda:0')
min of d_p_list:  tensor(-0.0162, device='cuda:0')
Epoch:  201  
Training Loss: 4.385638236999512
Test Loss:  6.313542366027832
Test Acc:  0.0
Valid Loss:  5.540102958679199
Valid Acc:  0.0
std:  0.14953564978997158 
thres:  0.004583180904388428
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 20%|██        | 201/1000 [12:50<51:37,  3.88s/it]Epoch:   202
max of grad d_p:  tensor(3.6052, device='cuda:0')
min of grad d_p:  tensor(-24.5742, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1216, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.5708, device='cuda:0') norm:  tensor(1.5699, device='cuda:0') MSE:  tensor(5.8929e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0041, device='cuda:0') mean:  tensor(1.3446e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0200, device='cuda:0') MSE:  tensor(7.4927e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0549, device='cuda:0')
min of d_p_list:  tensor(-0.1190, device='cuda:0')
Epoch:  202  
Training Loss: 4.30813455581665
Test Loss:  6.178484916687012
Test Acc:  0.0
Valid Loss:  5.418849945068359
Valid Acc:  0.0
std:  0.14968606071819826 
thres:  0.004491580677032471
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 20%|██        | 202/1000 [12:53<51:23,  3.86s/it]Epoch:   203
max of grad d_p:  tensor(3.6465, device='cuda:0')
min of grad d_p:  tensor(-23.7222, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1229, device='cuda:0') mean:  tensor(6.6191e-05, device='cuda:0') min:  tensor(-0.3353, device='cuda:0') norm:  tensor(1.2536, device='cuda:0') MSE:  tensor(4.7058e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0033, device='cuda:0') mean:  tensor(1.6240e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0219, device='cuda:0') MSE:  tensor(8.2091e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0327, device='cuda:0')
min of d_p_list:  tensor(-0.0310, device='cuda:0')
Epoch:  203  
Training Loss: 4.254572868347168
Test Loss:  6.105008125305176
Test Acc:  0.0
Valid Loss:  5.356234550476074
Valid Acc:  0.0
std:  0.13255802418087914 
thres:  0.00440343713760376
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 20%|██        | 203/1000 [12:57<51:33,  3.88s/it]Epoch:   204
max of grad d_p:  tensor(3.6683, device='cuda:0')
min of grad d_p:  tensor(-23.4514, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0889, device='cuda:0') mean:  tensor(9.8369e-05, device='cuda:0') min:  tensor(-0.5032, device='cuda:0') norm:  tensor(1.3442, device='cuda:0') MSE:  tensor(5.0458e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0096, device='cuda:0') mean:  tensor(4.7927e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0645, device='cuda:0') MSE:  tensor(2.4194e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0149, device='cuda:0')
min of d_p_list:  tensor(-0.0143, device='cuda:0')
Epoch:  204  
Training Loss: 4.207599639892578
Test Loss:  6.036289691925049
Test Acc:  0.0
Valid Loss:  5.297158718109131
Valid Acc:  0.0
std:  0.08164355566458059 
thres:  0.004317103958129883
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 20%|██        | 204/1000 [13:01<51:32,  3.89s/it]Epoch:   205
max of grad d_p:  tensor(3.6742, device='cuda:0')
min of grad d_p:  tensor(-23.0800, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1117, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.5402, device='cuda:0') norm:  tensor(1.4551, device='cuda:0') MSE:  tensor(5.4622e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0024, device='cuda:0') mean:  tensor(6.2731e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0086, device='cuda:0') MSE:  tensor(3.2285e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0178, device='cuda:0')
min of d_p_list:  tensor(-0.0160, device='cuda:0')
Epoch:  205  
Training Loss: 4.16147518157959
Test Loss:  5.969049453735352
Test Acc:  0.0
Valid Loss:  5.240278244018555
Valid Acc:  0.0
std:  0.07813270603159783 
thres:  0.004263484096527099
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 20%|██        | 205/1000 [13:05<49:29,  3.74s/it]Epoch:   206
max of grad d_p:  tensor(3.6480, device='cuda:0')
min of grad d_p:  tensor(-23.0009, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0886, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.6100, device='cuda:0') norm:  tensor(1.4242, device='cuda:0') MSE:  tensor(5.3460e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0176, device='cuda:0') mean:  tensor(3.6750e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0539, device='cuda:0') MSE:  tensor(2.0231e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0287, device='cuda:0')
min of d_p_list:  tensor(-0.0318, device='cuda:0')
Epoch:  206  
Training Loss: 4.112805366516113
Test Loss:  5.918257713317871
Test Acc:  0.0
Valid Loss:  5.1938066482543945
Valid Acc:  0.0
std:  0.06843754723691983 
thres:  0.0042089175224304205
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 21%|██        | 206/1000 [13:08<49:54,  3.77s/it]Epoch:   207
max of grad d_p:  tensor(3.6530, device='cuda:0')
min of grad d_p:  tensor(-22.8785, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1308, device='cuda:0') mean:  tensor(6.6932e-05, device='cuda:0') min:  tensor(-0.4011, device='cuda:0') norm:  tensor(1.1234, device='cuda:0') MSE:  tensor(4.2171e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.1086, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(3.7253e-09, device='cuda:0') norm:  tensor(2.4753, device='cuda:0') MSE:  tensor(9.2916e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0430, device='cuda:0')
min of d_p_list:  tensor(-0.0286, device='cuda:0')
Epoch:  207  
Training Loss: 4.071134567260742
Test Loss:  5.846706390380859
Test Acc:  0.0
Valid Loss:  5.131319999694824
Valid Acc:  0.0
std:  0.06530668184076281 
thres:  0.0041615175247192385
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 21%|██        | 207/1000 [13:12<50:08,  3.79s/it]Epoch:   208
max of grad d_p:  tensor(3.6334, device='cuda:0')
min of grad d_p:  tensor(-22.9962, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1466, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.7645, device='cuda:0') norm:  tensor(1.6884, device='cuda:0') MSE:  tensor(6.3377e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0237, device='cuda:0') mean:  tensor(3.0949e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0569, device='cuda:0') MSE:  tensor(2.1341e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0748, device='cuda:0')
min of d_p_list:  tensor(-0.1114, device='cuda:0')
Epoch:  208  
Training Loss: 4.0190253257751465
Test Loss:  5.755831241607666
Test Acc:  0.0
Valid Loss:  5.036527633666992
Valid Acc:  0.0
std:  0.06614078058976929 
thres:  0.004114408016204834
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 21%|██        | 208/1000 [13:16<50:14,  3.81s/it]Epoch:   209
max of grad d_p:  tensor(3.4490, device='cuda:0')
min of grad d_p:  tensor(-24.1745, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1182, device='cuda:0') mean:  tensor(9.5974e-05, device='cuda:0') min:  tensor(-0.5530, device='cuda:0') norm:  tensor(1.4037, device='cuda:0') MSE:  tensor(5.2692e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0201, device='cuda:0') mean:  tensor(3.2407e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0565, device='cuda:0') MSE:  tensor(2.1196e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0232, device='cuda:0')
min of d_p_list:  tensor(-0.0229, device='cuda:0')
Epoch:  209  
Training Loss: 3.972139835357666
Test Loss:  5.68791389465332
Test Acc:  0.0
Valid Loss:  4.973264694213867
Valid Acc:  0.0
std:  0.06684355904767576 
thres:  0.004067316055297852
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 21%|██        | 209/1000 [13:20<51:13,  3.89s/it]Epoch:   210
max of grad d_p:  tensor(3.3984, device='cuda:0')
min of grad d_p:  tensor(-23.9274, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0969, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.6015, device='cuda:0') norm:  tensor(1.3673, device='cuda:0') MSE:  tensor(5.1325e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0040, device='cuda:0') mean:  tensor(1.0467e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0157, device='cuda:0') MSE:  tensor(5.8835e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0318, device='cuda:0')
min of d_p_list:  tensor(-0.0427, device='cuda:0')
Epoch:  210  
Training Loss: 3.9235501289367676
Test Loss:  5.6123528480529785
Test Acc:  0.0
Valid Loss:  4.916449546813965
Valid Acc:  0.0
std:  0.06755936843414526 
thres:  0.004019731044769288
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 21%|██        | 210/1000 [13:24<50:26,  3.83s/it]Epoch:   211
max of grad d_p:  tensor(3.3556, device='cuda:0')
min of grad d_p:  tensor(-23.4835, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1344, device='cuda:0') mean:  tensor(6.2006e-05, device='cuda:0') min:  tensor(-0.3609, device='cuda:0') norm:  tensor(1.1431, device='cuda:0') MSE:  tensor(4.2909e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0043, device='cuda:0') mean:  tensor(1.1280e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0159, device='cuda:0') MSE:  tensor(5.9782e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0118, device='cuda:0')
min of d_p_list:  tensor(-0.0098, device='cuda:0')
Epoch:  211  
Training Loss: 3.8738462924957275
Test Loss:  5.551137924194336
Test Acc:  0.0
Valid Loss:  4.853652000427246
Valid Acc:  0.0
std:  0.06931173794106306 
thres:  0.00397193922996521
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 21%|██        | 211/1000 [13:28<50:30,  3.84s/it]Epoch:   212
max of grad d_p:  tensor(3.3346, device='cuda:0')
min of grad d_p:  tensor(-23.4043, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1156, device='cuda:0') mean:  tensor(8.3479e-05, device='cuda:0') min:  tensor(-0.4713, device='cuda:0') norm:  tensor(1.2761, device='cuda:0') MSE:  tensor(4.7901e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0059, device='cuda:0') mean:  tensor(6.7495e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0118, device='cuda:0') MSE:  tensor(4.4138e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1529, device='cuda:0')
min of d_p_list:  tensor(-0.1520, device='cuda:0')
Epoch:  212  
Training Loss: 3.916821002960205
Test Loss:  5.564642429351807
Test Acc:  0.0
Valid Loss:  4.93383264541626
Valid Acc:  0.0
std:  0.04991263139452106 
thres:  0.003941076517105103
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  44
 21%|██        | 212/1000 [13:32<50:44,  3.86s/it]Epoch:   213
max of grad d_p:  tensor(3.2130, device='cuda:0')
min of grad d_p:  tensor(-20.2956, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1633, device='cuda:0') mean:  tensor(3.9786e-05, device='cuda:0') min:  tensor(-0.3174, device='cuda:0') norm:  tensor(1.1457, device='cuda:0') MSE:  tensor(4.3005e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0358, device='cuda:0') mean:  tensor(8.2159e-05, device='cuda:0') min:  tensor(5.8208e-11, device='cuda:0') norm:  tensor(0.1285, device='cuda:0') MSE:  tensor(4.8225e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0308, device='cuda:0')
min of d_p_list:  tensor(-0.0218, device='cuda:0')
Epoch:  213  
Training Loss: 3.7342958450317383
Test Loss:  5.326287746429443
Test Acc:  0.0
Valid Loss:  4.728479385375977
Valid Acc:  0.0
std:  0.08114728337138287 
thres:  0.003884130620956421
Preserved_eigens number check:  44
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 21%|██▏       | 213/1000 [13:36<50:43,  3.87s/it]Epoch:   214
max of grad d_p:  tensor(3.0650, device='cuda:0')
min of grad d_p:  tensor(-19.9278, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1160, device='cuda:0') mean:  tensor(8.2104e-05, device='cuda:0') min:  tensor(-0.5516, device='cuda:0') norm:  tensor(1.3170, device='cuda:0') MSE:  tensor(4.9438e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0060, device='cuda:0') mean:  tensor(1.3348e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0194, device='cuda:0') MSE:  tensor(7.2731e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0132, device='cuda:0')
min of d_p_list:  tensor(-0.0156, device='cuda:0')
Epoch:  214  
Training Loss: 3.6935410499572754
Test Loss:  5.270462989807129
Test Acc:  0.0
Valid Loss:  4.675890922546387
Valid Acc:  0.0
std:  0.09589547862290168 
thres:  0.003828410863876343
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 21%|██▏       | 214/1000 [13:39<50:43,  3.87s/it]Epoch:   215
max of grad d_p:  tensor(3.0507, device='cuda:0')
min of grad d_p:  tensor(-19.8627, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1419, device='cuda:0') mean:  tensor(4.4921e-05, device='cuda:0') min:  tensor(-0.3484, device='cuda:0') norm:  tensor(1.1614, device='cuda:0') MSE:  tensor(4.3596e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0077, device='cuda:0') mean:  tensor(2.0067e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0337, device='cuda:0') MSE:  tensor(1.2650e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0105, device='cuda:0')
min of d_p_list:  tensor(-0.0088, device='cuda:0')
Epoch:  215  
Training Loss: 3.6526408195495605
Test Loss:  5.21358585357666
Test Acc:  0.0
Valid Loss:  4.621272563934326
Valid Acc:  0.0
std:  0.10309701454983797 
thres:  0.0037742290019989015
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 22%|██▏       | 215/1000 [13:43<49:58,  3.82s/it]Epoch:   216
max of grad d_p:  tensor(3.0087, device='cuda:0')
min of grad d_p:  tensor(-19.7575, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1413, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.7586, device='cuda:0') norm:  tensor(1.6677, device='cuda:0') MSE:  tensor(6.2602e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0189, device='cuda:0') mean:  tensor(3.2729e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0594, device='cuda:0') MSE:  tensor(2.2309e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0278, device='cuda:0')
min of d_p_list:  tensor(-0.0394, device='cuda:0')
Epoch:  216  
Training Loss: 3.608401298522949
Test Loss:  5.157715797424316
Test Acc:  0.0
Valid Loss:  4.572170734405518
Valid Acc:  0.0
std:  0.10642178889173504 
thres:  0.003721140003204346
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 22%|██▏       | 216/1000 [13:47<49:04,  3.76s/it]Epoch:   217
max of grad d_p:  tensor(3.0148, device='cuda:0')
min of grad d_p:  tensor(-19.7012, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0975, device='cuda:0') mean:  tensor(9.5596e-05, device='cuda:0') min:  tensor(-0.5918, device='cuda:0') norm:  tensor(1.3392, device='cuda:0') MSE:  tensor(5.0272e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0046, device='cuda:0') mean:  tensor(1.1517e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0173, device='cuda:0') MSE:  tensor(6.5057e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0151, device='cuda:0')
min of d_p_list:  tensor(-0.0287, device='cuda:0')
Epoch:  217  
Training Loss: 3.570798397064209
Test Loss:  5.0985894203186035
Test Acc:  0.0
Valid Loss:  4.520790100097656
Valid Acc:  0.0
std:  0.05829785908198908 
thres:  0.0036519354820251466
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 22%|██▏       | 217/1000 [13:51<49:06,  3.76s/it]Epoch:   218
max of grad d_p:  tensor(3.0092, device='cuda:0')
min of grad d_p:  tensor(-19.5264, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0973, device='cuda:0') mean:  tensor(8.0470e-05, device='cuda:0') min:  tensor(-0.5617, device='cuda:0') norm:  tensor(1.2554, device='cuda:0') MSE:  tensor(4.7125e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1647, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.4000, device='cuda:0') MSE:  tensor(1.5014e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0143, device='cuda:0')
min of d_p_list:  tensor(-0.0141, device='cuda:0')
Epoch:  218  
Training Loss: 3.5353055000305176
Test Loss:  5.049235820770264
Test Acc:  0.0
Valid Loss:  4.47688102722168
Valid Acc:  0.0
std:  0.05637924031497091 
thres:  0.0036121374130249025
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 22%|██▏       | 218/1000 [13:54<49:21,  3.79s/it]Epoch:   219
max of grad d_p:  tensor(2.9682, device='cuda:0')
min of grad d_p:  tensor(-19.4460, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1417, device='cuda:0') mean:  tensor(4.3058e-05, device='cuda:0') min:  tensor(-0.3946, device='cuda:0') norm:  tensor(1.1366, device='cuda:0') MSE:  tensor(4.2666e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0017, device='cuda:0') mean:  tensor(5.1692e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0076, device='cuda:0') MSE:  tensor(2.8490e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0309, device='cuda:0')
min of d_p_list:  tensor(-0.0549, device='cuda:0')
Epoch:  219  
Training Loss: 3.4810357093811035
Test Loss:  4.978684425354004
Test Acc:  0.0
Valid Loss:  4.410804748535156
Valid Acc:  0.0
std:  0.059029643960091936 
thres:  0.003569636344909668
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 22%|██▏       | 219/1000 [13:58<49:47,  3.83s/it]Epoch:   220
max of grad d_p:  tensor(2.9153, device='cuda:0')
min of grad d_p:  tensor(-19.9338, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0950, device='cuda:0') mean:  tensor(7.1448e-05, device='cuda:0') min:  tensor(-0.4743, device='cuda:0') norm:  tensor(1.1827, device='cuda:0') MSE:  tensor(4.4396e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0029, device='cuda:0') mean:  tensor(6.6162e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0095, device='cuda:0') MSE:  tensor(3.5776e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0167, device='cuda:0')
min of d_p_list:  tensor(-0.0135, device='cuda:0')
Epoch:  220  
Training Loss: 3.4436419010162354
Test Loss:  4.92366886138916
Test Acc:  0.0
Valid Loss:  4.362027645111084
Valid Acc:  0.0
std:  0.0594495446953582 
thres:  0.003527836561203003
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 22%|██▏       | 220/1000 [14:02<50:15,  3.87s/it]Epoch:   221
max of grad d_p:  tensor(2.9052, device='cuda:0')
min of grad d_p:  tensor(-19.7519, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0907, device='cuda:0') mean:  tensor(6.8330e-05, device='cuda:0') min:  tensor(-0.4746, device='cuda:0') norm:  tensor(1.1320, device='cuda:0') MSE:  tensor(4.2492e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0259, device='cuda:0') mean:  tensor(4.0222e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0606, device='cuda:0') MSE:  tensor(2.2734e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0640, device='cuda:0')
min of d_p_list:  tensor(-0.0944, device='cuda:0')
Epoch:  221  
Training Loss: 3.4301981925964355
Test Loss:  4.905700206756592
Test Acc:  0.0
Valid Loss:  4.35032320022583
Valid Acc:  0.0
std:  0.05359579564625511 
thres:  0.0034921959400177004
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 22%|██▏       | 221/1000 [14:06<50:45,  3.91s/it]Epoch:   222
max of grad d_p:  tensor(2.7746, device='cuda:0')
min of grad d_p:  tensor(-19.4957, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1466, device='cuda:0') mean:  tensor(6.1111e-05, device='cuda:0') min:  tensor(-0.4606, device='cuda:0') norm:  tensor(1.1426, device='cuda:0') MSE:  tensor(4.2890e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0033, device='cuda:0') mean:  tensor(1.0709e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0155, device='cuda:0') MSE:  tensor(5.8083e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0074, device='cuda:0')
min of d_p_list:  tensor(-0.0093, device='cuda:0')
Epoch:  222  
Training Loss: 3.3938169479370117
Test Loss:  4.852643013000488
Test Acc:  0.0
Valid Loss:  4.302586078643799
Valid Acc:  0.0
std:  0.04816251595755158 
thres:  0.0034567996501922607
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 22%|██▏       | 222/1000 [14:10<50:21,  3.88s/it]Epoch:   223
max of grad d_p:  tensor(2.7570, device='cuda:0')
min of grad d_p:  tensor(-19.4200, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1421, device='cuda:0') mean:  tensor(7.4731e-05, device='cuda:0') min:  tensor(-0.5425, device='cuda:0') norm:  tensor(1.3156, device='cuda:0') MSE:  tensor(4.9386e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0392, device='cuda:0') mean:  tensor(5.8282e-05, device='cuda:0') min:  tensor(5.6389e-11, device='cuda:0') norm:  tensor(0.0909, device='cuda:0') MSE:  tensor(3.4126e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0102, device='cuda:0')
min of d_p_list:  tensor(-0.0152, device='cuda:0')
Epoch:  223  
Training Loss: 3.358921527862549
Test Loss:  4.80179500579834
Test Acc:  0.0
Valid Loss:  4.254557132720947
Valid Acc:  0.0
std:  0.04193527622710984 
thres:  0.0034215228557586672
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 22%|██▏       | 223/1000 [14:14<49:54,  3.85s/it]Epoch:   224
max of grad d_p:  tensor(2.7482, device='cuda:0')
min of grad d_p:  tensor(-19.1866, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1826, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.8383, device='cuda:0') norm:  tensor(1.7193, device='cuda:0') MSE:  tensor(6.4538e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0107, device='cuda:0') mean:  tensor(3.7947e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0516, device='cuda:0') MSE:  tensor(1.9364e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0123, device='cuda:0')
min of d_p_list:  tensor(-0.0111, device='cuda:0')
Epoch:  224  
Training Loss: 3.3219685554504395
Test Loss:  4.750308036804199
Test Acc:  0.0
Valid Loss:  4.208124160766602
Valid Acc:  0.0
std:  0.0449480678847821 
thres:  0.0033897094249725345
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 22%|██▏       | 224/1000 [14:18<49:52,  3.86s/it]Epoch:   225
max of grad d_p:  tensor(2.7312, device='cuda:0')
min of grad d_p:  tensor(-19.0630, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1344, device='cuda:0') mean:  tensor(4.7438e-05, device='cuda:0') min:  tensor(-0.3957, device='cuda:0') norm:  tensor(1.1092, device='cuda:0') MSE:  tensor(4.1638e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0047, device='cuda:0') mean:  tensor(9.0752e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0153, device='cuda:0') MSE:  tensor(5.7270e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0461, device='cuda:0')
min of d_p_list:  tensor(-0.0472, device='cuda:0')
Epoch:  225  
Training Loss: 3.292682647705078
Test Loss:  4.697544097900391
Test Acc:  0.0
Valid Loss:  4.157978534698486
Valid Acc:  0.0
std:  0.049090504856899975 
thres:  0.0033595175743103027
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 22%|██▎       | 225/1000 [14:22<50:35,  3.92s/it]Epoch:   226
max of grad d_p:  tensor(2.7171, device='cuda:0')
min of grad d_p:  tensor(-18.7158, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1443, device='cuda:0') mean:  tensor(2.4268e-05, device='cuda:0') min:  tensor(-0.2928, device='cuda:0') norm:  tensor(0.9694, device='cuda:0') MSE:  tensor(3.6389e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0055, device='cuda:0') mean:  tensor(1.0363e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0155, device='cuda:0') MSE:  tensor(5.8242e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0127, device='cuda:0')
min of d_p_list:  tensor(-0.0255, device='cuda:0')
Epoch:  226  
Training Loss: 3.256390333175659
Test Loss:  4.6461992263793945
Test Acc:  0.0
Valid Loss:  4.1090216636657715
Valid Acc:  0.0
std:  0.04826392441352658 
thres:  0.0033247560024261477
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 23%|██▎       | 226/1000 [14:26<50:09,  3.89s/it]Epoch:   227
max of grad d_p:  tensor(2.7322, device='cuda:0')
min of grad d_p:  tensor(-18.4054, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1189, device='cuda:0') mean:  tensor(5.0098e-05, device='cuda:0') min:  tensor(-0.4821, device='cuda:0') norm:  tensor(1.1978, device='cuda:0') MSE:  tensor(4.4961e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0149, device='cuda:0') mean:  tensor(3.1246e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0460, device='cuda:0') MSE:  tensor(1.7258e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0110, device='cuda:0')
min of d_p_list:  tensor(-0.0068, device='cuda:0')
Epoch:  227  
Training Loss: 3.2234344482421875
Test Loss:  4.597159385681152
Test Acc:  0.0
Valid Loss:  4.067874908447266
Valid Acc:  0.0
std:  0.04761855920945162 
thres:  0.0032906795024871824
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 23%|██▎       | 227/1000 [14:29<49:17,  3.83s/it]Epoch:   228
max of grad d_p:  tensor(2.7072, device='cuda:0')
min of grad d_p:  tensor(-18.3594, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1576, device='cuda:0') mean:  tensor(7.0062e-05, device='cuda:0') min:  tensor(-0.5543, device='cuda:0') norm:  tensor(1.3261, device='cuda:0') MSE:  tensor(4.9780e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0104, device='cuda:0') mean:  tensor(2.8356e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0400, device='cuda:0') MSE:  tensor(1.5014e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0529, device='cuda:0')
min of d_p_list:  tensor(-0.0548, device='cuda:0')
Epoch:  228  
Training Loss: 3.1904983520507812
Test Loss:  4.5530781745910645
Test Acc:  0.0
Valid Loss:  4.026003837585449
Valid Acc:  0.0
std:  0.04699713087252177 
thres:  0.003256994867324829
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 23%|██▎       | 228/1000 [14:33<49:46,  3.87s/it]Epoch:   229
max of grad d_p:  tensor(2.7299, device='cuda:0')
min of grad d_p:  tensor(-18.3737, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1340, device='cuda:0') mean:  tensor(4.9041e-05, device='cuda:0') min:  tensor(-0.4463, device='cuda:0') norm:  tensor(1.1129, device='cuda:0') MSE:  tensor(4.1777e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0044, device='cuda:0') mean:  tensor(1.0169e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0158, device='cuda:0') MSE:  tensor(5.9185e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0302, device='cuda:0')
min of d_p_list:  tensor(-0.0234, device='cuda:0')
Epoch:  229  
Training Loss: 3.155121326446533
Test Loss:  4.500182151794434
Test Acc:  0.0
Valid Loss:  3.9805240631103516
Valid Acc:  0.0
std:  0.04823419983461123 
thres:  0.003223625421524048
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 23%|██▎       | 229/1000 [14:37<50:54,  3.96s/it]Epoch:   230
max of grad d_p:  tensor(2.7097, device='cuda:0')
min of grad d_p:  tensor(-17.7826, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0914, device='cuda:0') mean:  tensor(6.4968e-05, device='cuda:0') min:  tensor(-0.5341, device='cuda:0') norm:  tensor(1.1541, device='cuda:0') MSE:  tensor(4.3322e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0024, device='cuda:0') mean:  tensor(5.0529e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0079, device='cuda:0') MSE:  tensor(2.9745e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0182, device='cuda:0')
min of d_p_list:  tensor(-0.0289, device='cuda:0')
Epoch:  230  
Training Loss: 3.121631622314453
Test Loss:  4.452287197113037
Test Acc:  0.0
Valid Loss:  3.9429025650024414
Valid Acc:  0.0
std:  0.04778040205016772 
thres:  0.003189415216445923
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 23%|██▎       | 230/1000 [14:41<50:13,  3.91s/it]Epoch:   231
max of grad d_p:  tensor(2.7200, device='cuda:0')
min of grad d_p:  tensor(-17.6408, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1127, device='cuda:0') mean:  tensor(5.1994e-05, device='cuda:0') min:  tensor(-0.4744, device='cuda:0') norm:  tensor(1.1434, device='cuda:0') MSE:  tensor(4.2920e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0087, device='cuda:0') mean:  tensor(1.5714e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0257, device='cuda:0') MSE:  tensor(9.6551e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0085, device='cuda:0')
min of d_p_list:  tensor(-0.0111, device='cuda:0')
Epoch:  231  
Training Loss: 3.0868167877197266
Test Loss:  4.402693748474121
Test Acc:  0.0
Valid Loss:  3.902298927307129
Valid Acc:  0.0
std:  0.048382988648494794 
thres:  0.0031555005073547367
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 23%|██▎       | 231/1000 [14:45<49:56,  3.90s/it]Epoch:   232
max of grad d_p:  tensor(2.6734, device='cuda:0')
min of grad d_p:  tensor(-17.6670, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1365, device='cuda:0') mean:  tensor(9.3435e-05, device='cuda:0') min:  tensor(-0.7038, device='cuda:0') norm:  tensor(1.4836, device='cuda:0') MSE:  tensor(5.5690e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0470, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.2250, device='cuda:0') MSE:  tensor(8.4478e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0536, device='cuda:0')
min of d_p_list:  tensor(-0.0707, device='cuda:0')
Epoch:  232  
Training Loss: 3.0495240688323975
Test Loss:  4.345008373260498
Test Acc:  0.0
Valid Loss:  3.85213041305542
Valid Acc:  0.0
std:  0.04954107212584285 
thres:  0.0031207184314727787
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 23%|██▎       | 232/1000 [14:49<49:00,  3.83s/it]Epoch:   233
max of grad d_p:  tensor(2.5844, device='cuda:0')
min of grad d_p:  tensor(-17.5917, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1046, device='cuda:0') mean:  tensor(5.3834e-05, device='cuda:0') min:  tensor(-0.4310, device='cuda:0') norm:  tensor(1.1114, device='cuda:0') MSE:  tensor(4.1720e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0067, device='cuda:0') mean:  tensor(1.0361e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0177, device='cuda:0') MSE:  tensor(6.6588e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0187, device='cuda:0')
min of d_p_list:  tensor(-0.0153, device='cuda:0')
Epoch:  233  
Training Loss: 3.0142035484313965
Test Loss:  4.294010162353516
Test Acc:  0.0
Valid Loss:  3.8071112632751465
Valid Acc:  0.0
std:  0.050063560747707875 
thres:  0.0030854594707489013
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 23%|██▎       | 233/1000 [14:53<49:32,  3.88s/it]Epoch:   234
max of grad d_p:  tensor(2.5369, device='cuda:0')
min of grad d_p:  tensor(-17.5468, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1346, device='cuda:0') mean:  tensor(9.3193e-05, device='cuda:0') min:  tensor(-0.6665, device='cuda:0') norm:  tensor(1.4373, device='cuda:0') MSE:  tensor(5.3953e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0089, device='cuda:0') mean:  tensor(1.1708e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0205, device='cuda:0') MSE:  tensor(7.6986e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0155, device='cuda:0')
min of d_p_list:  tensor(-0.0483, device='cuda:0')
Epoch:  234  
Training Loss: 2.9879302978515625
Test Loss:  4.262463569641113
Test Acc:  0.0
Valid Loss:  3.781369209289551
Valid Acc:  0.0
std:  0.048167204593934365 
thres:  0.003052021265029907
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 23%|██▎       | 234/1000 [14:56<48:19,  3.79s/it]Epoch:   235
max of grad d_p:  tensor(2.5165, device='cuda:0')
min of grad d_p:  tensor(-17.5553, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1271, device='cuda:0') mean:  tensor(3.0245e-05, device='cuda:0') min:  tensor(-0.3069, device='cuda:0') norm:  tensor(1.0604, device='cuda:0') MSE:  tensor(3.9805e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0076, device='cuda:0') mean:  tensor(8.4766e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0141, device='cuda:0') MSE:  tensor(5.3005e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1460, device='cuda:0')
min of d_p_list:  tensor(-0.1003, device='cuda:0')
Epoch:  235  
Training Loss: 2.958357095718384
Test Loss:  4.220191955566406
Test Acc:  0.0
Valid Loss:  3.75683331489563
Valid Acc:  0.0
std:  0.045157631816717635 
thres:  0.0030193663597106934
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 24%|██▎       | 235/1000 [15:00<46:03,  3.61s/it]Epoch:   236
max of grad d_p:  tensor(2.4046, device='cuda:0')
min of grad d_p:  tensor(-17.0099, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1344, device='cuda:0') mean:  tensor(6.0978e-05, device='cuda:0') min:  tensor(-0.5087, device='cuda:0') norm:  tensor(1.1920, device='cuda:0') MSE:  tensor(4.4743e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0058, device='cuda:0') mean:  tensor(1.4486e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0255, device='cuda:0') MSE:  tensor(9.5867e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0130, device='cuda:0')
min of d_p_list:  tensor(-0.0086, device='cuda:0')
Epoch:  236  
Training Loss: 2.9272539615631104
Test Loss:  4.173705101013184
Test Acc:  0.0
Valid Loss:  3.7125847339630127
Valid Acc:  0.0
std:  0.04251854445333453 
thres:  0.0029874537944793705
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 24%|██▎       | 236/1000 [15:03<46:37,  3.66s/it]Epoch:   237
max of grad d_p:  tensor(2.3839, device='cuda:0')
min of grad d_p:  tensor(-16.9635, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1303, device='cuda:0') mean:  tensor(6.0167e-05, device='cuda:0') min:  tensor(-0.5216, device='cuda:0') norm:  tensor(1.1966, device='cuda:0') MSE:  tensor(4.4917e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0076, device='cuda:0') mean:  tensor(1.4580e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0223, device='cuda:0') MSE:  tensor(8.3686e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0068, device='cuda:0')
min of d_p_list:  tensor(-0.0119, device='cuda:0')
Epoch:  237  
Training Loss: 2.890838623046875
Test Loss:  4.111347675323486
Test Acc:  0.0
Valid Loss:  3.663088321685791
Valid Acc:  0.0
std:  0.04355385485577886 
thres:  0.0029557167053222656
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 24%|██▎       | 237/1000 [15:07<47:07,  3.71s/it]Epoch:   238
max of grad d_p:  tensor(2.3460, device='cuda:0')
min of grad d_p:  tensor(-16.8452, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1590, device='cuda:0') mean:  tensor(7.4096e-05, device='cuda:0') min:  tensor(-0.6287, device='cuda:0') norm:  tensor(1.3301, device='cuda:0') MSE:  tensor(4.9928e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0050, device='cuda:0') mean:  tensor(1.4548e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0203, device='cuda:0') MSE:  tensor(7.6355e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0159, device='cuda:0')
min of d_p_list:  tensor(-0.0088, device='cuda:0')
Epoch:  238  
Training Loss: 2.8605213165283203
Test Loss:  4.068904399871826
Test Acc:  0.0
Valid Loss:  3.6252331733703613
Valid Acc:  0.0
std:  0.04561249152196667 
thres:  0.0029249802589416504
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 24%|██▍       | 238/1000 [15:11<48:03,  3.78s/it]Epoch:   239
max of grad d_p:  tensor(2.3275, device='cuda:0')
min of grad d_p:  tensor(-16.7660, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1323, device='cuda:0') mean:  tensor(8.4436e-05, device='cuda:0') min:  tensor(-0.6551, device='cuda:0') norm:  tensor(1.3933, device='cuda:0') MSE:  tensor(5.2302e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0266, device='cuda:0') mean:  tensor(7.4080e-05, device='cuda:0') min:  tensor(1.4040e-11, device='cuda:0') norm:  tensor(0.1018, device='cuda:0') MSE:  tensor(3.8199e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0099, device='cuda:0')
min of d_p_list:  tensor(-0.0115, device='cuda:0')
Epoch:  239  
Training Loss: 2.829470634460449
Test Loss:  4.024786472320557
Test Acc:  0.0
Valid Loss:  3.589367628097534
Valid Acc:  0.0
std:  0.04591292824375947 
thres:  0.002893288326263428
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 24%|██▍       | 239/1000 [15:15<48:12,  3.80s/it]Epoch:   240
max of grad d_p:  tensor(2.2906, device='cuda:0')
min of grad d_p:  tensor(-16.6955, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1287, device='cuda:0') mean:  tensor(6.3883e-05, device='cuda:0') min:  tensor(-0.5470, device='cuda:0') norm:  tensor(1.2351, device='cuda:0') MSE:  tensor(4.6364e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0021, device='cuda:0') mean:  tensor(7.1852e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0106, device='cuda:0') MSE:  tensor(3.9804e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0116, device='cuda:0')
min of d_p_list:  tensor(-0.0124, device='cuda:0')
Epoch:  240  
Training Loss: 2.796727180480957
Test Loss:  3.9683361053466797
Test Acc:  0.0
Valid Loss:  3.5484166145324707
Valid Acc:  0.0
std:  0.045618525000470624 
thres:  0.0028609623432159425
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  34
 24%|██▍       | 240/1000 [15:19<48:24,  3.82s/it]Epoch:   241
max of grad d_p:  tensor(2.2565, device='cuda:0')
min of grad d_p:  tensor(-16.6005, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1683, device='cuda:0') mean:  tensor(9.4112e-05, device='cuda:0') min:  tensor(-0.7899, device='cuda:0') norm:  tensor(1.5792, device='cuda:0') MSE:  tensor(5.9279e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0309, device='cuda:0') mean:  tensor(5.7202e-05, device='cuda:0') min:  tensor(2.2084e-11, device='cuda:0') norm:  tensor(0.1014, device='cuda:0') MSE:  tensor(3.8065e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0154, device='cuda:0')
min of d_p_list:  tensor(-0.0141, device='cuda:0')
Epoch:  241  
Training Loss: 2.768090009689331
Test Loss:  3.9279279708862305
Test Acc:  0.0
Valid Loss:  3.510990619659424
Valid Acc:  0.0
std:  0.04374770410540107 
thres:  0.0028291295528411866
Preserved_eigens number check:  34
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 24%|██▍       | 241/1000 [15:22<47:40,  3.77s/it]Epoch:   242
max of grad d_p:  tensor(2.2380, device='cuda:0')
min of grad d_p:  tensor(-16.6544, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1265, device='cuda:0') mean:  tensor(4.5102e-05, device='cuda:0') min:  tensor(-0.4670, device='cuda:0') norm:  tensor(1.1041, device='cuda:0') MSE:  tensor(4.1444e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0024, device='cuda:0') mean:  tensor(9.7009e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0144, device='cuda:0') MSE:  tensor(5.3967e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0079, device='cuda:0')
min of d_p_list:  tensor(-0.0094, device='cuda:0')
Epoch:  242  
Training Loss: 2.7347750663757324
Test Loss:  3.871272325515747
Test Acc:  0.0
Valid Loss:  3.465677261352539
Valid Acc:  0.0
std:  0.04425584955417355 
thres:  0.0027979168415069584
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 24%|██▍       | 242/1000 [15:27<48:41,  3.85s/it]Epoch:   243
max of grad d_p:  tensor(2.2141, device='cuda:0')
min of grad d_p:  tensor(-16.6220, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1690, device='cuda:0') mean:  tensor(3.6174e-05, device='cuda:0') min:  tensor(-0.4457, device='cuda:0') norm:  tensor(1.0948, device='cuda:0') MSE:  tensor(4.1097e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1303, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(2.3283e-10, device='cuda:0') norm:  tensor(0.5359, device='cuda:0') MSE:  tensor(2.0116e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0452, device='cuda:0')
min of d_p_list:  tensor(-0.0339, device='cuda:0')
Epoch:  243  
Training Loss: 2.702709674835205
Test Loss:  3.8238048553466797
Test Acc:  0.0
Valid Loss:  3.4224579334259033
Valid Acc:  0.0
std:  0.044625290006890805 
thres:  0.002766354513168335
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 24%|██▍       | 243/1000 [15:30<48:11,  3.82s/it]Epoch:   244
max of grad d_p:  tensor(2.1509, device='cuda:0')
min of grad d_p:  tensor(-17.0511, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1390, device='cuda:0') mean:  tensor(5.1871e-05, device='cuda:0') min:  tensor(-0.5178, device='cuda:0') norm:  tensor(1.1826, device='cuda:0') MSE:  tensor(4.4393e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.1353, device='cuda:0') mean:  tensor(0.0011, device='cuda:0') min:  tensor(4.2201e-10, device='cuda:0') norm:  tensor(2.0829, device='cuda:0') MSE:  tensor(7.8185e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0136, device='cuda:0')
min of d_p_list:  tensor(-0.0139, device='cuda:0')
Epoch:  244  
Training Loss: 2.675525665283203
Test Loss:  3.7833352088928223
Test Acc:  0.0
Valid Loss:  3.3853960037231445
Valid Acc:  0.0
std:  0.04355113471582212 
thres:  0.002735565519332886
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 24%|██▍       | 244/1000 [15:34<48:19,  3.84s/it]Epoch:   245
max of grad d_p:  tensor(2.1301, device='cuda:0')
min of grad d_p:  tensor(-17.0267, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1222, device='cuda:0') mean:  tensor(6.5308e-05, device='cuda:0') min:  tensor(-0.5284, device='cuda:0') norm:  tensor(1.2272, device='cuda:0') MSE:  tensor(4.6067e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0125, device='cuda:0') mean:  tensor(2.9309e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0469, device='cuda:0') MSE:  tensor(1.7614e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0144, device='cuda:0')
min of d_p_list:  tensor(-0.0150, device='cuda:0')
Epoch:  245  
Training Loss: 2.6457395553588867
Test Loss:  3.7356905937194824
Test Acc:  0.0
Valid Loss:  3.344109535217285
Valid Acc:  0.0
std:  0.04301629713642155 
thres:  0.002705367994308472
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 24%|██▍       | 245/1000 [15:38<48:53,  3.89s/it]Epoch:   246
max of grad d_p:  tensor(2.1147, device='cuda:0')
min of grad d_p:  tensor(-16.7916, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1409, device='cuda:0') mean:  tensor(7.4933e-05, device='cuda:0') min:  tensor(-0.6226, device='cuda:0') norm:  tensor(1.3698, device='cuda:0') MSE:  tensor(5.1418e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0092, device='cuda:0') mean:  tensor(2.0452e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0330, device='cuda:0') MSE:  tensor(1.2391e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0562, device='cuda:0')
min of d_p_list:  tensor(-0.0407, device='cuda:0')
Epoch:  246  
Training Loss: 2.543858051300049
Test Loss:  3.614614486694336
Test Acc:  0.0
Valid Loss:  3.2578985691070557
Valid Acc:  0.0
std:  0.06534129680557806 
thres:  0.0026605216026306154
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 25%|██▍       | 246/1000 [15:42<49:43,  3.96s/it]Epoch:   247
max of grad d_p:  tensor(2.0588, device='cuda:0')
min of grad d_p:  tensor(-16.0615, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1376, device='cuda:0') mean:  tensor(7.6697e-05, device='cuda:0') min:  tensor(-0.5966, device='cuda:0') norm:  tensor(1.3149, device='cuda:0') MSE:  tensor(4.9356e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0060, device='cuda:0') mean:  tensor(1.7621e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0260, device='cuda:0') MSE:  tensor(9.7672e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0155, device='cuda:0')
min of d_p_list:  tensor(-0.0152, device='cuda:0')
Epoch:  247  
Training Loss: 2.513490915298462
Test Loss:  3.5642709732055664
Test Acc:  0.0
Valid Loss:  3.2178215980529785
Valid Acc:  0.0
std:  0.07437544806828872 
thres:  0.0026162647724151614
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 25%|██▍       | 247/1000 [15:46<49:28,  3.94s/it]Epoch:   248
max of grad d_p:  tensor(2.0219, device='cuda:0')
min of grad d_p:  tensor(-15.9416, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1215, device='cuda:0') mean:  tensor(5.0669e-05, device='cuda:0') min:  tensor(-0.4774, device='cuda:0') norm:  tensor(1.1154, device='cuda:0') MSE:  tensor(4.1870e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0127, device='cuda:0') mean:  tensor(2.1147e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0346, device='cuda:0') MSE:  tensor(1.2982e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0207, device='cuda:0')
min of d_p_list:  tensor(-0.0121, device='cuda:0')
Epoch:  248  
Training Loss: 2.48777174949646
Test Loss:  3.5250000953674316
Test Acc:  0.0
Valid Loss:  3.1849751472473145
Valid Acc:  0.0
std:  0.07410345445575896 
thres:  0.0025732771873474124
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 25%|██▍       | 248/1000 [15:50<49:13,  3.93s/it]Epoch:   249
max of grad d_p:  tensor(2.0271, device='cuda:0')
min of grad d_p:  tensor(-15.8223, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1261, device='cuda:0') mean:  tensor(5.9443e-05, device='cuda:0') min:  tensor(-0.5306, device='cuda:0') norm:  tensor(1.2053, device='cuda:0') MSE:  tensor(4.5244e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0024, device='cuda:0') mean:  tensor(6.8337e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0096, device='cuda:0') MSE:  tensor(3.5889e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0375, device='cuda:0')
min of d_p_list:  tensor(-0.0389, device='cuda:0')
Epoch:  249  
Training Loss: 2.3357455730438232
Test Loss:  3.302152633666992
Test Acc:  0.0
Valid Loss:  2.9796528816223145
Valid Acc:  0.0
std:  0.10033247146206095 
thres:  0.0025053211688995363
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 25%|██▍       | 249/1000 [15:54<49:36,  3.96s/it]Epoch:   250
max of grad d_p:  tensor(1.9896, device='cuda:0')
min of grad d_p:  tensor(-15.1968, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1750, device='cuda:0') mean:  tensor(5.1067e-05, device='cuda:0') min:  tensor(-0.5003, device='cuda:0') norm:  tensor(1.2338, device='cuda:0') MSE:  tensor(4.6314e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0027, device='cuda:0') mean:  tensor(7.4948e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0114, device='cuda:0') MSE:  tensor(4.2768e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0086, device='cuda:0')
min of d_p_list:  tensor(-0.0215, device='cuda:0')
Epoch:  250  
Training Loss: 2.3094542026519775
Test Loss:  3.2671303749084473
Test Acc:  0.0
Valid Loss:  2.9503321647644043
Valid Acc:  0.0
std:  0.09629330368261237 
thres:  0.0024380640983581543
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 25%|██▌       | 250/1000 [15:58<48:32,  3.88s/it]Epoch:   251
max of grad d_p:  tensor(1.9861, device='cuda:0')
min of grad d_p:  tensor(-15.0944, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0950, device='cuda:0') mean:  tensor(5.5139e-05, device='cuda:0') min:  tensor(-0.5759, device='cuda:0') norm:  tensor(1.1970, device='cuda:0') MSE:  tensor(4.4932e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0046, device='cuda:0') mean:  tensor(7.9301e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0120, device='cuda:0') MSE:  tensor(4.5231e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0147, device='cuda:0')
min of d_p_list:  tensor(-0.0135, device='cuda:0')
Epoch:  251  
Training Loss: 2.2848093509674072
Test Loss:  3.2345948219299316
Test Acc:  0.0
Valid Loss:  2.9211034774780273
Valid Acc:  0.0
std:  0.09511615316073584 
thres:  0.002386254358291626
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 25%|██▌       | 251/1000 [16:01<47:48,  3.83s/it]Epoch:   252
max of grad d_p:  tensor(1.9860, device='cuda:0')
min of grad d_p:  tensor(-14.9026, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1420, device='cuda:0') mean:  tensor(7.7351e-05, device='cuda:0') min:  tensor(-0.5865, device='cuda:0') norm:  tensor(1.3501, device='cuda:0') MSE:  tensor(5.0681e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0037, device='cuda:0') mean:  tensor(9.0905e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0136, device='cuda:0') MSE:  tensor(5.1157e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1514, device='cuda:0')
min of d_p_list:  tensor(-0.1138, device='cuda:0')
Epoch:  252  
Training Loss: 2.2297372817993164
Test Loss:  3.1638054847717285
Test Acc:  0.0
Valid Loss:  2.8806562423706055
Valid Acc:  0.0
std:  0.0865339723466281 
thres:  0.0023295036315917972
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 25%|██▌       | 252/1000 [16:05<47:19,  3.80s/it]Epoch:   253
max of grad d_p:  tensor(1.9301, device='cuda:0')
min of grad d_p:  tensor(-15.4038, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1145, device='cuda:0') mean:  tensor(4.9392e-05, device='cuda:0') min:  tensor(-0.4893, device='cuda:0') norm:  tensor(1.1081, device='cuda:0') MSE:  tensor(4.1593e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0156, device='cuda:0') mean:  tensor(3.0961e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0484, device='cuda:0') MSE:  tensor(1.8182e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0086, device='cuda:0')
min of d_p_list:  tensor(-0.0125, device='cuda:0')
Epoch:  253  
Training Loss: 2.207045078277588
Test Loss:  3.130356788635254
Test Acc:  0.0
Valid Loss:  2.850332260131836
Valid Acc:  0.0
std:  0.048221259208846616 
thres:  0.0022733582973480226
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 25%|██▌       | 253/1000 [16:09<47:39,  3.83s/it]Epoch:   254
max of grad d_p:  tensor(1.9084, device='cuda:0')
min of grad d_p:  tensor(-15.3475, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1302, device='cuda:0') mean:  tensor(2.9897e-05, device='cuda:0') min:  tensor(-0.4148, device='cuda:0') norm:  tensor(1.0586, device='cuda:0') MSE:  tensor(3.9738e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0051, device='cuda:0') mean:  tensor(7.8280e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0124, device='cuda:0') MSE:  tensor(4.6572e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0272, device='cuda:0')
min of d_p_list:  tensor(-0.0547, device='cuda:0')
Epoch:  254  
Training Loss: 2.1728110313415527
Test Loss:  3.083583116531372
Test Acc:  0.0
Valid Loss:  2.8051364421844482
Valid Acc:  0.0
std:  0.050068945974765675 
thres:  0.0022407713890075687
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 25%|██▌       | 254/1000 [16:13<47:53,  3.85s/it]Epoch:   255
max of grad d_p:  tensor(1.8453, device='cuda:0')
min of grad d_p:  tensor(-14.9705, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1288, device='cuda:0') mean:  tensor(4.8480e-05, device='cuda:0') min:  tensor(-0.5491, device='cuda:0') norm:  tensor(1.1881, device='cuda:0') MSE:  tensor(4.4600e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0049, device='cuda:0') mean:  tensor(4.9156e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0090, device='cuda:0') MSE:  tensor(3.3893e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0157, device='cuda:0')
min of d_p_list:  tensor(-0.0077, device='cuda:0')
Epoch:  255  
Training Loss: 2.1479270458221436
Test Loss:  3.0491719245910645
Test Acc:  0.0
Valid Loss:  2.7712321281433105
Valid Acc:  0.0
std:  0.047368840914327554 
thres:  0.0022084659576416016
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 26%|██▌       | 255/1000 [16:17<47:41,  3.84s/it]Epoch:   256
max of grad d_p:  tensor(1.8244, device='cuda:0')
min of grad d_p:  tensor(-14.8722, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1272, device='cuda:0') mean:  tensor(8.3403e-06, device='cuda:0') min:  tensor(-0.2482, device='cuda:0') norm:  tensor(0.9520, device='cuda:0') MSE:  tensor(3.5737e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0036, device='cuda:0') mean:  tensor(1.1290e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0168, device='cuda:0') MSE:  tensor(6.3025e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0171, device='cuda:0')
min of d_p_list:  tensor(-0.0072, device='cuda:0')
Epoch:  256  
Training Loss: 2.126377582550049
Test Loss:  3.0180459022521973
Test Acc:  0.0
Valid Loss:  2.743443489074707
Valid Acc:  0.0
std:  0.037707023270836026 
thres:  0.00217677960395813
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 26%|██▌       | 256/1000 [16:21<47:45,  3.85s/it]Epoch:   257
max of grad d_p:  tensor(1.8058, device='cuda:0')
min of grad d_p:  tensor(-14.7567, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1379, device='cuda:0') mean:  tensor(5.5938e-05, device='cuda:0') min:  tensor(-0.6025, device='cuda:0') norm:  tensor(1.2548, device='cuda:0') MSE:  tensor(4.7102e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1296, device='cuda:0') mean:  tensor(9.3464e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1979, device='cuda:0') MSE:  tensor(7.4270e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0160, device='cuda:0')
min of d_p_list:  tensor(-0.0076, device='cuda:0')
Epoch:  257  
Training Loss: 2.1028125286102295
Test Loss:  2.9851231575012207
Test Acc:  0.0
Valid Loss:  2.7118587493896484
Valid Acc:  0.0
std:  0.036204231847964397 
thres:  0.0021513946533203124
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 26%|██▌       | 257/1000 [16:25<48:43,  3.94s/it]Epoch:   258
max of grad d_p:  tensor(1.7949, device='cuda:0')
min of grad d_p:  tensor(-14.6685, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1580, device='cuda:0') mean:  tensor(7.0408e-05, device='cuda:0') min:  tensor(-0.7062, device='cuda:0') norm:  tensor(1.3890, device='cuda:0') MSE:  tensor(5.2140e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0043, device='cuda:0') mean:  tensor(4.5327e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0078, device='cuda:0') MSE:  tensor(2.9097e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0094, device='cuda:0')
min of d_p_list:  tensor(-0.0064, device='cuda:0')
Epoch:  258  
Training Loss: 2.0818018913269043
Test Loss:  2.954946994781494
Test Acc:  0.0
Valid Loss:  2.684474468231201
Valid Acc:  0.0
std:  0.0321332960243385 
thres:  0.002126346015930176
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 26%|██▌       | 258/1000 [16:29<47:59,  3.88s/it]Epoch:   259
max of grad d_p:  tensor(1.7816, device='cuda:0')
min of grad d_p:  tensor(-14.6446, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1308, device='cuda:0') mean:  tensor(4.1502e-05, device='cuda:0') min:  tensor(-0.5049, device='cuda:0') norm:  tensor(1.0862, device='cuda:0') MSE:  tensor(4.0772e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0103, device='cuda:0') mean:  tensor(2.6293e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0404, device='cuda:0') MSE:  tensor(1.5183e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2708, device='cuda:0')
min of d_p_list:  tensor(-0.3493, device='cuda:0')
Epoch:  259  
Training Loss: 2.2545533180236816
Test Loss:  3.2220468521118164
Test Acc:  0.0
Valid Loss:  2.940917491912842
Valid Acc:  0.0
std:  0.060173911179929374 
thres:  0.002142694473266602
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 26%|██▌       | 259/1000 [16:33<48:02,  3.89s/it]Epoch:   260
max of grad d_p:  tensor(1.9591, device='cuda:0')
min of grad d_p:  tensor(-18.3279, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1505, device='cuda:0') mean:  tensor(7.6032e-05, device='cuda:0') min:  tensor(-0.6867, device='cuda:0') norm:  tensor(1.5155, device='cuda:0') MSE:  tensor(5.6890e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0069, device='cuda:0') mean:  tensor(1.5499e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0229, device='cuda:0') MSE:  tensor(8.6020e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0365, device='cuda:0')
min of d_p_list:  tensor(-0.0090, device='cuda:0')
Epoch:  260  
Training Loss: 2.2306532859802246
Test Loss:  3.1888420581817627
Test Acc:  0.0
Valid Loss:  2.910942554473877
Valid Acc:  0.0
std:  0.06992159135739524 
thres:  0.002159239721298218
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 26%|██▌       | 260/1000 [16:36<47:58,  3.89s/it]Epoch:   261
max of grad d_p:  tensor(1.9267, device='cuda:0')
min of grad d_p:  tensor(-18.1359, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1136, device='cuda:0') mean:  tensor(5.4884e-05, device='cuda:0') min:  tensor(-0.5459, device='cuda:0') norm:  tensor(1.2446, device='cuda:0') MSE:  tensor(4.6719e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0171, device='cuda:0') mean:  tensor(3.4342e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0564, device='cuda:0') MSE:  tensor(2.1189e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0556, device='cuda:0')
min of d_p_list:  tensor(-0.0946, device='cuda:0')
Epoch:  261  
Training Loss: 2.181792736053467
Test Loss:  3.1194701194763184
Test Acc:  0.0
Valid Loss:  2.8409361839294434
Valid Acc:  0.0
std:  0.06820512466616852 
thres:  0.0021703227519989017
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 26%|██▌       | 261/1000 [16:40<47:57,  3.89s/it]Epoch:   262
max of grad d_p:  tensor(1.9167, device='cuda:0')
min of grad d_p:  tensor(-18.0203, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1192, device='cuda:0') mean:  tensor(3.7238e-05, device='cuda:0') min:  tensor(-0.4610, device='cuda:0') norm:  tensor(1.1002, device='cuda:0') MSE:  tensor(4.1299e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0160, device='cuda:0') mean:  tensor(2.4434e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0386, device='cuda:0') MSE:  tensor(1.4495e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0727, device='cuda:0')
min of d_p_list:  tensor(-0.1207, device='cuda:0')
Epoch:  262  
Training Loss: 2.235703706741333
Test Loss:  3.1882998943328857
Test Acc:  0.0
Valid Loss:  2.9155783653259277
Valid Acc:  0.0
std:  0.06236140006392885 
thres:  0.002196900987625122
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 26%|██▌       | 262/1000 [16:44<47:53,  3.89s/it]Epoch:   263
max of grad d_p:  tensor(1.8870, device='cuda:0')
min of grad d_p:  tensor(-19.0138, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1353, device='cuda:0') mean:  tensor(-1.2848e-05, device='cuda:0') min:  tensor(-0.3105, device='cuda:0') norm:  tensor(1.0438, device='cuda:0') MSE:  tensor(3.9182e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0115, device='cuda:0') mean:  tensor(1.2883e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0231, device='cuda:0') MSE:  tensor(8.6769e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0139, device='cuda:0')
min of d_p_list:  tensor(-0.0060, device='cuda:0')
Epoch:  263  
Training Loss: 2.2126455307006836
Test Loss:  3.1571106910705566
Test Acc:  0.0
Valid Loss:  2.8869972229003906
Valid Acc:  0.0
std:  0.02457965892661495 
thres:  0.002223069715499878
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 26%|██▋       | 263/1000 [16:48<47:46,  3.89s/it]Epoch:   264
max of grad d_p:  tensor(1.8707, device='cuda:0')
min of grad d_p:  tensor(-18.9023, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1329, device='cuda:0') mean:  tensor(7.9178e-06, device='cuda:0') min:  tensor(-0.4245, device='cuda:0') norm:  tensor(1.1265, device='cuda:0') MSE:  tensor(4.2288e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0061, device='cuda:0') mean:  tensor(5.3588e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0102, device='cuda:0') MSE:  tensor(3.8169e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0102, device='cuda:0')
min of d_p_list:  tensor(-0.0084, device='cuda:0')
Epoch:  264  
Training Loss: 2.1895861625671387
Test Loss:  3.122523546218872
Test Acc:  0.0
Valid Loss:  2.855679512023926
Valid Acc:  0.0
std:  0.02147828203671503 
thres:  0.0022100762844085697
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 26%|██▋       | 264/1000 [16:52<47:47,  3.90s/it]Epoch:   265
max of grad d_p:  tensor(1.8746, device='cuda:0')
min of grad d_p:  tensor(-18.8322, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1489, device='cuda:0') mean:  tensor(9.7083e-06, device='cuda:0') min:  tensor(-0.4420, device='cuda:0') norm:  tensor(1.1439, device='cuda:0') MSE:  tensor(4.2939e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0128, device='cuda:0') mean:  tensor(2.1727e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0340, device='cuda:0') MSE:  tensor(1.2764e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0046, device='cuda:0')
min of d_p_list:  tensor(-0.0055, device='cuda:0')
Epoch:  265  
Training Loss: 2.1669774055480957
Test Loss:  3.0906882286071777
Test Acc:  0.0
Valid Loss:  2.826697826385498
Valid Acc:  0.0
std:  0.024206444645308405 
thres:  0.0021973411083221436
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 26%|██▋       | 265/1000 [16:56<47:21,  3.87s/it]Epoch:   266
max of grad d_p:  tensor(1.8604, device='cuda:0')
min of grad d_p:  tensor(-18.7139, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1665, device='cuda:0') mean:  tensor(1.0660e-05, device='cuda:0') min:  tensor(-0.5252, device='cuda:0') norm:  tensor(1.3414, device='cuda:0') MSE:  tensor(5.0354e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0046, device='cuda:0') mean:  tensor(9.6945e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0144, device='cuda:0') MSE:  tensor(5.4186e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0619, device='cuda:0')
min of d_p_list:  tensor(-0.0344, device='cuda:0')
Epoch:  266  
Training Loss: 2.1484766006469727
Test Loss:  3.0619845390319824
Test Acc:  0.0
Valid Loss:  2.7958431243896484
Valid Acc:  0.0
std:  0.031156877463181732 
thres:  0.002190677881240845
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 27%|██▋       | 266/1000 [16:59<46:40,  3.82s/it]Epoch:   267
max of grad d_p:  tensor(1.8404, device='cuda:0')
min of grad d_p:  tensor(-18.1091, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1350, device='cuda:0') mean:  tensor(6.2414e-06, device='cuda:0') min:  tensor(-0.4381, device='cuda:0') norm:  tensor(1.1119, device='cuda:0') MSE:  tensor(4.1737e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0067, device='cuda:0') mean:  tensor(1.8256e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0262, device='cuda:0') MSE:  tensor(9.8411e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0075, device='cuda:0')
min of d_p_list:  tensor(-0.0064, device='cuda:0')
Epoch:  267  
Training Loss: 2.1234893798828125
Test Loss:  3.0260002613067627
Test Acc:  0.0
Valid Loss:  2.764017105102539
Valid Acc:  0.0
std:  0.031055800709543172 
thres:  0.0021682350158691408
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 27%|██▋       | 267/1000 [17:03<46:11,  3.78s/it]Epoch:   268
max of grad d_p:  tensor(1.8115, device='cuda:0')
min of grad d_p:  tensor(-18.0070, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1291, device='cuda:0') mean:  tensor(1.7641e-05, device='cuda:0') min:  tensor(-0.5444, device='cuda:0') norm:  tensor(1.2020, device='cuda:0') MSE:  tensor(4.5120e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0188, device='cuda:0') mean:  tensor(1.6068e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0306, device='cuda:0') MSE:  tensor(1.1479e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0073, device='cuda:0')
min of d_p_list:  tensor(-0.0082, device='cuda:0')
Epoch:  268  
Training Loss: 2.1021652221679688
Test Loss:  2.9954113960266113
Test Acc:  0.0
Valid Loss:  2.736097574234009
Valid Acc:  0.0
std:  0.030900025520928784 
thres:  0.0021461389541625976
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 27%|██▋       | 268/1000 [17:07<46:21,  3.80s/it]Epoch:   269
max of grad d_p:  tensor(1.7855, device='cuda:0')
min of grad d_p:  tensor(-17.8791, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1328, device='cuda:0') mean:  tensor(-8.5378e-06, device='cuda:0') min:  tensor(-0.3801, device='cuda:0') norm:  tensor(1.0834, device='cuda:0') MSE:  tensor(4.0669e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0034, device='cuda:0') mean:  tensor(7.4284e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0118, device='cuda:0') MSE:  tensor(4.4230e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1882, device='cuda:0')
min of d_p_list:  tensor(-0.2886, device='cuda:0')
Epoch:  269  
Training Loss: 2.1093430519104004
Test Loss:  2.989098310470581
Test Acc:  0.0
Valid Loss:  2.7610111236572266
Valid Acc:  0.0
std:  0.02430039106188202 
thres:  0.00213009033203125
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 27%|██▋       | 269/1000 [17:11<47:06,  3.87s/it]Epoch:   270
max of grad d_p:  tensor(1.7854, device='cuda:0')
min of grad d_p:  tensor(-18.1045, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1230, device='cuda:0') mean:  tensor(-4.9598e-06, device='cuda:0') min:  tensor(-0.4077, device='cuda:0') norm:  tensor(1.1117, device='cuda:0') MSE:  tensor(4.1729e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0059, device='cuda:0') mean:  tensor(1.5258e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0247, device='cuda:0') MSE:  tensor(9.2547e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0146, device='cuda:0')
min of d_p_list:  tensor(-0.0132, device='cuda:0')
Epoch:  270  
Training Loss: 2.0867302417755127
Test Loss:  2.954425811767578
Test Acc:  0.0
Valid Loss:  2.729766607284546
Valid Acc:  0.0
std:  0.0209000708345294 
thres:  0.002114040899276733
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 27%|██▋       | 270/1000 [17:15<45:36,  3.75s/it]Epoch:   271
max of grad d_p:  tensor(1.7763, device='cuda:0')
min of grad d_p:  tensor(-18.0980, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1471, device='cuda:0') mean:  tensor(-3.1404e-06, device='cuda:0') min:  tensor(-0.4335, device='cuda:0') norm:  tensor(1.2353, device='cuda:0') MSE:  tensor(4.6368e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0020, device='cuda:0') mean:  tensor(5.6317e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0083, device='cuda:0') MSE:  tensor(3.1097e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0125, device='cuda:0')
min of d_p_list:  tensor(-0.0104, device='cuda:0')
Epoch:  271  
Training Loss: 2.0650978088378906
Test Loss:  2.9227135181427
Test Acc:  0.0
Valid Loss:  2.701748847961426
Valid Acc:  0.0
std:  0.020016337290212353 
thres:  0.0020973651409149172
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 27%|██▋       | 271/1000 [17:18<45:16,  3.73s/it]Epoch:   272
max of grad d_p:  tensor(1.7614, device='cuda:0')
min of grad d_p:  tensor(-18.0067, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1501, device='cuda:0') mean:  tensor(-7.1576e-06, device='cuda:0') min:  tensor(-0.4126, device='cuda:0') norm:  tensor(1.2597, device='cuda:0') MSE:  tensor(4.7285e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0113, device='cuda:0') mean:  tensor(1.5237e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0255, device='cuda:0') MSE:  tensor(9.5757e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0283, device='cuda:0')
min of d_p_list:  tensor(-0.0248, device='cuda:0')
Epoch:  272  
Training Loss: 2.043747901916504
Test Loss:  2.890895128250122
Test Acc:  0.0
Valid Loss:  2.6724624633789062
Valid Acc:  0.0
std:  0.024182061893431302 
thres:  0.002081416845321655
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 27%|██▋       | 272/1000 [17:22<45:21,  3.74s/it]Epoch:   273
max of grad d_p:  tensor(1.7542, device='cuda:0')
min of grad d_p:  tensor(-17.8824, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1408, device='cuda:0') mean:  tensor(4.2463e-06, device='cuda:0') min:  tensor(-0.4848, device='cuda:0') norm:  tensor(1.2391, device='cuda:0') MSE:  tensor(4.6513e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0362, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(8.4071e-11, device='cuda:0') norm:  tensor(0.1718, device='cuda:0') MSE:  tensor(6.4481e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(1.8979, device='cuda:0')
min of d_p_list:  tensor(-2.1858, device='cuda:0')
Epoch:  273  
Training Loss: 31.055484771728516
Test Loss:  33.10867691040039
Test Acc:  0.0
Valid Loss:  29.21343231201172
Valid Acc:  0.0
std:  11.591722589690379 
thres:  0.007872080755233764
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 27%|██▋       | 273/1000 [17:26<46:06,  3.80s/it]Epoch:   274
max of grad d_p:  tensor(95.2756, device='cuda:0')
min of grad d_p:  tensor(-6.9331, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2260, device='cuda:0') mean:  tensor(-5.9672e-05, device='cuda:0') min:  tensor(-0.3396, device='cuda:0') norm:  tensor(1.4309, device='cuda:0') MSE:  tensor(5.3714e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0138, device='cuda:0') mean:  tensor(4.4269e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0688, device='cuda:0') MSE:  tensor(2.5839e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0281, device='cuda:0')
min of d_p_list:  tensor(-0.0238, device='cuda:0')
Epoch:  274  
Training Loss: 30.70508575439453
Test Loss:  32.74598693847656
Test Acc:  0.0
Valid Loss:  28.87433433532715
Valid Acc:  0.0
std:  14.11689650238148 
thres:  0.013591229295730591
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 27%|██▋       | 274/1000 [17:30<45:49,  3.79s/it]Epoch:   275
max of grad d_p:  tensor(94.6626, device='cuda:0')
min of grad d_p:  tensor(-6.7901, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2677, device='cuda:0') mean:  tensor(-5.9433e-05, device='cuda:0') min:  tensor(-0.3425, device='cuda:0') norm:  tensor(1.4990, device='cuda:0') MSE:  tensor(5.6267e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0287, device='cuda:0') mean:  tensor(7.2653e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1119, device='cuda:0') MSE:  tensor(4.1995e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1376, device='cuda:0')
min of d_p_list:  tensor(-0.2161, device='cuda:0')
Epoch:  275  
Training Loss: 30.387619018554688
Test Loss:  32.374351501464844
Test Acc:  0.0
Valid Loss:  28.543275833129883
Valid Acc:  0.0
std:  14.042869951845061 
thres:  0.019251407051086425
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 28%|██▊       | 275/1000 [17:33<45:35,  3.77s/it]Epoch:   276
max of grad d_p:  tensor(94.7818, device='cuda:0')
min of grad d_p:  tensor(-6.5331, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2599, device='cuda:0') mean:  tensor(-4.6412e-05, device='cuda:0') min:  tensor(-0.2521, device='cuda:0') norm:  tensor(1.3820, device='cuda:0') MSE:  tensor(5.1877e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0125, device='cuda:0') mean:  tensor(4.2310e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0655, device='cuda:0') MSE:  tensor(2.4604e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0362, device='cuda:0')
min of d_p_list:  tensor(-0.0276, device='cuda:0')
Epoch:  276  
Training Loss: 30.087329864501953
Test Loss:  32.05826950073242
Test Acc:  0.0
Valid Loss:  28.262161254882812
Valid Acc:  0.0
std:  11.410608067881125 
thres:  0.024855853462219236
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 28%|██▊       | 276/1000 [17:37<45:19,  3.76s/it]Epoch:   277
max of grad d_p:  tensor(94.4029, device='cuda:0')
min of grad d_p:  tensor(-6.4873, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2569, device='cuda:0') mean:  tensor(-5.9849e-05, device='cuda:0') min:  tensor(-0.3009, device='cuda:0') norm:  tensor(1.5269, device='cuda:0') MSE:  tensor(5.7315e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0239, device='cuda:0') mean:  tensor(5.7177e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0917, device='cuda:0') MSE:  tensor(3.4426e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.3605, device='cuda:0')
min of d_p_list:  tensor(-0.7110, device='cuda:0')
Epoch:  277  
Training Loss: 31.768653869628906
Test Loss:  34.03495788574219
Test Acc:  0.0
Valid Loss:  29.920883178710938
Valid Acc:  0.0
std:  0.5814679379619279 
thres:  0.03080083465576172
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 28%|██▊       | 277/1000 [17:41<45:14,  3.75s/it]Epoch:   278
max of grad d_p:  tensor(98.0569, device='cuda:0')
min of grad d_p:  tensor(-8.4201, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2971, device='cuda:0') mean:  tensor(-6.3910e-05, device='cuda:0') min:  tensor(-0.3810, device='cuda:0') norm:  tensor(1.3507, device='cuda:0') MSE:  tensor(5.0700e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0091, device='cuda:0') mean:  tensor(1.4998e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0247, device='cuda:0') MSE:  tensor(9.2892e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1372, device='cuda:0')
min of d_p_list:  tensor(-0.3322, device='cuda:0')
Epoch:  278  
Training Loss: 30.52758026123047
Test Loss:  32.7838249206543
Test Acc:  0.0
Valid Loss:  28.7291259765625
Valid Acc:  0.0
std:  0.5735171248561602 
thres:  0.030695253753662107
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 28%|██▊       | 278/1000 [17:45<46:09,  3.84s/it]Epoch:   279
max of grad d_p:  tensor(91.6495, device='cuda:0')
min of grad d_p:  tensor(-9.4470, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2698, device='cuda:0') mean:  tensor(-7.3770e-05, device='cuda:0') min:  tensor(-0.3042, device='cuda:0') norm:  tensor(1.2347, device='cuda:0') MSE:  tensor(4.6348e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0073, device='cuda:0') mean:  tensor(1.3288e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0232, device='cuda:0') MSE:  tensor(8.7167e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0346, device='cuda:0')
min of d_p_list:  tensor(-0.0292, device='cuda:0')
Epoch:  279  
Training Loss: 30.221546173095703
Test Loss:  32.44721984863281
Test Acc:  0.0
Valid Loss:  28.43301773071289
Valid Acc:  0.0
std:  0.603680306259452 
thres:  0.030598545837402347
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 28%|██▊       | 279/1000 [17:49<46:01,  3.83s/it]Epoch:   280
max of grad d_p:  tensor(91.3976, device='cuda:0')
min of grad d_p:  tensor(-9.3707, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3193, device='cuda:0') mean:  tensor(-8.5359e-05, device='cuda:0') min:  tensor(-0.3344, device='cuda:0') norm:  tensor(1.4896, device='cuda:0') MSE:  tensor(5.5916e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0056, device='cuda:0') mean:  tensor(1.5614e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0251, device='cuda:0') MSE:  tensor(9.4336e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0216, device='cuda:0')
min of d_p_list:  tensor(-0.0293, device='cuda:0')
Epoch:  280  
Training Loss: 29.91329574584961
Test Loss:  32.11741638183594
Test Acc:  0.0
Valid Loss:  28.14569854736328
Valid Acc:  0.0
std:  0.6636611503599464 
thres:  0.030503681182861328
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  33
 28%|██▊       | 280/1000 [17:52<45:22,  3.78s/it]Epoch:   281
max of grad d_p:  tensor(91.9800, device='cuda:0')
min of grad d_p:  tensor(-9.4607, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2490, device='cuda:0') mean:  tensor(-7.7343e-05, device='cuda:0') min:  tensor(-0.2697, device='cuda:0') norm:  tensor(1.2104, device='cuda:0') MSE:  tensor(4.5436e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0066, device='cuda:0') mean:  tensor(1.4999e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0250, device='cuda:0') MSE:  tensor(9.3830e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0153, device='cuda:0')
min of d_p_list:  tensor(-0.0085, device='cuda:0')
Epoch:  281  
Training Loss: 29.609264373779297
Test Loss:  31.776962280273438
Test Acc:  0.0
Valid Loss:  27.850439071655273
Valid Acc:  0.0
std:  0.7460769796569722 
thres:  0.030408068084716796
Preserved_eigens number check:  33
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 28%|██▊       | 281/1000 [17:56<45:21,  3.79s/it]Epoch:   282
max of grad d_p:  tensor(91.0873, device='cuda:0')
min of grad d_p:  tensor(-9.4914, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2830, device='cuda:0') mean:  tensor(-5.0871e-05, device='cuda:0') min:  tensor(-0.2700, device='cuda:0') norm:  tensor(1.2750, device='cuda:0') MSE:  tensor(4.7861e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0101, device='cuda:0') mean:  tensor(2.5297e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0422, device='cuda:0') MSE:  tensor(1.5855e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0648, device='cuda:0')
min of d_p_list:  tensor(-0.0360, device='cuda:0')
Epoch:  282  
Training Loss: 29.312829971313477
Test Loss:  31.4617977142334
Test Acc:  0.0
Valid Loss:  27.57227325439453
Valid Acc:  0.0
std:  0.43018436533869425 
thres:  0.029916903305053713
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 28%|██▊       | 282/1000 [18:00<45:41,  3.82s/it]Epoch:   283
max of grad d_p:  tensor(90.3653, device='cuda:0')
min of grad d_p:  tensor(-9.3221, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2650, device='cuda:0') mean:  tensor(-6.5256e-05, device='cuda:0') min:  tensor(-0.3457, device='cuda:0') norm:  tensor(1.2015, device='cuda:0') MSE:  tensor(4.5103e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0189, device='cuda:0') mean:  tensor(4.2616e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0667, device='cuda:0') MSE:  tensor(2.5049e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0200, device='cuda:0')
min of d_p_list:  tensor(-0.0234, device='cuda:0')
Epoch:  283  
Training Loss: 29.015697479248047
Test Loss:  31.141027450561523
Test Acc:  0.0
Valid Loss:  27.290237426757812
Valid Acc:  0.0
std:  0.42600014724857865 
thres:  0.02961452674865723
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 28%|██▊       | 283/1000 [18:04<45:30,  3.81s/it]Epoch:   284
max of grad d_p:  tensor(89.9112, device='cuda:0')
min of grad d_p:  tensor(-9.2131, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2851, device='cuda:0') mean:  tensor(-5.8170e-05, device='cuda:0') min:  tensor(-0.2831, device='cuda:0') norm:  tensor(1.2543, device='cuda:0') MSE:  tensor(4.7083e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0051, device='cuda:0') mean:  tensor(1.5157e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0239, device='cuda:0') MSE:  tensor(8.9886e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1515, device='cuda:0')
min of d_p_list:  tensor(-0.1008, device='cuda:0')
Epoch:  284  
Training Loss: 28.638957977294922
Test Loss:  30.699535369873047
Test Acc:  0.0
Valid Loss:  26.917646408081055
Valid Acc:  0.0
std:  0.4449101917900277 
thres:  0.02929800910949707
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 28%|██▊       | 284/1000 [18:07<44:08,  3.70s/it]Epoch:   285
max of grad d_p:  tensor(92.1175, device='cuda:0')
min of grad d_p:  tensor(-9.1590, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2718, device='cuda:0') mean:  tensor(-7.2740e-05, device='cuda:0') min:  tensor(-0.3962, device='cuda:0') norm:  tensor(1.3827, device='cuda:0') MSE:  tensor(5.1904e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0116, device='cuda:0') mean:  tensor(2.5235e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0455, device='cuda:0') MSE:  tensor(1.7067e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0374, device='cuda:0')
min of d_p_list:  tensor(-0.0351, device='cuda:0')
Epoch:  285  
Training Loss: 28.316736221313477
Test Loss:  30.407123565673828
Test Acc:  0.0
Valid Loss:  26.690914154052734
Valid Acc:  0.0
std:  0.46135534394345923 
thres:  0.028978697204589843
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 28%|██▊       | 285/1000 [18:11<44:45,  3.76s/it]Epoch:   286
max of grad d_p:  tensor(92.1623, device='cuda:0')
min of grad d_p:  tensor(-8.6752, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2665, device='cuda:0') mean:  tensor(-7.6721e-05, device='cuda:0') min:  tensor(-0.3205, device='cuda:0') norm:  tensor(1.3108, device='cuda:0') MSE:  tensor(4.9204e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0082, device='cuda:0') mean:  tensor(1.4930e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0260, device='cuda:0') MSE:  tensor(9.7736e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0422, device='cuda:0')
min of d_p_list:  tensor(-0.0502, device='cuda:0')
Epoch:  286  
Training Loss: 28.026779174804688
Test Loss:  30.073854446411133
Test Acc:  0.0
Valid Loss:  26.40161895751953
Valid Acc:  0.0
std:  0.4630172494630517 
thres:  0.028662200164794923
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 29%|██▊       | 286/1000 [18:15<45:11,  3.80s/it]Epoch:   287
max of grad d_p:  tensor(91.4932, device='cuda:0')
min of grad d_p:  tensor(-8.6235, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3149, device='cuda:0') mean:  tensor(-5.1476e-05, device='cuda:0') min:  tensor(-0.4035, device='cuda:0') norm:  tensor(1.4002, device='cuda:0') MSE:  tensor(5.2559e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0086, device='cuda:0') mean:  tensor(1.5084e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0263, device='cuda:0') MSE:  tensor(9.8875e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0373, device='cuda:0')
min of d_p_list:  tensor(-0.0384, device='cuda:0')
Epoch:  287  
Training Loss: 27.71641731262207
Test Loss:  29.73965072631836
Test Acc:  0.0
Valid Loss:  26.10834503173828
Valid Acc:  0.0
std:  0.4546216557687191 
thres:  0.02834291763305664
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 29%|██▊       | 287/1000 [18:19<45:18,  3.81s/it]Epoch:   288
max of grad d_p:  tensor(93.8791, device='cuda:0')
min of grad d_p:  tensor(-8.9137, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2739, device='cuda:0') mean:  tensor(-7.4187e-05, device='cuda:0') min:  tensor(-0.3612, device='cuda:0') norm:  tensor(1.3160, device='cuda:0') MSE:  tensor(4.9398e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0091, device='cuda:0') mean:  tensor(2.8902e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0458, device='cuda:0') MSE:  tensor(1.7180e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0417, device='cuda:0')
min of d_p_list:  tensor(-0.0509, device='cuda:0')
Epoch:  288  
Training Loss: 27.419845581054688
Test Loss:  29.426698684692383
Test Acc:  0.0
Valid Loss:  25.832881927490234
Valid Acc:  0.0
std:  0.4297638619106435 
thres:  0.02802374725341797
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 29%|██▉       | 288/1000 [18:23<44:42,  3.77s/it]Epoch:   289
max of grad d_p:  tensor(95.7751, device='cuda:0')
min of grad d_p:  tensor(-9.0948, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2700, device='cuda:0') mean:  tensor(-4.9632e-05, device='cuda:0') min:  tensor(-0.2702, device='cuda:0') norm:  tensor(1.2372, device='cuda:0') MSE:  tensor(4.6442e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0039, device='cuda:0') mean:  tensor(1.1426e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0173, device='cuda:0') MSE:  tensor(6.4831e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2982, device='cuda:0')
min of d_p_list:  tensor(-0.2607, device='cuda:0')
Epoch:  289  
Training Loss: 24.950685501098633
Test Loss:  26.95455551147461
Test Acc:  0.0
Valid Loss:  23.777164459228516
Valid Acc:  0.0
std:  1.2056565358412084 
thres:  0.027286092758178712
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 29%|██▉       | 289/1000 [18:26<44:18,  3.74s/it]Epoch:   290
max of grad d_p:  tensor(99.5983, device='cuda:0')
min of grad d_p:  tensor(-7.1765, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2550, device='cuda:0') mean:  tensor(-6.4454e-05, device='cuda:0') min:  tensor(-0.3364, device='cuda:0') norm:  tensor(1.2755, device='cuda:0') MSE:  tensor(4.7881e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0046, device='cuda:0') mean:  tensor(1.4129e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0222, device='cuda:0') MSE:  tensor(8.3240e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0563, device='cuda:0')
min of d_p_list:  tensor(-0.0260, device='cuda:0')
Epoch:  290  
Training Loss: 24.6971492767334
Test Loss:  26.647811889648438
Test Acc:  0.0
Valid Loss:  23.515369415283203
Valid Acc:  0.0
std:  1.434444762563129 
thres:  0.026562175369262697
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  36
 29%|██▉       | 290/1000 [18:30<44:23,  3.75s/it]Epoch:   291
max of grad d_p:  tensor(99.1957, device='cuda:0')
min of grad d_p:  tensor(-7.0891, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2467, device='cuda:0') mean:  tensor(-6.7017e-05, device='cuda:0') min:  tensor(-0.3765, device='cuda:0') norm:  tensor(1.2722, device='cuda:0') MSE:  tensor(4.7756e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0048, device='cuda:0') mean:  tensor(1.1798e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0196, device='cuda:0') MSE:  tensor(7.3607e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0508, device='cuda:0')
min of d_p_list:  tensor(-0.0407, device='cuda:0')
Epoch:  291  
Training Loss: 24.457000732421875
Test Loss:  26.3730525970459
Test Acc:  0.0
Valid Loss:  23.274391174316406
Valid Acc:  0.0
std:  1.4160643490373974 
thres:  0.025848219680786134
Preserved_eigens number check:  36
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 29%|██▉       | 291/1000 [18:34<45:14,  3.83s/it]Epoch:   292
max of grad d_p:  tensor(98.7393, device='cuda:0')
min of grad d_p:  tensor(-7.3311, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2445, device='cuda:0') mean:  tensor(-4.2461e-05, device='cuda:0') min:  tensor(-0.2950, device='cuda:0') norm:  tensor(1.1414, device='cuda:0') MSE:  tensor(4.2844e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0164, device='cuda:0') mean:  tensor(4.0984e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0655, device='cuda:0') MSE:  tensor(2.4580e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0135, device='cuda:0')
min of d_p_list:  tensor(-0.0120, device='cuda:0')
Epoch:  292  
Training Loss: 24.20935821533203
Test Loss:  26.084087371826172
Test Acc:  0.0
Valid Loss:  23.032413482666016
Valid Acc:  0.0
std:  1.1629275998143251 
thres:  0.025146807861328124
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 29%|██▉       | 292/1000 [18:38<44:08,  3.74s/it]Epoch:   293
max of grad d_p:  tensor(98.3731, device='cuda:0')
min of grad d_p:  tensor(-7.3545, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2680, device='cuda:0') mean:  tensor(-7.6887e-05, device='cuda:0') min:  tensor(-0.5381, device='cuda:0') norm:  tensor(1.4664, device='cuda:0') MSE:  tensor(5.5044e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0082, device='cuda:0') mean:  tensor(2.6262e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0435, device='cuda:0') MSE:  tensor(1.6347e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0351, device='cuda:0')
min of d_p_list:  tensor(-0.0349, device='cuda:0')
Epoch:  293  
Training Loss: 23.95462417602539
Test Loss:  25.784896850585938
Test Acc:  0.0
Valid Loss:  22.778396606445312
Valid Acc:  0.0
std:  0.3507285557456567 
thres:  0.024453763580322266
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 29%|██▉       | 293/1000 [18:41<43:47,  3.72s/it]Epoch:   294
max of grad d_p:  tensor(97.7119, device='cuda:0')
min of grad d_p:  tensor(-7.3103, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2276, device='cuda:0') mean:  tensor(-4.9278e-05, device='cuda:0') min:  tensor(-0.2636, device='cuda:0') norm:  tensor(1.1285, device='cuda:0') MSE:  tensor(4.2360e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0147, device='cuda:0') mean:  tensor(3.4599e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0547, device='cuda:0') MSE:  tensor(2.0523e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0267, device='cuda:0')
min of d_p_list:  tensor(-0.0158, device='cuda:0')
Epoch:  294  
Training Loss: 23.667570114135742
Test Loss:  25.549144744873047
Test Acc:  0.0
Valid Loss:  22.588289260864258
Valid Acc:  0.0
std:  0.3624760270007636 
thres:  0.02419714050292969
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  34
 29%|██▉       | 294/1000 [18:45<43:58,  3.74s/it]Epoch:   295
max of grad d_p:  tensor(97.0806, device='cuda:0')
min of grad d_p:  tensor(-6.9895, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2952, device='cuda:0') mean:  tensor(-3.7914e-05, device='cuda:0') min:  tensor(-0.3596, device='cuda:0') norm:  tensor(1.2651, device='cuda:0') MSE:  tensor(4.7490e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0136, device='cuda:0') mean:  tensor(4.6089e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0702, device='cuda:0') MSE:  tensor(2.6349e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0317, device='cuda:0')
min of d_p_list:  tensor(-0.0369, device='cuda:0')
Epoch:  295  
Training Loss: 23.431081771850586
Test Loss:  25.296884536743164
Test Acc:  0.0
Valid Loss:  22.362014770507812
Valid Acc:  0.0
std:  0.3669321929046526 
thres:  0.023943927001953125
Preserved_eigens number check:  34
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 30%|██▉       | 295/1000 [18:49<44:22,  3.78s/it]Epoch:   296
max of grad d_p:  tensor(96.9326, device='cuda:0')
min of grad d_p:  tensor(-7.1003, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2562, device='cuda:0') mean:  tensor(-7.3303e-05, device='cuda:0') min:  tensor(-0.5069, device='cuda:0') norm:  tensor(1.4320, device='cuda:0') MSE:  tensor(5.3753e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0340, device='cuda:0') mean:  tensor(6.0521e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1112, device='cuda:0') MSE:  tensor(4.1749e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0163, device='cuda:0')
min of d_p_list:  tensor(-0.0136, device='cuda:0')
Epoch:  296  
Training Loss: 23.195802688598633
Test Loss:  25.038467407226562
Test Acc:  0.0
Valid Loss:  22.13467788696289
Valid Acc:  0.0
std:  0.3609757346790453 
thres:  0.023691687393188478
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 30%|██▉       | 296/1000 [18:53<44:40,  3.81s/it]Epoch:   297
max of grad d_p:  tensor(96.5676, device='cuda:0')
min of grad d_p:  tensor(-7.0211, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2504, device='cuda:0') mean:  tensor(-5.9801e-05, device='cuda:0') min:  tensor(-0.3329, device='cuda:0') norm:  tensor(1.2581, device='cuda:0') MSE:  tensor(4.7226e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0035, device='cuda:0') mean:  tensor(1.2286e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0184, device='cuda:0') MSE:  tensor(6.8994e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2439, device='cuda:0')
min of d_p_list:  tensor(-0.1391, device='cuda:0')
Epoch:  297  
Training Loss: 22.946815490722656
Test Loss:  24.616535186767578
Test Acc:  0.0
Valid Loss:  21.77886962890625
Valid Acc:  0.0
std:  0.35201296846191227 
thres:  0.0234391788482666
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 30%|██▉       | 297/1000 [18:57<44:53,  3.83s/it]Epoch:   298
max of grad d_p:  tensor(96.6287, device='cuda:0')
min of grad d_p:  tensor(-7.3725, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1780, device='cuda:0') mean:  tensor(-8.5332e-05, device='cuda:0') min:  tensor(-0.3478, device='cuda:0') norm:  tensor(1.2559, device='cuda:0') MSE:  tensor(4.7142e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0669, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.2021, device='cuda:0') MSE:  tensor(7.5859e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0322, device='cuda:0')
min of d_p_list:  tensor(-0.0254, device='cuda:0')
Epoch:  298  
Training Loss: 22.71750259399414
Test Loss:  24.35504913330078
Test Acc:  0.0
Valid Loss:  21.55539321899414
Valid Acc:  0.0
std:  0.33722527134059804 
thres:  0.023191754531860353
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 30%|██▉       | 298/1000 [19:00<43:49,  3.75s/it]Epoch:   299
max of grad d_p:  tensor(95.9248, device='cuda:0')
min of grad d_p:  tensor(-7.4003, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2300, device='cuda:0') mean:  tensor(-5.5810e-05, device='cuda:0') min:  tensor(-0.3253, device='cuda:0') norm:  tensor(1.2218, device='cuda:0') MSE:  tensor(4.5863e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0093, device='cuda:0') mean:  tensor(1.6193e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0292, device='cuda:0') MSE:  tensor(1.0957e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0151, device='cuda:0')
min of d_p_list:  tensor(-0.0120, device='cuda:0')
Epoch:  299  
Training Loss: 22.491708755493164
Test Loss:  24.114051818847656
Test Acc:  0.0
Valid Loss:  21.344614028930664
Valid Acc:  0.0
std:  0.3333880777344671 
thres:  0.022956582260131836
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 30%|██▉       | 299/1000 [19:04<44:38,  3.82s/it]Epoch:   300
max of grad d_p:  tensor(95.2809, device='cuda:0')
min of grad d_p:  tensor(-7.3332, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2333, device='cuda:0') mean:  tensor(-4.5764e-05, device='cuda:0') min:  tensor(-0.2729, device='cuda:0') norm:  tensor(1.1416, device='cuda:0') MSE:  tensor(4.2851e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0074, device='cuda:0') mean:  tensor(2.3695e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0355, device='cuda:0') MSE:  tensor(1.3308e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0223, device='cuda:0')
min of d_p_list:  tensor(-0.0166, device='cuda:0')
Epoch:  300  
Training Loss: 22.265113830566406
Test Loss:  23.865711212158203
Test Acc:  0.0
Valid Loss:  21.135480880737305
Valid Acc:  0.0
std:  0.32766464756554714 
thres:  0.022723388671875
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 30%|███       | 300/1000 [19:08<44:22,  3.80s/it]Epoch:   301
max of grad d_p:  tensor(94.8277, device='cuda:0')
min of grad d_p:  tensor(-7.3277, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2154, device='cuda:0') mean:  tensor(-7.5356e-05, device='cuda:0') min:  tensor(-0.4047, device='cuda:0') norm:  tensor(1.3220, device='cuda:0') MSE:  tensor(4.9624e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0043, device='cuda:0') mean:  tensor(1.0381e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0169, device='cuda:0') MSE:  tensor(6.3375e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0416, device='cuda:0')
min of d_p_list:  tensor(-0.0271, device='cuda:0')
Epoch:  301  
Training Loss: 22.03496551513672
Test Loss:  23.607505798339844
Test Acc:  0.0
Valid Loss:  20.91561508178711
Valid Acc:  0.0
std:  0.32188925337749474 
thres:  0.02249122123718262
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 30%|███       | 301/1000 [19:12<44:36,  3.83s/it]Epoch:   302
max of grad d_p:  tensor(94.4085, device='cuda:0')
min of grad d_p:  tensor(-7.3525, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2283, device='cuda:0') mean:  tensor(-7.1111e-05, device='cuda:0') min:  tensor(-0.3538, device='cuda:0') norm:  tensor(1.3029, device='cuda:0') MSE:  tensor(4.8908e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0042, device='cuda:0') mean:  tensor(1.0071e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0169, device='cuda:0') MSE:  tensor(6.3533e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1275, device='cuda:0')
min of d_p_list:  tensor(-0.1047, device='cuda:0')
Epoch:  302  
Training Loss: 21.850997924804688
Test Loss:  23.43756675720215
Test Acc:  0.0
Valid Loss:  20.799915313720703
Valid Acc:  0.0
std:  0.3099096628045636 
thres:  0.022272057723999022
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 30%|███       | 302/1000 [19:15<43:42,  3.76s/it]Epoch:   303
max of grad d_p:  tensor(95.5068, device='cuda:0')
min of grad d_p:  tensor(-7.5602, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2387, device='cuda:0') mean:  tensor(-7.0028e-05, device='cuda:0') min:  tensor(-0.3391, device='cuda:0') norm:  tensor(1.3040, device='cuda:0') MSE:  tensor(4.8950e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0028, device='cuda:0') mean:  tensor(1.0807e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0164, device='cuda:0') MSE:  tensor(6.1743e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1036, device='cuda:0')
min of d_p_list:  tensor(-0.1806, device='cuda:0')
Epoch:  303  
Training Loss: 21.743873596191406
Test Loss:  23.316280364990234
Test Acc:  0.0
Valid Loss:  20.697494506835938
Valid Acc:  0.0
std:  0.27246528259161634 
thres:  0.022077331924438476
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 30%|███       | 303/1000 [19:19<44:33,  3.84s/it]Epoch:   304
max of grad d_p:  tensor(94.0959, device='cuda:0')
min of grad d_p:  tensor(-7.9078, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2390, device='cuda:0') mean:  tensor(-7.9980e-05, device='cuda:0') min:  tensor(-0.4026, device='cuda:0') norm:  tensor(1.3370, device='cuda:0') MSE:  tensor(5.0189e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0040, device='cuda:0') mean:  tensor(1.2086e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0182, device='cuda:0') MSE:  tensor(6.8189e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0373, device='cuda:0')
min of d_p_list:  tensor(-0.0287, device='cuda:0')
Epoch:  304  
Training Loss: 21.520709991455078
Test Loss:  23.0710391998291
Test Acc:  0.0
Valid Loss:  20.480693817138672
Valid Acc:  0.0
std:  0.2532740607718044 
thres:  0.02188313217163086
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 30%|███       | 304/1000 [19:23<44:09,  3.81s/it]Epoch:   305
max of grad d_p:  tensor(93.4527, device='cuda:0')
min of grad d_p:  tensor(-7.8019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2778, device='cuda:0') mean:  tensor(-5.5068e-05, device='cuda:0') min:  tensor(-0.3444, device='cuda:0') norm:  tensor(1.3034, device='cuda:0') MSE:  tensor(4.8926e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0131, device='cuda:0') mean:  tensor(3.0923e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0516, device='cuda:0') MSE:  tensor(1.9383e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1630, device='cuda:0')
min of d_p_list:  tensor(-0.1247, device='cuda:0')
Epoch:  305  
Training Loss: 21.260250091552734
Test Loss:  22.801725387573242
Test Acc:  0.0
Valid Loss:  20.212814331054688
Valid Acc:  0.0
std:  0.2686487001351729 
thres:  0.021682159423828125
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 30%|███       | 305/1000 [19:27<44:33,  3.85s/it]Epoch:   306
max of grad d_p:  tensor(92.8704, device='cuda:0')
min of grad d_p:  tensor(-6.8981, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2668, device='cuda:0') mean:  tensor(-4.0565e-05, device='cuda:0') min:  tensor(-0.2408, device='cuda:0') norm:  tensor(1.1197, device='cuda:0') MSE:  tensor(4.2031e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0057, device='cuda:0') mean:  tensor(1.9036e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0293, device='cuda:0') MSE:  tensor(1.0993e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0297, device='cuda:0')
min of d_p_list:  tensor(-0.0264, device='cuda:0')
Epoch:  306  
Training Loss: 21.04104232788086
Test Loss:  22.578088760375977
Test Acc:  0.0
Valid Loss:  20.00627326965332
Valid Acc:  0.0
std:  0.2999476463118284 
thres:  0.021483374786376953
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 31%|███       | 306/1000 [19:31<44:21,  3.83s/it]Epoch:   307
max of grad d_p:  tensor(92.4321, device='cuda:0')
min of grad d_p:  tensor(-6.7565, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2566, device='cuda:0') mean:  tensor(-5.6856e-05, device='cuda:0') min:  tensor(-0.4451, device='cuda:0') norm:  tensor(1.3190, device='cuda:0') MSE:  tensor(4.9511e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0076, device='cuda:0') mean:  tensor(1.5758e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0255, device='cuda:0') MSE:  tensor(9.5900e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0180, device='cuda:0')
min of d_p_list:  tensor(-0.0238, device='cuda:0')
Epoch:  307  
Training Loss: 20.830501556396484
Test Loss:  22.360008239746094
Test Acc:  0.0
Valid Loss:  19.821279525756836
Valid Acc:  0.0
std:  0.32639150343439866 
thres:  0.021279275512695314
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 31%|███       | 307/1000 [19:35<45:14,  3.92s/it]Epoch:   308
max of grad d_p:  tensor(92.0475, device='cuda:0')
min of grad d_p:  tensor(-6.7665, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2502, device='cuda:0') mean:  tensor(-5.4939e-05, device='cuda:0') min:  tensor(-0.3130, device='cuda:0') norm:  tensor(1.2401, device='cuda:0') MSE:  tensor(4.6549e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0067, device='cuda:0') mean:  tensor(1.9391e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0305, device='cuda:0') MSE:  tensor(1.1463e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0320, device='cuda:0')
min of d_p_list:  tensor(-0.0162, device='cuda:0')
Epoch:  308  
Training Loss: 20.622882843017578
Test Loss:  22.126121520996094
Test Acc:  0.0
Valid Loss:  19.615772247314453
Valid Acc:  0.0
std:  0.3150660157646363 
thres:  0.021055077362060547
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 31%|███       | 308/1000 [19:39<45:04,  3.91s/it]Epoch:   309
max of grad d_p:  tensor(91.4369, device='cuda:0')
min of grad d_p:  tensor(-6.8221, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2524, device='cuda:0') mean:  tensor(-6.9839e-05, device='cuda:0') min:  tensor(-0.3439, device='cuda:0') norm:  tensor(1.3172, device='cuda:0') MSE:  tensor(4.9445e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0064, device='cuda:0') mean:  tensor(2.1394e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0321, device='cuda:0') MSE:  tensor(1.2038e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0335, device='cuda:0')
min of d_p_list:  tensor(-0.0381, device='cuda:0')
Epoch:  309  
Training Loss: 20.41815948486328
Test Loss:  21.899381637573242
Test Acc:  0.0
Valid Loss:  19.41379165649414
Valid Acc:  0.0
std:  0.2973415827860108 
thres:  0.020834567260742187
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 31%|███       | 309/1000 [19:43<44:40,  3.88s/it]Epoch:   310
max of grad d_p:  tensor(91.0805, device='cuda:0')
min of grad d_p:  tensor(-6.7272, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2243, device='cuda:0') mean:  tensor(-4.7508e-05, device='cuda:0') min:  tensor(-0.2348, device='cuda:0') norm:  tensor(1.0537, device='cuda:0') MSE:  tensor(3.9553e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0152, device='cuda:0') mean:  tensor(3.7890e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0632, device='cuda:0') MSE:  tensor(2.3730e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0371, device='cuda:0')
min of d_p_list:  tensor(-0.0163, device='cuda:0')
Epoch:  310  
Training Loss: 20.20937728881836
Test Loss:  21.67084503173828
Test Acc:  0.0
Valid Loss:  19.228248596191406
Valid Acc:  0.0
std:  0.29354726478382553 
thres:  0.020624392700195313
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 31%|███       | 310/1000 [19:47<44:13,  3.85s/it]Epoch:   311
max of grad d_p:  tensor(90.2923, device='cuda:0')
min of grad d_p:  tensor(-6.7039, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2479, device='cuda:0') mean:  tensor(-6.9973e-05, device='cuda:0') min:  tensor(-0.5051, device='cuda:0') norm:  tensor(1.3767, device='cuda:0') MSE:  tensor(5.1677e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0790, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(3.3481e-11, device='cuda:0') norm:  tensor(0.3935, device='cuda:0') MSE:  tensor(1.4773e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2064, device='cuda:0')
min of d_p_list:  tensor(-0.1323, device='cuda:0')
Epoch:  311  
Training Loss: 19.960487365722656
Test Loss:  21.36844253540039
Test Acc:  0.0
Valid Loss:  18.99261474609375
Valid Acc:  0.0
std:  0.3047961807346439 
thres:  0.02040828170776367
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 31%|███       | 311/1000 [19:50<43:56,  3.83s/it]Epoch:   312
max of grad d_p:  tensor(87.6969, device='cuda:0')
min of grad d_p:  tensor(-7.5249, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2838, device='cuda:0') mean:  tensor(-4.1683e-05, device='cuda:0') min:  tensor(-0.2365, device='cuda:0') norm:  tensor(1.2411, device='cuda:0') MSE:  tensor(4.6589e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0422, device='cuda:0') mean:  tensor(7.8266e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1336, device='cuda:0') MSE:  tensor(5.0168e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0211, device='cuda:0')
min of d_p_list:  tensor(-0.0143, device='cuda:0')
Epoch:  312  
Training Loss: 19.760101318359375
Test Loss:  21.149402618408203
Test Acc:  0.0
Valid Loss:  18.798076629638672
Valid Acc:  0.0
std:  0.3089402666092393 
thres:  0.02019420166015625
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 31%|███       | 312/1000 [19:54<43:31,  3.80s/it]Epoch:   313
max of grad d_p:  tensor(87.2183, device='cuda:0')
min of grad d_p:  tensor(-7.4154, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2619, device='cuda:0') mean:  tensor(-3.6097e-05, device='cuda:0') min:  tensor(-0.2293, device='cuda:0') norm:  tensor(1.1864, device='cuda:0') MSE:  tensor(4.4536e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0539, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1607, device='cuda:0') MSE:  tensor(6.0316e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0387, device='cuda:0')
min of d_p_list:  tensor(-0.0340, device='cuda:0')
Epoch:  313  
Training Loss: 19.573486328125
Test Loss:  20.948822021484375
Test Acc:  0.0
Valid Loss:  18.62222671508789
Valid Acc:  0.0
std:  0.3028180309851046 
thres:  0.019984322357177734
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 31%|███▏      | 313/1000 [19:58<43:32,  3.80s/it]Epoch:   314
max of grad d_p:  tensor(86.6909, device='cuda:0')
min of grad d_p:  tensor(-7.2139, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2623, device='cuda:0') mean:  tensor(-6.4894e-05, device='cuda:0') min:  tensor(-0.2695, device='cuda:0') norm:  tensor(1.2968, device='cuda:0') MSE:  tensor(4.8680e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0274, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1486, device='cuda:0') MSE:  tensor(5.5789e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0565, device='cuda:0')
min of d_p_list:  tensor(-0.0505, device='cuda:0')
Epoch:  314  
Training Loss: 19.392147064208984
Test Loss:  20.748577117919922
Test Acc:  0.0
Valid Loss:  18.442058563232422
Valid Acc:  0.0
std:  0.2864997124694126 
thres:  0.019779119873046876
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 31%|███▏      | 314/1000 [20:02<43:27,  3.80s/it]Epoch:   315
max of grad d_p:  tensor(87.4455, device='cuda:0')
min of grad d_p:  tensor(-7.3156, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2753, device='cuda:0') mean:  tensor(-6.8701e-05, device='cuda:0') min:  tensor(-0.5553, device='cuda:0') norm:  tensor(1.4813, device='cuda:0') MSE:  tensor(5.5603e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0101, device='cuda:0') mean:  tensor(1.6637e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0274, device='cuda:0') MSE:  tensor(1.0280e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0151, device='cuda:0')
min of d_p_list:  tensor(-0.0088, device='cuda:0')
Epoch:  315  
Training Loss: 19.19731330871582
Test Loss:  20.536365509033203
Test Acc:  0.0
Valid Loss:  18.254074096679688
Valid Acc:  0.0
std:  0.2679302747855985 
thres:  0.019576707077026367
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 32%|███▏      | 315/1000 [20:06<43:42,  3.83s/it]Epoch:   316
max of grad d_p:  tensor(86.9380, device='cuda:0')
min of grad d_p:  tensor(-7.2376, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2629, device='cuda:0') mean:  tensor(-3.1245e-05, device='cuda:0') min:  tensor(-0.2667, device='cuda:0') norm:  tensor(1.1998, device='cuda:0') MSE:  tensor(4.5037e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0664, device='cuda:0') mean:  tensor(6.9877e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1283, device='cuda:0') MSE:  tensor(4.8158e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0267, device='cuda:0')
min of d_p_list:  tensor(-0.0214, device='cuda:0')
Epoch:  316  
Training Loss: 19.00540542602539
Test Loss:  20.32528305053711
Test Acc:  0.0
Valid Loss:  18.064685821533203
Valid Acc:  0.0
std:  0.2666815047471001 
thres:  0.019385690689086913
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 32%|███▏      | 316/1000 [20:09<43:14,  3.79s/it]Epoch:   317
max of grad d_p:  tensor(86.3918, device='cuda:0')
min of grad d_p:  tensor(-7.2463, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2358, device='cuda:0') mean:  tensor(-4.7329e-05, device='cuda:0') min:  tensor(-0.2234, device='cuda:0') norm:  tensor(1.1516, device='cuda:0') MSE:  tensor(4.3228e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0079, device='cuda:0') mean:  tensor(1.9969e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0307, device='cuda:0') MSE:  tensor(1.1508e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0903, device='cuda:0')
min of d_p_list:  tensor(-0.0673, device='cuda:0')
Epoch:  317  
Training Loss: 18.84259605407715
Test Loss:  20.14427947998047
Test Acc:  0.0
Valid Loss:  17.922962188720703
Valid Acc:  0.0
std:  0.26153409190312404 
thres:  0.01920218963623047
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 32%|███▏      | 317/1000 [20:13<43:19,  3.81s/it]Epoch:   318
max of grad d_p:  tensor(85.6953, device='cuda:0')
min of grad d_p:  tensor(-7.3023, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2504, device='cuda:0') mean:  tensor(-4.7535e-05, device='cuda:0') min:  tensor(-0.2591, device='cuda:0') norm:  tensor(1.2186, device='cuda:0') MSE:  tensor(4.5743e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0483, device='cuda:0') mean:  tensor(9.6938e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1653, device='cuda:0') MSE:  tensor(6.2039e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0193, device='cuda:0')
min of d_p_list:  tensor(-0.0204, device='cuda:0')
Epoch:  318  
Training Loss: 18.661724090576172
Test Loss:  19.959264755249023
Test Acc:  0.0
Valid Loss:  17.755277633666992
Valid Acc:  0.0
std:  0.25689690663825593 
thres:  0.019019837188720704
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 32%|███▏      | 318/1000 [20:17<43:24,  3.82s/it]Epoch:   319
max of grad d_p:  tensor(85.2015, device='cuda:0')
min of grad d_p:  tensor(-7.1474, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2606, device='cuda:0') mean:  tensor(-6.0593e-05, device='cuda:0') min:  tensor(-0.4870, device='cuda:0') norm:  tensor(1.4720, device='cuda:0') MSE:  tensor(5.5255e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0159, device='cuda:0') mean:  tensor(3.3891e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0520, device='cuda:0') MSE:  tensor(1.9513e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0439, device='cuda:0')
min of d_p_list:  tensor(-0.0372, device='cuda:0')
Epoch:  319  
Training Loss: 18.45069694519043
Test Loss:  19.711606979370117
Test Acc:  0.0
Valid Loss:  17.52657699584961
Valid Acc:  0.0
std:  0.2600078503819118 
thres:  0.01883154716491699
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 32%|███▏      | 319/1000 [20:21<44:11,  3.89s/it]Epoch:   320
max of grad d_p:  tensor(85.3245, device='cuda:0')
min of grad d_p:  tensor(-7.1849, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2362, device='cuda:0') mean:  tensor(-6.0622e-05, device='cuda:0') min:  tensor(-0.4310, device='cuda:0') norm:  tensor(1.3520, device='cuda:0') MSE:  tensor(5.0752e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0336, device='cuda:0') mean:  tensor(8.3982e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1390, device='cuda:0') MSE:  tensor(5.2187e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0350, device='cuda:0')
min of d_p_list:  tensor(-0.0352, device='cuda:0')
Epoch:  320  
Training Loss: 18.266544342041016
Test Loss:  19.517784118652344
Test Acc:  0.0
Valid Loss:  17.35671615600586
Valid Acc:  0.0
std:  0.2646497894745029 
thres:  0.018645393371582032
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 32%|███▏      | 320/1000 [20:25<43:56,  3.88s/it]Epoch:   321
max of grad d_p:  tensor(84.9163, device='cuda:0')
min of grad d_p:  tensor(-7.1703, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2514, device='cuda:0') mean:  tensor(-4.3798e-05, device='cuda:0') min:  tensor(-0.2298, device='cuda:0') norm:  tensor(1.1850, device='cuda:0') MSE:  tensor(4.4482e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4321, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(1.4188e-10, device='cuda:0') norm:  tensor(1.8528, device='cuda:0') MSE:  tensor(6.9550e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0169, device='cuda:0')
min of d_p_list:  tensor(-0.0184, device='cuda:0')
Epoch:  321  
Training Loss: 18.08404541015625
Test Loss:  19.31966781616211
Test Acc:  0.0
Valid Loss:  17.183147430419922
Valid Acc:  0.0
std:  0.2705252498486487 
thres:  0.018461121368408204
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 32%|███▏      | 321/1000 [20:29<43:30,  3.85s/it]Epoch:   322
max of grad d_p:  tensor(84.2430, device='cuda:0')
min of grad d_p:  tensor(-7.0479, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2495, device='cuda:0') mean:  tensor(-5.5818e-05, device='cuda:0') min:  tensor(-0.3385, device='cuda:0') norm:  tensor(1.2900, device='cuda:0') MSE:  tensor(4.8425e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0539, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.2010, device='cuda:0') MSE:  tensor(7.5448e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0147, device='cuda:0')
min of d_p_list:  tensor(-0.0069, device='cuda:0')
Epoch:  322  
Training Loss: 17.893726348876953
Test Loss:  19.146726608276367
Test Acc:  0.0
Valid Loss:  17.042190551757812
Valid Acc:  0.0
std:  0.2691702000302689 
thres:  0.018271347427368162
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 32%|███▏      | 322/1000 [20:32<42:50,  3.79s/it]Epoch:   323
max of grad d_p:  tensor(83.8005, device='cuda:0')
min of grad d_p:  tensor(-6.8716, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2997, device='cuda:0') mean:  tensor(-4.1798e-05, device='cuda:0') min:  tensor(-0.2896, device='cuda:0') norm:  tensor(1.3846, device='cuda:0') MSE:  tensor(5.1973e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0068, device='cuda:0') mean:  tensor(1.8635e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0272, device='cuda:0') MSE:  tensor(1.0222e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0255, device='cuda:0')
min of d_p_list:  tensor(-0.0194, device='cuda:0')
Epoch:  323  
Training Loss: 17.70925521850586
Test Loss:  18.94498634338379
Test Acc:  0.0
Valid Loss:  16.87025260925293
Valid Acc:  0.0
std:  0.26244134756374904 
thres:  0.0180808536529541
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 32%|███▏      | 323/1000 [20:36<43:05,  3.82s/it]Epoch:   324
max of grad d_p:  tensor(83.1691, device='cuda:0')
min of grad d_p:  tensor(-6.7241, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2608, device='cuda:0') mean:  tensor(-4.1939e-05, device='cuda:0') min:  tensor(-0.2648, device='cuda:0') norm:  tensor(1.1977, device='cuda:0') MSE:  tensor(4.4960e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0288, device='cuda:0') mean:  tensor(6.7431e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1135, device='cuda:0') MSE:  tensor(4.2593e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.4414, device='cuda:0')
min of d_p_list:  tensor(-0.9169, device='cuda:0')
Epoch:  324  
Training Loss: 21.841087341308594
Test Loss:  23.863361358642578
Test Acc:  0.0
Valid Loss:  21.606403350830078
Valid Acc:  0.0
std:  1.5522887120095377 
thres:  0.018758931732177735
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  38
 32%|███▏      | 324/1000 [20:40<43:12,  3.83s/it]Epoch:   325
max of grad d_p:  tensor(100.1684, device='cuda:0')
min of grad d_p:  tensor(-6.1693, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3472, device='cuda:0') mean:  tensor(3.0636e-05, device='cuda:0') min:  tensor(-0.3708, device='cuda:0') norm:  tensor(1.9717, device='cuda:0') MSE:  tensor(7.4012e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0077, device='cuda:0') mean:  tensor(2.0758e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0304, device='cuda:0') MSE:  tensor(1.1407e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0534, device='cuda:0')
min of d_p_list:  tensor(-0.0482, device='cuda:0')
Epoch:  325  
Training Loss: 21.517799377441406
Test Loss:  23.602642059326172
Test Acc:  0.0
Valid Loss:  21.418956756591797
Valid Acc:  0.0
std:  1.8602566870319235 
thres:  0.01940918273925781
Preserved_eigens number check:  38
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 32%|███▎      | 325/1000 [20:44<42:08,  3.75s/it]Epoch:   326
max of grad d_p:  tensor(99.5932, device='cuda:0')
min of grad d_p:  tensor(-5.6300, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2689, device='cuda:0') mean:  tensor(1.4601e-05, device='cuda:0') min:  tensor(-0.2404, device='cuda:0') norm:  tensor(1.4402, device='cuda:0') MSE:  tensor(5.4063e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0078, device='cuda:0') mean:  tensor(2.5133e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0367, device='cuda:0') MSE:  tensor(1.3769e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0804, device='cuda:0')
min of d_p_list:  tensor(-0.1548, device='cuda:0')
Epoch:  326  
Training Loss: 21.21889877319336
Test Loss:  23.30400848388672
Test Acc:  0.0
Valid Loss:  21.169158935546875
Valid Acc:  0.0
std:  1.8361043962253838 
thres:  0.020036153411865237
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 33%|███▎      | 326/1000 [20:47<41:42,  3.71s/it]Epoch:   327
max of grad d_p:  tensor(97.9928, device='cuda:0')
min of grad d_p:  tensor(-5.4449, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2688, device='cuda:0') mean:  tensor(-1.6881e-06, device='cuda:0') min:  tensor(-0.3851, device='cuda:0') norm:  tensor(1.5625, device='cuda:0') MSE:  tensor(5.8652e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0051, device='cuda:0') mean:  tensor(9.2957e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0158, device='cuda:0') MSE:  tensor(5.9186e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0650, device='cuda:0')
min of d_p_list:  tensor(-0.0823, device='cuda:0')
Epoch:  327  
Training Loss: 21.001853942871094
Test Loss:  23.061710357666016
Test Acc:  0.0
Valid Loss:  20.944101333618164
Valid Acc:  0.0
std:  1.5011255201642366 
thres:  0.02065777893066406
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 33%|███▎      | 327/1000 [20:51<42:06,  3.75s/it]Epoch:   328
max of grad d_p:  tensor(95.6531, device='cuda:0')
min of grad d_p:  tensor(-5.4780, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2621, device='cuda:0') mean:  tensor(-1.7412e-05, device='cuda:0') min:  tensor(-0.2491, device='cuda:0') norm:  tensor(1.3262, device='cuda:0') MSE:  tensor(4.9784e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2995, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(1.4886e-12, device='cuda:0') norm:  tensor(0.9981, device='cuda:0') MSE:  tensor(3.7465e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0297, device='cuda:0')
min of d_p_list:  tensor(-0.0200, device='cuda:0')
Epoch:  328  
Training Loss: 20.789134979248047
Test Loss:  22.836997985839844
Test Acc:  0.0
Valid Loss:  20.735977172851562
Valid Acc:  0.0
std:  0.37234919058762234 
thres:  0.021273754882812503
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 33%|███▎      | 328/1000 [20:55<42:33,  3.80s/it]Epoch:   329
max of grad d_p:  tensor(95.1693, device='cuda:0')
min of grad d_p:  tensor(-5.3969, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2929, device='cuda:0') mean:  tensor(-8.0034e-06, device='cuda:0') min:  tensor(-0.5098, device='cuda:0') norm:  tensor(1.7225, device='cuda:0') MSE:  tensor(6.4658e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0050, device='cuda:0') mean:  tensor(1.5732e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0232, device='cuda:0') MSE:  tensor(8.7152e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2071, device='cuda:0')
min of d_p_list:  tensor(-0.2442, device='cuda:0')
Epoch:  329  
Training Loss: 20.701492309570312
Test Loss:  22.667509078979492
Test Acc:  0.0
Valid Loss:  20.603160858154297
Valid Acc:  0.0
std:  0.29634526001079237 
thres:  0.021045835876464844
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 33%|███▎      | 329/1000 [20:59<42:45,  3.82s/it]Epoch:   330
max of grad d_p:  tensor(95.4553, device='cuda:0')
min of grad d_p:  tensor(-6.2635, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3124, device='cuda:0') mean:  tensor(1.3094e-05, device='cuda:0') min:  tensor(-0.3213, device='cuda:0') norm:  tensor(1.6383, device='cuda:0') MSE:  tensor(6.1497e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0035, device='cuda:0') mean:  tensor(1.2072e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0178, device='cuda:0') MSE:  tensor(6.6739e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0270, device='cuda:0')
min of d_p_list:  tensor(-0.0329, device='cuda:0')
Epoch:  330  
Training Loss: 20.48970603942871
Test Loss:  22.43216896057129
Test Acc:  0.0
Valid Loss:  20.38955307006836
Valid Acc:  0.0
std:  0.25069432889831605 
thres:  0.020840217208862307
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 33%|███▎      | 330/1000 [21:03<43:19,  3.88s/it]Epoch:   331
max of grad d_p:  tensor(95.0265, device='cuda:0')
min of grad d_p:  tensor(-6.1434, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3224, device='cuda:0') mean:  tensor(4.0786e-05, device='cuda:0') min:  tensor(-0.3204, device='cuda:0') norm:  tensor(1.6507, device='cuda:0') MSE:  tensor(6.1963e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0188, device='cuda:0') mean:  tensor(4.4811e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0685, device='cuda:0') MSE:  tensor(2.5720e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0929, device='cuda:0')
min of d_p_list:  tensor(-0.0872, device='cuda:0')
Epoch:  331  
Training Loss: 20.271759033203125
Test Loss:  22.250812530517578
Test Acc:  0.0
Valid Loss:  20.224567413330078
Valid Acc:  0.0
std:  0.2508260216184436 
thres:  0.020650789260864257
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 33%|███▎      | 331/1000 [21:07<43:18,  3.88s/it]Epoch:   332
max of grad d_p:  tensor(94.4714, device='cuda:0')
min of grad d_p:  tensor(-5.9635, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3122, device='cuda:0') mean:  tensor(1.1426e-05, device='cuda:0') min:  tensor(-0.3317, device='cuda:0') norm:  tensor(1.6464, device='cuda:0') MSE:  tensor(6.1802e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0042, device='cuda:0') mean:  tensor(2.6264e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0396, device='cuda:0') MSE:  tensor(1.4878e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0146, device='cuda:0')
min of d_p_list:  tensor(-0.0215, device='cuda:0')
Epoch:  332  
Training Loss: 20.071949005126953
Test Loss:  22.021329879760742
Test Acc:  0.0
Valid Loss:  20.018686294555664
Valid Acc:  0.0
std:  0.26586968900796504 
thres:  0.02046480827331543
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 33%|███▎      | 332/1000 [21:11<43:31,  3.91s/it]Epoch:   333
max of grad d_p:  tensor(93.9652, device='cuda:0')
min of grad d_p:  tensor(-5.9602, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2703, device='cuda:0') mean:  tensor(-1.3691e-05, device='cuda:0') min:  tensor(-0.3761, device='cuda:0') norm:  tensor(1.4092, device='cuda:0') MSE:  tensor(5.2897e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0111, device='cuda:0') mean:  tensor(2.2973e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0328, device='cuda:0') MSE:  tensor(1.2309e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0634, device='cuda:0')
min of d_p_list:  tensor(-0.0555, device='cuda:0')
Epoch:  333  
Training Loss: 19.866304397583008
Test Loss:  21.81648063659668
Test Acc:  0.0
Valid Loss:  19.81544303894043
Valid Acc:  0.0
std:  0.2953402371030204 
thres:  0.02028024215698242
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 33%|███▎      | 333/1000 [21:14<42:59,  3.87s/it]Epoch:   334
max of grad d_p:  tensor(92.6677, device='cuda:0')
min of grad d_p:  tensor(-5.7697, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2981, device='cuda:0') mean:  tensor(-2.7841e-06, device='cuda:0') min:  tensor(-0.4996, device='cuda:0') norm:  tensor(1.6826, device='cuda:0') MSE:  tensor(6.3162e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0031, device='cuda:0') mean:  tensor(8.8595e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0131, device='cuda:0') MSE:  tensor(4.9030e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1311, device='cuda:0')
min of d_p_list:  tensor(-0.0615, device='cuda:0')
Epoch:  334  
Training Loss: 19.560352325439453
Test Loss:  21.557392120361328
Test Acc:  0.0
Valid Loss:  19.599205017089844
Valid Acc:  0.0
std:  0.32139659739566273 
thres:  0.020052014160156253
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 33%|███▎      | 334/1000 [21:18<42:08,  3.80s/it]Epoch:   335
max of grad d_p:  tensor(90.5542, device='cuda:0')
min of grad d_p:  tensor(-5.6766, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3142, device='cuda:0') mean:  tensor(1.9085e-05, device='cuda:0') min:  tensor(-0.3045, device='cuda:0') norm:  tensor(1.5511, device='cuda:0') MSE:  tensor(5.8226e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0257, device='cuda:0') mean:  tensor(5.0238e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0846, device='cuda:0') MSE:  tensor(3.1753e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0125, device='cuda:0')
min of d_p_list:  tensor(-0.0112, device='cuda:0')
Epoch:  335  
Training Loss: 19.36530113220215
Test Loss:  21.335830688476562
Test Acc:  0.0
Valid Loss:  19.398635864257812
Valid Acc:  0.0
std:  0.3297338886403233 
thres:  0.01982713317871094
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 34%|███▎      | 335/1000 [21:22<42:03,  3.79s/it]Epoch:   336
max of grad d_p:  tensor(89.9961, device='cuda:0')
min of grad d_p:  tensor(-5.6169, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3182, device='cuda:0') mean:  tensor(1.0197e-05, device='cuda:0') min:  tensor(-0.5427, device='cuda:0') norm:  tensor(1.8243, device='cuda:0') MSE:  tensor(6.8478e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0077, device='cuda:0') mean:  tensor(1.3670e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0226, device='cuda:0') MSE:  tensor(8.4892e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0456, device='cuda:0')
min of d_p_list:  tensor(-0.0244, device='cuda:0')
Epoch:  336  
Training Loss: 19.147340774536133
Test Loss:  21.075172424316406
Test Acc:  0.0
Valid Loss:  19.163997650146484
Valid Acc:  0.0
std:  0.33322198750846466 
thres:  0.019602249526977537
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  40
 34%|███▎      | 336/1000 [21:26<41:20,  3.74s/it]Epoch:   337
max of grad d_p:  tensor(89.9084, device='cuda:0')
min of grad d_p:  tensor(-5.6017, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2952, device='cuda:0') mean:  tensor(-6.7481e-06, device='cuda:0') min:  tensor(-0.6115, device='cuda:0') norm:  tensor(1.6647, device='cuda:0') MSE:  tensor(6.2487e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0035, device='cuda:0') mean:  tensor(1.0731e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0170, device='cuda:0') MSE:  tensor(6.3970e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0345, device='cuda:0')
min of d_p_list:  tensor(-0.0472, device='cuda:0')
Epoch:  337  
Training Loss: 17.374282836914062
Test Loss:  19.059940338134766
Test Acc:  0.0
Valid Loss:  17.339054107666016
Valid Acc:  0.0
std:  0.8766894417101125 
thres:  0.01906271629333496
Preserved_eigens number check:  40
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 34%|███▎      | 337/1000 [21:29<41:49,  3.79s/it]Epoch:   338
max of grad d_p:  tensor(85.5202, device='cuda:0')
min of grad d_p:  tensor(-5.3359, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3005, device='cuda:0') mean:  tensor(1.2507e-06, device='cuda:0') min:  tensor(-0.5504, device='cuda:0') norm:  tensor(1.7173, device='cuda:0') MSE:  tensor(6.4464e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0319, device='cuda:0') mean:  tensor(9.1861e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1330, device='cuda:0') MSE:  tensor(4.9914e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0449, device='cuda:0')
min of d_p_list:  tensor(-0.0256, device='cuda:0')
Epoch:  338  
Training Loss: 17.182350158691406
Test Loss:  18.86037826538086
Test Acc:  0.0
Valid Loss:  17.1611328125
Valid Acc:  0.0
std:  1.0288073457905011 
thres:  0.018525925445556642
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 34%|███▍      | 338/1000 [21:33<42:09,  3.82s/it]Epoch:   339
max of grad d_p:  tensor(85.0725, device='cuda:0')
min of grad d_p:  tensor(-5.2673, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2813, device='cuda:0') mean:  tensor(-3.0764e-06, device='cuda:0') min:  tensor(-0.5190, device='cuda:0') norm:  tensor(1.5901, device='cuda:0') MSE:  tensor(5.9688e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0023, device='cuda:0') mean:  tensor(8.5143e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0122, device='cuda:0') MSE:  tensor(4.5947e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0548, device='cuda:0')
min of d_p_list:  tensor(-0.0785, device='cuda:0')
Epoch:  339  
Training Loss: 17.038230895996094
Test Loss:  18.727092742919922
Test Acc:  0.0
Valid Loss:  17.03652572631836
Valid Acc:  0.0
std:  1.0161889170581486 
thres:  0.018021501159667972
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 34%|███▍      | 339/1000 [21:37<42:14,  3.83s/it]Epoch:   340
max of grad d_p:  tensor(84.6842, device='cuda:0')
min of grad d_p:  tensor(-5.0604, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2932, device='cuda:0') mean:  tensor(1.8325e-06, device='cuda:0') min:  tensor(-0.5598, device='cuda:0') norm:  tensor(1.7493, device='cuda:0') MSE:  tensor(6.5666e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0129, device='cuda:0') mean:  tensor(4.3963e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0622, device='cuda:0') MSE:  tensor(2.3367e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2102, device='cuda:0')
min of d_p_list:  tensor(-0.1528, device='cuda:0')
Epoch:  340  
Training Loss: 16.858314514160156
Test Loss:  18.565086364746094
Test Acc:  0.0
Valid Loss:  16.8813419342041
Valid Acc:  0.0
std:  0.8310725601601335 
thres:  0.01752010383605957
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 34%|███▍      | 340/1000 [21:41<42:13,  3.84s/it]Epoch:   341
max of grad d_p:  tensor(85.6017, device='cuda:0')
min of grad d_p:  tensor(-5.7296, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3178, device='cuda:0') mean:  tensor(1.7023e-05, device='cuda:0') min:  tensor(-0.2668, device='cuda:0') norm:  tensor(1.3513, device='cuda:0') MSE:  tensor(5.0725e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0817, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(4.4338e-12, device='cuda:0') norm:  tensor(0.4197, device='cuda:0') MSE:  tensor(1.5753e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0083, device='cuda:0')
min of d_p_list:  tensor(-0.0134, device='cuda:0')
Epoch:  341  
Training Loss: 16.688047409057617
Test Loss:  18.377872467041016
Test Acc:  0.0
Valid Loss:  16.711807250976562
Valid Acc:  0.0
std:  0.2400837660196728 
thres:  0.017028245162963866
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 34%|███▍      | 341/1000 [21:45<41:44,  3.80s/it]Epoch:   342
max of grad d_p:  tensor(85.3432, device='cuda:0')
min of grad d_p:  tensor(-5.6900, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2713, device='cuda:0') mean:  tensor(-3.6903e-06, device='cuda:0') min:  tensor(-0.2995, device='cuda:0') norm:  tensor(1.3217, device='cuda:0') MSE:  tensor(4.9614e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0022, device='cuda:0') mean:  tensor(1.0176e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0140, device='cuda:0') MSE:  tensor(5.2646e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0503, device='cuda:0')
min of d_p_list:  tensor(-0.0645, device='cuda:0')
Epoch:  342  
Training Loss: 16.503704071044922
Test Loss:  18.181978225708008
Test Acc:  0.0
Valid Loss:  16.538665771484375
Valid Acc:  0.0
std:  0.24166956007455948 
thres:  0.01685412940979004
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 34%|███▍      | 342/1000 [21:49<42:01,  3.83s/it]Epoch:   343
max of grad d_p:  tensor(84.6743, device='cuda:0')
min of grad d_p:  tensor(-5.5692, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3180, device='cuda:0') mean:  tensor(1.2897e-05, device='cuda:0') min:  tensor(-0.2820, device='cuda:0') norm:  tensor(1.4390, device='cuda:0') MSE:  tensor(5.4018e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0061, device='cuda:0') mean:  tensor(1.3241e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0193, device='cuda:0') MSE:  tensor(7.2314e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0849, device='cuda:0')
min of d_p_list:  tensor(-0.0986, device='cuda:0')
Epoch:  343  
Training Loss: 16.291492462158203
Test Loss:  17.959087371826172
Test Acc:  0.0
Valid Loss:  16.319805145263672
Valid Acc:  0.0
std:  0.26158244171570905 
thres:  0.0166759578704834
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 34%|███▍      | 343/1000 [21:53<42:38,  3.89s/it]Epoch:   344
max of grad d_p:  tensor(84.2661, device='cuda:0')
min of grad d_p:  tensor(-5.5927, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3177, device='cuda:0') mean:  tensor(1.8974e-06, device='cuda:0') min:  tensor(-0.3044, device='cuda:0') norm:  tensor(1.3773, device='cuda:0') MSE:  tensor(5.1700e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0081, device='cuda:0') mean:  tensor(2.3216e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0373, device='cuda:0') MSE:  tensor(1.4004e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0285, device='cuda:0')
min of d_p_list:  tensor(-0.0201, device='cuda:0')
Epoch:  344  
Training Loss: 16.122928619384766
Test Loss:  17.783538818359375
Test Acc:  0.0
Valid Loss:  16.167560577392578
Valid Acc:  0.0
std:  0.26426154662091045 
thres:  0.01649289741516113
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 34%|███▍      | 344/1000 [21:56<42:05,  3.85s/it]Epoch:   345
max of grad d_p:  tensor(84.0581, device='cuda:0')
min of grad d_p:  tensor(-5.5993, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3104, device='cuda:0') mean:  tensor(-2.7252e-05, device='cuda:0') min:  tensor(-0.5747, device='cuda:0') norm:  tensor(1.5195, device='cuda:0') MSE:  tensor(5.7039e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0031, device='cuda:0') mean:  tensor(9.2388e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0132, device='cuda:0') MSE:  tensor(4.9627e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(1.0756, device='cuda:0')
min of d_p_list:  tensor(-1.4025, device='cuda:0')
Epoch:  345  
Training Loss: 3.2111454010009766
Test Loss:  3.44154953956604
Test Acc:  0.0
Valid Loss:  3.4761486053466797
Valid Acc:  0.0
std:  5.279612348911342 
thres:  0.013763463592529297
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 34%|███▍      | 345/1000 [22:00<41:44,  3.82s/it]Epoch:   346
max of grad d_p:  tensor(35.2160, device='cuda:0')
min of grad d_p:  tensor(-1.3331, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2817, device='cuda:0') mean:  tensor(2.0888e-05, device='cuda:0') min:  tensor(-0.4417, device='cuda:0') norm:  tensor(2.1304, device='cuda:0') MSE:  tensor(7.9971e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0106, device='cuda:0') mean:  tensor(2.2979e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0380, device='cuda:0') MSE:  tensor(1.4246e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0192, device='cuda:0')
min of d_p_list:  tensor(-0.0164, device='cuda:0')
Epoch:  346  
Training Loss: 3.1753079891204834
Test Loss:  3.402280330657959
Test Acc:  0.0
Valid Loss:  3.4423575401306152
Valid Acc:  0.0
std:  6.425084529090014 
thres:  0.01106091570854187
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  37
 35%|███▍      | 346/1000 [22:04<42:09,  3.87s/it]Epoch:   347
max of grad d_p:  tensor(35.0756, device='cuda:0')
min of grad d_p:  tensor(-1.3049, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2648, device='cuda:0') mean:  tensor(1.9091e-05, device='cuda:0') min:  tensor(-0.3998, device='cuda:0') norm:  tensor(1.9268, device='cuda:0') MSE:  tensor(7.2328e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0148, device='cuda:0') mean:  tensor(4.2782e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0638, device='cuda:0') MSE:  tensor(2.3935e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0272, device='cuda:0')
min of d_p_list:  tensor(-0.0212, device='cuda:0')
Epoch:  347  
Training Loss: 3.1356558799743652
Test Loss:  3.359065532684326
Test Acc:  0.0
Valid Loss:  3.397693634033203
Valid Acc:  0.0
std:  6.385192428318969 
thres:  0.008387306070327758
Preserved_eigens number check:  37
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 35%|███▍      | 347/1000 [22:08<42:18,  3.89s/it]Epoch:   348
max of grad d_p:  tensor(34.9076, device='cuda:0')
min of grad d_p:  tensor(-1.3017, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2469, device='cuda:0') mean:  tensor(1.7193e-05, device='cuda:0') min:  tensor(-0.4582, device='cuda:0') norm:  tensor(2.1135, device='cuda:0') MSE:  tensor(7.9335e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0142, device='cuda:0') mean:  tensor(2.3196e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0376, device='cuda:0') MSE:  tensor(1.4097e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0249, device='cuda:0')
min of d_p_list:  tensor(-0.0223, device='cuda:0')
Epoch:  348  
Training Loss: 3.101871967315674
Test Loss:  3.3238120079040527
Test Acc:  0.0
Valid Loss:  3.3603010177612305
Valid Acc:  0.0
std:  5.186903606472768 
thres:  0.005749381971359253
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  40
 35%|███▍      | 348/1000 [22:12<41:36,  3.83s/it]Epoch:   349
max of grad d_p:  tensor(34.7166, device='cuda:0')
min of grad d_p:  tensor(-1.3059, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2977, device='cuda:0') mean:  tensor(1.9188e-05, device='cuda:0') min:  tensor(-0.4111, device='cuda:0') norm:  tensor(1.9316, device='cuda:0') MSE:  tensor(7.2508e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0107, device='cuda:0') mean:  tensor(2.1687e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0343, device='cuda:0') MSE:  tensor(1.2862e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0202, device='cuda:0')
min of d_p_list:  tensor(-0.0164, device='cuda:0')
Epoch:  349  
Training Loss: 3.048388957977295
Test Loss:  3.2887587547302246
Test Acc:  0.0
Valid Loss:  3.3183319568634033
Valid Acc:  0.0
std:  0.05660537471726735 
thres:  0.0031344740390777588
Preserved_eigens number check:  40
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  69
 35%|███▍      | 349/1000 [22:15<40:56,  3.77s/it]Epoch:   350
max of grad d_p:  tensor(34.4940, device='cuda:0')
min of grad d_p:  tensor(-1.2907, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2459, device='cuda:0') mean:  tensor(3.2100e-06, device='cuda:0') min:  tensor(-0.4426, device='cuda:0') norm:  tensor(2.1714, device='cuda:0') MSE:  tensor(8.1509e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0068, device='cuda:0') mean:  tensor(2.6178e-05, device='cuda:0') min:  tensor(1.4211e-13, device='cuda:0') norm:  tensor(0.0380, device='cuda:0') MSE:  tensor(1.4264e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0495, device='cuda:0')
min of d_p_list:  tensor(-0.0243, device='cuda:0')
Epoch:  350  
Training Loss: 2.954467296600342
Test Loss:  3.1932055950164795
Test Acc:  0.0
Valid Loss:  3.2173941135406494
Valid Acc:  0.0
std:  0.07663947021847253 
thres:  0.003083138418197632
Preserved_eigens number check:  69
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  39
 35%|███▌      | 350/1000 [22:19<41:14,  3.81s/it]Epoch:   351
max of grad d_p:  tensor(33.8949, device='cuda:0')
min of grad d_p:  tensor(-1.2111, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3166, device='cuda:0') mean:  tensor(1.7473e-05, device='cuda:0') min:  tensor(-0.4093, device='cuda:0') norm:  tensor(1.9681, device='cuda:0') MSE:  tensor(7.3878e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0320, device='cuda:0') mean:  tensor(7.5591e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1128, device='cuda:0') MSE:  tensor(4.2335e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1930, device='cuda:0')
min of d_p_list:  tensor(-0.2553, device='cuda:0')
Epoch:  351  
Training Loss: 2.857537031173706
Test Loss:  3.119663953781128
Test Acc:  0.0
Valid Loss:  3.1272165775299072
Valid Acc:  0.0
std:  0.10156093900410212 
thres:  0.003019584226608276
Preserved_eigens number check:  39
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 35%|███▌      | 351/1000 [22:23<41:24,  3.83s/it]Epoch:   352
max of grad d_p:  tensor(32.8120, device='cuda:0')
min of grad d_p:  tensor(-1.1489, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4643, device='cuda:0') mean:  tensor(1.0590e-05, device='cuda:0') min:  tensor(-0.4420, device='cuda:0') norm:  tensor(2.0315, device='cuda:0') MSE:  tensor(7.6259e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0166, device='cuda:0') mean:  tensor(7.9039e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1178, device='cuda:0') MSE:  tensor(4.4221e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0725, device='cuda:0')
min of d_p_list:  tensor(-0.1316, device='cuda:0')
Epoch:  352  
Training Loss: 2.857156753540039
Test Loss:  3.141645908355713
Test Acc:  0.0
Valid Loss:  3.135983943939209
Valid Acc:  0.0
std:  0.09896547303401694 
thres:  0.002963884401321411
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 35%|███▌      | 352/1000 [22:27<41:48,  3.87s/it]Epoch:   353
max of grad d_p:  tensor(32.8600, device='cuda:0')
min of grad d_p:  tensor(-1.1953, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3527, device='cuda:0') mean:  tensor(2.6926e-05, device='cuda:0') min:  tensor(-0.5188, device='cuda:0') norm:  tensor(2.1458, device='cuda:0') MSE:  tensor(8.0547e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0248, device='cuda:0') mean:  tensor(6.8845e-05, device='cuda:0') min:  tensor(5.8208e-11, device='cuda:0') norm:  tensor(0.1143, device='cuda:0') MSE:  tensor(4.2893e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0391, device='cuda:0')
min of d_p_list:  tensor(-0.0503, device='cuda:0')
Epoch:  353  
Training Loss: 2.8154709339141846
Test Loss:  3.1058924198150635
Test Acc:  0.0
Valid Loss:  3.095278263092041
Valid Acc:  0.0
std:  0.08432283536072584 
thres:  0.0029066041946411133
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 35%|███▌      | 353/1000 [22:31<42:09,  3.91s/it]Epoch:   354
max of grad d_p:  tensor(32.5544, device='cuda:0')
min of grad d_p:  tensor(-1.1837, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2992, device='cuda:0') mean:  tensor(-3.7284e-06, device='cuda:0') min:  tensor(-0.5224, device='cuda:0') norm:  tensor(2.2816, device='cuda:0') MSE:  tensor(8.5647e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0049, device='cuda:0') mean:  tensor(1.6369e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0246, device='cuda:0') MSE:  tensor(9.2427e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0264, device='cuda:0')
min of d_p_list:  tensor(-0.0094, device='cuda:0')
Epoch:  354  
Training Loss: 2.781148910522461
Test Loss:  3.0654478073120117
Test Acc:  0.0
Valid Loss:  3.0598225593566895
Valid Acc:  0.0
std:  0.0581452722456826 
thres:  0.0028531561851501464
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 35%|███▌      | 354/1000 [22:35<42:14,  3.92s/it]Epoch:   355
max of grad d_p:  tensor(32.3092, device='cuda:0')
min of grad d_p:  tensor(-1.1344, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2946, device='cuda:0') mean:  tensor(2.0473e-05, device='cuda:0') min:  tensor(-0.4884, device='cuda:0') norm:  tensor(2.0135, device='cuda:0') MSE:  tensor(7.5583e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0092, device='cuda:0') mean:  tensor(2.6587e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0441, device='cuda:0') MSE:  tensor(1.6539e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0732, device='cuda:0')
min of d_p_list:  tensor(-0.0725, device='cuda:0')
Epoch:  355  
Training Loss: 2.7289485931396484
Test Loss:  3.0230910778045654
Test Acc:  0.0
Valid Loss:  3.021249294281006
Valid Acc:  0.0
std:  0.04877747617553977 
thres:  0.002808052444458008
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  39
 36%|███▌      | 355/1000 [22:39<42:37,  3.96s/it]Epoch:   356
max of grad d_p:  tensor(31.8776, device='cuda:0')
min of grad d_p:  tensor(-1.1366, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2631, device='cuda:0') mean:  tensor(1.5308e-05, device='cuda:0') min:  tensor(-0.3727, device='cuda:0') norm:  tensor(1.6444, device='cuda:0') MSE:  tensor(6.1728e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0056, device='cuda:0') mean:  tensor(1.7815e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0267, device='cuda:0') MSE:  tensor(1.0028e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0319, device='cuda:0')
min of d_p_list:  tensor(-0.0368, device='cuda:0')
Epoch:  356  
Training Loss: 2.648252487182617
Test Loss:  2.9335899353027344
Test Acc:  0.0
Valid Loss:  2.925276279449463
Valid Acc:  0.0
std:  0.07242031325858561 
thres:  0.00276619553565979
Preserved_eigens number check:  39
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 36%|███▌      | 356/1000 [22:43<41:58,  3.91s/it]Epoch:   357
max of grad d_p:  tensor(31.6211, device='cuda:0')
min of grad d_p:  tensor(-1.0740, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3724, device='cuda:0') mean:  tensor(1.3372e-05, device='cuda:0') min:  tensor(-0.3504, device='cuda:0') norm:  tensor(1.7111, device='cuda:0') MSE:  tensor(6.4229e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0246, device='cuda:0') mean:  tensor(4.5090e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0718, device='cuda:0') MSE:  tensor(2.6958e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0901, device='cuda:0')
min of d_p_list:  tensor(-0.0758, device='cuda:0')
Epoch:  357  
Training Loss: 2.6033520698547363
Test Loss:  2.885639190673828
Test Acc:  0.0
Valid Loss:  2.881739854812622
Valid Acc:  0.0
std:  0.07947854624662257 
thres:  0.002715434598922729
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 36%|███▌      | 357/1000 [22:47<41:31,  3.88s/it]Epoch:   358
max of grad d_p:  tensor(30.9544, device='cuda:0')
min of grad d_p:  tensor(-1.0306, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2994, device='cuda:0') mean:  tensor(1.7291e-05, device='cuda:0') min:  tensor(-0.4260, device='cuda:0') norm:  tensor(1.8601, device='cuda:0') MSE:  tensor(6.9823e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0738, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.2179, device='cuda:0') MSE:  tensor(8.1801e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0124, device='cuda:0')
min of d_p_list:  tensor(-0.0241, device='cuda:0')
Epoch:  358  
Training Loss: 2.566620111465454
Test Loss:  2.8578543663024902
Test Acc:  0.0
Valid Loss:  2.8491220474243164
Valid Acc:  0.0
std:  0.07916733361601822 
thres:  0.0026656644344329834
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 36%|███▌      | 358/1000 [22:50<40:08,  3.75s/it]Epoch:   359
max of grad d_p:  tensor(30.7597, device='cuda:0')
min of grad d_p:  tensor(-1.0061, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2868, device='cuda:0') mean:  tensor(9.2840e-06, device='cuda:0') min:  tensor(-0.3210, device='cuda:0') norm:  tensor(1.4961, device='cuda:0') MSE:  tensor(5.6160e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0058, device='cuda:0') mean:  tensor(9.9712e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0168, device='cuda:0') MSE:  tensor(6.2919e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0591, device='cuda:0')
min of d_p_list:  tensor(-0.0552, device='cuda:0')
Epoch:  359  
Training Loss: 2.5231103897094727
Test Loss:  2.8215742111206055
Test Acc:  0.0
Valid Loss:  2.8080263137817383
Valid Acc:  0.0
std:  0.07071852566909216 
thres:  0.002614056730270386
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 36%|███▌      | 359/1000 [22:54<40:42,  3.81s/it]Epoch:   360
max of grad d_p:  tensor(30.6216, device='cuda:0')
min of grad d_p:  tensor(-1.0171, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2225, device='cuda:0') mean:  tensor(-1.5835e-05, device='cuda:0') min:  tensor(-0.3765, device='cuda:0') norm:  tensor(1.7322, device='cuda:0') MSE:  tensor(6.5024e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0048, device='cuda:0') mean:  tensor(8.6064e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0142, device='cuda:0') MSE:  tensor(5.3173e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0156, device='cuda:0')
min of d_p_list:  tensor(-0.0083, device='cuda:0')
Epoch:  360  
Training Loss: 2.4959876537323
Test Loss:  2.792452335357666
Test Acc:  0.0
Valid Loss:  2.77742075920105
Valid Acc:  0.0
std:  0.054573906195408625 
thres:  0.002567464542388916
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 36%|███▌      | 360/1000 [22:58<40:23,  3.79s/it]Epoch:   361
max of grad d_p:  tensor(30.4154, device='cuda:0')
min of grad d_p:  tensor(-1.0179, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2667, device='cuda:0') mean:  tensor(6.1330e-06, device='cuda:0') min:  tensor(-0.4157, device='cuda:0') norm:  tensor(1.8251, device='cuda:0') MSE:  tensor(6.8511e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0065, device='cuda:0') mean:  tensor(1.9628e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0299, device='cuda:0') MSE:  tensor(1.1238e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0484, device='cuda:0')
min of d_p_list:  tensor(-0.0372, device='cuda:0')
Epoch:  361  
Training Loss: 2.4633495807647705
Test Loss:  2.75673508644104
Test Acc:  0.0
Valid Loss:  2.736649513244629
Valid Acc:  0.0
std:  0.04973323322845618 
thres:  0.002530483961105347
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 36%|███▌      | 361/1000 [23:02<40:23,  3.79s/it]Epoch:   362
max of grad d_p:  tensor(30.2993, device='cuda:0')
min of grad d_p:  tensor(-1.0115, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2571, device='cuda:0') mean:  tensor(-1.9783e-05, device='cuda:0') min:  tensor(-0.4666, device='cuda:0') norm:  tensor(1.9157, device='cuda:0') MSE:  tensor(7.1911e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0099, device='cuda:0') mean:  tensor(2.7144e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0417, device='cuda:0') MSE:  tensor(1.5656e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0699, device='cuda:0')
min of d_p_list:  tensor(-0.0535, device='cuda:0')
Epoch:  362  
Training Loss: 2.421215057373047
Test Loss:  2.7205233573913574
Test Acc:  0.0
Valid Loss:  2.700037956237793
Valid Acc:  0.0
std:  0.049723487857902315 
thres:  0.002494056558609009
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 36%|███▌      | 362/1000 [23:06<40:44,  3.83s/it]Epoch:   363
max of grad d_p:  tensor(29.9050, device='cuda:0')
min of grad d_p:  tensor(-0.9956, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1593, device='cuda:0') mean:  tensor(-2.4769e-05, device='cuda:0') min:  tensor(-0.2723, device='cuda:0') norm:  tensor(1.3209, device='cuda:0') MSE:  tensor(4.9584e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0030, device='cuda:0') mean:  tensor(6.1703e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0101, device='cuda:0') MSE:  tensor(3.8030e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0280, device='cuda:0')
min of d_p_list:  tensor(-0.0628, device='cuda:0')
Epoch:  363  
Training Loss: 2.390740394592285
Test Loss:  2.691671848297119
Test Acc:  0.0
Valid Loss:  2.6732630729675293
Valid Acc:  0.0
std:  0.048133464047953135 
thres:  0.0024588806152343753
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  31
 36%|███▋      | 363/1000 [23:10<41:31,  3.91s/it]Epoch:   364
max of grad d_p:  tensor(29.8670, device='cuda:0')
min of grad d_p:  tensor(-0.9535, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3081, device='cuda:0') mean:  tensor(-2.2941e-06, device='cuda:0') min:  tensor(-0.3730, device='cuda:0') norm:  tensor(1.6903, device='cuda:0') MSE:  tensor(6.3449e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0290, device='cuda:0') mean:  tensor(5.4333e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0832, device='cuda:0') MSE:  tensor(3.1234e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2457, device='cuda:0')
min of d_p_list:  tensor(-0.0821, device='cuda:0')
Epoch:  364  
Training Loss: 2.1773934364318848
Test Loss:  2.443967342376709
Test Acc:  0.0
Valid Loss:  2.446136951446533
Valid Acc:  0.0
std:  0.1120621946515716 
thres:  0.0023897372245788575
Preserved_eigens number check:  31
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 36%|███▋      | 364/1000 [23:14<41:20,  3.90s/it]Epoch:   365
max of grad d_p:  tensor(27.5500, device='cuda:0')
min of grad d_p:  tensor(-0.9560, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2732, device='cuda:0') mean:  tensor(8.0155e-06, device='cuda:0') min:  tensor(-0.3900, device='cuda:0') norm:  tensor(1.7151, device='cuda:0') MSE:  tensor(6.4379e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0078, device='cuda:0') mean:  tensor(1.5829e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0247, device='cuda:0') MSE:  tensor(9.2876e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0145, device='cuda:0')
min of d_p_list:  tensor(-0.0318, device='cuda:0')
Epoch:  365  
Training Loss: 2.1468353271484375
Test Loss:  2.4060707092285156
Test Acc:  0.0
Valid Loss:  2.4040753841400146
Valid Acc:  0.0
std:  0.13124053184809667 
thres:  0.0023199067592620847
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  42
 36%|███▋      | 365/1000 [23:18<41:32,  3.92s/it]Epoch:   366
max of grad d_p:  tensor(27.4462, device='cuda:0')
min of grad d_p:  tensor(-0.9675, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2488, device='cuda:0') mean:  tensor(-8.5206e-06, device='cuda:0') min:  tensor(-0.3924, device='cuda:0') norm:  tensor(1.7661, device='cuda:0') MSE:  tensor(6.6293e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1014, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(5.8208e-11, device='cuda:0') norm:  tensor(0.4085, device='cuda:0') MSE:  tensor(1.5333e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0167, device='cuda:0')
min of d_p_list:  tensor(-0.0284, device='cuda:0')
Epoch:  366  
Training Loss: 2.1073408126831055
Test Loss:  2.382193088531494
Test Acc:  0.0
Valid Loss:  2.3717756271362305
Valid Acc:  0.0
std:  0.13067545753737975 
thres:  0.0022487050056457522
Preserved_eigens number check:  42
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  42
 37%|███▋      | 366/1000 [23:21<41:18,  3.91s/it]Epoch:   367
max of grad d_p:  tensor(27.3652, device='cuda:0')
min of grad d_p:  tensor(-0.9723, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3113, device='cuda:0') mean:  tensor(2.6039e-06, device='cuda:0') min:  tensor(-0.3327, device='cuda:0') norm:  tensor(1.5474, device='cuda:0') MSE:  tensor(5.8086e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0421, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(7.2760e-11, device='cuda:0') norm:  tensor(0.1614, device='cuda:0') MSE:  tensor(6.0588e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0274, device='cuda:0')
min of d_p_list:  tensor(-0.0242, device='cuda:0')
Epoch:  367  
Training Loss: 2.066997528076172
Test Loss:  2.350778579711914
Test Acc:  0.0
Valid Loss:  2.3321146965026855
Valid Acc:  0.0
std:  0.11273353880591759 
thres:  0.002177861499786377
Preserved_eigens number check:  42
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 37%|███▋      | 367/1000 [23:25<41:04,  3.89s/it]Epoch:   368
max of grad d_p:  tensor(27.1895, device='cuda:0')
min of grad d_p:  tensor(-0.9794, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4615, device='cuda:0') mean:  tensor(3.2183e-07, device='cuda:0') min:  tensor(-0.3032, device='cuda:0') norm:  tensor(1.5764, device='cuda:0') MSE:  tensor(5.9175e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0056, device='cuda:0') mean:  tensor(1.9212e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0289, device='cuda:0') MSE:  tensor(1.0831e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0163, device='cuda:0')
min of d_p_list:  tensor(-0.0199, device='cuda:0')
Epoch:  368  
Training Loss: 2.039280891418457
Test Loss:  2.317286252975464
Test Acc:  0.0
Valid Loss:  2.2965147495269775
Valid Acc:  0.0
std:  0.05045128055089522 
thres:  0.0021075695991516112
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 37%|███▋      | 368/1000 [23:29<40:31,  3.85s/it]Epoch:   369
max of grad d_p:  tensor(27.0322, device='cuda:0')
min of grad d_p:  tensor(-0.9622, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2266, device='cuda:0') mean:  tensor(-1.2531e-05, device='cuda:0') min:  tensor(-0.3585, device='cuda:0') norm:  tensor(1.5917, device='cuda:0') MSE:  tensor(5.9750e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0449, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(1.0426e-10, device='cuda:0') norm:  tensor(0.1746, device='cuda:0') MSE:  tensor(6.5522e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0120, device='cuda:0')
min of d_p_list:  tensor(-0.0098, device='cuda:0')
Epoch:  369  
Training Loss: 2.010796070098877
Test Loss:  2.2926907539367676
Test Acc:  0.0
Valid Loss:  2.2711665630340576
Valid Acc:  0.0
std:  0.0483021111859205 
thres:  0.0020742501258850096
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 37%|███▋      | 369/1000 [23:33<39:59,  3.80s/it]Epoch:   370
max of grad d_p:  tensor(26.9182, device='cuda:0')
min of grad d_p:  tensor(-0.9300, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2415, device='cuda:0') mean:  tensor(-5.5351e-06, device='cuda:0') min:  tensor(-0.3755, device='cuda:0') norm:  tensor(1.6818, device='cuda:0') MSE:  tensor(6.3130e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0030, device='cuda:0') mean:  tensor(6.8341e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0114, device='cuda:0') MSE:  tensor(4.2645e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0132, device='cuda:0')
min of d_p_list:  tensor(-0.0112, device='cuda:0')
Epoch:  370  
Training Loss: 1.9887983798980713
Test Loss:  2.26444673538208
Test Acc:  0.0
Valid Loss:  2.2430248260498047
Valid Acc:  0.0
std:  0.041722233486729994 
thres:  0.0020426427364349364
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 37%|███▋      | 370/1000 [23:37<40:02,  3.81s/it]Epoch:   371
max of grad d_p:  tensor(26.7046, device='cuda:0')
min of grad d_p:  tensor(-0.9323, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1927, device='cuda:0') mean:  tensor(-1.7587e-05, device='cuda:0') min:  tensor(-0.3091, device='cuda:0') norm:  tensor(1.4511, device='cuda:0') MSE:  tensor(5.4469e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0046, device='cuda:0') mean:  tensor(9.5636e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0145, device='cuda:0') MSE:  tensor(5.4459e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0095, device='cuda:0')
min of d_p_list:  tensor(-0.0127, device='cuda:0')
Epoch:  371  
Training Loss: 1.9642809629440308
Test Loss:  2.237778663635254
Test Acc:  0.0
Valid Loss:  2.2198097705841064
Valid Acc:  0.0
std:  0.03623596607946001 
thres:  0.0020140307664871216
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 37%|███▋      | 371/1000 [23:41<40:50,  3.90s/it]Epoch:   372
max of grad d_p:  tensor(26.5634, device='cuda:0')
min of grad d_p:  tensor(-0.8918, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2119, device='cuda:0') mean:  tensor(-1.3988e-05, device='cuda:0') min:  tensor(-0.3326, device='cuda:0') norm:  tensor(1.5130, device='cuda:0') MSE:  tensor(5.6795e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0056, device='cuda:0') mean:  tensor(1.9768e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0288, device='cuda:0') MSE:  tensor(1.0823e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0301, device='cuda:0')
min of d_p_list:  tensor(-0.0510, device='cuda:0')
Epoch:  372  
Training Loss: 1.938637614250183
Test Loss:  2.2047204971313477
Test Acc:  0.0
Valid Loss:  2.185894012451172
Valid Acc:  0.0
std:  0.035067427234020794 
thres:  0.001988358783721924
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 37%|███▋      | 372/1000 [23:45<40:44,  3.89s/it]Epoch:   373
max of grad d_p:  tensor(26.5546, device='cuda:0')
min of grad d_p:  tensor(-0.8942, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2604, device='cuda:0') mean:  tensor(-6.4715e-06, device='cuda:0') min:  tensor(-0.3738, device='cuda:0') norm:  tensor(1.6272, device='cuda:0') MSE:  tensor(6.1080e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0045, device='cuda:0') mean:  tensor(1.3054e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0198, device='cuda:0') MSE:  tensor(7.4432e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0278, device='cuda:0')
min of d_p_list:  tensor(-0.0233, device='cuda:0')
Epoch:  373  
Training Loss: 1.9122881889343262
Test Loss:  2.175236225128174
Test Acc:  0.0
Valid Loss:  2.1624879837036133
Valid Acc:  0.0
std:  0.03497675601396926 
thres:  0.0019629602432250978
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 37%|███▋      | 373/1000 [23:49<40:57,  3.92s/it]Epoch:   374
max of grad d_p:  tensor(26.3294, device='cuda:0')
min of grad d_p:  tensor(-0.8808, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3823, device='cuda:0') mean:  tensor(-1.2545e-05, device='cuda:0') min:  tensor(-0.2713, device='cuda:0') norm:  tensor(1.3776, device='cuda:0') MSE:  tensor(5.1712e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0031, device='cuda:0') mean:  tensor(7.8938e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0123, device='cuda:0') MSE:  tensor(4.6111e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0482, device='cuda:0')
min of d_p_list:  tensor(-0.0464, device='cuda:0')
Epoch:  374  
Training Loss: 1.8804011344909668
Test Loss:  2.1483142375946045
Test Acc:  0.0
Valid Loss:  2.1341018676757812
Valid Acc:  0.0
std:  0.03806320943415393 
thres:  0.0019368812561035157
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 37%|███▋      | 374/1000 [23:52<40:36,  3.89s/it]Epoch:   375
max of grad d_p:  tensor(25.9887, device='cuda:0')
min of grad d_p:  tensor(-0.8591, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4214, device='cuda:0') mean:  tensor(-1.2626e-05, device='cuda:0') min:  tensor(-0.2989, device='cuda:0') norm:  tensor(1.5382, device='cuda:0') MSE:  tensor(5.7740e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0022, device='cuda:0') mean:  tensor(5.5018e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0085, device='cuda:0') MSE:  tensor(3.1899e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0232, device='cuda:0')
min of d_p_list:  tensor(-0.0154, device='cuda:0')
Epoch:  375  
Training Loss: 1.8579002618789673
Test Loss:  2.1181087493896484
Test Acc:  0.0
Valid Loss:  2.104551315307617
Valid Acc:  0.0
std:  0.038366093904778964 
thres:  0.0019107016324996949
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 38%|███▊      | 375/1000 [23:56<40:36,  3.90s/it]Epoch:   376
max of grad d_p:  tensor(25.8653, device='cuda:0')
min of grad d_p:  tensor(-0.8262, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2418, device='cuda:0') mean:  tensor(-6.8785e-06, device='cuda:0') min:  tensor(-0.2899, device='cuda:0') norm:  tensor(1.3994, device='cuda:0') MSE:  tensor(5.2529e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0013, device='cuda:0') mean:  tensor(4.5294e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0070, device='cuda:0') MSE:  tensor(2.6201e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0439, device='cuda:0')
min of d_p_list:  tensor(-0.0429, device='cuda:0')
Epoch:  376  
Training Loss: 1.821575403213501
Test Loss:  2.0784575939178467
Test Acc:  0.0
Valid Loss:  2.0678482055664062
Valid Acc:  0.0
std:  0.04088899741461677 
thres:  0.001882160520553589
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 38%|███▊      | 376/1000 [24:00<40:36,  3.90s/it]Epoch:   377
max of grad d_p:  tensor(25.6657, device='cuda:0')
min of grad d_p:  tensor(-0.8004, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3286, device='cuda:0') mean:  tensor(-2.1047e-05, device='cuda:0') min:  tensor(-0.2503, device='cuda:0') norm:  tensor(1.2795, device='cuda:0') MSE:  tensor(4.8031e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0107, device='cuda:0') mean:  tensor(3.4618e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0508, device='cuda:0') MSE:  tensor(1.9077e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0241, device='cuda:0')
min of d_p_list:  tensor(-0.0129, device='cuda:0')
Epoch:  377  
Training Loss: 1.6575127840042114
Test Loss:  1.8838194608688354
Test Acc:  0.0
Valid Loss:  1.8740190267562866
Valid Acc:  0.0
std:  0.08925274218313073 
thres:  0.0018259355545043945
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 38%|███▊      | 377/1000 [24:04<39:38,  3.82s/it]Epoch:   378
max of grad d_p:  tensor(24.3917, device='cuda:0')
min of grad d_p:  tensor(-0.7727, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1884, device='cuda:0') mean:  tensor(-2.2612e-05, device='cuda:0') min:  tensor(-0.2875, device='cuda:0') norm:  tensor(1.4121, device='cuda:0') MSE:  tensor(5.3008e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0082, device='cuda:0') mean:  tensor(2.8158e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0403, device='cuda:0') MSE:  tensor(1.5136e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0407, device='cuda:0')
min of d_p_list:  tensor(-0.0242, device='cuda:0')
Epoch:  378  
Training Loss: 1.634031057357788
Test Loss:  1.8591911792755127
Test Acc:  0.0
Valid Loss:  1.850984811782837
Valid Acc:  0.0
std:  0.10364884199401739 
thres:  0.001770284128189087
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 38%|███▊      | 378/1000 [24:08<39:46,  3.84s/it]Epoch:   379
max of grad d_p:  tensor(24.1785, device='cuda:0')
min of grad d_p:  tensor(-0.7446, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3095, device='cuda:0') mean:  tensor(-1.6242e-05, device='cuda:0') min:  tensor(-0.2488, device='cuda:0') norm:  tensor(1.3005, device='cuda:0') MSE:  tensor(4.8819e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0049, device='cuda:0') mean:  tensor(1.6407e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0268, device='cuda:0') MSE:  tensor(1.0050e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0184, device='cuda:0')
min of d_p_list:  tensor(-0.0246, device='cuda:0')
Epoch:  379  
Training Loss: 1.6162347793579102
Test Loss:  1.8393449783325195
Test Acc:  0.0
Valid Loss:  1.8311738967895508
Valid Acc:  0.0
std:  0.1013549075230878 
thres:  0.0017174508571624757
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 38%|███▊      | 379/1000 [24:12<39:58,  3.86s/it]Epoch:   380
max of grad d_p:  tensor(24.0532, device='cuda:0')
min of grad d_p:  tensor(-0.7592, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3640, device='cuda:0') mean:  tensor(-1.8232e-05, device='cuda:0') min:  tensor(-0.2589, device='cuda:0') norm:  tensor(1.2158, device='cuda:0') MSE:  tensor(4.5639e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0066, device='cuda:0') mean:  tensor(2.0541e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0365, device='cuda:0') MSE:  tensor(1.3701e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.3091, device='cuda:0')
min of d_p_list:  tensor(-0.3433, device='cuda:0')
Epoch:  380  
Training Loss: 1.495570182800293
Test Loss:  1.7187910079956055
Test Acc:  0.0
Valid Loss:  1.6831021308898926
Valid Acc:  0.0
std:  0.10451073392167598 
thres:  0.0016449848413467407
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 38%|███▊      | 380/1000 [24:15<39:27,  3.82s/it]Epoch:   381
max of grad d_p:  tensor(22.8203, device='cuda:0')
min of grad d_p:  tensor(-0.6954, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2565, device='cuda:0') mean:  tensor(-4.8096e-05, device='cuda:0') min:  tensor(-0.2169, device='cuda:0') norm:  tensor(0.9961, device='cuda:0') MSE:  tensor(3.7391e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0038, device='cuda:0') mean:  tensor(1.0877e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0170, device='cuda:0') MSE:  tensor(6.3749e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0202, device='cuda:0')
min of d_p_list:  tensor(-0.0141, device='cuda:0')
Epoch:  381  
Training Loss: 1.4777615070343018
Test Loss:  1.6959686279296875
Test Acc:  0.0
Valid Loss:  1.6608284711837769
Valid Acc:  0.0
std:  0.0744987053326488 
thres:  0.001576222062110901
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 38%|███▊      | 381/1000 [24:19<38:11,  3.70s/it]Epoch:   382
max of grad d_p:  tensor(22.6829, device='cuda:0')
min of grad d_p:  tensor(-0.6995, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2132, device='cuda:0') mean:  tensor(-4.7793e-05, device='cuda:0') min:  tensor(-0.2052, device='cuda:0') norm:  tensor(0.9536, device='cuda:0') MSE:  tensor(3.5797e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0045, device='cuda:0') mean:  tensor(1.2308e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0204, device='cuda:0') MSE:  tensor(7.6598e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0615, device='cuda:0')
min of d_p_list:  tensor(-0.1101, device='cuda:0')
Epoch:  382  
Training Loss: 1.4359321594238281
Test Loss:  1.6569534540176392
Test Acc:  0.0
Valid Loss:  1.6212401390075684
Valid Acc:  0.0
std:  0.0787448616397672 
thres:  0.0015319059371948242
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 38%|███▊      | 382/1000 [24:22<38:03,  3.70s/it]Epoch:   383
max of grad d_p:  tensor(22.4606, device='cuda:0')
min of grad d_p:  tensor(-0.6480, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3401, device='cuda:0') mean:  tensor(-3.0809e-05, device='cuda:0') min:  tensor(-0.1529, device='cuda:0') norm:  tensor(1.0234, device='cuda:0') MSE:  tensor(3.8417e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0023, device='cuda:0') mean:  tensor(5.4432e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0093, device='cuda:0') MSE:  tensor(3.5054e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0220, device='cuda:0')
min of d_p_list:  tensor(-0.0133, device='cuda:0')
Epoch:  383  
Training Loss: 1.4209692478179932
Test Loss:  1.6393390893936157
Test Acc:  0.0
Valid Loss:  1.6037949323654175
Valid Acc:  0.0
std:  0.06899580873944115 
thres:  0.0014892935752868653
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 38%|███▊      | 383/1000 [24:26<38:46,  3.77s/it]Epoch:   384
max of grad d_p:  tensor(22.2707, device='cuda:0')
min of grad d_p:  tensor(-0.6477, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3974, device='cuda:0') mean:  tensor(-3.1313e-05, device='cuda:0') min:  tensor(-0.1527, device='cuda:0') norm:  tensor(1.0905, device='cuda:0') MSE:  tensor(4.0933e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0062, device='cuda:0') mean:  tensor(8.4559e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0144, device='cuda:0') MSE:  tensor(5.4198e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0041, device='cuda:0')
min of d_p_list:  tensor(-0.0048, device='cuda:0')
Epoch:  384  
Training Loss: 1.4064840078353882
Test Loss:  1.6236917972564697
Test Acc:  0.0
Valid Loss:  1.5886635780334473
Valid Acc:  0.0
std:  0.03390099130610531 
thres:  0.0014473434209823608
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 38%|███▊      | 384/1000 [24:30<38:52,  3.79s/it]Epoch:   385
max of grad d_p:  tensor(22.1464, device='cuda:0')
min of grad d_p:  tensor(-0.6431, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1523, device='cuda:0') mean:  tensor(-4.6355e-05, device='cuda:0') min:  tensor(-0.2609, device='cuda:0') norm:  tensor(0.9490, device='cuda:0') MSE:  tensor(3.5622e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0019, device='cuda:0') mean:  tensor(5.2426e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0091, device='cuda:0') MSE:  tensor(3.4091e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1421, device='cuda:0')
min of d_p_list:  tensor(-0.0595, device='cuda:0')
Epoch:  385  
Training Loss: 1.3858428001403809
Test Loss:  1.6004831790924072
Test Acc:  0.0
Valid Loss:  1.5690118074417114
Valid Acc:  0.0
std:  0.030967312331261845 
thres:  0.0014253979444503785
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 38%|███▊      | 385/1000 [24:34<39:03,  3.81s/it]Epoch:   386
max of grad d_p:  tensor(21.6421, device='cuda:0')
min of grad d_p:  tensor(-0.6212, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3231, device='cuda:0') mean:  tensor(-2.3515e-05, device='cuda:0') min:  tensor(-0.1472, device='cuda:0') norm:  tensor(0.9517, device='cuda:0') MSE:  tensor(3.5726e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1760, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(4.9477e-10, device='cuda:0') norm:  tensor(0.5191, device='cuda:0') MSE:  tensor(1.9484e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0348, device='cuda:0')
min of d_p_list:  tensor(-0.0241, device='cuda:0')
Epoch:  386  
Training Loss: 1.3653202056884766
Test Loss:  1.5787347555160522
Test Acc:  0.0
Valid Loss:  1.5448510646820068
Valid Acc:  0.0
std:  0.025034595757487052 
thres:  0.0014029096841812133
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 39%|███▊      | 386/1000 [24:38<39:01,  3.81s/it]Epoch:   387
max of grad d_p:  tensor(21.4579, device='cuda:0')
min of grad d_p:  tensor(-0.6352, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1621, device='cuda:0') mean:  tensor(-3.0508e-05, device='cuda:0') min:  tensor(-0.2363, device='cuda:0') norm:  tensor(0.8780, device='cuda:0') MSE:  tensor(3.2956e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0079, device='cuda:0') mean:  tensor(1.4332e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0252, device='cuda:0') MSE:  tensor(9.4482e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0324, device='cuda:0')
min of d_p_list:  tensor(-0.0190, device='cuda:0')
Epoch:  387  
Training Loss: 1.3316447734832764
Test Loss:  1.5419543981552124
Test Acc:  0.0
Valid Loss:  1.5037823915481567
Valid Acc:  0.0
std:  0.03145373356559459 
thres:  0.001382052206993103
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 39%|███▊      | 387/1000 [24:42<39:38,  3.88s/it]Epoch:   388
max of grad d_p:  tensor(21.3415, device='cuda:0')
min of grad d_p:  tensor(-0.5845, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1115, device='cuda:0') mean:  tensor(-4.0046e-05, device='cuda:0') min:  tensor(-0.3176, device='cuda:0') norm:  tensor(0.8947, device='cuda:0') MSE:  tensor(3.3586e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0049, device='cuda:0') mean:  tensor(7.7290e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0133, device='cuda:0') MSE:  tensor(4.9791e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0254, device='cuda:0')
min of d_p_list:  tensor(-0.0334, device='cuda:0')
Epoch:  388  
Training Loss: 1.3122406005859375
Test Loss:  1.5207735300064087
Test Acc:  0.0
Valid Loss:  1.4832749366760254
Valid Acc:  0.0
std:  0.034471516801200745 
thres:  0.001360306477546692
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 39%|███▉      | 388/1000 [24:46<39:40,  3.89s/it]Epoch:   389
max of grad d_p:  tensor(21.2468, device='cuda:0')
min of grad d_p:  tensor(-0.5528, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2266, device='cuda:0') mean:  tensor(-3.4630e-05, device='cuda:0') min:  tensor(-0.2366, device='cuda:0') norm:  tensor(0.9454, device='cuda:0') MSE:  tensor(3.5486e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0028, device='cuda:0') mean:  tensor(5.9106e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0098, device='cuda:0') MSE:  tensor(3.6785e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0165, device='cuda:0')
min of d_p_list:  tensor(-0.0151, device='cuda:0')
Epoch:  389  
Training Loss: 1.2990912199020386
Test Loss:  1.505735993385315
Test Acc:  0.0
Valid Loss:  1.4686654806137085
Valid Acc:  0.0
std:  0.03240286603927397 
thres:  0.001338827919960022
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 39%|███▉      | 389/1000 [24:50<39:44,  3.90s/it]Epoch:   390
max of grad d_p:  tensor(21.1251, device='cuda:0')
min of grad d_p:  tensor(-0.5469, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2827, device='cuda:0') mean:  tensor(-2.4671e-05, device='cuda:0') min:  tensor(-0.1536, device='cuda:0') norm:  tensor(0.8901, device='cuda:0') MSE:  tensor(3.3412e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0024, device='cuda:0') mean:  tensor(3.6847e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0067, device='cuda:0') MSE:  tensor(2.5126e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0284, device='cuda:0')
min of d_p_list:  tensor(-0.0387, device='cuda:0')
Epoch:  390  
Training Loss: 1.2855629920959473
Test Loss:  1.4921770095825195
Test Acc:  0.0
Valid Loss:  1.4558916091918945
Valid Acc:  0.0
std:  0.02780386390234839 
thres:  0.0013187719583511353
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 39%|███▉      | 390/1000 [24:54<40:16,  3.96s/it]Epoch:   391
max of grad d_p:  tensor(21.0722, device='cuda:0')
min of grad d_p:  tensor(-0.5499, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1085, device='cuda:0') mean:  tensor(-3.4578e-05, device='cuda:0') min:  tensor(-0.2980, device='cuda:0') norm:  tensor(0.8730, device='cuda:0') MSE:  tensor(3.2770e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0024, device='cuda:0') mean:  tensor(6.9614e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0103, device='cuda:0') MSE:  tensor(3.8760e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0307, device='cuda:0')
min of d_p_list:  tensor(-0.0252, device='cuda:0')
Epoch:  391  
Training Loss: 1.2657012939453125
Test Loss:  1.474043369293213
Test Acc:  0.0
Valid Loss:  1.436289668083191
Valid Acc:  0.0
std:  0.022495532064924613 
thres:  0.0012988481760025023
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 39%|███▉      | 391/1000 [24:58<39:57,  3.94s/it]Epoch:   392
max of grad d_p:  tensor(20.9784, device='cuda:0')
min of grad d_p:  tensor(-0.5395, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2177, device='cuda:0') mean:  tensor(-2.6133e-05, device='cuda:0') min:  tensor(-0.1656, device='cuda:0') norm:  tensor(0.8204, device='cuda:0') MSE:  tensor(3.0796e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0019, device='cuda:0') mean:  tensor(2.7891e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0048, device='cuda:0') MSE:  tensor(1.8078e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0316, device='cuda:0')
min of d_p_list:  tensor(-0.0167, device='cuda:0')
Epoch:  392  
Training Loss: 1.2459795475006104
Test Loss:  1.452001929283142
Test Acc:  0.0
Valid Loss:  1.413667917251587
Valid Acc:  0.0
std:  0.023588190686202194 
thres:  0.0012817151308059692
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 39%|███▉      | 392/1000 [25:01<39:10,  3.87s/it]Epoch:   393
max of grad d_p:  tensor(20.7933, device='cuda:0')
min of grad d_p:  tensor(-0.5197, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3208, device='cuda:0') mean:  tensor(-2.8846e-05, device='cuda:0') min:  tensor(-0.2019, device='cuda:0') norm:  tensor(0.9861, device='cuda:0') MSE:  tensor(3.7014e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0027, device='cuda:0') mean:  tensor(3.1025e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0053, device='cuda:0') MSE:  tensor(1.9890e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0600, device='cuda:0')
min of d_p_list:  tensor(-0.0908, device='cuda:0')
Epoch:  393  
Training Loss: 1.2380582094192505
Test Loss:  1.4389766454696655
Test Acc:  0.0
Valid Loss:  1.3999948501586914
Valid Acc:  0.0
std:  0.023045740374655323 
thres:  0.001266878652572632
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 39%|███▉      | 393/1000 [25:05<39:13,  3.88s/it]Epoch:   394
max of grad d_p:  tensor(20.6772, device='cuda:0')
min of grad d_p:  tensor(-0.5843, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1629, device='cuda:0') mean:  tensor(-2.4606e-05, device='cuda:0') min:  tensor(-0.2189, device='cuda:0') norm:  tensor(0.7914, device='cuda:0') MSE:  tensor(2.9706e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0054, device='cuda:0') mean:  tensor(8.4378e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0141, device='cuda:0') MSE:  tensor(5.2814e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0176, device='cuda:0')
min of d_p_list:  tensor(-0.0106, device='cuda:0')
Epoch:  394  
Training Loss: 1.2247490882873535
Test Loss:  1.4241328239440918
Test Acc:  0.0
Valid Loss:  1.385364294052124
Valid Acc:  0.0
std:  0.02138892673040374 
thres:  0.0012520102262496948
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 39%|███▉      | 394/1000 [25:09<39:31,  3.91s/it]Epoch:   395
max of grad d_p:  tensor(20.5407, device='cuda:0')
min of grad d_p:  tensor(-0.5628, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2576, device='cuda:0') mean:  tensor(-2.4936e-05, device='cuda:0') min:  tensor(-0.1961, device='cuda:0') norm:  tensor(0.9078, device='cuda:0') MSE:  tensor(3.4077e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0014, device='cuda:0') mean:  tensor(3.5074e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0055, device='cuda:0') MSE:  tensor(2.0712e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0223, device='cuda:0')
min of d_p_list:  tensor(-0.0398, device='cuda:0')
Epoch:  395  
Training Loss: 1.2125282287597656
Test Loss:  1.411278247833252
Test Acc:  0.0
Valid Loss:  1.3721946477890015
Valid Acc:  0.0
std:  0.01818601458340896 
thres:  0.0012374032735824585
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 40%|███▉      | 395/1000 [25:13<38:46,  3.85s/it]Epoch:   396
max of grad d_p:  tensor(20.5340, device='cuda:0')
min of grad d_p:  tensor(-0.5735, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2864, device='cuda:0') mean:  tensor(-2.1096e-05, device='cuda:0') min:  tensor(-0.1655, device='cuda:0') norm:  tensor(0.8663, device='cuda:0') MSE:  tensor(3.2517e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0043, device='cuda:0') mean:  tensor(8.4309e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0137, device='cuda:0') MSE:  tensor(5.1518e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0159, device='cuda:0')
min of d_p_list:  tensor(-0.0108, device='cuda:0')
Epoch:  396  
Training Loss: 1.2004507780075073
Test Loss:  1.3973324298858643
Test Acc:  0.0
Valid Loss:  1.3583400249481201
Valid Acc:  0.0
std:  0.016533835845744624 
thres:  0.0012243531703948975
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 40%|███▉      | 396/1000 [25:17<38:49,  3.86s/it]Epoch:   397
max of grad d_p:  tensor(20.4720, device='cuda:0')
min of grad d_p:  tensor(-0.5723, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1139, device='cuda:0') mean:  tensor(-3.4386e-05, device='cuda:0') min:  tensor(-0.3192, device='cuda:0') norm:  tensor(0.8966, device='cuda:0') MSE:  tensor(3.3655e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0013, device='cuda:0') mean:  tensor(2.8989e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0045, device='cuda:0') MSE:  tensor(1.6990e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0151, device='cuda:0')
min of d_p_list:  tensor(-0.0093, device='cuda:0')
Epoch:  397  
Training Loss: 1.1878429651260376
Test Loss:  1.3822195529937744
Test Acc:  0.0
Valid Loss:  1.3438490629196167
Valid Acc:  0.0
std:  0.017641774847712077 
thres:  0.0012127258539199831
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 40%|███▉      | 397/1000 [25:21<38:44,  3.86s/it]Epoch:   398
max of grad d_p:  tensor(20.3531, device='cuda:0')
min of grad d_p:  tensor(-0.5649, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1257, device='cuda:0') mean:  tensor(-2.7679e-05, device='cuda:0') min:  tensor(-0.2518, device='cuda:0') norm:  tensor(0.8069, device='cuda:0') MSE:  tensor(3.0290e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0019, device='cuda:0') mean:  tensor(3.8578e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0057, device='cuda:0') MSE:  tensor(2.1565e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0047, device='cuda:0')
min of d_p_list:  tensor(-0.0051, device='cuda:0')
Epoch:  398  
Training Loss: 1.1732022762298584
Test Loss:  1.367252230644226
Test Acc:  0.0
Valid Loss:  1.329568862915039
Valid Acc:  0.0
std:  0.01808473192059805 
thres:  0.0011997546672821045
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 40%|███▉      | 398/1000 [25:25<39:01,  3.89s/it]Epoch:   399
max of grad d_p:  tensor(20.2534, device='cuda:0')
min of grad d_p:  tensor(-0.5433, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2078, device='cuda:0') mean:  tensor(-2.2923e-05, device='cuda:0') min:  tensor(-0.1887, device='cuda:0') norm:  tensor(0.8912, device='cuda:0') MSE:  tensor(3.3454e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0019, device='cuda:0') mean:  tensor(5.8185e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0093, device='cuda:0') MSE:  tensor(3.4939e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0204, device='cuda:0')
min of d_p_list:  tensor(-0.0214, device='cuda:0')
Epoch:  399  
Training Loss: 1.1611943244934082
Test Loss:  1.3539907932281494
Test Acc:  0.0
Valid Loss:  1.3166759014129639
Valid Acc:  0.0
std:  0.018382736453601146 
thres:  0.0011870437145233156
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 40%|███▉      | 399/1000 [25:29<38:37,  3.86s/it]Epoch:   400
max of grad d_p:  tensor(20.1303, device='cuda:0')
min of grad d_p:  tensor(-0.4975, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1219, device='cuda:0') mean:  tensor(-2.4127e-05, device='cuda:0') min:  tensor(-0.2430, device='cuda:0') norm:  tensor(0.8488, device='cuda:0') MSE:  tensor(3.1863e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0052, device='cuda:0') mean:  tensor(1.0139e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0187, device='cuda:0') MSE:  tensor(7.0342e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0373, device='cuda:0')
min of d_p_list:  tensor(-0.0348, device='cuda:0')
Epoch:  400  
Training Loss: 1.1410102844238281
Test Loss:  1.3325308561325073
Test Acc:  0.0
Valid Loss:  1.2930784225463867
Valid Acc:  0.0
std:  0.02067016180905066 
thres:  0.0011727401256561279
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 40%|████      | 400/1000 [25:33<38:51,  3.89s/it]Epoch:   401
max of grad d_p:  tensor(19.9921, device='cuda:0')
min of grad d_p:  tensor(-0.4363, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3733, device='cuda:0') mean:  tensor(-2.1014e-05, device='cuda:0') min:  tensor(-0.1510, device='cuda:0') norm:  tensor(1.0464, device='cuda:0') MSE:  tensor(3.9278e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0012, device='cuda:0') mean:  tensor(3.9120e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0058, device='cuda:0') MSE:  tensor(2.1842e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0176, device='cuda:0')
min of d_p_list:  tensor(-0.0234, device='cuda:0')
Epoch:  401  
Training Loss: 1.1277470588684082
Test Loss:  1.31911301612854
Test Acc:  0.0
Valid Loss:  1.280168056488037
Valid Acc:  0.0
std:  0.021612994220863893 
thres:  0.001158199381828308
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 40%|████      | 401/1000 [25:37<39:15,  3.93s/it]Epoch:   402
max of grad d_p:  tensor(19.8906, device='cuda:0')
min of grad d_p:  tensor(-0.4442, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3609, device='cuda:0') mean:  tensor(-2.1006e-05, device='cuda:0') min:  tensor(-0.1497, device='cuda:0') norm:  tensor(0.9949, device='cuda:0') MSE:  tensor(3.7347e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0559, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(2.9831e-10, device='cuda:0') norm:  tensor(0.2605, device='cuda:0') MSE:  tensor(9.7784e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0077, device='cuda:0')
min of d_p_list:  tensor(-0.0123, device='cuda:0')
Epoch:  402  
Training Loss: 1.115612506866455
Test Loss:  1.3049449920654297
Test Acc:  0.0
Valid Loss:  1.2665082216262817
Valid Acc:  0.0
std:  0.02110478459574842 
thres:  0.0011437532901763916
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 40%|████      | 402/1000 [25:40<38:39,  3.88s/it]Epoch:   403
max of grad d_p:  tensor(19.8326, device='cuda:0')
min of grad d_p:  tensor(-0.4386, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1260, device='cuda:0') mean:  tensor(-2.5847e-05, device='cuda:0') min:  tensor(-0.2440, device='cuda:0') norm:  tensor(0.7951, device='cuda:0') MSE:  tensor(2.9845e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0090, device='cuda:0') mean:  tensor(9.6950e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0173, device='cuda:0') MSE:  tensor(6.5000e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0073, device='cuda:0')
min of d_p_list:  tensor(-0.0092, device='cuda:0')
Epoch:  403  
Training Loss: 1.1021521091461182
Test Loss:  1.2907700538635254
Test Acc:  0.0
Valid Loss:  1.2528516054153442
Valid Acc:  0.0
std:  0.020400244602335135 
thres:  0.0011295432567596435
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 40%|████      | 403/1000 [25:44<38:10,  3.84s/it]Epoch:   404
max of grad d_p:  tensor(19.7263, device='cuda:0')
min of grad d_p:  tensor(-0.4266, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1278, device='cuda:0') mean:  tensor(-3.0703e-05, device='cuda:0') min:  tensor(-0.2189, device='cuda:0') norm:  tensor(0.9045, device='cuda:0') MSE:  tensor(3.3954e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0015, device='cuda:0') mean:  tensor(5.4109e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0080, device='cuda:0') MSE:  tensor(3.0184e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0420, device='cuda:0')
min of d_p_list:  tensor(-0.0268, device='cuda:0')
Epoch:  404  
Training Loss: 1.0930308103561401
Test Loss:  1.2818242311477661
Test Acc:  0.0
Valid Loss:  1.2431550025939941
Valid Acc:  0.0
std:  0.017221879229332448 
thres:  0.00111591055393219
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 40%|████      | 404/1000 [25:48<37:36,  3.79s/it]Epoch:   405
max of grad d_p:  tensor(19.6343, device='cuda:0')
min of grad d_p:  tensor(-0.4462, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.1118, device='cuda:0') mean:  tensor(-3.3575e-05, device='cuda:0') min:  tensor(-0.2276, device='cuda:0') norm:  tensor(0.7827, device='cuda:0') MSE:  tensor(2.9380e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0073, device='cuda:0') mean:  tensor(9.7303e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0169, device='cuda:0') MSE:  tensor(6.3514e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(1.6482, device='cuda:0')
min of d_p_list:  tensor(-1.4178, device='cuda:0')
Epoch:  405  
Training Loss: 2.240504264831543
Test Loss:  1.870605230331421
Test Acc:  0.0
Valid Loss:  2.0068464279174805
Valid Acc:  0.0
std:  0.4525011781540493 
thres:  0.001335809350013733
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 40%|████      | 405/1000 [25:52<37:36,  3.79s/it]Epoch:   406
max of grad d_p:  tensor(2.8383, device='cuda:0')
min of grad d_p:  tensor(-7.6962, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5739, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3018, device='cuda:0') norm:  tensor(2.4372, device='cuda:0') MSE:  tensor(9.1486e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2803, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(1.7462e-10, device='cuda:0') norm:  tensor(0.9130, device='cuda:0') MSE:  tensor(3.4270e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1236, device='cuda:0')
min of d_p_list:  tensor(-0.1046, device='cuda:0')
Epoch:  406  
Training Loss: 2.1818578243255615
Test Loss:  1.7942543029785156
Test Acc:  0.0
Valid Loss:  1.9678783416748047
Valid Acc:  0.0
std:  0.542966810011848 
thres:  0.0015466315031051636
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 41%|████      | 406/1000 [25:56<38:19,  3.87s/it]Epoch:   407
max of grad d_p:  tensor(2.5476, device='cuda:0')
min of grad d_p:  tensor(-6.5742, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3623, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3214, device='cuda:0') norm:  tensor(2.2113, device='cuda:0') MSE:  tensor(8.3005e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0102, device='cuda:0') mean:  tensor(2.2690e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0346, device='cuda:0') MSE:  tensor(1.2978e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0471, device='cuda:0')
min of d_p_list:  tensor(-0.0925, device='cuda:0')
Epoch:  407  
Training Loss: 2.120852470397949
Test Loss:  1.7378623485565186
Test Acc:  0.0
Valid Loss:  1.9387478828430176
Valid Acc:  0.0
std:  0.5321495374753398 
thres:  0.0017476794958114624
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 41%|████      | 407/1000 [25:59<37:05,  3.75s/it]Epoch:   408
max of grad d_p:  tensor(2.2307, device='cuda:0')
min of grad d_p:  tensor(-6.6817, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3902, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3227, device='cuda:0') norm:  tensor(2.0931, device='cuda:0') MSE:  tensor(7.8571e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0238, device='cuda:0') mean:  tensor(5.8818e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0900, device='cuda:0') MSE:  tensor(3.3775e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0303, device='cuda:0')
min of d_p_list:  tensor(-0.0169, device='cuda:0')
Epoch:  408  
Training Loss: 2.0764122009277344
Test Loss:  1.7016199827194214
Test Acc:  0.0
Valid Loss:  1.901914119720459
Valid Acc:  0.0
std:  0.42835468723162073 
thres:  0.0019425315141677858
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 41%|████      | 408/1000 [26:03<37:23,  3.79s/it]Epoch:   409
max of grad d_p:  tensor(2.2908, device='cuda:0')
min of grad d_p:  tensor(-6.6834, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4512, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.4316, device='cuda:0') norm:  tensor(2.8212, device='cuda:0') MSE:  tensor(1.0590e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0228, device='cuda:0') mean:  tensor(4.8840e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0721, device='cuda:0') MSE:  tensor(2.7046e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0220, device='cuda:0')
min of d_p_list:  tensor(-0.0188, device='cuda:0')
Epoch:  409  
Training Loss: 2.0346062183380127
Test Loss:  1.6626489162445068
Test Acc:  0.0
Valid Loss:  1.8720853328704834
Valid Acc:  0.0
std:  0.07341954229604802 
thres:  0.0021308465957641603
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 41%|████      | 409/1000 [26:06<36:22,  3.69s/it]Epoch:   410
max of grad d_p:  tensor(2.2123, device='cuda:0')
min of grad d_p:  tensor(-6.6766, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2816, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.3521, device='cuda:0') norm:  tensor(2.0234, device='cuda:0') MSE:  tensor(7.5955e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1987, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(2.3283e-10, device='cuda:0') norm:  tensor(0.8655, device='cuda:0') MSE:  tensor(3.2487e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0391, device='cuda:0')
min of d_p_list:  tensor(-0.0408, device='cuda:0')
Epoch:  410  
Training Loss: 2.0053529739379883
Test Loss:  1.638784646987915
Test Acc:  0.0
Valid Loss:  1.8493831157684326
Valid Acc:  0.0
std:  0.06263667418818386 
thres:  0.0020838163375854492
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 41%|████      | 410/1000 [26:10<37:25,  3.81s/it]Epoch:   411
max of grad d_p:  tensor(2.1593, device='cuda:0')
min of grad d_p:  tensor(-6.5579, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3055, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3750, device='cuda:0') norm:  tensor(2.2224, device='cuda:0') MSE:  tensor(8.3424e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0115, device='cuda:0') mean:  tensor(3.2520e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0510, device='cuda:0') MSE:  tensor(1.9141e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0269, device='cuda:0')
min of d_p_list:  tensor(-0.0172, device='cuda:0')
Epoch:  411  
Training Loss: 1.951263189315796
Test Loss:  1.5859098434448242
Test Acc:  0.0
Valid Loss:  1.8068362474441528
Valid Acc:  0.0
std:  0.05820685805248581 
thres:  0.0020376974105834962
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 41%|████      | 411/1000 [26:14<37:18,  3.80s/it]Epoch:   412
max of grad d_p:  tensor(2.0565, device='cuda:0')
min of grad d_p:  tensor(-6.2990, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3794, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.4669, device='cuda:0') norm:  tensor(2.7080, device='cuda:0') MSE:  tensor(1.0165e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0079, device='cuda:0') mean:  tensor(2.5455e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0367, device='cuda:0') MSE:  tensor(1.3786e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0643, device='cuda:0')
min of d_p_list:  tensor(-0.0291, device='cuda:0')
Epoch:  412  
Training Loss: 1.780957818031311
Test Loss:  1.450058937072754
Test Acc:  0.0
Valid Loss:  1.6507081985473633
Valid Acc:  0.0
std:  0.1027958861933106 
thres:  0.0019697184801101683
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 41%|████      | 412/1000 [26:18<37:08,  3.79s/it]Epoch:   413
max of grad d_p:  tensor(1.9843, device='cuda:0')
min of grad d_p:  tensor(-6.1181, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3753, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.4306, device='cuda:0') norm:  tensor(2.5735, device='cuda:0') MSE:  tensor(9.6603e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0083, device='cuda:0') mean:  tensor(2.0786e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0305, device='cuda:0') MSE:  tensor(1.1447e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.4245, device='cuda:0')
min of d_p_list:  tensor(-0.2575, device='cuda:0')
Epoch:  413  
Training Loss: 1.5686845779418945
Test Loss:  1.1422441005706787
Test Acc:  0.0
Valid Loss:  1.4117069244384766
Valid Acc:  0.0
std:  0.17362151012428506 
thres:  0.0018681729555130005
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 41%|████▏     | 413/1000 [26:22<37:23,  3.82s/it]Epoch:   414
max of grad d_p:  tensor(1.3492, device='cuda:0')
min of grad d_p:  tensor(-5.5805, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4719, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.2532, device='cuda:0') norm:  tensor(1.8779, device='cuda:0') MSE:  tensor(7.0490e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3784, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(5.8208e-11, device='cuda:0') norm:  tensor(1.3576, device='cuda:0') MSE:  tensor(5.0961e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0138, device='cuda:0')
min of d_p_list:  tensor(-0.0150, device='cuda:0')
Epoch:  414  
Training Loss: 1.5460706949234009
Test Loss:  1.1243456602096558
Test Acc:  0.0
Valid Loss:  1.4008746147155762
Valid Acc:  0.0
std:  0.18922927239935108 
thres:  0.0017704658508300782
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 41%|████▏     | 414/1000 [26:26<37:54,  3.88s/it]Epoch:   415
max of grad d_p:  tensor(1.3169, device='cuda:0')
min of grad d_p:  tensor(-5.5503, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5601, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.2840, device='cuda:0') norm:  tensor(2.2131, device='cuda:0') MSE:  tensor(8.3076e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0046, device='cuda:0') mean:  tensor(1.7433e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0246, device='cuda:0') MSE:  tensor(9.2240e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0557, device='cuda:0')
min of d_p_list:  tensor(-0.0501, device='cuda:0')
Epoch:  415  
Training Loss: 1.5027105808258057
Test Loss:  1.0891337394714355
Test Acc:  0.0
Valid Loss:  1.3692774772644043
Valid Acc:  0.0
std:  0.17031126598459717 
thres:  0.0016699373722076417
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 42%|████▏     | 415/1000 [26:30<37:04,  3.80s/it]Epoch:   416
max of grad d_p:  tensor(1.4728, device='cuda:0')
min of grad d_p:  tensor(-5.6601, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5970, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.2442, device='cuda:0') norm:  tensor(2.0860, device='cuda:0') MSE:  tensor(7.8304e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0697, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(7.2760e-12, device='cuda:0') norm:  tensor(0.2694, device='cuda:0') MSE:  tensor(1.0112e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0661, device='cuda:0')
min of d_p_list:  tensor(-0.0847, device='cuda:0')
Epoch:  416  
Training Loss: 1.4690889120101929
Test Loss:  1.045332908630371
Test Acc:  0.0
Valid Loss:  1.3337246179580688
Valid Acc:  0.0
std:  0.10929512199495489 
thres:  0.001573502516746521
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  37
 42%|████▏     | 416/1000 [26:33<36:57,  3.80s/it]Epoch:   417
max of grad d_p:  tensor(1.3680, device='cuda:0')
min of grad d_p:  tensor(-5.6507, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4021, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3278, device='cuda:0') norm:  tensor(2.0465, device='cuda:0') MSE:  tensor(7.6820e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0174, device='cuda:0') mean:  tensor(2.4792e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0413, device='cuda:0') MSE:  tensor(1.5506e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0237, device='cuda:0')
min of d_p_list:  tensor(-0.0252, device='cuda:0')
Epoch:  417  
Training Loss: 1.4337784051895142
Test Loss:  1.0114586353302002
Test Acc:  0.0
Valid Loss:  1.3049196004867554
Valid Acc:  0.0
std:  0.04920474537777284 
thres:  0.0015040666341781617
Preserved_eigens number check:  37
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 42%|████▏     | 417/1000 [26:37<36:52,  3.79s/it]Epoch:   418
max of grad d_p:  tensor(1.3561, device='cuda:0')
min of grad d_p:  tensor(-5.4562, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3729, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3205, device='cuda:0') norm:  tensor(1.9444, device='cuda:0') MSE:  tensor(7.2987e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0172, device='cuda:0') mean:  tensor(3.9011e-05, device='cuda:0') min:  tensor(3.6380e-12, device='cuda:0') norm:  tensor(0.0640, device='cuda:0') MSE:  tensor(2.4023e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0132, device='cuda:0')
min of d_p_list:  tensor(-0.0166, device='cuda:0')
Epoch:  418  
Training Loss: 1.415069818496704
Test Loss:  0.9986547827720642
Test Acc:  0.0
Valid Loss:  1.2945075035095215
Valid Acc:  0.0
std:  0.04718260382760349 
thres:  0.0014733436822891234
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 42%|████▏     | 418/1000 [26:41<36:31,  3.77s/it]Epoch:   419
max of grad d_p:  tensor(1.3884, device='cuda:0')
min of grad d_p:  tensor(-5.4209, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4035, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.2859, device='cuda:0') norm:  tensor(1.9455, device='cuda:0') MSE:  tensor(7.3028e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2582, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(8.1536e-10, device='cuda:0') norm:  tensor(0.7003, device='cuda:0') MSE:  tensor(2.6286e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0101, device='cuda:0')
min of d_p_list:  tensor(-0.0133, device='cuda:0')
Epoch:  419  
Training Loss: 1.2918909788131714
Test Loss:  0.9132370352745056
Test Acc:  0.0
Valid Loss:  1.182356595993042
Valid Acc:  0.0
std:  0.07189630051040599 
thres:  0.0014225077390670777
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 42%|████▏     | 419/1000 [26:45<36:49,  3.80s/it]Epoch:   420
max of grad d_p:  tensor(1.3048, device='cuda:0')
min of grad d_p:  tensor(-5.3520, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4197, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.4697, device='cuda:0') norm:  tensor(2.3979, device='cuda:0') MSE:  tensor(9.0010e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0075, device='cuda:0') mean:  tensor(1.7499e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0267, device='cuda:0') MSE:  tensor(1.0033e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0186, device='cuda:0')
min of d_p_list:  tensor(-0.0395, device='cuda:0')
Epoch:  420  
Training Loss: 1.2743784189224243
Test Loss:  0.901713490486145
Test Acc:  0.0
Valid Loss:  1.175304889678955
Valid Acc:  0.0
std:  0.07864868029898565 
thres:  0.0013768413066864015
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  31
 42%|████▏     | 420/1000 [26:49<37:02,  3.83s/it]Epoch:   421
max of grad d_p:  tensor(1.2905, device='cuda:0')
min of grad d_p:  tensor(-5.2524, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2809, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3739, device='cuda:0') norm:  tensor(2.1278, device='cuda:0') MSE:  tensor(7.9871e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0066, device='cuda:0') mean:  tensor(1.7529e-05, device='cuda:0') min:  tensor(3.6380e-12, device='cuda:0') norm:  tensor(0.0253, device='cuda:0') MSE:  tensor(9.4834e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2815, device='cuda:0')
min of d_p_list:  tensor(-0.3473, device='cuda:0')
Epoch:  421  
Training Loss: 1.1075654029846191
Test Loss:  0.7933253049850464
Test Acc:  0.0
Valid Loss:  1.016271948814392
Valid Acc:  0.0
std:  0.11729289550067808 
thres:  0.0013045366048812866
Preserved_eigens number check:  31
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 42%|████▏     | 421/1000 [26:53<37:25,  3.88s/it]Epoch:   422
max of grad d_p:  tensor(0.9270, device='cuda:0')
min of grad d_p:  tensor(-3.6101, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5085, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3378, device='cuda:0') norm:  tensor(2.0640, device='cuda:0') MSE:  tensor(7.7477e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0112, device='cuda:0') mean:  tensor(3.0179e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0429, device='cuda:0') MSE:  tensor(1.6094e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0984, device='cuda:0')
min of d_p_list:  tensor(-0.0664, device='cuda:0')
Epoch:  422  
Training Loss: 1.0795857906341553
Test Loss:  0.7682132124900818
Test Acc:  0.0
Valid Loss:  0.9935801029205322
Valid Acc:  0.0
std:  0.1245769327902147 
thres:  0.0012336980819702148
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 42%|████▏     | 422/1000 [26:57<37:43,  3.92s/it]Epoch:   423
max of grad d_p:  tensor(0.7937, device='cuda:0')
min of grad d_p:  tensor(-3.6701, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5221, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.2573, device='cuda:0') norm:  tensor(1.8821, device='cuda:0') MSE:  tensor(7.0647e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0197, device='cuda:0') mean:  tensor(4.6755e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0683, device='cuda:0') MSE:  tensor(2.5636e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0250, device='cuda:0')
min of d_p_list:  tensor(-0.0311, device='cuda:0')
Epoch:  423  
Training Loss: 1.063056230545044
Test Loss:  0.7598088979721069
Test Acc:  0.0
Valid Loss:  0.9888017773628235
Valid Acc:  0.0
std:  0.09903260305954194 
thres:  0.001163295364379883
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 42%|████▏     | 423/1000 [27:00<37:28,  3.90s/it]Epoch:   424
max of grad d_p:  tensor(0.7617, device='cuda:0')
min of grad d_p:  tensor(-3.6235, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2914, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3955, device='cuda:0') norm:  tensor(2.0724, device='cuda:0') MSE:  tensor(7.7792e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0029, device='cuda:0') mean:  tensor(1.0550e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0152, device='cuda:0') MSE:  tensor(5.7215e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0537, device='cuda:0')
min of d_p_list:  tensor(-0.0285, device='cuda:0')
Epoch:  424  
Training Loss: 1.0407942533493042
Test Loss:  0.7461504936218262
Test Acc:  0.0
Valid Loss:  0.9804844856262207
Valid Acc:  0.0
std:  0.0835428744876064 
thres:  0.0011130760192871094
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 42%|████▏     | 424/1000 [27:04<37:08,  3.87s/it]Epoch:   425
max of grad d_p:  tensor(0.7711, device='cuda:0')
min of grad d_p:  tensor(-3.6364, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4629, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3882, device='cuda:0') norm:  tensor(2.4582, device='cuda:0') MSE:  tensor(9.2273e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0057, device='cuda:0') mean:  tensor(1.7025e-05, device='cuda:0') min:  tensor(2.5466e-11, device='cuda:0') norm:  tensor(0.0256, device='cuda:0') MSE:  tensor(9.6061e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0315, device='cuda:0')
min of d_p_list:  tensor(-0.0181, device='cuda:0')
Epoch:  425  
Training Loss: 1.0216877460479736
Test Loss:  0.7371973991394043
Test Acc:  0.0
Valid Loss:  0.9751291275024414
Valid Acc:  0.0
std:  0.02986602254814434 
thres:  0.0010625378847122194
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 42%|████▎     | 425/1000 [27:08<36:25,  3.80s/it]Epoch:   426
max of grad d_p:  tensor(0.7756, device='cuda:0')
min of grad d_p:  tensor(-3.6160, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3327, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3411, device='cuda:0') norm:  tensor(2.1208, device='cuda:0') MSE:  tensor(7.9610e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0466, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(2.5466e-10, device='cuda:0') norm:  tensor(0.2183, device='cuda:0') MSE:  tensor(8.1935e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0784, device='cuda:0')
min of d_p_list:  tensor(-0.0686, device='cuda:0')
Epoch:  426  
Training Loss: 1.0097583532333374
Test Loss:  0.7244260311126709
Test Acc:  0.0
Valid Loss:  0.9671026468276978
Valid Acc:  0.0
std:  0.025709353392803808 
thres:  0.001042976474761963
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 43%|████▎     | 426/1000 [27:12<37:15,  3.89s/it]Epoch:   427
max of grad d_p:  tensor(0.7944, device='cuda:0')
min of grad d_p:  tensor(-3.6514, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4367, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.2614, device='cuda:0') norm:  tensor(1.7747, device='cuda:0') MSE:  tensor(6.6619e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0112, device='cuda:0') mean:  tensor(2.3881e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0344, device='cuda:0') MSE:  tensor(1.2898e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0125, device='cuda:0')
min of d_p_list:  tensor(-0.0092, device='cuda:0')
Epoch:  427  
Training Loss: 0.9972115755081177
Test Loss:  0.7111786007881165
Test Acc:  0.0
Valid Loss:  0.9533514976501465
Valid Acc:  0.0
std:  0.023246229762862038 
thres:  0.0010265016317367555
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 43%|████▎     | 427/1000 [27:16<36:58,  3.87s/it]Epoch:   428
max of grad d_p:  tensor(0.7710, device='cuda:0')
min of grad d_p:  tensor(-3.5895, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2537, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3380, device='cuda:0') norm:  tensor(1.9585, device='cuda:0') MSE:  tensor(7.3517e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0109, device='cuda:0') mean:  tensor(2.7597e-05, device='cuda:0') min:  tensor(1.4552e-11, device='cuda:0') norm:  tensor(0.0420, device='cuda:0') MSE:  tensor(1.5754e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0250, device='cuda:0')
min of d_p_list:  tensor(-0.0353, device='cuda:0')
Epoch:  428  
Training Loss: 0.9802654385566711
Test Loss:  0.69781094789505
Test Acc:  0.0
Valid Loss:  0.9414857625961304
Valid Acc:  0.0
std:  0.02065245655643704 
thres:  0.001009943473339081
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 43%|████▎     | 428/1000 [27:19<36:11,  3.80s/it]Epoch:   429
max of grad d_p:  tensor(0.7544, device='cuda:0')
min of grad d_p:  tensor(-3.5447, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.6370, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3117, device='cuda:0') norm:  tensor(2.3408, device='cuda:0') MSE:  tensor(8.7867e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0160, device='cuda:0') mean:  tensor(4.2234e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0668, device='cuda:0') MSE:  tensor(2.5075e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0187, device='cuda:0')
min of d_p_list:  tensor(-0.0302, device='cuda:0')
Epoch:  429  
Training Loss: 0.955859899520874
Test Loss:  0.682388961315155
Test Acc:  0.0
Valid Loss:  0.9231381416320801
Valid Acc:  0.0
std:  0.023078618878681737 
thres:  0.0009929566025733947
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 43%|████▎     | 429/1000 [27:23<35:34,  3.74s/it]Epoch:   430
max of grad d_p:  tensor(0.8494, device='cuda:0')
min of grad d_p:  tensor(-3.4008, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3923, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.2793, device='cuda:0') norm:  tensor(1.9089, device='cuda:0') MSE:  tensor(7.1656e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4081, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(4.0018e-11, device='cuda:0') norm:  tensor(2.1665, device='cuda:0') MSE:  tensor(8.1327e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0559, device='cuda:0')
min of d_p_list:  tensor(-0.0657, device='cuda:0')
Epoch:  430  
Training Loss: 0.9438648223876953
Test Loss:  0.6706949472427368
Test Acc:  0.0
Valid Loss:  0.9149588346481323
Valid Acc:  0.0
std:  0.02464287334616125 
thres:  0.0009773920178413392
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 43%|████▎     | 430/1000 [27:27<36:23,  3.83s/it]Epoch:   431
max of grad d_p:  tensor(0.8519, device='cuda:0')
min of grad d_p:  tensor(-3.3739, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2681, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3290, device='cuda:0') norm:  tensor(2.0614, device='cuda:0') MSE:  tensor(7.7380e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0099, device='cuda:0') mean:  tensor(2.1179e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0308, device='cuda:0') MSE:  tensor(1.1553e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0119, device='cuda:0')
min of d_p_list:  tensor(-0.0137, device='cuda:0')
Epoch:  431  
Training Loss: 0.9324469566345215
Test Loss:  0.661866307258606
Test Acc:  0.0
Valid Loss:  0.9086641073226929
Valid Acc:  0.0
std:  0.023720980102601593 
thres:  0.000961929738521576
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 43%|████▎     | 431/1000 [27:31<36:12,  3.82s/it]Epoch:   432
max of grad d_p:  tensor(0.8501, device='cuda:0')
min of grad d_p:  tensor(-3.3447, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3538, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.2681, device='cuda:0') norm:  tensor(1.7778, device='cuda:0') MSE:  tensor(6.6733e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0184, device='cuda:0') mean:  tensor(4.9240e-05, device='cuda:0') min:  tensor(6.2300e-11, device='cuda:0') norm:  tensor(0.0743, device='cuda:0') MSE:  tensor(2.7905e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0441, device='cuda:0')
min of d_p_list:  tensor(-0.0193, device='cuda:0')
Epoch:  432  
Training Loss: 0.9192669987678528
Test Loss:  0.651294469833374
Test Acc:  0.0
Valid Loss:  0.8938363790512085
Valid Acc:  0.0
std:  0.0208502010476892 
thres:  0.000946340823173523
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 43%|████▎     | 432/1000 [27:35<36:02,  3.81s/it]Epoch:   433
max of grad d_p:  tensor(0.9290, device='cuda:0')
min of grad d_p:  tensor(-3.1645, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3243, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3457, device='cuda:0') norm:  tensor(1.8158, device='cuda:0') MSE:  tensor(6.8160e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0218, device='cuda:0') mean:  tensor(5.6884e-05, device='cuda:0') min:  tensor(5.4115e-11, device='cuda:0') norm:  tensor(0.0828, device='cuda:0') MSE:  tensor(3.1067e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0156, device='cuda:0')
min of d_p_list:  tensor(-0.0079, device='cuda:0')
Epoch:  433  
Training Loss: 0.907896876335144
Test Loss:  0.643941342830658
Test Acc:  0.0
Valid Loss:  0.8865602016448975
Valid Acc:  0.0
std:  0.017048578701232896 
thres:  0.0009318671107292176
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 43%|████▎     | 433/1000 [27:38<35:57,  3.80s/it]Epoch:   434
max of grad d_p:  tensor(0.9250, device='cuda:0')
min of grad d_p:  tensor(-3.1570, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3073, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3624, device='cuda:0') norm:  tensor(2.1358, device='cuda:0') MSE:  tensor(8.0172e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0033, device='cuda:0') mean:  tensor(9.8415e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0150, device='cuda:0') MSE:  tensor(5.6257e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0807, device='cuda:0')
min of d_p_list:  tensor(-0.0315, device='cuda:0')
Epoch:  434  
Training Loss: 0.8911097049713135
Test Loss:  0.6373504400253296
Test Acc:  0.0
Valid Loss:  0.8751872777938843
Valid Acc:  0.0
std:  0.018440525209076148 
thres:  0.0009189170718193054
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 43%|████▎     | 434/1000 [27:42<36:24,  3.86s/it]Epoch:   435
max of grad d_p:  tensor(0.9083, device='cuda:0')
min of grad d_p:  tensor(-3.1760, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4008, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.2854, device='cuda:0') norm:  tensor(2.1253, device='cuda:0') MSE:  tensor(7.9780e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0172, device='cuda:0') mean:  tensor(4.1606e-05, device='cuda:0') min:  tensor(2.2737e-11, device='cuda:0') norm:  tensor(0.0603, device='cuda:0') MSE:  tensor(2.2626e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0177, device='cuda:0')
min of d_p_list:  tensor(-0.0236, device='cuda:0')
Epoch:  435  
Training Loss: 0.8755669593811035
Test Loss:  0.6284484267234802
Test Acc:  0.0
Valid Loss:  0.8654844164848328
Valid Acc:  0.0
std:  0.020120572664124536 
thres:  0.0009052574992179871
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 44%|████▎     | 435/1000 [27:46<35:42,  3.79s/it]Epoch:   436
max of grad d_p:  tensor(0.9047, device='cuda:0')
min of grad d_p:  tensor(-3.1994, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2151, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.2758, device='cuda:0') norm:  tensor(1.7099, device='cuda:0') MSE:  tensor(6.4184e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0442, device='cuda:0') mean:  tensor(7.2842e-05, device='cuda:0') min:  tensor(5.1159e-12, device='cuda:0') norm:  tensor(0.1229, device='cuda:0') MSE:  tensor(4.6140e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0381, device='cuda:0')
min of d_p_list:  tensor(-0.0487, device='cuda:0')
Epoch:  436  
Training Loss: 0.8649052381515503
Test Loss:  0.6196898221969604
Test Acc:  0.0
Valid Loss:  0.8557456731796265
Valid Acc:  0.0
std:  0.020004243815267404 
thres:  0.0008917491555213928
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 44%|████▎     | 436/1000 [27:50<35:39,  3.79s/it]Epoch:   437
max of grad d_p:  tensor(0.8767, device='cuda:0')
min of grad d_p:  tensor(-3.2286, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3139, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.2339, device='cuda:0') norm:  tensor(1.5978, device='cuda:0') MSE:  tensor(5.9977e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0215, device='cuda:0') mean:  tensor(7.2599e-05, device='cuda:0') min:  tensor(2.7740e-11, device='cuda:0') norm:  tensor(0.1123, device='cuda:0') MSE:  tensor(4.2153e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2482, device='cuda:0')
min of d_p_list:  tensor(-0.1380, device='cuda:0')
Epoch:  437  
Training Loss: 0.9002975821495056
Test Loss:  0.7133308053016663
Test Acc:  0.0
Valid Loss:  0.9295374155044556
Valid Acc:  0.0
std:  0.01577799100402026 
thres:  0.0008879552721977234
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 44%|████▎     | 437/1000 [27:54<36:07,  3.85s/it]Epoch:   438
max of grad d_p:  tensor(0.8167, device='cuda:0')
min of grad d_p:  tensor(-5.4460, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.6112, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3128, device='cuda:0') norm:  tensor(2.1565, device='cuda:0') MSE:  tensor(8.0951e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0068, device='cuda:0') mean:  tensor(1.5315e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0244, device='cuda:0') MSE:  tensor(9.1749e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0413, device='cuda:0')
min of d_p_list:  tensor(-0.0421, device='cuda:0')
Epoch:  438  
Training Loss: 0.882866621017456
Test Loss:  0.7068361043930054
Test Acc:  0.0
Valid Loss:  0.9224616289138794
Valid Acc:  0.0
std:  0.012228238300113681 
thres:  0.0008829492211341859
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 44%|████▍     | 438/1000 [27:58<36:28,  3.89s/it]Epoch:   439
max of grad d_p:  tensor(0.8221, device='cuda:0')
min of grad d_p:  tensor(-5.3940, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4833, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.2746, device='cuda:0') norm:  tensor(2.0919, device='cuda:0') MSE:  tensor(7.8525e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0133, device='cuda:0') mean:  tensor(2.8738e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0470, device='cuda:0') MSE:  tensor(1.7658e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0582, device='cuda:0')
min of d_p_list:  tensor(-0.0911, device='cuda:0')
Epoch:  439  
Training Loss: 0.8783010244369507
Test Loss:  0.713572084903717
Test Acc:  0.0
Valid Loss:  0.9378806352615356
Valid Acc:  0.0
std:  0.011574530973613814 
thres:  0.0008803874850273133
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 44%|████▍     | 439/1000 [28:02<35:47,  3.83s/it]Epoch:   440
max of grad d_p:  tensor(0.8662, device='cuda:0')
min of grad d_p:  tensor(-5.5146, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3218, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3897, device='cuda:0') norm:  tensor(2.2492, device='cuda:0') MSE:  tensor(8.4427e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0082, device='cuda:0') mean:  tensor(1.9940e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0282, device='cuda:0') MSE:  tensor(1.0580e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0177, device='cuda:0')
min of d_p_list:  tensor(-0.0382, device='cuda:0')
Epoch:  440  
Training Loss: 0.8662751913070679
Test Loss:  0.7053977847099304
Test Acc:  0.0
Valid Loss:  0.9314317107200623
Valid Acc:  0.0
std:  0.012872457512441865 
thres:  0.0008785291314125062
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 44%|████▍     | 440/1000 [28:05<34:10,  3.66s/it]Epoch:   441
max of grad d_p:  tensor(0.8566, device='cuda:0')
min of grad d_p:  tensor(-5.5011, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2108, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3391, device='cuda:0') norm:  tensor(1.8689, device='cuda:0') MSE:  tensor(7.0153e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0364, device='cuda:0') mean:  tensor(8.5855e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1311, device='cuda:0') MSE:  tensor(4.9228e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1924, device='cuda:0')
min of d_p_list:  tensor(-0.1047, device='cuda:0')
Epoch:  441  
Training Loss: 0.887743353843689
Test Loss:  0.7268502712249756
Test Acc:  0.0
Valid Loss:  0.943444013595581
Valid Acc:  0.0
std:  0.011166703486705459 
thres:  0.0008830967545509339
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  33
 44%|████▍     | 441/1000 [28:09<34:33,  3.71s/it]Epoch:   442
max of grad d_p:  tensor(0.8693, device='cuda:0')
min of grad d_p:  tensor(-5.5464, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3693, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.4001, device='cuda:0') norm:  tensor(1.9424, device='cuda:0') MSE:  tensor(7.2912e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2586, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(1.2369e-10, device='cuda:0') norm:  tensor(1.1606, device='cuda:0') MSE:  tensor(4.3566e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1971, device='cuda:0')
min of d_p_list:  tensor(-0.1922, device='cuda:0')
Epoch:  442  
Training Loss: 0.9063612818717957
Test Loss:  0.8032518625259399
Test Acc:  0.0
Valid Loss:  1.017397165298462
Valid Acc:  0.0
std:  0.013126251592308572 
thres:  0.0008843094944953919
Preserved_eigens number check:  33
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 44%|████▍     | 442/1000 [28:13<34:59,  3.76s/it]Epoch:   443
max of grad d_p:  tensor(0.9810, device='cuda:0')
min of grad d_p:  tensor(-6.5120, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4396, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.3719, device='cuda:0') norm:  tensor(2.0223, device='cuda:0') MSE:  tensor(7.5910e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0319, device='cuda:0') mean:  tensor(7.8306e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1142, device='cuda:0') MSE:  tensor(4.2853e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2704, device='cuda:0')
min of d_p_list:  tensor(-0.1653, device='cuda:0')
Epoch:  443  
Training Loss: 0.9471105337142944
Test Loss:  0.9382201433181763
Test Acc:  0.0
Valid Loss:  1.0999958515167236
Valid Acc:  0.0
std:  0.028206116300206696 
thres:  0.0008971582770347595
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 44%|████▍     | 443/1000 [28:17<35:42,  3.85s/it]Epoch:   444
max of grad d_p:  tensor(1.3435, device='cuda:0')
min of grad d_p:  tensor(-6.9428, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3309, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4901, device='cuda:0') norm:  tensor(1.9116, device='cuda:0') MSE:  tensor(7.1758e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0085, device='cuda:0') mean:  tensor(2.9847e-05, device='cuda:0') min:  tensor(7.2760e-12, device='cuda:0') norm:  tensor(0.0400, device='cuda:0') MSE:  tensor(1.5007e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0519, device='cuda:0')
min of d_p_list:  tensor(-0.0333, device='cuda:0')
Epoch:  444  
Training Loss: 0.9281593561172485
Test Loss:  0.9217478632926941
Test Acc:  0.0
Valid Loss:  1.0828807353973389
Valid Acc:  0.0
std:  0.028587498193639052 
thres:  0.0009071299433708191
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 44%|████▍     | 444/1000 [28:20<35:47,  3.86s/it]Epoch:   445
max of grad d_p:  tensor(1.3291, device='cuda:0')
min of grad d_p:  tensor(-6.9348, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4194, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.4823, device='cuda:0') norm:  tensor(2.0610, device='cuda:0') MSE:  tensor(7.7365e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0126, device='cuda:0') mean:  tensor(4.0897e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0555, device='cuda:0') MSE:  tensor(2.0844e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0912, device='cuda:0')
min of d_p_list:  tensor(-0.0491, device='cuda:0')
Epoch:  445  
Training Loss: 0.9071975946426392
Test Loss:  0.8943666219711304
Test Acc:  0.0
Valid Loss:  1.0563631057739258
Valid Acc:  0.0
std:  0.020406814824507714 
thres:  0.0009153144240379334
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 44%|████▍     | 445/1000 [28:24<35:56,  3.89s/it]Epoch:   446
max of grad d_p:  tensor(1.2896, device='cuda:0')
min of grad d_p:  tensor(-6.6147, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4209, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4352, device='cuda:0') norm:  tensor(1.7117, device='cuda:0') MSE:  tensor(6.4251e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0075, device='cuda:0') mean:  tensor(2.6440e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0409, device='cuda:0') MSE:  tensor(1.5355e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0663, device='cuda:0')
min of d_p_list:  tensor(-0.0468, device='cuda:0')
Epoch:  446  
Training Loss: 0.88936847448349
Test Loss:  0.8840947151184082
Test Acc:  0.0
Valid Loss:  1.0454084873199463
Valid Acc:  0.0
std:  0.019973435556336953 
thres:  0.0009156394481658936
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 45%|████▍     | 446/1000 [28:28<35:34,  3.85s/it]Epoch:   447
max of grad d_p:  tensor(1.3249, device='cuda:0')
min of grad d_p:  tensor(-6.6835, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4814, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.4651, device='cuda:0') norm:  tensor(2.0284, device='cuda:0') MSE:  tensor(7.6142e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3894, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(8.7311e-11, device='cuda:0') norm:  tensor(1.4346, device='cuda:0') MSE:  tensor(5.3850e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0993, device='cuda:0')
min of d_p_list:  tensor(-0.0829, device='cuda:0')
Epoch:  447  
Training Loss: 0.875667154788971
Test Loss:  0.8650728464126587
Test Acc:  0.0
Valid Loss:  1.0287548303604126
Valid Acc:  0.0
std:  0.025760297436831916 
thres:  0.0009095006227493286
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 45%|████▍     | 447/1000 [28:32<35:32,  3.86s/it]Epoch:   448
max of grad d_p:  tensor(1.2699, device='cuda:0')
min of grad d_p:  tensor(-6.6267, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3368, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.5312, device='cuda:0') norm:  tensor(1.9987, device='cuda:0') MSE:  tensor(7.5025e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0051, device='cuda:0') mean:  tensor(1.3535e-05, device='cuda:0') min:  tensor(2.9104e-11, device='cuda:0') norm:  tensor(0.0198, device='cuda:0') MSE:  tensor(7.4264e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0392, device='cuda:0')
min of d_p_list:  tensor(-0.0204, device='cuda:0')
Epoch:  448  
Training Loss: 0.8578435182571411
Test Loss:  0.8430630564689636
Test Acc:  0.0
Valid Loss:  1.0031558275222778
Valid Acc:  0.0
std:  0.024405719215662692 
thres:  0.000891647219657898
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 45%|████▍     | 448/1000 [28:36<35:26,  3.85s/it]Epoch:   449
max of grad d_p:  tensor(1.2212, device='cuda:0')
min of grad d_p:  tensor(-6.3708, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4536, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.4900, device='cuda:0') norm:  tensor(2.1542, device='cuda:0') MSE:  tensor(8.0865e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0257, device='cuda:0') mean:  tensor(9.3507e-05, device='cuda:0') min:  tensor(2.0373e-10, device='cuda:0') norm:  tensor(0.1273, device='cuda:0') MSE:  tensor(4.7793e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0353, device='cuda:0')
min of d_p_list:  tensor(-0.0315, device='cuda:0')
Epoch:  449  
Training Loss: 0.845343291759491
Test Loss:  0.8336119055747986
Test Acc:  0.0
Valid Loss:  0.9911802411079407
Valid Acc:  0.0
std:  0.021988238578939518 
thres:  0.0008750840067863465
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  38
 45%|████▍     | 449/1000 [28:40<35:25,  3.86s/it]Epoch:   450
max of grad d_p:  tensor(1.2063, device='cuda:0')
min of grad d_p:  tensor(-6.4076, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4549, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4700, device='cuda:0') norm:  tensor(1.8850, device='cuda:0') MSE:  tensor(7.0758e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0077, device='cuda:0') mean:  tensor(2.9005e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0453, device='cuda:0') MSE:  tensor(1.6988e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0291, device='cuda:0')
min of d_p_list:  tensor(-0.0329, device='cuda:0')
Epoch:  450  
Training Loss: 0.8272826075553894
Test Loss:  0.8091888427734375
Test Acc:  0.0
Valid Loss:  0.9690735340118408
Valid Acc:  0.0
std:  0.02188069190050566 
thres:  0.0008591010093688964
Preserved_eigens number check:  38
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 45%|████▌     | 450/1000 [28:44<35:47,  3.90s/it]Epoch:   451
max of grad d_p:  tensor(1.1349, device='cuda:0')
min of grad d_p:  tensor(-6.3120, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4568, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-0.5145, device='cuda:0') norm:  tensor(2.0962, device='cuda:0') MSE:  tensor(7.8684e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0062, device='cuda:0') mean:  tensor(1.4041e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0217, device='cuda:0') MSE:  tensor(8.1477e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0569, device='cuda:0')
min of d_p_list:  tensor(-0.0579, device='cuda:0')
Epoch:  451  
Training Loss: 0.8145260810852051
Test Loss:  0.7988390922546387
Test Acc:  0.0
Valid Loss:  0.9566142559051514
Valid Acc:  0.0
std:  0.021653412697958903 
thres:  0.0008441325306892396
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 45%|████▌     | 451/1000 [28:48<35:18,  3.86s/it]Epoch:   452
max of grad d_p:  tensor(1.0715, device='cuda:0')
min of grad d_p:  tensor(-6.3136, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4380, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4163, device='cuda:0') norm:  tensor(1.6909, device='cuda:0') MSE:  tensor(6.3470e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0091, device='cuda:0') mean:  tensor(4.4861e-05, device='cuda:0') min:  tensor(5.0932e-11, device='cuda:0') norm:  tensor(0.0621, device='cuda:0') MSE:  tensor(2.3294e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0066, device='cuda:0')
min of d_p_list:  tensor(-0.0096, device='cuda:0')
Epoch:  452  
Training Loss: 0.75278639793396
Test Loss:  0.7453742027282715
Test Acc:  0.0
Valid Loss:  0.8875077366828918
Valid Acc:  0.0
std:  0.03653518517408216 
thres:  0.0008195563793182373
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  39
 45%|████▌     | 452/1000 [28:51<35:02,  3.84s/it]Epoch:   453
max of grad d_p:  tensor(1.0436, device='cuda:0')
min of grad d_p:  tensor(-6.2755, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5696, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4292, device='cuda:0') norm:  tensor(1.9213, device='cuda:0') MSE:  tensor(7.2122e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0091, device='cuda:0') mean:  tensor(1.9990e-05, device='cuda:0') min:  tensor(2.2737e-12, device='cuda:0') norm:  tensor(0.0301, device='cuda:0') MSE:  tensor(1.1295e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0486, device='cuda:0')
min of d_p_list:  tensor(-0.0359, device='cuda:0')
Epoch:  453  
Training Loss: 0.7383435964584351
Test Loss:  0.7237569093704224
Test Acc:  0.0
Valid Loss:  0.8660472631454468
Valid Acc:  0.0
std:  0.042302868952943266 
thres:  0.0007956563949584961
Preserved_eigens number check:  39
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 45%|████▌     | 453/1000 [28:55<35:17,  3.87s/it]Epoch:   454
max of grad d_p:  tensor(0.9930, device='cuda:0')
min of grad d_p:  tensor(-5.9722, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5309, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.3649, device='cuda:0') norm:  tensor(1.5666, device='cuda:0') MSE:  tensor(5.8806e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0106, device='cuda:0') mean:  tensor(2.7980e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0469, device='cuda:0') MSE:  tensor(1.7588e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0635, device='cuda:0')
min of d_p_list:  tensor(-0.0765, device='cuda:0')
Epoch:  454  
Training Loss: 0.7266858816146851
Test Loss:  0.7146143913269043
Test Acc:  0.0
Valid Loss:  0.8542029857635498
Valid Acc:  0.0
std:  0.041036304436415864 
thres:  0.0007719249129295349
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 45%|████▌     | 454/1000 [28:59<34:55,  3.84s/it]Epoch:   455
max of grad d_p:  tensor(0.9445, device='cuda:0')
min of grad d_p:  tensor(-5.9444, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4162, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.3969, device='cuda:0') norm:  tensor(1.6208, device='cuda:0') MSE:  tensor(6.0840e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0045, device='cuda:0') mean:  tensor(1.0689e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0166, device='cuda:0') MSE:  tensor(6.2495e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0073, device='cuda:0')
min of d_p_list:  tensor(-0.0087, device='cuda:0')
Epoch:  455  
Training Loss: 0.7156091332435608
Test Loss:  0.706342875957489
Test Acc:  0.0
Valid Loss:  0.8434122800827026
Valid Acc:  0.0
std:  0.034735259098978684 
thres:  0.0007495902180671692
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 46%|████▌     | 455/1000 [29:03<34:44,  3.82s/it]Epoch:   456
max of grad d_p:  tensor(0.9394, device='cuda:0')
min of grad d_p:  tensor(-5.8811, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.7649, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.3558, device='cuda:0') norm:  tensor(1.6808, device='cuda:0') MSE:  tensor(6.3093e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0116, device='cuda:0') mean:  tensor(4.3369e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0608, device='cuda:0') MSE:  tensor(2.2839e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0300, device='cuda:0')
min of d_p_list:  tensor(-0.0540, device='cuda:0')
Epoch:  456  
Training Loss: 0.7050655484199524
Test Loss:  0.7014578580856323
Test Acc:  0.0
Valid Loss:  0.8343890905380249
Valid Acc:  0.0
std:  0.01674604062093727 
thres:  0.0007276981115341187
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 46%|████▌     | 456/1000 [29:07<35:04,  3.87s/it]Epoch:   457
max of grad d_p:  tensor(0.9408, device='cuda:0')
min of grad d_p:  tensor(-5.8784, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5239, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4676, device='cuda:0') norm:  tensor(1.8260, device='cuda:0') MSE:  tensor(6.8544e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0278, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1557, device='cuda:0') MSE:  tensor(5.8442e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0197, device='cuda:0')
min of d_p_list:  tensor(-0.0202, device='cuda:0')
Epoch:  457  
Training Loss: 0.694023847579956
Test Loss:  0.6918277144432068
Test Acc:  0.0
Valid Loss:  0.8229316473007202
Valid Acc:  0.0
std:  0.015595357360081162 
thres:  0.0007159456014633179
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  31
 46%|████▌     | 457/1000 [29:11<35:12,  3.89s/it]Epoch:   458
max of grad d_p:  tensor(0.9316, device='cuda:0')
min of grad d_p:  tensor(-5.7643, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.6518, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4471, device='cuda:0') norm:  tensor(1.8687, device='cuda:0') MSE:  tensor(7.0145e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0131, device='cuda:0') mean:  tensor(1.6905e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0290, device='cuda:0') MSE:  tensor(1.0884e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0511, device='cuda:0')
min of d_p_list:  tensor(-0.0934, device='cuda:0')
Epoch:  458  
Training Loss: 0.6798827052116394
Test Loss:  0.6785969138145447
Test Acc:  0.0
Valid Loss:  0.8039321899414062
Valid Acc:  0.0
std:  0.016318106514711102 
thres:  0.0007042534232139588
Preserved_eigens number check:  31
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 46%|████▌     | 458/1000 [29:15<35:24,  3.92s/it]Epoch:   459
max of grad d_p:  tensor(0.9214, device='cuda:0')
min of grad d_p:  tensor(-5.5941, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5318, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4184, device='cuda:0') norm:  tensor(1.6175, device='cuda:0') MSE:  tensor(6.0715e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0062, device='cuda:0') mean:  tensor(1.2281e-05, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0178, device='cuda:0') MSE:  tensor(6.6771e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0071, device='cuda:0')
min of d_p_list:  tensor(-0.0227, device='cuda:0')
Epoch:  459  
Training Loss: 0.6703779697418213
Test Loss:  0.6716349720954895
Test Acc:  0.0
Valid Loss:  0.7954427003860474
Valid Acc:  0.0
std:  0.016380585894732087 
thres:  0.0006929918408393861
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 46%|████▌     | 459/1000 [29:19<35:11,  3.90s/it]Epoch:   460
max of grad d_p:  tensor(0.9130, device='cuda:0')
min of grad d_p:  tensor(-5.5926, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3382, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4799, device='cuda:0') norm:  tensor(1.7605, device='cuda:0') MSE:  tensor(6.6084e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0057, device='cuda:0') mean:  tensor(1.7131e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0245, device='cuda:0') MSE:  tensor(9.2075e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0315, device='cuda:0')
min of d_p_list:  tensor(-0.0254, device='cuda:0')
Epoch:  460  
Training Loss: 0.6606223583221436
Test Loss:  0.6646227240562439
Test Acc:  0.0
Valid Loss:  0.7834057807922363
Valid Acc:  0.0
std:  0.015957132391253005 
thres:  0.0006819944858551026
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 46%|████▌     | 460/1000 [29:22<34:30,  3.83s/it]Epoch:   461
max of grad d_p:  tensor(0.9106, device='cuda:0')
min of grad d_p:  tensor(-5.5856, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3198, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.5001, device='cuda:0') norm:  tensor(1.9937, device='cuda:0') MSE:  tensor(7.4838e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0195, device='cuda:0') mean:  tensor(5.9883e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0923, device='cuda:0') MSE:  tensor(3.4643e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0423, device='cuda:0')
min of d_p_list:  tensor(-0.0527, device='cuda:0')
Epoch:  461  
Training Loss: 0.6533863544464111
Test Loss:  0.657313346862793
Test Acc:  0.0
Valid Loss:  0.7733347415924072
Valid Acc:  0.0
std:  0.014318895262097826 
thres:  0.0006716586470603943
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 46%|████▌     | 461/1000 [29:26<34:25,  3.83s/it]Epoch:   462
max of grad d_p:  tensor(0.8967, device='cuda:0')
min of grad d_p:  tensor(-5.5890, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5026, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4040, device='cuda:0') norm:  tensor(1.5627, device='cuda:0') MSE:  tensor(5.8659e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0035, device='cuda:0') mean:  tensor(9.5476e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0146, device='cuda:0') MSE:  tensor(5.4982e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0125, device='cuda:0')
min of d_p_list:  tensor(-0.0100, device='cuda:0')
Epoch:  462  
Training Loss: 0.6469120979309082
Test Loss:  0.6510927677154541
Test Acc:  0.0
Valid Loss:  0.7655985951423645
Valid Acc:  0.0
std:  0.011776586230088822 
thres:  0.0006622362971305848
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 46%|████▌     | 462/1000 [29:30<34:45,  3.88s/it]Epoch:   463
max of grad d_p:  tensor(0.8944, device='cuda:0')
min of grad d_p:  tensor(-5.5533, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4096, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4802, device='cuda:0') norm:  tensor(1.6517, device='cuda:0') MSE:  tensor(6.2000e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0077, device='cuda:0') mean:  tensor(2.6509e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0409, device='cuda:0') MSE:  tensor(1.5368e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0142, device='cuda:0')
min of d_p_list:  tensor(-0.0126, device='cuda:0')
Epoch:  463  
Training Loss: 0.6392258405685425
Test Loss:  0.6448744535446167
Test Acc:  0.0
Valid Loss:  0.7560092210769653
Valid Acc:  0.0
std:  0.010778953387807998 
thres:  0.0006541049242019654
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 46%|████▋     | 463/1000 [29:34<33:50,  3.78s/it]Epoch:   464
max of grad d_p:  tensor(0.8875, device='cuda:0')
min of grad d_p:  tensor(-5.5002, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2580, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4357, device='cuda:0') norm:  tensor(1.7881, device='cuda:0') MSE:  tensor(6.7120e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0637, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.2068, device='cuda:0') MSE:  tensor(7.7634e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2462, device='cuda:0')
min of d_p_list:  tensor(-0.2427, device='cuda:0')
Epoch:  464  
Training Loss: 0.6248955726623535
Test Loss:  0.6205153465270996
Test Acc:  0.0
Valid Loss:  0.7446610927581787
Valid Acc:  0.0
std:  0.012292873529701747 
thres:  0.0006450084447860718
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 46%|████▋     | 464/1000 [29:37<33:54,  3.80s/it]Epoch:   465
max of grad d_p:  tensor(0.9474, device='cuda:0')
min of grad d_p:  tensor(-5.8228, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.6660, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.3555, device='cuda:0') norm:  tensor(1.7330, device='cuda:0') MSE:  tensor(6.5052e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0247, device='cuda:0') mean:  tensor(3.8414e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0612, device='cuda:0') MSE:  tensor(2.2955e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0092, device='cuda:0')
min of d_p_list:  tensor(-0.0169, device='cuda:0')
Epoch:  465  
Training Loss: 0.616592526435852
Test Loss:  0.61162269115448
Test Acc:  0.0
Valid Loss:  0.7335009574890137
Valid Acc:  0.0
std:  0.013649312060859476 
thres:  0.0006362024784088135
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 46%|████▋     | 465/1000 [29:41<33:54,  3.80s/it]Epoch:   466
max of grad d_p:  tensor(0.9308, device='cuda:0')
min of grad d_p:  tensor(-5.7654, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2723, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4121, device='cuda:0') norm:  tensor(1.8021, device='cuda:0') MSE:  tensor(6.7646e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0061, device='cuda:0') mean:  tensor(1.6781e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0242, device='cuda:0') MSE:  tensor(9.0928e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0300, device='cuda:0')
min of d_p_list:  tensor(-0.0378, device='cuda:0')
Epoch:  466  
Training Loss: 0.6091762185096741
Test Loss:  0.6032395362854004
Test Acc:  0.0
Valid Loss:  0.7238573431968689
Valid Acc:  0.0
std:  0.013969570524715307 
thres:  0.0006273604512214661
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 47%|████▋     | 466/1000 [29:45<34:24,  3.87s/it]Epoch:   467
max of grad d_p:  tensor(0.9206, device='cuda:0')
min of grad d_p:  tensor(-5.7730, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4662, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4279, device='cuda:0') norm:  tensor(1.6475, device='cuda:0') MSE:  tensor(6.1843e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0255, device='cuda:0') mean:  tensor(7.0404e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1081, device='cuda:0') MSE:  tensor(4.0591e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0361, device='cuda:0')
min of d_p_list:  tensor(-0.0252, device='cuda:0')
Epoch:  467  
Training Loss: 0.6022119522094727
Test Loss:  0.5980997085571289
Test Acc:  0.0
Valid Loss:  0.7195029854774475
Valid Acc:  0.0
std:  0.012855380283965564 
thres:  0.0006184204220771789
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 47%|████▋     | 467/1000 [29:49<33:38,  3.79s/it]Epoch:   468
max of grad d_p:  tensor(0.8945, device='cuda:0')
min of grad d_p:  tensor(-5.7012, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3047, device='cuda:0') mean:  tensor(9.7532e-05, device='cuda:0') min:  tensor(-0.3678, device='cuda:0') norm:  tensor(1.5288, device='cuda:0') MSE:  tensor(5.7388e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0120, device='cuda:0') mean:  tensor(3.1446e-05, device='cuda:0') min:  tensor(7.2760e-12, device='cuda:0') norm:  tensor(0.0458, device='cuda:0') MSE:  tensor(1.7183e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0301, device='cuda:0')
min of d_p_list:  tensor(-0.0209, device='cuda:0')
Epoch:  468  
Training Loss: 0.595584511756897
Test Loss:  0.5933127403259277
Test Acc:  0.0
Valid Loss:  0.7114195823669434
Valid Acc:  0.0
std:  0.010334449735644471 
thres:  0.0006096921563148498
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 47%|████▋     | 468/1000 [29:53<34:00,  3.83s/it]Epoch:   469
max of grad d_p:  tensor(0.8962, device='cuda:0')
min of grad d_p:  tensor(-5.6455, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3884, device='cuda:0') mean:  tensor(9.7626e-05, device='cuda:0') min:  tensor(-0.3830, device='cuda:0') norm:  tensor(1.6020, device='cuda:0') MSE:  tensor(6.0135e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0091, device='cuda:0') mean:  tensor(3.1524e-05, device='cuda:0') min:  tensor(4.5475e-11, device='cuda:0') norm:  tensor(0.0497, device='cuda:0') MSE:  tensor(1.8641e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0127, device='cuda:0')
min of d_p_list:  tensor(-0.0099, device='cuda:0')
Epoch:  469  
Training Loss: 0.5807893872261047
Test Loss:  0.5705539584159851
Test Acc:  0.0
Valid Loss:  0.6889432668685913
Valid Acc:  0.0
std:  0.012240582750075555 
thres:  0.0006008709192276001
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 47%|████▋     | 469/1000 [29:57<33:42,  3.81s/it]Epoch:   470
max of grad d_p:  tensor(0.8429, device='cuda:0')
min of grad d_p:  tensor(-5.3199, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2652, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-0.4228, device='cuda:0') norm:  tensor(1.6775, device='cuda:0') MSE:  tensor(6.2969e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0245, device='cuda:0') mean:  tensor(7.9520e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1109, device='cuda:0') MSE:  tensor(4.1614e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0281, device='cuda:0')
min of d_p_list:  tensor(-0.0394, device='cuda:0')
Epoch:  470  
Training Loss: 0.5334441065788269
Test Loss:  0.527567982673645
Test Acc:  0.0
Valid Loss:  0.6310750842094421
Valid Acc:  0.0
std:  0.02707631258545155 
thres:  0.000584241235256195
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 47%|████▋     | 470/1000 [30:00<33:53,  3.84s/it]Epoch:   471
max of grad d_p:  tensor(0.8005, device='cuda:0')
min of grad d_p:  tensor(-5.2954, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2944, device='cuda:0') mean:  tensor(9.0722e-05, device='cuda:0') min:  tensor(-0.4486, device='cuda:0') norm:  tensor(1.7788, device='cuda:0') MSE:  tensor(6.6771e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0353, device='cuda:0') mean:  tensor(6.3027e-05, device='cuda:0') min:  tensor(2.5466e-11, device='cuda:0') norm:  tensor(0.1012, device='cuda:0') MSE:  tensor(3.7992e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0108, device='cuda:0')
min of d_p_list:  tensor(-0.0142, device='cuda:0')
Epoch:  471  
Training Loss: 0.5208141803741455
Test Loss:  0.5089964866638184
Test Acc:  0.0
Valid Loss:  0.6123583912849426
Valid Acc:  0.0
std:  0.033182228558647886 
thres:  0.0005665688276290893
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  36
 47%|████▋     | 471/1000 [30:04<33:50,  3.84s/it]Epoch:   472
max of grad d_p:  tensor(0.7471, device='cuda:0')
min of grad d_p:  tensor(-5.0514, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4253, device='cuda:0') mean:  tensor(9.0402e-05, device='cuda:0') min:  tensor(-0.3621, device='cuda:0') norm:  tensor(1.4780, device='cuda:0') MSE:  tensor(5.5481e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0037, device='cuda:0') mean:  tensor(1.3933e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0214, device='cuda:0') MSE:  tensor(8.0199e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0122, device='cuda:0')
min of d_p_list:  tensor(-0.0114, device='cuda:0')
Epoch:  472  
Training Loss: 0.4781247675418854
Test Loss:  0.47199100255966187
Test Acc:  0.0
Valid Loss:  0.5643687844276428
Valid Acc:  0.0
std:  0.042373800905045986 
thres:  0.0005417513906955719
Preserved_eigens number check:  36
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 47%|████▋     | 472/1000 [30:08<33:50,  3.85s/it]Epoch:   473
max of grad d_p:  tensor(0.7360, device='cuda:0')
min of grad d_p:  tensor(-5.0129, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4318, device='cuda:0') mean:  tensor(9.1419e-05, device='cuda:0') min:  tensor(-0.3685, device='cuda:0') norm:  tensor(1.5358, device='cuda:0') MSE:  tensor(5.7649e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0209, device='cuda:0') mean:  tensor(5.7414e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0892, device='cuda:0') MSE:  tensor(3.3485e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0133, device='cuda:0')
min of d_p_list:  tensor(-0.0097, device='cuda:0')
Epoch:  473  
Training Loss: 0.4734410047531128
Test Loss:  0.46659138798713684
Test Acc:  0.0
Valid Loss:  0.5578968524932861
Valid Acc:  0.0
std:  0.03940099404702911 
thres:  0.0005173226892948151
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  34
 47%|████▋     | 473/1000 [30:12<33:03,  3.76s/it]Epoch:   474
max of grad d_p:  tensor(0.7248, device='cuda:0')
min of grad d_p:  tensor(-4.9790, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.2989, device='cuda:0') mean:  tensor(8.8921e-05, device='cuda:0') min:  tensor(-0.3662, device='cuda:0') norm:  tensor(1.4650, device='cuda:0') MSE:  tensor(5.4994e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0521, device='cuda:0') mean:  tensor(9.8998e-05, device='cuda:0') min:  tensor(2.9104e-11, device='cuda:0') norm:  tensor(0.1634, device='cuda:0') MSE:  tensor(6.1352e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2997, device='cuda:0')
min of d_p_list:  tensor(-0.2220, device='cuda:0')
Epoch:  474  
Training Loss: 0.5187100172042847
Test Loss:  0.5227054357528687
Test Acc:  0.0
Valid Loss:  0.6373430490493774
Valid Acc:  0.0
std:  0.02435292571924668 
thres:  0.000504906815290451
Preserved_eigens number check:  34
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  31
 47%|████▋     | 474/1000 [30:16<33:24,  3.81s/it]Epoch:   475
max of grad d_p:  tensor(0.4628, device='cuda:0')
min of grad d_p:  tensor(-5.5619, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5336, device='cuda:0') mean:  tensor(9.6654e-05, device='cuda:0') min:  tensor(-0.5057, device='cuda:0') norm:  tensor(1.9160, device='cuda:0') MSE:  tensor(7.1924e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0059, device='cuda:0') mean:  tensor(1.9332e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0263, device='cuda:0') MSE:  tensor(9.8754e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0062, device='cuda:0')
min of d_p_list:  tensor(-0.0138, device='cuda:0')
Epoch:  475  
Training Loss: 0.47609943151474
Test Loss:  0.4834466576576233
Test Acc:  0.0
Valid Loss:  0.5874291062355042
Valid Acc:  0.0
std:  0.021555189489856397 
thres:  0.0004934378802776337
Preserved_eigens number check:  31
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 48%|████▊     | 475/1000 [30:19<33:20,  3.81s/it]Epoch:   476
max of grad d_p:  tensor(0.4618, device='cuda:0')
min of grad d_p:  tensor(-5.5107, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3183, device='cuda:0') mean:  tensor(6.2398e-05, device='cuda:0') min:  tensor(-0.6602, device='cuda:0') norm:  tensor(1.6677, device='cuda:0') MSE:  tensor(6.2601e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0026, device='cuda:0') mean:  tensor(7.5403e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0111, device='cuda:0') MSE:  tensor(4.1545e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0362, device='cuda:0')
min of d_p_list:  tensor(-0.0315, device='cuda:0')
Epoch:  476  
Training Loss: 0.46994495391845703
Test Loss:  0.47474077343940735
Test Acc:  0.0
Valid Loss:  0.5799956321716309
Valid Acc:  0.0
std:  0.017933494425914197 
thres:  0.00048326403498649597
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 48%|████▊     | 476/1000 [30:23<32:11,  3.69s/it]Epoch:   477
max of grad d_p:  tensor(0.4324, device='cuda:0')
min of grad d_p:  tensor(-5.4049, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5720, device='cuda:0') mean:  tensor(8.3437e-05, device='cuda:0') min:  tensor(-0.4609, device='cuda:0') norm:  tensor(1.6611, device='cuda:0') MSE:  tensor(6.2355e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0072, device='cuda:0') mean:  tensor(2.6378e-05, device='cuda:0') min:  tensor(2.1828e-11, device='cuda:0') norm:  tensor(0.0385, device='cuda:0') MSE:  tensor(1.4462e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0870, device='cuda:0')
min of d_p_list:  tensor(-0.2514, device='cuda:0')
Epoch:  477  
Training Loss: 0.4600445330142975
Test Loss:  0.466175377368927
Test Acc:  0.0
Valid Loss:  0.5691854953765869
Valid Acc:  0.0
std:  0.02027513421645665 
thres:  0.0004796479880809784
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 48%|████▊     | 477/1000 [30:27<32:46,  3.76s/it]Epoch:   478
max of grad d_p:  tensor(0.4276, device='cuda:0')
min of grad d_p:  tensor(-5.7254, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5073, device='cuda:0') mean:  tensor(6.6563e-05, device='cuda:0') min:  tensor(-0.4897, device='cuda:0') norm:  tensor(1.6648, device='cuda:0') MSE:  tensor(6.2493e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0043, device='cuda:0') mean:  tensor(1.2762e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0186, device='cuda:0') MSE:  tensor(6.9702e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0106, device='cuda:0')
min of d_p_list:  tensor(-0.0090, device='cuda:0')
Epoch:  478  
Training Loss: 0.4456183910369873
Test Loss:  0.45494580268859863
Test Acc:  0.0
Valid Loss:  0.552879810333252
Valid Acc:  0.0
std:  0.024576706873058955 
thres:  0.00047408346533775334
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 48%|████▊     | 478/1000 [30:31<33:22,  3.84s/it]Epoch:   479
max of grad d_p:  tensor(0.4201, device='cuda:0')
min of grad d_p:  tensor(-5.6913, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.6582, device='cuda:0') mean:  tensor(8.0157e-05, device='cuda:0') min:  tensor(-0.5837, device='cuda:0') norm:  tensor(1.9287, device='cuda:0') MSE:  tensor(7.2398e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0143, device='cuda:0') mean:  tensor(2.9685e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0490, device='cuda:0') MSE:  tensor(1.8401e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0107, device='cuda:0')
min of d_p_list:  tensor(-0.0124, device='cuda:0')
Epoch:  479  
Training Loss: 0.43351781368255615
Test Loss:  0.4470990300178528
Test Acc:  0.0
Valid Loss:  0.5401977896690369
Valid Acc:  0.0
std:  0.015636964271612167 
thres:  0.00045704502463340756
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 48%|████▊     | 479/1000 [30:35<33:18,  3.84s/it]Epoch:   480
max of grad d_p:  tensor(0.4149, device='cuda:0')
min of grad d_p:  tensor(-5.6707, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4971, device='cuda:0') mean:  tensor(6.4657e-05, device='cuda:0') min:  tensor(-0.4898, device='cuda:0') norm:  tensor(1.6087, device='cuda:0') MSE:  tensor(6.0385e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0134, device='cuda:0') mean:  tensor(4.6613e-05, device='cuda:0') min:  tensor(1.1642e-10, device='cuda:0') norm:  tensor(0.0664, device='cuda:0') MSE:  tensor(2.4925e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0127, device='cuda:0')
min of d_p_list:  tensor(-0.0132, device='cuda:0')
Epoch:  480  
Training Loss: 0.42229023575782776
Test Loss:  0.43973344564437866
Test Acc:  0.0
Valid Loss:  0.5288390517234802
Valid Acc:  0.0
std:  0.01725289701322069 
thres:  0.0004462831854820252
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 48%|████▊     | 480/1000 [30:38<32:59,  3.81s/it]Epoch:   481
max of grad d_p:  tensor(0.4096, device='cuda:0')
min of grad d_p:  tensor(-5.6195, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5741, device='cuda:0') mean:  tensor(6.9310e-05, device='cuda:0') min:  tensor(-0.4665, device='cuda:0') norm:  tensor(1.5885, device='cuda:0') MSE:  tensor(5.9628e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0560, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(6.7303e-11, device='cuda:0') norm:  tensor(0.2195, device='cuda:0') MSE:  tensor(8.2411e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0616, device='cuda:0')
min of d_p_list:  tensor(-0.0541, device='cuda:0')
Epoch:  481  
Training Loss: 0.42084479331970215
Test Loss:  0.43451762199401855
Test Acc:  0.0
Valid Loss:  0.5257478356361389
Valid Acc:  0.0
std:  0.014787695106703443 
thres:  0.00043646315336227416
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 48%|████▊     | 481/1000 [30:42<32:58,  3.81s/it]Epoch:   482
max of grad d_p:  tensor(0.3929, device='cuda:0')
min of grad d_p:  tensor(-5.5520, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3773, device='cuda:0') mean:  tensor(5.4074e-05, device='cuda:0') min:  tensor(-0.4914, device='cuda:0') norm:  tensor(1.6632, device='cuda:0') MSE:  tensor(6.2431e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0075, device='cuda:0') mean:  tensor(2.7912e-05, device='cuda:0') min:  tensor(7.2760e-12, device='cuda:0') norm:  tensor(0.0402, device='cuda:0') MSE:  tensor(1.5081e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0035, device='cuda:0')
min of d_p_list:  tensor(-0.0064, device='cuda:0')
Epoch:  482  
Training Loss: 0.41673070192337036
Test Loss:  0.43016672134399414
Test Acc:  0.0
Valid Loss:  0.5206137299537659
Valid Acc:  0.0
std:  0.010501906622944897 
thres:  0.00042780038714408875
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 48%|████▊     | 482/1000 [30:46<33:15,  3.85s/it]Epoch:   483
max of grad d_p:  tensor(0.3903, device='cuda:0')
min of grad d_p:  tensor(-5.5236, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.6454, device='cuda:0') mean:  tensor(7.2447e-05, device='cuda:0') min:  tensor(-0.5098, device='cuda:0') norm:  tensor(1.7660, device='cuda:0') MSE:  tensor(6.6292e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0026, device='cuda:0') mean:  tensor(5.7872e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0086, device='cuda:0') MSE:  tensor(3.2097e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0118, device='cuda:0')
min of d_p_list:  tensor(-0.0111, device='cuda:0')
Epoch:  483  
Training Loss: 0.40961360931396484
Test Loss:  0.4242711365222931
Test Acc:  0.0
Valid Loss:  0.5130833387374878
Valid Acc:  0.0
std:  0.00781612406907297 
thres:  0.00042059943079948426
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 48%|████▊     | 483/1000 [30:50<33:06,  3.84s/it]Epoch:   484
max of grad d_p:  tensor(0.3861, device='cuda:0')
min of grad d_p:  tensor(-5.4901, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5755, device='cuda:0') mean:  tensor(6.1494e-05, device='cuda:0') min:  tensor(-0.4690, device='cuda:0') norm:  tensor(1.6250, device='cuda:0') MSE:  tensor(6.1000e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0081, device='cuda:0') mean:  tensor(2.1355e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0312, device='cuda:0') MSE:  tensor(1.1725e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0100, device='cuda:0')
min of d_p_list:  tensor(-0.0139, device='cuda:0')
Epoch:  484  
Training Loss: 0.3764631152153015
Test Loss:  0.39370983839035034
Test Acc:  0.0
Valid Loss:  0.4741731882095337
Valid Acc:  0.0
std:  0.016944267413557697 
thres:  0.00040918849110603334
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 48%|████▊     | 484/1000 [30:54<32:49,  3.82s/it]Epoch:   485
max of grad d_p:  tensor(0.3738, device='cuda:0')
min of grad d_p:  tensor(-5.4360, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5485, device='cuda:0') mean:  tensor(4.6893e-05, device='cuda:0') min:  tensor(-0.4480, device='cuda:0') norm:  tensor(1.5178, device='cuda:0') MSE:  tensor(5.6975e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0202, device='cuda:0') mean:  tensor(6.9167e-05, device='cuda:0') min:  tensor(5.8208e-11, device='cuda:0') norm:  tensor(0.1011, device='cuda:0') MSE:  tensor(3.7961e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0087, device='cuda:0')
min of d_p_list:  tensor(-0.0107, device='cuda:0')
Epoch:  485  
Training Loss: 0.3709179759025574
Test Loss:  0.3889511823654175
Test Acc:  0.0
Valid Loss:  0.467520534992218
Valid Acc:  0.0
std:  0.02097949377559879 
thres:  0.00039891403913497927
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 48%|████▊     | 485/1000 [30:57<31:51,  3.71s/it]Epoch:   486
max of grad d_p:  tensor(0.3703, device='cuda:0')
min of grad d_p:  tensor(-5.4280, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4626, device='cuda:0') mean:  tensor(5.8867e-05, device='cuda:0') min:  tensor(-0.4470, device='cuda:0') norm:  tensor(1.5421, device='cuda:0') MSE:  tensor(5.7885e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0047, device='cuda:0') mean:  tensor(1.3283e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0203, device='cuda:0') MSE:  tensor(7.6183e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0163, device='cuda:0')
min of d_p_list:  tensor(-0.0188, device='cuda:0')
Epoch:  486  
Training Loss: 0.3660130500793457
Test Loss:  0.38570109009742737
Test Acc:  0.0
Valid Loss:  0.4623992443084717
Valid Acc:  0.0
std:  0.02098050944936678 
thres:  0.00038794769048690797
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 49%|████▊     | 486/1000 [31:01<31:12,  3.64s/it]Epoch:   487
max of grad d_p:  tensor(0.3667, device='cuda:0')
min of grad d_p:  tensor(-5.4279, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5081, device='cuda:0') mean:  tensor(5.6231e-05, device='cuda:0') min:  tensor(-0.5152, device='cuda:0') norm:  tensor(1.6879, device='cuda:0') MSE:  tensor(6.3360e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0070, device='cuda:0') mean:  tensor(3.1502e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0470, device='cuda:0') MSE:  tensor(1.7648e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0184, device='cuda:0')
min of d_p_list:  tensor(-0.0222, device='cuda:0')
Epoch:  487  
Training Loss: 0.36107563972473145
Test Loss:  0.37769365310668945
Test Acc:  0.0
Valid Loss:  0.4544990658760071
Valid Acc:  0.0
std:  0.017175896243989342 
thres:  0.0003768166780471802
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 49%|████▊     | 487/1000 [31:05<31:45,  3.72s/it]Epoch:   488
max of grad d_p:  tensor(0.3626, device='cuda:0')
min of grad d_p:  tensor(-5.3712, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4984, device='cuda:0') mean:  tensor(5.8714e-05, device='cuda:0') min:  tensor(-0.4625, device='cuda:0') norm:  tensor(1.4982, device='cuda:0') MSE:  tensor(5.6239e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0105, device='cuda:0') mean:  tensor(3.0753e-05, device='cuda:0') min:  tensor(1.4552e-11, device='cuda:0') norm:  tensor(0.0491, device='cuda:0') MSE:  tensor(1.8449e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0060, device='cuda:0')
min of d_p_list:  tensor(-0.0115, device='cuda:0')
Epoch:  488  
Training Loss: 0.3560330867767334
Test Loss:  0.37287577986717224
Test Acc:  0.0
Valid Loss:  0.44833600521087646
Valid Acc:  0.0
std:  0.007172189978349383 
thres:  0.00036610057353973394
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 49%|████▉     | 488/1000 [31:08<31:42,  3.72s/it]Epoch:   489
max of grad d_p:  tensor(0.3585, device='cuda:0')
min of grad d_p:  tensor(-5.3451, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3812, device='cuda:0') mean:  tensor(4.7898e-05, device='cuda:0') min:  tensor(-0.4841, device='cuda:0') norm:  tensor(1.5101, device='cuda:0') MSE:  tensor(5.6685e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0195, device='cuda:0') mean:  tensor(4.6718e-05, device='cuda:0') min:  tensor(2.9104e-11, device='cuda:0') norm:  tensor(0.0739, device='cuda:0') MSE:  tensor(2.7751e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0077, device='cuda:0')
min of d_p_list:  tensor(-0.0115, device='cuda:0')
Epoch:  489  
Training Loss: 0.3515344560146332
Test Loss:  0.36977750062942505
Test Acc:  0.0
Valid Loss:  0.4435698986053467
Valid Acc:  0.0
std:  0.006894975638771082 
thres:  0.00036111484169960026
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 49%|████▉     | 489/1000 [31:12<32:09,  3.78s/it]Epoch:   490
max of grad d_p:  tensor(0.3549, device='cuda:0')
min of grad d_p:  tensor(-5.3387, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.6063, device='cuda:0') mean:  tensor(5.6771e-05, device='cuda:0') min:  tensor(-0.4376, device='cuda:0') norm:  tensor(1.5069, device='cuda:0') MSE:  tensor(5.6563e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0045, device='cuda:0') mean:  tensor(1.1068e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0163, device='cuda:0') MSE:  tensor(6.1263e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0098, device='cuda:0')
min of d_p_list:  tensor(-0.0169, device='cuda:0')
Epoch:  490  
Training Loss: 0.3470141887664795
Test Loss:  0.36449119448661804
Test Acc:  0.0
Valid Loss:  0.43653786182403564
Valid Acc:  0.0
std:  0.006725358136872515 
thres:  0.0003563340842723847
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 49%|████▉     | 490/1000 [31:16<31:22,  3.69s/it]Epoch:   491
max of grad d_p:  tensor(0.3550, device='cuda:0')
min of grad d_p:  tensor(-5.3297, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.7017, device='cuda:0') mean:  tensor(6.2362e-05, device='cuda:0') min:  tensor(-0.4426, device='cuda:0') norm:  tensor(1.5732, device='cuda:0') MSE:  tensor(5.9053e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0045, device='cuda:0') mean:  tensor(1.0851e-05, device='cuda:0') min:  tensor(2.7285e-12, device='cuda:0') norm:  tensor(0.0190, device='cuda:0') MSE:  tensor(7.1494e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0068, device='cuda:0')
min of d_p_list:  tensor(-0.0085, device='cuda:0')
Epoch:  491  
Training Loss: 0.34328770637512207
Test Loss:  0.36034247279167175
Test Acc:  0.0
Valid Loss:  0.43167030811309814
Valid Acc:  0.0
std:  0.006314896011761832 
thres:  0.0003517890155315399
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 49%|████▉     | 491/1000 [31:19<31:32,  3.72s/it]Epoch:   492
max of grad d_p:  tensor(0.3531, device='cuda:0')
min of grad d_p:  tensor(-5.3074, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.3976, device='cuda:0') mean:  tensor(5.3017e-05, device='cuda:0') min:  tensor(-0.4751, device='cuda:0') norm:  tensor(1.6268, device='cuda:0') MSE:  tensor(6.1065e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0055, device='cuda:0') mean:  tensor(1.3514e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0210, device='cuda:0') MSE:  tensor(7.8790e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0116, device='cuda:0')
min of d_p_list:  tensor(-0.0112, device='cuda:0')
Epoch:  492  
Training Loss: 0.3391686677932739
Test Loss:  0.35596269369125366
Test Acc:  0.0
Valid Loss:  0.4257611036300659
Valid Acc:  0.0
std:  0.005940341109479812 
thres:  0.00034740762114524845
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 49%|████▉     | 492/1000 [31:24<32:17,  3.81s/it]Epoch:   493
max of grad d_p:  tensor(0.3511, device='cuda:0')
min of grad d_p:  tensor(-5.2964, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.6089, device='cuda:0') mean:  tensor(6.0306e-05, device='cuda:0') min:  tensor(-0.4803, device='cuda:0') norm:  tensor(1.6156, device='cuda:0') MSE:  tensor(6.0647e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0063, device='cuda:0') mean:  tensor(1.5688e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0243, device='cuda:0') MSE:  tensor(9.1218e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0495, device='cuda:0')
min of d_p_list:  tensor(-0.0203, device='cuda:0')
Epoch:  493  
Training Loss: 0.33571457862854004
Test Loss:  0.3538421094417572
Test Acc:  0.0
Valid Loss:  0.42309218645095825
Valid Acc:  0.0
std:  0.005589248495976186 
thres:  0.00034334391951560973
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 49%|████▉     | 493/1000 [31:27<32:14,  3.81s/it]Epoch:   494
max of grad d_p:  tensor(0.3467, device='cuda:0')
min of grad d_p:  tensor(-5.2462, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4671, device='cuda:0') mean:  tensor(5.6310e-05, device='cuda:0') min:  tensor(-0.5063, device='cuda:0') norm:  tensor(1.6863, device='cuda:0') MSE:  tensor(6.3299e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0052, device='cuda:0') mean:  tensor(1.6960e-05, device='cuda:0') min:  tensor(2.9104e-11, device='cuda:0') norm:  tensor(0.0257, device='cuda:0') MSE:  tensor(9.6400e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0107, device='cuda:0')
min of d_p_list:  tensor(-0.0123, device='cuda:0')
Epoch:  494  
Training Loss: 0.3274186849594116
Test Loss:  0.34291085600852966
Test Acc:  0.0
Valid Loss:  0.4111477732658386
Valid Acc:  0.0
std:  0.0067292290577655265 
thres:  0.0003385207653045654
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 49%|████▉     | 494/1000 [31:31<31:35,  3.75s/it]Epoch:   495
max of grad d_p:  tensor(0.3359, device='cuda:0')
min of grad d_p:  tensor(-5.0164, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4936, device='cuda:0') mean:  tensor(4.7976e-05, device='cuda:0') min:  tensor(-0.4421, device='cuda:0') norm:  tensor(1.5257, device='cuda:0') MSE:  tensor(5.7269e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0080, device='cuda:0') mean:  tensor(1.9067e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0281, device='cuda:0') MSE:  tensor(1.0538e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0212, device='cuda:0')
min of d_p_list:  tensor(-0.0352, device='cuda:0')
Epoch:  495  
Training Loss: 0.3237895965576172
Test Loss:  0.3388305902481079
Test Acc:  0.0
Valid Loss:  0.40652596950531006
Valid Acc:  0.0
std:  0.007258172944391204 
thres:  0.00033387584686279297
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 50%|████▉     | 495/1000 [31:35<31:35,  3.75s/it]Epoch:   496
max of grad d_p:  tensor(0.3342, device='cuda:0')
min of grad d_p:  tensor(-5.0107, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5108, device='cuda:0') mean:  tensor(4.5477e-05, device='cuda:0') min:  tensor(-0.4701, device='cuda:0') norm:  tensor(1.6155, device='cuda:0') MSE:  tensor(6.0643e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0062, device='cuda:0') mean:  tensor(1.0147e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0164, device='cuda:0') MSE:  tensor(6.1642e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0531, device='cuda:0')
min of d_p_list:  tensor(-0.0420, device='cuda:0')
Epoch:  496  
Training Loss: 0.3202997148036957
Test Loss:  0.33502933382987976
Test Acc:  0.0
Valid Loss:  0.40288931131362915
Valid Acc:  0.0
std:  0.007119607901592583 
thres:  0.0003292782485485077
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 50%|████▉     | 496/1000 [31:39<32:08,  3.83s/it]Epoch:   497
max of grad d_p:  tensor(0.3317, device='cuda:0')
min of grad d_p:  tensor(-5.0489, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4772, device='cuda:0') mean:  tensor(5.0960e-05, device='cuda:0') min:  tensor(-0.4456, device='cuda:0') norm:  tensor(1.5708, device='cuda:0') MSE:  tensor(5.8962e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0042, device='cuda:0') mean:  tensor(1.0538e-05, device='cuda:0') min:  tensor(4.3656e-11, device='cuda:0') norm:  tensor(0.0157, device='cuda:0') MSE:  tensor(5.9044e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0086, device='cuda:0')
min of d_p_list:  tensor(-0.0061, device='cuda:0')
Epoch:  497  
Training Loss: 0.3163626194000244
Test Loss:  0.3314039409160614
Test Acc:  0.0
Valid Loss:  0.39893198013305664
Valid Acc:  0.0
std:  0.006609296455190348 
thres:  0.00032471703886985783
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 50%|████▉     | 497/1000 [31:43<32:16,  3.85s/it]Epoch:   498
max of grad d_p:  tensor(0.3290, device='cuda:0')
min of grad d_p:  tensor(-5.0299, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.4479, device='cuda:0') mean:  tensor(5.4768e-05, device='cuda:0') min:  tensor(-0.5324, device='cuda:0') norm:  tensor(1.7499, device='cuda:0') MSE:  tensor(6.5689e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0077, device='cuda:0') mean:  tensor(1.4563e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0233, device='cuda:0') MSE:  tensor(8.7499e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0229, device='cuda:0')
min of d_p_list:  tensor(-0.0597, device='cuda:0')
Epoch:  498  
Training Loss: 0.31169596314430237
Test Loss:  0.3263195753097534
Test Acc:  0.0
Valid Loss:  0.392985463142395
Valid Acc:  0.0
std:  0.00550704553302182 
thres:  0.00031991331577301024
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 50%|████▉     | 498/1000 [31:46<31:54,  3.81s/it]Epoch:   499
max of grad d_p:  tensor(0.3293, device='cuda:0')
min of grad d_p:  tensor(-5.0756, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.5266, device='cuda:0') mean:  tensor(5.2574e-05, device='cuda:0') min:  tensor(-0.4513, device='cuda:0') norm:  tensor(1.5300, device='cuda:0') MSE:  tensor(5.7432e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0058, device='cuda:0') mean:  tensor(1.3609e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0212, device='cuda:0') MSE:  tensor(7.9536e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0427, device='cuda:0')
min of d_p_list:  tensor(-0.0544, device='cuda:0')
Epoch:  499  
Training Loss: 0.3074585199356079
Test Loss:  0.3216403126716614
Test Acc:  0.0
Valid Loss:  0.3888845145702362
Valid Acc:  0.0
std:  0.005843757142208668 
thres:  0.0003159212827682495
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 50%|████▉     | 499/1000 [31:50<31:56,  3.83s/it]Epoch:   500
max of grad d_p:  tensor(0.3231, device='cuda:0')
min of grad d_p:  tensor(-5.0742, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.6621, device='cuda:0') mean:  tensor(5.7477e-05, device='cuda:0') min:  tensor(-0.4439, device='cuda:0') norm:  tensor(1.6040, device='cuda:0') MSE:  tensor(6.0209e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0032, device='cuda:0') mean:  tensor(9.6068e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0140, device='cuda:0') MSE:  tensor(5.2419e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(4.4981, device='cuda:0')
min of d_p_list:  tensor(-4.9745, device='cuda:0')
Epoch:  500  
Training Loss: 379.046142578125
Test Loss:  221.57608032226562
Test Acc:  0.0
Valid Loss:  276.94921875
Valid Acc:  0.0
std:  151.492875411148 
thres:  0.07606039187908172
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  35
 50%|█████     | 500/1000 [31:54<31:55,  3.83s/it]Epoch:   501
max of grad d_p:  tensor(543.4846, device='cuda:0')
min of grad d_p:  tensor(-492.2183, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.7272, device='cuda:0') mean:  tensor(4.5605e-06, device='cuda:0') min:  tensor(-1.0959, device='cuda:0') norm:  tensor(5.1260, device='cuda:0') MSE:  tensor(1.9242e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0628, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.3555, device='cuda:0') MSE:  tensor(1.3346e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0483, device='cuda:0')
min of d_p_list:  tensor(-0.0472, device='cuda:0')
Epoch:  501  
Training Loss: 374.99017333984375
Test Loss:  219.8367462158203
Test Acc:  0.0
Valid Loss:  275.00592041015625
Valid Acc:  0.0
std:  184.55210990090194 
thres:  0.15099436660408974
Preserved_eigens number check:  35
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 50%|█████     | 501/1000 [31:58<32:02,  3.85s/it]Epoch:   502
max of grad d_p:  tensor(535.3051, device='cuda:0')
min of grad d_p:  tensor(-484.7710, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.1307, device='cuda:0') mean:  tensor(4.4903e-05, device='cuda:0') min:  tensor(-1.1180, device='cuda:0') norm:  tensor(5.5626, device='cuda:0') MSE:  tensor(2.0880e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2055, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7886, device='cuda:0') MSE:  tensor(2.9601e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0366, device='cuda:0')
min of d_p_list:  tensor(-0.0328, device='cuda:0')
Epoch:  502  
Training Loss: 371.01806640625
Test Loss:  217.9573516845703
Test Acc:  0.0
Valid Loss:  272.7487487792969
Valid Acc:  0.0
std:  183.58650456724712 
thres:  0.22513470736145974
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 50%|█████     | 502/1000 [32:02<31:55,  3.85s/it]Epoch:   503
max of grad d_p:  tensor(528.0971, device='cuda:0')
min of grad d_p:  tensor(-477.2986, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.7749, device='cuda:0') mean:  tensor(5.1986e-05, device='cuda:0') min:  tensor(-1.3139, device='cuda:0') norm:  tensor(5.3703, device='cuda:0') MSE:  tensor(2.0159e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2463, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.6888, device='cuda:0') MSE:  tensor(2.5857e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.3149, device='cuda:0')
min of d_p_list:  tensor(-0.3816, device='cuda:0')
Epoch:  503  
Training Loss: 370.4049377441406
Test Loss:  222.07456970214844
Test Acc:  0.0
Valid Loss:  277.6935729980469
Valid Acc:  0.0
std:  149.45519405824336 
thres:  0.299153355717659
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  41
 50%|█████     | 503/1000 [32:06<32:10,  3.88s/it]Epoch:   504
max of grad d_p:  tensor(514.9942, device='cuda:0')
min of grad d_p:  tensor(-467.4902, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.7763, device='cuda:0') mean:  tensor(-6.5456e-06, device='cuda:0') min:  tensor(-0.9764, device='cuda:0') norm:  tensor(5.0654, device='cuda:0') MSE:  tensor(1.9014e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.4683, device='cuda:0') mean:  tensor(0.0034, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(5.4150, device='cuda:0') MSE:  tensor(2.0326e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0555, device='cuda:0')
min of d_p_list:  tensor(-0.0530, device='cuda:0')
Epoch:  504  
Training Loss: 366.22589111328125
Test Loss:  220.3508758544922
Test Acc:  0.0
Valid Loss:  275.15380859375
Valid Acc:  0.0
std:  4.35591609438289 
thres:  0.37233704223632813
Preserved_eigens number check:  41
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 50%|█████     | 504/1000 [32:10<32:39,  3.95s/it]Epoch:   505
max of grad d_p:  tensor(509.4381, device='cuda:0')
min of grad d_p:  tensor(-462.4329, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.9305, device='cuda:0') mean:  tensor(2.7238e-05, device='cuda:0') min:  tensor(-1.2023, device='cuda:0') norm:  tensor(5.5645, device='cuda:0') MSE:  tensor(2.0888e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1202, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.5058, device='cuda:0') MSE:  tensor(1.8986e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.4208, device='cuda:0')
min of d_p_list:  tensor(-0.3801, device='cuda:0')
Epoch:  505  
Training Loss: 358.8983459472656
Test Loss:  207.88624572753906
Test Acc:  0.0
Valid Loss:  264.1446228027344
Valid Acc:  0.0
std:  5.463877997250471 
thres:  0.36830748291015625
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 50%|█████     | 505/1000 [32:14<32:19,  3.92s/it]Epoch:   506
max of grad d_p:  tensor(518.7508, device='cuda:0')
min of grad d_p:  tensor(-469.4323, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.9928, device='cuda:0') mean:  tensor(3.6959e-05, device='cuda:0') min:  tensor(-1.0755, device='cuda:0') norm:  tensor(5.5978, device='cuda:0') MSE:  tensor(2.1013e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2134, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.9321, device='cuda:0') MSE:  tensor(3.4988e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0889, device='cuda:0')
min of d_p_list:  tensor(-0.0933, device='cuda:0')
Epoch:  506  
Training Loss: 354.8820495605469
Test Loss:  206.2348175048828
Test Acc:  0.0
Valid Loss:  262.09228515625
Valid Acc:  0.0
std:  6.3872747663655565 
thres:  0.36428585815429687
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  45
 51%|█████     | 506/1000 [32:17<31:45,  3.86s/it]Epoch:   507
max of grad d_p:  tensor(517.2892, device='cuda:0')
min of grad d_p:  tensor(-469.4236, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.8920, device='cuda:0') mean:  tensor(-2.3406e-05, device='cuda:0') min:  tensor(-0.9991, device='cuda:0') norm:  tensor(5.3714, device='cuda:0') MSE:  tensor(2.0163e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4541, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.2293, device='cuda:0') MSE:  tensor(4.6144e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0299, device='cuda:0')
min of d_p_list:  tensor(-0.0518, device='cuda:0')
Epoch:  507  
Training Loss: 351.2266540527344
Test Loss:  204.08688354492188
Test Acc:  0.0
Valid Loss:  259.4394226074219
Valid Acc:  0.0
std:  7.0833124727696966 
thres:  0.36032757568359375
Preserved_eigens number check:  45
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 51%|█████     | 507/1000 [32:21<30:57,  3.77s/it]Epoch:   508
max of grad d_p:  tensor(517.5833, device='cuda:0')
min of grad d_p:  tensor(-470.3638, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.2718, device='cuda:0') mean:  tensor(1.8238e-05, device='cuda:0') min:  tensor(-1.1240, device='cuda:0') norm:  tensor(5.7394, device='cuda:0') MSE:  tensor(2.1544e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0522, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1652, device='cuda:0') MSE:  tensor(6.2016e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0269, device='cuda:0')
min of d_p_list:  tensor(-0.0648, device='cuda:0')
Epoch:  508  
Training Loss: 347.477783203125
Test Loss:  202.30313110351562
Test Acc:  0.0
Valid Loss:  256.9077453613281
Valid Acc:  0.0
std:  6.469924814968297 
thres:  0.3557421447753906
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 51%|█████     | 508/1000 [32:25<31:11,  3.80s/it]Epoch:   509
max of grad d_p:  tensor(512.9612, device='cuda:0')
min of grad d_p:  tensor(-466.8601, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.0071, device='cuda:0') mean:  tensor(-3.3449e-05, device='cuda:0') min:  tensor(-1.0227, device='cuda:0') norm:  tensor(5.4970, device='cuda:0') MSE:  tensor(2.0634e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1226, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.3791, device='cuda:0') MSE:  tensor(1.4230e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0764, device='cuda:0')
min of d_p_list:  tensor(-0.0536, device='cuda:0')
Epoch:  509  
Training Loss: 343.75250244140625
Test Loss:  200.41595458984375
Test Acc:  0.0
Valid Loss:  254.30276489257812
Valid Acc:  0.0
std:  5.3316335563674295 
thres:  0.3512474670410156
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 51%|█████     | 509/1000 [32:29<31:04,  3.80s/it]Epoch:   510
max of grad d_p:  tensor(508.1107, device='cuda:0')
min of grad d_p:  tensor(-461.7812, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.9237, device='cuda:0') mean:  tensor(-2.9081e-05, device='cuda:0') min:  tensor(-1.0633, device='cuda:0') norm:  tensor(5.3870, device='cuda:0') MSE:  tensor(2.0222e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0928, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.3132, device='cuda:0') MSE:  tensor(1.1756e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0358, device='cuda:0')
min of d_p_list:  tensor(-0.0568, device='cuda:0')
Epoch:  510  
Training Loss: 339.9970703125
Test Loss:  198.219482421875
Test Acc:  0.0
Valid Loss:  251.41641235351562
Valid Acc:  0.0
std:  5.2671703272921215 
thres:  0.3474672119140625
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 51%|█████     | 510/1000 [32:32<31:10,  3.82s/it]Epoch:   511
max of grad d_p:  tensor(504.6995, device='cuda:0')
min of grad d_p:  tensor(-459.4251, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.9880, device='cuda:0') mean:  tensor(-7.3014e-05, device='cuda:0') min:  tensor(-1.0198, device='cuda:0') norm:  tensor(5.4202, device='cuda:0') MSE:  tensor(2.0346e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.7083, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.9564, device='cuda:0') MSE:  tensor(7.3437e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0688, device='cuda:0')
min of d_p_list:  tensor(-0.0358, device='cuda:0')
Epoch:  511  
Training Loss: 336.31585693359375
Test Loss:  196.5610809326172
Test Acc:  0.0
Valid Loss:  249.08074951171875
Valid Acc:  0.0
std:  5.2753694681607 
thres:  0.34375397338867186
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 51%|█████     | 511/1000 [32:36<30:56,  3.80s/it]Epoch:   512
max of grad d_p:  tensor(499.2065, device='cuda:0')
min of grad d_p:  tensor(-452.3016, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.5330, device='cuda:0') mean:  tensor(-3.6575e-05, device='cuda:0') min:  tensor(-0.9918, device='cuda:0') norm:  tensor(4.7161, device='cuda:0') MSE:  tensor(1.7703e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3171, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.4026, device='cuda:0') MSE:  tensor(5.2650e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0833, device='cuda:0')
min of d_p_list:  tensor(-0.1715, device='cuda:0')
Epoch:  512  
Training Loss: 334.762451171875
Test Loss:  194.4235382080078
Test Acc:  0.0
Valid Loss:  246.91802978515625
Valid Acc:  0.0
std:  4.68913926634066 
thres:  0.3404611328125
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 51%|█████     | 512/1000 [32:40<31:32,  3.88s/it]Epoch:   513
max of grad d_p:  tensor(494.1895, device='cuda:0')
min of grad d_p:  tensor(-443.7137, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.0547, device='cuda:0') mean:  tensor(3.2249e-05, device='cuda:0') min:  tensor(-1.1669, device='cuda:0') norm:  tensor(5.4183, device='cuda:0') MSE:  tensor(2.0339e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0508, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.2574, device='cuda:0') MSE:  tensor(9.6625e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.3724, device='cuda:0')
min of d_p_list:  tensor(-0.4195, device='cuda:0')
Epoch:  513  
Training Loss: 335.2658996582031
Test Loss:  193.76832580566406
Test Acc:  0.0
Valid Loss:  248.48350524902344
Valid Acc:  0.0
std:  3.40209289044229 
thres:  0.3380187561035156
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  170
 51%|█████▏    | 513/1000 [32:44<30:48,  3.80s/it]Epoch:   514
max of grad d_p:  tensor(499.5652, device='cuda:0')
min of grad d_p:  tensor(-455.8362, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.8293, device='cuda:0') mean:  tensor(1.5702e-05, device='cuda:0') min:  tensor(-0.9583, device='cuda:0') norm:  tensor(5.1594, device='cuda:0') MSE:  tensor(1.9367e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0510, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1971, device='cuda:0') MSE:  tensor(7.3988e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.6085, device='cuda:0')
min of d_p_list:  tensor(-0.3106, device='cuda:0')
Epoch:  514  
Training Loss: 361.8190612792969
Test Loss:  213.75787353515625
Test Acc:  0.0
Valid Loss:  274.1036376953125
Valid Acc:  0.0
std:  10.25836000460544 
thres:  0.34163206787109374
Preserved_eigens number check:  170
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  48
 51%|█████▏    | 514/1000 [32:48<31:05,  3.84s/it]Epoch:   515
max of grad d_p:  tensor(571.8495, device='cuda:0')
min of grad d_p:  tensor(-506.0110, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.3042, device='cuda:0') mean:  tensor(-6.7193e-06, device='cuda:0') min:  tensor(-1.2257, device='cuda:0') norm:  tensor(5.8100, device='cuda:0') MSE:  tensor(2.1809e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2748, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8812, device='cuda:0') MSE:  tensor(3.3077e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0498, device='cuda:0')
min of d_p_list:  tensor(-0.0531, device='cuda:0')
Epoch:  515  
Training Loss: 358.13262939453125
Test Loss:  211.69564819335938
Test Acc:  0.0
Valid Loss:  271.1595153808594
Valid Acc:  0.0
std:  12.082924835063835 
thres:  0.34525917968750003
Preserved_eigens number check:  48
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  34
 52%|█████▏    | 515/1000 [32:52<31:20,  3.88s/it]Epoch:   516
max of grad d_p:  tensor(570.1266, device='cuda:0')
min of grad d_p:  tensor(-504.6299, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.4846, device='cuda:0') mean:  tensor(-9.7419e-05, device='cuda:0') min:  tensor(-1.1682, device='cuda:0') norm:  tensor(5.8216, device='cuda:0') MSE:  tensor(2.1853e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1517, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7126, device='cuda:0') MSE:  tensor(2.6749e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0340, device='cuda:0')
min of d_p_list:  tensor(-0.0344, device='cuda:0')
Epoch:  516  
Training Loss: 354.2406005859375
Test Loss:  209.52137756347656
Test Acc:  0.0
Valid Loss:  268.34869384765625
Valid Acc:  0.0
std:  11.544773495594592 
thres:  0.34884412841796875
Preserved_eigens number check:  34
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  33
 52%|█████▏    | 516/1000 [32:56<31:34,  3.92s/it]Epoch:   517
max of grad d_p:  tensor(564.4812, device='cuda:0')
min of grad d_p:  tensor(-499.0941, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.1785, device='cuda:0') mean:  tensor(1.8070e-05, device='cuda:0') min:  tensor(-1.2682, device='cuda:0') norm:  tensor(5.5410, device='cuda:0') MSE:  tensor(2.0799e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0552, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1798, device='cuda:0') MSE:  tensor(6.7488e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0496, device='cuda:0')
min of d_p_list:  tensor(-0.0340, device='cuda:0')
Epoch:  517  
Training Loss: 350.4664611816406
Test Loss:  207.506103515625
Test Acc:  0.0
Valid Loss:  265.74810791015625
Valid Acc:  0.0
std:  9.1806766502092 
thres:  0.35198493041992185
Preserved_eigens number check:  33
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  36
 52%|█████▏    | 517/1000 [33:00<31:12,  3.88s/it]Epoch:   518
max of grad d_p:  tensor(560.0546, device='cuda:0')
min of grad d_p:  tensor(-493.6338, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.0957, device='cuda:0') mean:  tensor(-9.7490e-06, device='cuda:0') min:  tensor(-1.4228, device='cuda:0') norm:  tensor(5.6171, device='cuda:0') MSE:  tensor(2.1085e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0564, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1977, device='cuda:0') MSE:  tensor(7.4214e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0629, device='cuda:0')
min of d_p_list:  tensor(-0.1072, device='cuda:0')
Epoch:  518  
Training Loss: 346.63604736328125
Test Loss:  205.24057006835938
Test Acc:  0.0
Valid Loss:  262.9486389160156
Valid Acc:  0.0
std:  5.378710391046217 
thres:  0.3542589599609375
Preserved_eigens number check:  36
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 52%|█████▏    | 518/1000 [33:03<31:01,  3.86s/it]Epoch:   519
max of grad d_p:  tensor(555.0146, device='cuda:0')
min of grad d_p:  tensor(-490.5031, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.3355, device='cuda:0') mean:  tensor(2.2677e-05, device='cuda:0') min:  tensor(-1.1634, device='cuda:0') norm:  tensor(5.6533, device='cuda:0') MSE:  tensor(2.1221e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0435, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.2224, device='cuda:0') MSE:  tensor(8.3482e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2551, device='cuda:0')
min of d_p_list:  tensor(-0.1273, device='cuda:0')
Epoch:  519  
Training Loss: 343.0330810546875
Test Loss:  203.13638305664062
Test Acc:  0.0
Valid Loss:  260.2618408203125
Valid Acc:  0.0
std:  5.346685740302854 
thres:  0.3505017639160157
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 52%|█████▏    | 519/1000 [33:07<30:30,  3.81s/it]Epoch:   520
max of grad d_p:  tensor(544.8400, device='cuda:0')
min of grad d_p:  tensor(-482.7788, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.3712, device='cuda:0') mean:  tensor(-1.0416e-05, device='cuda:0') min:  tensor(-1.0611, device='cuda:0') norm:  tensor(5.3686, device='cuda:0') MSE:  tensor(2.0152e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.7541, device='cuda:0') mean:  tensor(0.0033, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(5.0444, device='cuda:0') MSE:  tensor(1.8936e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0589, device='cuda:0')
min of d_p_list:  tensor(-0.0635, device='cuda:0')
Epoch:  520  
Training Loss: 339.47430419921875
Test Loss:  201.08688354492188
Test Acc:  0.0
Valid Loss:  257.5060119628906
Valid Acc:  0.0
std:  5.228448757774318 
thres:  0.34677009887695315
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  92
 52%|█████▏    | 520/1000 [33:11<30:55,  3.87s/it]Epoch:   521
max of grad d_p:  tensor(540.8739, device='cuda:0')
min of grad d_p:  tensor(-478.9545, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.1581, device='cuda:0') mean:  tensor(1.1677e-05, device='cuda:0') min:  tensor(-0.9807, device='cuda:0') norm:  tensor(5.1793, device='cuda:0') MSE:  tensor(1.9442e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0505, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.2163, device='cuda:0') MSE:  tensor(8.1193e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0928, device='cuda:0')
min of d_p_list:  tensor(-0.0735, device='cuda:0')
Epoch:  521  
Training Loss: 334.7149353027344
Test Loss:  198.9925537109375
Test Acc:  0.0
Valid Loss:  255.0195770263672
Valid Acc:  0.0
std:  5.476342467929747 
thres:  0.3428649658203125
Preserved_eigens number check:  92
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  33
 52%|█████▏    | 521/1000 [33:15<31:00,  3.88s/it]Epoch:   522
max of grad d_p:  tensor(536.4257, device='cuda:0')
min of grad d_p:  tensor(-469.3841, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.0450, device='cuda:0') mean:  tensor(-9.2151e-06, device='cuda:0') min:  tensor(-1.2383, device='cuda:0') norm:  tensor(5.2949, device='cuda:0') MSE:  tensor(1.9876e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0364, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.2323, device='cuda:0') MSE:  tensor(8.7193e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0401, device='cuda:0')
min of d_p_list:  tensor(-0.0201, device='cuda:0')
Epoch:  522  
Training Loss: 331.3966064453125
Test Loss:  197.2412872314453
Test Acc:  0.0
Valid Loss:  252.7411346435547
Valid Acc:  0.0
std:  5.494730152121768 
thres:  0.3390509948730469
Preserved_eigens number check:  33
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 52%|█████▏    | 522/1000 [33:19<30:41,  3.85s/it]Epoch:   523
max of grad d_p:  tensor(532.0776, device='cuda:0')
min of grad d_p:  tensor(-465.9467, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.7642, device='cuda:0') mean:  tensor(1.8987e-07, device='cuda:0') min:  tensor(-1.1805, device='cuda:0') norm:  tensor(4.9161, device='cuda:0') MSE:  tensor(1.8454e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.7244, device='cuda:0') mean:  tensor(0.0046, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(6.7716, device='cuda:0') MSE:  tensor(2.5419e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0580, device='cuda:0')
min of d_p_list:  tensor(-0.0808, device='cuda:0')
Epoch:  523  
Training Loss: 328.2020263671875
Test Loss:  195.37220764160156
Test Acc:  0.0
Valid Loss:  250.28079223632812
Valid Acc:  0.0
std:  5.350976874698926 
thres:  0.33536419067382817
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  36
 52%|█████▏    | 523/1000 [33:23<31:02,  3.90s/it]Epoch:   524
max of grad d_p:  tensor(528.3729, device='cuda:0')
min of grad d_p:  tensor(-461.8032, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.3661, device='cuda:0') mean:  tensor(-4.2339e-05, device='cuda:0') min:  tensor(-1.2163, device='cuda:0') norm:  tensor(5.5713, device='cuda:0') MSE:  tensor(2.0913e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1428, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.3782, device='cuda:0') MSE:  tensor(1.4198e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0308, device='cuda:0')
min of d_p_list:  tensor(-0.0502, device='cuda:0')
Epoch:  524  
Training Loss: 324.7741394042969
Test Loss:  193.36117553710938
Test Acc:  0.0
Valid Loss:  247.70022583007812
Valid Acc:  0.0
std:  5.095572269078371 
thres:  0.33171240234375
Preserved_eigens number check:  36
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 52%|█████▏    | 524/1000 [33:27<30:54,  3.90s/it]Epoch:   525
max of grad d_p:  tensor(523.9234, device='cuda:0')
min of grad d_p:  tensor(-458.3083, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.6837, device='cuda:0') mean:  tensor(-6.2306e-05, device='cuda:0') min:  tensor(-1.1217, device='cuda:0') norm:  tensor(4.9393, device='cuda:0') MSE:  tensor(1.8541e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0955, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.3093, device='cuda:0') MSE:  tensor(1.1608e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.9987, device='cuda:0')
min of d_p_list:  tensor(-2.1050, device='cuda:0')
Epoch:  525  
Training Loss: 299.3572998046875
Test Loss:  165.2623291015625
Test Acc:  0.0
Valid Loss:  211.31961059570312
Valid Acc:  0.0
std:  12.605990760968803 
thres:  0.32368900146484375
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 52%|█████▎    | 525/1000 [33:30<30:16,  3.82s/it]Epoch:   526
max of grad d_p:  tensor(441.0233, device='cuda:0')
min of grad d_p:  tensor(-395.6020, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.3938, device='cuda:0') mean:  tensor(-6.5929e-05, device='cuda:0') min:  tensor(-1.1509, device='cuda:0') norm:  tensor(6.7473, device='cuda:0') MSE:  tensor(2.5328e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1231, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.4533, device='cuda:0') MSE:  tensor(1.7017e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0687, device='cuda:0')
min of d_p_list:  tensor(-0.0611, device='cuda:0')
Epoch:  526  
Training Loss: 296.247314453125
Test Loss:  163.60855102539062
Test Acc:  0.0
Valid Loss:  209.1265106201172
Valid Acc:  0.0
std:  15.033817968925163 
thres:  0.3159954772949219
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 53%|█████▎    | 526/1000 [33:34<30:33,  3.87s/it]Epoch:   527
max of grad d_p:  tensor(438.2451, device='cuda:0')
min of grad d_p:  tensor(-392.5888, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.8115, device='cuda:0') mean:  tensor(-7.0640e-05, device='cuda:0') min:  tensor(-1.0853, device='cuda:0') norm:  tensor(5.9898, device='cuda:0') MSE:  tensor(2.2484e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1938, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.9116, device='cuda:0') MSE:  tensor(3.4218e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1093, device='cuda:0')
min of d_p_list:  tensor(-0.2431, device='cuda:0')
Epoch:  527  
Training Loss: 293.6800231933594
Test Loss:  162.58859252929688
Test Acc:  0.0
Valid Loss:  207.79718017578125
Valid Acc:  0.0
std:  14.875180643108266 
thres:  0.3084521606445313
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  35
 53%|█████▎    | 527/1000 [33:38<31:03,  3.94s/it]Epoch:   528
max of grad d_p:  tensor(426.6249, device='cuda:0')
min of grad d_p:  tensor(-383.0011, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.9193, device='cuda:0') mean:  tensor(-7.1260e-06, device='cuda:0') min:  tensor(-1.2333, device='cuda:0') norm:  tensor(6.3269, device='cuda:0') MSE:  tensor(2.3750e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1317, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.4992, device='cuda:0') MSE:  tensor(1.8737e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0315, device='cuda:0')
min of d_p_list:  tensor(-0.0266, device='cuda:0')
Epoch:  528  
Training Loss: 290.69598388671875
Test Loss:  161.1630859375
Test Acc:  0.0
Valid Loss:  205.884033203125
Valid Acc:  0.0
std:  12.249399726581688 
thres:  0.30095095214843753
Preserved_eigens number check:  35
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  40
 53%|█████▎    | 528/1000 [33:42<30:25,  3.87s/it]Epoch:   529
max of grad d_p:  tensor(422.9974, device='cuda:0')
min of grad d_p:  tensor(-380.3268, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.7970, device='cuda:0') mean:  tensor(-6.2288e-05, device='cuda:0') min:  tensor(-1.1234, device='cuda:0') norm:  tensor(6.0260, device='cuda:0') MSE:  tensor(2.2620e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0959, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.5228, device='cuda:0') MSE:  tensor(1.9623e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1327, device='cuda:0')
min of d_p_list:  tensor(-0.0607, device='cuda:0')
Epoch:  529  
Training Loss: 287.8979187011719
Test Loss:  159.80946350097656
Test Acc:  0.0
Valid Loss:  204.03262329101562
Valid Acc:  0.0
std:  4.027536934317923 
thres:  0.2935757080078125
Preserved_eigens number check:  40
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 53%|█████▎    | 529/1000 [33:46<30:08,  3.84s/it]Epoch:   530
max of grad d_p:  tensor(420.6205, device='cuda:0')
min of grad d_p:  tensor(-377.3682, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.8403, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-1.0381, device='cuda:0') norm:  tensor(5.8986, device='cuda:0') MSE:  tensor(2.2142e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1425, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7534, device='cuda:0') MSE:  tensor(2.8279e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0644, device='cuda:0')
min of d_p_list:  tensor(-0.0352, device='cuda:0')
Epoch:  530  
Training Loss: 284.6744079589844
Test Loss:  158.5289306640625
Test Acc:  0.0
Valid Loss:  202.09083557128906
Valid Acc:  0.0
std:  4.093754879069515 
thres:  0.2906391296386719
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 53%|█████▎    | 530/1000 [33:50<30:05,  3.84s/it]Epoch:   531
max of grad d_p:  tensor(417.8842, device='cuda:0')
min of grad d_p:  tensor(-374.5973, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.9752, device='cuda:0') mean:  tensor(-8.6654e-05, device='cuda:0') min:  tensor(-0.9648, device='cuda:0') norm:  tensor(5.7766, device='cuda:0') MSE:  tensor(2.1684e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0819, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.2494, device='cuda:0') MSE:  tensor(9.3609e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0735, device='cuda:0')
min of d_p_list:  tensor(-0.0493, device='cuda:0')
Epoch:  531  
Training Loss: 281.623291015625
Test Loss:  156.95611572265625
Test Acc:  0.0
Valid Loss:  199.97039794921875
Valid Acc:  0.0
std:  4.2627536150516265 
thres:  0.2877143249511719
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 53%|█████▎    | 531/1000 [33:54<30:43,  3.93s/it]Epoch:   532
max of grad d_p:  tensor(413.6422, device='cuda:0')
min of grad d_p:  tensor(-370.8042, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.4512, device='cuda:0') mean:  tensor(-6.6891e-05, device='cuda:0') min:  tensor(-1.0502, device='cuda:0') norm:  tensor(5.2377, device='cuda:0') MSE:  tensor(1.9661e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0318, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.1554, device='cuda:0') MSE:  tensor(5.8331e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0966, device='cuda:0')
min of d_p_list:  tensor(-0.1199, device='cuda:0')
Epoch:  532  
Training Loss: 278.94451904296875
Test Loss:  155.4767303466797
Test Acc:  0.0
Valid Loss:  198.12506103515625
Valid Acc:  0.0
std:  4.213033718133718 
thres:  0.2847672241210938
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 53%|█████▎    | 532/1000 [33:58<30:48,  3.95s/it]Epoch:   533
max of grad d_p:  tensor(406.6231, device='cuda:0')
min of grad d_p:  tensor(-365.0385, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.8441, device='cuda:0') mean:  tensor(-9.2776e-05, device='cuda:0') min:  tensor(-1.0793, device='cuda:0') norm:  tensor(5.8380, device='cuda:0') MSE:  tensor(2.1914e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0846, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.2923, device='cuda:0') MSE:  tensor(1.0971e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(16.3783, device='cuda:0')
min of d_p_list:  tensor(-7.2842, device='cuda:0')
Epoch:  533  
Training Loss: 51287.296875
Test Loss:  68027.1484375
Test Acc:  0.0
Valid Loss:  65287.859375
Valid Acc:  0.0
std:  20401.604955970284 
thres:  10.48408740234375
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  53
 53%|█████▎    | 533/1000 [34:02<30:08,  3.87s/it]Epoch:   534
max of grad d_p:  tensor(25088.6074, device='cuda:0')
min of grad d_p:  tensor(-2964.8096, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.4004, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-2.1649, device='cuda:0') norm:  tensor(18.3426, device='cuda:0') MSE:  tensor(6.8854e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.7454, device='cuda:0') mean:  tensor(0.0082, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(13.4890, device='cuda:0') MSE:  tensor(5.0634e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0424, device='cuda:0')
min of d_p_list:  tensor(-0.0480, device='cuda:0')
Epoch:  534  
Training Loss: 50776.11328125
Test Loss:  67374.2578125
Test Acc:  0.0
Valid Loss:  64649.7734375
Valid Acc:  0.0
std:  24862.82572532109 
thres:  20.58173047485352
Preserved_eigens number check:  53
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  39
 53%|█████▎    | 534/1000 [34:05<30:04,  3.87s/it]Epoch:   535
max of grad d_p:  tensor(24918.0117, device='cuda:0')
min of grad d_p:  tensor(-2978.4446, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.3735, device='cuda:0') mean:  tensor(-0.0013, device='cuda:0') min:  tensor(-2.4629, device='cuda:0') norm:  tensor(21.1237, device='cuda:0') MSE:  tensor(7.9293e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(55.7262, device='cuda:0') mean:  tensor(0.1166, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(193.9345, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1678, device='cuda:0')
min of d_p_list:  tensor(-0.1530, device='cuda:0')
Epoch:  535  
Training Loss: 50292.171875
Test Loss:  66808.2421875
Test Acc:  0.0
Valid Loss:  64108.92578125
Valid Acc:  0.0
std:  24744.253465659847 
thres:  30.58322996826172
Preserved_eigens number check:  39
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 54%|█████▎    | 535/1000 [34:10<30:29,  3.93s/it]Epoch:   536
max of grad d_p:  tensor(24750.6797, device='cuda:0')
min of grad d_p:  tensor(-3038.8003, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.8291, device='cuda:0') mean:  tensor(-0.0013, device='cuda:0') min:  tensor(-2.7450, device='cuda:0') norm:  tensor(21.6472, device='cuda:0') MSE:  tensor(8.1258e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(15.2925, device='cuda:0') mean:  tensor(0.0356, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(58.3283, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(1.1442, device='cuda:0')
min of d_p_list:  tensor(-0.9406, device='cuda:0')
Epoch:  536  
Training Loss: 49005.0546875
Test Loss:  64110.58984375
Test Acc:  0.0
Valid Loss:  61438.90234375
Valid Acc:  0.0
std:  20038.822835777184 
thres:  40.32791624755859
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  36
 54%|█████▎    | 536/1000 [34:13<29:46,  3.85s/it]Epoch:   537
max of grad d_p:  tensor(24931.0684, device='cuda:0')
min of grad d_p:  tensor(-2820.1514, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.3401, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-2.2446, device='cuda:0') norm:  tensor(19.7056, device='cuda:0') MSE:  tensor(7.3970e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(10.8242, device='cuda:0') mean:  tensor(0.0301, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(44.5312, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1995, device='cuda:0')
min of d_p_list:  tensor(-0.2546, device='cuda:0')
Epoch:  537  
Training Loss: 48483.390625
Test Loss:  63422.6015625
Test Acc:  0.0
Valid Loss:  60727.796875
Valid Acc:  0.0
std:  1061.1318628297333 
thres:  49.96880546875
Preserved_eigens number check:  36
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  48
 54%|█████▎    | 537/1000 [34:17<29:47,  3.86s/it]Epoch:   538
max of grad d_p:  tensor(24529.0547, device='cuda:0')
min of grad d_p:  tensor(-2735.1560, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.9131, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-2.2407, device='cuda:0') norm:  tensor(19.9265, device='cuda:0') MSE:  tensor(7.4799e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.4707, device='cuda:0') mean:  tensor(0.0100, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(14.3023, device='cuda:0') MSE:  tensor(5.3687e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1913, device='cuda:0')
min of d_p_list:  tensor(-0.1868, device='cuda:0')
Epoch:  538  
Training Loss: 48044.75
Test Loss:  62855.61328125
Test Acc:  0.0
Valid Loss:  60158.4921875
Valid Acc:  0.0
std:  1047.926711437372 
thres:  49.32029609375
Preserved_eigens number check:  48
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  34
 54%|█████▍    | 538/1000 [34:21<30:00,  3.90s/it]Epoch:   539
max of grad d_p:  tensor(24102.5391, device='cuda:0')
min of grad d_p:  tensor(-2748.5049, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.9434, device='cuda:0') mean:  tensor(-0.0010, device='cuda:0') min:  tensor(-2.3208, device='cuda:0') norm:  tensor(20.6216, device='cuda:0') MSE:  tensor(7.7408e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.3770, device='cuda:0') mean:  tensor(0.0100, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(15.4863, device='cuda:0') MSE:  tensor(5.8132e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0526, device='cuda:0')
min of d_p_list:  tensor(-0.0464, device='cuda:0')
Epoch:  539  
Training Loss: 47553.62109375
Test Loss:  62255.265625
Test Acc:  0.0
Valid Loss:  59573.60546875
Valid Acc:  0.0
std:  939.7443966552405 
thres:  48.67579765625
Preserved_eigens number check:  34
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 54%|█████▍    | 539/1000 [34:25<30:00,  3.91s/it]Epoch:   540
max of grad d_p:  tensor(24054.7109, device='cuda:0')
min of grad d_p:  tensor(-2681.1990, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.7500, device='cuda:0') mean:  tensor(-0.0007, device='cuda:0') min:  tensor(-2.1270, device='cuda:0') norm:  tensor(19.4191, device='cuda:0') MSE:  tensor(7.2894e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(25.4668, device='cuda:0') mean:  tensor(0.1072, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(159.8535, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.6867, device='cuda:0')
min of d_p_list:  tensor(-0.3736, device='cuda:0')
Epoch:  540  
Training Loss: 47216.953125
Test Loss:  61834.40234375
Test Acc:  0.0
Valid Loss:  59184.21875
Valid Acc:  0.0
std:  638.7120375368944 
thres:  48.06075390625
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  89
 54%|█████▍    | 540/1000 [34:28<28:45,  3.75s/it]Epoch:   541
max of grad d_p:  tensor(24546.0566, device='cuda:0')
min of grad d_p:  tensor(-2731.5239, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.1025, device='cuda:0') mean:  tensor(-0.0007, device='cuda:0') min:  tensor(-2.0815, device='cuda:0') norm:  tensor(18.5774, device='cuda:0') MSE:  tensor(6.9735e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.6777, device='cuda:0') mean:  tensor(0.0051, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(7.3336, device='cuda:0') MSE:  tensor(2.7529e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0367, device='cuda:0')
min of d_p_list:  tensor(-0.0258, device='cuda:0')
Epoch:  541  
Training Loss: 46729.24609375
Test Loss:  61212.5078125
Test Acc:  0.0
Valid Loss:  58595.546875
Valid Acc:  0.0
std:  614.0217378358132 
thres:  47.6055921875
Preserved_eigens number check:  89
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 54%|█████▍    | 541/1000 [34:32<29:02,  3.80s/it]Epoch:   542
max of grad d_p:  tensor(24359.9453, device='cuda:0')
min of grad d_p:  tensor(-2704.1328, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.1299, device='cuda:0') mean:  tensor(-0.0008, device='cuda:0') min:  tensor(-2.5439, device='cuda:0') norm:  tensor(20.4388, device='cuda:0') MSE:  tensor(7.6722e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.9102, device='cuda:0') mean:  tensor(0.0071, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(11.1457, device='cuda:0') MSE:  tensor(4.1838e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.5819, device='cuda:0')
min of d_p_list:  tensor(-0.7480, device='cuda:0')
Epoch:  542  
Training Loss: 46579.109375
Test Loss:  60955.68359375
Test Acc:  0.0
Valid Loss:  58346.0
Valid Acc:  0.0
std:  537.2137236398037 
thres:  47.2247359375
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 54%|█████▍    | 542/1000 [34:36<28:56,  3.79s/it]Epoch:   543
max of grad d_p:  tensor(24821.4922, device='cuda:0')
min of grad d_p:  tensor(-2482.2798, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.0674, device='cuda:0') mean:  tensor(-0.0018, device='cuda:0') min:  tensor(-2.9785, device='cuda:0') norm:  tensor(21.7697, device='cuda:0') MSE:  tensor(8.1718e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.1226, device='cuda:0') mean:  tensor(0.0063, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(9.5250, device='cuda:0') MSE:  tensor(3.5755e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1308, device='cuda:0')
min of d_p_list:  tensor(-0.0879, device='cuda:0')
Epoch:  543  
Training Loss: 46112.85546875
Test Loss:  60338.4375
Test Acc:  0.0
Valid Loss:  57752.0703125
Valid Acc:  0.0
std:  502.07663607261213 
thres:  46.838357031250005
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  119
 54%|█████▍    | 543/1000 [34:40<29:14,  3.84s/it]Epoch:   544
max of grad d_p:  tensor(24752.9707, device='cuda:0')
min of grad d_p:  tensor(-2458.1245, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.0693, device='cuda:0') mean:  tensor(-0.0015, device='cuda:0') min:  tensor(-2.5190, device='cuda:0') norm:  tensor(20.9537, device='cuda:0') MSE:  tensor(7.8655e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.5764, device='cuda:0') mean:  tensor(0.0102, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(14.4895, device='cuda:0') MSE:  tensor(5.4390e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0219, device='cuda:0')
min of d_p_list:  tensor(-0.0311, device='cuda:0')
Epoch:  544  
Training Loss: 45645.9375
Test Loss:  59764.765625
Test Acc:  0.0
Valid Loss:  57205.66015625
Valid Acc:  0.0
std:  537.1806145198901 
thres:  46.4568203125
Preserved_eigens number check:  119
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  36
 54%|█████▍    | 544/1000 [34:44<28:59,  3.81s/it]Epoch:   545
max of grad d_p:  tensor(24620.8477, device='cuda:0')
min of grad d_p:  tensor(-2437.5059, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.2578, device='cuda:0') mean:  tensor(-0.0012, device='cuda:0') min:  tensor(-2.2954, device='cuda:0') norm:  tensor(19.5946, device='cuda:0') MSE:  tensor(7.3553e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(11.5713, device='cuda:0') mean:  tensor(0.0294, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(48.4179, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0488, device='cuda:0')
min of d_p_list:  tensor(-0.0335, device='cuda:0')
Epoch:  545  
Training Loss: 45191.984375
Test Loss:  59187.984375
Test Acc:  0.0
Valid Loss:  56667.390625
Valid Acc:  0.0
std:  573.5369964591413 
thres:  46.0518265625
Preserved_eigens number check:  36
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  34
 55%|█████▍    | 545/1000 [34:48<29:24,  3.88s/it]Epoch:   546
max of grad d_p:  tensor(24511.2676, device='cuda:0')
min of grad d_p:  tensor(-2402.4451, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.4600, device='cuda:0') mean:  tensor(-0.0016, device='cuda:0') min:  tensor(-2.4209, device='cuda:0') norm:  tensor(21.4234, device='cuda:0') MSE:  tensor(8.0418e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.5125, device='cuda:0') mean:  tensor(0.0079, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(12.0991, device='cuda:0') MSE:  tensor(4.5417e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1426, device='cuda:0')
min of d_p_list:  tensor(-0.0834, device='cuda:0')
Epoch:  546  
Training Loss: 44752.25
Test Loss:  58645.1640625
Test Acc:  0.0
Valid Loss:  56132.8125
Valid Acc:  0.0
std:  646.996559662671 
thres:  45.65642734375
Preserved_eigens number check:  34
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  31
 55%|█████▍    | 546/1000 [34:51<28:55,  3.82s/it]Epoch:   547
max of grad d_p:  tensor(24475.9258, device='cuda:0')
min of grad d_p:  tensor(-2467.2800, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.0664, device='cuda:0') mean:  tensor(-0.0017, device='cuda:0') min:  tensor(-2.5454, device='cuda:0') norm:  tensor(20.2944, device='cuda:0') MSE:  tensor(7.6180e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.2844, device='cuda:0') mean:  tensor(0.0048, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(7.5551, device='cuda:0') MSE:  tensor(2.8360e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0256, device='cuda:0')
min of d_p_list:  tensor(-0.0410, device='cuda:0')
Epoch:  547  
Training Loss: 44306.7890625
Test Loss:  58083.02734375
Test Acc:  0.0
Valid Loss:  55591.65625
Valid Acc:  0.0
std:  637.2622976421042 
thres:  45.20196328125
Preserved_eigens number check:  31
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 55%|█████▍    | 547/1000 [34:55<29:11,  3.87s/it]Epoch:   548
max of grad d_p:  tensor(24340.5039, device='cuda:0')
min of grad d_p:  tensor(-2450.2410, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.7354, device='cuda:0') mean:  tensor(-0.0010, device='cuda:0') min:  tensor(-2.1091, device='cuda:0') norm:  tensor(18.6528, device='cuda:0') MSE:  tensor(7.0018e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(16.5574, device='cuda:0') mean:  tensor(0.0469, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(73.3660, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0530, device='cuda:0')
min of d_p_list:  tensor(-0.0750, device='cuda:0')
Epoch:  548  
Training Loss: 43856.33203125
Test Loss:  57493.3203125
Test Acc:  0.0
Valid Loss:  55030.890625
Valid Acc:  0.0
std:  631.3692198565168 
thres:  44.750658593749996
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 55%|█████▍    | 548/1000 [34:59<29:14,  3.88s/it]Epoch:   549
max of grad d_p:  tensor(24280.7852, device='cuda:0')
min of grad d_p:  tensor(-2376.1543, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.3779, device='cuda:0') mean:  tensor(-0.0012, device='cuda:0') min:  tensor(-2.3643, device='cuda:0') norm:  tensor(19.1074, device='cuda:0') MSE:  tensor(7.1724e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.1385, device='cuda:0') mean:  tensor(0.0055, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(8.4987, device='cuda:0') MSE:  tensor(3.1902e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0297, device='cuda:0')
min of d_p_list:  tensor(-0.0278, device='cuda:0')
Epoch:  549  
Training Loss: 43417.27734375
Test Loss:  56933.9296875
Test Acc:  0.0
Valid Loss:  54503.8125
Valid Acc:  0.0
std:  628.6702598938881 
thres:  44.3049265625
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  38
 55%|█████▍    | 549/1000 [35:03<29:26,  3.92s/it]Epoch:   550
max of grad d_p:  tensor(24107.9375, device='cuda:0')
min of grad d_p:  tensor(-2343.7832, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.4707, device='cuda:0') mean:  tensor(-0.0013, device='cuda:0') min:  tensor(-2.4412, device='cuda:0') norm:  tensor(18.6187, device='cuda:0') MSE:  tensor(6.9890e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(15.1547, device='cuda:0') mean:  tensor(0.0445, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(63.4287, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0301, device='cuda:0')
min of d_p_list:  tensor(-0.0200, device='cuda:0')
Epoch:  550  
Training Loss: 42982.9765625
Test Loss:  56370.3828125
Test Acc:  0.0
Valid Loss:  53978.5
Valid Acc:  0.0
std:  626.2377527777692 
thres:  43.863125000000004
Preserved_eigens number check:  38
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 55%|█████▌    | 550/1000 [35:07<29:39,  3.95s/it]Epoch:   551
max of grad d_p:  tensor(23985.0312, device='cuda:0')
min of grad d_p:  tensor(-2345.1926, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.8811, device='cuda:0') mean:  tensor(-0.0013, device='cuda:0') min:  tensor(-2.3916, device='cuda:0') norm:  tensor(19.0360, device='cuda:0') MSE:  tensor(7.1456e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.5918, device='cuda:0') mean:  tensor(0.0081, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(11.6437, device='cuda:0') MSE:  tensor(4.3707e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0273, device='cuda:0')
min of d_p_list:  tensor(-0.0372, device='cuda:0')
Epoch:  551  
Training Loss: 42550.6328125
Test Loss:  55809.109375
Test Acc:  0.0
Valid Loss:  53448.68359375
Valid Acc:  0.0
std:  620.2479252017221 
thres:  43.4228015625
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 55%|█████▌    | 551/1000 [35:11<29:17,  3.91s/it]Epoch:   552
max of grad d_p:  tensor(23868.6699, device='cuda:0')
min of grad d_p:  tensor(-2320.0051, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.8284, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-1.9639, device='cuda:0') norm:  tensor(16.9859, device='cuda:0') MSE:  tensor(6.3760e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.8691, device='cuda:0') mean:  tensor(0.0057, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(9.6370, device='cuda:0') MSE:  tensor(3.6175e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0422, device='cuda:0')
min of d_p_list:  tensor(-0.0561, device='cuda:0')
Epoch:  552  
Training Loss: 42133.1015625
Test Loss:  55291.56640625
Test Acc:  0.0
Valid Loss:  52943.1953125
Valid Acc:  0.0
std:  609.9911743456138 
thres:  42.9880640625
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  33
 55%|█████▌    | 552/1000 [35:15<29:03,  3.89s/it]Epoch:   553
max of grad d_p:  tensor(23863.7383, device='cuda:0')
min of grad d_p:  tensor(-2265.3259, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.8594, device='cuda:0') mean:  tensor(-0.0013, device='cuda:0') min:  tensor(-2.0767, device='cuda:0') norm:  tensor(18.5657, device='cuda:0') MSE:  tensor(6.9691e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.6400, device='cuda:0') mean:  tensor(0.0110, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(16.3888, device='cuda:0') MSE:  tensor(6.1519e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1045, device='cuda:0')
min of d_p_list:  tensor(-0.1506, device='cuda:0')
Epoch:  553  
Training Loss: 41724.65625
Test Loss:  54808.4375
Test Acc:  0.0
Valid Loss:  52439.1328125
Valid Acc:  0.0
std:  598.9904626541111 
thres:  42.561728906249996
Preserved_eigens number check:  33
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 55%|█████▌    | 553/1000 [35:19<29:08,  3.91s/it]Epoch:   554
max of grad d_p:  tensor(23824.0508, device='cuda:0')
min of grad d_p:  tensor(-2259.4058, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.6016, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-2.2883, device='cuda:0') norm:  tensor(16.2072, device='cuda:0') MSE:  tensor(6.0838e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.9821, device='cuda:0') mean:  tensor(0.0237, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(37.4585, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0671, device='cuda:0')
min of d_p_list:  tensor(-0.1412, device='cuda:0')
Epoch:  554  
Training Loss: 41315.11328125
Test Loss:  54269.14453125
Test Acc:  0.0
Valid Loss:  51904.3515625
Valid Acc:  0.0
std:  588.5943442142608 
thres:  42.14129609375
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 55%|█████▌    | 554/1000 [35:23<29:28,  3.97s/it]Epoch:   555
max of grad d_p:  tensor(23694.4805, device='cuda:0')
min of grad d_p:  tensor(-2221.0225, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.2256, device='cuda:0') mean:  tensor(-0.0020, device='cuda:0') min:  tensor(-2.7568, device='cuda:0') norm:  tensor(21.3399, device='cuda:0') MSE:  tensor(8.0104e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.7532, device='cuda:0') mean:  tensor(0.0185, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(28.8460, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0283, device='cuda:0')
min of d_p_list:  tensor(-0.0520, device='cuda:0')
Epoch:  555  
Training Loss: 40903.671875
Test Loss:  53724.1875
Test Acc:  0.0
Valid Loss:  51385.125
Valid Acc:  0.0
std:  581.5157106862224 
thres:  41.72543515625
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  35
 56%|█████▌    | 555/1000 [35:27<28:50,  3.89s/it]Epoch:   556
max of grad d_p:  tensor(23559.4648, device='cuda:0')
min of grad d_p:  tensor(-2197.4238, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.2432, device='cuda:0') mean:  tensor(-0.0015, device='cuda:0') min:  tensor(-2.3552, device='cuda:0') norm:  tensor(19.1815, device='cuda:0') MSE:  tensor(7.2002e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.0229, device='cuda:0') mean:  tensor(0.0097, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(14.6581, device='cuda:0') MSE:  tensor(5.5023e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0602, device='cuda:0')
min of d_p_list:  tensor(-0.1928, device='cuda:0')
Epoch:  556  
Training Loss: 40536.56640625
Test Loss:  53245.68359375
Test Acc:  0.0
Valid Loss:  50937.3359375
Valid Acc:  0.0
std:  567.7970841706785 
thres:  41.322621874999996
Preserved_eigens number check:  35
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 56%|█████▌    | 556/1000 [35:30<28:07,  3.80s/it]Epoch:   557
max of grad d_p:  tensor(23659.7930, device='cuda:0')
min of grad d_p:  tensor(-2128.0156, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.7024, device='cuda:0') mean:  tensor(-0.0015, device='cuda:0') min:  tensor(-2.5142, device='cuda:0') norm:  tensor(19.3345, device='cuda:0') MSE:  tensor(7.2577e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.3560, device='cuda:0') mean:  tensor(0.0161, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(25.7347, device='cuda:0') MSE:  tensor(9.6601e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0502, device='cuda:0')
min of d_p_list:  tensor(-0.1152, device='cuda:0')
Epoch:  557  
Training Loss: 40119.6015625
Test Loss:  52730.859375
Test Acc:  0.0
Valid Loss:  50433.515625
Valid Acc:  0.0
std:  564.1829033923525 
thres:  40.919921875
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  73
 56%|█████▌    | 557/1000 [35:34<28:04,  3.80s/it]Epoch:   558
max of grad d_p:  tensor(23601.1797, device='cuda:0')
min of grad d_p:  tensor(-2152.4509, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.7007, device='cuda:0') mean:  tensor(-0.0015, device='cuda:0') min:  tensor(-2.7361, device='cuda:0') norm:  tensor(19.3700, device='cuda:0') MSE:  tensor(7.2710e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.6721, device='cuda:0') mean:  tensor(0.0063, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(9.5248, device='cuda:0') MSE:  tensor(3.5753e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1077, device='cuda:0')
min of d_p_list:  tensor(-0.1405, device='cuda:0')
Epoch:  558  
Training Loss: 39704.02734375
Test Loss:  52125.5625
Test Acc:  0.0
Valid Loss:  49870.5390625
Valid Acc:  0.0
std:  566.6966743970755 
thres:  40.515796093750005
Preserved_eigens number check:  73
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  36
 56%|█████▌    | 558/1000 [35:38<28:19,  3.85s/it]Epoch:   559
max of grad d_p:  tensor(23857.7109, device='cuda:0')
min of grad d_p:  tensor(-2080.9487, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.1660, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-2.2664, device='cuda:0') norm:  tensor(17.4119, device='cuda:0') MSE:  tensor(6.5360e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(10.3085, device='cuda:0') mean:  tensor(0.0262, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(39.8265, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0398, device='cuda:0')
min of d_p_list:  tensor(-0.0259, device='cuda:0')
Epoch:  559  
Training Loss: 39307.86328125
Test Loss:  51605.16015625
Test Acc:  0.0
Valid Loss:  49375.31640625
Valid Acc:  0.0
std:  569.2290935370003 
thres:  40.11434609375
Preserved_eigens number check:  36
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 56%|█████▌    | 559/1000 [35:42<28:27,  3.87s/it]Epoch:   560
max of grad d_p:  tensor(23773.3945, device='cuda:0')
min of grad d_p:  tensor(-2082.6499, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.5029, device='cuda:0') mean:  tensor(-0.0008, device='cuda:0') min:  tensor(-1.8228, device='cuda:0') norm:  tensor(15.0248, device='cuda:0') MSE:  tensor(5.6399e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.5251, device='cuda:0') mean:  tensor(0.0077, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(13.0304, device='cuda:0') MSE:  tensor(4.8913e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1298, device='cuda:0')
min of d_p_list:  tensor(-0.1440, device='cuda:0')
Epoch:  560  
Training Loss: 38907.46875
Test Loss:  51057.6484375
Test Acc:  0.0
Valid Loss:  48910.90625
Valid Acc:  0.0
std:  575.6146550087054 
thres:  39.715105468750004
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 56%|█████▌    | 560/1000 [35:46<28:05,  3.83s/it]Epoch:   561
max of grad d_p:  tensor(23738.5273, device='cuda:0')
min of grad d_p:  tensor(-2185.3511, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.1611, device='cuda:0') mean:  tensor(-0.0018, device='cuda:0') min:  tensor(-2.1978, device='cuda:0') norm:  tensor(22.2863, device='cuda:0') MSE:  tensor(8.3657e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.0968, device='cuda:0') mean:  tensor(0.0070, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(10.8504, device='cuda:0') MSE:  tensor(4.0730e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2492, device='cuda:0')
min of d_p_list:  tensor(-0.2307, device='cuda:0')
Epoch:  561  
Training Loss: 38583.25390625
Test Loss:  50713.78125
Test Acc:  0.0
Valid Loss:  48546.9921875
Valid Acc:  0.0
std:  547.6979274140112 
thres:  39.32444296875
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  56
 56%|█████▌    | 561/1000 [35:49<27:18,  3.73s/it]Epoch:   562
max of grad d_p:  tensor(23660.4609, device='cuda:0')
min of grad d_p:  tensor(-2116.8999, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(2.7949, device='cuda:0') mean:  tensor(-0.0013, device='cuda:0') min:  tensor(-2.2983, device='cuda:0') norm:  tensor(19.1072, device='cuda:0') MSE:  tensor(7.1724e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(30.0510, device='cuda:0') mean:  tensor(0.0695, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(107.1147, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0370, device='cuda:0')
min of d_p_list:  tensor(-0.0862, device='cuda:0')
Epoch:  562  
Training Loss: 38197.2578125
Test Loss:  50204.7265625
Test Acc:  0.0
Valid Loss:  48057.828125
Valid Acc:  0.0
std:  528.9713011290999 
thres:  38.93997421875
Preserved_eigens number check:  56
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 56%|█████▌    | 562/1000 [35:53<27:39,  3.79s/it]Epoch:   563
max of grad d_p:  tensor(23469.2500, device='cuda:0')
min of grad d_p:  tensor(-2111.4468, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.5732, device='cuda:0') mean:  tensor(-0.0014, device='cuda:0') min:  tensor(-2.3831, device='cuda:0') norm:  tensor(20.6665, device='cuda:0') MSE:  tensor(7.7577e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(11.7746, device='cuda:0') mean:  tensor(0.0288, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(45.1040, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0204, device='cuda:0')
min of d_p_list:  tensor(-0.0203, device='cuda:0')
Epoch:  563  
Training Loss: 37815.8359375
Test Loss:  49701.36328125
Test Acc:  0.0
Valid Loss:  47584.796875
Valid Acc:  0.0
std:  522.6680643225168 
thres:  38.5623359375
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  38
 56%|█████▋    | 563/1000 [35:57<27:31,  3.78s/it]Epoch:   564
max of grad d_p:  tensor(23380.7812, device='cuda:0')
min of grad d_p:  tensor(-2091.6875, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.0234, device='cuda:0') mean:  tensor(-0.0015, device='cuda:0') min:  tensor(-2.3506, device='cuda:0') norm:  tensor(18.8303, device='cuda:0') MSE:  tensor(7.0684e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.5092, device='cuda:0') mean:  tensor(0.0043, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(6.2272, device='cuda:0') MSE:  tensor(2.3375e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2034, device='cuda:0')
min of d_p_list:  tensor(-0.1407, device='cuda:0')
Epoch:  564  
Training Loss: 37459.77734375
Test Loss:  49283.921875
Test Acc:  0.0
Valid Loss:  47184.6171875
Valid Acc:  0.0
std:  518.1987327675027 
thres:  38.19271875
Preserved_eigens number check:  38
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  52
 56%|█████▋    | 564/1000 [36:01<27:42,  3.81s/it]Epoch:   565
max of grad d_p:  tensor(23543.6875, device='cuda:0')
min of grad d_p:  tensor(-2070.2708, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.1182, device='cuda:0') mean:  tensor(-0.0015, device='cuda:0') min:  tensor(-2.4277, device='cuda:0') norm:  tensor(18.4699, device='cuda:0') MSE:  tensor(6.9331e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(12.5037, device='cuda:0') mean:  tensor(0.0233, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(36.3169, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0920, device='cuda:0')
min of d_p_list:  tensor(-0.0610, device='cuda:0')
Epoch:  565  
Training Loss: 37073.05078125
Test Loss:  48810.84375
Test Acc:  0.0
Valid Loss:  46714.8828125
Valid Acc:  0.0
std:  531.4923469137452 
thres:  37.82583515625
Preserved_eigens number check:  52
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 56%|█████▋    | 565/1000 [36:05<27:32,  3.80s/it]Epoch:   566
max of grad d_p:  tensor(23429.6172, device='cuda:0')
min of grad d_p:  tensor(-2022.5243, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.7764, device='cuda:0') mean:  tensor(-0.0015, device='cuda:0') min:  tensor(-2.3245, device='cuda:0') norm:  tensor(19.6677, device='cuda:0') MSE:  tensor(7.3827e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.8156, device='cuda:0') mean:  tensor(0.0090, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(12.7968, device='cuda:0') MSE:  tensor(4.8036e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0305, device='cuda:0')
min of d_p_list:  tensor(-0.0315, device='cuda:0')
Epoch:  566  
Training Loss: 36701.40625
Test Loss:  48322.8359375
Test Acc:  0.0
Valid Loss:  46247.4921875
Valid Acc:  0.0
std:  528.1680899546449 
thres:  37.449465624999995
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  79
 57%|█████▋    | 566/1000 [36:09<28:12,  3.90s/it]Epoch:   567
max of grad d_p:  tensor(23275.9180, device='cuda:0')
min of grad d_p:  tensor(-2025.3298, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.2363, device='cuda:0') mean:  tensor(-0.0015, device='cuda:0') min:  tensor(-2.5449, device='cuda:0') norm:  tensor(19.5899, device='cuda:0') MSE:  tensor(7.3535e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.9574, device='cuda:0') mean:  tensor(0.0116, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(17.8268, device='cuda:0') MSE:  tensor(6.6917e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0394, device='cuda:0')
min of d_p_list:  tensor(-0.0182, device='cuda:0')
Epoch:  567  
Training Loss: 36331.125
Test Loss:  47830.0859375
Test Acc:  0.0
Valid Loss:  45783.546875
Valid Acc:  0.0
std:  527.2210009651005 
thres:  37.0762390625
Preserved_eigens number check:  79
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 57%|█████▋    | 567/1000 [36:13<28:20,  3.93s/it]Epoch:   568
max of grad d_p:  tensor(23157.6445, device='cuda:0')
min of grad d_p:  tensor(-1991.2882, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.0264, device='cuda:0') mean:  tensor(-0.0011, device='cuda:0') min:  tensor(-2.2190, device='cuda:0') norm:  tensor(17.6616, device='cuda:0') MSE:  tensor(6.6297e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.9799, device='cuda:0') mean:  tensor(0.0113, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(19.4355, device='cuda:0') MSE:  tensor(7.2956e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(16.8778, device='cuda:0')
min of d_p_list:  tensor(-19.4973, device='cuda:0')
Epoch:  568  
Training Loss: 2400654.0
Test Loss:  1525980.625
Test Acc:  0.0
Valid Loss:  1921378.25
Valid Acc:  0.0
std:  945505.1387374537 
thres:  509.643871875
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  70
 57%|█████▋    | 568/1000 [36:17<28:21,  3.94s/it]Epoch:   569
max of grad d_p:  tensor(919372., device='cuda:0')
min of grad d_p:  tensor(-153067.7500, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(14., device='cuda:0') mean:  tensor(-0.0025, device='cuda:0') min:  tensor(-13., device='cuda:0') norm:  tensor(84.4616, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(455.3477, device='cuda:0') mean:  tensor(0.5337, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1229.5596, device='cuda:0') MSE:  tensor(0.0046, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0862, device='cuda:0')
min of d_p_list:  tensor(-0.0477, device='cuda:0')
Epoch:  569  
Training Loss: 2376397.5
Test Loss:  1511017.25
Test Acc:  0.0
Valid Loss:  1902958.25
Valid Acc:  0.0
std:  1152179.256174258 
thres:  977.43141640625
Preserved_eigens number check:  70
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  61
 57%|█████▋    | 569/1000 [36:21<27:51,  3.88s/it]Epoch:   570
max of grad d_p:  tensor(911599.8750, device='cuda:0')
min of grad d_p:  tensor(-151092.5312, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(14.1094, device='cuda:0') mean:  tensor(-0.0021, device='cuda:0') min:  tensor(-9.0156, device='cuda:0') norm:  tensor(72.0686, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(300.3144, device='cuda:0') mean:  tensor(0.5779, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1338.2609, device='cuda:0') MSE:  tensor(0.0050, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0635, device='cuda:0')
min of d_p_list:  tensor(-0.0355, device='cuda:0')
Epoch:  570  
Training Loss: 2352491.5
Test Loss:  1495656.5
Test Acc:  0.0
Valid Loss:  1884699.0
Valid Acc:  0.0
std:  1146461.429834144 
thres:  1440.51510625
Preserved_eigens number check:  61
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  115
 57%|█████▋    | 570/1000 [36:24<27:49,  3.88s/it]Epoch:   571
max of grad d_p:  tensor(911132.6250, device='cuda:0')
min of grad d_p:  tensor(-149600.6875, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(13.2188, device='cuda:0') mean:  tensor(-0.0019, device='cuda:0') min:  tensor(-12.7031, device='cuda:0') norm:  tensor(80.7607, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(241.8242, device='cuda:0') mean:  tensor(0.2848, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(658.7164, device='cuda:0') MSE:  tensor(0.0025, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2845, device='cuda:0')
min of d_p_list:  tensor(-0.2273, device='cuda:0')
Epoch:  571  
Training Loss: 2335839.5
Test Loss:  1484515.125
Test Acc:  0.0
Valid Loss:  1870949.75
Valid Acc:  0.0
std:  932263.3449188472 
thres:  1900.3427250000002
Preserved_eigens number check:  115
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  53
 57%|█████▋    | 571/1000 [36:28<28:01,  3.92s/it]Epoch:   572
max of grad d_p:  tensor(910408.7500, device='cuda:0')
min of grad d_p:  tensor(-148181.9844, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(14.3125, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-12.3281, device='cuda:0') norm:  tensor(94.1450, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(38.3750, device='cuda:0') mean:  tensor(0.0810, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(184.6320, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1438, device='cuda:0')
min of d_p_list:  tensor(-0.2744, device='cuda:0')
Epoch:  572  
Training Loss: 2314449.0
Test Loss:  1470632.875
Test Acc:  0.0
Valid Loss:  1855031.125
Valid Acc:  0.0
std:  30183.68094616692 
thres:  2355.9663
Preserved_eigens number check:  53
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  143
 57%|█████▋    | 572/1000 [36:32<27:40,  3.88s/it]Epoch:   573
max of grad d_p:  tensor(914155.8125, device='cuda:0')
min of grad d_p:  tensor(-146646.8750, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.7891, device='cuda:0') mean:  tensor(-0.0018, device='cuda:0') min:  tensor(-10.5781, device='cuda:0') norm:  tensor(79.3281, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(667.3047, device='cuda:0') mean:  tensor(1.4980, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(3420., device='cuda:0') MSE:  tensor(0.0128, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2941, device='cuda:0')
min of d_p_list:  tensor(-0.5256, device='cuda:0')
Epoch:  573  
Training Loss: 2297855.0
Test Loss:  1461995.75
Test Acc:  0.0
Valid Loss:  1843138.25
Valid Acc:  0.0
std:  27646.62277204939 
thres:  2335.4065
Preserved_eigens number check:  143
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  124
 57%|█████▋    | 573/1000 [36:36<27:47,  3.90s/it]Epoch:   574
max of grad d_p:  tensor(935249.3750, device='cuda:0')
min of grad d_p:  tensor(-147556.2031, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(13.8828, device='cuda:0') mean:  tensor(-0.0030, device='cuda:0') min:  tensor(-12.7188, device='cuda:0') norm:  tensor(83.8357, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(86.4805, device='cuda:0') mean:  tensor(0.2258, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(485.0456, device='cuda:0') MSE:  tensor(0.0018, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1774, device='cuda:0')
min of d_p_list:  tensor(-0.2946, device='cuda:0')
Epoch:  574  
Training Loss: 2279404.0
Test Loss:  1449777.75
Test Acc:  0.0
Valid Loss:  1825675.0
Valid Acc:  0.0
std:  26062.037028214047 
thres:  2316.0078
Preserved_eigens number check:  124
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  93
 57%|█████▋    | 574/1000 [36:40<27:31,  3.88s/it]Epoch:   575
max of grad d_p:  tensor(919295.1250, device='cuda:0')
min of grad d_p:  tensor(-145428.1250, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(15.3750, device='cuda:0') mean:  tensor(-0.0015, device='cuda:0') min:  tensor(-13.1406, device='cuda:0') norm:  tensor(91.7644, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(38.4648, device='cuda:0') mean:  tensor(0.0548, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(142.3925, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0481, device='cuda:0')
min of d_p_list:  tensor(-0.1074, device='cuda:0')
Epoch:  575  
Training Loss: 2257132.5
Test Loss:  1435649.125
Test Acc:  0.0
Valid Loss:  1807660.125
Valid Acc:  0.0
std:  27249.666708053515 
thres:  2296.936
Preserved_eigens number check:  93
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  130
 57%|█████▊    | 575/1000 [36:44<26:43,  3.77s/it]Epoch:   576
max of grad d_p:  tensor(906077., device='cuda:0')
min of grad d_p:  tensor(-144050.4062, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(14.8203, device='cuda:0') mean:  tensor(-0.0015, device='cuda:0') min:  tensor(-12.3438, device='cuda:0') norm:  tensor(85.9146, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(34.4927, device='cuda:0') mean:  tensor(0.0584, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(142.1128, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0356, device='cuda:0')
min of d_p_list:  tensor(-0.0436, device='cuda:0')
Epoch:  576  
Training Loss: 2234749.0
Test Loss:  1421276.875
Test Acc:  0.0
Valid Loss:  1789780.0
Valid Acc:  0.0
std:  28364.077623642195 
thres:  2276.7179
Preserved_eigens number check:  130
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  86
 58%|█████▊    | 576/1000 [36:47<25:56,  3.67s/it]Epoch:   577
max of grad d_p:  tensor(900307.0625, device='cuda:0')
min of grad d_p:  tensor(-142107.7344, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.6094, device='cuda:0') mean:  tensor(-0.0020, device='cuda:0') min:  tensor(-9.5000, device='cuda:0') norm:  tensor(71.7874, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(50.6602, device='cuda:0') mean:  tensor(0.0636, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(154.2304, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0651, device='cuda:0')
min of d_p_list:  tensor(-0.0589, device='cuda:0')
Epoch:  577  
Training Loss: 2212971.75
Test Loss:  1407046.0
Test Acc:  0.0
Valid Loss:  1772028.75
Valid Acc:  0.0
std:  30341.436275496253 
thres:  2256.42245
Preserved_eigens number check:  86
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  46
 58%|█████▊    | 577/1000 [36:50<24:59,  3.54s/it]Epoch:   578
max of grad d_p:  tensor(891175.5000, device='cuda:0')
min of grad d_p:  tensor(-141178.6875, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.9453, device='cuda:0') mean:  tensor(-0.0027, device='cuda:0') min:  tensor(-10.1094, device='cuda:0') norm:  tensor(75.4950, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(198.5508, device='cuda:0') mean:  tensor(0.5780, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1315.1733, device='cuda:0') MSE:  tensor(0.0049, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0929, device='cuda:0')
min of d_p_list:  tensor(-0.0546, device='cuda:0')
Epoch:  578  
Training Loss: 2191010.0
Test Loss:  1392865.5
Test Acc:  0.0
Valid Loss:  1754655.625
Valid Acc:  0.0
std:  31247.321122937883 
thres:  2235.0534500000003
Preserved_eigens number check:  46
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  65
 58%|█████▊    | 578/1000 [36:54<25:51,  3.68s/it]Epoch:   579
max of grad d_p:  tensor(884927.8750, device='cuda:0')
min of grad d_p:  tensor(-139918.8438, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.5469, device='cuda:0') mean:  tensor(-0.0010, device='cuda:0') min:  tensor(-10.3906, device='cuda:0') norm:  tensor(78.8926, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(34.9648, device='cuda:0') mean:  tensor(0.0684, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(157.1571, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0527, device='cuda:0')
min of d_p_list:  tensor(-0.0300, device='cuda:0')
Epoch:  579  
Training Loss: 2169212.0
Test Loss:  1378946.75
Test Acc:  0.0
Valid Loss:  1737530.375
Valid Acc:  0.0
std:  31053.647987957873 
thres:  2213.01505
Preserved_eigens number check:  65
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  38
 58%|█████▊    | 579/1000 [36:58<26:28,  3.77s/it]Epoch:   580
max of grad d_p:  tensor(880260.1250, device='cuda:0')
min of grad d_p:  tensor(-138670., device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(16.4375, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-12.1406, device='cuda:0') norm:  tensor(89.6208, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(53.7598, device='cuda:0') mean:  tensor(0.0992, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(225.9582, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.5359, device='cuda:0')
min of d_p_list:  tensor(-0.2654, device='cuda:0')
Epoch:  580  
Training Loss: 2159732.0
Test Loss:  1375214.0
Test Acc:  0.0
Valid Loss:  1730323.25
Valid Acc:  0.0
std:  27629.72243635466 
thres:  2193.53495
Preserved_eigens number check:  38
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  46
 58%|█████▊    | 580/1000 [37:02<26:13,  3.75s/it]Epoch:   581
max of grad d_p:  tensor(883846.0625, device='cuda:0')
min of grad d_p:  tensor(-136281.4375, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(14.2891, device='cuda:0') mean:  tensor(-0.0042, device='cuda:0') min:  tensor(-12.3594, device='cuda:0') norm:  tensor(86.0260, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(236.3750, device='cuda:0') mean:  tensor(0.7332, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1533.6880, device='cuda:0') MSE:  tensor(0.0058, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0720, device='cuda:0')
min of d_p_list:  tensor(-0.0522, device='cuda:0')
Epoch:  581  
Training Loss: 2138407.75
Test Loss:  1361918.75
Test Acc:  0.0
Valid Loss:  1714024.125
Valid Acc:  0.0
std:  25694.71066844303 
thres:  2174.2667
Preserved_eigens number check:  46
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  247
 58%|█████▊    | 581/1000 [37:06<26:29,  3.79s/it]Epoch:   582
max of grad d_p:  tensor(875648.1250, device='cuda:0')
min of grad d_p:  tensor(-134678.2500, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.8047, device='cuda:0') mean:  tensor(-0.0025, device='cuda:0') min:  tensor(-9.5312, device='cuda:0') norm:  tensor(73.7225, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(105.3594, device='cuda:0') mean:  tensor(0.2003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(515.9141, device='cuda:0') MSE:  tensor(0.0019, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1107, device='cuda:0')
min of d_p_list:  tensor(-0.0931, device='cuda:0')
Epoch:  582  
Training Loss: 2116937.75
Test Loss:  1346521.625
Test Acc:  0.0
Valid Loss:  1696523.375
Valid Acc:  0.0
std:  25475.92025060135 
thres:  2155.0598999999997
Preserved_eigens number check:  247
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  88
 58%|█████▊    | 582/1000 [37:10<26:57,  3.87s/it]Epoch:   583
max of grad d_p:  tensor(871732.6250, device='cuda:0')
min of grad d_p:  tensor(-133842.8594, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(13.1562, device='cuda:0') mean:  tensor(-0.0006, device='cuda:0') min:  tensor(-9.7344, device='cuda:0') norm:  tensor(77.8088, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(23.5078, device='cuda:0') mean:  tensor(0.0477, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(109.4820, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0405, device='cuda:0')
min of d_p_list:  tensor(-0.0340, device='cuda:0')
Epoch:  583  
Training Loss: 2096150.375
Test Loss:  1333442.125
Test Acc:  0.0
Valid Loss:  1679754.75
Valid Acc:  0.0
std:  26919.752293669048 
thres:  2136.087975
Preserved_eigens number check:  88
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  160
 58%|█████▊    | 583/1000 [37:14<26:51,  3.86s/it]Epoch:   584
max of grad d_p:  tensor(865952.7500, device='cuda:0')
min of grad d_p:  tensor(-132530.7500, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.1875, device='cuda:0') mean:  tensor(-0.0021, device='cuda:0') min:  tensor(-11.8438, device='cuda:0') norm:  tensor(81.5968, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(39.4297, device='cuda:0') mean:  tensor(0.0621, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(150.0022, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0238, device='cuda:0')
min of d_p_list:  tensor(-0.0304, device='cuda:0')
Epoch:  584  
Training Loss: 2075329.0
Test Loss:  1320409.25
Test Acc:  0.0
Valid Loss:  1663294.75
Valid Acc:  0.0
std:  29849.669314123064 
thres:  2117.311375
Preserved_eigens number check:  160
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  70
 58%|█████▊    | 584/1000 [37:18<26:56,  3.89s/it]Epoch:   585
max of grad d_p:  tensor(862635.3750, device='cuda:0')
min of grad d_p:  tensor(-131385.9219, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.5938, device='cuda:0') mean:  tensor(-0.0005, device='cuda:0') min:  tensor(-8.7812, device='cuda:0') norm:  tensor(80.8869, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(83.5449, device='cuda:0') mean:  tensor(0.0969, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(248.5841, device='cuda:0') MSE:  tensor(0.0009, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0993, device='cuda:0')
min of d_p_list:  tensor(-0.0410, device='cuda:0')
Epoch:  585  
Training Loss: 2054815.375
Test Loss:  1307633.5
Test Acc:  0.0
Valid Loss:  1647582.0
Valid Acc:  0.0
std:  29528.815557498237 
thres:  2096.32805
Preserved_eigens number check:  70
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  86
 58%|█████▊    | 585/1000 [37:22<26:58,  3.90s/it]Epoch:   586
max of grad d_p:  tensor(859726.1250, device='cuda:0')
min of grad d_p:  tensor(-129971.6484, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.3906, device='cuda:0') mean:  tensor(-0.0012, device='cuda:0') min:  tensor(-7.6484, device='cuda:0') norm:  tensor(62.7824, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(42.0176, device='cuda:0') mean:  tensor(0.0563, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(124.3893, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1189, device='cuda:0')
min of d_p_list:  tensor(-0.1184, device='cuda:0')
Epoch:  586  
Training Loss: 2034722.0
Test Loss:  1295099.25
Test Acc:  0.0
Valid Loss:  1631779.5
Valid Acc:  0.0
std:  29100.556816128967 
thres:  2075.5909
Preserved_eigens number check:  86
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  129
 59%|█████▊    | 586/1000 [37:26<27:11,  3.94s/it]Epoch:   587
max of grad d_p:  tensor(854438.4375, device='cuda:0')
min of grad d_p:  tensor(-129151.4062, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.7734, device='cuda:0') mean:  tensor(-0.0020, device='cuda:0') min:  tensor(-9.0312, device='cuda:0') norm:  tensor(74.4055, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(106.3281, device='cuda:0') mean:  tensor(0.2751, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(643.0627, device='cuda:0') MSE:  tensor(0.0024, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.4387, device='cuda:0')
min of d_p_list:  tensor(-0.5902, device='cuda:0')
Epoch:  587  
Training Loss: 2028268.75
Test Loss:  1291112.25
Test Acc:  0.0
Valid Loss:  1625104.5
Valid Acc:  0.0
std:  25264.986042124583 
thres:  2057.8571
Preserved_eigens number check:  129
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  85
 59%|█████▊    | 587/1000 [37:29<26:48,  3.90s/it]Epoch:   588
max of grad d_p:  tensor(842941.7500, device='cuda:0')
min of grad d_p:  tensor(-127152.5859, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.4531, device='cuda:0') mean:  tensor(-0.0011, device='cuda:0') min:  tensor(-9.6562, device='cuda:0') norm:  tensor(77.8134, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(174.2188, device='cuda:0') mean:  tensor(0.1613, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(490.6595, device='cuda:0') MSE:  tensor(0.0018, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0839, device='cuda:0')
min of d_p_list:  tensor(-0.0963, device='cuda:0')
Epoch:  588  
Training Loss: 2008994.0
Test Loss:  1278729.625
Test Acc:  0.0
Valid Loss:  1608757.875
Valid Acc:  0.0
std:  22775.33090560925 
thres:  2040.425825
Preserved_eigens number check:  85
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  196
 59%|█████▉    | 588/1000 [37:33<26:36,  3.87s/it]Epoch:   589
max of grad d_p:  tensor(840519.7500, device='cuda:0')
min of grad d_p:  tensor(-126070.3906, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.4141, device='cuda:0') mean:  tensor(-0.0022, device='cuda:0') min:  tensor(-9.5625, device='cuda:0') norm:  tensor(80.0318, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(65.3398, device='cuda:0') mean:  tensor(0.1294, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(268.2725, device='cuda:0') MSE:  tensor(0.0010, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1057, device='cuda:0')
min of d_p_list:  tensor(-0.1411, device='cuda:0')
Epoch:  589  
Training Loss: 1989444.5
Test Loss:  1266033.5
Test Acc:  0.0
Valid Loss:  1594271.875
Valid Acc:  0.0
std:  22357.159456983798 
thres:  2023.248925
Preserved_eigens number check:  196
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  83
 59%|█████▉    | 589/1000 [37:37<26:35,  3.88s/it]Epoch:   590
max of grad d_p:  tensor(840796.8125, device='cuda:0')
min of grad d_p:  tensor(-125865.2031, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(13.5625, device='cuda:0') mean:  tensor(-0.0025, device='cuda:0') min:  tensor(-10., device='cuda:0') norm:  tensor(85.0210, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(163.8047, device='cuda:0') mean:  tensor(0.2512, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(605.0209, device='cuda:0') MSE:  tensor(0.0023, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1847, device='cuda:0')
min of d_p_list:  tensor(-0.1140, device='cuda:0')
Epoch:  590  
Training Loss: 1969848.375
Test Loss:  1253924.0
Test Acc:  0.0
Valid Loss:  1579282.125
Valid Acc:  0.0
std:  24126.80108023026 
thres:  2006.255525
Preserved_eigens number check:  83
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  174
 59%|█████▉    | 590/1000 [37:41<26:08,  3.83s/it]Epoch:   591
max of grad d_p:  tensor(836305.1875, device='cuda:0')
min of grad d_p:  tensor(-124860.3906, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.7656, device='cuda:0') mean:  tensor(-0.0016, device='cuda:0') min:  tensor(-7.9766, device='cuda:0') norm:  tensor(73.2777, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(118.7129, device='cuda:0') mean:  tensor(0.2047, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(503.1598, device='cuda:0') MSE:  tensor(0.0019, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0710, device='cuda:0')
min of d_p_list:  tensor(-0.1113, device='cuda:0')
Epoch:  591  
Training Loss: 1950421.625
Test Loss:  1241120.625
Test Acc:  0.0
Valid Loss:  1564368.0
Valid Acc:  0.0
std:  27554.622832044897 
thres:  1989.39545
Preserved_eigens number check:  174
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  66
 59%|█████▉    | 591/1000 [37:45<26:05,  3.83s/it]Epoch:   592
max of grad d_p:  tensor(828174.8750, device='cuda:0')
min of grad d_p:  tensor(-124261.2969, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.4688, device='cuda:0') mean:  tensor(-0.0021, device='cuda:0') min:  tensor(-9.0156, device='cuda:0') norm:  tensor(80.3043, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(93.3413, device='cuda:0') mean:  tensor(0.1927, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(434.7514, device='cuda:0') MSE:  tensor(0.0016, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1523, device='cuda:0')
min of d_p_list:  tensor(-0.2217, device='cuda:0')
Epoch:  592  
Training Loss: 1934147.875
Test Loss:  1231088.5
Test Acc:  0.0
Valid Loss:  1551449.75
Valid Acc:  0.0
std:  26704.679235739753 
thres:  1970.571275
Preserved_eigens number check:  66
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  63
 59%|█████▉    | 592/1000 [37:49<26:14,  3.86s/it]Epoch:   593
max of grad d_p:  tensor(821650.1250, device='cuda:0')
min of grad d_p:  tensor(-122171.2891, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(13.5000, device='cuda:0') mean:  tensor(-0.0043, device='cuda:0') min:  tensor(-8.8750, device='cuda:0') norm:  tensor(72.7296, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(58.0625, device='cuda:0') mean:  tensor(0.0982, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(232.0635, device='cuda:0') MSE:  tensor(0.0009, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0446, device='cuda:0')
min of d_p_list:  tensor(-0.0306, device='cuda:0')
Epoch:  593  
Training Loss: 1914918.625
Test Loss:  1218791.75
Test Acc:  0.0
Valid Loss:  1535992.0
Valid Acc:  0.0
std:  26140.297950625965 
thres:  1951.7562
Preserved_eigens number check:  63
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  66
 59%|█████▉    | 593/1000 [37:52<25:52,  3.82s/it]Epoch:   594
max of grad d_p:  tensor(818238.6875, device='cuda:0')
min of grad d_p:  tensor(-121021.3203, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(16.2500, device='cuda:0') mean:  tensor(-0.0005, device='cuda:0') min:  tensor(-8.6094, device='cuda:0') norm:  tensor(84.1354, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(154.8984, device='cuda:0') mean:  tensor(0.1276, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(366.2208, device='cuda:0') MSE:  tensor(0.0014, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0939, device='cuda:0')
min of d_p_list:  tensor(-0.0620, device='cuda:0')
Epoch:  594  
Training Loss: 1895972.0
Test Loss:  1206964.75
Test Acc:  0.0
Valid Loss:  1520951.25
Valid Acc:  0.0
std:  25925.366906709343 
thres:  1933.0617
Preserved_eigens number check:  66
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  123
 59%|█████▉    | 594/1000 [37:56<25:56,  3.83s/it]Epoch:   595
max of grad d_p:  tensor(809409.5000, device='cuda:0')
min of grad d_p:  tensor(-119932.5000, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.9375, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-7.7734, device='cuda:0') norm:  tensor(75.6801, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(872.0391, device='cuda:0') mean:  tensor(1.2154, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(3306.2844, device='cuda:0') MSE:  tensor(0.0124, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0719, device='cuda:0')
min of d_p_list:  tensor(-0.0486, device='cuda:0')
Epoch:  595  
Training Loss: 1877282.5
Test Loss:  1194820.625
Test Acc:  0.0
Valid Loss:  1505776.125
Valid Acc:  0.0
std:  26095.956385688376 
thres:  1914.548525
Preserved_eigens number check:  123
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  69
 60%|█████▉    | 595/1000 [38:00<25:55,  3.84s/it]Epoch:   596
max of grad d_p:  tensor(803611.8750, device='cuda:0')
min of grad d_p:  tensor(-118631.5000, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(14.0938, device='cuda:0') mean:  tensor(-0.0023, device='cuda:0') min:  tensor(-9.5938, device='cuda:0') norm:  tensor(79.6929, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(41.2500, device='cuda:0') mean:  tensor(0.0894, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(228.8971, device='cuda:0') MSE:  tensor(0.0009, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1528, device='cuda:0')
min of d_p_list:  tensor(-0.1368, device='cuda:0')
Epoch:  596  
Training Loss: 1859299.25
Test Loss:  1184076.25
Test Acc:  0.0
Valid Loss:  1491480.625
Valid Acc:  0.0
std:  26495.05741720991 
thres:  1896.3240500000002
Preserved_eigens number check:  69
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  171
 60%|█████▉    | 596/1000 [38:04<26:03,  3.87s/it]Epoch:   597
max of grad d_p:  tensor(796616.8750, device='cuda:0')
min of grad d_p:  tensor(-118052.6406, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.4844, device='cuda:0') mean:  tensor(-0.0015, device='cuda:0') min:  tensor(-7.1094, device='cuda:0') norm:  tensor(69.6370, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(86.2207, device='cuda:0') mean:  tensor(0.0836, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(213.3524, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0292, device='cuda:0')
min of d_p_list:  tensor(-0.0846, device='cuda:0')
Epoch:  597  
Training Loss: 1841061.0
Test Loss:  1172448.75
Test Acc:  0.0
Valid Loss:  1477008.125
Valid Acc:  0.0
std:  26077.845140751182 
thres:  1877.7066750000001
Preserved_eigens number check:  171
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  82
 60%|█████▉    | 597/1000 [38:08<26:08,  3.89s/it]Epoch:   598
max of grad d_p:  tensor(796222.5000, device='cuda:0')
min of grad d_p:  tensor(-117101.9688, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.5078, device='cuda:0') mean:  tensor(-0.0015, device='cuda:0') min:  tensor(-8.6406, device='cuda:0') norm:  tensor(75.1456, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(58.7812, device='cuda:0') mean:  tensor(0.0747, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(187.3416, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0317, device='cuda:0')
min of d_p_list:  tensor(-0.0479, device='cuda:0')
Epoch:  598  
Training Loss: 1822734.375
Test Loss:  1160871.75
Test Acc:  0.0
Valid Loss:  1462260.75
Valid Acc:  0.0
std:  25837.598149982907 
thres:  1859.269825
Preserved_eigens number check:  82
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  52
 60%|█████▉    | 598/1000 [38:12<26:24,  3.94s/it]Epoch:   599
max of grad d_p:  tensor(793684.4375, device='cuda:0')
min of grad d_p:  tensor(-115937.4219, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.5625, device='cuda:0') mean:  tensor(-0.0007, device='cuda:0') min:  tensor(-7.6875, device='cuda:0') norm:  tensor(73.1528, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(191.0664, device='cuda:0') mean:  tensor(0.3051, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(723.7396, device='cuda:0') MSE:  tensor(0.0027, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1028, device='cuda:0')
min of d_p_list:  tensor(-0.2266, device='cuda:0')
Epoch:  599  
Training Loss: 1806548.25
Test Loss:  1150718.625
Test Acc:  0.0
Valid Loss:  1449490.875
Valid Acc:  0.0
std:  25183.72807484031 
thres:  1841.385075
Preserved_eigens number check:  52
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  72
 60%|█████▉    | 599/1000 [38:16<26:18,  3.94s/it]Epoch:   600
max of grad d_p:  tensor(803341.8750, device='cuda:0')
min of grad d_p:  tensor(-114916.5000, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(13., device='cuda:0') mean:  tensor(-0.0005, device='cuda:0') min:  tensor(-8.0547, device='cuda:0') norm:  tensor(77.0931, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(62.9648, device='cuda:0') mean:  tensor(0.1379, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(296.6279, device='cuda:0') MSE:  tensor(0.0011, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0507, device='cuda:0')
min of d_p_list:  tensor(-0.0440, device='cuda:0')
Epoch:  600  
Training Loss: 1788600.25
Test Loss:  1139401.0
Test Acc:  0.0
Valid Loss:  1435437.625
Valid Acc:  0.0
std:  24882.946507095978 
thres:  1823.648625
Preserved_eigens number check:  72
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  125
 60%|██████    | 600/1000 [38:20<26:05,  3.91s/it]Epoch:   601
max of grad d_p:  tensor(799498.0625, device='cuda:0')
min of grad d_p:  tensor(-113704.2656, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.6602, device='cuda:0') mean:  tensor(-0.0005, device='cuda:0') min:  tensor(-7.6719, device='cuda:0') norm:  tensor(79.5699, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(59.5742, device='cuda:0') mean:  tensor(0.1559, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(345.3111, device='cuda:0') MSE:  tensor(0.0013, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0574, device='cuda:0')
min of d_p_list:  tensor(-0.0485, device='cuda:0')
Epoch:  601  
Training Loss: 1770850.0
Test Loss:  1128128.75
Test Acc:  0.0
Valid Loss:  1421464.25
Valid Acc:  0.0
std:  24689.588527403608 
thres:  1805.9587749999998
Preserved_eigens number check:  125
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  135
 60%|██████    | 601/1000 [38:24<26:11,  3.94s/it]Epoch:   602
max of grad d_p:  tensor(795440., device='cuda:0')
min of grad d_p:  tensor(-112769.3281, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(15.1250, device='cuda:0') mean:  tensor(-0.0006, device='cuda:0') min:  tensor(-8.5859, device='cuda:0') norm:  tensor(81.4842, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(99.7969, device='cuda:0') mean:  tensor(0.1772, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(415.6704, device='cuda:0') MSE:  tensor(0.0016, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0157, device='cuda:0')
min of d_p_list:  tensor(-0.0130, device='cuda:0')
Epoch:  602  
Training Loss: 1753214.125
Test Loss:  1116829.75
Test Acc:  0.0
Valid Loss:  1407223.625
Valid Acc:  0.0
std:  24715.566440934545 
thres:  1788.3894
Preserved_eigens number check:  135
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  140
 60%|██████    | 602/1000 [38:28<26:01,  3.92s/it]Epoch:   603
max of grad d_p:  tensor(790329.2500, device='cuda:0')
min of grad d_p:  tensor(-111743.5000, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.6250, device='cuda:0') mean:  tensor(-0.0004, device='cuda:0') min:  tensor(-9.0234, device='cuda:0') norm:  tensor(78.2894, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(89.1133, device='cuda:0') mean:  tensor(0.3019, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(677.3329, device='cuda:0') MSE:  tensor(0.0025, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0878, device='cuda:0')
min of d_p_list:  tensor(-0.1845, device='cuda:0')
Epoch:  603  
Training Loss: 1736926.375
Test Loss:  1107191.0
Test Acc:  0.0
Valid Loss:  1394563.625
Valid Acc:  0.0
std:  24700.442036859382 
thres:  1771.2278000000001
Preserved_eigens number check:  140
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  55
 60%|██████    | 603/1000 [38:31<25:44,  3.89s/it]Epoch:   604
max of grad d_p:  tensor(783621.8750, device='cuda:0')
min of grad d_p:  tensor(-111075.4531, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.1992, device='cuda:0') mean:  tensor(-0.0038, device='cuda:0') min:  tensor(-8.5469, device='cuda:0') norm:  tensor(74.2462, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(20.8594, device='cuda:0') mean:  tensor(0.0479, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(110.9979, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0433, device='cuda:0')
min of d_p_list:  tensor(-0.0264, device='cuda:0')
Epoch:  604  
Training Loss: 1719645.0
Test Loss:  1096218.375
Test Acc:  0.0
Valid Loss:  1380675.125
Valid Acc:  0.0
std:  24303.807436721723 
thres:  1753.84715
Preserved_eigens number check:  55
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  175
 60%|██████    | 604/1000 [38:35<25:49,  3.91s/it]Epoch:   605
max of grad d_p:  tensor(776886.4375, device='cuda:0')
min of grad d_p:  tensor(-109860.4922, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.9375, device='cuda:0') mean:  tensor(-0.0024, device='cuda:0') min:  tensor(-10.3750, device='cuda:0') norm:  tensor(66.3198, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(546.8906, device='cuda:0') mean:  tensor(1.0529, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2330.8345, device='cuda:0') MSE:  tensor(0.0087, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1305, device='cuda:0')
min of d_p_list:  tensor(-0.0642, device='cuda:0')
Epoch:  605  
Training Loss: 1702656.0
Test Loss:  1085373.875
Test Acc:  0.0
Valid Loss:  1366995.625
Valid Acc:  0.0
std:  24036.839795223706 
thres:  1736.6583
Preserved_eigens number check:  175
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  73
 60%|██████    | 605/1000 [38:39<26:04,  3.96s/it]Epoch:   606
max of grad d_p:  tensor(764658.8125, device='cuda:0')
min of grad d_p:  tensor(-108917.6172, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(14.3750, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-7.0547, device='cuda:0') norm:  tensor(76.4607, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(90.8965, device='cuda:0') mean:  tensor(0.2019, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(478.9590, device='cuda:0') MSE:  tensor(0.0018, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1207, device='cuda:0')
min of d_p_list:  tensor(-0.0802, device='cuda:0')
Epoch:  606  
Training Loss: 1685692.5
Test Loss:  1074459.25
Test Acc:  0.0
Valid Loss:  1353442.0
Valid Acc:  0.0
std:  23945.474713215644 
thres:  1719.6268
Preserved_eigens number check:  73
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  62
 61%|██████    | 606/1000 [38:43<25:39,  3.91s/it]Epoch:   607
max of grad d_p:  tensor(756453.3750, device='cuda:0')
min of grad d_p:  tensor(-107688.6094, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.1211, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-6.9844, device='cuda:0') norm:  tensor(71.6639, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1065.8125, device='cuda:0') mean:  tensor(1.8829, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(4366.7031, device='cuda:0') MSE:  tensor(0.0164, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2530, device='cuda:0')
min of d_p_list:  tensor(-0.4818, device='cuda:0')
Epoch:  607  
Training Loss: 1669940.375
Test Loss:  1064785.25
Test Acc:  0.0
Valid Loss:  1342583.0
Valid Acc:  0.0
std:  23751.453585070325 
thres:  1702.97205
Preserved_eigens number check:  62
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  104
 61%|██████    | 607/1000 [38:47<25:28,  3.89s/it]Epoch:   608
max of grad d_p:  tensor(771796.3125, device='cuda:0')
min of grad d_p:  tensor(-107581.8281, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(13.0508, device='cuda:0') mean:  tensor(-0.0015, device='cuda:0') min:  tensor(-8.0469, device='cuda:0') norm:  tensor(76.2275, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(330.6797, device='cuda:0') mean:  tensor(0.4041, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(969.3349, device='cuda:0') MSE:  tensor(0.0036, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0392, device='cuda:0')
min of d_p_list:  tensor(-0.0718, device='cuda:0')
Epoch:  608  
Training Loss: 1653429.5
Test Loss:  1054176.375
Test Acc:  0.0
Valid Loss:  1328966.0
Valid Acc:  0.0
std:  23357.569155896766 
thres:  1686.2726750000002
Preserved_eigens number check:  104
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  54
 61%|██████    | 608/1000 [38:51<25:52,  3.96s/it]Epoch:   609
max of grad d_p:  tensor(767699.5000, device='cuda:0')
min of grad d_p:  tensor(-106488.2500, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.8594, device='cuda:0') mean:  tensor(-0.0012, device='cuda:0') min:  tensor(-8.2188, device='cuda:0') norm:  tensor(74.5260, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(29.2266, device='cuda:0') mean:  tensor(0.0407, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(95.3662, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0242, device='cuda:0')
min of d_p_list:  tensor(-0.0470, device='cuda:0')
Epoch:  609  
Training Loss: 1636981.0
Test Loss:  1043692.25
Test Acc:  0.0
Valid Loss:  1315771.375
Valid Acc:  0.0
std:  23139.44663799245 
thres:  1669.739875
Preserved_eigens number check:  54
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  192
 61%|██████    | 609/1000 [38:55<25:12,  3.87s/it]Epoch:   610
max of grad d_p:  tensor(765409.8750, device='cuda:0')
min of grad d_p:  tensor(-105369.2812, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.9648, device='cuda:0') mean:  tensor(-2.8709e-05, device='cuda:0') min:  tensor(-6.7031, device='cuda:0') norm:  tensor(67.5241, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(945.2031, device='cuda:0') mean:  tensor(2.3647, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(5399.1914, device='cuda:0') MSE:  tensor(0.0203, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0274, device='cuda:0')
min of d_p_list:  tensor(-0.0308, device='cuda:0')
Epoch:  610  
Training Loss: 1620584.75
Test Loss:  1032658.0
Test Acc:  0.0
Valid Loss:  1303045.0
Valid Acc:  0.0
std:  23077.205060405387 
thres:  1653.325625
Preserved_eigens number check:  192
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  125
 61%|██████    | 610/1000 [38:59<24:55,  3.83s/it]Epoch:   611
max of grad d_p:  tensor(761482.6250, device='cuda:0')
min of grad d_p:  tensor(-104924.9531, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.4688, device='cuda:0') mean:  tensor(-0.0003, device='cuda:0') min:  tensor(-7.4219, device='cuda:0') norm:  tensor(71.7259, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(23.7812, device='cuda:0') mean:  tensor(0.0557, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(133.2552, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0229, device='cuda:0')
min of d_p_list:  tensor(-0.0326, device='cuda:0')
Epoch:  611  
Training Loss: 1604255.875
Test Loss:  1022487.375
Test Acc:  0.0
Valid Loss:  1289535.625
Valid Acc:  0.0
std:  23223.38457899171 
thres:  1637.0383000000002
Preserved_eigens number check:  125
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  57
 61%|██████    | 611/1000 [39:02<24:39,  3.80s/it]Epoch:   612
max of grad d_p:  tensor(758985.5000, device='cuda:0')
min of grad d_p:  tensor(-103828.4688, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.7188, device='cuda:0') mean:  tensor(-0.0017, device='cuda:0') min:  tensor(-9.7031, device='cuda:0') norm:  tensor(77.7721, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(112.6230, device='cuda:0') mean:  tensor(0.2573, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(563.8577, device='cuda:0') MSE:  tensor(0.0021, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1269, device='cuda:0')
min of d_p_list:  tensor(-0.1087, device='cuda:0')
Epoch:  612  
Training Loss: 1588886.25
Test Loss:  1012784.375
Test Acc:  0.0
Valid Loss:  1277938.75
Valid Acc:  0.0
std:  22885.57231319549 
thres:  1620.827475
Preserved_eigens number check:  57
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  43
 61%|██████    | 612/1000 [39:06<24:18,  3.76s/it]Epoch:   613
max of grad d_p:  tensor(748836.9375, device='cuda:0')
min of grad d_p:  tensor(-102979.6562, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.3398, device='cuda:0') mean:  tensor(-0.0037, device='cuda:0') min:  tensor(-8.0391, device='cuda:0') norm:  tensor(70.0528, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(22.2109, device='cuda:0') mean:  tensor(0.0640, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(138.8638, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0598, device='cuda:0')
min of d_p_list:  tensor(-0.0273, device='cuda:0')
Epoch:  613  
Training Loss: 1573113.5
Test Loss:  1002782.9375
Test Acc:  0.0
Valid Loss:  1265267.375
Valid Acc:  0.0
std:  22549.263870523577 
thres:  1604.764275
Preserved_eigens number check:  43
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  234
 61%|██████▏   | 613/1000 [39:10<24:41,  3.83s/it]Epoch:   614
max of grad d_p:  tensor(741695.3750, device='cuda:0')
min of grad d_p:  tensor(-101957.9688, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.0039, device='cuda:0') mean:  tensor(-0.0012, device='cuda:0') min:  tensor(-8.1562, device='cuda:0') norm:  tensor(71.3443, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(71.4062, device='cuda:0') mean:  tensor(0.1351, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(315.4219, device='cuda:0') MSE:  tensor(0.0012, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.4267, device='cuda:0')
min of d_p_list:  tensor(-0.8539, device='cuda:0')
Epoch:  614  
Training Loss: 1578983.75
Test Loss:  1007148.4375
Test Acc:  0.0
Valid Loss:  1269945.25
Valid Acc:  0.0
std:  17299.29711606804 
thres:  1593.164825
Preserved_eigens number check:  234
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  110
 61%|██████▏   | 614/1000 [39:14<24:50,  3.86s/it]Epoch:   615
max of grad d_p:  tensor(745856.8750, device='cuda:0')
min of grad d_p:  tensor(-101922.4219, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.3867, device='cuda:0') mean:  tensor(-0.0013, device='cuda:0') min:  tensor(-8.0156, device='cuda:0') norm:  tensor(70.7925, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(84.7578, device='cuda:0') mean:  tensor(0.1994, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(442.3638, device='cuda:0') MSE:  tensor(0.0017, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0927, device='cuda:0')
min of d_p_list:  tensor(-0.1146, device='cuda:0')
Epoch:  615  
Training Loss: 1563808.375
Test Loss:  997390.375
Test Acc:  0.0
Valid Loss:  1258058.875
Valid Acc:  0.0
std:  13867.702920950895 
thres:  1581.8095500000002
Preserved_eigens number check:  110
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  77
 62%|██████▏   | 615/1000 [39:18<24:48,  3.87s/it]Epoch:   616
max of grad d_p:  tensor(740645.5625, device='cuda:0')
min of grad d_p:  tensor(-100771.8750, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.2891, device='cuda:0') mean:  tensor(-0.0019, device='cuda:0') min:  tensor(-8.1641, device='cuda:0') norm:  tensor(75.6003, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(86.9961, device='cuda:0') mean:  tensor(0.2329, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(539.2351, device='cuda:0') MSE:  tensor(0.0020, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0214, device='cuda:0')
min of d_p_list:  tensor(-0.0309, device='cuda:0')
Epoch:  616  
Training Loss: 1548244.5
Test Loss:  987590.75
Test Acc:  0.0
Valid Loss:  1245395.875
Valid Acc:  0.0
std:  13833.916084301654 
thres:  1570.6072749999998
Preserved_eigens number check:  77
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  55
 62%|██████▏   | 616/1000 [39:22<25:06,  3.92s/it]Epoch:   617
max of grad d_p:  tensor(737956.6250, device='cuda:0')
min of grad d_p:  tensor(-99914.1719, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.6875, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-7.1328, device='cuda:0') norm:  tensor(74.0703, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(77.0312, device='cuda:0') mean:  tensor(0.1013, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(253.7978, device='cuda:0') MSE:  tensor(0.0010, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2141, device='cuda:0')
min of d_p_list:  tensor(-0.2135, device='cuda:0')
Epoch:  617  
Training Loss: 1536328.0
Test Loss:  980840.125
Test Acc:  0.0
Valid Loss:  1236543.0
Valid Acc:  0.0
std:  15782.015143827482 
thres:  1560.095625
Preserved_eigens number check:  55
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  144
 62%|██████▏   | 617/1000 [39:26<24:56,  3.91s/it]Epoch:   618
max of grad d_p:  tensor(734981.7500, device='cuda:0')
min of grad d_p:  tensor(-99045.9297, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.2578, device='cuda:0') mean:  tensor(-0.0014, device='cuda:0') min:  tensor(-7.6484, device='cuda:0') norm:  tensor(66.8780, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(27.9883, device='cuda:0') mean:  tensor(0.0362, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(93.5472, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0344, device='cuda:0')
min of d_p_list:  tensor(-0.0698, device='cuda:0')
Epoch:  618  
Training Loss: 1520990.875
Test Loss:  971150.6875
Test Acc:  0.0
Valid Loss:  1223895.5
Valid Acc:  0.0
std:  20306.269010671313 
thres:  1549.6711
Preserved_eigens number check:  144
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  198
 62%|██████▏   | 618/1000 [39:30<24:43,  3.88s/it]Epoch:   619
max of grad d_p:  tensor(731446., device='cuda:0')
min of grad d_p:  tensor(-97963.6094, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.1680, device='cuda:0') mean:  tensor(-0.0004, device='cuda:0') min:  tensor(-6.9062, device='cuda:0') norm:  tensor(64.8875, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(565.1250, device='cuda:0') mean:  tensor(0.4917, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1329.4761, device='cuda:0') MSE:  tensor(0.0050, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0214, device='cuda:0')
min of d_p_list:  tensor(-0.0199, device='cuda:0')
Epoch:  619  
Training Loss: 1505666.125
Test Loss:  960588.6875
Test Acc:  0.0
Valid Loss:  1212017.375
Valid Acc:  0.0
std:  20316.664850652778 
thres:  1535.007575
Preserved_eigens number check:  198
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  123
 62%|██████▏   | 619/1000 [39:33<24:39,  3.88s/it]Epoch:   620
max of grad d_p:  tensor(727494.3750, device='cuda:0')
min of grad d_p:  tensor(-97429.5625, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.0742, device='cuda:0') mean:  tensor(-0.0014, device='cuda:0') min:  tensor(-7.4102, device='cuda:0') norm:  tensor(68.0097, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(51.6328, device='cuda:0') mean:  tensor(0.0833, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(192.1809, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.3729, device='cuda:0')
min of d_p_list:  tensor(-0.3994, device='cuda:0')
Epoch:  620  
Training Loss: 1498585.5
Test Loss:  956602.5625
Test Acc:  0.0
Valid Loss:  1206765.875
Valid Acc:  0.0
std:  18493.842949918493 
thres:  1521.963
Preserved_eigens number check:  123
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  57
 62%|██████▏   | 620/1000 [39:37<24:19,  3.84s/it]Epoch:   621
max of grad d_p:  tensor(713574.0625, device='cuda:0')
min of grad d_p:  tensor(-95732.5781, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.5977, device='cuda:0') mean:  tensor(-0.0016, device='cuda:0') min:  tensor(-7.1641, device='cuda:0') norm:  tensor(64.2274, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(33.7734, device='cuda:0') mean:  tensor(0.0796, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(183.6472, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0376, device='cuda:0')
min of d_p_list:  tensor(-0.0737, device='cuda:0')
Epoch:  621  
Training Loss: 1483666.75
Test Loss:  947126.1875
Test Acc:  0.0
Valid Loss:  1194970.875
Valid Acc:  0.0
std:  18176.575574520357 
thres:  1509.04745
Preserved_eigens number check:  57
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  45
 62%|██████▏   | 621/1000 [39:41<24:17,  3.85s/it]Epoch:   622
max of grad d_p:  tensor(707568.6875, device='cuda:0')
min of grad d_p:  tensor(-94935.4219, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.9805, device='cuda:0') mean:  tensor(-0.0004, device='cuda:0') min:  tensor(-8.1094, device='cuda:0') norm:  tensor(69.7684, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(46.2812, device='cuda:0') mean:  tensor(0.0876, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(203.3348, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1005, device='cuda:0')
min of d_p_list:  tensor(-0.0814, device='cuda:0')
Epoch:  622  
Training Loss: 1469311.625
Test Loss:  938575.75
Test Acc:  0.0
Valid Loss:  1183075.25
Valid Acc:  0.0
std:  17823.624629021167 
thres:  1495.6441750000001
Preserved_eigens number check:  45
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  41
 62%|██████▏   | 622/1000 [39:45<23:51,  3.79s/it]Epoch:   623
max of grad d_p:  tensor(698895.4375, device='cuda:0')
min of grad d_p:  tensor(-94336.4297, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(19.6875, device='cuda:0') mean:  tensor(0.0011, device='cuda:0') min:  tensor(-7.0078, device='cuda:0') norm:  tensor(85.5137, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(22.1348, device='cuda:0') mean:  tensor(0.0582, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(130.6898, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0168, device='cuda:0')
min of d_p_list:  tensor(-0.0192, device='cuda:0')
Epoch:  623  
Training Loss: 1454695.25
Test Loss:  929342.1875
Test Acc:  0.0
Valid Loss:  1171433.75
Valid Acc:  0.0
std:  18674.82398052924 
thres:  1482.38505
Preserved_eigens number check:  41
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  79
 62%|██████▏   | 623/1000 [39:48<23:42,  3.77s/it]Epoch:   624
max of grad d_p:  tensor(695657.3750, device='cuda:0')
min of grad d_p:  tensor(-93363.6250, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.4648, device='cuda:0') mean:  tensor(-0.0005, device='cuda:0') min:  tensor(-7.1406, device='cuda:0') norm:  tensor(74.4279, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(52.5332, device='cuda:0') mean:  tensor(0.0669, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(169.1207, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1144, device='cuda:0')
min of d_p_list:  tensor(-0.0833, device='cuda:0')
Epoch:  624  
Training Loss: 1440853.0
Test Loss:  920549.875
Test Acc:  0.0
Valid Loss:  1159487.75
Valid Acc:  0.0
std:  20427.920810070224 
thres:  1469.422425
Preserved_eigens number check:  79
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  39
 62%|██████▏   | 624/1000 [39:52<23:57,  3.82s/it]Epoch:   625
max of grad d_p:  tensor(688407.7500, device='cuda:0')
min of grad d_p:  tensor(-92338.0781, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.3633, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-6.3438, device='cuda:0') norm:  tensor(67.1664, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(19.7109, device='cuda:0') mean:  tensor(0.0346, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(81.2375, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1302, device='cuda:0')
min of d_p_list:  tensor(-0.1569, device='cuda:0')
Epoch:  625  
Training Loss: 1427617.75
Test Loss:  912705.875
Test Acc:  0.0
Valid Loss:  1149602.25
Valid Acc:  0.0
std:  19881.455396927056 
thres:  1455.228875
Preserved_eigens number check:  39
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  41
 62%|██████▎   | 625/1000 [39:56<23:56,  3.83s/it]Epoch:   626
max of grad d_p:  tensor(681122.6250, device='cuda:0')
min of grad d_p:  tensor(-91120.0078, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(14.9375, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-6.3203, device='cuda:0') norm:  tensor(72.8249, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(263.9648, device='cuda:0') mean:  tensor(0.4380, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1112.8754, device='cuda:0') MSE:  tensor(0.0042, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0627, device='cuda:0')
min of d_p_list:  tensor(-0.0396, device='cuda:0')
Epoch:  626  
Training Loss: 1413557.875
Test Loss:  903727.5
Test Acc:  0.0
Valid Loss:  1138721.75
Valid Acc:  0.0
std:  19601.37739665889 
thres:  1441.2071
Preserved_eigens number check:  41
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  36
 63%|██████▎   | 626/1000 [40:00<23:55,  3.84s/it]Epoch:   627
max of grad d_p:  tensor(676778.5625, device='cuda:0')
min of grad d_p:  tensor(-90199.7344, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.0508, device='cuda:0') mean:  tensor(-0.0006, device='cuda:0') min:  tensor(-5.9219, device='cuda:0') norm:  tensor(64.9471, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(42.8379, device='cuda:0') mean:  tensor(0.0787, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(175.5671, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0295, device='cuda:0')
min of d_p_list:  tensor(-0.0441, device='cuda:0')
Epoch:  627  
Training Loss: 1399469.625
Test Loss:  894847.375
Test Acc:  0.0
Valid Loss:  1127518.375
Valid Acc:  0.0
std:  19481.48598198428 
thres:  1427.2386999999999
Preserved_eigens number check:  36
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  102
 63%|██████▎   | 627/1000 [40:04<23:56,  3.85s/it]Epoch:   628
max of grad d_p:  tensor(673659.9375, device='cuda:0')
min of grad d_p:  tensor(-89411.2344, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.0742, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-6.3203, device='cuda:0') norm:  tensor(61.4800, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(25.2344, device='cuda:0') mean:  tensor(0.0332, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(80.5999, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0612, device='cuda:0')
min of d_p_list:  tensor(-0.0360, device='cuda:0')
Epoch:  628  
Training Loss: 1385610.375
Test Loss:  886145.5
Test Acc:  0.0
Valid Loss:  1116398.25
Valid Acc:  0.0
std:  19606.900795287613 
thres:  1413.4217250000002
Preserved_eigens number check:  102
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  101
 63%|██████▎   | 628/1000 [40:08<23:53,  3.85s/it]Epoch:   629
max of grad d_p:  tensor(670556.7500, device='cuda:0')
min of grad d_p:  tensor(-88463.7812, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.2969, device='cuda:0') mean:  tensor(-1.4331e-05, device='cuda:0') min:  tensor(-6.8516, device='cuda:0') norm:  tensor(67.9100, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(97.3984, device='cuda:0') mean:  tensor(0.1451, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(366.7944, device='cuda:0') MSE:  tensor(0.0014, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0284, device='cuda:0')
min of d_p_list:  tensor(-0.0308, device='cuda:0')
Epoch:  629  
Training Loss: 1371893.25
Test Loss:  877237.5625
Test Acc:  0.0
Valid Loss:  1105346.5
Valid Acc:  0.0
std:  19713.968436967476 
thres:  1399.6297749999999
Preserved_eigens number check:  101
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  43
 63%|██████▎   | 629/1000 [40:12<24:01,  3.88s/it]Epoch:   630
max of grad d_p:  tensor(668726.8750, device='cuda:0')
min of grad d_p:  tensor(-87534.2422, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.6445, device='cuda:0') mean:  tensor(-0.0007, device='cuda:0') min:  tensor(-6.4883, device='cuda:0') norm:  tensor(69.0890, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(89.3184, device='cuda:0') mean:  tensor(0.1162, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(337.4250, device='cuda:0') MSE:  tensor(0.0013, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0154, device='cuda:0')
min of d_p_list:  tensor(-0.0160, device='cuda:0')
Epoch:  630  
Training Loss: 1358253.0
Test Loss:  868464.8125
Test Acc:  0.0
Valid Loss:  1094316.875
Valid Acc:  0.0
std:  19542.874987863222 
thres:  1385.756825
Preserved_eigens number check:  43
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  67
 63%|██████▎   | 630/1000 [40:16<24:01,  3.90s/it]Epoch:   631
max of grad d_p:  tensor(666555.7500, device='cuda:0')
min of grad d_p:  tensor(-86685.8438, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.4297, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-6.6797, device='cuda:0') norm:  tensor(66.2281, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(103.8789, device='cuda:0') mean:  tensor(0.1373, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(382.0988, device='cuda:0') MSE:  tensor(0.0014, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0198, device='cuda:0')
min of d_p_list:  tensor(-0.0339, device='cuda:0')
Epoch:  631  
Training Loss: 1344816.25
Test Loss:  859899.5
Test Acc:  0.0
Valid Loss:  1083486.25
Valid Acc:  0.0
std:  19327.544658627747 
thres:  1372.0085000000001
Preserved_eigens number check:  67
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  56
 63%|██████▎   | 631/1000 [40:20<23:51,  3.88s/it]Epoch:   632
max of grad d_p:  tensor(661716.8750, device='cuda:0')
min of grad d_p:  tensor(-85752.9688, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.1992, device='cuda:0') mean:  tensor(-0.0005, device='cuda:0') min:  tensor(-6.3164, device='cuda:0') norm:  tensor(66.2743, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(88.0391, device='cuda:0') mean:  tensor(0.1439, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(346.5417, device='cuda:0') MSE:  tensor(0.0013, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2616, device='cuda:0')
min of d_p_list:  tensor(-0.2946, device='cuda:0')
Epoch:  632  
Training Loss: 1333255.375
Test Loss:  852637.5
Test Acc:  0.0
Valid Loss:  1074634.25
Valid Acc:  0.0
std:  18647.229515634488 
thres:  1358.7656499999998
Preserved_eigens number check:  56
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  50
 63%|██████▎   | 632/1000 [40:24<24:02,  3.92s/it]Epoch:   633
max of grad d_p:  tensor(665742.5000, device='cuda:0')
min of grad d_p:  tensor(-84417.9062, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.4414, device='cuda:0') mean:  tensor(-0.0012, device='cuda:0') min:  tensor(-6.7852, device='cuda:0') norm:  tensor(71.7155, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(27.1846, device='cuda:0') mean:  tensor(0.0671, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(142.5357, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0468, device='cuda:0')
min of d_p_list:  tensor(-0.0993, device='cuda:0')
Epoch:  633  
Training Loss: 1320253.625
Test Loss:  844382.0
Test Acc:  0.0
Valid Loss:  1064310.0
Valid Acc:  0.0
std:  18148.452816734818 
thres:  1345.6943
Preserved_eigens number check:  50
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  47
 63%|██████▎   | 633/1000 [40:27<23:31,  3.85s/it]Epoch:   634
max of grad d_p:  tensor(666494.6250, device='cuda:0')
min of grad d_p:  tensor(-83659.7344, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.1367, device='cuda:0') mean:  tensor(-0.0024, device='cuda:0') min:  tensor(-6.4766, device='cuda:0') norm:  tensor(61.9686, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(58.1328, device='cuda:0') mean:  tensor(0.0976, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(221.1640, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0342, device='cuda:0')
min of d_p_list:  tensor(-0.0363, device='cuda:0')
Epoch:  634  
Training Loss: 1307234.625
Test Loss:  835993.125
Test Acc:  0.0
Valid Loss:  1053920.25
Valid Acc:  0.0
std:  17907.795848910326 
thres:  1332.762575
Preserved_eigens number check:  47
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  50
 63%|██████▎   | 634/1000 [40:31<23:27,  3.85s/it]Epoch:   635
max of grad d_p:  tensor(664406.4375, device='cuda:0')
min of grad d_p:  tensor(-82988.8672, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.3398, device='cuda:0') mean:  tensor(-0.0019, device='cuda:0') min:  tensor(-7.5078, device='cuda:0') norm:  tensor(73.6511, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(45.9844, device='cuda:0') mean:  tensor(0.1429, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(332.3386, device='cuda:0') MSE:  tensor(0.0012, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1220, device='cuda:0')
min of d_p_list:  tensor(-0.0803, device='cuda:0')
Epoch:  635  
Training Loss: 1294957.25
Test Loss:  828027.25
Test Acc:  0.0
Valid Loss:  1044140.5
Valid Acc:  0.0
std:  17785.703241051506 
thres:  1320.103425
Preserved_eigens number check:  50
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  79
 64%|██████▎   | 635/1000 [40:35<23:08,  3.80s/it]Epoch:   636
max of grad d_p:  tensor(656624.0625, device='cuda:0')
min of grad d_p:  tensor(-82770.3750, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.9531, device='cuda:0') mean:  tensor(-0.0005, device='cuda:0') min:  tensor(-6.6484, device='cuda:0') norm:  tensor(64.5250, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(57.4570, device='cuda:0') mean:  tensor(0.0646, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(164.8928, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0150, device='cuda:0')
min of d_p_list:  tensor(-0.0131, device='cuda:0')
Epoch:  636  
Training Loss: 1282064.25
Test Loss:  819828.875
Test Acc:  0.0
Valid Loss:  1033784.375
Valid Acc:  0.0
std:  18057.40077250184 
thres:  1307.553025
Preserved_eigens number check:  79
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  107
 64%|██████▎   | 636/1000 [40:39<22:57,  3.78s/it]Epoch:   637
max of grad d_p:  tensor(654200.2500, device='cuda:0')
min of grad d_p:  tensor(-82075.9688, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.4766, device='cuda:0') mean:  tensor(-0.0008, device='cuda:0') min:  tensor(-6.5898, device='cuda:0') norm:  tensor(62.4996, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(288.6719, device='cuda:0') mean:  tensor(0.5616, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1326.5953, device='cuda:0') MSE:  tensor(0.0050, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0409, device='cuda:0')
min of d_p_list:  tensor(-0.0353, device='cuda:0')
Epoch:  637  
Training Loss: 1269313.5
Test Loss:  811747.3125
Test Acc:  0.0
Valid Loss:  1023454.0
Valid Acc:  0.0
std:  17968.229819844524 
thres:  1294.7646499999998
Preserved_eigens number check:  107
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  49
 64%|██████▎   | 637/1000 [40:43<23:22,  3.86s/it]Epoch:   638
max of grad d_p:  tensor(650100.6250, device='cuda:0')
min of grad d_p:  tensor(-81414.9375, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.0312, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-6.5664, device='cuda:0') norm:  tensor(65.8036, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(63.2744, device='cuda:0') mean:  tensor(0.1032, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(257.7123, device='cuda:0') MSE:  tensor(0.0010, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0194, device='cuda:0')
min of d_p_list:  tensor(-0.0166, device='cuda:0')
Epoch:  638  
Training Loss: 1256694.625
Test Loss:  803746.0
Test Acc:  0.0
Valid Loss:  1013328.6875
Valid Acc:  0.0
std:  17921.919958775346 
thres:  1282.05285
Preserved_eigens number check:  49
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  50
 64%|██████▍   | 638/1000 [40:46<23:09,  3.84s/it]Epoch:   639
max of grad d_p:  tensor(645138.2500, device='cuda:0')
min of grad d_p:  tensor(-80634.8125, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.4531, device='cuda:0') mean:  tensor(-3.9008e-05, device='cuda:0') min:  tensor(-6.5938, device='cuda:0') norm:  tensor(71.2787, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(48.7129, device='cuda:0') mean:  tensor(0.0884, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(205.8984, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0261, device='cuda:0')
min of d_p_list:  tensor(-0.0444, device='cuda:0')
Epoch:  639  
Training Loss: 1244266.25
Test Loss:  795683.375
Test Acc:  0.0
Valid Loss:  1003376.5625
Valid Acc:  0.0
std:  17925.837065113585 
thres:  1269.4591750000002
Preserved_eigens number check:  50
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  44
 64%|██████▍   | 639/1000 [40:50<23:10,  3.85s/it]Epoch:   640
max of grad d_p:  tensor(640575.9375, device='cuda:0')
min of grad d_p:  tensor(-79697.8906, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.4727, device='cuda:0') mean:  tensor(-0.0025, device='cuda:0') min:  tensor(-7.1445, device='cuda:0') norm:  tensor(69.8456, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(35.4062, device='cuda:0') mean:  tensor(0.0736, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(169.1371, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0343, device='cuda:0')
min of d_p_list:  tensor(-0.0294, device='cuda:0')
Epoch:  640  
Training Loss: 1231914.375
Test Loss:  787785.875
Test Acc:  0.0
Valid Loss:  993561.375
Valid Acc:  0.0
std:  17727.1403960495 
thres:  1256.8506000000002
Preserved_eigens number check:  44
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  254
 64%|██████▍   | 640/1000 [40:54<23:09,  3.86s/it]Epoch:   641
max of grad d_p:  tensor(637635.7500, device='cuda:0')
min of grad d_p:  tensor(-79116.9531, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.0781, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-6.0820, device='cuda:0') norm:  tensor(66.4396, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1901.5469, device='cuda:0') mean:  tensor(2.0710, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(5615.0898, device='cuda:0') MSE:  tensor(0.0211, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1141, device='cuda:0')
min of d_p_list:  tensor(-0.1677, device='cuda:0')
Epoch:  641  
Training Loss: 1218622.125
Test Loss:  779170.375
Test Acc:  0.0
Valid Loss:  982168.875
Valid Acc:  0.0
std:  17843.570509885347 
thres:  1244.1621750000002
Preserved_eigens number check:  254
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  124
 64%|██████▍   | 641/1000 [40:58<23:11,  3.88s/it]Epoch:   642
max of grad d_p:  tensor(632809.8750, device='cuda:0')
min of grad d_p:  tensor(-77958.3203, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.7305, device='cuda:0') mean:  tensor(-5.4468e-05, device='cuda:0') min:  tensor(-5.1133, device='cuda:0') norm:  tensor(58.8366, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(15.1797, device='cuda:0') mean:  tensor(0.0407, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(87.1077, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1719, device='cuda:0')
min of d_p_list:  tensor(-0.1644, device='cuda:0')
Epoch:  642  
Training Loss: 1209050.375
Test Loss:  773941.3125
Test Acc:  0.0
Valid Loss:  973778.875
Valid Acc:  0.0
std:  17122.415400506437 
thres:  1232.1095500000001
Preserved_eigens number check:  124
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  58
 64%|██████▍   | 642/1000 [41:02<23:07,  3.88s/it]Epoch:   643
max of grad d_p:  tensor(634173.3750, device='cuda:0')
min of grad d_p:  tensor(-77385.9922, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.0938, device='cuda:0') mean:  tensor(-0.0001, device='cuda:0') min:  tensor(-6.0898, device='cuda:0') norm:  tensor(69.4728, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(32.4922, device='cuda:0') mean:  tensor(0.0647, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(140.4047, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(1.5801, device='cuda:0')
min of d_p_list:  tensor(-1.7085, device='cuda:0')
Epoch:  643  
Training Loss: 1265751.5
Test Loss:  823079.8125
Test Acc:  0.0
Valid Loss:  1020238.625
Valid Acc:  0.0
std:  19883.837837959 
thres:  1233.9209250000001
Preserved_eigens number check:  58
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 64%|██████▍   | 643/1000 [41:06<23:06,  3.88s/it]Epoch:   644
max of grad d_p:  tensor(691859.6250, device='cuda:0')
min of grad d_p:  tensor(-74186.6562, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.7188, device='cuda:0') mean:  tensor(-0.0008, device='cuda:0') min:  tensor(-5.8281, device='cuda:0') norm:  tensor(59.6056, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(377.2344, device='cuda:0') mean:  tensor(0.4026, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1159.2388, device='cuda:0') MSE:  tensor(0.0044, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0883, device='cuda:0')
min of d_p_list:  tensor(-0.0256, device='cuda:0')
Epoch:  644  
Training Loss: 1253100.0
Test Loss:  814904.875
Test Acc:  0.0
Valid Loss:  1010267.5625
Valid Acc:  0.0
std:  21080.982787900328 
thres:  1235.6876750000001
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  36
 64%|██████▍   | 644/1000 [41:10<23:15,  3.92s/it]Epoch:   645
max of grad d_p:  tensor(688572.1875, device='cuda:0')
min of grad d_p:  tensor(-73503.5312, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.9062, device='cuda:0') mean:  tensor(-0.0012, device='cuda:0') min:  tensor(-6.0312, device='cuda:0') norm:  tensor(61.4613, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(37.2109, device='cuda:0') mean:  tensor(0.0624, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(157.7515, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0506, device='cuda:0')
min of d_p_list:  tensor(-0.0330, device='cuda:0')
Epoch:  645  
Training Loss: 1240638.75
Test Loss:  806861.625
Test Acc:  0.0
Valid Loss:  1000377.5
Valid Acc:  0.0
std:  21057.500247922355 
thres:  1237.43255
Preserved_eigens number check:  36
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  64
 64%|██████▍   | 645/1000 [41:14<22:58,  3.88s/it]Epoch:   646
max of grad d_p:  tensor(685205.8750, device='cuda:0')
min of grad d_p:  tensor(-72898.6016, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.4688, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-6.4180, device='cuda:0') norm:  tensor(66.6595, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(68., device='cuda:0') mean:  tensor(0.1545, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(393.4019, device='cuda:0') MSE:  tensor(0.0015, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0369, device='cuda:0')
min of d_p_list:  tensor(-0.0238, device='cuda:0')
Epoch:  646  
Training Loss: 1228296.75
Test Loss:  798864.0625
Test Acc:  0.0
Valid Loss:  990564.75
Valid Acc:  0.0
std:  19636.713893304553 
thres:  1239.367475
Preserved_eigens number check:  64
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  48
 65%|██████▍   | 646/1000 [41:18<22:56,  3.89s/it]Epoch:   647
max of grad d_p:  tensor(681490., device='cuda:0')
min of grad d_p:  tensor(-72158.8438, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.9844, device='cuda:0') mean:  tensor(-0.0005, device='cuda:0') min:  tensor(-6.7227, device='cuda:0') norm:  tensor(63.5307, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(25.0371, device='cuda:0') mean:  tensor(0.0730, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(177.2407, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0251, device='cuda:0')
min of d_p_list:  tensor(-0.0129, device='cuda:0')
Epoch:  647  
Training Loss: 1216097.125
Test Loss:  790971.25
Test Acc:  0.0
Valid Loss:  980751.0
Valid Acc:  0.0
std:  17552.515274099605 
thres:  1240.776825
Preserved_eigens number check:  48
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  80
 65%|██████▍   | 647/1000 [41:21<22:47,  3.87s/it]Epoch:   648
max of grad d_p:  tensor(677196.0625, device='cuda:0')
min of grad d_p:  tensor(-71429.1875, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.4062, device='cuda:0') mean:  tensor(-0.0006, device='cuda:0') min:  tensor(-6.6055, device='cuda:0') norm:  tensor(67.8052, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(37.7754, device='cuda:0') mean:  tensor(0.0595, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(172.1322, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0329, device='cuda:0')
min of d_p_list:  tensor(-0.0575, device='cuda:0')
Epoch:  648  
Training Loss: 1204040.5
Test Loss:  783216.5625
Test Acc:  0.0
Valid Loss:  971022.625
Valid Acc:  0.0
std:  17347.205199613567 
thres:  1228.434625
Preserved_eigens number check:  80
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 65%|██████▍   | 648/1000 [41:25<22:41,  3.87s/it]Epoch:   649
max of grad d_p:  tensor(672086.1250, device='cuda:0')
min of grad d_p:  tensor(-70591.2500, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.5000, device='cuda:0') mean:  tensor(-5.4814e-05, device='cuda:0') min:  tensor(-6.2617, device='cuda:0') norm:  tensor(62.4751, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(45.6797, device='cuda:0') mean:  tensor(0.0756, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(182.9245, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0446, device='cuda:0')
min of d_p_list:  tensor(-0.0393, device='cuda:0')
Epoch:  649  
Training Loss: 1192072.625
Test Loss:  775490.25
Test Acc:  0.0
Valid Loss:  961357.9375
Valid Acc:  0.0
std:  17167.258729446294 
thres:  1216.22915
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  60
 65%|██████▍   | 649/1000 [41:29<22:44,  3.89s/it]Epoch:   650
max of grad d_p:  tensor(668426.8750, device='cuda:0')
min of grad d_p:  tensor(-69907.7969, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.3281, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-5.5508, device='cuda:0') norm:  tensor(60.2447, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(328.0547, device='cuda:0') mean:  tensor(0.6835, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1612.0090, device='cuda:0') MSE:  tensor(0.0061, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0385, device='cuda:0')
min of d_p_list:  tensor(-0.0268, device='cuda:0')
Epoch:  650  
Training Loss: 1180218.25
Test Loss:  767863.4375
Test Acc:  0.0
Valid Loss:  951964.375
Valid Acc:  0.0
std:  16996.48695477245 
thres:  1204.14505
Preserved_eigens number check:  60
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  31
 65%|██████▌   | 650/1000 [41:33<22:42,  3.89s/it]Epoch:   651
max of grad d_p:  tensor(664832.8750, device='cuda:0')
min of grad d_p:  tensor(-69146.8281, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.3438, device='cuda:0') mean:  tensor(-0.0003, device='cuda:0') min:  tensor(-6.0527, device='cuda:0') norm:  tensor(56.9780, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(111.5264, device='cuda:0') mean:  tensor(0.2917, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(691.1746, device='cuda:0') MSE:  tensor(0.0026, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0433, device='cuda:0')
min of d_p_list:  tensor(-0.0263, device='cuda:0')
Epoch:  651  
Training Loss: 1168511.75
Test Loss:  760409.5
Test Acc:  0.0
Valid Loss:  942681.1875
Valid Acc:  0.0
std:  16828.43459754204 
thres:  1192.18805
Preserved_eigens number check:  31
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 65%|██████▌   | 651/1000 [41:37<22:09,  3.81s/it]Epoch:   652
max of grad d_p:  tensor(661498.2500, device='cuda:0')
min of grad d_p:  tensor(-68425.3438, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.1250, device='cuda:0') mean:  tensor(-0.0018, device='cuda:0') min:  tensor(-8., device='cuda:0') norm:  tensor(57.6493, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.8477, device='cuda:0') mean:  tensor(0.0197, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(47.6888, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0170, device='cuda:0')
min of d_p_list:  tensor(-0.0307, device='cuda:0')
Epoch:  652  
Training Loss: 1156875.75
Test Loss:  752835.375
Test Acc:  0.0
Valid Loss:  933344.125
Valid Acc:  0.0
std:  16672.501117558815 
thres:  1180.3437749999998
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  53
 65%|██████▌   | 652/1000 [41:40<22:02,  3.80s/it]Epoch:   653
max of grad d_p:  tensor(657743.8125, device='cuda:0')
min of grad d_p:  tensor(-67762.7344, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.7188, device='cuda:0') mean:  tensor(-0.0005, device='cuda:0') min:  tensor(-6.4473, device='cuda:0') norm:  tensor(63.9240, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(74.3770, device='cuda:0') mean:  tensor(0.1089, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(312.4864, device='cuda:0') MSE:  tensor(0.0012, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0567, device='cuda:0')
min of d_p_list:  tensor(-0.0337, device='cuda:0')
Epoch:  653  
Training Loss: 1145431.375
Test Loss:  745543.125
Test Acc:  0.0
Valid Loss:  924189.0
Valid Acc:  0.0
std:  16493.61366684845 
thres:  1168.62195
Preserved_eigens number check:  53
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  65
 65%|██████▌   | 653/1000 [41:44<21:53,  3.78s/it]Epoch:   654
max of grad d_p:  tensor(654170.2500, device='cuda:0')
min of grad d_p:  tensor(-66989.9062, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.4844, device='cuda:0') mean:  tensor(-0.0001, device='cuda:0') min:  tensor(-6.6582, device='cuda:0') norm:  tensor(65.0610, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(17.7344, device='cuda:0') mean:  tensor(0.0352, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(88.9671, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0308, device='cuda:0')
min of d_p_list:  tensor(-0.0420, device='cuda:0')
Epoch:  654  
Training Loss: 1134066.875
Test Loss:  738171.25
Test Acc:  0.0
Valid Loss:  915172.375
Valid Acc:  0.0
std:  16317.978444916209 
thres:  1157.0208
Preserved_eigens number check:  65
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 65%|██████▌   | 654/1000 [41:48<21:57,  3.81s/it]Epoch:   655
max of grad d_p:  tensor(651056.1250, device='cuda:0')
min of grad d_p:  tensor(-66315.1875, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.4375, device='cuda:0') mean:  tensor(-0.0005, device='cuda:0') min:  tensor(-6.1465, device='cuda:0') norm:  tensor(60.7830, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(44.6094, device='cuda:0') mean:  tensor(0.0532, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(146.3413, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0386, device='cuda:0')
min of d_p_list:  tensor(-0.0256, device='cuda:0')
Epoch:  655  
Training Loss: 1122788.875
Test Loss:  730862.625
Test Acc:  0.0
Valid Loss:  906160.125
Valid Acc:  0.0
std:  16158.33210927879 
thres:  1145.5349250000002
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  41
 66%|██████▌   | 655/1000 [41:52<21:52,  3.80s/it]Epoch:   656
max of grad d_p:  tensor(648000.8750, device='cuda:0')
min of grad d_p:  tensor(-65729.1562, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.0625, device='cuda:0') mean:  tensor(0.0011, device='cuda:0') min:  tensor(-6.1055, device='cuda:0') norm:  tensor(61.1541, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(58.3406, device='cuda:0') mean:  tensor(0.1472, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(351.9949, device='cuda:0') MSE:  tensor(0.0013, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0858, device='cuda:0')
min of d_p_list:  tensor(-0.0611, device='cuda:0')
Epoch:  656  
Training Loss: 1111676.25
Test Loss:  723774.375
Test Acc:  0.0
Valid Loss:  897302.625
Valid Acc:  0.0
std:  15986.738606693674 
thres:  1134.167825
Preserved_eigens number check:  41
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  51
 66%|██████▌   | 656/1000 [41:56<22:07,  3.86s/it]Epoch:   657
max of grad d_p:  tensor(645574.8125, device='cuda:0')
min of grad d_p:  tensor(-65042.5078, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.8730, device='cuda:0') mean:  tensor(-0.0016, device='cuda:0') min:  tensor(-5.6855, device='cuda:0') norm:  tensor(55.5872, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(127.7305, device='cuda:0') mean:  tensor(0.3195, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(743.3181, device='cuda:0') MSE:  tensor(0.0028, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0375, device='cuda:0')
min of d_p_list:  tensor(-0.0288, device='cuda:0')
Epoch:  657  
Training Loss: 1100607.625
Test Loss:  716482.4375
Test Acc:  0.0
Valid Loss:  888385.375
Valid Acc:  0.0
std:  15844.84676117128 
thres:  1122.9142
Preserved_eigens number check:  51
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  37
 66%|██████▌   | 657/1000 [42:00<21:58,  3.85s/it]Epoch:   658
max of grad d_p:  tensor(642175.6250, device='cuda:0')
min of grad d_p:  tensor(-64404.6133, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.6406, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-5.9062, device='cuda:0') norm:  tensor(59.1674, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(21.6797, device='cuda:0') mean:  tensor(0.0420, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(116.6148, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0186, device='cuda:0')
min of d_p_list:  tensor(-0.0258, device='cuda:0')
Epoch:  658  
Training Loss: 1089634.875
Test Loss:  709355.375
Test Acc:  0.0
Valid Loss:  879632.5625
Valid Acc:  0.0
std:  15704.370502825002 
thres:  1111.7549
Preserved_eigens number check:  37
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 66%|██████▌   | 658/1000 [42:03<21:53,  3.84s/it]Epoch:   659
max of grad d_p:  tensor(639006.3750, device='cuda:0')
min of grad d_p:  tensor(-63838.7383, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.3750, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-5.7793, device='cuda:0') norm:  tensor(62.1684, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(12.4863, device='cuda:0') mean:  tensor(0.0285, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(69.9846, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1690, device='cuda:0')
min of d_p_list:  tensor(-0.1664, device='cuda:0')
Epoch:  659  
Training Loss: 1078970.5
Test Loss:  702934.125
Test Acc:  0.0
Valid Loss:  871072.125
Valid Acc:  0.0
std:  15511.33012853024 
thres:  1100.735625
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  37
 66%|██████▌   | 659/1000 [42:07<21:34,  3.80s/it]Epoch:   660
max of grad d_p:  tensor(634624.6250, device='cuda:0')
min of grad d_p:  tensor(-63596.4805, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.9688, device='cuda:0') mean:  tensor(-0.0001, device='cuda:0') min:  tensor(-6.1094, device='cuda:0') norm:  tensor(62.6009, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(12.6348, device='cuda:0') mean:  tensor(0.0219, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(59.3187, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1247, device='cuda:0')
min of d_p_list:  tensor(-0.1285, device='cuda:0')
Epoch:  660  
Training Loss: 1069608.75
Test Loss:  696983.25
Test Acc:  0.0
Valid Loss:  862723.375
Valid Acc:  0.0
std:  14966.08288418349 
thres:  1090.0996
Preserved_eigens number check:  37
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  99
 66%|██████▌   | 660/1000 [42:11<21:24,  3.78s/it]Epoch:   661
max of grad d_p:  tensor(632870.3750, device='cuda:0')
min of grad d_p:  tensor(-63198.1562, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.3594, device='cuda:0') mean:  tensor(-0.0005, device='cuda:0') min:  tensor(-6.5703, device='cuda:0') norm:  tensor(62.9626, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(58.9980, device='cuda:0') mean:  tensor(0.0984, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(229.0083, device='cuda:0') MSE:  tensor(0.0009, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0096, device='cuda:0')
min of d_p_list:  tensor(-0.0088, device='cuda:0')
Epoch:  661  
Training Loss: 1058958.5
Test Loss:  690071.25
Test Acc:  0.0
Valid Loss:  854151.75
Valid Acc:  0.0
std:  14617.128551505935 
thres:  1079.5560500000001
Preserved_eigens number check:  99
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  59
 66%|██████▌   | 661/1000 [42:15<21:34,  3.82s/it]Epoch:   662
max of grad d_p:  tensor(629249.5625, device='cuda:0')
min of grad d_p:  tensor(-62587.3281, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.8281, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(-5.7324, device='cuda:0') norm:  tensor(61.3502, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(44.6758, device='cuda:0') mean:  tensor(0.0741, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(191.7360, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0187, device='cuda:0')
min of d_p_list:  tensor(-0.0098, device='cuda:0')
Epoch:  662  
Training Loss: 1048405.9375
Test Loss:  683247.625
Test Acc:  0.0
Valid Loss:  845693.25
Valid Acc:  0.0
std:  14494.548621248956 
thres:  1069.1157125
Preserved_eigens number check:  59
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  42
 66%|██████▌   | 662/1000 [42:19<21:26,  3.81s/it]Epoch:   663
max of grad d_p:  tensor(625948.8750, device='cuda:0')
min of grad d_p:  tensor(-61873.9922, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.5938, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-5.5957, device='cuda:0') norm:  tensor(57.9415, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(108.7812, device='cuda:0') mean:  tensor(0.2263, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(609.0493, device='cuda:0') MSE:  tensor(0.0023, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0791, device='cuda:0')
min of d_p_list:  tensor(-0.0677, device='cuda:0')
Epoch:  663  
Training Loss: 1037958.125
Test Loss:  676364.5625
Test Acc:  0.0
Valid Loss:  837558.4375
Valid Acc:  0.0
std:  14602.20277680734 
thres:  1058.7803625000001
Preserved_eigens number check:  42
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 66%|██████▋   | 663/1000 [42:22<21:31,  3.83s/it]Epoch:   664
max of grad d_p:  tensor(625131.1875, device='cuda:0')
min of grad d_p:  tensor(-61167.6133, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(13.4375, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-5.6133, device='cuda:0') norm:  tensor(63.8549, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(43.1484, device='cuda:0') mean:  tensor(0.1010, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(272.6317, device='cuda:0') MSE:  tensor(0.0010, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0198, device='cuda:0')
min of d_p_list:  tensor(-0.0263, device='cuda:0')
Epoch:  664  
Training Loss: 1027628.875
Test Loss:  669703.875
Test Acc:  0.0
Valid Loss:  829268.0
Valid Acc:  0.0
std:  14843.871862426091 
thres:  1048.5120375
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  58
 66%|██████▋   | 664/1000 [42:27<21:51,  3.90s/it]Epoch:   665
max of grad d_p:  tensor(621420.5625, device='cuda:0')
min of grad d_p:  tensor(-60620.9102, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(15.6250, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-5.9746, device='cuda:0') norm:  tensor(71.7042, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(36.2344, device='cuda:0') mean:  tensor(0.1028, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(243.0805, device='cuda:0') MSE:  tensor(0.0009, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2747, device='cuda:0')
min of d_p_list:  tensor(-0.2584, device='cuda:0')
Epoch:  665  
Training Loss: 1017277.625
Test Loss:  663010.125
Test Acc:  0.0
Valid Loss:  820906.875
Valid Acc:  0.0
std:  14727.597064694566 
thres:  1038.0458125
Preserved_eigens number check:  58
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  117
 66%|██████▋   | 665/1000 [42:30<21:27,  3.84s/it]Epoch:   666
max of grad d_p:  tensor(609148.8125, device='cuda:0')
min of grad d_p:  tensor(-60689.4922, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.7656, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(-5.0820, device='cuda:0') norm:  tensor(64.6525, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(25.8438, device='cuda:0') mean:  tensor(0.0381, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(93.8875, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0428, device='cuda:0')
min of d_p_list:  tensor(-0.0627, device='cuda:0')
Epoch:  666  
Training Loss: 1007216.6875
Test Loss:  656608.625
Test Acc:  0.0
Valid Loss:  812839.5
Valid Acc:  0.0
std:  14575.060851577515 
thres:  1027.69745
Preserved_eigens number check:  117
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  102
 67%|██████▋   | 666/1000 [42:34<21:04,  3.79s/it]Epoch:   667
max of grad d_p:  tensor(606647.9375, device='cuda:0')
min of grad d_p:  tensor(-60115.1055, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.1914, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-5.0664, device='cuda:0') norm:  tensor(53.5116, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(11.7656, device='cuda:0') mean:  tensor(0.0203, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(53.7828, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0842, device='cuda:0')
min of d_p_list:  tensor(-0.0762, device='cuda:0')
Epoch:  667  
Training Loss: 997247.0
Test Loss:  649988.4375
Test Acc:  0.0
Valid Loss:  804778.0
Valid Acc:  0.0
std:  14402.104482158154 
thres:  1017.4656625
Preserved_eigens number check:  102
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  77
 67%|██████▋   | 667/1000 [42:38<21:18,  3.84s/it]Epoch:   668
max of grad d_p:  tensor(604186.8750, device='cuda:0')
min of grad d_p:  tensor(-59337.8047, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.7188, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-5.5234, device='cuda:0') norm:  tensor(64.6689, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4331.5352, device='cuda:0') mean:  tensor(6.0551, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(16231.2080, device='cuda:0') MSE:  tensor(0.0609, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0500, device='cuda:0')
min of d_p_list:  tensor(-0.0535, device='cuda:0')
Epoch:  668  
Training Loss: 987329.875
Test Loss:  643518.125
Test Acc:  0.0
Valid Loss:  796821.5
Valid Acc:  0.0
std:  14231.541005061608 
thres:  1007.3400125
Preserved_eigens number check:  77
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 67%|██████▋   | 668/1000 [42:42<21:22,  3.86s/it]Epoch:   669
max of grad d_p:  tensor(600545.5625, device='cuda:0')
min of grad d_p:  tensor(-58772.1250, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.7656, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-5.7227, device='cuda:0') norm:  tensor(55.5499, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(21.3906, device='cuda:0') mean:  tensor(0.0405, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(98.3532, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1438, device='cuda:0')
min of d_p_list:  tensor(-0.0893, device='cuda:0')
Epoch:  669  
Training Loss: 977903.5
Test Loss:  637489.25
Test Acc:  0.0
Valid Loss:  789577.0625
Valid Acc:  0.0
std:  13950.1364848834 
thres:  997.3949375
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  34
 67%|██████▋   | 669/1000 [42:45<21:01,  3.81s/it]Epoch:   670
max of grad d_p:  tensor(598612.8750, device='cuda:0')
min of grad d_p:  tensor(-58214.0859, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.7656, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-5.2656, device='cuda:0') norm:  tensor(61.5557, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(16.7324, device='cuda:0') mean:  tensor(0.0259, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(71.9286, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0825, device='cuda:0')
min of d_p_list:  tensor(-0.0338, device='cuda:0')
Epoch:  670  
Training Loss: 968174.875
Test Loss:  631088.75
Test Acc:  0.0
Valid Loss:  781887.5
Valid Acc:  0.0
std:  13779.015338572819 
thres:  987.5743875
Preserved_eigens number check:  34
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  64
 67%|██████▋   | 670/1000 [42:49<20:43,  3.77s/it]Epoch:   671
max of grad d_p:  tensor(594866.9375, device='cuda:0')
min of grad d_p:  tensor(-57645.0234, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.3535, device='cuda:0') mean:  tensor(-0.0013, device='cuda:0') min:  tensor(-5.3594, device='cuda:0') norm:  tensor(54.5961, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(166.2207, device='cuda:0') mean:  tensor(0.1289, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(358.0831, device='cuda:0') MSE:  tensor(0.0013, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0144, device='cuda:0')
min of d_p_list:  tensor(-0.0298, device='cuda:0')
Epoch:  671  
Training Loss: 958545.3125
Test Loss:  624821.625
Test Acc:  0.0
Valid Loss:  774219.125
Valid Acc:  0.0
std:  13655.716866504117 
thres:  977.8401125
Preserved_eigens number check:  64
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  42
 67%|██████▋   | 671/1000 [42:53<20:28,  3.73s/it]Epoch:   672
max of grad d_p:  tensor(591936.0625, device='cuda:0')
min of grad d_p:  tensor(-56933.3242, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.7656, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-5.1523, device='cuda:0') norm:  tensor(58.3163, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(41.7383, device='cuda:0') mean:  tensor(0.0442, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(117.1933, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0264, device='cuda:0')
min of d_p_list:  tensor(-0.0132, device='cuda:0')
Epoch:  672  
Training Loss: 949005.125
Test Loss:  618713.75
Test Acc:  0.0
Valid Loss:  766571.5625
Valid Acc:  0.0
std:  13577.676801831747 
thres:  968.1917375
Preserved_eigens number check:  42
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  36
 67%|██████▋   | 672/1000 [42:57<20:32,  3.76s/it]Epoch:   673
max of grad d_p:  tensor(589030.8750, device='cuda:0')
min of grad d_p:  tensor(-56363.3711, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.4375, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(-5.1367, device='cuda:0') norm:  tensor(58.6970, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.6680, device='cuda:0') mean:  tensor(0.0154, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(44.7540, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0325, device='cuda:0')
min of d_p_list:  tensor(-0.0196, device='cuda:0')
Epoch:  673  
Training Loss: 939581.5
Test Loss:  612631.375
Test Acc:  0.0
Valid Loss:  759147.25
Valid Acc:  0.0
std:  13550.3686775259 
thres:  958.6420625000001
Preserved_eigens number check:  36
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  50
 67%|██████▋   | 673/1000 [43:01<21:02,  3.86s/it]Epoch:   674
max of grad d_p:  tensor(586222.7500, device='cuda:0')
min of grad d_p:  tensor(-55723.9219, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.9590, device='cuda:0') mean:  tensor(-1.2085e-05, device='cuda:0') min:  tensor(-5.1250, device='cuda:0') norm:  tensor(54.0714, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(20.6895, device='cuda:0') mean:  tensor(0.0381, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(93.9590, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0815, device='cuda:0')
min of d_p_list:  tensor(-0.0576, device='cuda:0')
Epoch:  674  
Training Loss: 930695.0
Test Loss:  607071.0
Test Acc:  0.0
Valid Loss:  752039.5625
Valid Acc:  0.0
std:  13284.346350851254 
thres:  949.2003625000001
Preserved_eigens number check:  50
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  53
 67%|██████▋   | 674/1000 [43:05<21:01,  3.87s/it]Epoch:   675
max of grad d_p:  tensor(583921.1250, device='cuda:0')
min of grad d_p:  tensor(-55088.0312, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.8438, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-5.0859, device='cuda:0') norm:  tensor(62.5092, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(105.1660, device='cuda:0') mean:  tensor(0.1832, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(485.7682, device='cuda:0') MSE:  tensor(0.0018, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0126, device='cuda:0')
min of d_p_list:  tensor(-0.0132, device='cuda:0')
Epoch:  675  
Training Loss: 921425.5
Test Loss:  601043.25
Test Acc:  0.0
Valid Loss:  744624.0
Valid Acc:  0.0
std:  13089.53276133262 
thres:  939.8504875000001
Preserved_eigens number check:  53
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  33
 68%|██████▊   | 675/1000 [43:08<20:56,  3.87s/it]Epoch:   676
max of grad d_p:  tensor(581096., device='cuda:0')
min of grad d_p:  tensor(-54485.8047, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(15.3125, device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(-5.0078, device='cuda:0') norm:  tensor(67.8051, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(64.2793, device='cuda:0') mean:  tensor(0.0939, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(218.2247, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0176, device='cuda:0')
min of d_p_list:  tensor(-0.0199, device='cuda:0')
Epoch:  676  
Training Loss: 912254.75
Test Loss:  595138.375
Test Acc:  0.0
Valid Loss:  737372.0625
Valid Acc:  0.0
std:  12962.595038224406 
thres:  930.5923750000001
Preserved_eigens number check:  33
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  82
 68%|██████▊   | 676/1000 [43:12<21:02,  3.90s/it]Epoch:   677
max of grad d_p:  tensor(578894.8750, device='cuda:0')
min of grad d_p:  tensor(-53942.7344, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.9219, device='cuda:0') mean:  tensor(-0.0003, device='cuda:0') min:  tensor(-5.8555, device='cuda:0') norm:  tensor(57.8630, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(26.0117, device='cuda:0') mean:  tensor(0.0575, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(128.1334, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0135, device='cuda:0')
min of d_p_list:  tensor(-0.0153, device='cuda:0')
Epoch:  677  
Training Loss: 903166.8125
Test Loss:  589255.75
Test Acc:  0.0
Valid Loss:  730100.125
Valid Acc:  0.0
std:  12907.72085175671 
thres:  921.4247125
Preserved_eigens number check:  82
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  45
 68%|██████▊   | 677/1000 [43:16<20:55,  3.89s/it]Epoch:   678
max of grad d_p:  tensor(575896.7500, device='cuda:0')
min of grad d_p:  tensor(-53368.4375, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.1562, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-5.4863, device='cuda:0') norm:  tensor(60.0463, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(303.7070, device='cuda:0') mean:  tensor(0.6417, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1637.0702, device='cuda:0') MSE:  tensor(0.0061, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1205, device='cuda:0')
min of d_p_list:  tensor(-0.1240, device='cuda:0')
Epoch:  678  
Training Loss: 894534.375
Test Loss:  583774.25
Test Acc:  0.0
Valid Loss:  723185.125
Valid Acc:  0.0
std:  12811.080456581327 
thres:  912.4152875
Preserved_eigens number check:  45
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  66
 68%|██████▊   | 678/1000 [43:20<20:44,  3.86s/it]Epoch:   679
max of grad d_p:  tensor(573786.7500, device='cuda:0')
min of grad d_p:  tensor(-53167.8750, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(14.2500, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(-5.5332, device='cuda:0') norm:  tensor(63.3881, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(12.6289, device='cuda:0') mean:  tensor(0.0388, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(91.7956, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0109, device='cuda:0')
min of d_p_list:  tensor(-0.0144, device='cuda:0')
Epoch:  679  
Training Loss: 885634.25
Test Loss:  577994.25
Test Acc:  0.0
Valid Loss:  716013.8125
Valid Acc:  0.0
std:  12630.12869852283 
thres:  903.4031375
Preserved_eigens number check:  66
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 68%|██████▊   | 679/1000 [43:24<20:29,  3.83s/it]Epoch:   680
max of grad d_p:  tensor(570713.1875, device='cuda:0')
min of grad d_p:  tensor(-52621.4141, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.1250, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-5.4844, device='cuda:0') norm:  tensor(59.8575, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.2090, device='cuda:0') mean:  tensor(0.0273, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(63.2464, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1197, device='cuda:0')
min of d_p_list:  tensor(-0.0887, device='cuda:0')
Epoch:  680  
Training Loss: 876866.9375
Test Loss:  572180.75
Test Acc:  0.0
Valid Loss:  708866.75
Valid Acc:  0.0
std:  12488.971267895226 
thres:  894.491425
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  50
 68%|██████▊   | 680/1000 [43:28<20:42,  3.88s/it]Epoch:   681
max of grad d_p:  tensor(568934.1250, device='cuda:0')
min of grad d_p:  tensor(-52011.5078, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(14.3750, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(-5.3945, device='cuda:0') norm:  tensor(65.5777, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(20.1387, device='cuda:0') mean:  tensor(0.0323, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(83.5984, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0536, device='cuda:0')
min of d_p_list:  tensor(-0.0501, device='cuda:0')
Epoch:  681  
Training Loss: 868160.25
Test Loss:  566556.125
Test Acc:  0.0
Valid Loss:  701872.125
Valid Acc:  0.0
std:  12400.01687439628 
thres:  885.6725250000001
Preserved_eigens number check:  50
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  161
 68%|██████▊   | 681/1000 [43:32<20:38,  3.88s/it]Epoch:   682
max of grad d_p:  tensor(565436.2500, device='cuda:0')
min of grad d_p:  tensor(-51520.8281, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(23.5000, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-5.8809, device='cuda:0') norm:  tensor(80.0915, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(13.3516, device='cuda:0') mean:  tensor(0.0221, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(56.8137, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0083, device='cuda:0')
min of d_p_list:  tensor(-0.0200, device='cuda:0')
Epoch:  682  
Training Loss: 859500.75
Test Loss:  560913.625
Test Acc:  0.0
Valid Loss:  694815.75
Valid Acc:  0.0
std:  12380.378032142233 
thres:  876.9393125
Preserved_eigens number check:  161
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  71
 68%|██████▊   | 682/1000 [43:36<20:28,  3.86s/it]Epoch:   683
max of grad d_p:  tensor(562406.6250, device='cuda:0')
min of grad d_p:  tensor(-51035.0898, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.1562, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-5.7910, device='cuda:0') norm:  tensor(60.4198, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(77.9707, device='cuda:0') mean:  tensor(0.1321, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(292.0833, device='cuda:0') MSE:  tensor(0.0011, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0186, device='cuda:0')
min of d_p_list:  tensor(-0.0222, device='cuda:0')
Epoch:  683  
Training Loss: 850970.875
Test Loss:  555382.0625
Test Acc:  0.0
Valid Loss:  687963.9375
Valid Acc:  0.0
std:  12260.396538907296 
thres:  868.2266125000001
Preserved_eigens number check:  71
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  76
 68%|██████▊   | 683/1000 [43:39<20:15,  3.83s/it]Epoch:   684
max of grad d_p:  tensor(559448.6875, device='cuda:0')
min of grad d_p:  tensor(-50497.0273, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.2500, device='cuda:0') mean:  tensor(-7.6434e-05, device='cuda:0') min:  tensor(-5.1738, device='cuda:0') norm:  tensor(60.1853, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(13.5312, device='cuda:0') mean:  tensor(0.0224, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(53.9558, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0299, device='cuda:0')
min of d_p_list:  tensor(-0.0540, device='cuda:0')
Epoch:  684  
Training Loss: 842502.625
Test Loss:  549862.125
Test Acc:  0.0
Valid Loss:  681165.75
Valid Acc:  0.0
std:  12150.859154783047 
thres:  859.6002875
Preserved_eigens number check:  76
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  94
 68%|██████▊   | 684/1000 [43:43<20:17,  3.85s/it]Epoch:   685
max of grad d_p:  tensor(556492.7500, device='cuda:0')
min of grad d_p:  tensor(-49997.1953, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(13.1562, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-5.4219, device='cuda:0') norm:  tensor(66.7420, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(33.0156, device='cuda:0') mean:  tensor(0.0570, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(147.2082, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0190, device='cuda:0')
min of d_p_list:  tensor(-0.0577, device='cuda:0')
Epoch:  685  
Training Loss: 834155.1875
Test Loss:  544422.25
Test Acc:  0.0
Valid Loss:  674429.0
Valid Acc:  0.0
std:  12022.263390658807 
thres:  851.0579375
Preserved_eigens number check:  94
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 68%|██████▊   | 685/1000 [43:47<20:22,  3.88s/it]Epoch:   686
max of grad d_p:  tensor(553872.7500, device='cuda:0')
min of grad d_p:  tensor(-49489.7227, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(14.8750, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(-5.2695, device='cuda:0') norm:  tensor(64.1547, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(21.3867, device='cuda:0') mean:  tensor(0.0497, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(125.0081, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0187, device='cuda:0')
min of d_p_list:  tensor(-0.0242, device='cuda:0')
Epoch:  686  
Training Loss: 825850.4375
Test Loss:  538999.8125
Test Acc:  0.0
Valid Loss:  667735.25
Valid Acc:  0.0
std:  11896.041373643482 
thres:  842.595975
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  35
 69%|██████▊   | 686/1000 [43:51<20:06,  3.84s/it]Epoch:   687
max of grad d_p:  tensor(551156.5000, device='cuda:0')
min of grad d_p:  tensor(-49051.6250, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.7656, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(-5.1816, device='cuda:0') norm:  tensor(58.7401, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(11.3906, device='cuda:0') mean:  tensor(0.0185, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(45.6052, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0100, device='cuda:0')
min of d_p_list:  tensor(-0.0164, device='cuda:0')
Epoch:  687  
Training Loss: 817626.5
Test Loss:  533668.9375
Test Acc:  0.0
Valid Loss:  661135.5
Valid Acc:  0.0
std:  11786.362485344556 
thres:  834.221125
Preserved_eigens number check:  35
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  56
 69%|██████▊   | 687/1000 [43:55<20:13,  3.88s/it]Epoch:   688
max of grad d_p:  tensor(548375.6250, device='cuda:0')
min of grad d_p:  tensor(-48546.8398, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.8281, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-5.2676, device='cuda:0') norm:  tensor(63.4391, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(170.0801, device='cuda:0') mean:  tensor(0.4803, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1064.1959, device='cuda:0') MSE:  tensor(0.0040, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.6165, device='cuda:0')
min of d_p_list:  tensor(-0.3671, device='cuda:0')
Epoch:  688  
Training Loss: 814483.75
Test Loss:  530895.0625
Test Acc:  0.0
Valid Loss:  659272.0
Valid Acc:  0.0
std:  10366.672483055376 
thres:  826.9236999999999
Preserved_eigens number check:  56
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  86
 69%|██████▉   | 688/1000 [43:59<20:22,  3.92s/it]Epoch:   689
max of grad d_p:  tensor(554944., device='cuda:0')
min of grad d_p:  tensor(-48171.2188, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.7188, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-5.3711, device='cuda:0') norm:  tensor(56.5007, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(56.3613, device='cuda:0') mean:  tensor(0.1752, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(373.5013, device='cuda:0') MSE:  tensor(0.0014, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0107, device='cuda:0')
min of d_p_list:  tensor(-0.0124, device='cuda:0')
Epoch:  689  
Training Loss: 806368.6875
Test Loss:  525637.3125
Test Acc:  0.0
Valid Loss:  652704.6875
Valid Acc:  0.0
std:  9550.003546841617 
thres:  819.6969124999999
Preserved_eigens number check:  86
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  67
 69%|██████▉   | 689/1000 [44:02<19:44,  3.81s/it]Epoch:   690
max of grad d_p:  tensor(552023., device='cuda:0')
min of grad d_p:  tensor(-47703.1914, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.2344, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-5.5566, device='cuda:0') norm:  tensor(61.2484, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(23.1465, device='cuda:0') mean:  tensor(0.0365, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(103.1596, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0214, device='cuda:0')
min of d_p_list:  tensor(-0.0270, device='cuda:0')
Epoch:  690  
Training Loss: 798340.1875
Test Loss:  520453.0625
Test Acc:  0.0
Valid Loss:  646087.125
Valid Acc:  0.0
std:  9450.26963079295 
thres:  812.5339125
Preserved_eigens number check:  67
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  80
 69%|██████▉   | 690/1000 [44:06<19:29,  3.77s/it]Epoch:   691
max of grad d_p:  tensor(549221., device='cuda:0')
min of grad d_p:  tensor(-47237.8320, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.2500, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-5.3047, device='cuda:0') norm:  tensor(56.4631, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(30.8398, device='cuda:0') mean:  tensor(0.0510, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(138.8987, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0240, device='cuda:0')
min of d_p_list:  tensor(-0.0160, device='cuda:0')
Epoch:  691  
Training Loss: 790401.5
Test Loss:  515322.46875
Test Acc:  0.0
Valid Loss:  639666.375
Valid Acc:  0.0
std:  10076.96771347599 
thres:  805.444125
Preserved_eigens number check:  80
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  56
 69%|██████▉   | 691/1000 [44:10<19:34,  3.80s/it]Epoch:   692
max of grad d_p:  tensor(546490.2500, device='cuda:0')
min of grad d_p:  tensor(-46694.1367, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(14., device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(-5.0820, device='cuda:0') norm:  tensor(65.4756, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(37.9717, device='cuda:0') mean:  tensor(0.0651, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(167.3742, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(1.9732, device='cuda:0')
min of d_p_list:  tensor(-2.1808, device='cuda:0')
Epoch:  692  
Training Loss: 1243615.75
Test Loss:  846492.75
Test Acc:  0.0
Valid Loss:  1005131.8125
Valid Acc:  0.0
std:  176669.36398984387 
thres:  890.641975
Preserved_eigens number check:  56
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  40
 69%|██████▉   | 692/1000 [44:14<19:49,  3.86s/it]Epoch:   693
max of grad d_p:  tensor(811375.1875, device='cuda:0')
min of grad d_p:  tensor(-62580.5000, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.8770, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-7.2773, device='cuda:0') norm:  tensor(54.7416, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(16.2930, device='cuda:0') mean:  tensor(0.0511, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(107.6876, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0069, device='cuda:0')
min of d_p_list:  tensor(-0.0073, device='cuda:0')
Epoch:  693  
Training Loss: 1231223.625
Test Loss:  838051.75
Test Acc:  0.0
Valid Loss:  995134.875
Valid Acc:  0.0
std:  215184.423814294 
thres:  973.98995
Preserved_eigens number check:  40
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  43
 69%|██████▉   | 693/1000 [44:18<19:42,  3.85s/it]Epoch:   694
max of grad d_p:  tensor(808140.1250, device='cuda:0')
min of grad d_p:  tensor(-61921.9766, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.2500, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(-6.9609, device='cuda:0') norm:  tensor(60.0811, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6753.3613, device='cuda:0') mean:  tensor(7.5595, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(20181.8066, device='cuda:0') MSE:  tensor(0.0758, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0062, device='cuda:0')
min of d_p_list:  tensor(-0.0065, device='cuda:0')
Epoch:  694  
Training Loss: 1218950.625
Test Loss:  829656.125
Test Acc:  0.0
Valid Loss:  985175.1875
Valid Acc:  0.0
std:  214189.52116551332 
thres:  1056.5063375
Preserved_eigens number check:  43
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  66
 69%|██████▉   | 694/1000 [44:22<19:26,  3.81s/it]Epoch:   695
max of grad d_p:  tensor(804567.6250, device='cuda:0')
min of grad d_p:  tensor(-61263.4531, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.0625, device='cuda:0') mean:  tensor(0.0011, device='cuda:0') min:  tensor(-7.1992, device='cuda:0') norm:  tensor(56.4546, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(34.9824, device='cuda:0') mean:  tensor(0.0556, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(137.3918, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0221, device='cuda:0')
min of d_p_list:  tensor(-0.0302, device='cuda:0')
Epoch:  695  
Training Loss: 1206827.5
Test Loss:  821389.25
Test Acc:  0.0
Valid Loss:  975327.4375
Valid Acc:  0.0
std:  174333.0541695371 
thres:  1138.2038
Preserved_eigens number check:  66
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  31
 70%|██████▉   | 695/1000 [44:25<19:06,  3.76s/it]Epoch:   696
max of grad d_p:  tensor(800866., device='cuda:0')
min of grad d_p:  tensor(-60623.8477, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.9375, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(-7.2812, device='cuda:0') norm:  tensor(57.3582, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(32.4961, device='cuda:0') mean:  tensor(0.0700, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(175.3839, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0244, device='cuda:0')
min of d_p_list:  tensor(-0.0121, device='cuda:0')
Epoch:  696  
Training Loss: 1194804.5
Test Loss:  813267.375
Test Acc:  0.0
Valid Loss:  965622.125
Valid Acc:  0.0
std:  17256.366673165878 
thres:  1219.0844
Preserved_eigens number check:  31
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  43
 70%|██████▉   | 696/1000 [44:29<19:17,  3.81s/it]Epoch:   697
max of grad d_p:  tensor(797320.6250, device='cuda:0')
min of grad d_p:  tensor(-60012.5859, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.4922, device='cuda:0') mean:  tensor(-0.0003, device='cuda:0') min:  tensor(-8.0078, device='cuda:0') norm:  tensor(56.5330, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(56.9316, device='cuda:0') mean:  tensor(0.0849, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(219.4749, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0078, device='cuda:0')
min of d_p_list:  tensor(-0.0083, device='cuda:0')
Epoch:  697  
Training Loss: 1182892.0
Test Loss:  805157.75
Test Acc:  0.0
Valid Loss:  955989.125
Valid Acc:  0.0
std:  17085.308752953515 
thres:  1206.93965
Preserved_eigens number check:  43
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  89
 70%|██████▉   | 697/1000 [44:33<19:25,  3.85s/it]Epoch:   698
max of grad d_p:  tensor(794391.6875, device='cuda:0')
min of grad d_p:  tensor(-59472.1758, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.2676, device='cuda:0') mean:  tensor(1.9484e-05, device='cuda:0') min:  tensor(-7.1758, device='cuda:0') norm:  tensor(53.4021, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(23.5898, device='cuda:0') mean:  tensor(0.0468, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(114.1031, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0392, device='cuda:0')
min of d_p_list:  tensor(-0.0806, device='cuda:0')
Epoch:  698  
Training Loss: 1171320.25
Test Loss:  796981.25
Test Acc:  0.0
Valid Loss:  946877.125
Valid Acc:  0.0
std:  16857.55749330252 
thres:  1194.958975
Preserved_eigens number check:  89
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  70
 70%|██████▉   | 698/1000 [44:37<19:18,  3.84s/it]Epoch:   699
max of grad d_p:  tensor(791415.8125, device='cuda:0')
min of grad d_p:  tensor(-59093.8906, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.7188, device='cuda:0') mean:  tensor(-0.0006, device='cuda:0') min:  tensor(-8.1367, device='cuda:0') norm:  tensor(56.6105, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(28.9844, device='cuda:0') mean:  tensor(0.0840, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(192.4606, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0277, device='cuda:0')
min of d_p_list:  tensor(-0.0769, device='cuda:0')
Epoch:  699  
Training Loss: 1159742.0
Test Loss:  789131.25
Test Acc:  0.0
Valid Loss:  937705.5625
Valid Acc:  0.0
std:  16639.65159941758 
thres:  1183.11725
Preserved_eigens number check:  70
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  39
 70%|██████▉   | 699/1000 [44:41<19:29,  3.88s/it]Epoch:   700
max of grad d_p:  tensor(786651.7500, device='cuda:0')
min of grad d_p:  tensor(-58449.8086, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.2188, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-7.0273, device='cuda:0') norm:  tensor(54.1378, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(46.8809, device='cuda:0') mean:  tensor(0.1192, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(280.6578, device='cuda:0') MSE:  tensor(0.0011, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0104, device='cuda:0')
min of d_p_list:  tensor(-0.0135, device='cuda:0')
Epoch:  700  
Training Loss: 1148188.5
Test Loss:  781312.25
Test Acc:  0.0
Valid Loss:  928379.75
Valid Acc:  0.0
std:  16459.193078945274 
thres:  1171.38945
Preserved_eigens number check:  39
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  58
 70%|███████   | 700/1000 [44:45<19:41,  3.94s/it]Epoch:   701
max of grad d_p:  tensor(783343.1250, device='cuda:0')
min of grad d_p:  tensor(-57860.0703, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6., device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(-6.2539, device='cuda:0') norm:  tensor(54.1827, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(779.2734, device='cuda:0') mean:  tensor(1.4082, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(3226.6277, device='cuda:0') MSE:  tensor(0.0121, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0164, device='cuda:0')
min of d_p_list:  tensor(-0.0166, device='cuda:0')
Epoch:  701  
Training Loss: 1136748.875
Test Loss:  773643.625
Test Acc:  0.0
Valid Loss:  919183.25
Valid Acc:  0.0
std:  16322.615813955801 
thres:  1159.778325
Preserved_eigens number check:  58
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  47
 70%|███████   | 701/1000 [44:48<18:56,  3.80s/it]Epoch:   702
max of grad d_p:  tensor(780258.4375, device='cuda:0')
min of grad d_p:  tensor(-57198.4648, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.7383, device='cuda:0') mean:  tensor(-0.0004, device='cuda:0') min:  tensor(-7.7773, device='cuda:0') norm:  tensor(51.9416, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(15.4316, device='cuda:0') mean:  tensor(0.0452, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(99.1914, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0484, device='cuda:0')
min of d_p_list:  tensor(-0.0495, device='cuda:0')
Epoch:  702  
Training Loss: 1125498.25
Test Loss:  765825.5625
Test Acc:  0.0
Valid Loss:  909947.5625
Valid Acc:  0.0
std:  16212.414978882696 
thres:  1148.299575
Preserved_eigens number check:  47
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  41
 70%|███████   | 702/1000 [44:52<19:09,  3.86s/it]Epoch:   703
max of grad d_p:  tensor(776124.9375, device='cuda:0')
min of grad d_p:  tensor(-56456.5703, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.9375, device='cuda:0') mean:  tensor(-0.0001, device='cuda:0') min:  tensor(-7.3789, device='cuda:0') norm:  tensor(51.1370, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(29.4561, device='cuda:0') mean:  tensor(0.0475, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(120.5444, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0085, device='cuda:0')
min of d_p_list:  tensor(-0.0174, device='cuda:0')
Epoch:  703  
Training Loss: 1114279.25
Test Loss:  758177.625
Test Acc:  0.0
Valid Loss:  900854.125
Valid Acc:  0.0
std:  16068.029727925574 
thres:  1136.891375
Preserved_eigens number check:  41
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  104
 70%|███████   | 703/1000 [44:56<18:49,  3.80s/it]Epoch:   704
max of grad d_p:  tensor(772762.0625, device='cuda:0')
min of grad d_p:  tensor(-55851.3125, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.2812, device='cuda:0') mean:  tensor(-0.0004, device='cuda:0') min:  tensor(-7.9727, device='cuda:0') norm:  tensor(52.1363, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(12.6748, device='cuda:0') mean:  tensor(0.0357, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(84.0149, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0103, device='cuda:0')
min of d_p_list:  tensor(-0.0107, device='cuda:0')
Epoch:  704  
Training Loss: 1103155.75
Test Loss:  750702.0
Test Acc:  0.0
Valid Loss:  891601.75
Valid Acc:  0.0
std:  15915.077694595147 
thres:  1125.574125
Preserved_eigens number check:  104
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  65
 70%|███████   | 704/1000 [45:00<19:12,  3.89s/it]Epoch:   705
max of grad d_p:  tensor(769261.7500, device='cuda:0')
min of grad d_p:  tensor(-55208.8750, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.5703, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-6.6406, device='cuda:0') norm:  tensor(49.1188, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(40.7451, device='cuda:0') mean:  tensor(0.0589, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(148.7940, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0124, device='cuda:0')
min of d_p_list:  tensor(-0.0136, device='cuda:0')
Epoch:  705  
Training Loss: 1092172.5
Test Loss:  743349.375
Test Acc:  0.0
Valid Loss:  882669.25
Valid Acc:  0.0
std:  15767.99692367423 
thres:  1114.3709250000002
Preserved_eigens number check:  65
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  62
 70%|███████   | 705/1000 [45:04<19:08,  3.89s/it]Epoch:   706
max of grad d_p:  tensor(765982.0625, device='cuda:0')
min of grad d_p:  tensor(-54599.0664, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.8750, device='cuda:0') mean:  tensor(1.6878e-06, device='cuda:0') min:  tensor(-8.2031, device='cuda:0') norm:  tensor(53.8973, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(47.0898, device='cuda:0') mean:  tensor(0.0727, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(167.7108, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0243, device='cuda:0')
min of d_p_list:  tensor(-0.0187, device='cuda:0')
Epoch:  706  
Training Loss: 1081319.25
Test Loss:  735986.75
Test Acc:  0.0
Valid Loss:  873896.25
Valid Acc:  0.0
std:  15622.423265934129 
thres:  1103.285
Preserved_eigens number check:  62
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  46
 71%|███████   | 706/1000 [45:08<18:50,  3.84s/it]Epoch:   707
max of grad d_p:  tensor(761511.6250, device='cuda:0')
min of grad d_p:  tensor(-54198.2578, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.4102, device='cuda:0') mean:  tensor(-0.0004, device='cuda:0') min:  tensor(-6.3984, device='cuda:0') norm:  tensor(47.1878, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(199.3301, device='cuda:0') mean:  tensor(0.4527, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1045.5289, device='cuda:0') MSE:  tensor(0.0039, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0211, device='cuda:0')
min of d_p_list:  tensor(-0.0215, device='cuda:0')
Epoch:  707  
Training Loss: 1070533.625
Test Loss:  728731.125
Test Acc:  0.0
Valid Loss:  865148.875
Valid Acc:  0.0
std:  15461.58227381661 
thres:  1092.292075
Preserved_eigens number check:  46
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  38
 71%|███████   | 707/1000 [45:12<18:49,  3.85s/it]Epoch:   708
max of grad d_p:  tensor(759410.0625, device='cuda:0')
min of grad d_p:  tensor(-53660.4648, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.8125, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(-7.6055, device='cuda:0') norm:  tensor(57.4113, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(28.2383, device='cuda:0') mean:  tensor(0.0493, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(118.0192, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0398, device='cuda:0')
min of d_p_list:  tensor(-0.0685, device='cuda:0')
Epoch:  708  
Training Loss: 1060060.0
Test Loss:  721570.9375
Test Acc:  0.0
Valid Loss:  856651.6875
Valid Acc:  0.0
std:  15250.101719414857 
thres:  1081.448225
Preserved_eigens number check:  38
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  87
 71%|███████   | 708/1000 [45:16<19:09,  3.94s/it]Epoch:   709
max of grad d_p:  tensor(758437.1250, device='cuda:0')
min of grad d_p:  tensor(-53206.2344, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.7500, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(-6.4453, device='cuda:0') norm:  tensor(48.1140, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(12.1641, device='cuda:0') mean:  tensor(0.0303, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(83.5317, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0503, device='cuda:0')
min of d_p_list:  tensor(-0.0408, device='cuda:0')
Epoch:  709  
Training Loss: 1049568.375
Test Loss:  714467.5625
Test Acc:  0.0
Valid Loss:  847905.625
Valid Acc:  0.0
std:  15057.3228349614 
thres:  1070.73075
Preserved_eigens number check:  87
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  58
 71%|███████   | 709/1000 [45:20<18:57,  3.91s/it]Epoch:   710
max of grad d_p:  tensor(751881.0625, device='cuda:0')
min of grad d_p:  tensor(-52642.7969, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.8408, device='cuda:0') mean:  tensor(-0.0001, device='cuda:0') min:  tensor(-7.6602, device='cuda:0') norm:  tensor(50.6105, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(31.9062, device='cuda:0') mean:  tensor(0.0668, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(151.8139, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1982, device='cuda:0')
min of d_p_list:  tensor(-0.1302, device='cuda:0')
Epoch:  710  
Training Loss: 1040588.25
Test Loss:  708167.5625
Test Acc:  0.0
Valid Loss:  840371.125
Valid Acc:  0.0
std:  14493.098691144347 
thres:  1060.4139
Preserved_eigens number check:  58
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  52
 71%|███████   | 710/1000 [45:23<18:49,  3.90s/it]Epoch:   711
max of grad d_p:  tensor(740048.0625, device='cuda:0')
min of grad d_p:  tensor(-52063.1836, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.1562, device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(-7.1211, device='cuda:0') norm:  tensor(56.5001, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(227.2852, device='cuda:0') mean:  tensor(0.5995, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1313.4180, device='cuda:0') MSE:  tensor(0.0049, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0338, device='cuda:0')
min of d_p_list:  tensor(-0.0286, device='cuda:0')
Epoch:  711  
Training Loss: 1030273.4375
Test Loss:  701190.375
Test Acc:  0.0
Valid Loss:  832067.0
Valid Acc:  0.0
std:  14145.871303603924 
thres:  1050.2047375
Preserved_eigens number check:  52
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  115
 71%|███████   | 711/1000 [45:28<19:00,  3.95s/it]Epoch:   712
max of grad d_p:  tensor(736140.7500, device='cuda:0')
min of grad d_p:  tensor(-51465.7070, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.4062, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(-7.8047, device='cuda:0') norm:  tensor(58.1598, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(59.1875, device='cuda:0') mean:  tensor(0.1500, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(339.7206, device='cuda:0') MSE:  tensor(0.0013, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0160, device='cuda:0')
min of d_p_list:  tensor(-0.0187, device='cuda:0')
Epoch:  712  
Training Loss: 1020027.875
Test Loss:  694134.5625
Test Acc:  0.0
Valid Loss:  823760.5625
Valid Acc:  0.0
std:  14055.188233775989 
thres:  1040.1035875
Preserved_eigens number check:  115
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  39
 71%|███████   | 712/1000 [45:31<18:51,  3.93s/it]Epoch:   713
max of grad d_p:  tensor(732775., device='cuda:0')
min of grad d_p:  tensor(-50989.3789, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.5000, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-6.8555, device='cuda:0') norm:  tensor(50.0092, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(48.3018, device='cuda:0') mean:  tensor(0.0881, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(192.8692, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2126, device='cuda:0')
min of d_p_list:  tensor(-0.2420, device='cuda:0')
Epoch:  713  
Training Loss: 1012069.75
Test Loss:  688476.75
Test Acc:  0.0
Valid Loss:  817015.25
Valid Acc:  0.0
std:  13526.022383007688 
thres:  1030.5055375
Preserved_eigens number check:  39
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  86
 71%|███████▏  | 713/1000 [45:35<18:43,  3.92s/it]Epoch:   714
max of grad d_p:  tensor(731637.6250, device='cuda:0')
min of grad d_p:  tensor(-50838.4023, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.1641, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-7.4023, device='cuda:0') norm:  tensor(55.0517, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(93.7617, device='cuda:0') mean:  tensor(0.1796, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(381.9129, device='cuda:0') MSE:  tensor(0.0014, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0100, device='cuda:0')
min of d_p_list:  tensor(-0.0134, device='cuda:0')
Epoch:  714  
Training Loss: 1001988.375
Test Loss:  681562.875
Test Acc:  0.0
Valid Loss:  808859.3125
Valid Acc:  0.0
std:  13504.309764131782 
thres:  1020.9895375
Preserved_eigens number check:  86
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  44
 71%|███████▏  | 714/1000 [45:39<18:40,  3.92s/it]Epoch:   715
max of grad d_p:  tensor(728433.0625, device='cuda:0')
min of grad d_p:  tensor(-50338.8320, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.3828, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-6.6992, device='cuda:0') norm:  tensor(46.4596, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(84.9824, device='cuda:0') mean:  tensor(0.1582, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(376.5630, device='cuda:0') MSE:  tensor(0.0014, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0221, device='cuda:0')
min of d_p_list:  tensor(-0.0328, device='cuda:0')
Epoch:  715  
Training Loss: 992012.0
Test Loss:  674837.25
Test Acc:  0.0
Valid Loss:  800838.25
Valid Acc:  0.0
std:  13382.747446782929 
thres:  1011.2742875
Preserved_eigens number check:  44
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 72%|███████▏  | 715/1000 [45:43<18:37,  3.92s/it]Epoch:   716
max of grad d_p:  tensor(725464.8750, device='cuda:0')
min of grad d_p:  tensor(-49862.2188, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.9062, device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(-7.1875, device='cuda:0') norm:  tensor(55.0872, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(78.3000, device='cuda:0') mean:  tensor(0.2123, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(481.1628, device='cuda:0') MSE:  tensor(0.0018, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0604, device='cuda:0')
min of d_p_list:  tensor(-0.0271, device='cuda:0')
Epoch:  716  
Training Loss: 982262.5
Test Loss:  668297.9375
Test Acc:  0.0
Valid Loss:  792990.0
Valid Acc:  0.0
std:  13529.19609894653 
thres:  1001.6721
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  37
 72%|███████▏  | 716/1000 [45:47<18:15,  3.86s/it]Epoch:   717
max of grad d_p:  tensor(725955.0625, device='cuda:0')
min of grad d_p:  tensor(-49631.9922, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12., device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-7.5820, device='cuda:0') norm:  tensor(58.8273, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(314.2285, device='cuda:0') mean:  tensor(0.6274, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1439.1013, device='cuda:0') MSE:  tensor(0.0054, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.3498, device='cuda:0')
min of d_p_list:  tensor(-0.4350, device='cuda:0')
Epoch:  717  
Training Loss: 988197.125
Test Loss:  671774.8125
Test Acc:  0.0
Valid Loss:  796609.5
Valid Acc:  0.0
std:  10556.485037229484 
thres:  995.3059499999999
Preserved_eigens number check:  37
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  87
 72%|███████▏  | 717/1000 [45:51<18:15,  3.87s/it]Epoch:   718
max of grad d_p:  tensor(716108.6875, device='cuda:0')
min of grad d_p:  tensor(-49423.9688, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.6172, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-5.5508, device='cuda:0') norm:  tensor(46.9006, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(76.7500, device='cuda:0') mean:  tensor(0.1763, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(405.8623, device='cuda:0') MSE:  tensor(0.0015, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1300, device='cuda:0')
min of d_p_list:  tensor(-0.1542, device='cuda:0')
Epoch:  718  
Training Loss: 978611.875
Test Loss:  665486.125
Test Acc:  0.0
Valid Loss:  788389.5
Valid Acc:  0.0
std:  8136.069708019346 
thres:  988.614375
Preserved_eigens number check:  87
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  90
 72%|███████▏  | 718/1000 [45:55<18:00,  3.83s/it]Epoch:   719
max of grad d_p:  tensor(699626.1250, device='cuda:0')
min of grad d_p:  tensor(-48686.7891, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.8438, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(-6.8633, device='cuda:0') norm:  tensor(56.0477, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(268.6523, device='cuda:0') mean:  tensor(0.5711, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1361.8838, device='cuda:0') MSE:  tensor(0.0051, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0937, device='cuda:0')
min of d_p_list:  tensor(-0.0528, device='cuda:0')
Epoch:  719  
Training Loss: 968910.625
Test Loss:  659064.875
Test Acc:  0.0
Valid Loss:  780669.4375
Valid Acc:  0.0
std:  8019.033988190224 
thres:  981.998825
Preserved_eigens number check:  90
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  46
 72%|███████▏  | 719/1000 [45:59<18:19,  3.91s/it]Epoch:   720
max of grad d_p:  tensor(699696.1250, device='cuda:0')
min of grad d_p:  tensor(-47878.1836, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.7188, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(-5.4336, device='cuda:0') norm:  tensor(50.2976, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(22.9629, device='cuda:0') mean:  tensor(0.0381, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(87.3671, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0334, device='cuda:0')
min of d_p_list:  tensor(-0.0223, device='cuda:0')
Epoch:  720  
Training Loss: 959312.9375
Test Loss:  652513.125
Test Acc:  0.0
Valid Loss:  772963.3125
Valid Acc:  0.0
std:  10218.264147349098 
thres:  975.4590125
Preserved_eigens number check:  46
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  44
 72%|███████▏  | 720/1000 [46:02<18:06,  3.88s/it]Epoch:   721
max of grad d_p:  tensor(696862.6250, device='cuda:0')
min of grad d_p:  tensor(-47303.6797, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.0625, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-5.5977, device='cuda:0') norm:  tensor(56.7928, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(217.9004, device='cuda:0') mean:  tensor(0.5571, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1272.8541, device='cuda:0') MSE:  tensor(0.0048, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0088, device='cuda:0')
min of d_p_list:  tensor(-0.0088, device='cuda:0')
Epoch:  721  
Training Loss: 949758.3125
Test Loss:  645978.25
Test Acc:  0.0
Valid Loss:  765270.0625
Valid Acc:  0.0
std:  13601.461011562784 
thres:  968.9581750000001
Preserved_eigens number check:  44
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 72%|███████▏  | 721/1000 [46:06<17:57,  3.86s/it]Epoch:   722
max of grad d_p:  tensor(693032.1250, device='cuda:0')
min of grad d_p:  tensor(-46852.9453, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.8828, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-6.6094, device='cuda:0') norm:  tensor(50.2355, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(45.8848, device='cuda:0') mean:  tensor(0.0663, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(154.1705, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0127, device='cuda:0')
min of d_p_list:  tensor(-0.0183, device='cuda:0')
Epoch:  722  
Training Loss: 940308.5
Test Loss:  639552.625
Test Acc:  0.0
Valid Loss:  757670.1875
Valid Acc:  0.0
std:  13542.53527128737 
thres:  959.38045
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 72%|███████▏  | 722/1000 [46:10<18:00,  3.89s/it]Epoch:   723
max of grad d_p:  tensor(689997.8750, device='cuda:0')
min of grad d_p:  tensor(-46361.1797, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.8438, device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(-5.9961, device='cuda:0') norm:  tensor(57.2572, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(63.6387, device='cuda:0') mean:  tensor(0.1152, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(279.6972, device='cuda:0') MSE:  tensor(0.0010, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0248, device='cuda:0')
min of d_p_list:  tensor(-0.0372, device='cuda:0')
Epoch:  723  
Training Loss: 930978.875
Test Loss:  633260.4375
Test Acc:  0.0
Valid Loss:  750244.875
Valid Acc:  0.0
std:  13416.575755536973 
thres:  949.85385
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  58
 72%|███████▏  | 723/1000 [46:14<18:06,  3.92s/it]Epoch:   724
max of grad d_p:  tensor(688693., device='cuda:0')
min of grad d_p:  tensor(-45851.7852, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12., device='cuda:0') mean:  tensor(0.0030, device='cuda:0') min:  tensor(-5.6602, device='cuda:0') norm:  tensor(61.8827, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(26.4365, device='cuda:0') mean:  tensor(0.0653, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(141.5557, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0537, device='cuda:0')
min of d_p_list:  tensor(-0.0880, device='cuda:0')
Epoch:  724  
Training Loss: 922025.0
Test Loss:  627320.625
Test Acc:  0.0
Valid Loss:  742951.8125
Valid Acc:  0.0
std:  13203.441805938803 
thres:  940.476725
Preserved_eigens number check:  58
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 72%|███████▏  | 724/1000 [46:18<17:45,  3.86s/it]Epoch:   725
max of grad d_p:  tensor(683593.5000, device='cuda:0')
min of grad d_p:  tensor(-45314.4180, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.8750, device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(-7.0898, device='cuda:0') norm:  tensor(61.8201, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(50.8477, device='cuda:0') mean:  tensor(0.1645, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(350.0154, device='cuda:0') MSE:  tensor(0.0013, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1817, device='cuda:0')
min of d_p_list:  tensor(-0.1059, device='cuda:0')
Epoch:  725  
Training Loss: 914157.875
Test Loss:  621736.5625
Test Acc:  0.0
Valid Loss:  736370.1875
Valid Acc:  0.0
std:  12662.838605270344 
thres:  931.4457125
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 72%|███████▎  | 725/1000 [46:22<17:22,  3.79s/it]Epoch:   726
max of grad d_p:  tensor(685010.5625, device='cuda:0')
min of grad d_p:  tensor(-44701.8203, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.5469, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-5.6719, device='cuda:0') norm:  tensor(46.5798, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(59.5986, device='cuda:0') mean:  tensor(0.0650, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(172.2396, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0528, device='cuda:0')
min of d_p_list:  tensor(-0.0738, device='cuda:0')
Epoch:  726  
Training Loss: 905338.375
Test Loss:  616074.375
Test Acc:  0.0
Valid Loss:  729412.1875
Valid Acc:  0.0
std:  12274.795238974457 
thres:  922.561725
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  31
 73%|███████▎  | 726/1000 [46:25<17:16,  3.78s/it]Epoch:   727
max of grad d_p:  tensor(682594.7500, device='cuda:0')
min of grad d_p:  tensor(-43888.9688, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.0938, device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(-5.4082, device='cuda:0') norm:  tensor(54.3474, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(36.7422, device='cuda:0') mean:  tensor(0.0713, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(158.2901, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0142, device='cuda:0')
min of d_p_list:  tensor(-0.0267, device='cuda:0')
Epoch:  727  
Training Loss: 896325.8125
Test Loss:  609941.375
Test Acc:  0.0
Valid Loss:  722222.875
Valid Acc:  0.0
std:  12164.149889377803 
thres:  913.7651875
Preserved_eigens number check:  31
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 73%|███████▎  | 727/1000 [46:29<17:36,  3.87s/it]Epoch:   728
max of grad d_p:  tensor(679072.8125, device='cuda:0')
min of grad d_p:  tensor(-43482.1680, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.5000, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-5.7344, device='cuda:0') norm:  tensor(57.9579, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(28.3486, device='cuda:0') mean:  tensor(0.0437, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(111.9034, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0121, device='cuda:0')
min of d_p_list:  tensor(-0.0119, device='cuda:0')
Epoch:  728  
Training Loss: 887416.9375
Test Loss:  603926.0
Test Acc:  0.0
Valid Loss:  715022.3125
Valid Acc:  0.0
std:  12314.410043687132 
thres:  905.0528
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  50
 73%|███████▎  | 728/1000 [46:33<17:30,  3.86s/it]Epoch:   729
max of grad d_p:  tensor(674622., device='cuda:0')
min of grad d_p:  tensor(-43052.0312, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.1250, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(-5.8535, device='cuda:0') norm:  tensor(52.5747, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(102.4570, device='cuda:0') mean:  tensor(0.2728, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(621.0059, device='cuda:0') MSE:  tensor(0.0023, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.8785, device='cuda:0')
min of d_p_list:  tensor(-0.8728, device='cuda:0')
Epoch:  729  
Training Loss: 962975.8125
Test Loss:  659656.875
Test Acc:  0.0
Valid Loss:  779792.125
Valid Acc:  0.0
std:  26419.119852763593 
thres:  913.2429625000001
Preserved_eigens number check:  50
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  36
 73%|███████▎  | 729/1000 [46:37<17:28,  3.87s/it]Epoch:   730
max of grad d_p:  tensor(689587.5625, device='cuda:0')
min of grad d_p:  tensor(-46744.0703, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.5312, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-5.2598, device='cuda:0') norm:  tensor(54.8546, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(85.0918, device='cuda:0') mean:  tensor(0.1548, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(367.0181, device='cuda:0') MSE:  tensor(0.0014, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(1.0369, device='cuda:0')
min of d_p_list:  tensor(-0.8956, device='cuda:0')
Epoch:  730  
Training Loss: 1006465.0
Test Loss:  696470.25
Test Acc:  0.0
Valid Loss:  816968.4375
Valid Acc:  0.0
std:  45771.693467882666 
thres:  931.7043874999999
Preserved_eigens number check:  36
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 73%|███████▎  | 730/1000 [46:41<17:14,  3.83s/it]Epoch:   731
max of grad d_p:  tensor(679116.5000, device='cuda:0')
min of grad d_p:  tensor(-48710.8672, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(16.1250, device='cuda:0') mean:  tensor(0.0035, device='cuda:0') min:  tensor(-4.7266, device='cuda:0') norm:  tensor(64.8575, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(18.4238, device='cuda:0') mean:  tensor(0.0483, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(112.6574, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2395, device='cuda:0')
min of d_p_list:  tensor(-0.2098, device='cuda:0')
Epoch:  731  
Training Loss: 997807.4375
Test Loss:  690958.625
Test Acc:  0.0
Valid Loss:  810847.3125
Valid Acc:  0.0
std:  49879.015056064665 
thres:  950.1981999999999
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  127
 73%|███████▎  | 731/1000 [46:45<17:24,  3.88s/it]Epoch:   732
max of grad d_p:  tensor(699956.4375, device='cuda:0')
min of grad d_p:  tensor(-45690., device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(16.2500, device='cuda:0') mean:  tensor(0.0037, device='cuda:0') min:  tensor(-5.5020, device='cuda:0') norm:  tensor(65.7954, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(45.7422, device='cuda:0') mean:  tensor(0.0951, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(232.8861, device='cuda:0') MSE:  tensor(0.0009, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0244, device='cuda:0')
min of d_p_list:  tensor(-0.0184, device='cuda:0')
Epoch:  732  
Training Loss: 987909.0
Test Loss:  684098.0
Test Acc:  0.0
Valid Loss:  802838.25
Valid Acc:  0.0
std:  43085.85607823857 
thres:  968.5148375
Preserved_eigens number check:  127
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  58
 73%|███████▎  | 732/1000 [46:49<17:24,  3.90s/it]Epoch:   733
max of grad d_p:  tensor(695191.8750, device='cuda:0')
min of grad d_p:  tensor(-45408.1641, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.5605, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-5., device='cuda:0') norm:  tensor(47.1014, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(32.0781, device='cuda:0') mean:  tensor(0.0546, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(128.7102, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1545, device='cuda:0')
min of d_p_list:  tensor(-0.1521, device='cuda:0')
Epoch:  733  
Training Loss: 979387.3125
Test Loss:  677483.375
Test Acc:  0.0
Valid Loss:  795797.6875
Valid Acc:  0.0
std:  15043.844739034885 
thres:  986.9089125
Preserved_eigens number check:  58
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  33
 73%|███████▎  | 733/1000 [46:52<16:47,  3.77s/it]Epoch:   734
max of grad d_p:  tensor(676791.4375, device='cuda:0')
min of grad d_p:  tensor(-45274.4297, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.8721, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(-5.3047, device='cuda:0') norm:  tensor(50.7518, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(23.3408, device='cuda:0') mean:  tensor(0.0481, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(108.6801, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0375, device='cuda:0')
min of d_p_list:  tensor(-0.0193, device='cuda:0')
Epoch:  734  
Training Loss: 969693.625
Test Loss:  670721.625
Test Acc:  0.0
Valid Loss:  787768.75
Valid Acc:  0.0
std:  13008.715307835455 
thres:  988.252475
Preserved_eigens number check:  33
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  38
 73%|███████▎  | 734/1000 [46:56<16:46,  3.78s/it]Epoch:   735
max of grad d_p:  tensor(672559.6250, device='cuda:0')
min of grad d_p:  tensor(-44929.7070, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.5000, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-5.0195, device='cuda:0') norm:  tensor(52.5788, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(110.0078, device='cuda:0') mean:  tensor(0.2341, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(521.3690, device='cuda:0') MSE:  tensor(0.0020, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0122, device='cuda:0')
min of d_p_list:  tensor(-0.0160, device='cuda:0')
Epoch:  735  
Training Loss: 960036.0
Test Loss:  664026.9375
Test Acc:  0.0
Valid Loss:  779876.625
Valid Acc:  0.0
std:  13262.551460043896 
thres:  978.9666750000001
Preserved_eigens number check:  38
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 74%|███████▎  | 735/1000 [47:00<17:06,  3.87s/it]Epoch:   736
max of grad d_p:  tensor(668079.2500, device='cuda:0')
min of grad d_p:  tensor(-44748.4609, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.3750, device='cuda:0') mean:  tensor(0.0026, device='cuda:0') min:  tensor(-5.2695, device='cuda:0') norm:  tensor(55.2452, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(32.0234, device='cuda:0') mean:  tensor(0.0341, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(91.2035, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0526, device='cuda:0')
min of d_p_list:  tensor(-0.0964, device='cuda:0')
Epoch:  736  
Training Loss: 950788.625
Test Loss:  658101.8125
Test Acc:  0.0
Valid Loss:  772378.5
Valid Acc:  0.0
std:  13238.963559060241 
thres:  969.5629125
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  33
 74%|███████▎  | 736/1000 [47:04<16:59,  3.86s/it]Epoch:   737
max of grad d_p:  tensor(660329.6250, device='cuda:0')
min of grad d_p:  tensor(-44790.8086, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.5625, device='cuda:0') mean:  tensor(0.0020, device='cuda:0') min:  tensor(-4.4766, device='cuda:0') norm:  tensor(49.7741, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(77.3105, device='cuda:0') mean:  tensor(0.1264, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(313.7732, device='cuda:0') MSE:  tensor(0.0012, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0315, device='cuda:0')
min of d_p_list:  tensor(-0.0389, device='cuda:0')
Epoch:  737  
Training Loss: 941415.125
Test Loss:  651663.9375
Test Acc:  0.0
Valid Loss:  764894.625
Valid Acc:  0.0
std:  13414.42292963063 
thres:  960.2641375
Preserved_eigens number check:  33
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  33
 74%|███████▎  | 737/1000 [47:08<16:53,  3.85s/it]Epoch:   738
max of grad d_p:  tensor(652553.9375, device='cuda:0')
min of grad d_p:  tensor(-44655.7969, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9., device='cuda:0') mean:  tensor(0.0024, device='cuda:0') min:  tensor(-4.3652, device='cuda:0') norm:  tensor(52.3192, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(77.9062, device='cuda:0') mean:  tensor(0.1101, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(298.5145, device='cuda:0') MSE:  tensor(0.0011, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0071, device='cuda:0')
min of d_p_list:  tensor(-0.0113, device='cuda:0')
Epoch:  738  
Training Loss: 932035.0625
Test Loss:  645157.6875
Test Acc:  0.0
Valid Loss:  757338.375
Valid Acc:  0.0
std:  13285.11535469301 
thres:  950.7936875
Preserved_eigens number check:  33
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 74%|███████▍  | 738/1000 [47:12<17:01,  3.90s/it]Epoch:   739
max of grad d_p:  tensor(648430.1250, device='cuda:0')
min of grad d_p:  tensor(-44399.9453, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.4375, device='cuda:0') mean:  tensor(0.0028, device='cuda:0') min:  tensor(-4.5820, device='cuda:0') norm:  tensor(53.7245, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(55.3496, device='cuda:0') mean:  tensor(0.0932, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(247.4663, device='cuda:0') MSE:  tensor(0.0009, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.5768, device='cuda:0')
min of d_p_list:  tensor(-0.2301, device='cuda:0')
Epoch:  739  
Training Loss: 928913.1875
Test Loss:  643506.0
Test Acc:  0.0
Valid Loss:  755456.9375
Valid Acc:  0.0
std:  11588.022058533652 
thres:  942.6376
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  61
 74%|███████▍  | 739/1000 [47:16<16:57,  3.90s/it]Epoch:   740
max of grad d_p:  tensor(641815.3750, device='cuda:0')
min of grad d_p:  tensor(-44706.6836, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.8125, device='cuda:0') mean:  tensor(0.0031, device='cuda:0') min:  tensor(-4.2090, device='cuda:0') norm:  tensor(55.9561, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(71.2319, device='cuda:0') mean:  tensor(0.1184, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(305.9782, device='cuda:0') MSE:  tensor(0.0011, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0291, device='cuda:0')
min of d_p_list:  tensor(-0.0272, device='cuda:0')
Epoch:  740  
Training Loss: 919732.875
Test Loss:  637095.9375
Test Acc:  0.0
Valid Loss:  747904.75
Valid Acc:  0.0
std:  10662.692004909572 
thres:  934.576975
Preserved_eigens number check:  61
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  104
 74%|███████▍  | 740/1000 [47:19<16:40,  3.85s/it]Epoch:   741
max of grad d_p:  tensor(639404.6250, device='cuda:0')
min of grad d_p:  tensor(-44421.1758, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.7695, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-4.5273, device='cuda:0') norm:  tensor(50.6964, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(128.5234, device='cuda:0') mean:  tensor(0.2010, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(525.4556, device='cuda:0') MSE:  tensor(0.0020, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0131, device='cuda:0')
min of d_p_list:  tensor(-0.0141, device='cuda:0')
Epoch:  741  
Training Loss: 910580.3125
Test Loss:  630755.8125
Test Acc:  0.0
Valid Loss:  740573.625
Valid Acc:  0.0
std:  10565.467718512868 
thres:  926.5353125
Preserved_eigens number check:  104
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  47
 74%|███████▍  | 741/1000 [47:23<16:45,  3.88s/it]Epoch:   742
max of grad d_p:  tensor(635439.6250, device='cuda:0')
min of grad d_p:  tensor(-44235.7812, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.6631, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-4.6777, device='cuda:0') norm:  tensor(44.7826, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(98.4985, device='cuda:0') mean:  tensor(0.2707, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(652.7654, device='cuda:0') MSE:  tensor(0.0025, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0440, device='cuda:0')
min of d_p_list:  tensor(-0.0381, device='cuda:0')
Epoch:  742  
Training Loss: 901553.9375
Test Loss:  624550.625
Test Acc:  0.0
Valid Loss:  733267.3125
Valid Acc:  0.0
std:  11340.39649772551 
thres:  918.563075
Preserved_eigens number check:  47
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  264
 74%|███████▍  | 742/1000 [47:28<17:00,  3.95s/it]Epoch:   743
max of grad d_p:  tensor(631651.6250, device='cuda:0')
min of grad d_p:  tensor(-43931.1562, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.8125, device='cuda:0') mean:  tensor(0.0029, device='cuda:0') min:  tensor(-4.4160, device='cuda:0') norm:  tensor(55.3481, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(94.3428, device='cuda:0') mean:  tensor(0.1685, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(421.9282, device='cuda:0') MSE:  tensor(0.0016, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0466, device='cuda:0')
min of d_p_list:  tensor(-0.0743, device='cuda:0')
Epoch:  743  
Training Loss: 891897.75
Test Loss:  620054.0625
Test Acc:  0.0
Valid Loss:  725922.0
Valid Acc:  0.0
std:  13041.221590319386 
thres:  910.5356125000001
Preserved_eigens number check:  264
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  38
 74%|███████▍  | 743/1000 [47:31<16:37,  3.88s/it]Epoch:   744
max of grad d_p:  tensor(626441., device='cuda:0')
min of grad d_p:  tensor(-43430.1719, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.7500, device='cuda:0') mean:  tensor(0.0027, device='cuda:0') min:  tensor(-3.7773, device='cuda:0') norm:  tensor(48.8084, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(14.0195, device='cuda:0') mean:  tensor(0.0353, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(77.9646, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0286, device='cuda:0')
min of d_p_list:  tensor(-0.0163, device='cuda:0')
Epoch:  744  
Training Loss: 883041.0
Test Loss:  613808.4375
Test Acc:  0.0
Valid Loss:  718561.75
Valid Acc:  0.0
std:  13021.015623034653 
thres:  901.3611750000001
Preserved_eigens number check:  38
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 74%|███████▍  | 744/1000 [47:35<16:31,  3.87s/it]Epoch:   745
max of grad d_p:  tensor(623684.1250, device='cuda:0')
min of grad d_p:  tensor(-43083.7500, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.5625, device='cuda:0') mean:  tensor(0.0028, device='cuda:0') min:  tensor(-4.5859, device='cuda:0') norm:  tensor(53.8648, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(71.5625, device='cuda:0') mean:  tensor(0.1529, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(352.9379, device='cuda:0') MSE:  tensor(0.0013, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0246, device='cuda:0')
min of d_p_list:  tensor(-0.0414, device='cuda:0')
Epoch:  745  
Training Loss: 874311.5
Test Loss:  607688.125
Test Acc:  0.0
Valid Loss:  711504.5
Valid Acc:  0.0
std:  12878.50561683352 
thres:  892.2769000000001
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  49
 74%|███████▍  | 745/1000 [47:39<16:32,  3.89s/it]Epoch:   746
max of grad d_p:  tensor(619128.8125, device='cuda:0')
min of grad d_p:  tensor(-42744.5859, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(13.0625, device='cuda:0') mean:  tensor(0.0036, device='cuda:0') min:  tensor(-4.0156, device='cuda:0') norm:  tensor(55.9440, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(26.9922, device='cuda:0') mean:  tensor(0.0308, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(78.8837, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0258, device='cuda:0')
min of d_p_list:  tensor(-0.0189, device='cuda:0')
Epoch:  746  
Training Loss: 865631.75
Test Loss:  601623.6875
Test Acc:  0.0
Valid Loss:  704412.0
Valid Acc:  0.0
std:  12650.327978579251 
thres:  883.2871875000001
Preserved_eigens number check:  49
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  50
 75%|███████▍  | 746/1000 [47:43<16:27,  3.89s/it]Epoch:   747
max of grad d_p:  tensor(614988.5000, device='cuda:0')
min of grad d_p:  tensor(-42701.3711, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.6406, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(-5.1328, device='cuda:0') norm:  tensor(48.0570, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(26.7266, device='cuda:0') mean:  tensor(0.0759, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(171.7611, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0677, device='cuda:0')
min of d_p_list:  tensor(-0.0344, device='cuda:0')
Epoch:  747  
Training Loss: 857171.375
Test Loss:  595713.625
Test Acc:  0.0
Valid Loss:  697092.25
Valid Acc:  0.0
std:  12284.568580031615 
thres:  874.4106750000001
Preserved_eigens number check:  50
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 75%|███████▍  | 747/1000 [47:47<16:26,  3.90s/it]Epoch:   748
max of grad d_p:  tensor(611889.2500, device='cuda:0')
min of grad d_p:  tensor(-42670.4727, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.7500, device='cuda:0') mean:  tensor(0.0030, device='cuda:0') min:  tensor(-3.8193, device='cuda:0') norm:  tensor(49.7561, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(30.5625, device='cuda:0') mean:  tensor(0.0472, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(124.9862, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0149, device='cuda:0')
min of d_p_list:  tensor(-0.0256, device='cuda:0')
Epoch:  748  
Training Loss: 848642.625
Test Loss:  589676.375
Test Acc:  0.0
Valid Loss:  690243.5
Valid Acc:  0.0
std:  12153.57204266507 
thres:  865.7596500000001
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  60
 75%|███████▍  | 748/1000 [47:51<16:26,  3.91s/it]Epoch:   749
max of grad d_p:  tensor(607489.8125, device='cuda:0')
min of grad d_p:  tensor(-42434.6250, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.2500, device='cuda:0') mean:  tensor(0.0030, device='cuda:0') min:  tensor(-4.1631, device='cuda:0') norm:  tensor(55.6264, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(46.8125, device='cuda:0') mean:  tensor(0.0723, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(181.8650, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0323, device='cuda:0')
min of d_p_list:  tensor(-0.0399, device='cuda:0')
Epoch:  749  
Training Loss: 840240.6875
Test Loss:  583726.75
Test Acc:  0.0
Valid Loss:  683400.875
Valid Acc:  0.0
std:  12039.481768046538 
thres:  857.1995875
Preserved_eigens number check:  60
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  107
 75%|███████▍  | 749/1000 [47:55<16:24,  3.92s/it]Epoch:   750
max of grad d_p:  tensor(600989.9375, device='cuda:0')
min of grad d_p:  tensor(-42344.9062, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.8125, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-4.7891, device='cuda:0') norm:  tensor(47.2334, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1353.6094, device='cuda:0') mean:  tensor(1.7027, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(4304.2378, device='cuda:0') MSE:  tensor(0.0162, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0571, device='cuda:0')
min of d_p_list:  tensor(-0.0292, device='cuda:0')
Epoch:  750  
Training Loss: 832009.375
Test Loss:  578282.875
Test Acc:  0.0
Valid Loss:  676491.4375
Valid Acc:  0.0
std:  11904.460564847112 
thres:  848.7391625
Preserved_eigens number check:  107
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  111
 75%|███████▌  | 750/1000 [47:59<16:13,  3.90s/it]Epoch:   751
max of grad d_p:  tensor(601386., device='cuda:0')
min of grad d_p:  tensor(-42041.8555, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.4375, device='cuda:0') mean:  tensor(0.0025, device='cuda:0') min:  tensor(-4.4189, device='cuda:0') norm:  tensor(51.8859, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(132.2578, device='cuda:0') mean:  tensor(0.2370, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(632.9321, device='cuda:0') MSE:  tensor(0.0024, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0152, device='cuda:0')
min of d_p_list:  tensor(-0.0106, device='cuda:0')
Epoch:  751  
Training Loss: 823713.875
Test Loss:  572533.5
Test Acc:  0.0
Valid Loss:  669828.125
Valid Acc:  0.0
std:  11815.792481330865 
thres:  840.3555875000001
Preserved_eigens number check:  111
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  37
 75%|███████▌  | 751/1000 [48:02<16:05,  3.88s/it]Epoch:   752
max of grad d_p:  tensor(598955.5000, device='cuda:0')
min of grad d_p:  tensor(-41784.9180, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7., device='cuda:0') mean:  tensor(0.0027, device='cuda:0') min:  tensor(-3.9590, device='cuda:0') norm:  tensor(49.1808, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(70.7773, device='cuda:0') mean:  tensor(0.0793, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(206.3314, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0124, device='cuda:0')
min of d_p_list:  tensor(-0.0119, device='cuda:0')
Epoch:  752  
Training Loss: 815516.25
Test Loss:  566804.625
Test Acc:  0.0
Valid Loss:  663103.75
Valid Acc:  0.0
std:  11706.89412483089 
thres:  832.0245625
Preserved_eigens number check:  37
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 75%|███████▌  | 752/1000 [48:06<16:04,  3.89s/it]Epoch:   753
max of grad d_p:  tensor(594968.6250, device='cuda:0')
min of grad d_p:  tensor(-41629.4531, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.1523, device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(-4.2539, device='cuda:0') norm:  tensor(50.1183, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(21.6211, device='cuda:0') mean:  tensor(0.0604, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(137.2938, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0253, device='cuda:0')
min of d_p_list:  tensor(-0.0247, device='cuda:0')
Epoch:  753  
Training Loss: 807423.3125
Test Loss:  561204.375
Test Acc:  0.0
Valid Loss:  656574.125
Valid Acc:  0.0
std:  11614.749295306056 
thres:  823.7807
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  40
 75%|███████▌  | 753/1000 [48:10<16:00,  3.89s/it]Epoch:   754
max of grad d_p:  tensor(591824.5625, device='cuda:0')
min of grad d_p:  tensor(-41562.3672, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.0781, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(-3.9736, device='cuda:0') norm:  tensor(42.7909, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(31.2500, device='cuda:0') mean:  tensor(0.0640, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(147.0262, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1134, device='cuda:0')
min of d_p_list:  tensor(-0.0575, device='cuda:0')
Epoch:  754  
Training Loss: 799736.125
Test Loss:  555475.125
Test Acc:  0.0
Valid Loss:  649687.8125
Valid Acc:  0.0
std:  11433.27151546092 
thres:  815.6797875
Preserved_eigens number check:  40
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 75%|███████▌  | 754/1000 [48:14<16:01,  3.91s/it]Epoch:   755
max of grad d_p:  tensor(587817.9375, device='cuda:0')
min of grad d_p:  tensor(-41146.1484, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.2500, device='cuda:0') mean:  tensor(0.0024, device='cuda:0') min:  tensor(-4.5195, device='cuda:0') norm:  tensor(49.7999, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(212.8809, device='cuda:0') mean:  tensor(0.4996, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1151.0916, device='cuda:0') MSE:  tensor(0.0043, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0747, device='cuda:0')
min of d_p_list:  tensor(-0.1641, device='cuda:0')
Epoch:  755  
Training Loss: 791895.0
Test Loss:  550234.0
Test Acc:  0.0
Valid Loss:  643602.375
Valid Acc:  0.0
std:  11232.333327524828 
thres:  807.6569125
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 76%|███████▌  | 755/1000 [48:18<15:51,  3.88s/it]Epoch:   756
max of grad d_p:  tensor(582440., device='cuda:0')
min of grad d_p:  tensor(-40382.8125, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.1992, device='cuda:0') mean:  tensor(0.0024, device='cuda:0') min:  tensor(-4.5918, device='cuda:0') norm:  tensor(51.8614, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(26.1885, device='cuda:0') mean:  tensor(0.0357, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(92.7222, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0295, device='cuda:0')
min of d_p_list:  tensor(-0.0474, device='cuda:0')
Epoch:  756  
Training Loss: 784066.5
Test Loss:  544942.125
Test Acc:  0.0
Valid Loss:  637257.4375
Valid Acc:  0.0
std:  11091.665413442202 
thres:  799.7274375000001
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  38
 76%|███████▌  | 756/1000 [48:22<15:37,  3.84s/it]Epoch:   757
max of grad d_p:  tensor(579076.1875, device='cuda:0')
min of grad d_p:  tensor(-40360.1133, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.8750, device='cuda:0') mean:  tensor(0.0026, device='cuda:0') min:  tensor(-4.5469, device='cuda:0') norm:  tensor(51.5001, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(113.5522, device='cuda:0') mean:  tensor(0.1720, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(460.5892, device='cuda:0') MSE:  tensor(0.0017, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0109, device='cuda:0')
min of d_p_list:  tensor(-0.0170, device='cuda:0')
Epoch:  757  
Training Loss: 776262.0
Test Loss:  539530.6875
Test Acc:  0.0
Valid Loss:  630947.875
Valid Acc:  0.0
std:  11029.833512002799 
thres:  791.8765875
Preserved_eigens number check:  38
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  35
 76%|███████▌  | 757/1000 [48:26<15:45,  3.89s/it]Epoch:   758
max of grad d_p:  tensor(575676., device='cuda:0')
min of grad d_p:  tensor(-40245.2617, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.4375, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(-4.4639, device='cuda:0') norm:  tensor(45.4981, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(38.1328, device='cuda:0') mean:  tensor(0.0663, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(157.3433, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0452, device='cuda:0')
min of d_p_list:  tensor(-0.0419, device='cuda:0')
Epoch:  758  
Training Loss: 768635.375
Test Loss:  534325.0
Test Acc:  0.0
Valid Loss:  624679.75
Valid Acc:  0.0
std:  11007.621156782696 
thres:  784.119
Preserved_eigens number check:  35
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  73
 76%|███████▌  | 758/1000 [48:30<15:31,  3.85s/it]Epoch:   759
max of grad d_p:  tensor(573065.6875, device='cuda:0')
min of grad d_p:  tensor(-39927.1250, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.5625, device='cuda:0') mean:  tensor(0.0027, device='cuda:0') min:  tensor(-5.0273, device='cuda:0') norm:  tensor(53.1181, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(48.9297, device='cuda:0') mean:  tensor(0.0706, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(165.4522, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0181, device='cuda:0')
min of d_p_list:  tensor(-0.0165, device='cuda:0')
Epoch:  759  
Training Loss: 760975.75
Test Loss:  529003.9375
Test Acc:  0.0
Valid Loss:  618429.8125
Valid Acc:  0.0
std:  10927.769314228774 
thres:  776.366925
Preserved_eigens number check:  73
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  35
 76%|███████▌  | 759/1000 [48:33<15:20,  3.82s/it]Epoch:   760
max of grad d_p:  tensor(569681.1250, device='cuda:0')
min of grad d_p:  tensor(-39702.3320, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.8125, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-4.9258, device='cuda:0') norm:  tensor(51.5655, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(27.7930, device='cuda:0') mean:  tensor(0.0430, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(102.3149, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0121, device='cuda:0')
min of d_p_list:  tensor(-0.0103, device='cuda:0')
Epoch:  760  
Training Loss: 753400.0
Test Loss:  523795.6875
Test Acc:  0.0
Valid Loss:  612254.5
Valid Acc:  0.0
std:  10835.739353408238 
thres:  768.6679250000001
Preserved_eigens number check:  35
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  53
 76%|███████▌  | 760/1000 [48:37<14:56,  3.74s/it]Epoch:   761
max of grad d_p:  tensor(564799.1250, device='cuda:0')
min of grad d_p:  tensor(-39560.0234, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.3750, device='cuda:0') mean:  tensor(0.0031, device='cuda:0') min:  tensor(-4.6406, device='cuda:0') norm:  tensor(57.2005, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(34.0645, device='cuda:0') mean:  tensor(0.1333, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(277.8640, device='cuda:0') MSE:  tensor(0.0010, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0103, device='cuda:0')
min of d_p_list:  tensor(-0.0118, device='cuda:0')
Epoch:  761  
Training Loss: 745895.125
Test Loss:  518620.875
Test Acc:  0.0
Valid Loss:  606169.875
Valid Acc:  0.0
std:  10743.740229605795 
thres:  761.0336500000001
Preserved_eigens number check:  53
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  40
 76%|███████▌  | 761/1000 [48:41<15:05,  3.79s/it]Epoch:   762
max of grad d_p:  tensor(561957.5000, device='cuda:0')
min of grad d_p:  tensor(-39362.9961, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.8125, device='cuda:0') mean:  tensor(0.0030, device='cuda:0') min:  tensor(-4.0078, device='cuda:0') norm:  tensor(53.5520, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(43.8438, device='cuda:0') mean:  tensor(0.1137, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(252.8607, device='cuda:0') MSE:  tensor(0.0009, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0092, device='cuda:0')
min of d_p_list:  tensor(-0.0153, device='cuda:0')
Epoch:  762  
Training Loss: 738466.0
Test Loss:  513478.5625
Test Acc:  0.0
Valid Loss:  600130.125
Valid Acc:  0.0
std:  10666.099851456951 
thres:  753.4744499999999
Preserved_eigens number check:  40
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  135
 76%|███████▌  | 762/1000 [48:45<15:13,  3.84s/it]Epoch:   763
max of grad d_p:  tensor(559223.1875, device='cuda:0')
min of grad d_p:  tensor(-39191.8672, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6., device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-4.2061, device='cuda:0') norm:  tensor(47.7462, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(21.0137, device='cuda:0') mean:  tensor(0.0455, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(106.8861, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0374, device='cuda:0')
min of d_p_list:  tensor(-0.0263, device='cuda:0')
Epoch:  763  
Training Loss: 731211.0
Test Loss:  508528.0
Test Acc:  0.0
Valid Loss:  594328.75
Valid Acc:  0.0
std:  10531.089406371973 
thres:  745.989575
Preserved_eigens number check:  135
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  123
 76%|███████▋  | 763/1000 [48:48<15:02,  3.81s/it]Epoch:   764
max of grad d_p:  tensor(555327.1250, device='cuda:0')
min of grad d_p:  tensor(-39092.1445, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.6875, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-4.1934, device='cuda:0') norm:  tensor(48.9968, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(31.6885, device='cuda:0') mean:  tensor(0.0630, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(164.7793, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0085, device='cuda:0')
min of d_p_list:  tensor(-0.0119, device='cuda:0')
Epoch:  764  
Training Loss: 723896.75
Test Loss:  503476.125
Test Acc:  0.0
Valid Loss:  588092.4375
Valid Acc:  0.0
std:  10421.672107440341 
thres:  738.5737750000001
Preserved_eigens number check:  123
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 76%|███████▋  | 764/1000 [48:52<14:56,  3.80s/it]Epoch:   765
max of grad d_p:  tensor(551931.1875, device='cuda:0')
min of grad d_p:  tensor(-38990.0547, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.1562, device='cuda:0') mean:  tensor(0.0023, device='cuda:0') min:  tensor(-4.4111, device='cuda:0') norm:  tensor(50.3191, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(52.3281, device='cuda:0') mean:  tensor(0.0860, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(218.3876, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0829, device='cuda:0')
min of d_p_list:  tensor(-0.0517, device='cuda:0')
Epoch:  765  
Training Loss: 716786.875
Test Loss:  498813.375
Test Acc:  0.0
Valid Loss:  582570.625
Valid Acc:  0.0
std:  10293.727478238872 
thres:  731.25115
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  36
 76%|███████▋  | 765/1000 [48:56<14:47,  3.78s/it]Epoch:   766
max of grad d_p:  tensor(550134.8125, device='cuda:0')
min of grad d_p:  tensor(-38717.2305, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.4414, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(-4.3438, device='cuda:0') norm:  tensor(47.5012, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(77.7930, device='cuda:0') mean:  tensor(0.1602, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(393.1030, device='cuda:0') MSE:  tensor(0.0015, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0090, device='cuda:0')
min of d_p_list:  tensor(-0.0067, device='cuda:0')
Epoch:  766  
Training Loss: 709642.75
Test Loss:  493821.0625
Test Acc:  0.0
Valid Loss:  576735.875
Valid Acc:  0.0
std:  10192.488755083325 
thres:  724.0006750000001
Preserved_eigens number check:  36
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 77%|███████▋  | 766/1000 [49:00<15:00,  3.85s/it]Epoch:   767
max of grad d_p:  tensor(547025., device='cuda:0')
min of grad d_p:  tensor(-38550.1094, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.2500, device='cuda:0') mean:  tensor(0.0020, device='cuda:0') min:  tensor(-4.8594, device='cuda:0') norm:  tensor(52.5953, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(25.8633, device='cuda:0') mean:  tensor(0.0317, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(93.0303, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0167, device='cuda:0')
min of d_p_list:  tensor(-0.0253, device='cuda:0')
Epoch:  767  
Training Loss: 702583.0
Test Loss:  488945.375
Test Acc:  0.0
Valid Loss:  571011.9375
Valid Acc:  0.0
std:  10113.232642063565 
thres:  716.824075
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  45
 77%|███████▋  | 767/1000 [49:04<15:02,  3.87s/it]Epoch:   768
max of grad d_p:  tensor(543156.1250, device='cuda:0')
min of grad d_p:  tensor(-38414.2227, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(16.1250, device='cuda:0') mean:  tensor(0.0034, device='cuda:0') min:  tensor(-4.3594, device='cuda:0') norm:  tensor(56.9828, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(41.9805, device='cuda:0') mean:  tensor(0.1023, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(249.2899, device='cuda:0') MSE:  tensor(0.0009, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0335, device='cuda:0')
min of d_p_list:  tensor(-0.0254, device='cuda:0')
Epoch:  768  
Training Loss: 695627.6875
Test Loss:  484078.625
Test Acc:  0.0
Valid Loss:  565279.8125
Valid Acc:  0.0
std:  10004.560747604064 
thres:  709.7074125
Preserved_eigens number check:  45
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  42
 77%|███████▋  | 768/1000 [49:08<14:50,  3.84s/it]Epoch:   769
max of grad d_p:  tensor(539984.2500, device='cuda:0')
min of grad d_p:  tensor(-38097.6289, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.5625, device='cuda:0') mean:  tensor(0.0027, device='cuda:0') min:  tensor(-4.1709, device='cuda:0') norm:  tensor(49.3802, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(42.1367, device='cuda:0') mean:  tensor(0.0466, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(130.4490, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0288, device='cuda:0')
min of d_p_list:  tensor(-0.0512, device='cuda:0')
Epoch:  769  
Training Loss: 688706.5
Test Loss:  479421.84375
Test Acc:  0.0
Valid Loss:  559711.5
Valid Acc:  0.0
std:  9924.58026209421 
thres:  702.6693625
Preserved_eigens number check:  42
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 77%|███████▋  | 769/1000 [49:12<15:06,  3.92s/it]Epoch:   770
max of grad d_p:  tensor(532983.3750, device='cuda:0')
min of grad d_p:  tensor(-37631.8555, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.5625, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-4.4922, device='cuda:0') norm:  tensor(49.8394, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(22.9102, device='cuda:0') mean:  tensor(0.0475, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(117.9713, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0092, device='cuda:0')
min of d_p_list:  tensor(-0.0047, device='cuda:0')
Epoch:  770  
Training Loss: 681842.0
Test Loss:  474644.46875
Test Acc:  0.0
Valid Loss:  554144.6875
Valid Acc:  0.0
std:  9825.807637638496 
thres:  695.6803874999999
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  89
 77%|███████▋  | 770/1000 [49:15<14:49,  3.87s/it]Epoch:   771
max of grad d_p:  tensor(530324.7500, device='cuda:0')
min of grad d_p:  tensor(-37458.7109, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.4336, device='cuda:0') mean:  tensor(0.0024, device='cuda:0') min:  tensor(-4.2539, device='cuda:0') norm:  tensor(51.2624, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(67.7812, device='cuda:0') mean:  tensor(0.0623, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(162.0826, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0678, device='cuda:0')
min of d_p_list:  tensor(-0.0685, device='cuda:0')
Epoch:  771  
Training Loss: 675281.9375
Test Loss:  470106.625
Test Acc:  0.0
Valid Loss:  548693.6875
Valid Acc:  0.0
std:  9672.11029040134 
thres:  688.808225
Preserved_eigens number check:  89
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  94
 77%|███████▋  | 771/1000 [49:19<14:39,  3.84s/it]Epoch:   772
max of grad d_p:  tensor(524450., device='cuda:0')
min of grad d_p:  tensor(-37615.6797, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(14.0625, device='cuda:0') mean:  tensor(0.0032, device='cuda:0') min:  tensor(-4.3252, device='cuda:0') norm:  tensor(57.0969, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(44.2695, device='cuda:0') mean:  tensor(0.0850, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(205.7138, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0171, device='cuda:0')
min of d_p_list:  tensor(-0.0103, device='cuda:0')
Epoch:  772  
Training Loss: 668555.5
Test Loss:  465436.5625
Test Acc:  0.0
Valid Loss:  543238.25
Valid Acc:  0.0
std:  9556.179987039148 
thres:  682.0027249999999
Preserved_eigens number check:  94
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  40
 77%|███████▋  | 772/1000 [49:23<14:42,  3.87s/it]Epoch:   773
max of grad d_p:  tensor(521301.1875, device='cuda:0')
min of grad d_p:  tensor(-37461.0664, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.3359, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(-4.9219, device='cuda:0') norm:  tensor(47.0383, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(34.3867, device='cuda:0') mean:  tensor(0.0516, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(129.4162, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0234, device='cuda:0')
min of d_p_list:  tensor(-0.0369, device='cuda:0')
Epoch:  773  
Training Loss: 661938.3125
Test Loss:  460856.5625
Test Acc:  0.0
Valid Loss:  537973.625
Valid Acc:  0.0
std:  9450.387589819398 
thres:  675.26485
Preserved_eigens number check:  40
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  85
 77%|███████▋  | 773/1000 [49:27<14:49,  3.92s/it]Epoch:   774
max of grad d_p:  tensor(518316.9375, device='cuda:0')
min of grad d_p:  tensor(-37507.5195, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(14.4062, device='cuda:0') mean:  tensor(0.0035, device='cuda:0') min:  tensor(-4.1406, device='cuda:0') norm:  tensor(56.0274, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(234.2539, device='cuda:0') mean:  tensor(0.1473, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(479.2729, device='cuda:0') MSE:  tensor(0.0018, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0164, device='cuda:0')
min of d_p_list:  tensor(-0.0193, device='cuda:0')
Epoch:  774  
Training Loss: 655354.5
Test Loss:  456303.34375
Test Acc:  0.0
Valid Loss:  532568.875
Valid Acc:  0.0
std:  9378.934156811876 
thres:  668.5944499999999
Preserved_eigens number check:  85
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 77%|███████▋  | 774/1000 [49:31<14:40,  3.90s/it]Epoch:   775
max of grad d_p:  tensor(514664., device='cuda:0')
min of grad d_p:  tensor(-37329.7148, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.6562, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-4.2598, device='cuda:0') norm:  tensor(47.9654, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(590.9102, device='cuda:0') mean:  tensor(0.8994, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2409.3313, device='cuda:0') MSE:  tensor(0.0090, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0062, device='cuda:0')
min of d_p_list:  tensor(-0.0104, device='cuda:0')
Epoch:  775  
Training Loss: 648824.8125
Test Loss:  451742.8125
Test Acc:  0.0
Valid Loss:  527206.5
Valid Acc:  0.0
std:  9350.252203934795 
thres:  661.9910125
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  42
 78%|███████▊  | 775/1000 [49:35<14:36,  3.90s/it]Epoch:   776
max of grad d_p:  tensor(512463.3438, device='cuda:0')
min of grad d_p:  tensor(-37192.8125, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.1562, device='cuda:0') mean:  tensor(0.0027, device='cuda:0') min:  tensor(-4.4365, device='cuda:0') norm:  tensor(53.9705, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(94.3398, device='cuda:0') mean:  tensor(0.2398, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(564.5851, device='cuda:0') MSE:  tensor(0.0021, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0136, device='cuda:0')
min of d_p_list:  tensor(-0.0169, device='cuda:0')
Epoch:  776  
Training Loss: 642366.625
Test Loss:  447227.28125
Test Acc:  0.0
Valid Loss:  521967.25
Valid Acc:  0.0
std:  9261.96976226912 
thres:  655.4079499999999
Preserved_eigens number check:  42
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 78%|███████▊  | 776/1000 [49:39<14:34,  3.90s/it]Epoch:   777
max of grad d_p:  tensor(509810.1875, device='cuda:0')
min of grad d_p:  tensor(-37076.8125, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.3750, device='cuda:0') mean:  tensor(0.0029, device='cuda:0') min:  tensor(-4.0498, device='cuda:0') norm:  tensor(52.8583, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(72.1953, device='cuda:0') mean:  tensor(0.1607, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(389.0424, device='cuda:0') MSE:  tensor(0.0015, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0050, device='cuda:0')
min of d_p_list:  tensor(-0.0100, device='cuda:0')
Epoch:  777  
Training Loss: 635963.9375
Test Loss:  442743.625
Test Acc:  0.0
Valid Loss:  516760.0625
Valid Acc:  0.0
std:  9183.572085472106 
thres:  648.8896374999999
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  38
 78%|███████▊  | 777/1000 [49:43<14:20,  3.86s/it]Epoch:   778
max of grad d_p:  tensor(507472.7500, device='cuda:0')
min of grad d_p:  tensor(-36958.1953, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5., device='cuda:0') mean:  tensor(0.0020, device='cuda:0') min:  tensor(-3.7031, device='cuda:0') norm:  tensor(44.7184, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(48.8867, device='cuda:0') mean:  tensor(0.0508, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(148.3484, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0118, device='cuda:0')
min of d_p_list:  tensor(-0.0098, device='cuda:0')
Epoch:  778  
Training Loss: 629630.75
Test Loss:  438286.875
Test Acc:  0.0
Valid Loss:  511602.40625
Valid Acc:  0.0
std:  9094.735738756377 
thres:  642.428125
Preserved_eigens number check:  38
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  50
 78%|███████▊  | 778/1000 [49:46<14:13,  3.85s/it]Epoch:   779
max of grad d_p:  tensor(504611.1250, device='cuda:0')
min of grad d_p:  tensor(-36838.5312, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.5312, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-3.7666, device='cuda:0') norm:  tensor(49.4014, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(125.2344, device='cuda:0') mean:  tensor(0.0734, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(265.4855, device='cuda:0') MSE:  tensor(0.0010, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0748, device='cuda:0')
min of d_p_list:  tensor(-0.0647, device='cuda:0')
Epoch:  779  
Training Loss: 623305.625
Test Loss:  433948.71875
Test Acc:  0.0
Valid Loss:  506358.21875
Valid Acc:  0.0
std:  9019.13353538257 
thres:  636.0183499999999
Preserved_eigens number check:  50
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  37
 78%|███████▊  | 779/1000 [49:50<14:01,  3.81s/it]Epoch:   780
max of grad d_p:  tensor(499462.1875, device='cuda:0')
min of grad d_p:  tensor(-36373.3984, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.2461, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(-3.8994, device='cuda:0') norm:  tensor(43.8771, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(28.0117, device='cuda:0') mean:  tensor(0.0578, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(149.7721, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0086, device='cuda:0')
min of d_p_list:  tensor(-0.0153, device='cuda:0')
Epoch:  780  
Training Loss: 617102.5625
Test Loss:  429590.875
Test Acc:  0.0
Valid Loss:  501327.75
Valid Acc:  0.0
std:  8936.05231200067 
thres:  629.6739
Preserved_eigens number check:  37
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  35
 78%|███████▊  | 780/1000 [49:54<13:53,  3.79s/it]Epoch:   781
max of grad d_p:  tensor(496616.1875, device='cuda:0')
min of grad d_p:  tensor(-36346.2344, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.0625, device='cuda:0') mean:  tensor(0.0028, device='cuda:0') min:  tensor(-4.0312, device='cuda:0') norm:  tensor(51.5569, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(22.6445, device='cuda:0') mean:  tensor(0.0434, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(106.8928, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.6266, device='cuda:0')
min of d_p_list:  tensor(-0.6928, device='cuda:0')
Epoch:  781  
Training Loss: 614179.625
Test Loss:  428335.75
Test Acc:  0.0
Valid Loss:  497869.4375
Valid Acc:  0.0
std:  7991.633758676163 
thres:  624.0365
Preserved_eigens number check:  35
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  43
 78%|███████▊  | 781/1000 [49:58<14:09,  3.88s/it]Epoch:   782
max of grad d_p:  tensor(511811.9062, device='cuda:0')
min of grad d_p:  tensor(-36286.3516, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.7188, device='cuda:0') mean:  tensor(0.0028, device='cuda:0') min:  tensor(-4.3174, device='cuda:0') norm:  tensor(52.9139, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(33.1328, device='cuda:0') mean:  tensor(0.0543, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(146.7977, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0130, device='cuda:0')
min of d_p_list:  tensor(-0.0079, device='cuda:0')
Epoch:  782  
Training Loss: 608060.3125
Test Loss:  424038.1875
Test Acc:  0.0
Valid Loss:  492900.8125
Valid Acc:  0.0
std:  7437.51833281354 
thres:  618.455775
Preserved_eigens number check:  43
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  50
 78%|███████▊  | 782/1000 [50:02<14:03,  3.87s/it]Epoch:   783
max of grad d_p:  tensor(508970.0312, device='cuda:0')
min of grad d_p:  tensor(-36129.5312, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.2812, device='cuda:0') mean:  tensor(0.0028, device='cuda:0') min:  tensor(-4.4326, device='cuda:0') norm:  tensor(55.2366, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(39.0938, device='cuda:0') mean:  tensor(0.1010, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(200.5378, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0117, device='cuda:0')
min of d_p_list:  tensor(-0.0124, device='cuda:0')
Epoch:  783  
Training Loss: 602014.125
Test Loss:  419770.4375
Test Acc:  0.0
Valid Loss:  487928.15625
Valid Acc:  0.0
std:  7341.601840857859 
thres:  612.93245
Preserved_eigens number check:  50
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  87
 78%|███████▊  | 783/1000 [50:06<13:55,  3.85s/it]Epoch:   784
max of grad d_p:  tensor(506555.6562, device='cuda:0')
min of grad d_p:  tensor(-35987.9102, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.4297, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-3.9570, device='cuda:0') norm:  tensor(46.7190, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(97.5820, device='cuda:0') mean:  tensor(0.1631, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(390.6302, device='cuda:0') MSE:  tensor(0.0015, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0160, device='cuda:0')
min of d_p_list:  tensor(-0.0159, device='cuda:0')
Epoch:  784  
Training Loss: 596009.125
Test Loss:  415559.5
Test Acc:  0.0
Valid Loss:  483094.15625
Valid Acc:  0.0
std:  7736.562220695153 
thres:  607.47315
Preserved_eigens number check:  87
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 78%|███████▊  | 784/1000 [50:10<13:57,  3.88s/it]Epoch:   785
max of grad d_p:  tensor(505588.9375, device='cuda:0')
min of grad d_p:  tensor(-35853.4180, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.7188, device='cuda:0') mean:  tensor(0.0026, device='cuda:0') min:  tensor(-3.6445, device='cuda:0') norm:  tensor(47.8713, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(36.4883, device='cuda:0') mean:  tensor(0.0671, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(181.9668, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0097, device='cuda:0')
min of d_p_list:  tensor(-0.0130, device='cuda:0')
Epoch:  785  
Training Loss: 590081.125
Test Loss:  411404.6875
Test Acc:  0.0
Valid Loss:  478321.125
Valid Acc:  0.0
std:  8520.53175060835 
thres:  602.0688625
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  31
 78%|███████▊  | 785/1000 [50:14<14:03,  3.93s/it]Epoch:   786
max of grad d_p:  tensor(502719.5625, device='cuda:0')
min of grad d_p:  tensor(-35709.3516, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.4727, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-3.8418, device='cuda:0') norm:  tensor(45.9480, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(20.6133, device='cuda:0') mean:  tensor(0.0273, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(71.2376, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0099, device='cuda:0')
min of d_p_list:  tensor(-0.0170, device='cuda:0')
Epoch:  786  
Training Loss: 584203.8125
Test Loss:  407238.65625
Test Acc:  0.0
Valid Loss:  473556.4375
Valid Acc:  0.0
std:  8435.364636216831 
thres:  596.0736999999999
Preserved_eigens number check:  31
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  39
 79%|███████▊  | 786/1000 [50:17<13:46,  3.86s/it]Epoch:   787
max of grad d_p:  tensor(499277.8125, device='cuda:0')
min of grad d_p:  tensor(-35459.6562, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.4844, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-3.7725, device='cuda:0') norm:  tensor(46.2768, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6269.7886, device='cuda:0') mean:  tensor(10.3700, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(22432.2832, device='cuda:0') MSE:  tensor(0.0842, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0130, device='cuda:0')
min of d_p_list:  tensor(-0.0152, device='cuda:0')
Epoch:  787  
Training Loss: 578398.25
Test Loss:  403245.8125
Test Acc:  0.0
Valid Loss:  468845.71875
Valid Acc:  0.0
std:  8349.274769179057 
thres:  590.1412875
Preserved_eigens number check:  39
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  56
 79%|███████▊  | 787/1000 [50:21<13:45,  3.87s/it]Epoch:   788
max of grad d_p:  tensor(495934.7500, device='cuda:0')
min of grad d_p:  tensor(-35313.9766, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.9844, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-4.2412, device='cuda:0') norm:  tensor(50.5654, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(18.8872, device='cuda:0') mean:  tensor(0.0427, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(100.4228, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0068, device='cuda:0')
min of d_p_list:  tensor(-0.0088, device='cuda:0')
Epoch:  788  
Training Loss: 572639.625
Test Loss:  399226.0625
Test Acc:  0.0
Valid Loss:  464211.75
Valid Acc:  0.0
std:  8262.246858678938 
thres:  584.2663875
Preserved_eigens number check:  56
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  43
 79%|███████▉  | 788/1000 [50:25<13:55,  3.94s/it]Epoch:   789
max of grad d_p:  tensor(493296.3438, device='cuda:0')
min of grad d_p:  tensor(-35180.8047, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.3750, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-3.7139, device='cuda:0') norm:  tensor(45.5513, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(56.3926, device='cuda:0') mean:  tensor(0.0825, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(205.0215, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(1.1155, device='cuda:0')
min of d_p_list:  tensor(-1.1172, device='cuda:0')
Epoch:  789  
Training Loss: 574734.6875
Test Loss:  405736.5625
Test Acc:  0.0
Valid Loss:  472463.8125
Valid Acc:  0.0
std:  6383.802917956702 
thres:  580.0115
Preserved_eigens number check:  43
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  37
 79%|███████▉  | 789/1000 [50:29<13:45,  3.91s/it]Epoch:   790
max of grad d_p:  tensor(453447.5312, device='cuda:0')
min of grad d_p:  tensor(-34515.7812, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.1094, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(-3.2930, device='cuda:0') norm:  tensor(43.8825, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(473.3828, device='cuda:0') mean:  tensor(0.6281, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1447.8241, device='cuda:0') MSE:  tensor(0.0054, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0230, device='cuda:0')
min of d_p_list:  tensor(-0.0241, device='cuda:0')
Epoch:  790  
Training Loss: 569006.25
Test Loss:  401791.0
Test Acc:  0.0
Valid Loss:  467894.375
Valid Acc:  0.0
std:  5189.466391553422 
thres:  575.7965250000001
Preserved_eigens number check:  37
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  34
 79%|███████▉  | 790/1000 [50:33<13:31,  3.86s/it]Epoch:   791
max of grad d_p:  tensor(449038.9375, device='cuda:0')
min of grad d_p:  tensor(-34502.1094, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.8125, device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(-3.9570, device='cuda:0') norm:  tensor(48.2958, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(16.1562, device='cuda:0') mean:  tensor(0.0341, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(87.2326, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0393, device='cuda:0')
min of d_p_list:  tensor(-0.0309, device='cuda:0')
Epoch:  791  
Training Loss: 563334.25
Test Loss:  397853.125
Test Acc:  0.0
Valid Loss:  463229.1875
Valid Acc:  0.0
std:  5141.417983883434 
thres:  571.6226125000001
Preserved_eigens number check:  34
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 79%|███████▉  | 791/1000 [50:37<13:16,  3.81s/it]Epoch:   792
max of grad d_p:  tensor(444313.8125, device='cuda:0')
min of grad d_p:  tensor(-34545.7617, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(14.5625, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-3.7988, device='cuda:0') norm:  tensor(54.4470, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1273.6562, device='cuda:0') mean:  tensor(2.1179, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(5534.7871, device='cuda:0') MSE:  tensor(0.0208, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1182, device='cuda:0')
min of d_p_list:  tensor(-0.1121, device='cuda:0')
Epoch:  792  
Training Loss: 558118.375
Test Loss:  394379.375
Test Acc:  0.0
Valid Loss:  458684.5
Valid Acc:  0.0
std:  6105.266502731474 
thres:  567.5666375
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 79%|███████▉  | 792/1000 [50:40<13:08,  3.79s/it]Epoch:   793
max of grad d_p:  tensor(445928.1562, device='cuda:0')
min of grad d_p:  tensor(-33604.2344, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.7812, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-3.9492, device='cuda:0') norm:  tensor(52.6010, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(35.6523, device='cuda:0') mean:  tensor(0.0863, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(202.6785, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0430, device='cuda:0')
min of d_p_list:  tensor(-0.0318, device='cuda:0')
Epoch:  793  
Training Loss: 552641.125
Test Loss:  390620.5
Test Acc:  0.0
Valid Loss:  454346.65625
Valid Acc:  0.0
std:  7789.98223501665 
thres:  563.5669375
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  55
 79%|███████▉  | 793/1000 [50:44<13:05,  3.79s/it]Epoch:   794
max of grad d_p:  tensor(445287.3750, device='cuda:0')
min of grad d_p:  tensor(-33912.3828, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.3906, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(-3.4492, device='cuda:0') norm:  tensor(45.4794, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(33.5039, device='cuda:0') mean:  tensor(0.0720, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(168.9501, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0102, device='cuda:0')
min of d_p_list:  tensor(-0.0115, device='cuda:0')
Epoch:  794  
Training Loss: 547136.5
Test Loss:  386704.0625
Test Acc:  0.0
Valid Loss:  449860.03125
Valid Acc:  0.0
std:  7698.412327632886 
thres:  558.0473000000001
Preserved_eigens number check:  55
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 79%|███████▉  | 794/1000 [50:48<13:06,  3.82s/it]Epoch:   795
max of grad d_p:  tensor(443566.5625, device='cuda:0')
min of grad d_p:  tensor(-34164.3398, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5., device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(-3.7207, device='cuda:0') norm:  tensor(44.0028, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(277.5586, device='cuda:0') mean:  tensor(0.2237, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(695.0772, device='cuda:0') MSE:  tensor(0.0026, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0248, device='cuda:0')
min of d_p_list:  tensor(-0.0396, device='cuda:0')
Epoch:  795  
Training Loss: 541723.3125
Test Loss:  382823.65625
Test Acc:  0.0
Valid Loss:  445372.0625
Valid Acc:  0.0
std:  7665.898628381738 
thres:  552.5907125
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  64
 80%|███████▉  | 795/1000 [50:52<13:07,  3.84s/it]Epoch:   796
max of grad d_p:  tensor(440591.6562, device='cuda:0')
min of grad d_p:  tensor(-34114.9531, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.6562, device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(-3.5156, device='cuda:0') norm:  tensor(45.2253, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(770.3828, device='cuda:0') mean:  tensor(0.9243, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2285.5164, device='cuda:0') MSE:  tensor(0.0086, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0125, device='cuda:0')
min of d_p_list:  tensor(-0.0166, device='cuda:0')
Epoch:  796  
Training Loss: 536337.5
Test Loss:  379046.71875
Test Acc:  0.0
Valid Loss:  440945.125
Valid Acc:  0.0
std:  7704.653468480916 
thres:  547.1913625000001
Preserved_eigens number check:  64
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  34
 80%|███████▉  | 796/1000 [50:56<13:01,  3.83s/it]Epoch:   797
max of grad d_p:  tensor(438147.7500, device='cuda:0')
min of grad d_p:  tensor(-33747.2109, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.6250, device='cuda:0') mean:  tensor(0.0025, device='cuda:0') min:  tensor(-3.6621, device='cuda:0') norm:  tensor(49.1098, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(195.9473, device='cuda:0') mean:  tensor(0.3009, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(776.4770, device='cuda:0') MSE:  tensor(0.0029, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0482, device='cuda:0')
min of d_p_list:  tensor(-0.0937, device='cuda:0')
Epoch:  797  
Training Loss: 531337.25
Test Loss:  375373.1875
Test Acc:  0.0
Valid Loss:  436926.9375
Valid Acc:  0.0
std:  7554.018468090345 
thres:  541.8351375
Preserved_eigens number check:  34
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 80%|███████▉  | 797/1000 [51:00<13:10,  3.89s/it]Epoch:   798
max of grad d_p:  tensor(435489.5312, device='cuda:0')
min of grad d_p:  tensor(-33019.4688, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.0391, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(-3.6797, device='cuda:0') norm:  tensor(48.4163, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2499.7188, device='cuda:0') mean:  tensor(2.9618, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(7693.0688, device='cuda:0') MSE:  tensor(0.0289, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1623, device='cuda:0')
min of d_p_list:  tensor(-0.1382, device='cuda:0')
Epoch:  798  
Training Loss: 526890.0
Test Loss:  372386.5625
Test Acc:  0.0
Valid Loss:  433890.5
Valid Acc:  0.0
std:  7201.106253512373 
thres:  536.6849125
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  61
 80%|███████▉  | 798/1000 [51:03<12:50,  3.81s/it]Epoch:   799
max of grad d_p:  tensor(443005.5312, device='cuda:0')
min of grad d_p:  tensor(-34806.4531, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.5391, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(-3.6484, device='cuda:0') norm:  tensor(41.2461, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(108.9062, device='cuda:0') mean:  tensor(0.2267, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(539.5526, device='cuda:0') MSE:  tensor(0.0020, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0420, device='cuda:0')
min of d_p_list:  tensor(-0.0459, device='cuda:0')
Epoch:  799  
Training Loss: 521636.0
Test Loss:  368749.375
Test Acc:  0.0
Valid Loss:  429663.9375
Valid Acc:  0.0
std:  7020.806826631467 
thres:  531.5848125
Preserved_eigens number check:  61
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  63
 80%|███████▉  | 799/1000 [51:07<12:54,  3.85s/it]Epoch:   800
max of grad d_p:  tensor(439850.8125, device='cuda:0')
min of grad d_p:  tensor(-34366.9531, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10., device='cuda:0') mean:  tensor(0.0025, device='cuda:0') min:  tensor(-3.7871, device='cuda:0') norm:  tensor(51.6140, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(127.4375, device='cuda:0') mean:  tensor(0.1509, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(449.3516, device='cuda:0') MSE:  tensor(0.0017, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0123, device='cuda:0')
min of d_p_list:  tensor(-0.0115, device='cuda:0')
Epoch:  800  
Training Loss: 516422.3125
Test Loss:  365124.1875
Test Acc:  0.0
Valid Loss:  425409.375
Valid Acc:  0.0
std:  7007.749229023182 
thres:  526.5246125000001
Preserved_eigens number check:  63
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 80%|████████  | 800/1000 [51:11<12:47,  3.84s/it]Epoch:   801
max of grad d_p:  tensor(437805.6250, device='cuda:0')
min of grad d_p:  tensor(-34118.6172, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.4688, device='cuda:0') mean:  tensor(0.0025, device='cuda:0') min:  tensor(-4.3770, device='cuda:0') norm:  tensor(51.4028, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(76.3574, device='cuda:0') mean:  tensor(0.1865, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(420.6445, device='cuda:0') MSE:  tensor(0.0016, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0717, device='cuda:0')
min of d_p_list:  tensor(-0.0504, device='cuda:0')
Epoch:  801  
Training Loss: 511353.59375
Test Loss:  361559.3125
Test Acc:  0.0
Valid Loss:  421146.90625
Valid Acc:  0.0
std:  7135.414224946055 
thres:  521.52783125
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  60
 80%|████████  | 801/1000 [51:15<13:00,  3.92s/it]Epoch:   802
max of grad d_p:  tensor(437117.5938, device='cuda:0')
min of grad d_p:  tensor(-34337.3711, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.9688, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(-4.1113, device='cuda:0') norm:  tensor(44.5486, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(68.7061, device='cuda:0') mean:  tensor(0.1186, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(291.5063, device='cuda:0') MSE:  tensor(0.0011, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1052, device='cuda:0')
min of d_p_list:  tensor(-0.0567, device='cuda:0')
Epoch:  802  
Training Loss: 506344.6875
Test Loss:  358184.28125
Test Acc:  0.0
Valid Loss:  417357.625
Valid Acc:  0.0
std:  7265.647977501301 
thres:  516.52931875
Preserved_eigens number check:  60
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  99
 80%|████████  | 802/1000 [51:19<12:54,  3.91s/it]Epoch:   803
max of grad d_p:  tensor(430557.5625, device='cuda:0')
min of grad d_p:  tensor(-34957.7461, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.7422, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-3.8613, device='cuda:0') norm:  tensor(41.3513, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(48.7336, device='cuda:0') mean:  tensor(0.1087, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(249.4541, device='cuda:0') MSE:  tensor(0.0009, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0310, device='cuda:0')
min of d_p_list:  tensor(-0.0403, device='cuda:0')
Epoch:  803  
Training Loss: 501302.625
Test Loss:  354619.4375
Test Acc:  0.0
Valid Loss:  413312.0
Valid Acc:  0.0
std:  7176.54425721609 
thres:  511.41184375
Preserved_eigens number check:  99
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  52
 80%|████████  | 803/1000 [51:23<12:43,  3.88s/it]Epoch:   804
max of grad d_p:  tensor(427142.6250, device='cuda:0')
min of grad d_p:  tensor(-35140.3633, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(16.3438, device='cuda:0') mean:  tensor(0.0030, device='cuda:0') min:  tensor(-4.1523, device='cuda:0') norm:  tensor(58.8131, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(16.7734, device='cuda:0') mean:  tensor(0.0297, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(70.3579, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0249, device='cuda:0')
min of d_p_list:  tensor(-0.0136, device='cuda:0')
Epoch:  804  
Training Loss: 496318.53125
Test Loss:  351124.625
Test Acc:  0.0
Valid Loss:  409190.5625
Valid Acc:  0.0
std:  7107.655081610294 
thres:  506.34835
Preserved_eigens number check:  52
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  66
 80%|████████  | 804/1000 [51:27<12:42,  3.89s/it]Epoch:   805
max of grad d_p:  tensor(424690.7500, device='cuda:0')
min of grad d_p:  tensor(-34831.0664, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.2188, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(-4.1641, device='cuda:0') norm:  tensor(48.9448, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(49.5508, device='cuda:0') mean:  tensor(0.0827, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(212.2623, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0398, device='cuda:0')
min of d_p_list:  tensor(-0.0352, device='cuda:0')
Epoch:  805  
Training Loss: 491582.65625
Test Loss:  347686.6875
Test Acc:  0.0
Valid Loss:  405467.90625
Valid Acc:  0.0
std:  7010.464902407731 
thres:  501.38041875000005
Preserved_eigens number check:  66
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  53
 80%|████████  | 805/1000 [51:31<12:47,  3.94s/it]Epoch:   806
max of grad d_p:  tensor(424420.3750, device='cuda:0')
min of grad d_p:  tensor(-34563.4297, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(16.5000, device='cuda:0') mean:  tensor(0.0033, device='cuda:0') min:  tensor(-5.6250, device='cuda:0') norm:  tensor(60.5276, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(51.2383, device='cuda:0') mean:  tensor(0.0771, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(209.1048, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0213, device='cuda:0')
min of d_p_list:  tensor(-0.0338, device='cuda:0')
Epoch:  806  
Training Loss: 486676.8125
Test Loss:  344338.25
Test Acc:  0.0
Valid Loss:  401628.9375
Valid Acc:  0.0
std:  6937.956490809046 
thres:  496.4450625
Preserved_eigens number check:  53
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  38
 81%|████████  | 806/1000 [51:35<12:36,  3.90s/it]Epoch:   807
max of grad d_p:  tensor(421650.9375, device='cuda:0')
min of grad d_p:  tensor(-34320.4688, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.4375, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-4.7227, device='cuda:0') norm:  tensor(48.9391, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(30.7520, device='cuda:0') mean:  tensor(0.0509, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(126.2924, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0134, device='cuda:0')
min of d_p_list:  tensor(-0.0142, device='cuda:0')
Epoch:  807  
Training Loss: 481820.25
Test Loss:  340952.1875
Test Acc:  0.0
Valid Loss:  397703.6875
Valid Acc:  0.0
std:  6874.14227264823 
thres:  491.540175
Preserved_eigens number check:  38
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  33
 81%|████████  | 807/1000 [51:39<12:25,  3.86s/it]Epoch:   808
max of grad d_p:  tensor(418792.5312, device='cuda:0')
min of grad d_p:  tensor(-34414.5586, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.5742, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(-4.5215, device='cuda:0') norm:  tensor(44.2006, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(59.7617, device='cuda:0') mean:  tensor(0.0493, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(154.6548, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0252, device='cuda:0')
min of d_p_list:  tensor(-0.0184, device='cuda:0')
Epoch:  808  
Training Loss: 477009.90625
Test Loss:  337664.28125
Test Acc:  0.0
Valid Loss:  393786.75
Valid Acc:  0.0
std:  6842.005597987379 
thres:  486.68163125
Preserved_eigens number check:  33
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  41
 81%|████████  | 808/1000 [51:43<12:29,  3.90s/it]Epoch:   809
max of grad d_p:  tensor(416082.6250, device='cuda:0')
min of grad d_p:  tensor(-33966., device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.3125, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(-4.1133, device='cuda:0') norm:  tensor(43.3968, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(94.4863, device='cuda:0') mean:  tensor(0.1101, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(279.7521, device='cuda:0') MSE:  tensor(0.0011, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0372, device='cuda:0')
min of d_p_list:  tensor(-0.0365, device='cuda:0')
Epoch:  809  
Training Loss: 472257.875
Test Loss:  334428.6875
Test Acc:  0.0
Valid Loss:  389931.25
Valid Acc:  0.0
std:  6833.111588840538 
thres:  481.8695
Preserved_eigens number check:  41
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  45
 81%|████████  | 809/1000 [51:47<12:30,  3.93s/it]Epoch:   810
max of grad d_p:  tensor(415503.8750, device='cuda:0')
min of grad d_p:  tensor(-33864.9336, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.7148, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-4.6660, device='cuda:0') norm:  tensor(45.0906, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(44.6465, device='cuda:0') mean:  tensor(0.0667, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(161.4686, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0197, device='cuda:0')
min of d_p_list:  tensor(-0.0164, device='cuda:0')
Epoch:  810  
Training Loss: 467544.625
Test Loss:  331150.34375
Test Acc:  0.0
Valid Loss:  386073.1875
Valid Acc:  0.0
std:  6763.849792555272 
thres:  477.06189375
Preserved_eigens number check:  45
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  38
 81%|████████  | 810/1000 [51:50<12:21,  3.90s/it]Epoch:   811
max of grad d_p:  tensor(413065.6875, device='cuda:0')
min of grad d_p:  tensor(-33865.7656, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.3281, device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(-4.4902, device='cuda:0') norm:  tensor(44.5873, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(37.1914, device='cuda:0') mean:  tensor(0.0378, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(98.1320, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0109, device='cuda:0')
min of d_p_list:  tensor(-0.0121, device='cuda:0')
Epoch:  811  
Training Loss: 462873.90625
Test Loss:  327885.875
Test Acc:  0.0
Valid Loss:  382284.3125
Valid Acc:  0.0
std:  6697.536526560298 
thres:  472.3013125
Preserved_eigens number check:  38
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  62
 81%|████████  | 811/1000 [51:54<12:12,  3.87s/it]Epoch:   812
max of grad d_p:  tensor(411036.0625, device='cuda:0')
min of grad d_p:  tensor(-33803.8203, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.4688, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(-4.2637, device='cuda:0') norm:  tensor(44.0532, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(61.9824, device='cuda:0') mean:  tensor(0.0895, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(237.8456, device='cuda:0') MSE:  tensor(0.0009, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0203, device='cuda:0')
min of d_p_list:  tensor(-0.0135, device='cuda:0')
Epoch:  812  
Training Loss: 458270.0
Test Loss:  324628.90625
Test Acc:  0.0
Valid Loss:  378484.21875
Valid Acc:  0.0
std:  6627.664474825153 
thres:  467.5912625
Preserved_eigens number check:  62
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 81%|████████  | 812/1000 [51:58<12:24,  3.96s/it]Epoch:   813
max of grad d_p:  tensor(410095.9062, device='cuda:0')
min of grad d_p:  tensor(-33708.5234, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.0430, device='cuda:0') mean:  tensor(0.0020, device='cuda:0') min:  tensor(-4.3887, device='cuda:0') norm:  tensor(46.1598, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(21.9814, device='cuda:0') mean:  tensor(0.0511, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(109.0636, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0237, device='cuda:0')
min of d_p_list:  tensor(-0.0137, device='cuda:0')
Epoch:  813  
Training Loss: 453725.3125
Test Loss:  321406.625
Test Acc:  0.0
Valid Loss:  374677.96875
Valid Acc:  0.0
std:  6553.608777564847 
thres:  462.93434375
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 81%|████████▏ | 813/1000 [52:02<12:17,  3.95s/it]Epoch:   814
max of grad d_p:  tensor(407720.7188, device='cuda:0')
min of grad d_p:  tensor(-33782.0859, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.1562, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-4.5391, device='cuda:0') norm:  tensor(47.1297, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(31.4375, device='cuda:0') mean:  tensor(0.0423, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(109.1054, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0179, device='cuda:0')
min of d_p_list:  tensor(-0.0181, device='cuda:0')
Epoch:  814  
Training Loss: 449222.875
Test Loss:  318249.1875
Test Acc:  0.0
Valid Loss:  370987.8125
Valid Acc:  0.0
std:  6476.15372515778 
thres:  458.32734375
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  120
 81%|████████▏ | 814/1000 [52:06<12:04,  3.90s/it]Epoch:   815
max of grad d_p:  tensor(405434.9688, device='cuda:0')
min of grad d_p:  tensor(-33486.9023, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.6562, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(-4.5938, device='cuda:0') norm:  tensor(46.8438, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(549.1191, device='cuda:0') mean:  tensor(1.2086, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2875.8899, device='cuda:0') MSE:  tensor(0.0108, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0810, device='cuda:0')
min of d_p_list:  tensor(-0.1272, device='cuda:0')
Epoch:  815  
Training Loss: 445100.375
Test Loss:  315277.3125
Test Acc:  0.0
Valid Loss:  367288.6875
Valid Acc:  0.0
std:  6307.906030034848 
thres:  453.83849375000005
Preserved_eigens number check:  120
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 82%|████████▏ | 815/1000 [52:10<11:57,  3.88s/it]Epoch:   816
max of grad d_p:  tensor(399953.5625, device='cuda:0')
min of grad d_p:  tensor(-33641.6172, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.6250, device='cuda:0') mean:  tensor(0.0023, device='cuda:0') min:  tensor(-4.1445, device='cuda:0') norm:  tensor(48.2044, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(191.9443, device='cuda:0') mean:  tensor(0.4056, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(938.6532, device='cuda:0') MSE:  tensor(0.0035, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0062, device='cuda:0')
min of d_p_list:  tensor(-0.0089, device='cuda:0')
Epoch:  816  
Training Loss: 440664.25
Test Loss:  312120.1875
Test Acc:  0.0
Valid Loss:  363607.4375
Valid Acc:  0.0
std:  6200.268471757897 
thres:  449.3965625
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  76
 82%|████████▏ | 816/1000 [52:14<12:03,  3.93s/it]Epoch:   817
max of grad d_p:  tensor(397897.5625, device='cuda:0')
min of grad d_p:  tensor(-33517.4844, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.4492, device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(-4.5898, device='cuda:0') norm:  tensor(43.5232, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(80.4961, device='cuda:0') mean:  tensor(0.1189, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(315.9785, device='cuda:0') MSE:  tensor(0.0012, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0084, device='cuda:0')
min of d_p_list:  tensor(-0.0129, device='cuda:0')
Epoch:  817  
Training Loss: 436264.0625
Test Loss:  309042.90625
Test Acc:  0.0
Valid Loss:  360006.0625
Valid Acc:  0.0
std:  6149.618715695918 
thres:  444.995375
Preserved_eigens number check:  76
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  34
 82%|████████▏ | 817/1000 [52:18<11:59,  3.93s/it]Epoch:   818
max of grad d_p:  tensor(396107.5000, device='cuda:0')
min of grad d_p:  tensor(-33447.9375, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.1875, device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(-3.9570, device='cuda:0') norm:  tensor(45.1358, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(32.5430, device='cuda:0') mean:  tensor(0.0471, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(109.5472, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0306, device='cuda:0')
min of d_p_list:  tensor(-0.0243, device='cuda:0')
Epoch:  818  
Training Loss: 431976.09375
Test Loss:  305853.625
Test Acc:  0.0
Valid Loss:  356444.0625
Valid Acc:  0.0
std:  6128.184462103152 
thres:  440.64553125000003
Preserved_eigens number check:  34
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  40
 82%|████████▏ | 818/1000 [52:22<11:57,  3.94s/it]Epoch:   819
max of grad d_p:  tensor(395950.0938, device='cuda:0')
min of grad d_p:  tensor(-33303.7969, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.7500, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(-4.6211, device='cuda:0') norm:  tensor(43.0943, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(48.7412, device='cuda:0') mean:  tensor(0.0959, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(250.9707, device='cuda:0') MSE:  tensor(0.0009, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1095, device='cuda:0')
min of d_p_list:  tensor(-0.1069, device='cuda:0')
Epoch:  819  
Training Loss: 428463.28125
Test Loss:  302908.4375
Test Acc:  0.0
Valid Loss:  353122.375
Valid Acc:  0.0
std:  5939.991022411408 
thres:  436.4936125
Preserved_eigens number check:  40
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  56
 82%|████████▏ | 819/1000 [52:25<11:38,  3.86s/it]Epoch:   820
max of grad d_p:  tensor(389151.4375, device='cuda:0')
min of grad d_p:  tensor(-33392.4648, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.3438, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-4.6680, device='cuda:0') norm:  tensor(50.0422, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(67.8906, device='cuda:0') mean:  tensor(0.0926, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(207.0255, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0086, device='cuda:0')
min of d_p_list:  tensor(-0.0116, device='cuda:0')
Epoch:  820  
Training Loss: 424197.09375
Test Loss:  299871.625
Test Acc:  0.0
Valid Loss:  349628.4375
Valid Acc:  0.0
std:  5764.65169747515 
thres:  432.31295625
Preserved_eigens number check:  56
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  44
 82%|████████▏ | 820/1000 [52:29<11:37,  3.87s/it]Epoch:   821
max of grad d_p:  tensor(386822.4375, device='cuda:0')
min of grad d_p:  tensor(-33188.0312, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.1250, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-4.4277, device='cuda:0') norm:  tensor(47.5248, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(347.4766, device='cuda:0') mean:  tensor(1.1108, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2662.8667, device='cuda:0') MSE:  tensor(0.0100, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1767, device='cuda:0')
min of d_p_list:  tensor(-0.2713, device='cuda:0')
Epoch:  821  
Training Loss: 421737.5
Test Loss:  297795.375
Test Acc:  0.0
Valid Loss:  347511.15625
Valid Acc:  0.0
std:  5227.003739244705 
thres:  428.52760625
Preserved_eigens number check:  44
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 82%|████████▏ | 821/1000 [52:33<11:30,  3.86s/it]Epoch:   822
max of grad d_p:  tensor(383999.4688, device='cuda:0')
min of grad d_p:  tensor(-34137.4258, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.2188, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-4.8027, device='cuda:0') norm:  tensor(48.6111, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(16623.6562, device='cuda:0') mean:  tensor(35.8594, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(77012.3672, device='cuda:0') MSE:  tensor(0.2891, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0129, device='cuda:0')
min of d_p_list:  tensor(-0.0148, device='cuda:0')
Epoch:  822  
Training Loss: 417540.9375
Test Loss:  294874.34375
Test Acc:  0.0
Valid Loss:  344061.65625
Valid Acc:  0.0
std:  5046.798854944154 
thres:  424.78298125000003
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  31
 82%|████████▏ | 822/1000 [52:37<11:31,  3.88s/it]Epoch:   823
max of grad d_p:  tensor(382124.3125, device='cuda:0')
min of grad d_p:  tensor(-33981.1641, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.5938, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(-5.1152, device='cuda:0') norm:  tensor(46.8689, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(23.6953, device='cuda:0') mean:  tensor(0.0609, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(151.5784, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1213, device='cuda:0')
min of d_p_list:  tensor(-0.0708, device='cuda:0')
Epoch:  823  
Training Loss: 413610.8125
Test Loss:  292288.5
Test Acc:  0.0
Valid Loss:  340789.6875
Valid Acc:  0.0
std:  5156.950057424022 
thres:  421.109925
Preserved_eigens number check:  31
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  36
 82%|████████▏ | 823/1000 [52:41<11:37,  3.94s/it]Epoch:   824
max of grad d_p:  tensor(377236.8125, device='cuda:0')
min of grad d_p:  tensor(-33640.1328, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.0312, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(-4.1152, device='cuda:0') norm:  tensor(44.8102, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(84.3643, device='cuda:0') mean:  tensor(0.2036, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(472.8011, device='cuda:0') MSE:  tensor(0.0018, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0568, device='cuda:0')
min of d_p_list:  tensor(-0.0715, device='cuda:0')
Epoch:  824  
Training Loss: 409690.375
Test Loss:  289653.9375
Test Acc:  0.0
Valid Loss:  337560.71875
Valid Acc:  0.0
std:  5269.165811068318 
thres:  417.35534375000003
Preserved_eigens number check:  36
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  40
 82%|████████▏ | 824/1000 [52:45<11:26,  3.90s/it]Epoch:   825
max of grad d_p:  tensor(376221.7812, device='cuda:0')
min of grad d_p:  tensor(-33554.0703, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.1914, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(-3.7598, device='cuda:0') norm:  tensor(49.2891, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(13.8853, device='cuda:0') mean:  tensor(0.0316, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(67.9951, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0761, device='cuda:0')
min of d_p_list:  tensor(-0.0370, device='cuda:0')
Epoch:  825  
Training Loss: 405956.875
Test Loss:  287292.3125
Test Acc:  0.0
Valid Loss:  334543.65625
Valid Acc:  0.0
std:  5574.85376481415 
thres:  413.7073
Preserved_eigens number check:  40
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  54
 82%|████████▎ | 825/1000 [52:49<11:22,  3.90s/it]Epoch:   826
max of grad d_p:  tensor(375554.6250, device='cuda:0')
min of grad d_p:  tensor(-33571.2695, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.1250, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(-3.6484, device='cuda:0') norm:  tensor(44.0060, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(57.5156, device='cuda:0') mean:  tensor(0.0876, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(244.5959, device='cuda:0') MSE:  tensor(0.0009, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0194, device='cuda:0')
min of d_p_list:  tensor(-0.0239, device='cuda:0')
Epoch:  826  
Training Loss: 401931.875
Test Loss:  284418.15625
Test Acc:  0.0
Valid Loss:  331244.5
Valid Acc:  0.0
std:  5497.616539152445 
thres:  409.746175
Preserved_eigens number check:  54
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  78
 83%|████████▎ | 826/1000 [52:53<11:15,  3.88s/it]Epoch:   827
max of grad d_p:  tensor(372820.1562, device='cuda:0')
min of grad d_p:  tensor(-33481.5039, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.8867, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-4.0586, device='cuda:0') norm:  tensor(43.4804, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(28.3887, device='cuda:0') mean:  tensor(0.0535, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(132.1942, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0047, device='cuda:0')
min of d_p_list:  tensor(-0.0098, device='cuda:0')
Epoch:  827  
Training Loss: 397928.59375
Test Loss:  281596.4375
Test Acc:  0.0
Valid Loss:  327939.8125
Valid Acc:  0.0
std:  5533.29986089901 
thres:  405.82370625
Preserved_eigens number check:  78
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  31
 83%|████████▎ | 827/1000 [52:57<11:17,  3.92s/it]Epoch:   828
max of grad d_p:  tensor(371105.8125, device='cuda:0')
min of grad d_p:  tensor(-33353.1094, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.6250, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(-3.7188, device='cuda:0') norm:  tensor(46.9799, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(12.3047, device='cuda:0') mean:  tensor(0.0270, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(60.1682, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0081, device='cuda:0')
min of d_p_list:  tensor(-0.0162, device='cuda:0')
Epoch:  828  
Training Loss: 393966.5625
Test Loss:  278779.59375
Test Acc:  0.0
Valid Loss:  324674.3125
Valid Acc:  0.0
std:  5583.199070425485 
thres:  401.89485625000003
Preserved_eigens number check:  31
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  95
 83%|████████▎ | 828/1000 [53:01<11:07,  3.88s/it]Epoch:   829
max of grad d_p:  tensor(369088.7812, device='cuda:0')
min of grad d_p:  tensor(-33230.8516, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(13.9375, device='cuda:0') mean:  tensor(0.0023, device='cuda:0') min:  tensor(-4.2070, device='cuda:0') norm:  tensor(56.3768, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(155.3809, device='cuda:0') mean:  tensor(0.1880, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(514.0750, device='cuda:0') MSE:  tensor(0.0019, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0180, device='cuda:0')
min of d_p_list:  tensor(-0.0200, device='cuda:0')
Epoch:  829  
Training Loss: 390077.46875
Test Loss:  275986.125
Test Acc:  0.0
Valid Loss:  321433.5625
Valid Acc:  0.0
std:  5617.968952019882 
thres:  397.972275
Preserved_eigens number check:  95
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  35
 83%|████████▎ | 829/1000 [53:04<11:01,  3.87s/it]Epoch:   830
max of grad d_p:  tensor(367247.1250, device='cuda:0')
min of grad d_p:  tensor(-33059.6719, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.4375, device='cuda:0') mean:  tensor(0.0020, device='cuda:0') min:  tensor(-3.6992, device='cuda:0') norm:  tensor(47.9919, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(12.9004, device='cuda:0') mean:  tensor(0.0396, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(86.0411, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0106, device='cuda:0')
min of d_p_list:  tensor(-0.0090, device='cuda:0')
Epoch:  830  
Training Loss: 386196.53125
Test Loss:  273271.40625
Test Acc:  0.0
Valid Loss:  318235.4375
Valid Acc:  0.0
std:  5561.0779964199055 
thres:  394.02020625
Preserved_eigens number check:  35
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  212
 83%|████████▎ | 830/1000 [53:08<10:51,  3.83s/it]Epoch:   831
max of grad d_p:  tensor(365973.7500, device='cuda:0')
min of grad d_p:  tensor(-32923.0547, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.8359, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-3.5879, device='cuda:0') norm:  tensor(42.2391, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(35.9805, device='cuda:0') mean:  tensor(0.0558, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(128.9594, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0391, device='cuda:0')
min of d_p_list:  tensor(-0.0274, device='cuda:0')
Epoch:  831  
Training Loss: 382371.78125
Test Loss:  270661.375
Test Acc:  0.0
Valid Loss:  314767.9375
Valid Acc:  0.0
std:  5499.087042054685 
thres:  390.1081875
Preserved_eigens number check:  212
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  70
 83%|████████▎ | 831/1000 [53:12<10:56,  3.89s/it]Epoch:   832
max of grad d_p:  tensor(363113.3438, device='cuda:0')
min of grad d_p:  tensor(-32699.9180, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(20.2812, device='cuda:0') mean:  tensor(0.0031, device='cuda:0') min:  tensor(-3.6094, device='cuda:0') norm:  tensor(59.0164, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(32.7852, device='cuda:0') mean:  tensor(0.0520, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(140.1472, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0102, device='cuda:0')
min of d_p_list:  tensor(-0.0078, device='cuda:0')
Epoch:  832  
Training Loss: 378560.4375
Test Loss:  267961.9375
Test Acc:  0.0
Valid Loss:  311630.8125
Valid Acc:  0.0
std:  5447.31993411525 
thres:  386.23455625
Preserved_eigens number check:  70
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 83%|████████▎ | 832/1000 [53:16<10:45,  3.84s/it]Epoch:   833
max of grad d_p:  tensor(361249.6875, device='cuda:0')
min of grad d_p:  tensor(-32592.0547, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.2695, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(-3.6372, device='cuda:0') norm:  tensor(47.0126, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(185.4883, device='cuda:0') mean:  tensor(0.4563, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1002.4688, device='cuda:0') MSE:  tensor(0.0038, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0239, device='cuda:0')
min of d_p_list:  tensor(-0.0212, device='cuda:0')
Epoch:  833  
Training Loss: 374797.0
Test Loss:  265222.25
Test Acc:  0.0
Valid Loss:  308504.375
Valid Acc:  0.0
std:  5401.959262279578 
thres:  382.40064375
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  59
 83%|████████▎ | 833/1000 [53:20<10:36,  3.81s/it]Epoch:   834
max of grad d_p:  tensor(357534.0312, device='cuda:0')
min of grad d_p:  tensor(-32420.7676, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.4375, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(-3.7734, device='cuda:0') norm:  tensor(47.6567, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(43.5664, device='cuda:0') mean:  tensor(0.1301, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(286.8015, device='cuda:0') MSE:  tensor(0.0011, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1643, device='cuda:0')
min of d_p_list:  tensor(-0.2288, device='cuda:0')
Epoch:  834  
Training Loss: 372259.46875
Test Loss:  263971.09375
Test Acc:  0.0
Valid Loss:  306267.875
Valid Acc:  0.0
std:  5026.3183913604325 
thres:  378.83704375
Preserved_eigens number check:  59
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  52
 83%|████████▎ | 834/1000 [53:23<10:21,  3.75s/it]Epoch:   835
max of grad d_p:  tensor(358651.4375, device='cuda:0')
min of grad d_p:  tensor(-32277.8477, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.5000, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-3.3672, device='cuda:0') norm:  tensor(41.8220, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(37.5039, device='cuda:0') mean:  tensor(0.0706, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(166.5391, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0091, device='cuda:0')
min of d_p_list:  tensor(-0.0133, device='cuda:0')
Epoch:  835  
Training Loss: 368550.4375
Test Loss:  261328.734375
Test Acc:  0.0
Valid Loss:  303190.6875
Valid Acc:  0.0
std:  4810.294581619001 
thres:  375.30782500000004
Preserved_eigens number check:  52
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 84%|████████▎ | 835/1000 [53:27<10:24,  3.78s/it]Epoch:   836
max of grad d_p:  tensor(356277.3750, device='cuda:0')
min of grad d_p:  tensor(-32131.8828, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.2500, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-3.3262, device='cuda:0') norm:  tensor(42.3764, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(25.3574, device='cuda:0') mean:  tensor(0.0621, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(139.0926, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0410, device='cuda:0')
min of d_p_list:  tensor(-0.0260, device='cuda:0')
Epoch:  836  
Training Loss: 364908.0625
Test Loss:  258715.625
Test Acc:  0.0
Valid Loss:  300241.1875
Valid Acc:  0.0
std:  4752.977118573946 
thres:  371.81508125
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  47
 84%|████████▎ | 836/1000 [53:31<10:19,  3.78s/it]Epoch:   837
max of grad d_p:  tensor(354136.4062, device='cuda:0')
min of grad d_p:  tensor(-32050.5898, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(18.8438, device='cuda:0') mean:  tensor(0.0024, device='cuda:0') min:  tensor(-3.8965, device='cuda:0') norm:  tensor(55.2863, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(33.5078, device='cuda:0') mean:  tensor(0.0385, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(108.8820, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1032, device='cuda:0')
min of d_p_list:  tensor(-0.0795, device='cuda:0')
Epoch:  837  
Training Loss: 361644.5625
Test Loss:  256703.421875
Test Acc:  0.0
Valid Loss:  297574.9375
Valid Acc:  0.0
std:  4767.897078377427 
thres:  368.43190625
Preserved_eigens number check:  47
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 84%|████████▎ | 837/1000 [53:35<10:19,  3.80s/it]Epoch:   838
max of grad d_p:  tensor(355850.7500, device='cuda:0')
min of grad d_p:  tensor(-32189.4707, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.2188, device='cuda:0') mean:  tensor(0.0011, device='cuda:0') min:  tensor(-3.2529, device='cuda:0') norm:  tensor(40.9633, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(14.1523, device='cuda:0') mean:  tensor(0.0530, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(106.9677, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0150, device='cuda:0')
min of d_p_list:  tensor(-0.0118, device='cuda:0')
Epoch:  838  
Training Loss: 358044.5
Test Loss:  254188.65625
Test Acc:  0.0
Valid Loss:  294618.21875
Valid Acc:  0.0
std:  4998.374768987415 
thres:  365.08140625
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  42
 84%|████████▍ | 838/1000 [53:39<10:19,  3.82s/it]Epoch:   839
max of grad d_p:  tensor(354880.5625, device='cuda:0')
min of grad d_p:  tensor(-32007.3008, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.6250, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-3.7100, device='cuda:0') norm:  tensor(47.7744, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(27.1367, device='cuda:0') mean:  tensor(0.0856, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(182.0729, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0093, device='cuda:0')
min of d_p_list:  tensor(-0.0066, device='cuda:0')
Epoch:  839  
Training Loss: 354474.1875
Test Loss:  251690.125
Test Acc:  0.0
Valid Loss:  291687.8125
Valid Acc:  0.0
std:  4952.656139575511 
thres:  361.52434999999997
Preserved_eigens number check:  42
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  40
 84%|████████▍ | 839/1000 [53:42<10:04,  3.76s/it]Epoch:   840
max of grad d_p:  tensor(353419.5625, device='cuda:0')
min of grad d_p:  tensor(-31907.6055, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.9688, device='cuda:0') mean:  tensor(0.0026, device='cuda:0') min:  tensor(-3.7168, device='cuda:0') norm:  tensor(51.8411, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(113.3789, device='cuda:0') mean:  tensor(0.1740, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(395.9059, device='cuda:0') MSE:  tensor(0.0015, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0192, device='cuda:0')
min of d_p_list:  tensor(-0.0256, device='cuda:0')
Epoch:  840  
Training Loss: 350961.53125
Test Loss:  249252.265625
Test Acc:  0.0
Valid Loss:  288808.59375
Valid Acc:  0.0
std:  4959.3814928438915 
thres:  358.00656875
Preserved_eigens number check:  40
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  51
 84%|████████▍ | 840/1000 [53:46<10:04,  3.78s/it]Epoch:   841
max of grad d_p:  tensor(352003.6562, device='cuda:0')
min of grad d_p:  tensor(-31775.3008, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.4141, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-3.1133, device='cuda:0') norm:  tensor(40.0842, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(283.2031, device='cuda:0') mean:  tensor(0.5134, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1192.2322, device='cuda:0') MSE:  tensor(0.0045, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0117, device='cuda:0')
min of d_p_list:  tensor(-0.0064, device='cuda:0')
Epoch:  841  
Training Loss: 347464.65625
Test Loss:  246784.234375
Test Acc:  0.0
Valid Loss:  285920.71875
Valid Acc:  0.0
std:  5012.4673128843815 
thres:  354.51788750000003
Preserved_eigens number check:  51
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  34
 84%|████████▍ | 841/1000 [53:50<10:01,  3.78s/it]Epoch:   842
max of grad d_p:  tensor(350073.4375, device='cuda:0')
min of grad d_p:  tensor(-31654.8594, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.0693, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-3.3145, device='cuda:0') norm:  tensor(38.9991, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(388.5039, device='cuda:0') mean:  tensor(0.3831, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1106.1273, device='cuda:0') MSE:  tensor(0.0042, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0050, device='cuda:0')
min of d_p_list:  tensor(-0.0112, device='cuda:0')
Epoch:  842  
Training Loss: 344000.65625
Test Loss:  244293.34375
Test Acc:  0.0
Valid Loss:  283079.3125
Valid Acc:  0.0
std:  4963.573589104238 
thres:  350.98910625
Preserved_eigens number check:  34
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  136
 84%|████████▍ | 842/1000 [53:54<10:00,  3.80s/it]Epoch:   843
max of grad d_p:  tensor(347611.6562, device='cuda:0')
min of grad d_p:  tensor(-31524.6641, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.7344, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-3.5664, device='cuda:0') norm:  tensor(44.1881, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(42.1836, device='cuda:0') mean:  tensor(0.0783, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(184.3513, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0172, device='cuda:0')
min of d_p_list:  tensor(-0.0208, device='cuda:0')
Epoch:  843  
Training Loss: 340577.03125
Test Loss:  241866.90625
Test Acc:  0.0
Valid Loss:  280225.5625
Valid Acc:  0.0
std:  4915.1916708080935 
thres:  347.4956125
Preserved_eigens number check:  136
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  87
 84%|████████▍ | 843/1000 [53:57<09:52,  3.77s/it]Epoch:   844
max of grad d_p:  tensor(346208., device='cuda:0')
min of grad d_p:  tensor(-31372.2344, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(18.5000, device='cuda:0') mean:  tensor(0.0031, device='cuda:0') min:  tensor(-3.8887, device='cuda:0') norm:  tensor(58.9972, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(28.2207, device='cuda:0') mean:  tensor(0.0491, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(118.7869, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0093, device='cuda:0')
min of d_p_list:  tensor(-0.0142, device='cuda:0')
Epoch:  844  
Training Loss: 337183.65625
Test Loss:  239439.8125
Test Acc:  0.0
Valid Loss:  277434.0
Valid Acc:  0.0
std:  4871.118645521786 
thres:  344.03750625
Preserved_eigens number check:  87
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  41
 84%|████████▍ | 844/1000 [54:01<09:55,  3.82s/it]Epoch:   845
max of grad d_p:  tensor(344097.5625, device='cuda:0')
min of grad d_p:  tensor(-31226.2852, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.4336, device='cuda:0') mean:  tensor(0.0011, device='cuda:0') min:  tensor(-2.9375, device='cuda:0') norm:  tensor(37.9492, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(110.5391, device='cuda:0') mean:  tensor(0.2165, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(468.7600, device='cuda:0') MSE:  tensor(0.0018, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0207, device='cuda:0')
min of d_p_list:  tensor(-0.0142, device='cuda:0')
Epoch:  845  
Training Loss: 333841.4375
Test Loss:  237075.84375
Test Acc:  0.0
Valid Loss:  274589.28125
Valid Acc:  0.0
std:  4817.4092216894705 
thres:  340.6134875
Preserved_eigens number check:  41
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 84%|████████▍ | 845/1000 [54:05<09:51,  3.82s/it]Epoch:   846
max of grad d_p:  tensor(340843.5312, device='cuda:0')
min of grad d_p:  tensor(-31148.5312, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.1562, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-3.6592, device='cuda:0') norm:  tensor(48.1288, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(17.1914, device='cuda:0') mean:  tensor(0.0280, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(67.8316, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0125, device='cuda:0')
min of d_p_list:  tensor(-0.0057, device='cuda:0')
Epoch:  846  
Training Loss: 330515.8125
Test Loss:  234712.59375
Test Acc:  0.0
Valid Loss:  271870.75
Valid Acc:  0.0
std:  4766.7394373588195 
thres:  337.22371875
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  44
 85%|████████▍ | 846/1000 [54:09<09:55,  3.87s/it]Epoch:   847
max of grad d_p:  tensor(338714.1875, device='cuda:0')
min of grad d_p:  tensor(-31029.8359, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.2344, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(-3.3203, device='cuda:0') norm:  tensor(41.8741, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(38.3379, device='cuda:0') mean:  tensor(0.0736, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(168.3871, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0159, device='cuda:0')
min of d_p_list:  tensor(-0.0133, device='cuda:0')
Epoch:  847  
Training Loss: 327221.71875
Test Loss:  232396.828125
Test Acc:  0.0
Valid Loss:  269151.4375
Valid Acc:  0.0
std:  4720.499925085729 
thres:  333.86793125
Preserved_eigens number check:  44
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  70
 85%|████████▍ | 847/1000 [54:13<09:43,  3.81s/it]Epoch:   848
max of grad d_p:  tensor(337075.9375, device='cuda:0')
min of grad d_p:  tensor(-30917.1133, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.6914, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-3.2588, device='cuda:0') norm:  tensor(41.6107, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(25.1602, device='cuda:0') mean:  tensor(0.0361, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(84.9699, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0047, device='cuda:0')
min of d_p_list:  tensor(-0.0074, device='cuda:0')
Epoch:  848  
Training Loss: 323958.0
Test Loss:  230090.234375
Test Acc:  0.0
Valid Loss:  266464.5
Valid Acc:  0.0
std:  4677.004860927625 
thres:  330.544125
Preserved_eigens number check:  70
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 85%|████████▍ | 848/1000 [54:17<09:41,  3.82s/it]Epoch:   849
max of grad d_p:  tensor(335627.1875, device='cuda:0')
min of grad d_p:  tensor(-30773.8848, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(21.7188, device='cuda:0') mean:  tensor(0.0040, device='cuda:0') min:  tensor(-3.7383, device='cuda:0') norm:  tensor(64.6143, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.4881, device='cuda:0') mean:  tensor(0.0196, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(48.5028, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0080, device='cuda:0')
min of d_p_list:  tensor(-0.0102, device='cuda:0')
Epoch:  849  
Training Loss: 320732.0
Test Loss:  227803.8125
Test Acc:  0.0
Valid Loss:  263821.03125
Valid Acc:  0.0
std:  4635.404954649998 
thres:  327.25379375
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  91
 85%|████████▍ | 849/1000 [54:20<09:39,  3.84s/it]Epoch:   850
max of grad d_p:  tensor(333804.5000, device='cuda:0')
min of grad d_p:  tensor(-30651.1953, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(15.6562, device='cuda:0') mean:  tensor(0.0031, device='cuda:0') min:  tensor(-3.6279, device='cuda:0') norm:  tensor(53.6574, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(21.7227, device='cuda:0') mean:  tensor(0.0329, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(80.6454, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0061, device='cuda:0')
min of d_p_list:  tensor(-0.0077, device='cuda:0')
Epoch:  850  
Training Loss: 317535.0625
Test Loss:  225543.6875
Test Acc:  0.0
Valid Loss:  261198.171875
Valid Acc:  0.0
std:  4589.379245010294 
thres:  323.99251875
Preserved_eigens number check:  91
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 85%|████████▌ | 850/1000 [54:24<09:41,  3.88s/it]Epoch:   851
max of grad d_p:  tensor(332050.2188, device='cuda:0')
min of grad d_p:  tensor(-30526.4531, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.8906, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-3.0811, device='cuda:0') norm:  tensor(43.4433, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(59., device='cuda:0') mean:  tensor(0.1338, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(283.7013, device='cuda:0') MSE:  tensor(0.0011, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0056, device='cuda:0')
min of d_p_list:  tensor(-0.0059, device='cuda:0')
Epoch:  851  
Training Loss: 314369.875
Test Loss:  223292.65625
Test Acc:  0.0
Valid Loss:  258627.734375
Valid Acc:  0.0
std:  4543.471384580297 
thres:  320.76333125
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  95
 85%|████████▌ | 851/1000 [54:28<09:33,  3.85s/it]Epoch:   852
max of grad d_p:  tensor(330269.3125, device='cuda:0')
min of grad d_p:  tensor(-30409.0098, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.6250, device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(-3.7617, device='cuda:0') norm:  tensor(46.4581, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(28.0713, device='cuda:0') mean:  tensor(0.0582, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(134.9013, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0279, device='cuda:0')
min of d_p_list:  tensor(-0.0167, device='cuda:0')
Epoch:  852  
Training Loss: 311251.3125
Test Loss:  221137.3125
Test Acc:  0.0
Valid Loss:  256112.21875
Valid Acc:  0.0
std:  4493.831718137374 
thres:  317.56925
Preserved_eigens number check:  95
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 85%|████████▌ | 852/1000 [54:32<09:32,  3.87s/it]Epoch:   853
max of grad d_p:  tensor(329404.2812, device='cuda:0')
min of grad d_p:  tensor(-30270.4453, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(13.1562, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-4.0732, device='cuda:0') norm:  tensor(51.1240, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(11.7886, device='cuda:0') mean:  tensor(0.0267, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(59.4353, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0081, device='cuda:0')
min of d_p_list:  tensor(-0.0055, device='cuda:0')
Epoch:  853  
Training Loss: 308147.71875
Test Loss:  218930.96875
Test Acc:  0.0
Valid Loss:  253580.515625
Valid Acc:  0.0
std:  4448.1174320400705 
thres:  314.40719375
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 85%|████████▌ | 853/1000 [54:36<09:31,  3.88s/it]Epoch:   854
max of grad d_p:  tensor(327814.9688, device='cuda:0')
min of grad d_p:  tensor(-30139.3730, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.9141, device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(-3.4736, device='cuda:0') norm:  tensor(44.5454, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(40.8398, device='cuda:0') mean:  tensor(0.0371, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(97.8876, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0047, device='cuda:0')
min of d_p_list:  tensor(-0.0058, device='cuda:0')
Epoch:  854  
Training Loss: 305075.125
Test Loss:  216754.140625
Test Acc:  0.0
Valid Loss:  251051.734375
Valid Acc:  0.0
std:  4404.214562158757 
thres:  311.27581875
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  69
 85%|████████▌ | 854/1000 [54:40<09:29,  3.90s/it]Epoch:   855
max of grad d_p:  tensor(325849., device='cuda:0')
min of grad d_p:  tensor(-29996.8594, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.4375, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(-3.2363, device='cuda:0') norm:  tensor(40.3341, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(27.5586, device='cuda:0') mean:  tensor(0.0467, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(113.6909, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0125, device='cuda:0')
min of d_p_list:  tensor(-0.0101, device='cuda:0')
Epoch:  855  
Training Loss: 302036.5625
Test Loss:  214530.5
Test Acc:  0.0
Valid Loss:  248526.375
Valid Acc:  0.0
std:  4361.893002559926 
thres:  308.17611875000006
Preserved_eigens number check:  69
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  70
 86%|████████▌ | 855/1000 [54:44<09:27,  3.91s/it]Epoch:   856
max of grad d_p:  tensor(324147.6875, device='cuda:0')
min of grad d_p:  tensor(-29806.3184, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.5586, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-3.5664, device='cuda:0') norm:  tensor(40.8407, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(23.7158, device='cuda:0') mean:  tensor(0.0303, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(85.2335, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0095, device='cuda:0')
min of d_p_list:  tensor(-0.0092, device='cuda:0')
Epoch:  856  
Training Loss: 299027.5625
Test Loss:  212415.1875
Test Acc:  0.0
Valid Loss:  245998.140625
Valid Acc:  0.0
std:  4321.728988133685 
thres:  305.10765625
Preserved_eigens number check:  70
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  40
 86%|████████▌ | 856/1000 [54:48<09:23,  3.91s/it]Epoch:   857
max of grad d_p:  tensor(322138.7812, device='cuda:0')
min of grad d_p:  tensor(-29645.4648, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(13.5312, device='cuda:0') mean:  tensor(0.0023, device='cuda:0') min:  tensor(-3.4980, device='cuda:0') norm:  tensor(47.9491, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(43.9121, device='cuda:0') mean:  tensor(0.1278, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(288.9773, device='cuda:0') MSE:  tensor(0.0011, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0155, device='cuda:0')
min of d_p_list:  tensor(-0.0134, device='cuda:0')
Epoch:  857  
Training Loss: 296056.6875
Test Loss:  210307.671875
Test Acc:  0.0
Valid Loss:  243546.71875
Valid Acc:  0.0
std:  4275.205367033554 
thres:  302.06873125000004
Preserved_eigens number check:  40
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  44
 86%|████████▌ | 857/1000 [54:52<09:24,  3.95s/it]Epoch:   858
max of grad d_p:  tensor(320874.2812, device='cuda:0')
min of grad d_p:  tensor(-29556.4102, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.0088, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.9062, device='cuda:0') norm:  tensor(40.3906, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(57.0664, device='cuda:0') mean:  tensor(0.0744, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(186.9081, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0296, device='cuda:0')
min of d_p_list:  tensor(-0.0335, device='cuda:0')
Epoch:  858  
Training Loss: 293123.53125
Test Loss:  208215.9375
Test Acc:  0.0
Valid Loss:  241090.984375
Valid Acc:  0.0
std:  4226.208150561802 
thres:  299.06389375
Preserved_eigens number check:  44
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 86%|████████▌ | 858/1000 [54:56<09:23,  3.97s/it]Epoch:   859
max of grad d_p:  tensor(318053.2812, device='cuda:0')
min of grad d_p:  tensor(-29298.5488, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.2188, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-3.7949, device='cuda:0') norm:  tensor(48.6179, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(49.8223, device='cuda:0') mean:  tensor(0.1249, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(302.3568, device='cuda:0') MSE:  tensor(0.0011, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0276, device='cuda:0')
min of d_p_list:  tensor(-0.0333, device='cuda:0')
Epoch:  859  
Training Loss: 290256.65625
Test Loss:  206133.484375
Test Acc:  0.0
Valid Loss:  238792.5625
Valid Acc:  0.0
std:  4166.996632608656 
thres:  296.10020000000003
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  65
 86%|████████▌ | 859/1000 [55:00<09:07,  3.88s/it]Epoch:   860
max of grad d_p:  tensor(316703.3438, device='cuda:0')
min of grad d_p:  tensor(-29166.6328, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.3125, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(-3.1719, device='cuda:0') norm:  tensor(39.5214, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(16.9717, device='cuda:0') mean:  tensor(0.0265, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(63.3433, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0168, device='cuda:0')
min of d_p_list:  tensor(-0.0269, device='cuda:0')
Epoch:  860  
Training Loss: 287377.375
Test Loss:  204084.703125
Test Acc:  0.0
Valid Loss:  236408.921875
Valid Acc:  0.0
std:  4115.537031738309 
thres:  293.1683625
Preserved_eigens number check:  65
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 86%|████████▌ | 860/1000 [55:04<09:05,  3.90s/it]Epoch:   861
max of grad d_p:  tensor(314021.4375, device='cuda:0')
min of grad d_p:  tensor(-28901.7227, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.3750, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-3.2334, device='cuda:0') norm:  tensor(41.7561, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(34.1426, device='cuda:0') mean:  tensor(0.0479, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(119.5598, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0153, device='cuda:0')
min of d_p_list:  tensor(-0.0158, device='cuda:0')
Epoch:  861  
Training Loss: 284531.03125
Test Loss:  202092.0
Test Acc:  0.0
Valid Loss:  234109.4375
Valid Acc:  0.0
std:  4072.6307989757215 
thres:  290.26905625
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 86%|████████▌ | 861/1000 [55:07<08:51,  3.82s/it]Epoch:   862
max of grad d_p:  tensor(312626.6875, device='cuda:0')
min of grad d_p:  tensor(-28771.1387, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.6055, device='cuda:0') mean:  tensor(0.0020, device='cuda:0') min:  tensor(-3.5869, device='cuda:0') norm:  tensor(47.0752, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(11.2500, device='cuda:0') mean:  tensor(0.0336, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(74.0596, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0192, device='cuda:0')
min of d_p_list:  tensor(-0.0157, device='cuda:0')
Epoch:  862  
Training Loss: 281700.5625
Test Loss:  200083.46875
Test Acc:  0.0
Valid Loss:  231774.84375
Valid Acc:  0.0
std:  4040.6522438466695 
thres:  287.39783124999997
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 86%|████████▌ | 862/1000 [55:11<08:51,  3.85s/it]Epoch:   863
max of grad d_p:  tensor(310596.0938, device='cuda:0')
min of grad d_p:  tensor(-28641.7969, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.9717, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-4.3125, device='cuda:0') norm:  tensor(42.9121, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(43.6198, device='cuda:0') mean:  tensor(0.0966, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(232.9029, device='cuda:0') MSE:  tensor(0.0009, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0689, device='cuda:0')
min of d_p_list:  tensor(-0.0597, device='cuda:0')
Epoch:  863  
Training Loss: 279118.75
Test Loss:  198348.828125
Test Acc:  0.0
Valid Loss:  229671.125
Valid Acc:  0.0
std:  3953.9124689488735 
thres:  284.596875
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 86%|████████▋ | 863/1000 [55:15<08:45,  3.83s/it]Epoch:   864
max of grad d_p:  tensor(304925.0312, device='cuda:0')
min of grad d_p:  tensor(-28450.0762, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.2461, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-3.5605, device='cuda:0') norm:  tensor(42.6080, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(18.1309, device='cuda:0') mean:  tensor(0.0213, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(56.9311, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0583, device='cuda:0')
min of d_p_list:  tensor(-0.0412, device='cuda:0')
Epoch:  864  
Training Loss: 276406.09375
Test Loss:  196524.328125
Test Acc:  0.0
Valid Loss:  227577.75
Valid Acc:  0.0
std:  3869.244795428835 
thres:  281.82676250000003
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  67
 86%|████████▋ | 864/1000 [55:19<08:41,  3.84s/it]Epoch:   865
max of grad d_p:  tensor(301857.3750, device='cuda:0')
min of grad d_p:  tensor(-28260.7812, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.0938, device='cuda:0') mean:  tensor(0.0020, device='cuda:0') min:  tensor(-3.6924, device='cuda:0') norm:  tensor(48.8520, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(222.7617, device='cuda:0') mean:  tensor(0.2003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(573.9985, device='cuda:0') MSE:  tensor(0.0022, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1352, device='cuda:0')
min of d_p_list:  tensor(-0.0875, device='cuda:0')
Epoch:  865  
Training Loss: 274031.84375
Test Loss:  194720.09375
Test Acc:  0.0
Valid Loss:  225646.9375
Valid Acc:  0.0
std:  3719.8412535957937 
thres:  279.15765625
Preserved_eigens number check:  67
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 86%|████████▋ | 865/1000 [55:23<08:43,  3.88s/it]Epoch:   866
max of grad d_p:  tensor(299968.5938, device='cuda:0')
min of grad d_p:  tensor(-27965.7363, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.9805, device='cuda:0') mean:  tensor(0.0024, device='cuda:0') min:  tensor(-3.0186, device='cuda:0') norm:  tensor(44.7502, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(348.5586, device='cuda:0') mean:  tensor(0.4904, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1227.6099, device='cuda:0') MSE:  tensor(0.0046, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0028, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  866  
Training Loss: 271299.125
Test Loss:  192778.625
Test Acc:  0.0
Valid Loss:  223399.9375
Valid Acc:  0.0
std:  3662.0426178462035 
thres:  276.511275
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  38
 87%|████████▋ | 866/1000 [55:26<08:33,  3.83s/it]Epoch:   867
max of grad d_p:  tensor(298453.3125, device='cuda:0')
min of grad d_p:  tensor(-27842.4434, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.2969, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(-2.7529, device='cuda:0') norm:  tensor(37.9218, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(50.8594, device='cuda:0') mean:  tensor(0.0861, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(197.6758, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2796, device='cuda:0')
min of d_p_list:  tensor(-0.1871, device='cuda:0')
Epoch:  867  
Training Loss: 269922.75
Test Loss:  192187.40625
Test Acc:  0.0
Valid Loss:  222667.421875
Valid Acc:  0.0
std:  3340.3402262508193 
thres:  274.15571250000005
Preserved_eigens number check:  38
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  49
 87%|████████▋ | 867/1000 [55:30<08:30,  3.84s/it]Epoch:   868
max of grad d_p:  tensor(300422.8750, device='cuda:0')
min of grad d_p:  tensor(-27825.1953, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.0938, device='cuda:0') mean:  tensor(0.0026, device='cuda:0') min:  tensor(-3.0645, device='cuda:0') norm:  tensor(47.8786, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(27.3848, device='cuda:0') mean:  tensor(0.0370, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(90.3647, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0415, device='cuda:0')
min of d_p_list:  tensor(-0.0302, device='cuda:0')
Epoch:  868  
Training Loss: 267255.75
Test Loss:  190247.90625
Test Acc:  0.0
Valid Loss:  220368.375
Valid Acc:  0.0
std:  3181.8532841897936 
thres:  271.7831125
Preserved_eigens number check:  49
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 87%|████████▋ | 868/1000 [55:34<08:24,  3.82s/it]Epoch:   869
max of grad d_p:  tensor(297546.9375, device='cuda:0')
min of grad d_p:  tensor(-27683.3945, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.6875, device='cuda:0') mean:  tensor(0.0025, device='cuda:0') min:  tensor(-3.0615, device='cuda:0') norm:  tensor(48.5836, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(16.3018, device='cuda:0') mean:  tensor(0.0333, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(84.7076, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0536, device='cuda:0')
min of d_p_list:  tensor(-0.0357, device='cuda:0')
Epoch:  869  
Training Loss: 264620.1875
Test Loss:  188437.765625
Test Acc:  0.0
Valid Loss:  218195.015625
Valid Acc:  0.0
std:  3248.8451271663444 
thres:  269.42593125
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  36
 87%|████████▋ | 869/1000 [55:38<08:26,  3.86s/it]Epoch:   870
max of grad d_p:  tensor(293901.6250, device='cuda:0')
min of grad d_p:  tensor(-27889.3945, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.3281, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-3.4238, device='cuda:0') norm:  tensor(39.7487, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(81.9707, device='cuda:0') mean:  tensor(0.1379, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(314.8501, device='cuda:0') MSE:  tensor(0.0012, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0058, device='cuda:0')
min of d_p_list:  tensor(-0.0033, device='cuda:0')
Epoch:  870  
Training Loss: 261981.6875
Test Loss:  186561.859375
Test Acc:  0.0
Valid Loss:  216028.375
Valid Acc:  0.0
std:  3403.999272133809 
thres:  267.01590000000004
Preserved_eigens number check:  36
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 87%|████████▋ | 870/1000 [55:42<08:21,  3.85s/it]Epoch:   871
max of grad d_p:  tensor(292399.0625, device='cuda:0')
min of grad d_p:  tensor(-27752.2617, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(13.9375, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-3.5977, device='cuda:0') norm:  tensor(50.6236, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(10.6582, device='cuda:0') mean:  tensor(0.0163, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(40.6417, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0041, device='cuda:0')
min of d_p_list:  tensor(-0.0037, device='cuda:0')
Epoch:  871  
Training Loss: 259369.625
Test Loss:  184706.0625
Test Acc:  0.0
Valid Loss:  213878.90625
Valid Acc:  0.0
std:  3730.763089461391 
thres:  264.63
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  42
 87%|████████▋ | 871/1000 [55:46<08:15,  3.84s/it]Epoch:   872
max of grad d_p:  tensor(290870.7188, device='cuda:0')
min of grad d_p:  tensor(-27625.9766, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.3828, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-2.8027, device='cuda:0') norm:  tensor(40.8513, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(41.8496, device='cuda:0') mean:  tensor(0.0715, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(172.6605, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0058, device='cuda:0')
min of d_p_list:  tensor(-0.0085, device='cuda:0')
Epoch:  872  
Training Loss: 256783.484375
Test Loss:  182846.0
Test Acc:  0.0
Valid Loss:  211724.59375
Valid Acc:  0.0
std:  3704.5785403050995 
thres:  262.002146875
Preserved_eigens number check:  42
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  46
 87%|████████▋ | 872/1000 [55:49<08:07,  3.81s/it]Epoch:   873
max of grad d_p:  tensor(289128., device='cuda:0')
min of grad d_p:  tensor(-27491.7891, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.2500, device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(-2.8691, device='cuda:0') norm:  tensor(40.8009, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(15.8901, device='cuda:0') mean:  tensor(0.0418, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(92.1474, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0773, device='cuda:0')
min of d_p_list:  tensor(-0.0431, device='cuda:0')
Epoch:  873  
Training Loss: 254294.234375
Test Loss:  181090.765625
Test Acc:  0.0
Valid Loss:  209704.9375
Valid Acc:  0.0
std:  3655.9787378940805 
thres:  259.40984375
Preserved_eigens number check:  46
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 87%|████████▋ | 873/1000 [55:53<08:05,  3.83s/it]Epoch:   874
max of grad d_p:  tensor(287953.2500, device='cuda:0')
min of grad d_p:  tensor(-27379.3613, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.3750, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-3.0518, device='cuda:0') norm:  tensor(44.9107, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(21.2383, device='cuda:0') mean:  tensor(0.0699, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(147.3013, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0036, device='cuda:0')
min of d_p_list:  tensor(-0.0053, device='cuda:0')
Epoch:  874  
Training Loss: 251758.46875
Test Loss:  179297.15625
Test Acc:  0.0
Valid Loss:  207618.9375
Valid Acc:  0.0
std:  3609.487448830058 
thres:  256.8375
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  174
 87%|████████▋ | 874/1000 [55:57<08:10,  3.89s/it]Epoch:   875
max of grad d_p:  tensor(286679.5938, device='cuda:0')
min of grad d_p:  tensor(-27250.0449, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.6562, device='cuda:0') mean:  tensor(0.0025, device='cuda:0') min:  tensor(-3.0703, device='cuda:0') norm:  tensor(47.8348, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(13.1230, device='cuda:0') mean:  tensor(0.0411, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(87.0614, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0556, device='cuda:0')
min of d_p_list:  tensor(-0.0439, device='cuda:0')
Epoch:  875  
Training Loss: 249343.8125
Test Loss:  177587.1875
Test Acc:  0.0
Valid Loss:  205752.15625
Valid Acc:  0.0
std:  3546.590154660772 
thres:  254.309925
Preserved_eigens number check:  174
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  48
 88%|████████▊ | 875/1000 [56:01<08:08,  3.90s/it]Epoch:   876
max of grad d_p:  tensor(286474.6250, device='cuda:0')
min of grad d_p:  tensor(-26963.3926, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.5625, device='cuda:0') mean:  tensor(0.0025, device='cuda:0') min:  tensor(-3.1094, device='cuda:0') norm:  tensor(48.7170, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(21.0957, device='cuda:0') mean:  tensor(0.0334, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(84.2083, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0088, device='cuda:0')
min of d_p_list:  tensor(-0.0118, device='cuda:0')
Epoch:  876  
Training Loss: 246863.625
Test Loss:  175825.34375
Test Acc:  0.0
Valid Loss:  203668.09375
Valid Acc:  0.0
std:  3505.9469769431366 
thres:  251.808725
Preserved_eigens number check:  48
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 88%|████████▊ | 876/1000 [56:05<07:47,  3.77s/it]Epoch:   877
max of grad d_p:  tensor(285172.4688, device='cuda:0')
min of grad d_p:  tensor(-26835.7480, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.9395, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(-3.3438, device='cuda:0') norm:  tensor(39.1228, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(20.7773, device='cuda:0') mean:  tensor(0.0550, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(127.5660, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0149, device='cuda:0')
min of d_p_list:  tensor(-0.0164, device='cuda:0')
Epoch:  877  
Training Loss: 244405.59375
Test Loss:  174053.640625
Test Acc:  0.0
Valid Loss:  201668.6875
Valid Acc:  0.0
std:  3489.2408121643653 
thres:  249.333146875
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  47
 88%|████████▊ | 877/1000 [56:09<07:45,  3.79s/it]Epoch:   878
max of grad d_p:  tensor(283673.3750, device='cuda:0')
min of grad d_p:  tensor(-26683.1445, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.9062, device='cuda:0') mean:  tensor(0.0027, device='cuda:0') min:  tensor(-3.1094, device='cuda:0') norm:  tensor(48.3637, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(14.3154, device='cuda:0') mean:  tensor(0.0309, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(77.9703, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0072, device='cuda:0')
min of d_p_list:  tensor(-0.0057, device='cuda:0')
Epoch:  878  
Training Loss: 241968.421875
Test Loss:  172301.5625
Test Acc:  0.0
Valid Loss:  199642.0
Valid Acc:  0.0
std:  3467.4388707605126 
thres:  246.867984375
Preserved_eigens number check:  47
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 88%|████████▊ | 878/1000 [56:12<07:38,  3.76s/it]Epoch:   879
max of grad d_p:  tensor(282465.7812, device='cuda:0')
min of grad d_p:  tensor(-26575.5527, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(15.6562, device='cuda:0') mean:  tensor(0.0028, device='cuda:0') min:  tensor(-3.4023, device='cuda:0') norm:  tensor(53.4227, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(40.9121, device='cuda:0') mean:  tensor(0.0427, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(117.8613, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0063, device='cuda:0')
min of d_p_list:  tensor(-0.0057, device='cuda:0')
Epoch:  879  
Training Loss: 239557.40625
Test Loss:  170571.46875
Test Acc:  0.0
Valid Loss:  197645.546875
Valid Acc:  0.0
std:  3460.3523371510255 
thres:  244.42777187500002
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  63
 88%|████████▊ | 879/1000 [56:16<07:35,  3.77s/it]Epoch:   880
max of grad d_p:  tensor(281058.3438, device='cuda:0')
min of grad d_p:  tensor(-26432.0215, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.2188, device='cuda:0') mean:  tensor(0.0026, device='cuda:0') min:  tensor(-3.1133, device='cuda:0') norm:  tensor(48.3098, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.3086, device='cuda:0') mean:  tensor(0.0189, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(38.3926, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0071, device='cuda:0')
min of d_p_list:  tensor(-0.0103, device='cuda:0')
Epoch:  880  
Training Loss: 237172.65625
Test Loss:  168839.453125
Test Acc:  0.0
Valid Loss:  195646.0
Valid Acc:  0.0
std:  3426.7194194803506 
thres:  241.993540625
Preserved_eigens number check:  63
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  89
 88%|████████▊ | 880/1000 [56:20<07:37,  3.81s/it]Epoch:   881
max of grad d_p:  tensor(279610.3750, device='cuda:0')
min of grad d_p:  tensor(-26331.2031, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.5020, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(-2.8574, device='cuda:0') norm:  tensor(42.4996, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(15.6387, device='cuda:0') mean:  tensor(0.0397, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(95.0069, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0368, device='cuda:0')
min of d_p_list:  tensor(-0.0222, device='cuda:0')
Epoch:  881  
Training Loss: 234829.90625
Test Loss:  167238.703125
Test Acc:  0.0
Valid Loss:  193609.453125
Valid Acc:  0.0
std:  3386.7355417115446 
thres:  239.586796875
Preserved_eigens number check:  89
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  54
 88%|████████▊ | 881/1000 [56:24<07:32,  3.81s/it]Epoch:   882
max of grad d_p:  tensor(279515.8750, device='cuda:0')
min of grad d_p:  tensor(-26098.1016, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.0938, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-3.2373, device='cuda:0') norm:  tensor(47.1833, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.6921, device='cuda:0') mean:  tensor(0.0221, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(46.9365, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0351, device='cuda:0')
min of d_p_list:  tensor(-0.0486, device='cuda:0')
Epoch:  882  
Training Loss: 232509.28125
Test Loss:  165635.90625
Test Acc:  0.0
Valid Loss:  191735.84375
Valid Acc:  0.0
std:  3344.1250582936955 
thres:  237.207534375
Preserved_eigens number check:  54
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 88%|████████▊ | 882/1000 [56:28<07:32,  3.83s/it]Epoch:   883
max of grad d_p:  tensor(279888.5625, device='cuda:0')
min of grad d_p:  tensor(-26056.0391, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.3105, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-3.2520, device='cuda:0') norm:  tensor(46.6497, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(10.1377, device='cuda:0') mean:  tensor(0.0305, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(63.7541, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0398, device='cuda:0')
min of d_p_list:  tensor(-0.0451, device='cuda:0')
Epoch:  883  
Training Loss: 230254.015625
Test Loss:  164057.765625
Test Acc:  0.0
Valid Loss:  189765.46875
Valid Acc:  0.0
std:  3291.0719374840946 
thres:  234.86465312500002
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  20
 88%|████████▊ | 883/1000 [56:32<07:32,  3.87s/it]Epoch:   884
max of grad d_p:  tensor(280934.3750, device='cuda:0')
min of grad d_p:  tensor(-25554.4180, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.6328, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(-4.3906, device='cuda:0') norm:  tensor(39.7088, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(37.6477, device='cuda:0') mean:  tensor(0.0879, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(185.8192, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0068, device='cuda:0')
min of d_p_list:  tensor(-0.0047, device='cuda:0')
Epoch:  884  
Training Loss: 227959.0
Test Loss:  162414.375
Test Acc:  0.0
Valid Loss:  187858.671875
Valid Acc:  0.0
std:  3253.2224077395554 
thres:  232.544971875
Preserved_eigens number check:  20
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 88%|████████▊ | 884/1000 [56:35<07:25,  3.84s/it]Epoch:   885
max of grad d_p:  tensor(279436.4062, device='cuda:0')
min of grad d_p:  tensor(-25456.6445, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.3125, device='cuda:0') mean:  tensor(0.0028, device='cuda:0') min:  tensor(-3.2949, device='cuda:0') norm:  tensor(50.9588, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(10.5842, device='cuda:0') mean:  tensor(0.0295, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(63.1918, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0114, device='cuda:0')
min of d_p_list:  tensor(-0.0083, device='cuda:0')
Epoch:  885  
Training Loss: 225687.28125
Test Loss:  160794.046875
Test Acc:  0.0
Valid Loss:  185971.875
Valid Acc:  0.0
std:  3229.4572431466718 
thres:  230.247896875
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 88%|████████▊ | 885/1000 [56:39<07:28,  3.90s/it]Epoch:   886
max of grad d_p:  tensor(277948.0938, device='cuda:0')
min of grad d_p:  tensor(-25338.9297, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.0508, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(-3.1807, device='cuda:0') norm:  tensor(40.6586, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(13.7363, device='cuda:0') mean:  tensor(0.0268, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(58.8671, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0031, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  886  
Training Loss: 223436.765625
Test Loss:  159189.171875
Test Acc:  0.0
Valid Loss:  184104.4375
Valid Acc:  0.0
std:  3211.9445436836572 
thres:  227.96926875
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  43
 89%|████████▊ | 886/1000 [56:43<07:26,  3.92s/it]Epoch:   887
max of grad d_p:  tensor(276555.6250, device='cuda:0')
min of grad d_p:  tensor(-25224.4297, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.1309, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-3.4551, device='cuda:0') norm:  tensor(39.9990, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(35.9766, device='cuda:0') mean:  tensor(0.0325, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(92.2259, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0202, device='cuda:0')
min of d_p_list:  tensor(-0.0285, device='cuda:0')
Epoch:  887  
Training Loss: 221235.671875
Test Loss:  157578.6875
Test Acc:  0.0
Valid Loss:  182284.84375
Valid Acc:  0.0
std:  3190.413718166722 
thres:  225.714546875
Preserved_eigens number check:  43
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 89%|████████▊ | 887/1000 [56:47<07:22,  3.91s/it]Epoch:   888
max of grad d_p:  tensor(274365.8438, device='cuda:0')
min of grad d_p:  tensor(-25060.1172, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.2188, device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(-3.2920, device='cuda:0') norm:  tensor(43.6796, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.1016, device='cuda:0') mean:  tensor(0.0198, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(43.1990, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0201, device='cuda:0')
min of d_p_list:  tensor(-0.0258, device='cuda:0')
Epoch:  888  
Training Loss: 219035.71875
Test Loss:  156004.78125
Test Acc:  0.0
Valid Loss:  180487.171875
Valid Acc:  0.0
std:  3153.5259663199076 
thres:  223.4708875
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  38
 89%|████████▉ | 888/1000 [56:51<07:18,  3.91s/it]Epoch:   889
max of grad d_p:  tensor(272967.1875, device='cuda:0')
min of grad d_p:  tensor(-24996.4961, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.5117, device='cuda:0') mean:  tensor(0.0024, device='cuda:0') min:  tensor(-3.2998, device='cuda:0') norm:  tensor(47.5338, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(20.3555, device='cuda:0') mean:  tensor(0.0260, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(63.0344, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0337, device='cuda:0')
min of d_p_list:  tensor(-0.0427, device='cuda:0')
Epoch:  889  
Training Loss: 216866.6875
Test Loss:  154456.0625
Test Acc:  0.0
Valid Loss:  178764.03125
Valid Acc:  0.0
std:  3117.308281485231 
thres:  221.252425
Preserved_eigens number check:  38
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  47
 89%|████████▉ | 889/1000 [56:55<07:13,  3.90s/it]Epoch:   890
max of grad d_p:  tensor(272345.9375, device='cuda:0')
min of grad d_p:  tensor(-24911.4277, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.5625, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-3.3057, device='cuda:0') norm:  tensor(47.6655, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(276.6230, device='cuda:0') mean:  tensor(0.2336, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(721.0474, device='cuda:0') MSE:  tensor(0.0027, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0918, device='cuda:0')
min of d_p_list:  tensor(-0.1289, device='cuda:0')
Epoch:  890  
Training Loss: 215176.28125
Test Loss:  153257.0625
Test Acc:  0.0
Valid Loss:  177494.046875
Valid Acc:  0.0
std:  2957.8168747095224 
thres:  219.150225
Preserved_eigens number check:  47
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 89%|████████▉ | 890/1000 [56:59<07:09,  3.90s/it]Epoch:   891
max of grad d_p:  tensor(271755.9688, device='cuda:0')
min of grad d_p:  tensor(-24576.5586, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.1445, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(-3.2969, device='cuda:0') norm:  tensor(38.7597, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(16.7109, device='cuda:0') mean:  tensor(0.0367, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(89.0926, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0120, device='cuda:0')
min of d_p_list:  tensor(-0.0122, device='cuda:0')
Epoch:  891  
Training Loss: 213034.234375
Test Loss:  151717.921875
Test Acc:  0.0
Valid Loss:  175715.65625
Valid Acc:  0.0
std:  2868.16257682333 
thres:  217.06971875
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 89%|████████▉ | 891/1000 [57:03<07:03,  3.88s/it]Epoch:   892
max of grad d_p:  tensor(271321.8125, device='cuda:0')
min of grad d_p:  tensor(-24387.1816, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.0625, device='cuda:0') mean:  tensor(0.0020, device='cuda:0') min:  tensor(-3.4678, device='cuda:0') norm:  tensor(44.2587, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(84.1797, device='cuda:0') mean:  tensor(0.1407, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(344.5809, device='cuda:0') MSE:  tensor(0.0013, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0311, device='cuda:0')
min of d_p_list:  tensor(-0.0314, device='cuda:0')
Epoch:  892  
Training Loss: 210951.265625
Test Loss:  150271.078125
Test Acc:  0.0
Valid Loss:  174048.53125
Valid Acc:  0.0
std:  2830.487013062113 
thres:  215.0128375
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  45
 89%|████████▉ | 892/1000 [57:07<06:57,  3.87s/it]Epoch:   893
max of grad d_p:  tensor(271147.5000, device='cuda:0')
min of grad d_p:  tensor(-24205.5723, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.4863, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-2.9580, device='cuda:0') norm:  tensor(39.3255, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(30.4434, device='cuda:0') mean:  tensor(0.0634, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(159.1342, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2881, device='cuda:0')
min of d_p_list:  tensor(-0.5610, device='cuda:0')
Epoch:  893  
Training Loss: 214105.84375
Test Loss:  152522.234375
Test Acc:  0.0
Valid Loss:  177698.09375
Valid Acc:  0.0
std:  1991.813960357689 
thres:  214.0268625
Preserved_eigens number check:  45
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  59
 89%|████████▉ | 893/1000 [57:11<07:01,  3.94s/it]Epoch:   894
max of grad d_p:  tensor(291389.0312, device='cuda:0')
min of grad d_p:  tensor(-24836.9824, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.4688, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-3.1152, device='cuda:0') norm:  tensor(46.6544, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(36.4746, device='cuda:0') mean:  tensor(0.0337, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(91.8177, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0261, device='cuda:0')
min of d_p_list:  tensor(-0.0277, device='cuda:0')
Epoch:  894  
Training Loss: 211983.4375
Test Loss:  151036.71875
Test Acc:  0.0
Valid Loss:  175995.09375
Valid Acc:  0.0
std:  1495.216897368332 
thres:  213.0502125
Preserved_eigens number check:  59
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  37
 89%|████████▉ | 894/1000 [57:15<06:55,  3.92s/it]Epoch:   895
max of grad d_p:  tensor(287811.6562, device='cuda:0')
min of grad d_p:  tensor(-24620.6270, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.8750, device='cuda:0') mean:  tensor(0.0020, device='cuda:0') min:  tensor(-2.9736, device='cuda:0') norm:  tensor(45.2564, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(26.6562, device='cuda:0') mean:  tensor(0.0612, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(129.9296, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0133, device='cuda:0')
min of d_p_list:  tensor(-0.0097, device='cuda:0')
Epoch:  895  
Training Loss: 209873.5
Test Loss:  149526.390625
Test Acc:  0.0
Valid Loss:  174201.484375
Valid Acc:  0.0
std:  1491.69729045395 
thres:  211.98965625
Preserved_eigens number check:  37
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  39
 90%|████████▉ | 895/1000 [57:18<06:49,  3.90s/it]Epoch:   896
max of grad d_p:  tensor(286319.3750, device='cuda:0')
min of grad d_p:  tensor(-24516.9844, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.6797, device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(-2.8193, device='cuda:0') norm:  tensor(43.9116, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(46.4531, device='cuda:0') mean:  tensor(0.1369, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(296.7349, device='cuda:0') MSE:  tensor(0.0011, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0122, device='cuda:0')
min of d_p_list:  tensor(-0.0223, device='cuda:0')
Epoch:  896  
Training Loss: 207790.25
Test Loss:  148056.53125
Test Acc:  0.0
Valid Loss:  172506.125
Valid Acc:  0.0
std:  2105.6969867480934 
thres:  210.940859375
Preserved_eigens number check:  39
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  165
 90%|████████▉ | 896/1000 [57:22<06:44,  3.89s/it]Epoch:   897
max of grad d_p:  tensor(283583.2500, device='cuda:0')
min of grad d_p:  tensor(-24275.1484, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.1562, device='cuda:0') mean:  tensor(0.0025, device='cuda:0') min:  tensor(-2.4688, device='cuda:0') norm:  tensor(42.5669, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(23.1035, device='cuda:0') mean:  tensor(0.0439, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(101.6841, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0397, device='cuda:0')
min of d_p_list:  tensor(-0.0755, device='cuda:0')
Epoch:  897  
Training Loss: 205606.65625
Test Loss:  146870.8125
Test Acc:  0.0
Valid Loss:  170785.71875
Valid Acc:  0.0
std:  2997.013307092684 
thres:  209.8719375
Preserved_eigens number check:  165
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  73
 90%|████████▉ | 897/1000 [57:26<06:42,  3.91s/it]Epoch:   898
max of grad d_p:  tensor(283068.6250, device='cuda:0')
min of grad d_p:  tensor(-24028.4629, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.4883, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-2.6982, device='cuda:0') norm:  tensor(39.7607, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(42.7598, device='cuda:0') mean:  tensor(0.0572, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(176.9417, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0111, device='cuda:0')
min of d_p_list:  tensor(-0.0150, device='cuda:0')
Epoch:  898  
Training Loss: 203559.1875
Test Loss:  145420.984375
Test Acc:  0.0
Valid Loss:  169066.203125
Valid Acc:  0.0
std:  2986.2653141350734 
thres:  207.76260625
Preserved_eigens number check:  73
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  61
 90%|████████▉ | 898/1000 [57:30<06:37,  3.89s/it]Epoch:   899
max of grad d_p:  tensor(281046.4375, device='cuda:0')
min of grad d_p:  tensor(-23981.4375, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.9805, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(-3.0156, device='cuda:0') norm:  tensor(36.9321, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(20.2832, device='cuda:0') mean:  tensor(0.0339, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(83.6765, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0432, device='cuda:0')
min of d_p_list:  tensor(-0.0591, device='cuda:0')
Epoch:  899  
Training Loss: 201608.4375
Test Loss:  144134.703125
Test Acc:  0.0
Valid Loss:  167483.78125
Valid Acc:  0.0
std:  2936.6359731683206 
thres:  205.68760625000002
Preserved_eigens number check:  61
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  40
 90%|████████▉ | 899/1000 [57:34<06:32,  3.88s/it]Epoch:   900
max of grad d_p:  tensor(280853.9688, device='cuda:0')
min of grad d_p:  tensor(-23809.3320, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.9727, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-3.1953, device='cuda:0') norm:  tensor(46.5236, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(17.3984, device='cuda:0') mean:  tensor(0.0406, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(95.7747, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0657, device='cuda:0')
min of d_p_list:  tensor(-0.0385, device='cuda:0')
Epoch:  900  
Training Loss: 199716.59375
Test Loss:  142707.40625
Test Acc:  0.0
Valid Loss:  165761.03125
Valid Acc:  0.0
std:  2850.1890838728796 
thres:  203.656225
Preserved_eigens number check:  40
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  96
 90%|█████████ | 900/1000 [57:38<06:27,  3.87s/it]Epoch:   901
max of grad d_p:  tensor(281967.4062, device='cuda:0')
min of grad d_p:  tensor(-23743.3809, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.1992, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(-3.7891, device='cuda:0') norm:  tensor(40.8311, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(14.4766, device='cuda:0') mean:  tensor(0.0353, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(85.4957, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0269, device='cuda:0')
min of d_p_list:  tensor(-0.0327, device='cuda:0')
Epoch:  901  
Training Loss: 197769.125
Test Loss:  141226.390625
Test Acc:  0.0
Valid Loss:  164124.84375
Valid Acc:  0.0
std:  2760.474000072836 
thres:  201.65200000000002
Preserved_eigens number check:  96
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 90%|█████████ | 901/1000 [57:42<06:22,  3.86s/it]Epoch:   902
max of grad d_p:  tensor(281052.5938, device='cuda:0')
min of grad d_p:  tensor(-23735.5156, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.2188, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-2.8926, device='cuda:0') norm:  tensor(40.5409, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(43.8730, device='cuda:0') mean:  tensor(0.0970, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(213.5763, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0186, device='cuda:0')
min of d_p_list:  tensor(-0.0200, device='cuda:0')
Epoch:  902  
Training Loss: 195806.390625
Test Loss:  139878.5625
Test Acc:  0.0
Valid Loss:  162522.375
Valid Acc:  0.0
std:  2735.8320551782094 
thres:  199.69194687499999
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  31
 90%|█████████ | 902/1000 [57:46<06:18,  3.86s/it]Epoch:   903
max of grad d_p:  tensor(278783., device='cuda:0')
min of grad d_p:  tensor(-23735.8379, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.3711, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-2.7119, device='cuda:0') norm:  tensor(39.5803, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(224.1035, device='cuda:0') mean:  tensor(0.4702, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1068.6543, device='cuda:0') MSE:  tensor(0.0040, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0316, device='cuda:0')
min of d_p_list:  tensor(-0.0352, device='cuda:0')
Epoch:  903  
Training Loss: 193882.15625
Test Loss:  138534.1875
Test Acc:  0.0
Valid Loss:  160953.6875
Valid Acc:  0.0
std:  2738.3577364068165 
thres:  197.75654062499999
Preserved_eigens number check:  31
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  113
 90%|█████████ | 903/1000 [57:49<06:14,  3.86s/it]Epoch:   904
max of grad d_p:  tensor(278026.8750, device='cuda:0')
min of grad d_p:  tensor(-23752.4277, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.6895, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(-3.1484, device='cuda:0') norm:  tensor(41.3899, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(31.8705, device='cuda:0') mean:  tensor(0.0668, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(181.7456, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0079, device='cuda:0')
min of d_p_list:  tensor(-0.0063, device='cuda:0')
Epoch:  904  
Training Loss: 191943.75
Test Loss:  137177.28125
Test Acc:  0.0
Valid Loss:  159341.03125
Valid Acc:  0.0
std:  2748.2068292840404 
thres:  195.823603125
Preserved_eigens number check:  113
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 90%|█████████ | 904/1000 [57:53<06:06,  3.82s/it]Epoch:   905
max of grad d_p:  tensor(276627.5000, device='cuda:0')
min of grad d_p:  tensor(-23696.3301, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.2324, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-3.1289, device='cuda:0') norm:  tensor(46.7285, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(42.5215, device='cuda:0') mean:  tensor(0.0595, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(152.0435, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0466, device='cuda:0')
min of d_p_list:  tensor(-0.0496, device='cuda:0')
Epoch:  905  
Training Loss: 190079.234375
Test Loss:  135869.5625
Test Acc:  0.0
Valid Loss:  157912.234375
Valid Acc:  0.0
std:  2721.391595036472 
thres:  193.89613125
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  43
 90%|█████████ | 905/1000 [57:57<06:06,  3.86s/it]Epoch:   906
max of grad d_p:  tensor(274005.5000, device='cuda:0')
min of grad d_p:  tensor(-23379.5312, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.2500, device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(-3.2734, device='cuda:0') norm:  tensor(46.7461, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(10.2148, device='cuda:0') mean:  tensor(0.0243, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(53.0219, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0108, device='cuda:0')
min of d_p_list:  tensor(-0.0077, device='cuda:0')
Epoch:  906  
Training Loss: 188187.65625
Test Loss:  134555.40625
Test Acc:  0.0
Valid Loss:  156356.96875
Valid Acc:  0.0
std:  2692.7888377782765 
thres:  191.9798375
Preserved_eigens number check:  43
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 91%|█████████ | 906/1000 [58:01<05:59,  3.82s/it]Epoch:   907
max of grad d_p:  tensor(272020.3125, device='cuda:0')
min of grad d_p:  tensor(-23297.0977, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.8125, device='cuda:0') mean:  tensor(0.0031, device='cuda:0') min:  tensor(-2.8096, device='cuda:0') norm:  tensor(50.3164, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(18.2842, device='cuda:0') mean:  tensor(0.0439, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(106.7329, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0049, device='cuda:0')
min of d_p_list:  tensor(-0.0044, device='cuda:0')
Epoch:  907  
Training Loss: 186311.25
Test Loss:  133212.484375
Test Acc:  0.0
Valid Loss:  154788.5
Valid Acc:  0.0
std:  2672.6165064715256 
thres:  190.08080937500003
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  71
 91%|█████████ | 907/1000 [58:05<05:59,  3.86s/it]Epoch:   908
max of grad d_p:  tensor(270460.5000, device='cuda:0')
min of grad d_p:  tensor(-23183.7500, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.3750, device='cuda:0') mean:  tensor(0.0029, device='cuda:0') min:  tensor(-3.0508, device='cuda:0') norm:  tensor(48.0050, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1888.5703, device='cuda:0') mean:  tensor(3.5537, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(9086.0078, device='cuda:0') MSE:  tensor(0.0341, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0112, device='cuda:0')
min of d_p_list:  tensor(-0.0118, device='cuda:0')
Epoch:  908  
Training Loss: 184454.96875
Test Loss:  131863.8125
Test Acc:  0.0
Valid Loss:  153240.0
Valid Acc:  0.0
std:  2651.032508103859 
thres:  188.195371875
Preserved_eigens number check:  71
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  35
 91%|█████████ | 908/1000 [58:09<05:55,  3.87s/it]Epoch:   909
max of grad d_p:  tensor(269298., device='cuda:0')
min of grad d_p:  tensor(-23109.1855, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.8516, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-2.8516, device='cuda:0') norm:  tensor(42.9995, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(30.6348, device='cuda:0') mean:  tensor(0.0605, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(144.3105, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0193, device='cuda:0')
min of d_p_list:  tensor(-0.0168, device='cuda:0')
Epoch:  909  
Training Loss: 182633.53125
Test Loss:  130480.4140625
Test Acc:  0.0
Valid Loss:  151704.25
Valid Acc:  0.0
std:  2633.9158957897175 
thres:  186.333328125
Preserved_eigens number check:  35
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  38
 91%|█████████ | 909/1000 [58:12<05:48,  3.83s/it]Epoch:   910
max of grad d_p:  tensor(267778.4062, device='cuda:0')
min of grad d_p:  tensor(-22788.9121, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.3438, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-3.9395, device='cuda:0') norm:  tensor(43.1291, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(23.6357, device='cuda:0') mean:  tensor(0.0452, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(121.1923, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0088, device='cuda:0')
min of d_p_list:  tensor(-0.0082, device='cuda:0')
Epoch:  910  
Training Loss: 180814.875
Test Loss:  129167.5859375
Test Acc:  0.0
Valid Loss:  150160.59375
Valid Acc:  0.0
std:  2605.509741439163 
thres:  184.48045625
Preserved_eigens number check:  38
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  113
 91%|█████████ | 910/1000 [58:16<05:43,  3.82s/it]Epoch:   911
max of grad d_p:  tensor(267160.5625, device='cuda:0')
min of grad d_p:  tensor(-22715.7285, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.3438, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-3.2188, device='cuda:0') norm:  tensor(46.3957, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(19.0254, device='cuda:0') mean:  tensor(0.0339, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(80.8315, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0581, device='cuda:0')
min of d_p_list:  tensor(-0.0936, device='cuda:0')
Epoch:  911  
Training Loss: 179054.96875
Test Loss:  127854.6015625
Test Acc:  0.0
Valid Loss:  148645.625
Valid Acc:  0.0
std:  2567.286179676776 
thres:  182.65391875
Preserved_eigens number check:  113
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 91%|█████████ | 911/1000 [58:20<05:41,  3.84s/it]Epoch:   912
max of grad d_p:  tensor(266451.0625, device='cuda:0')
min of grad d_p:  tensor(-22710.5332, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.1299, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-3.9180, device='cuda:0') norm:  tensor(38.7196, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(201.7715, device='cuda:0') mean:  tensor(0.2897, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(794.0292, device='cuda:0') MSE:  tensor(0.0030, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0141, device='cuda:0')
min of d_p_list:  tensor(-0.0127, device='cuda:0')
Epoch:  912  
Training Loss: 177273.859375
Test Loss:  126617.984375
Test Acc:  0.0
Valid Loss:  147181.3125
Valid Acc:  0.0
std:  2537.2769965586385 
thres:  180.84644062499999
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  35
 91%|█████████ | 912/1000 [58:24<05:40,  3.86s/it]Epoch:   913
max of grad d_p:  tensor(264634.5625, device='cuda:0')
min of grad d_p:  tensor(-22505.6992, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.2744, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-3.6562, device='cuda:0') norm:  tensor(39.1213, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(12.3027, device='cuda:0') mean:  tensor(0.0222, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(52.3729, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1129, device='cuda:0')
min of d_p_list:  tensor(-0.0746, device='cuda:0')
Epoch:  913  
Training Loss: 175616.84375
Test Loss:  125449.3671875
Test Acc:  0.0
Valid Loss:  145732.96875
Valid Acc:  0.0
std:  2485.702730790505 
thres:  179.078815625
Preserved_eigens number check:  35
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 91%|█████████▏| 913/1000 [58:28<05:38,  3.89s/it]Epoch:   914
max of grad d_p:  tensor(263054., device='cuda:0')
min of grad d_p:  tensor(-22355.2070, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.7129, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-3.6855, device='cuda:0') norm:  tensor(43.7193, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(168.4156, device='cuda:0') mean:  tensor(0.3708, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(826.0641, device='cuda:0') MSE:  tensor(0.0031, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0104, device='cuda:0')
min of d_p_list:  tensor(-0.0069, device='cuda:0')
Epoch:  914  
Training Loss: 173866.75
Test Loss:  124195.578125
Test Acc:  0.0
Valid Loss:  144279.109375
Valid Acc:  0.0
std:  2451.608636667527 
thres:  177.325459375
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  48
 91%|█████████▏| 914/1000 [58:32<05:32,  3.87s/it]Epoch:   915
max of grad d_p:  tensor(261545.4688, device='cuda:0')
min of grad d_p:  tensor(-22271.6523, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.0781, device='cuda:0') mean:  tensor(0.0020, device='cuda:0') min:  tensor(-3.7578, device='cuda:0') norm:  tensor(45.6624, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(28.6895, device='cuda:0') mean:  tensor(0.0811, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(190.5885, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0152, device='cuda:0')
min of d_p_list:  tensor(-0.0163, device='cuda:0')
Epoch:  915  
Training Loss: 172137.75
Test Loss:  122968.1953125
Test Acc:  0.0
Valid Loss:  142817.5
Valid Acc:  0.0
std:  2438.4311365817903 
thres:  175.590034375
Preserved_eigens number check:  48
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 92%|█████████▏| 915/1000 [58:36<05:28,  3.87s/it]Epoch:   916
max of grad d_p:  tensor(259427.5000, device='cuda:0')
min of grad d_p:  tensor(-22134.5254, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.6719, device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(-3.7520, device='cuda:0') norm:  tensor(44.5358, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(13.7578, device='cuda:0') mean:  tensor(0.0423, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(90.7426, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1961, device='cuda:0')
min of d_p_list:  tensor(-0.1143, device='cuda:0')
Epoch:  916  
Training Loss: 171104.5
Test Loss:  122488.890625
Test Acc:  0.0
Valid Loss:  141781.09375
Valid Acc:  0.0
std:  2245.083062007395 
thres:  173.999940625
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  45
 92%|█████████▏| 916/1000 [58:39<05:25,  3.87s/it]Epoch:   917
max of grad d_p:  tensor(257297.9688, device='cuda:0')
min of grad d_p:  tensor(-22091.3281, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.7656, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-3.3750, device='cuda:0') norm:  tensor(44.5245, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(13.4688, device='cuda:0') mean:  tensor(0.0299, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(70.0303, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0166, device='cuda:0')
min of d_p_list:  tensor(-0.0122, device='cuda:0')
Epoch:  917  
Training Loss: 169401.46875
Test Loss:  121275.2109375
Test Acc:  0.0
Valid Loss:  140368.53125
Valid Acc:  0.0
std:  2155.6661406446674 
thres:  172.4254625
Preserved_eigens number check:  45
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  82
 92%|█████████▏| 917/1000 [58:43<05:21,  3.87s/it]Epoch:   918
max of grad d_p:  tensor(255498.3750, device='cuda:0')
min of grad d_p:  tensor(-22026.5195, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.6172, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-6.2969, device='cuda:0') norm:  tensor(37.6848, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(10.4863, device='cuda:0') mean:  tensor(0.0245, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(56.3343, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0053, device='cuda:0')
min of d_p_list:  tensor(-0.0062, device='cuda:0')
Epoch:  918  
Training Loss: 167712.046875
Test Loss:  120080.5078125
Test Acc:  0.0
Valid Loss:  138950.390625
Valid Acc:  0.0
std:  2133.949033775174 
thres:  170.844503125
Preserved_eigens number check:  82
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  41
 92%|█████████▏| 918/1000 [58:47<05:12,  3.81s/it]Epoch:   919
max of grad d_p:  tensor(253742.6562, device='cuda:0')
min of grad d_p:  tensor(-21930.8652, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.5469, device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(-3.8496, device='cuda:0') norm:  tensor(45.4779, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(326.4258, device='cuda:0') mean:  tensor(0.3705, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1027.5237, device='cuda:0') MSE:  tensor(0.0039, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0069, device='cuda:0')
min of d_p_list:  tensor(-0.0128, device='cuda:0')
Epoch:  919  
Training Loss: 166040.5
Test Loss:  118853.5859375
Test Acc:  0.0
Valid Loss:  137561.46875
Valid Acc:  0.0
std:  2211.9278664916947 
thres:  169.279253125
Preserved_eigens number check:  41
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  42
 92%|█████████▏| 919/1000 [58:51<05:09,  3.82s/it]Epoch:   920
max of grad d_p:  tensor(252385.8125, device='cuda:0')
min of grad d_p:  tensor(-21749.6836, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.2188, device='cuda:0') mean:  tensor(0.0028, device='cuda:0') min:  tensor(-3.2822, device='cuda:0') norm:  tensor(47.4024, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(21.5176, device='cuda:0') mean:  tensor(0.0382, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(90.7152, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1178, device='cuda:0')
min of d_p_list:  tensor(-0.1303, device='cuda:0')
Epoch:  920  
Training Loss: 165130.484375
Test Loss:  118238.8359375
Test Acc:  0.0
Valid Loss:  136658.421875
Valid Acc:  0.0
std:  2176.4212773056124 
thres:  167.87779999999998
Preserved_eigens number check:  42
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  39
 92%|█████████▏| 920/1000 [58:55<05:12,  3.91s/it]Epoch:   921
max of grad d_p:  tensor(252006.6875, device='cuda:0')
min of grad d_p:  tensor(-22040.3945, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.4062, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-3.2812, device='cuda:0') norm:  tensor(42.0151, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(15.3060, device='cuda:0') mean:  tensor(0.0404, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(94.2682, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0152, device='cuda:0')
min of d_p_list:  tensor(-0.0178, device='cuda:0')
Epoch:  921  
Training Loss: 163484.953125
Test Loss:  117038.78125
Test Acc:  0.0
Valid Loss:  135277.21875
Valid Acc:  0.0
std:  2047.3426553792008 
thres:  166.353890625
Preserved_eigens number check:  39
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  63
 92%|█████████▏| 921/1000 [58:59<05:09,  3.91s/it]Epoch:   922
max of grad d_p:  tensor(250250.5312, device='cuda:0')
min of grad d_p:  tensor(-21950.4062, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.6719, device='cuda:0') mean:  tensor(0.0029, device='cuda:0') min:  tensor(-3.0488, device='cuda:0') norm:  tensor(50.0102, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(24.9150, device='cuda:0') mean:  tensor(0.0648, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(150.0497, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0146, device='cuda:0')
min of d_p_list:  tensor(-0.0170, device='cuda:0')
Epoch:  922  
Training Loss: 161854.078125
Test Loss:  115885.7265625
Test Acc:  0.0
Valid Loss:  133906.703125
Valid Acc:  0.0
std:  2026.1302426342654 
thres:  164.8444125
Preserved_eigens number check:  63
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  31
 92%|█████████▏| 922/1000 [59:03<05:04,  3.90s/it]Epoch:   923
max of grad d_p:  tensor(247974.6250, device='cuda:0')
min of grad d_p:  tensor(-21847.8438, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.5469, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-2.5332, device='cuda:0') norm:  tensor(44.2485, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(12.9238, device='cuda:0') mean:  tensor(0.0316, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(73.5207, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0223, device='cuda:0')
min of d_p_list:  tensor(-0.0285, device='cuda:0')
Epoch:  923  
Training Loss: 160280.875
Test Loss:  114771.0
Test Acc:  0.0
Valid Loss:  132578.84375
Valid Acc:  0.0
std:  2101.6233401184118 
thres:  163.35817812500002
Preserved_eigens number check:  31
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 92%|█████████▏| 923/1000 [59:07<05:00,  3.91s/it]Epoch:   924
max of grad d_p:  tensor(245382.5312, device='cuda:0')
min of grad d_p:  tensor(-21694.1738, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.1406, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-3.1348, device='cuda:0') norm:  tensor(43.1745, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(52.5889, device='cuda:0') mean:  tensor(0.1238, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(301.6707, device='cuda:0') MSE:  tensor(0.0011, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.3899, device='cuda:0')
min of d_p_list:  tensor(-0.4784, device='cuda:0')
Epoch:  924  
Training Loss: 162797.03125
Test Loss:  117205.3359375
Test Acc:  0.0
Valid Loss:  135341.953125
Valid Acc:  0.0
std:  1618.6488554609848 
thres:  162.70948437500002
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  55
 92%|█████████▏| 924/1000 [59:11<05:00,  3.95s/it]Epoch:   925
max of grad d_p:  tensor(254774.6875, device='cuda:0')
min of grad d_p:  tensor(-26268.5391, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.2725, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-4.9521, device='cuda:0') norm:  tensor(41.1221, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(49.1621, device='cuda:0') mean:  tensor(0.1389, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(292.3741, device='cuda:0') MSE:  tensor(0.0011, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1656, device='cuda:0')
min of d_p_list:  tensor(-0.1863, device='cuda:0')
Epoch:  925  
Training Loss: 161967.9375
Test Loss:  116518.8203125
Test Acc:  0.0
Valid Loss:  134703.265625
Valid Acc:  0.0
std:  1075.9582526226186 
thres:  162.076975
Preserved_eigens number check:  55
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  44
 92%|█████████▎| 925/1000 [59:15<04:55,  3.94s/it]Epoch:   926
max of grad d_p:  tensor(263506.4062, device='cuda:0')
min of grad d_p:  tensor(-25781.4023, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.3760, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(-4.0820, device='cuda:0') norm:  tensor(40.2526, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(20.3894, device='cuda:0') mean:  tensor(0.0734, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(173.8080, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0456, device='cuda:0')
min of d_p_list:  tensor(-0.0574, device='cuda:0')
Epoch:  926  
Training Loss: 160430.984375
Test Loss:  115478.8203125
Test Acc:  0.0
Valid Loss:  133454.28125
Valid Acc:  0.0
std:  964.3618116503427 
thres:  161.46618125
Preserved_eigens number check:  44
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  84
 93%|█████████▎| 926/1000 [59:18<04:48,  3.90s/it]Epoch:   927
max of grad d_p:  tensor(261946.9062, device='cuda:0')
min of grad d_p:  tensor(-25810.5684, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.1875, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-3.5342, device='cuda:0') norm:  tensor(43.5506, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(24.7617, device='cuda:0') mean:  tensor(0.0756, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(151.0057, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0521, device='cuda:0')
min of d_p_list:  tensor(-0.0548, device='cuda:0')
Epoch:  927  
Training Loss: 158820.09375
Test Loss:  114294.9765625
Test Acc:  0.0
Valid Loss:  132077.03125
Valid Acc:  0.0
std:  1389.9835505012504 
thres:  160.859384375
Preserved_eigens number check:  84
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 93%|█████████▎| 927/1000 [59:23<04:48,  3.95s/it]Epoch:   928
max of grad d_p:  tensor(259899.4219, device='cuda:0')
min of grad d_p:  tensor(-25529.6992, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.3799, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-3.3721, device='cuda:0') norm:  tensor(40.5574, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(19.3350, device='cuda:0') mean:  tensor(0.0558, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(123.2323, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0231, device='cuda:0')
min of d_p_list:  tensor(-0.0269, device='cuda:0')
Epoch:  928  
Training Loss: 157255.875
Test Loss:  113185.890625
Test Acc:  0.0
Valid Loss:  130788.328125
Valid Acc:  0.0
std:  2023.8949118998405 
thres:  160.254384375
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  40
 93%|█████████▎| 928/1000 [59:26<04:35,  3.82s/it]Epoch:   929
max of grad d_p:  tensor(258333.4375, device='cuda:0')
min of grad d_p:  tensor(-25401.2383, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.4072, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-3.4277, device='cuda:0') norm:  tensor(42.0619, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(13.2764, device='cuda:0') mean:  tensor(0.0284, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(73.9859, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0262, device='cuda:0')
min of d_p_list:  tensor(-0.0404, device='cuda:0')
Epoch:  929  
Training Loss: 155710.71875
Test Loss:  112132.71875
Test Acc:  0.0
Valid Loss:  129501.5625
Valid Acc:  0.0
std:  2218.893070131972 
thres:  158.837121875
Preserved_eigens number check:  40
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  79
 93%|█████████▎| 929/1000 [59:30<04:33,  3.85s/it]Epoch:   930
max of grad d_p:  tensor(256998.0938, device='cuda:0')
min of grad d_p:  tensor(-25478.7578, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.1641, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(-3.1992, device='cuda:0') norm:  tensor(37.8603, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(11.6230, device='cuda:0') mean:  tensor(0.0283, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(61.9748, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0613, device='cuda:0')
min of d_p_list:  tensor(-0.0348, device='cuda:0')
Epoch:  930  
Training Loss: 154184.125
Test Loss:  111040.0625
Test Acc:  0.0
Valid Loss:  128220.3671875
Valid Acc:  0.0
std:  2206.7287244871222 
thres:  157.280359375
Preserved_eigens number check:  79
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 93%|█████████▎| 930/1000 [59:34<04:31,  3.88s/it]Epoch:   931
max of grad d_p:  tensor(255246.4531, device='cuda:0')
min of grad d_p:  tensor(-24801.6289, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.9219, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-3.3975, device='cuda:0') norm:  tensor(45.0634, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(18.6802, device='cuda:0') mean:  tensor(0.0683, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(146.4067, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0334, device='cuda:0')
min of d_p_list:  tensor(-0.0259, device='cuda:0')
Epoch:  931  
Training Loss: 152652.34375
Test Loss:  109891.515625
Test Acc:  0.0
Valid Loss:  126930.921875
Valid Acc:  0.0
std:  2178.9400660606466 
thres:  155.72463125000002
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  31
 93%|█████████▎| 931/1000 [59:38<04:32,  3.94s/it]Epoch:   932
max of grad d_p:  tensor(254345.4219, device='cuda:0')
min of grad d_p:  tensor(-24919.5781, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.8281, device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(-3.0342, device='cuda:0') norm:  tensor(41.3324, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(21.2407, device='cuda:0') mean:  tensor(0.0327, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(84.4944, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0116, device='cuda:0')
min of d_p_list:  tensor(-0.0074, device='cuda:0')
Epoch:  932  
Training Loss: 151128.765625
Test Loss:  108779.5
Test Acc:  0.0
Valid Loss:  125658.0546875
Valid Acc:  0.0
std:  2165.5339362978852 
thres:  154.186365625
Preserved_eigens number check:  31
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  39
 93%|█████████▎| 932/1000 [59:42<04:27,  3.94s/it]Epoch:   933
max of grad d_p:  tensor(253088.2656, device='cuda:0')
min of grad d_p:  tensor(-24850.0156, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.6484, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-3.3926, device='cuda:0') norm:  tensor(44.2235, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(54.7432, device='cuda:0') mean:  tensor(0.0823, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(219.9897, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0036, device='cuda:0')
min of d_p_list:  tensor(-0.0035, device='cuda:0')
Epoch:  933  
Training Loss: 149620.90625
Test Loss:  107671.3203125
Test Acc:  0.0
Valid Loss:  124387.0625
Valid Acc:  0.0
std:  2154.561119353835 
thres:  152.659371875
Preserved_eigens number check:  39
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  42
 93%|█████████▎| 933/1000 [59:46<04:23,  3.93s/it]Epoch:   934
max of grad d_p:  tensor(251777., device='cuda:0')
min of grad d_p:  tensor(-24727.2344, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.4688, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-3.1367, device='cuda:0') norm:  tensor(41.9818, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(28.6777, device='cuda:0') mean:  tensor(0.0934, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(193.6780, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0060, device='cuda:0')
min of d_p_list:  tensor(-0.0060, device='cuda:0')
Epoch:  934  
Training Loss: 148128.21875
Test Loss:  106575.21875
Test Acc:  0.0
Valid Loss:  123139.9921875
Valid Acc:  0.0
std:  2141.6086349182124 
thres:  151.14287187500003
Preserved_eigens number check:  42
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 93%|█████████▎| 934/1000 [59:50<04:18,  3.91s/it]Epoch:   935
max of grad d_p:  tensor(250544.8750, device='cuda:0')
min of grad d_p:  tensor(-24622.3223, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.0615, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-4.8359, device='cuda:0') norm:  tensor(42.6070, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(18.3652, device='cuda:0') mean:  tensor(0.0460, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(100.2864, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1986, device='cuda:0')
min of d_p_list:  tensor(-0.1627, device='cuda:0')
Epoch:  935  
Training Loss: 147008.5
Test Loss:  106094.828125
Test Acc:  0.0
Valid Loss:  122168.40625
Valid Acc:  0.0
std:  2023.775142061242 
thres:  149.70774687500003
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  65
 94%|█████████▎| 935/1000 [59:54<04:11,  3.87s/it]Epoch:   936
max of grad d_p:  tensor(248992.5000, device='cuda:0')
min of grad d_p:  tensor(-24398.4629, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.7500, device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(-3.3052, device='cuda:0') norm:  tensor(42.7898, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(46.2603, device='cuda:0') mean:  tensor(0.1248, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(272.0408, device='cuda:0') MSE:  tensor(0.0010, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0365, device='cuda:0')
min of d_p_list:  tensor(-0.0385, device='cuda:0')
Epoch:  936  
Training Loss: 145557.25
Test Loss:  105025.265625
Test Acc:  0.0
Valid Loss:  120951.234375
Valid Acc:  0.0
std:  1947.6258170907565 
thres:  148.288728125
Preserved_eigens number check:  65
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  124
 94%|█████████▎| 936/1000 [59:57<04:06,  3.86s/it]Epoch:   937
max of grad d_p:  tensor(247838.3906, device='cuda:0')
min of grad d_p:  tensor(-24171.1250, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(13.8750, device='cuda:0') mean:  tensor(0.0026, device='cuda:0') min:  tensor(-3.4189, device='cuda:0') norm:  tensor(51.4046, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(12.8730, device='cuda:0') mean:  tensor(0.0244, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(60.0003, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0251, device='cuda:0')
min of d_p_list:  tensor(-0.0138, device='cuda:0')
Epoch:  937  
Training Loss: 144110.28125
Test Loss:  103922.59375
Test Acc:  0.0
Valid Loss:  119726.390625
Valid Acc:  0.0
std:  1923.9549016730812 
thres:  146.88503125
Preserved_eigens number check:  124
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 94%|█████████▎| 937/1000 [1:00:01<04:05,  3.89s/it]Epoch:   938
max of grad d_p:  tensor(246651.3750, device='cuda:0')
min of grad d_p:  tensor(-24007.7695, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.2188, device='cuda:0') mean:  tensor(0.0023, device='cuda:0') min:  tensor(-3.3320, device='cuda:0') norm:  tensor(45.8000, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(374.2402, device='cuda:0') mean:  tensor(0.8493, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1823.7076, device='cuda:0') MSE:  tensor(0.0068, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0181, device='cuda:0')
min of d_p_list:  tensor(-0.0282, device='cuda:0')
Epoch:  938  
Training Loss: 142685.703125
Test Loss:  102895.1796875
Test Acc:  0.0
Valid Loss:  118557.3203125
Valid Acc:  0.0
std:  1951.304616257976 
thres:  145.497990625
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 94%|█████████▍| 938/1000 [1:00:05<04:04,  3.94s/it]Epoch:   939
max of grad d_p:  tensor(245504.4375, device='cuda:0')
min of grad d_p:  tensor(-23819.5215, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.5156, device='cuda:0') mean:  tensor(0.0025, device='cuda:0') min:  tensor(-3.3721, device='cuda:0') norm:  tensor(45.8341, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(11.4980, device='cuda:0') mean:  tensor(0.0201, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(46.6481, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0263, device='cuda:0')
min of d_p_list:  tensor(-0.0424, device='cuda:0')
Epoch:  939  
Training Loss: 141280.296875
Test Loss:  101882.859375
Test Acc:  0.0
Valid Loss:  117401.765625
Valid Acc:  0.0
std:  2026.32585262962 
thres:  144.12840625
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 94%|█████████▍| 939/1000 [1:00:09<03:56,  3.88s/it]Epoch:   940
max of grad d_p:  tensor(244401.0156, device='cuda:0')
min of grad d_p:  tensor(-23647.8438, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.2656, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-3.3936, device='cuda:0') norm:  tensor(49.2218, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(40.2529, device='cuda:0') mean:  tensor(0.0579, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(152.5880, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0123, device='cuda:0')
min of d_p_list:  tensor(-0.0310, device='cuda:0')
Epoch:  940  
Training Loss: 139877.5625
Test Loss:  100858.9765625
Test Acc:  0.0
Valid Loss:  116233.078125
Valid Acc:  0.0
std:  2006.721752387188 
thres:  142.70221875000001
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  127
 94%|█████████▍| 940/1000 [1:00:13<03:53,  3.90s/it]Epoch:   941
max of grad d_p:  tensor(243190.7500, device='cuda:0')
min of grad d_p:  tensor(-23563.0938, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.8799, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-5.7578, device='cuda:0') norm:  tensor(40.8978, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(20.6426, device='cuda:0') mean:  tensor(0.0337, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(86.5133, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0069, device='cuda:0')
min of d_p_list:  tensor(-0.0053, device='cuda:0')
Epoch:  941  
Training Loss: 138477.1875
Test Loss:  99834.9375
Test Acc:  0.0
Valid Loss:  115063.640625
Valid Acc:  0.0
std:  1990.4215423742921 
thres:  141.28620625
Preserved_eigens number check:  127
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 94%|█████████▍| 941/1000 [1:00:17<03:49,  3.89s/it]Epoch:   942
max of grad d_p:  tensor(242027., device='cuda:0')
min of grad d_p:  tensor(-23403.4277, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.5469, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(-3.3950, device='cuda:0') norm:  tensor(43.0517, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(15.0889, device='cuda:0') mean:  tensor(0.0326, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(76.6210, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0082, device='cuda:0')
min of d_p_list:  tensor(-0.0069, device='cuda:0')
Epoch:  942  
Training Loss: 137097.875
Test Loss:  98810.796875
Test Acc:  0.0
Valid Loss:  113884.046875
Valid Acc:  0.0
std:  1976.9087157899846 
thres:  139.883725
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  37
 94%|█████████▍| 942/1000 [1:00:21<03:48,  3.94s/it]Epoch:   943
max of grad d_p:  tensor(240801.9688, device='cuda:0')
min of grad d_p:  tensor(-23305.9648, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.9688, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(-3.2354, device='cuda:0') norm:  tensor(43.1707, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(50.4512, device='cuda:0') mean:  tensor(0.1042, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(255.2685, device='cuda:0') MSE:  tensor(0.0010, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0170, device='cuda:0')
min of d_p_list:  tensor(-0.0180, device='cuda:0')
Epoch:  943  
Training Loss: 135741.96875
Test Loss:  97862.1796875
Test Acc:  0.0
Valid Loss:  112788.859375
Valid Acc:  0.0
std:  1959.6333514285907 
thres:  138.494978125
Preserved_eigens number check:  37
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  38
 94%|█████████▍| 943/1000 [1:00:25<03:41,  3.88s/it]Epoch:   944
max of grad d_p:  tensor(239511.5469, device='cuda:0')
min of grad d_p:  tensor(-23070.4277, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.4688, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-3.4521, device='cuda:0') norm:  tensor(46.1790, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(34.4482, device='cuda:0') mean:  tensor(0.0650, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(162.8081, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0041, device='cuda:0')
min of d_p_list:  tensor(-0.0038, device='cuda:0')
Epoch:  944  
Training Loss: 134388.3125
Test Loss:  96879.390625
Test Acc:  0.0
Valid Loss:  111655.59375
Valid Acc:  0.0
std:  1939.4652176083232 
thres:  137.11658125
Preserved_eigens number check:  38
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 94%|█████████▍| 944/1000 [1:00:28<03:35,  3.86s/it]Epoch:   945
max of grad d_p:  tensor(238364.1562, device='cuda:0')
min of grad d_p:  tensor(-22973.4336, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.2188, device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(-3.6152, device='cuda:0') norm:  tensor(46.6904, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.8335, device='cuda:0') mean:  tensor(0.0186, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(49.8173, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0134, device='cuda:0')
min of d_p_list:  tensor(-0.0142, device='cuda:0')
Epoch:  945  
Training Loss: 133054.15625
Test Loss:  95898.625
Test Acc:  0.0
Valid Loss:  110533.171875
Valid Acc:  0.0
std:  1917.087973924417 
thres:  135.7519
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  24
 94%|█████████▍| 945/1000 [1:00:32<03:30,  3.83s/it]Epoch:   946
max of grad d_p:  tensor(237197.9375, device='cuda:0')
min of grad d_p:  tensor(-22954.2773, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.5225, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.5000, device='cuda:0') norm:  tensor(37.5660, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(34.8979, device='cuda:0') mean:  tensor(0.0920, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(203.3002, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0074, device='cuda:0')
min of d_p_list:  tensor(-0.0069, device='cuda:0')
Epoch:  946  
Training Loss: 131727.484375
Test Loss:  94935.984375
Test Acc:  0.0
Valid Loss:  109412.265625
Valid Acc:  0.0
std:  1899.1135936951775 
thres:  134.40195937500002
Preserved_eigens number check:  24
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  36
 95%|█████████▍| 946/1000 [1:00:36<03:29,  3.88s/it]Epoch:   947
max of grad d_p:  tensor(235965.1406, device='cuda:0')
min of grad d_p:  tensor(-22885.4805, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(16.1406, device='cuda:0') mean:  tensor(0.0028, device='cuda:0') min:  tensor(-3.5977, device='cuda:0') norm:  tensor(54.5424, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(16.1309, device='cuda:0') mean:  tensor(0.0173, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(44.7770, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0128, device='cuda:0')
min of d_p_list:  tensor(-0.0123, device='cuda:0')
Epoch:  947  
Training Loss: 130413.2890625
Test Loss:  94008.09375
Test Acc:  0.0
Valid Loss:  108336.5
Valid Acc:  0.0
std:  1883.5049340165913 
thres:  133.06504218749998
Preserved_eigens number check:  36
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 95%|█████████▍| 947/1000 [1:00:40<03:26,  3.89s/it]Epoch:   948
max of grad d_p:  tensor(234851.7969, device='cuda:0')
min of grad d_p:  tensor(-22727.2285, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.5625, device='cuda:0') mean:  tensor(0.0023, device='cuda:0') min:  tensor(-3.3076, device='cuda:0') norm:  tensor(46.3789, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.5693, device='cuda:0') mean:  tensor(0.0234, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(50.8412, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0037, device='cuda:0')
min of d_p_list:  tensor(-0.0034, device='cuda:0')
Epoch:  948  
Training Loss: 129112.6171875
Test Loss:  93060.09375
Test Acc:  0.0
Valid Loss:  107250.171875
Valid Acc:  0.0
std:  1865.6913632263463 
thres:  131.739171875
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  43
 95%|█████████▍| 948/1000 [1:00:44<03:24,  3.93s/it]Epoch:   949
max of grad d_p:  tensor(233696.9062, device='cuda:0')
min of grad d_p:  tensor(-22635.0781, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.5625, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(-3.4390, device='cuda:0') norm:  tensor(44.9300, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(30., device='cuda:0') mean:  tensor(0.0369, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(97.2740, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0054, device='cuda:0')
min of d_p_list:  tensor(-0.0047, device='cuda:0')
Epoch:  949  
Training Loss: 127825.09375
Test Loss:  92131.90625
Test Acc:  0.0
Valid Loss:  106171.2421875
Valid Acc:  0.0
std:  1848.8328620832508 
thres:  130.426528125
Preserved_eigens number check:  43
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 95%|█████████▍| 949/1000 [1:00:48<03:17,  3.87s/it]Epoch:   950
max of grad d_p:  tensor(232536.2656, device='cuda:0')
min of grad d_p:  tensor(-22532.6855, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.9023, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(-2.7949, device='cuda:0') norm:  tensor(37.6792, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(17.8342, device='cuda:0') mean:  tensor(0.0384, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(92.6360, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0143, device='cuda:0')
min of d_p_list:  tensor(-0.0191, device='cuda:0')
Epoch:  950  
Training Loss: 126550.046875
Test Loss:  91212.203125
Test Acc:  0.0
Valid Loss:  105097.6640625
Valid Acc:  0.0
std:  1830.4591951481846 
thres:  129.12570625
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  101
 95%|█████████▌| 950/1000 [1:00:52<03:14,  3.90s/it]Epoch:   951
max of grad d_p:  tensor(231407.4375, device='cuda:0')
min of grad d_p:  tensor(-22508.4727, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.2500, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(-3.0029, device='cuda:0') norm:  tensor(38.8624, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(21.1338, device='cuda:0') mean:  tensor(0.0235, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(68.3823, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0071, device='cuda:0')
min of d_p_list:  tensor(-0.0074, device='cuda:0')
Epoch:  951  
Training Loss: 125283.375
Test Loss:  90285.5
Test Acc:  0.0
Valid Loss:  104032.484375
Valid Acc:  0.0
std:  1813.3866229305963 
thres:  127.836884375
Preserved_eigens number check:  101
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  35
 95%|█████████▌| 951/1000 [1:00:56<03:07,  3.83s/it]Epoch:   952
max of grad d_p:  tensor(230245.8438, device='cuda:0')
min of grad d_p:  tensor(-22427.9473, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.4062, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-3.8125, device='cuda:0') norm:  tensor(49.3479, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(44.9956, device='cuda:0') mean:  tensor(0.1053, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(240.9313, device='cuda:0') MSE:  tensor(0.0009, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0053, device='cuda:0')
min of d_p_list:  tensor(-0.0045, device='cuda:0')
Epoch:  952  
Training Loss: 124034.234375
Test Loss:  89370.5
Test Acc:  0.0
Valid Loss:  102996.609375
Valid Acc:  0.0
std:  1795.8659965945703 
thres:  126.5610734375
Preserved_eigens number check:  35
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  50
 95%|█████████▌| 952/1000 [1:00:59<03:05,  3.86s/it]Epoch:   953
max of grad d_p:  tensor(229126.9062, device='cuda:0')
min of grad d_p:  tensor(-22318.6777, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.8750, device='cuda:0') mean:  tensor(0.0020, device='cuda:0') min:  tensor(-3.2734, device='cuda:0') norm:  tensor(45.9745, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(595.9185, device='cuda:0') mean:  tensor(0.9752, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2530.8162, device='cuda:0') MSE:  tensor(0.0095, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0060, device='cuda:0')
min of d_p_list:  tensor(-0.0049, device='cuda:0')
Epoch:  953  
Training Loss: 122797.5546875
Test Loss:  88464.125
Test Acc:  0.0
Valid Loss:  101953.90625
Valid Acc:  0.0
std:  1777.8283598975072 
thres:  125.29806093750001
Preserved_eigens number check:  50
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  25
 95%|█████████▌| 953/1000 [1:01:04<03:04,  3.92s/it]Epoch:   954
max of grad d_p:  tensor(227990.1562, device='cuda:0')
min of grad d_p:  tensor(-22248.9805, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.0156, device='cuda:0') mean:  tensor(0.0020, device='cuda:0') min:  tensor(-3.6357, device='cuda:0') norm:  tensor(47.3826, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(74.4453, device='cuda:0') mean:  tensor(0.0814, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(205.8860, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0201, device='cuda:0')
min of d_p_list:  tensor(-0.0118, device='cuda:0')
Epoch:  954  
Training Loss: 121576.90625
Test Loss:  87587.171875
Test Acc:  0.0
Valid Loss:  100926.234375
Valid Acc:  0.0
std:  1758.2091088434056 
thres:  124.04842343749999
Preserved_eigens number check:  25
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  76
 95%|█████████▌| 954/1000 [1:01:07<02:57,  3.86s/it]Epoch:   955
max of grad d_p:  tensor(226881.3281, device='cuda:0')
min of grad d_p:  tensor(-22022.3340, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.3867, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-2.9399, device='cuda:0') norm:  tensor(41.1383, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(10.3733, device='cuda:0') mean:  tensor(0.0259, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(63.6365, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0300, device='cuda:0')
min of d_p_list:  tensor(-0.0257, device='cuda:0')
Epoch:  955  
Training Loss: 120378.9140625
Test Loss:  86751.671875
Test Acc:  0.0
Valid Loss:  99915.46875
Valid Acc:  0.0
std:  1734.767969750442 
thres:  122.814196875
Preserved_eigens number check:  76
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  37
 96%|█████████▌| 955/1000 [1:01:11<02:53,  3.86s/it]Epoch:   956
max of grad d_p:  tensor(225705.5156, device='cuda:0')
min of grad d_p:  tensor(-22178.6699, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.5312, device='cuda:0') mean:  tensor(0.0026, device='cuda:0') min:  tensor(-3.4707, device='cuda:0') norm:  tensor(46.7238, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(10.9121, device='cuda:0') mean:  tensor(0.0299, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(66.3853, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0065, device='cuda:0')
min of d_p_list:  tensor(-0.0104, device='cuda:0')
Epoch:  956  
Training Loss: 119179.0625
Test Loss:  85875.40625
Test Acc:  0.0
Valid Loss:  98904.15625
Valid Acc:  0.0
std:  1715.3387208453744 
thres:  121.59333437500001
Preserved_eigens number check:  37
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  71
 96%|█████████▌| 956/1000 [1:01:15<02:49,  3.85s/it]Epoch:   957
max of grad d_p:  tensor(224594.3750, device='cuda:0')
min of grad d_p:  tensor(-22135.9512, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.0781, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-3.3877, device='cuda:0') norm:  tensor(46.8536, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(42.6748, device='cuda:0') mean:  tensor(0.0637, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(168.9110, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0186, device='cuda:0')
min of d_p_list:  tensor(-0.0108, device='cuda:0')
Epoch:  957  
Training Loss: 117985.15625
Test Loss:  85021.1875
Test Acc:  0.0
Valid Loss:  97846.5078125
Valid Acc:  0.0
std:  1700.2718591692942 
thres:  120.38351875000001
Preserved_eigens number check:  71
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  33
 96%|█████████▌| 957/1000 [1:01:19<02:48,  3.93s/it]Epoch:   958
max of grad d_p:  tensor(223502.6562, device='cuda:0')
min of grad d_p:  tensor(-21947.3691, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.1465, device='cuda:0') mean:  tensor(0.0011, device='cuda:0') min:  tensor(-3.1929, device='cuda:0') norm:  tensor(39.6463, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(57.2512, device='cuda:0') mean:  tensor(0.0858, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(234.9293, device='cuda:0') MSE:  tensor(0.0009, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0078, device='cuda:0')
min of d_p_list:  tensor(-0.0125, device='cuda:0')
Epoch:  958  
Training Loss: 116809.640625
Test Loss:  84161.34375
Test Acc:  0.0
Valid Loss:  96849.0390625
Valid Acc:  0.0
std:  1686.928235358576 
thres:  119.1859359375
Preserved_eigens number check:  33
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  55
 96%|█████████▌| 958/1000 [1:01:23<02:44,  3.91s/it]Epoch:   959
max of grad d_p:  tensor(222385.3906, device='cuda:0')
min of grad d_p:  tensor(-21813.4766, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.5625, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-3.5957, device='cuda:0') norm:  tensor(47.7999, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(12.5850, device='cuda:0') mean:  tensor(0.0274, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(64.8880, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0040, device='cuda:0')
min of d_p_list:  tensor(-0.0038, device='cuda:0')
Epoch:  959  
Training Loss: 115643.484375
Test Loss:  83312.921875
Test Acc:  0.0
Valid Loss:  95874.6015625
Valid Acc:  0.0
std:  1674.5004845807982 
thres:  117.99925156249999
Preserved_eigens number check:  55
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  37
 96%|█████████▌| 959/1000 [1:01:27<02:40,  3.90s/it]Epoch:   960
max of grad d_p:  tensor(221313.7188, device='cuda:0')
min of grad d_p:  tensor(-21765.0293, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.6250, device='cuda:0') mean:  tensor(0.0024, device='cuda:0') min:  tensor(-3.4619, device='cuda:0') norm:  tensor(46.3572, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(18.5449, device='cuda:0') mean:  tensor(0.0432, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(104.9106, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0063, device='cuda:0')
min of d_p_list:  tensor(-0.0071, device='cuda:0')
Epoch:  960  
Training Loss: 114490.6875
Test Loss:  82476.9375
Test Acc:  0.0
Valid Loss:  94918.2734375
Valid Acc:  0.0
std:  1657.2715601735754 
thres:  116.82160625
Preserved_eigens number check:  37
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  195
 96%|█████████▌| 960/1000 [1:01:31<02:39,  3.99s/it]Epoch:   961
max of grad d_p:  tensor(220199.4688, device='cuda:0')
min of grad d_p:  tensor(-21688.3770, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.1797, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-5.5938, device='cuda:0') norm:  tensor(40.9807, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(16.9805, device='cuda:0') mean:  tensor(0.0317, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(77.7547, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(1.6976, device='cuda:0')
min of d_p_list:  tensor(-1.5701, device='cuda:0')
Epoch:  961  
Training Loss: 174229.625
Test Loss:  116098.578125
Test Acc:  0.0
Valid Loss:  137033.5625
Valid Acc:  0.0
std:  23228.18492968061 
thres:  127.83171875000001
Preserved_eigens number check:  195
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  47
 96%|█████████▌| 961/1000 [1:01:35<02:32,  3.92s/it]Epoch:   962
max of grad d_p:  tensor(266184.5312, device='cuda:0')
min of grad d_p:  tensor(-35341.0195, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.7500, device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(-4.3496, device='cuda:0') norm:  tensor(55.6943, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(25.8176, device='cuda:0') mean:  tensor(0.0644, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(148.1438, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0322, device='cuda:0')
min of d_p_list:  tensor(-0.0306, device='cuda:0')
Epoch:  962  
Training Loss: 172526.703125
Test Loss:  114892.8125
Test Acc:  0.0
Valid Loss:  135795.6875
Valid Acc:  0.0
std:  28296.549767590855 
thres:  138.740028125
Preserved_eigens number check:  47
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  26
 96%|█████████▌| 962/1000 [1:01:39<02:27,  3.88s/it]Epoch:   963
max of grad d_p:  tensor(264633.6250, device='cuda:0')
min of grad d_p:  tensor(-35149.8945, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.6719, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.7998, device='cuda:0') norm:  tensor(44.1993, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(83.3633, device='cuda:0') mean:  tensor(0.1387, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(342.3637, device='cuda:0') MSE:  tensor(0.0013, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0361, device='cuda:0')
min of d_p_list:  tensor(-0.0424, device='cuda:0')
Epoch:  963  
Training Loss: 170818.09375
Test Loss:  113655.828125
Test Acc:  0.0
Valid Loss:  134474.25
Valid Acc:  0.0
std:  28171.44455046392 
thres:  149.54171875
Preserved_eigens number check:  26
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  144
 96%|█████████▋| 963/1000 [1:01:42<02:23,  3.89s/it]Epoch:   964
max of grad d_p:  tensor(262627., device='cuda:0')
min of grad d_p:  tensor(-35025.9258, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.6328, device='cuda:0') mean:  tensor(-0.0011, device='cuda:0') min:  tensor(-8.8125, device='cuda:0') norm:  tensor(43.9684, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(267.3408, device='cuda:0') mean:  tensor(0.6440, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1476.5204, device='cuda:0') MSE:  tensor(0.0055, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0278, device='cuda:0')
min of d_p_list:  tensor(-0.0501, device='cuda:0')
Epoch:  964  
Training Loss: 169118.90625
Test Loss:  112474.421875
Test Acc:  0.0
Valid Loss:  133143.21875
Valid Acc:  0.0
std:  22936.44814710942 
thres:  160.23680312500002
Preserved_eigens number check:  144
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  59
 96%|█████████▋| 964/1000 [1:01:47<02:21,  3.94s/it]Epoch:   965
max of grad d_p:  tensor(260821.8281, device='cuda:0')
min of grad d_p:  tensor(-34850.6055, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.9453, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(-4.3887, device='cuda:0') norm:  tensor(52.3358, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(21.7335, device='cuda:0') mean:  tensor(0.0443, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(101.1783, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0252, device='cuda:0')
min of d_p_list:  tensor(-0.0305, device='cuda:0')
Epoch:  965  
Training Loss: 167453.0625
Test Loss:  111292.859375
Test Acc:  0.0
Valid Loss:  131763.15625
Valid Acc:  0.0
std:  2398.663773373691 
thres:  170.829278125
Preserved_eigens number check:  59
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  23
 96%|█████████▋| 965/1000 [1:01:50<02:14,  3.84s/it]Epoch:   966
max of grad d_p:  tensor(259959.8438, device='cuda:0')
min of grad d_p:  tensor(-34804.5156, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.3281, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(-4.5527, device='cuda:0') norm:  tensor(51.6971, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(45.0107, device='cuda:0') mean:  tensor(0.0846, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(205.3751, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0221, device='cuda:0')
min of d_p_list:  tensor(-0.0267, device='cuda:0')
Epoch:  966  
Training Loss: 165802.28125
Test Loss:  110165.671875
Test Acc:  0.0
Valid Loss:  130438.375
Valid Acc:  0.0
std:  2377.9088991498916 
thres:  169.14380937500002
Preserved_eigens number check:  23
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  50
 97%|█████████▋| 966/1000 [1:01:54<02:10,  3.84s/it]Epoch:   967
max of grad d_p:  tensor(259405.4062, device='cuda:0')
min of grad d_p:  tensor(-34546.4414, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.5938, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-4.3740, device='cuda:0') norm:  tensor(54.2490, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(38.2402, device='cuda:0') mean:  tensor(0.0785, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(178.7735, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0511, device='cuda:0')
min of d_p_list:  tensor(-0.0515, device='cuda:0')
Epoch:  967  
Training Loss: 164187.9375
Test Loss:  108997.359375
Test Acc:  0.0
Valid Loss:  129095.09375
Valid Acc:  0.0
std:  2344.437977476558 
thres:  167.47605625
Preserved_eigens number check:  50
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 97%|█████████▋| 967/1000 [1:01:58<02:06,  3.82s/it]Epoch:   968
max of grad d_p:  tensor(257176.7969, device='cuda:0')
min of grad d_p:  tensor(-34605.6016, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.3516, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-4.6328, device='cuda:0') norm:  tensor(45.3925, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(12.2173, device='cuda:0') mean:  tensor(0.0305, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(65.2121, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.4683, device='cuda:0')
min of d_p_list:  tensor(-0.2750, device='cuda:0')
Epoch:  968  
Training Loss: 165630.9375
Test Loss:  109333.6796875
Test Acc:  0.0
Valid Loss:  129514.46875
Valid Acc:  0.0
std:  1693.2736169316745 
thres:  166.438625
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  101
 97%|█████████▋| 968/1000 [1:02:02<02:05,  3.91s/it]Epoch:   969
max of grad d_p:  tensor(253310.2188, device='cuda:0')
min of grad d_p:  tensor(-35642.9570, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.6094, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(-3.7676, device='cuda:0') norm:  tensor(49.4429, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(26.8740, device='cuda:0') mean:  tensor(0.0546, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(126.4865, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0663, device='cuda:0')
min of d_p_list:  tensor(-0.1211, device='cuda:0')
Epoch:  969  
Training Loss: 164219.703125
Test Loss:  108665.6875
Test Acc:  0.0
Valid Loss:  128728.3125
Valid Acc:  0.0
std:  1206.245925608404 
thres:  165.458784375
Preserved_eigens number check:  101
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 97%|█████████▋| 969/1000 [1:02:06<02:00,  3.88s/it]Epoch:   970
max of grad d_p:  tensor(250727.5938, device='cuda:0')
min of grad d_p:  tensor(-35150.2812, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.9531, device='cuda:0') mean:  tensor(0.0026, device='cuda:0') min:  tensor(-4.5391, device='cuda:0') norm:  tensor(55.3915, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(70.5684, device='cuda:0') mean:  tensor(0.1736, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(395.8278, device='cuda:0') MSE:  tensor(0.0015, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0425, device='cuda:0')
min of d_p_list:  tensor(-0.0245, device='cuda:0')
Epoch:  970  
Training Loss: 162604.296875
Test Loss:  107645.828125
Test Acc:  0.0
Valid Loss:  127525.890625
Valid Acc:  0.0
std:  1161.3779915084306 
thres:  164.48903125
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 97%|█████████▋| 970/1000 [1:02:09<01:54,  3.81s/it]Epoch:   971
max of grad d_p:  tensor(249667.1875, device='cuda:0')
min of grad d_p:  tensor(-34921.5000, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.9023, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-4.9277, device='cuda:0') norm:  tensor(47.6848, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(19.8672, device='cuda:0') mean:  tensor(0.0567, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(115.1240, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.4265, device='cuda:0')
min of d_p_list:  tensor(-0.3311, device='cuda:0')
Epoch:  971  
Training Loss: 164572.8125
Test Loss:  109079.5546875
Test Acc:  0.0
Valid Loss:  129456.46875
Valid Acc:  0.0
std:  972.0153547868501 
thres:  164.24313750000002
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  37
 97%|█████████▋| 971/1000 [1:02:13<01:51,  3.85s/it]Epoch:   972
max of grad d_p:  tensor(258186.6875, device='cuda:0')
min of grad d_p:  tensor(-33690.4336, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.5469, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(-4.3955, device='cuda:0') norm:  tensor(48.5763, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(240.9492, device='cuda:0') mean:  tensor(0.5640, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1314.6129, device='cuda:0') MSE:  tensor(0.0049, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0139, device='cuda:0')
min of d_p_list:  tensor(-0.0109, device='cuda:0')
Epoch:  972  
Training Loss: 162936.484375
Test Loss:  108025.796875
Test Acc:  0.0
Valid Loss:  128262.46875
Valid Acc:  0.0
std:  1105.9057476986764 
thres:  163.992846875
Preserved_eigens number check:  37
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  100
 97%|█████████▋| 972/1000 [1:02:17<01:49,  3.93s/it]Epoch:   973
max of grad d_p:  tensor(257263.1562, device='cuda:0')
min of grad d_p:  tensor(-33527.2578, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.7812, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-4.9443, device='cuda:0') norm:  tensor(48.4515, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(215.9297, device='cuda:0') mean:  tensor(0.3759, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(920.4159, device='cuda:0') MSE:  tensor(0.0035, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1408, device='cuda:0')
min of d_p_list:  tensor(-0.0761, device='cuda:0')
Epoch:  973  
Training Loss: 161522.96875
Test Loss:  107018.765625
Test Acc:  0.0
Valid Loss:  127288.6015625
Valid Acc:  0.0
std:  1109.6858312522654 
thres:  163.171253125
Preserved_eigens number check:  100
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  33
 97%|█████████▋| 973/1000 [1:02:21<01:45,  3.92s/it]Epoch:   974
max of grad d_p:  tensor(257755.2188, device='cuda:0')
min of grad d_p:  tensor(-33629.0547, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.7812, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(-4.2070, device='cuda:0') norm:  tensor(48.9601, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(63.0176, device='cuda:0') mean:  tensor(0.2205, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(464.2463, device='cuda:0') MSE:  tensor(0.0017, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0911, device='cuda:0')
min of d_p_list:  tensor(-0.0688, device='cuda:0')
Epoch:  974  
Training Loss: 160020.6875
Test Loss:  105893.8515625
Test Acc:  0.0
Valid Loss:  126111.0625
Valid Acc:  0.0
std:  1513.769013525047 
thres:  162.33145000000002
Preserved_eigens number check:  33
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 97%|█████████▋| 974/1000 [1:02:25<01:42,  3.93s/it]Epoch:   975
max of grad d_p:  tensor(256670.5312, device='cuda:0')
min of grad d_p:  tensor(-33542.5859, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.4531, device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(-4.3623, device='cuda:0') norm:  tensor(53.8731, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(22.5360, device='cuda:0') mean:  tensor(0.0532, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(117.7596, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0778, device='cuda:0')
min of d_p_list:  tensor(-0.0504, device='cuda:0')
Epoch:  975  
Training Loss: 158632.96875
Test Loss:  104825.71875
Test Acc:  0.0
Valid Loss:  125084.9296875
Valid Acc:  0.0
std:  2093.2038532194642 
thres:  161.537184375
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  31
 98%|█████████▊| 975/1000 [1:02:29<01:38,  3.96s/it]Epoch:   976
max of grad d_p:  tensor(255383.1875, device='cuda:0')
min of grad d_p:  tensor(-33691.3516, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(20.1094, device='cuda:0') mean:  tensor(0.0025, device='cuda:0') min:  tensor(-4.9541, device='cuda:0') norm:  tensor(65.5361, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(29.0068, device='cuda:0') mean:  tensor(0.0779, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(161.6296, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0126, device='cuda:0')
min of d_p_list:  tensor(-0.0133, device='cuda:0')
Epoch:  976  
Training Loss: 157054.90625
Test Loss:  103791.4375
Test Acc:  0.0
Valid Loss:  123842.7421875
Valid Acc:  0.0
std:  2072.6556904352806 
thres:  160.03360312499998
Preserved_eigens number check:  31
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  66
 98%|█████████▊| 976/1000 [1:02:33<01:34,  3.93s/it]Epoch:   977
max of grad d_p:  tensor(254113.5469, device='cuda:0')
min of grad d_p:  tensor(-33575.2969, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.3672, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(-4.3115, device='cuda:0') norm:  tensor(48.6773, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(37.5859, device='cuda:0') mean:  tensor(0.0786, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(197.1880, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0316, device='cuda:0')
min of d_p_list:  tensor(-0.0194, device='cuda:0')
Epoch:  977  
Training Loss: 155499.9375
Test Loss:  102739.9453125
Test Acc:  0.0
Valid Loss:  122543.96875
Valid Acc:  0.0
std:  2123.5096711981028 
thres:  158.54629375000002
Preserved_eigens number check:  66
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 98%|█████████▊| 977/1000 [1:02:37<01:30,  3.93s/it]Epoch:   978
max of grad d_p:  tensor(253315.1719, device='cuda:0')
min of grad d_p:  tensor(-33394.6094, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.4062, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(-4.6748, device='cuda:0') norm:  tensor(57.1402, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(53.1348, device='cuda:0') mean:  tensor(0.1204, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(267.8746, device='cuda:0') MSE:  tensor(0.0010, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0233, device='cuda:0')
min of d_p_list:  tensor(-0.0240, device='cuda:0')
Epoch:  978  
Training Loss: 153964.53125
Test Loss:  101656.5390625
Test Acc:  0.0
Valid Loss:  121334.234375
Valid Acc:  0.0
std:  2156.4983042357985 
thres:  157.03460625000002
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 98%|█████████▊| 978/1000 [1:02:41<01:26,  3.91s/it]Epoch:   979
max of grad d_p:  tensor(252235.5469, device='cuda:0')
min of grad d_p:  tensor(-33294.5625, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.7344, device='cuda:0') mean:  tensor(-0.0007, device='cuda:0') min:  tensor(-4.4521, device='cuda:0') norm:  tensor(48.7355, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(37.8330, device='cuda:0') mean:  tensor(0.0745, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(174.2296, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0209, device='cuda:0')
min of d_p_list:  tensor(-0.0103, device='cuda:0')
Epoch:  979  
Training Loss: 152433.375
Test Loss:  100645.1796875
Test Acc:  0.0
Valid Loss:  120189.609375
Valid Acc:  0.0
std:  2190.5985606999343 
thres:  155.51714375
Preserved_eigens number check:  30
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 98%|█████████▊| 979/1000 [1:02:45<01:23,  3.98s/it]Epoch:   980
max of grad d_p:  tensor(250907.3594, device='cuda:0')
min of grad d_p:  tensor(-33145.3789, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.2031, device='cuda:0') mean:  tensor(3.0625e-05, device='cuda:0') min:  tensor(-4.9492, device='cuda:0') norm:  tensor(50.0221, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(58.8350, device='cuda:0') mean:  tensor(0.1756, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(400.0012, device='cuda:0') MSE:  tensor(0.0015, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0913, device='cuda:0')
min of d_p_list:  tensor(-0.1163, device='cuda:0')
Epoch:  980  
Training Loss: 151016.71875
Test Loss:  99821.78125
Test Acc:  0.0
Valid Loss:  119237.390625
Valid Acc:  0.0
std:  2141.850471354297 
thres:  153.99389374999998
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  27
 98%|█████████▊| 980/1000 [1:02:49<01:18,  3.94s/it]Epoch:   981
max of grad d_p:  tensor(249938.5469, device='cuda:0')
min of grad d_p:  tensor(-33124.7344, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.7656, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-4.6240, device='cuda:0') norm:  tensor(49.6388, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(15.7515, device='cuda:0') mean:  tensor(0.0525, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(107.4599, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.3594, device='cuda:0')
min of d_p_list:  tensor(-0.4037, device='cuda:0')
Epoch:  981  
Training Loss: 152731.78125
Test Loss:  101801.6640625
Test Acc:  0.0
Valid Loss:  121533.5625
Valid Acc:  0.0
std:  1511.4804459587378 
thres:  153.12926875
Preserved_eigens number check:  27
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  40
 98%|█████████▊| 981/1000 [1:02:53<01:15,  3.96s/it]Epoch:   982
max of grad d_p:  tensor(246279.9062, device='cuda:0')
min of grad d_p:  tensor(-32830.4766, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.3438, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-4.3496, device='cuda:0') norm:  tensor(49.3334, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(169.0166, device='cuda:0') mean:  tensor(0.2566, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(638.7714, device='cuda:0') MSE:  tensor(0.0024, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1999, device='cuda:0')
min of d_p_list:  tensor(-0.2558, device='cuda:0')
Epoch:  982  
Training Loss: 152324.671875
Test Loss:  102018.7265625
Test Acc:  0.0
Valid Loss:  121608.265625
Valid Acc:  0.0
std:  941.669702576227 
thres:  152.494215625
Preserved_eigens number check:  40
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  48
 98%|█████████▊| 982/1000 [1:02:57<01:12,  4.04s/it]Epoch:   983
max of grad d_p:  tensor(244371.3281, device='cuda:0')
min of grad d_p:  tensor(-32354.4688, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.2812, device='cuda:0') mean:  tensor(0.0029, device='cuda:0') min:  tensor(-4.1211, device='cuda:0') norm:  tensor(51.2669, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(172.4180, device='cuda:0') mean:  tensor(0.2842, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(693.3751, device='cuda:0') MSE:  tensor(0.0026, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0986, device='cuda:0')
min of d_p_list:  tensor(-0.0823, device='cuda:0')
Epoch:  983  
Training Loss: 150944.09375
Test Loss:  100980.4765625
Test Acc:  0.0
Valid Loss:  120535.828125
Valid Acc:  0.0
std:  755.0033636617952 
thres:  151.890128125
Preserved_eigens number check:  48
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  38
 98%|█████████▊| 983/1000 [1:03:01<01:08,  4.01s/it]Epoch:   984
max of grad d_p:  tensor(242548.8594, device='cuda:0')
min of grad d_p:  tensor(-32361.8984, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.2344, device='cuda:0') mean:  tensor(0.0026, device='cuda:0') min:  tensor(-3.9473, device='cuda:0') norm:  tensor(50.8099, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(158.3774, device='cuda:0') mean:  tensor(0.3890, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(932.0381, device='cuda:0') MSE:  tensor(0.0035, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1676, device='cuda:0')
min of d_p_list:  tensor(-0.1549, device='cuda:0')
Epoch:  984  
Training Loss: 149836.875
Test Loss:  100329.734375
Test Acc:  0.0
Valid Loss:  119498.9921875
Valid Acc:  0.0
std:  1041.395138631646 
thres:  151.370828125
Preserved_eigens number check:  38
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  34
 98%|█████████▊| 984/1000 [1:03:05<01:03,  3.98s/it]Epoch:   985
max of grad d_p:  tensor(242794.3281, device='cuda:0')
min of grad d_p:  tensor(-32340.4883, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.7344, device='cuda:0') mean:  tensor(0.0036, device='cuda:0') min:  tensor(-3.5381, device='cuda:0') norm:  tensor(55.8842, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(229.0225, device='cuda:0') mean:  tensor(0.5657, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1267.0211, device='cuda:0') MSE:  tensor(0.0048, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0177, device='cuda:0')
min of d_p_list:  tensor(-0.0163, device='cuda:0')
Epoch:  985  
Training Loss: 148348.96875
Test Loss:  99324.1875
Test Acc:  0.0
Valid Loss:  118340.3515625
Valid Acc:  0.0
std:  1612.785279827456 
thres:  150.837278125
Preserved_eigens number check:  34
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  35
 98%|█████████▊| 985/1000 [1:03:09<01:00,  4.02s/it]Epoch:   986
max of grad d_p:  tensor(241503.5000, device='cuda:0')
min of grad d_p:  tensor(-32298.9863, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(15.2812, device='cuda:0') mean:  tensor(0.0033, device='cuda:0') min:  tensor(-4.0273, device='cuda:0') norm:  tensor(57.2105, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(28.4189, device='cuda:0') mean:  tensor(0.0425, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(106.8084, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0270, device='cuda:0')
min of d_p_list:  tensor(-0.0122, device='cuda:0')
Epoch:  986  
Training Loss: 146875.09375
Test Loss:  98328.4921875
Test Acc:  0.0
Valid Loss:  117161.59375
Valid Acc:  0.0
std:  1910.7583327291154 
thres:  149.665940625
Preserved_eigens number check:  35
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  69
 99%|█████████▊| 986/1000 [1:03:13<00:55,  3.97s/it]Epoch:   987
max of grad d_p:  tensor(240142.8438, device='cuda:0')
min of grad d_p:  tensor(-32195.0508, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5., device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-3.3721, device='cuda:0') norm:  tensor(43.8915, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(105.7216, device='cuda:0') mean:  tensor(0.2594, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(575.1047, device='cuda:0') MSE:  tensor(0.0022, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0151, device='cuda:0')
min of d_p_list:  tensor(-0.0092, device='cuda:0')
Epoch:  987  
Training Loss: 145413.71875
Test Loss:  97316.3203125
Test Acc:  0.0
Valid Loss:  116014.390625
Valid Acc:  0.0
std:  1985.7125383993148 
thres:  148.28375
Preserved_eigens number check:  69
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  42
 99%|█████████▊| 987/1000 [1:03:17<00:51,  3.95s/it]Epoch:   988
max of grad d_p:  tensor(239003.5938, device='cuda:0')
min of grad d_p:  tensor(-32099.6660, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.9062, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-3.7510, device='cuda:0') norm:  tensor(47.3214, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(53.2267, device='cuda:0') mean:  tensor(0.1074, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(274.7797, device='cuda:0') MSE:  tensor(0.0010, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0295, device='cuda:0')
min of d_p_list:  tensor(-0.0186, device='cuda:0')
Epoch:  988  
Training Loss: 143973.15625
Test Loss:  96325.359375
Test Acc:  0.0
Valid Loss:  114817.03125
Valid Acc:  0.0
std:  2073.6570164506475 
thres:  146.8895625
Preserved_eigens number check:  42
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  32
 99%|█████████▉| 988/1000 [1:03:21<00:46,  3.92s/it]Epoch:   989
max of grad d_p:  tensor(237600.4688, device='cuda:0')
min of grad d_p:  tensor(-32005.4492, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.7812, device='cuda:0') mean:  tensor(0.0024, device='cuda:0') min:  tensor(-3.8711, device='cuda:0') norm:  tensor(50.0353, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(120.1807, device='cuda:0') mean:  tensor(0.2791, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(629.5183, device='cuda:0') MSE:  tensor(0.0024, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0341, device='cuda:0')
min of d_p_list:  tensor(-0.0415, device='cuda:0')
Epoch:  989  
Training Loss: 142560.375
Test Loss:  95353.21875
Test Acc:  0.0
Valid Loss:  113689.609375
Valid Acc:  0.0
std:  2047.7299673968243 
thres:  145.43426250000002
Preserved_eigens number check:  32
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  29
 99%|█████████▉| 989/1000 [1:03:25<00:43,  3.96s/it]Epoch:   990
max of grad d_p:  tensor(236649.2656, device='cuda:0')
min of grad d_p:  tensor(-31841.6484, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.7578, device='cuda:0') mean:  tensor(0.0023, device='cuda:0') min:  tensor(-3.2754, device='cuda:0') norm:  tensor(45.5973, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(101.4785, device='cuda:0') mean:  tensor(0.1408, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(378.8667, device='cuda:0') MSE:  tensor(0.0014, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0285, device='cuda:0')
min of d_p_list:  tensor(-0.0246, device='cuda:0')
Epoch:  990  
Training Loss: 141155.34375
Test Loss:  94459.484375
Test Acc:  0.0
Valid Loss:  112618.96875
Valid Acc:  0.0
std:  2021.3844322178054 
thres:  143.9955375
Preserved_eigens number check:  29
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  56
 99%|█████████▉| 990/1000 [1:03:28<00:38,  3.83s/it]Epoch:   991
max of grad d_p:  tensor(235690.3125, device='cuda:0')
min of grad d_p:  tensor(-31666.6406, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.4688, device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(-3.7676, device='cuda:0') norm:  tensor(43.3266, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(161.5615, device='cuda:0') mean:  tensor(0.3420, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(768.1747, device='cuda:0') MSE:  tensor(0.0029, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2794, device='cuda:0')
min of d_p_list:  tensor(-0.1894, device='cuda:0')
Epoch:  991  
Training Loss: 140933.703125
Test Loss:  93938.890625
Test Acc:  0.0
Valid Loss:  112292.359375
Valid Acc:  0.0
std:  1700.1727056574284 
thres:  142.807259375
Preserved_eigens number check:  56
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  35
 99%|█████████▉| 991/1000 [1:03:32<00:34,  3.84s/it]Epoch:   992
max of grad d_p:  tensor(235722.2500, device='cuda:0')
min of grad d_p:  tensor(-31355.1016, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.8594, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(-3.1113, device='cuda:0') norm:  tensor(42.0980, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(66.1597, device='cuda:0') mean:  tensor(0.1322, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(302.2790, device='cuda:0') MSE:  tensor(0.0011, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1215, device='cuda:0')
min of d_p_list:  tensor(-0.1514, device='cuda:0')
Epoch:  992  
Training Loss: 139866.96875
Test Loss:  93014.9765625
Test Acc:  0.0
Valid Loss:  111367.359375
Valid Acc:  0.0
std:  1424.8738553815913 
thres:  141.697909375
Preserved_eigens number check:  35
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  37
 99%|█████████▉| 992/1000 [1:03:36<00:30,  3.83s/it]Epoch:   993
max of grad d_p:  tensor(235208.4844, device='cuda:0')
min of grad d_p:  tensor(-31523.4570, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.7188, device='cuda:0') mean:  tensor(0.0029, device='cuda:0') min:  tensor(-4.0059, device='cuda:0') norm:  tensor(56.0754, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(95.8887, device='cuda:0') mean:  tensor(0.2112, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(562.8664, device='cuda:0') MSE:  tensor(0.0021, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0166, device='cuda:0')
min of d_p_list:  tensor(-0.0563, device='cuda:0')
Epoch:  993  
Training Loss: 138484.40625
Test Loss:  92086.921875
Test Acc:  0.0
Valid Loss:  110266.515625
Valid Acc:  0.0
std:  1362.0503807449636 
thres:  140.600159375
Preserved_eigens number check:  37
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  40
 99%|█████████▉| 993/1000 [1:03:40<00:27,  3.87s/it]Epoch:   994
max of grad d_p:  tensor(234138.5000, device='cuda:0')
min of grad d_p:  tensor(-31445.8223, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.6641, device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(-3.5225, device='cuda:0') norm:  tensor(44.6850, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(120.8906, device='cuda:0') mean:  tensor(0.2381, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(552.5908, device='cuda:0') MSE:  tensor(0.0021, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0827, device='cuda:0')
min of d_p_list:  tensor(-0.0957, device='cuda:0')
Epoch:  994  
Training Loss: 137372.046875
Test Loss:  91366.1484375
Test Acc:  0.0
Valid Loss:  109498.578125
Valid Acc:  0.0
std:  1447.095122517273 
thres:  139.56249375
Preserved_eigens number check:  40
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  35
 99%|█████████▉| 994/1000 [1:03:44<00:23,  3.83s/it]Epoch:   995
max of grad d_p:  tensor(234317.1562, device='cuda:0')
min of grad d_p:  tensor(-31086.8867, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(11.2188, device='cuda:0') mean:  tensor(0.0025, device='cuda:0') min:  tensor(-4.0430, device='cuda:0') norm:  tensor(51.6194, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(51.3851, device='cuda:0') mean:  tensor(0.1204, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(270.9970, device='cuda:0') MSE:  tensor(0.0010, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0113, device='cuda:0')
min of d_p_list:  tensor(-0.0141, device='cuda:0')
Epoch:  995  
Training Loss: 136008.09375
Test Loss:  90473.6328125
Test Acc:  0.0
Valid Loss:  108408.0546875
Valid Acc:  0.0
std:  1747.4652038347663 
thres:  138.53304375000002
Preserved_eigens number check:  35
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  43
100%|█████████▉| 995/1000 [1:03:47<00:19,  3.84s/it]Epoch:   996
max of grad d_p:  tensor(233162.5469, device='cuda:0')
min of grad d_p:  tensor(-30964.9316, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.4062, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-3.5088, device='cuda:0') norm:  tensor(50.4759, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(53.0537, device='cuda:0') mean:  tensor(0.1567, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(329.2231, device='cuda:0') MSE:  tensor(0.0012, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0246, device='cuda:0')
min of d_p_list:  tensor(-0.0285, device='cuda:0')
Epoch:  996  
Training Loss: 134657.15625
Test Loss:  89565.15625
Test Acc:  0.0
Valid Loss:  107312.9921875
Valid Acc:  0.0
std:  1824.7467515319934 
thres:  137.277734375
Preserved_eigens number check:  43
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  33
100%|█████████▉| 996/1000 [1:03:51<00:15,  3.86s/it]Epoch:   997
max of grad d_p:  tensor(232116.1094, device='cuda:0')
min of grad d_p:  tensor(-30843.9844, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.0312, device='cuda:0') mean:  tensor(0.0023, device='cuda:0') min:  tensor(-4.2930, device='cuda:0') norm:  tensor(52.9000, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(19.4409, device='cuda:0') mean:  tensor(0.0671, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(148.3775, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0115, device='cuda:0')
min of d_p_list:  tensor(-0.0068, device='cuda:0')
Epoch:  997  
Training Loss: 133315.375
Test Loss:  88667.4375
Test Acc:  0.0
Valid Loss:  106261.390625
Valid Acc:  0.0
std:  1847.159146965618 
thres:  135.967415625
Preserved_eigens number check:  33
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  60
100%|█████████▉| 997/1000 [1:03:55<00:11,  3.89s/it]Epoch:   998
max of grad d_p:  tensor(231048.8438, device='cuda:0')
min of grad d_p:  tensor(-30692.7812, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.6719, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-3.7578, device='cuda:0') norm:  tensor(45.8658, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(27.5757, device='cuda:0') mean:  tensor(0.0772, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(171.9089, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1157, device='cuda:0')
min of d_p_list:  tensor(-0.0826, device='cuda:0')
Epoch:  998  
Training Loss: 132382.40625
Test Loss:  87818.4765625
Test Acc:  0.0
Valid Loss:  105338.3046875
Valid Acc:  0.0
std:  1796.115485351304 
thres:  134.747015625
Preserved_eigens number check:  60
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  202
100%|█████████▉| 998/1000 [1:03:59<00:07,  3.90s/it]Epoch:   999
max of grad d_p:  tensor(230725.5781, device='cuda:0')
min of grad d_p:  tensor(-30834.1211, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(12.7969, device='cuda:0') mean:  tensor(0.0028, device='cuda:0') min:  tensor(-4.1680, device='cuda:0') norm:  tensor(54.2785, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(126.3320, device='cuda:0') mean:  tensor(0.1588, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(380.9816, device='cuda:0') MSE:  tensor(0.0014, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2847, device='cuda:0')
min of d_p_list:  tensor(-0.5834, device='cuda:0')
Epoch:  999  
Training Loss: 132772.34375
Test Loss:  88301.7734375
Test Acc:  0.0
Valid Loss:  106281.6953125
Valid Acc:  0.0
std:  1334.708984491095 
thres:  133.827075
Preserved_eigens number check:  202
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  46
100%|█████████▉| 999/1000 [1:04:03<00:03,  3.92s/it]Epoch:   1000
max of grad d_p:  tensor(230155.8750, device='cuda:0')
min of grad d_p:  tensor(-31775.1992, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.3125, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-3.8789, device='cuda:0') norm:  tensor(50.1249, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(64.3311, device='cuda:0') mean:  tensor(0.1147, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(273.7754, device='cuda:0') MSE:  tensor(0.0010, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0124, device='cuda:0')
min of d_p_list:  tensor(-0.0203, device='cuda:0')
Epoch:  1000  
Training Loss: 131457.890625
Test Loss:  87460.609375
Test Acc:  0.0
Valid Loss:  105218.8046875
Valid Acc:  0.0
std:  1060.4303358115399 
thres:  132.917034375
Preserved_eigens number check:  46
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
100%|██████████| 1000/1000 [1:04:07<00:00,  3.98s/it]100%|██████████| 1000/1000 [1:04:07<00:00,  3.85s/it]
