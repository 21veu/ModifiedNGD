/nishome/yui/ModifiedNGD/utils/readData.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)
/nishome/yui/anaconda3/envs/ng/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /opt/conda/conda-bld/pytorch_1716905971214/work/torch/csrc/autograd/engine.cpp:1203.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Train info: 
 train data shape: torch.Size([512, 1]), 
 train lable shape: torch.Size([512, 1]), 
 positive / negative: 0.021206805482506752 / 0.978793203830719, 
 discrepancy norm error: 5.045955617788422e-07
Test info: 
 test data shape: torch.Size([128, 1]), 
 test lable shape: torch.Size([128, 1]), , 
 positive / negative: -0.030759211629629135 / 1.0307592153549194, 
 discrepancy norm error: 2.750667249529215e-07
Valid info: 
 valid data shape: torch.Size([128, 1]), valid lable shape: torch.Size([128, 1]), 
 positive / negative: 0.015859205275774002 / 0.9841408133506775, 
 discrepancy norm error: 2.3576444618811365e-07
torch.Size([512, 1]) torch.Size([512])
seed is  2191
---------------------------------------- NGD ----------------------------------------
OUTPUT CHECK:  torch.Size([512]) tensor(-0.1778, device='cuda:0', grad_fn=<MaxBackward1>) tensor(-0.2210, device='cuda:0', grad_fn=<MinBackward1>) 
TARGET:  torch.Size([512]) tensor(0.5000, device='cuda:0') tensor(-0.5000, device='cuda:0')
max of Lambda2 tensor(643.4709, device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  0%|          | 0/10 [00:00<?, ?it/s]Epoch:   1
Test train Loss:  0.08527871966362
Test train Acc:  0.0
Test Loss:  0.07638579607009888
Test Acc:  0.0
Valid Loss:  0.08337642252445221
Valid Acc:  0.0
max of grad d_p:  tensor(0.0511, device='cuda:0')
min of grad d_p:  tensor(-0.2201, device='cuda:0')
max|min: (J_L, Jta/N)  (0.05113335698843002, 0.052407748997211456, ratio: 1.0249229669570923)|(-0.2201463133096695, -0.2201462984085083)

 check Jacobi res:  torch.Size([53]) max:  tensor(0.0115, device='cuda:0') mean:  tensor(-0.0003, device='cuda:0') min:  tensor(-0.0093, device='cuda:0') norm:  tensor(0.0192, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([53, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(5.5567e-05, device='cuda:0') min:  tensor(5.2019e-07, device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(1.4234e-05, device='cuda:0')
Shape check:  torch.Size([53, 1])
max of d_p_list:  tensor(0.0369, device='cuda:0')
min of d_p_list:  tensor(-0.0192, device='cuda:0')
Epoch:  1  
Training Loss: 0.0850330688408576
Test Loss:  0.07610197365283966
Test Acc:  0.0
Valid Loss:  0.08299735188484192
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  512
max of Lambda2 tensor(641.5985, device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 10%|█         | 1/10 [00:02<00:22,  2.45s/it]Epoch:   2
max of grad d_p:  tensor(0.0494, device='cuda:0')
min of grad d_p:  tensor(-0.2190, device='cuda:0')
max|min: (J_L, Jta/N)  (0.04938672482967377, 0.05078444629907608, ratio: 1.0283015966415405)|(-0.21898961067199707, -0.21898961067199707)

 check Jacobi res:  torch.Size([53]) max:  tensor(0.0114, device='cuda:0') mean:  tensor(-0.0003, device='cuda:0') min:  tensor(-0.0097, device='cuda:0') norm:  tensor(0.0201, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([53, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(5.0301e-05, device='cuda:0') min:  tensor(3.3002e-07, device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(1.3533e-05, device='cuda:0')
Shape check:  torch.Size([53, 1])
max of d_p_list:  tensor(0.0191, device='cuda:0')
min of d_p_list:  tensor(-0.0132, device='cuda:0')
Epoch:  2  
Training Loss: 0.0844743549823761
Test Loss:  0.07583630084991455
Test Acc:  0.0
Valid Loss:  0.08264370262622833
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  512
max of Lambda2 tensor(643.1129, device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 20%|██        | 2/10 [00:04<00:18,  2.36s/it]Epoch:   3
max of grad d_p:  tensor(0.0491, device='cuda:0')
min of grad d_p:  tensor(-0.2178, device='cuda:0')
max|min: (J_L, Jta/N)  (0.0491221621632576, 0.05075984075665474, ratio: 1.0333389043807983)|(-0.21784958243370056, -0.21784958243370056)

 check Jacobi res:  torch.Size([53]) max:  tensor(0.0117, device='cuda:0') mean:  tensor(-0.0004, device='cuda:0') min:  tensor(-0.0100, device='cuda:0') norm:  tensor(0.0218, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([53, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(4.1442e-05, device='cuda:0') min:  tensor(2.3082e-07, device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(1.3228e-05, device='cuda:0')
Shape check:  torch.Size([53, 1])
max of d_p_list:  tensor(0.0174, device='cuda:0')
min of d_p_list:  tensor(-0.0133, device='cuda:0')
Epoch:  3  
Training Loss: 0.08410035073757172
Test Loss:  0.07559849321842194
Test Acc:  0.0
Valid Loss:  0.08230350911617279
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  512
max of Lambda2 tensor(646.0795, device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 30%|███       | 3/10 [00:07<00:16,  2.33s/it]Epoch:   4
max of grad d_p:  tensor(0.0497, device='cuda:0')
min of grad d_p:  tensor(-0.2167, device='cuda:0')
max|min: (J_L, Jta/N)  (0.04965083301067352, 0.05134383589029312, ratio: 1.0340981483459473)|(-0.21674758195877075, -0.21674759685993195)

 check Jacobi res:  torch.Size([53]) max:  tensor(0.0107, device='cuda:0') mean:  tensor(-0.0004, device='cuda:0') min:  tensor(-0.0092, device='cuda:0') norm:  tensor(0.0212, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([53, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(5.5978e-05, device='cuda:0') min:  tensor(9.5071e-07, device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(1.3812e-05, device='cuda:0')
Shape check:  torch.Size([53, 1])
max of d_p_list:  tensor(0.0410, device='cuda:0')
min of d_p_list:  tensor(-0.0644, device='cuda:0')
Epoch:  4  
Training Loss: 0.08368511497974396
Test Loss:  0.07527607679367065
Test Acc:  0.0
Valid Loss:  0.08193732798099518
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  512
max of Lambda2 tensor(645.7131, device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 40%|████      | 4/10 [00:09<00:13,  2.32s/it]Epoch:   5
max of grad d_p:  tensor(0.0472, device='cuda:0')
min of grad d_p:  tensor(-0.2155, device='cuda:0')
max|min: (J_L, Jta/N)  (0.047153208404779434, 0.048760853707790375, ratio: 1.0340940952301025)|(-0.2155390977859497, -0.2155390977859497)

 check Jacobi res:  torch.Size([53]) max:  tensor(0.0087, device='cuda:0') mean:  tensor(-0.0004, device='cuda:0') min:  tensor(-0.0091, device='cuda:0') norm:  tensor(0.0192, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([53, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(6.5445e-05, device='cuda:0') min:  tensor(7.7211e-08, device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(1.6611e-05, device='cuda:0')
Shape check:  torch.Size([53, 1])
max of d_p_list:  tensor(0.0280, device='cuda:0')
min of d_p_list:  tensor(-0.0306, device='cuda:0')
Epoch:  5  
Training Loss: 0.08329319953918457
Test Loss:  0.07499959319829941
Test Acc:  0.0
Valid Loss:  0.081583671271801
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  512
max of Lambda2 tensor(647.4466, device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 50%|█████     | 5/10 [00:11<00:11,  2.33s/it]Epoch:   6
max of grad d_p:  tensor(0.0458, device='cuda:0')
min of grad d_p:  tensor(-0.2145, device='cuda:0')
max|min: (J_L, Jta/N)  (0.045784011483192444, 0.04758644849061966, ratio: 1.0393682718276978)|(-0.21446017920970917, -0.21446019411087036)

 check Jacobi res:  torch.Size([53]) max:  tensor(0.0096, device='cuda:0') mean:  tensor(-0.0004, device='cuda:0') min:  tensor(-0.0101, device='cuda:0') norm:  tensor(0.0206, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([53, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(3.1469e-05, device='cuda:0') min:  tensor(2.8376e-08, device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(9.9898e-06, device='cuda:0')
Shape check:  torch.Size([53, 1])
max of d_p_list:  tensor(0.0349, device='cuda:0')
min of d_p_list:  tensor(-0.0298, device='cuda:0')
Epoch:  6  
Training Loss: 0.08290757983922958
Test Loss:  0.07472701370716095
Test Acc:  0.0
Valid Loss:  0.0812394991517067
Valid Acc:  0.0
std:  0.0005573569360793736 
thres:  8.369212001562118e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(651.2278, device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 60%|██████    | 6/10 [00:14<00:09,  2.34s/it]Epoch:   7
max of grad d_p:  tensor(0.0452, device='cuda:0')
min of grad d_p:  tensor(-0.2134, device='cuda:0')
max|min: (J_L, Jta/N)  (0.04515628516674042, 0.04700613394379616, ratio: 1.0409654378890991)|(-0.21339482069015503, -0.21339482069015503)

 check Jacobi res:  torch.Size([53]) max:  tensor(0.0102, device='cuda:0') mean:  tensor(-0.0004, device='cuda:0') min:  tensor(-0.0107, device='cuda:0') norm:  tensor(0.0206, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([53, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(6.3541e-05, device='cuda:0') min:  tensor(3.8149e-07, device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(1.5310e-05, device='cuda:0')
Shape check:  torch.Size([53, 1])
max of d_p_list:  tensor(0.1037, device='cuda:0')
min of d_p_list:  tensor(-0.0521, device='cuda:0')
Epoch:  7  
Training Loss: 0.08263744413852692
Test Loss:  0.0746326595544815
Test Acc:  0.0
Valid Loss:  0.08097213506698608
Valid Acc:  0.0
std:  0.0005251352480722079 
thres:  8.332473784685136e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(655.7689, device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 70%|███████   | 7/10 [00:16<00:07,  2.33s/it]Epoch:   8
max of grad d_p:  tensor(0.0491, device='cuda:0')
min of grad d_p:  tensor(-0.2123, device='cuda:0')
max|min: (J_L, Jta/N)  (0.049141231924295425, 0.050938162952661514, ratio: 1.0365666151046753)|(-0.21228283643722534, -0.21228283643722534)

 check Jacobi res:  torch.Size([53]) max:  tensor(0.0090, device='cuda:0') mean:  tensor(-0.0005, device='cuda:0') min:  tensor(-0.0110, device='cuda:0') norm:  tensor(0.0208, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([53, 1]) max:  tensor(0.0031, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(1.0673e-05, device='cuda:0') norm:  tensor(0.0075, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([53, 1])
max of d_p_list:  tensor(0.0138, device='cuda:0')
min of d_p_list:  tensor(-0.0095, device='cuda:0')
Epoch:  8  
Training Loss: 0.08228836953639984
Test Loss:  0.07441452890634537
Test Acc:  0.0
Valid Loss:  0.08065555989742279
Valid Acc:  0.0
std:  0.0004888075056329945 
thres:  8.296234160661697e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(659.6719, device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 80%|████████  | 8/10 [00:18<00:04,  2.34s/it]Epoch:   9
max of grad d_p:  tensor(0.0496, device='cuda:0')
min of grad d_p:  tensor(-0.2112, device='cuda:0')
max|min: (J_L, Jta/N)  (0.049569033086299896, 0.051581233739852905, ratio: 1.0405938625335693)|(-0.2112324833869934, -0.2112324833869934)

 check Jacobi res:  torch.Size([53]) max:  tensor(0.0100, device='cuda:0') mean:  tensor(-0.0006, device='cuda:0') min:  tensor(-0.0122, device='cuda:0') norm:  tensor(0.0227, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([53, 1]) max:  tensor(0.0010, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(1.4520e-06, device='cuda:0') norm:  tensor(0.0019, device='cuda:0') MSE:  tensor(3.6299e-05, device='cuda:0')
Shape check:  torch.Size([53, 1])
max of d_p_list:  tensor(0.0359, device='cuda:0')
min of d_p_list:  tensor(-0.0343, device='cuda:0')
Epoch:  9  
Training Loss: 0.08191560208797455
Test Loss:  0.07414604723453522
Test Acc:  0.0
Valid Loss:  0.08032502233982086
Valid Acc:  0.0
std:  0.0004778474618483479 
thres:  8.260843902826309e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(663.6437, device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 90%|█████████ | 9/10 [00:21<00:02,  2.34s/it]Epoch:   10
max of grad d_p:  tensor(0.0484, device='cuda:0')
min of grad d_p:  tensor(-0.2102, device='cuda:0')
max|min: (J_L, Jta/N)  (0.04843801632523537, 0.05077695846557617, ratio: 1.048287272453308)|(-0.2102198451757431, -0.2102198451757431)

 check Jacobi res:  torch.Size([53]) max:  tensor(0.0122, device='cuda:0') mean:  tensor(-0.0006, device='cuda:0') min:  tensor(-0.0144, device='cuda:0') norm:  tensor(0.0258, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([53, 1]) max:  tensor(0.0014, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(2.1942e-06, device='cuda:0') norm:  tensor(0.0028, device='cuda:0') MSE:  tensor(5.2688e-05, device='cuda:0')
Shape check:  torch.Size([53, 1])
max of d_p_list:  tensor(0.1020, device='cuda:0')
min of d_p_list:  tensor(-0.1199, device='cuda:0')
Epoch:  10  
Training Loss: 0.0817825198173523
Test Loss:  0.07426156848669052
Test Acc:  0.0
Valid Loss:  0.08019755035638809
Valid Acc:  0.0
std:  0.0004239117656346809 
thres:  8.230630308389664e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(663.0392, device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
100%|██████████| 10/10 [00:23<00:00,  2.34s/it]100%|██████████| 10/10 [00:23<00:00,  2.34s/it]
