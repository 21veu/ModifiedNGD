/nishome/yui/ModifiedNGD/utils/readData.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)
/nishome/yui/anaconda3/envs/ng/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /opt/conda/conda-bld/pytorch_1716905971214/work/torch/csrc/autograd/engine.cpp:1203.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Train info: 
 train data shape: torch.Size([512, 2]), 
 train lable shape: torch.Size([512, 1]), 
 positive / negative: -0.02499326691031456 / 1.0249933004379272
Test info: 
 test data shape: torch.Size([128, 2]), 
 test lable shape: torch.Size([128, 1]), , 
 positive / negative: -0.006046447902917862 / 1.0060464143753052
Valid info: 
 valid data shape: torch.Size([128, 2]), valid lable shape: torch.Size([128, 1]), 
 positive / negative: 0.050523675978183746 / 0.9494763016700745
torch.Size([512, 2]) torch.Size([512])
seed is  2190
---------------------------------------- NGD ----------------------------------------
OUTPUT CHECK:  torch.Size([512]) tensor(-0.0934, device='cuda:0', grad_fn=<MaxBackward1>) tensor(-0.1214, device='cuda:0', grad_fn=<MinBackward1>) 
TARGET:  torch.Size([512]) tensor(0.5000, device='cuda:0') tensor(-0.5000, device='cuda:0')
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch:   1
Test train Loss:  0.06703334301710129
Test train Acc:  0.0
Test Loss:  0.07140271365642548
Test Acc:  0.0
Valid Loss:  0.08514202386140823
Valid Acc:  0.0
max of grad d_p:  tensor(0.0067, device='cuda:0')
min of grad d_p:  tensor(-0.0852, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0023, device='cuda:0') mean:  tensor(-3.1503e-06, device='cuda:0') min:  tensor(-0.0022, device='cuda:0') norm:  tensor(0.0614, device='cuda:0') MSE:  tensor(2.3039e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.8077e-05, device='cuda:0') mean:  tensor(6.1226e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.3268e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0029, device='cuda:0')
min of d_p_list:  tensor(-0.0008, device='cuda:0')
Epoch:  1  
Training Loss: 0.06659603408479597
Test Loss:  0.07076616585254669
Test Acc:  0.0
Valid Loss:  0.0843849629163742
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  0%|          | 1/1000 [00:02<47:34,  2.86s/it]Epoch:   2
max of grad d_p:  tensor(0.0066, device='cuda:0')
min of grad d_p:  tensor(-0.0848, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0021, device='cuda:0') mean:  tensor(-3.2448e-06, device='cuda:0') min:  tensor(-0.0021, device='cuda:0') norm:  tensor(0.0613, device='cuda:0') MSE:  tensor(2.3003e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.0875e-05, device='cuda:0') mean:  tensor(3.0715e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.1573e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0020, device='cuda:0')
min of d_p_list:  tensor(-0.0023, device='cuda:0')
Epoch:  2  
Training Loss: 0.0659215897321701
Test Loss:  0.07020066678524017
Test Acc:  0.0
Valid Loss:  0.08367443829774857
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  0%|          | 2/1000 [00:05<46:06,  2.77s/it]Epoch:   3
max of grad d_p:  tensor(0.0064, device='cuda:0')
min of grad d_p:  tensor(-0.0844, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0018, device='cuda:0') mean:  tensor(-3.2350e-06, device='cuda:0') min:  tensor(-0.0016, device='cuda:0') norm:  tensor(0.0566, device='cuda:0') MSE:  tensor(2.1243e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.7936e-05, device='cuda:0') mean:  tensor(4.4059e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.6972e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0049, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  3  
Training Loss: 0.06536304205656052
Test Loss:  0.06955640017986298
Test Acc:  0.0
Valid Loss:  0.08292151987552643
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  0%|          | 3/1000 [00:08<44:24,  2.67s/it]Epoch:   4
max of grad d_p:  tensor(0.0062, device='cuda:0')
min of grad d_p:  tensor(-0.0839, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0022, device='cuda:0') mean:  tensor(-3.6380e-06, device='cuda:0') min:  tensor(-0.0018, device='cuda:0') norm:  tensor(0.0641, device='cuda:0') MSE:  tensor(2.4080e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.8502e-05, device='cuda:0') mean:  tensor(5.1994e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(2.0538e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0072, device='cuda:0')
min of d_p_list:  tensor(-0.0075, device='cuda:0')
Epoch:  4  
Training Loss: 0.06482306122779846
Test Loss:  0.06901627779006958
Test Acc:  0.0
Valid Loss:  0.08222837746143341
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  0%|          | 4/1000 [00:10<44:40,  2.69s/it]Epoch:   5
max of grad d_p:  tensor(0.0063, device='cuda:0')
min of grad d_p:  tensor(-0.0835, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0016, device='cuda:0') mean:  tensor(-4.0464e-06, device='cuda:0') min:  tensor(-0.0031, device='cuda:0') norm:  tensor(0.0615, device='cuda:0') MSE:  tensor(2.3095e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.3713e-05, device='cuda:0') mean:  tensor(8.5644e-07, device='cuda:0') min:  tensor(9.0949e-13, device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.3772e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0050, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  5  
Training Loss: 0.06427604705095291
Test Loss:  0.06839588284492493
Test Acc:  0.0
Valid Loss:  0.0814991146326065
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  0%|          | 5/1000 [00:13<44:21,  2.68s/it]Epoch:   6
max of grad d_p:  tensor(0.0062, device='cuda:0')
min of grad d_p:  tensor(-0.0830, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0020, device='cuda:0') mean:  tensor(-3.7316e-06, device='cuda:0') min:  tensor(-0.0023, device='cuda:0') norm:  tensor(0.0610, device='cuda:0') MSE:  tensor(2.2898e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.7997e-05, device='cuda:0') mean:  tensor(3.5321e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.3652e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0019, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  6  
Training Loss: 0.06373806297779083
Test Loss:  0.06779327988624573
Test Acc:  0.0
Valid Loss:  0.08077970147132874
Valid Acc:  0.0
std:  0.0007713340963005518 
thres:  6.482436060905457e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  1%|          | 6/1000 [00:16<43:41,  2.64s/it]Epoch:   7
max of grad d_p:  tensor(0.0061, device='cuda:0')
min of grad d_p:  tensor(-0.0826, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0020, device='cuda:0') mean:  tensor(-4.9793e-06, device='cuda:0') min:  tensor(-0.0035, device='cuda:0') norm:  tensor(0.0688, device='cuda:0') MSE:  tensor(2.5837e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.7792e-05, device='cuda:0') mean:  tensor(1.1425e-06, device='cuda:0') min:  tensor(1.3642e-12, device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.3750e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0214, device='cuda:0')
min of d_p_list:  tensor(-0.0195, device='cuda:0')
Epoch:  7  
Training Loss: 0.06302271038293839
Test Loss:  0.06660059094429016
Test Acc:  0.0
Valid Loss:  0.07967807352542877
Valid Acc:  0.0
std:  0.0008168369400253772 
thres:  6.424458473920822e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  1%|          | 7/1000 [00:18<43:33,  2.63s/it]Epoch:   8
max of grad d_p:  tensor(0.0065, device='cuda:0')
min of grad d_p:  tensor(-0.0832, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0022, device='cuda:0') mean:  tensor(-4.8707e-06, device='cuda:0') min:  tensor(-0.0054, device='cuda:0') norm:  tensor(0.0589, device='cuda:0') MSE:  tensor(2.2124e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.9177e-05, device='cuda:0') mean:  tensor(6.3755e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.5135e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0037, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  8  
Training Loss: 0.062488432973623276
Test Loss:  0.06599945574998856
Test Acc:  0.0
Valid Loss:  0.07896336913108826
Valid Acc:  0.0
std:  0.000838636954830549 
thres:  6.366966292262077e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  1%|          | 8/1000 [00:21<43:04,  2.61s/it]Epoch:   9
max of grad d_p:  tensor(0.0064, device='cuda:0')
min of grad d_p:  tensor(-0.0828, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0031, device='cuda:0') mean:  tensor(-5.3491e-06, device='cuda:0') min:  tensor(-0.0051, device='cuda:0') norm:  tensor(0.0613, device='cuda:0') MSE:  tensor(2.3011e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.6115e-05, device='cuda:0') mean:  tensor(1.1728e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.7040e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0041, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  9  
Training Loss: 0.0619637668132782
Test Loss:  0.06541058421134949
Test Acc:  0.0
Valid Loss:  0.07826070487499237
Valid Acc:  0.0
std:  0.0008320096977486856 
thres:  6.309780403971672e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  1%|          | 9/1000 [00:24<44:12,  2.68s/it]Epoch:   10
max of grad d_p:  tensor(0.0063, device='cuda:0')
min of grad d_p:  tensor(-0.0823, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0041, device='cuda:0') mean:  tensor(-5.8621e-06, device='cuda:0') min:  tensor(-0.0048, device='cuda:0') norm:  tensor(0.0641, device='cuda:0') MSE:  tensor(2.4066e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.1679e-05, device='cuda:0') mean:  tensor(5.9024e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.3421e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0035, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  10  
Training Loss: 0.061440788209438324
Test Loss:  0.06482115387916565
Test Acc:  0.0
Valid Loss:  0.07755951583385468
Valid Acc:  0.0
std:  0.0008013622170190265 
thres:  6.253075227141381e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  1%|          | 10/1000 [00:26<44:43,  2.71s/it]Epoch:   11
max of grad d_p:  tensor(0.0063, device='cuda:0')
min of grad d_p:  tensor(-0.0819, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0030, device='cuda:0') mean:  tensor(-5.5710e-06, device='cuda:0') min:  tensor(-0.0058, device='cuda:0') norm:  tensor(0.0640, device='cuda:0') MSE:  tensor(2.4021e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.0251e-05, device='cuda:0') mean:  tensor(3.8656e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5369e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0161, device='cuda:0')
min of d_p_list:  tensor(-0.0074, device='cuda:0')
Epoch:  11  
Training Loss: 0.06088627502322197
Test Loss:  0.06413862109184265
Test Acc:  0.0
Valid Loss:  0.07678958028554916
Valid Acc:  0.0
std:  0.0007524725091126476 
thres:  6.196039468050003e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  1%|          | 11/1000 [00:29<44:43,  2.71s/it]Epoch:   12
max of grad d_p:  tensor(0.0062, device='cuda:0')
min of grad d_p:  tensor(-0.0813, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0038, device='cuda:0') mean:  tensor(-5.7667e-06, device='cuda:0') min:  tensor(-0.0055, device='cuda:0') norm:  tensor(0.0599, device='cuda:0') MSE:  tensor(2.2478e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.7103e-05, device='cuda:0') mean:  tensor(4.3972e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7495e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0035, device='cuda:0')
min of d_p_list:  tensor(-0.0023, device='cuda:0')
Epoch:  12  
Training Loss: 0.060373976826667786
Test Loss:  0.06355565041303635
Test Acc:  0.0
Valid Loss:  0.07609827816486359
Valid Acc:  0.0
std:  0.0007504829711244952 
thres:  6.143064796924591e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  1%|          | 12/1000 [00:32<45:15,  2.75s/it]Epoch:   13
max of grad d_p:  tensor(0.0061, device='cuda:0')
min of grad d_p:  tensor(-0.0809, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0038, device='cuda:0') mean:  tensor(-6.6996e-06, device='cuda:0') min:  tensor(-0.0069, device='cuda:0') norm:  tensor(0.0682, device='cuda:0') MSE:  tensor(2.5595e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(3.2654e-06, device='cuda:0') min:  tensor(7.2760e-12, device='cuda:0') norm:  tensor(0.0033, device='cuda:0') MSE:  tensor(1.2471e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0035, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  13  
Training Loss: 0.05986768752336502
Test Loss:  0.06298452615737915
Test Acc:  0.0
Valid Loss:  0.07541805505752563
Valid Acc:  0.0
std:  0.0007438277148146536 
thres:  6.0906498879194265e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  1%|▏         | 13/1000 [00:35<47:12,  2.87s/it]Epoch:   14
max of grad d_p:  tensor(0.0060, device='cuda:0')
min of grad d_p:  tensor(-0.0804, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0046, device='cuda:0') mean:  tensor(-7.4055e-06, device='cuda:0') min:  tensor(-0.0075, device='cuda:0') norm:  tensor(0.0739, device='cuda:0') MSE:  tensor(2.7757e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(4.9025e-06, device='cuda:0') min:  tensor(5.4570e-12, device='cuda:0') norm:  tensor(0.0051, device='cuda:0') MSE:  tensor(1.9129e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0020, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  14  
Training Loss: 0.05936744436621666
Test Loss:  0.06241966784000397
Test Acc:  0.0
Valid Loss:  0.07474574446678162
Valid Acc:  0.0
std:  0.000730628990156211 
thres:  6.038723438978195e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  1%|▏         | 14/1000 [00:38<47:17,  2.88s/it]Epoch:   15
max of grad d_p:  tensor(0.0060, device='cuda:0')
min of grad d_p:  tensor(-0.0800, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0041, device='cuda:0') mean:  tensor(-8.0247e-06, device='cuda:0') min:  tensor(-0.0099, device='cuda:0') norm:  tensor(0.0786, device='cuda:0') MSE:  tensor(2.9504e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.9659e-05, device='cuda:0') mean:  tensor(3.6389e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4745e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0023, device='cuda:0')
Epoch:  15  
Training Loss: 0.05887226760387421
Test Loss:  0.06186247989535332
Test Acc:  0.0
Valid Loss:  0.07408104836940765
Valid Acc:  0.0
std:  0.0007120088057788392 
thres:  5.987353026866913e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  2%|▏         | 15/1000 [00:41<47:03,  2.87s/it]Epoch:   16
max of grad d_p:  tensor(0.0059, device='cuda:0')
min of grad d_p:  tensor(-0.0796, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0046, device='cuda:0') mean:  tensor(-7.3300e-06, device='cuda:0') min:  tensor(-0.0078, device='cuda:0') norm:  tensor(0.0678, device='cuda:0') MSE:  tensor(2.5460e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.4102e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.7550e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0045, device='cuda:0')
min of d_p_list:  tensor(-0.0056, device='cuda:0')
Epoch:  16  
Training Loss: 0.0583772137761116
Test Loss:  0.061294786632061005
Test Acc:  0.0
Valid Loss:  0.07341022789478302
Valid Acc:  0.0
std:  0.0007055517184740179 
thres:  5.937171801924705e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  2%|▏         | 16/1000 [00:43<45:13,  2.76s/it]Epoch:   17
max of grad d_p:  tensor(0.0059, device='cuda:0')
min of grad d_p:  tensor(-0.0792, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0047, device='cuda:0') mean:  tensor(-6.9351e-06, device='cuda:0') min:  tensor(-0.0075, device='cuda:0') norm:  tensor(0.0657, device='cuda:0') MSE:  tensor(2.4652e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.8568e-05, device='cuda:0') mean:  tensor(3.8247e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5732e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0028, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  17  
Training Loss: 0.05788885056972504
Test Loss:  0.06073984503746033
Test Acc:  0.0
Valid Loss:  0.07275247573852539
Valid Acc:  0.0
std:  0.0006997454952221493 
thres:  5.8874692767858506e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  2%|▏         | 17/1000 [00:46<45:04,  2.75s/it]Epoch:   18
max of grad d_p:  tensor(0.0061, device='cuda:0')
min of grad d_p:  tensor(-0.0788, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0051, device='cuda:0') mean:  tensor(-7.3164e-06, device='cuda:0') min:  tensor(-0.0068, device='cuda:0') norm:  tensor(0.0735, device='cuda:0') MSE:  tensor(2.7586e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.1184e-05, device='cuda:0') mean:  tensor(3.5520e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4525e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0023, device='cuda:0')
min of d_p_list:  tensor(-0.0032, device='cuda:0')
Epoch:  18  
Training Loss: 0.05740828067064285
Test Loss:  0.06020214408636093
Test Acc:  0.0
Valid Loss:  0.07210908830165863
Valid Acc:  0.0
std:  0.0006932255378117668 
thres:  5.8382811397314075e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  2%|▏         | 18/1000 [00:49<44:19,  2.71s/it]Epoch:   19
max of grad d_p:  tensor(0.0058, device='cuda:0')
min of grad d_p:  tensor(-0.0783, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0059, device='cuda:0') mean:  tensor(-7.5870e-06, device='cuda:0') min:  tensor(-0.0064, device='cuda:0') norm:  tensor(0.0758, device='cuda:0') MSE:  tensor(2.8435e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.1249e-05, device='cuda:0') mean:  tensor(4.2087e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7197e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0032, device='cuda:0')
min of d_p_list:  tensor(-0.0031, device='cuda:0')
Epoch:  19  
Training Loss: 0.05693022161722183
Test Loss:  0.05965786427259445
Test Acc:  0.0
Valid Loss:  0.07146485894918442
Valid Acc:  0.0
std:  0.0006863398970636898 
thres:  5.789536684751511e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  2%|▏         | 19/1000 [00:51<43:47,  2.68s/it]Epoch:   20
max of grad d_p:  tensor(0.0058, device='cuda:0')
min of grad d_p:  tensor(-0.0779, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0039, device='cuda:0') mean:  tensor(-8.3566e-06, device='cuda:0') min:  tensor(-0.0115, device='cuda:0') norm:  tensor(0.0824, device='cuda:0') MSE:  tensor(3.0918e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.6057e-05, device='cuda:0') mean:  tensor(4.0339e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5944e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0043, device='cuda:0')
min of d_p_list:  tensor(-0.0033, device='cuda:0')
Epoch:  20  
Training Loss: 0.05645417794585228
Test Loss:  0.05910923331975937
Test Acc:  0.0
Valid Loss:  0.07081883400678635
Valid Acc:  0.0
std:  0.0006794955651307202 
thres:  5.741174891591072e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  2%|▏         | 20/1000 [00:54<44:08,  2.70s/it]Epoch:   21
max of grad d_p:  tensor(0.0059, device='cuda:0')
min of grad d_p:  tensor(-0.0775, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0055, device='cuda:0') mean:  tensor(-8.3047e-06, device='cuda:0') min:  tensor(-0.0080, device='cuda:0') norm:  tensor(0.0791, device='cuda:0') MSE:  tensor(2.9683e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.6025e-05, device='cuda:0') mean:  tensor(3.9504e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.6110e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0030, device='cuda:0')
min of d_p_list:  tensor(-0.0025, device='cuda:0')
Epoch:  21  
Training Loss: 0.05598583072423935
Test Loss:  0.058576133102178574
Test Acc:  0.0
Valid Loss:  0.07018758356571198
Valid Acc:  0.0
std:  0.0006731937058621179 
thres:  5.693347230553627e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  2%|▏         | 21/1000 [00:57<44:01,  2.70s/it]Epoch:   22
max of grad d_p:  tensor(0.0061, device='cuda:0')
min of grad d_p:  tensor(-0.0771, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0064, device='cuda:0') mean:  tensor(-9.0627e-06, device='cuda:0') min:  tensor(-0.0095, device='cuda:0') norm:  tensor(0.0816, device='cuda:0') MSE:  tensor(3.0627e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.7098e-05, device='cuda:0') mean:  tensor(4.2819e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7179e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0030, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  22  
Training Loss: 0.0555233396589756
Test Loss:  0.05804871767759323
Test Acc:  0.0
Valid Loss:  0.0695621520280838
Valid Acc:  0.0
std:  0.0006667153676793104 
thres:  5.646037012338638e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  2%|▏         | 22/1000 [00:59<44:03,  2.70s/it]Epoch:   23
max of grad d_p:  tensor(0.0061, device='cuda:0')
min of grad d_p:  tensor(-0.0767, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0060, device='cuda:0') mean:  tensor(-8.5669e-06, device='cuda:0') min:  tensor(-0.0089, device='cuda:0') norm:  tensor(0.0748, device='cuda:0') MSE:  tensor(2.8061e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.3862e-05, device='cuda:0') mean:  tensor(5.7188e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2342e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0017, device='cuda:0')
min of d_p_list:  tensor(-0.0023, device='cuda:0')
Epoch:  23  
Training Loss: 0.05506867915391922
Test Loss:  0.05753491818904877
Test Acc:  0.0
Valid Loss:  0.06894825398921967
Valid Acc:  0.0
std:  0.0006581898214017104 
thres:  5.599244982004166e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  2%|▏         | 23/1000 [01:02<43:58,  2.70s/it]Epoch:   24
max of grad d_p:  tensor(0.0061, device='cuda:0')
min of grad d_p:  tensor(-0.0763, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0068, device='cuda:0') mean:  tensor(-1.0776e-05, device='cuda:0') min:  tensor(-0.0129, device='cuda:0') norm:  tensor(0.0943, device='cuda:0') MSE:  tensor(3.5397e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.9551e-05, device='cuda:0') mean:  tensor(4.4076e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7738e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0029, device='cuda:0')
min of d_p_list:  tensor(-0.0032, device='cuda:0')
Epoch:  24  
Training Loss: 0.054615318775177
Test Loss:  0.0570128932595253
Test Acc:  0.0
Valid Loss:  0.06833233684301376
Valid Acc:  0.0
std:  0.0006498289224874666 
thres:  5.552946925163269e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  2%|▏         | 24/1000 [01:05<43:11,  2.66s/it]Epoch:   25
max of grad d_p:  tensor(0.0062, device='cuda:0')
min of grad d_p:  tensor(-0.0759, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0058, device='cuda:0') mean:  tensor(-9.0007e-06, device='cuda:0') min:  tensor(-0.0109, device='cuda:0') norm:  tensor(0.0774, device='cuda:0') MSE:  tensor(2.9051e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.8153e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.8839e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0039, device='cuda:0')
min of d_p_list:  tensor(-0.0029, device='cuda:0')
Epoch:  25  
Training Loss: 0.054162148386240005
Test Loss:  0.05649162828922272
Test Acc:  0.0
Valid Loss:  0.06771527230739594
Valid Acc:  0.0
std:  0.0006442341844161524 
thres:  5.5071063339710235e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  2%|▎         | 25/1000 [01:07<43:50,  2.70s/it]Epoch:   26
max of grad d_p:  tensor(0.0066, device='cuda:0')
min of grad d_p:  tensor(-0.0755, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0061, device='cuda:0') mean:  tensor(-8.8115e-06, device='cuda:0') min:  tensor(-0.0108, device='cuda:0') norm:  tensor(0.0783, device='cuda:0') MSE:  tensor(2.9410e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.4711e-07, device='cuda:0') min:  tensor(3.6380e-12, device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.6316e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0044, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  26  
Training Loss: 0.05372121185064316
Test Loss:  0.055994316935539246
Test Acc:  0.0
Valid Loss:  0.06712570041418076
Valid Acc:  0.0
std:  0.000637932342503573 
thres:  5.4618139564991e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  3%|▎         | 26/1000 [01:10<42:58,  2.65s/it]Epoch:   27
max of grad d_p:  tensor(0.0064, device='cuda:0')
min of grad d_p:  tensor(-0.0751, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0064, device='cuda:0') mean:  tensor(-9.4568e-06, device='cuda:0') min:  tensor(-0.0112, device='cuda:0') norm:  tensor(0.0828, device='cuda:0') MSE:  tensor(3.1087e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.3218e-05, device='cuda:0') mean:  tensor(5.7722e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.3970e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  27  
Training Loss: 0.05328210070729256
Test Loss:  0.0554935559630394
Test Acc:  0.0
Valid Loss:  0.06653048098087311
Valid Acc:  0.0
std:  0.0006317864480158839 
thres:  5.416989177465439e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  3%|▎         | 27/1000 [01:13<44:11,  2.73s/it]Epoch:   28
max of grad d_p:  tensor(0.0064, device='cuda:0')
min of grad d_p:  tensor(-0.0747, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0066, device='cuda:0') mean:  tensor(-9.3668e-06, device='cuda:0') min:  tensor(-0.0100, device='cuda:0') norm:  tensor(0.0814, device='cuda:0') MSE:  tensor(3.0555e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.0524e-05, device='cuda:0') mean:  tensor(5.5775e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2841e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0018, device='cuda:0')
min of d_p_list:  tensor(-0.0034, device='cuda:0')
Epoch:  28  
Training Loss: 0.0528474897146225
Test Loss:  0.05499371141195297
Test Acc:  0.0
Valid Loss:  0.065938301384449
Valid Acc:  0.0
std:  0.0006244937997586243 
thres:  5.372565388679504e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  3%|▎         | 28/1000 [01:16<44:23,  2.74s/it]Epoch:   29
max of grad d_p:  tensor(0.0062, device='cuda:0')
min of grad d_p:  tensor(-0.0744, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0085, device='cuda:0') mean:  tensor(-1.1399e-05, device='cuda:0') min:  tensor(-0.0143, device='cuda:0') norm:  tensor(0.0978, device='cuda:0') MSE:  tensor(3.6708e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.3823e-05, device='cuda:0') mean:  tensor(4.7461e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9636e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0029, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  29  
Training Loss: 0.05241628736257553
Test Loss:  0.05450022965669632
Test Acc:  0.0
Valid Loss:  0.0653514564037323
Valid Acc:  0.0
std:  0.0006173737571504356 
thres:  5.3285847604274754e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  3%|▎         | 29/1000 [01:19<45:32,  2.81s/it]Epoch:   30
max of grad d_p:  tensor(0.0065, device='cuda:0')
min of grad d_p:  tensor(-0.0740, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0070, device='cuda:0') mean:  tensor(-9.6986e-06, device='cuda:0') min:  tensor(-0.0115, device='cuda:0') norm:  tensor(0.0835, device='cuda:0') MSE:  tensor(3.1360e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.1057e-05, device='cuda:0') mean:  tensor(4.4719e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8368e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0025, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  30  
Training Loss: 0.0519920289516449
Test Loss:  0.05401848256587982
Test Acc:  0.0
Valid Loss:  0.06477710604667664
Valid Acc:  0.0
std:  0.0006115442344473138 
thres:  5.285182371735573e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  3%|▎         | 30/1000 [01:22<46:12,  2.86s/it]Epoch:   31
max of grad d_p:  tensor(0.0066, device='cuda:0')
min of grad d_p:  tensor(-0.0736, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0080, device='cuda:0') mean:  tensor(-1.0699e-05, device='cuda:0') min:  tensor(-0.0130, device='cuda:0') norm:  tensor(0.0936, device='cuda:0') MSE:  tensor(3.5126e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(2.8386e-06, device='cuda:0') min:  tensor(7.9581e-13, device='cuda:0') norm:  tensor(0.0030, device='cuda:0') MSE:  tensor(1.1425e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0016, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  31  
Training Loss: 0.05157282203435898
Test Loss:  0.05354200303554535
Test Acc:  0.0
Valid Loss:  0.06420836597681046
Valid Acc:  0.0
std:  0.0006044543939278725 
thres:  5.2422145754098895e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  3%|▎         | 31/1000 [01:24<44:57,  2.78s/it]Epoch:   32
max of grad d_p:  tensor(0.0066, device='cuda:0')
min of grad d_p:  tensor(-0.0732, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0065, device='cuda:0') mean:  tensor(-1.0899e-05, device='cuda:0') min:  tensor(-0.0145, device='cuda:0') norm:  tensor(0.0919, device='cuda:0') MSE:  tensor(3.4503e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.9121e-05, device='cuda:0') mean:  tensor(5.1119e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.1393e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  32  
Training Loss: 0.05115613341331482
Test Loss:  0.053064245730638504
Test Acc:  0.0
Valid Loss:  0.06364183127880096
Valid Acc:  0.0
std:  0.0005976860229545615 
thres:  5.1996952295303345e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  3%|▎         | 32/1000 [01:27<45:53,  2.84s/it]Epoch:   33
max of grad d_p:  tensor(0.0066, device='cuda:0')
min of grad d_p:  tensor(-0.0729, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0064, device='cuda:0') mean:  tensor(-1.0491e-05, device='cuda:0') min:  tensor(-0.0150, device='cuda:0') norm:  tensor(0.0906, device='cuda:0') MSE:  tensor(3.4018e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.5084e-05, device='cuda:0') mean:  tensor(6.3139e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.6007e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0137, device='cuda:0')
min of d_p_list:  tensor(-0.0109, device='cuda:0')
Epoch:  33  
Training Loss: 0.050741046667099
Test Loss:  0.05262574926018715
Test Acc:  0.0
Valid Loss:  0.06308002769947052
Valid Acc:  0.0
std:  0.0005920485610112491 
thres:  5.157566368579865e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  3%|▎         | 33/1000 [01:30<45:43,  2.84s/it]Epoch:   34
max of grad d_p:  tensor(0.0055, device='cuda:0')
min of grad d_p:  tensor(-0.0725, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0062, device='cuda:0') mean:  tensor(-1.0990e-05, device='cuda:0') min:  tensor(-0.0156, device='cuda:0') norm:  tensor(0.0931, device='cuda:0') MSE:  tensor(3.4960e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(8.9720e-07, device='cuda:0') min:  tensor(3.9790e-13, device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.7225e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0022, device='cuda:0')
min of d_p_list:  tensor(-0.0027, device='cuda:0')
Epoch:  34  
Training Loss: 0.05033683404326439
Test Loss:  0.05216589197516441
Test Acc:  0.0
Valid Loss:  0.06253219395875931
Valid Acc:  0.0
std:  0.0005858042315999929 
thres:  5.1159773021936416e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  3%|▎         | 34/1000 [01:33<44:56,  2.79s/it]Epoch:   35
max of grad d_p:  tensor(0.0054, device='cuda:0')
min of grad d_p:  tensor(-0.0722, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0066, device='cuda:0') mean:  tensor(-1.2260e-05, device='cuda:0') min:  tensor(-0.0192, device='cuda:0') norm:  tensor(0.1030, device='cuda:0') MSE:  tensor(3.8663e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.7375e-05, device='cuda:0') mean:  tensor(7.9955e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.2775e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0019, device='cuda:0')
min of d_p_list:  tensor(-0.0037, device='cuda:0')
Epoch:  35  
Training Loss: 0.049936167895793915
Test Loss:  0.051705799996852875
Test Acc:  0.0
Valid Loss:  0.06198533624410629
Valid Acc:  0.0
std:  0.0005788056020455619 
thres:  5.0748600810766226e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  4%|▎         | 35/1000 [01:35<43:55,  2.73s/it]Epoch:   36
max of grad d_p:  tensor(0.0052, device='cuda:0')
min of grad d_p:  tensor(-0.0718, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0078, device='cuda:0') mean:  tensor(-1.0848e-05, device='cuda:0') min:  tensor(-0.0143, device='cuda:0') norm:  tensor(0.0976, device='cuda:0') MSE:  tensor(3.6621e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.8375e-05, device='cuda:0') mean:  tensor(4.4853e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8643e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0018, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  36  
Training Loss: 0.04953860118985176
Test Loss:  0.0512523278594017
Test Acc:  0.0
Valid Loss:  0.06144315004348755
Valid Acc:  0.0
std:  0.0005713540396537838 
thres:  5.034175664186478e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  4%|▎         | 36/1000 [01:38<43:20,  2.70s/it]Epoch:   37
max of grad d_p:  tensor(0.0053, device='cuda:0')
min of grad d_p:  tensor(-0.0714, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0086, device='cuda:0') mean:  tensor(-1.2236e-05, device='cuda:0') min:  tensor(-0.0161, device='cuda:0') norm:  tensor(0.1001, device='cuda:0') MSE:  tensor(3.7581e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.2516e-05, device='cuda:0') mean:  tensor(5.3779e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2745e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0022, device='cuda:0')
min of d_p_list:  tensor(-0.0029, device='cuda:0')
Epoch:  37  
Training Loss: 0.049142830073833466
Test Loss:  0.05079900473356247
Test Acc:  0.0
Valid Loss:  0.060905180871486664
Valid Acc:  0.0
std:  0.0005649361938208731 
thres:  4.993909597396851e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  4%|▎         | 37/1000 [01:41<42:56,  2.68s/it]Epoch:   38
max of grad d_p:  tensor(0.0052, device='cuda:0')
min of grad d_p:  tensor(-0.0710, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0072, device='cuda:0') mean:  tensor(-1.2092e-05, device='cuda:0') min:  tensor(-0.0166, device='cuda:0') norm:  tensor(0.0965, device='cuda:0') MSE:  tensor(3.6237e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(4.1763e-06, device='cuda:0') min:  tensor(1.8048e-12, device='cuda:0') norm:  tensor(0.0045, device='cuda:0') MSE:  tensor(1.6878e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0032, device='cuda:0')
Epoch:  38  
Training Loss: 0.04874994605779648
Test Loss:  0.05033889785408974
Test Acc:  0.0
Valid Loss:  0.06036432832479477
Valid Acc:  0.0
std:  0.0005610384651858665 
thres:  4.9540875852108e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  4%|▍         | 38/1000 [01:43<44:09,  2.75s/it]Epoch:   39
max of grad d_p:  tensor(0.0050, device='cuda:0')
min of grad d_p:  tensor(-0.0707, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0073, device='cuda:0') mean:  tensor(-1.3441e-05, device='cuda:0') min:  tensor(-0.0201, device='cuda:0') norm:  tensor(0.1077, device='cuda:0') MSE:  tensor(4.0411e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.1152e-05, device='cuda:0') mean:  tensor(5.0836e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.0727e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0084, device='cuda:0')
min of d_p_list:  tensor(-0.0083, device='cuda:0')
Epoch:  39  
Training Loss: 0.04836006835103035
Test Loss:  0.04989304393529892
Test Acc:  0.0
Valid Loss:  0.05983928591012955
Valid Acc:  0.0
std:  0.0005573252531913767 
thres:  4.91455227136612e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  4%|▍         | 39/1000 [01:46<45:00,  2.81s/it]Epoch:   40
max of grad d_p:  tensor(0.0060, device='cuda:0')
min of grad d_p:  tensor(-0.0703, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0077, device='cuda:0') mean:  tensor(-1.1656e-05, device='cuda:0') min:  tensor(-0.0151, device='cuda:0') norm:  tensor(0.0977, device='cuda:0') MSE:  tensor(3.6679e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.9051e-05, device='cuda:0') mean:  tensor(6.1626e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.6073e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0023, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  40  
Training Loss: 0.04797239229083061
Test Loss:  0.04944820702075958
Test Acc:  0.0
Valid Loss:  0.05930952727794647
Valid Acc:  0.0
std:  0.000553694762271658 
thres:  4.8752767592668535e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  4%|▍         | 40/1000 [01:49<44:25,  2.78s/it]Epoch:   41
max of grad d_p:  tensor(0.0064, device='cuda:0')
min of grad d_p:  tensor(-0.0699, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0089, device='cuda:0') mean:  tensor(-1.2525e-05, device='cuda:0') min:  tensor(-0.0183, device='cuda:0') norm:  tensor(0.1026, device='cuda:0') MSE:  tensor(3.8520e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.5975e-05, device='cuda:0') mean:  tensor(6.5209e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.6401e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0016, device='cuda:0')
min of d_p_list:  tensor(-0.0025, device='cuda:0')
Epoch:  41  
Training Loss: 0.04759296774864197
Test Loss:  0.04901079088449478
Test Acc:  0.0
Valid Loss:  0.05879030376672745
Valid Acc:  0.0
std:  0.0005483416429684475 
thres:  4.836364090442657e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  4%|▍         | 41/1000 [01:52<43:44,  2.74s/it]Epoch:   42
max of grad d_p:  tensor(0.0063, device='cuda:0')
min of grad d_p:  tensor(-0.0696, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0075, device='cuda:0') mean:  tensor(-1.2198e-05, device='cuda:0') min:  tensor(-0.0172, device='cuda:0') norm:  tensor(0.0988, device='cuda:0') MSE:  tensor(3.7080e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.4235e-05, device='cuda:0') mean:  tensor(6.1058e-07, device='cuda:0') min:  tensor(5.6843e-14, device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.5844e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0030, device='cuda:0')
Epoch:  42  
Training Loss: 0.04721515253186226
Test Loss:  0.04856935888528824
Test Acc:  0.0
Valid Loss:  0.058273039758205414
Valid Acc:  0.0
std:  0.0005426038013315207 
thres:  4.7978105396032336e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  4%|▍         | 42/1000 [01:54<43:31,  2.73s/it]Epoch:   43
max of grad d_p:  tensor(0.0064, device='cuda:0')
min of grad d_p:  tensor(-0.0692, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0076, device='cuda:0') mean:  tensor(-1.2593e-05, device='cuda:0') min:  tensor(-0.0178, device='cuda:0') norm:  tensor(0.1041, device='cuda:0') MSE:  tensor(3.9091e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(3.6878e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0040, device='cuda:0') MSE:  tensor(1.5157e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0076, device='cuda:0')
min of d_p_list:  tensor(-0.0086, device='cuda:0')
Epoch:  43  
Training Loss: 0.04685119912028313
Test Loss:  0.0481896698474884
Test Acc:  0.0
Valid Loss:  0.05778816342353821
Valid Acc:  0.0
std:  0.0005338962795757709 
thres:  4.7598356008529664e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  4%|▍         | 43/1000 [01:57<43:37,  2.74s/it]Epoch:   44
max of grad d_p:  tensor(0.0073, device='cuda:0')
min of grad d_p:  tensor(-0.0689, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0106, device='cuda:0') mean:  tensor(-1.4131e-05, device='cuda:0') min:  tensor(-0.0190, device='cuda:0') norm:  tensor(0.1102, device='cuda:0') MSE:  tensor(4.1378e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(2.5776e-06, device='cuda:0') min:  tensor(1.0914e-11, device='cuda:0') norm:  tensor(0.0028, device='cuda:0') MSE:  tensor(1.0661e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  44  
Training Loss: 0.04648318141698837
Test Loss:  0.04776842147111893
Test Acc:  0.0
Valid Loss:  0.057286303490400314
Valid Acc:  0.0
std:  0.0005261357146193652 
thres:  4.7222978621721273e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  4%|▍         | 44/1000 [02:00<43:11,  2.71s/it]Epoch:   45
max of grad d_p:  tensor(0.0073, device='cuda:0')
min of grad d_p:  tensor(-0.0686, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0084, device='cuda:0') mean:  tensor(-1.3689e-05, device='cuda:0') min:  tensor(-0.0193, device='cuda:0') norm:  tensor(0.1082, device='cuda:0') MSE:  tensor(4.0632e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.1847e-06, device='cuda:0') min:  tensor(2.2737e-12, device='cuda:0') norm:  tensor(0.0014, device='cuda:0') MSE:  tensor(5.1404e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0060, device='cuda:0')
min of d_p_list:  tensor(-0.0035, device='cuda:0')
Epoch:  45  
Training Loss: 0.04610588401556015
Test Loss:  0.047332294285297394
Test Acc:  0.0
Valid Loss:  0.05677284300327301
Valid Acc:  0.0
std:  0.000524137927329412 
thres:  4.684967696666718e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  4%|▍         | 45/1000 [02:03<43:03,  2.71s/it]Epoch:   46
max of grad d_p:  tensor(0.0075, device='cuda:0')
min of grad d_p:  tensor(-0.0682, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0122, device='cuda:0') mean:  tensor(-1.2759e-05, device='cuda:0') min:  tensor(-0.0173, device='cuda:0') norm:  tensor(0.1062, device='cuda:0') MSE:  tensor(3.9852e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.2637e-05, device='cuda:0') mean:  tensor(5.6373e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.3868e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  46  
Training Loss: 0.04574466496706009
Test Loss:  0.04691643267869949
Test Acc:  0.0
Valid Loss:  0.05627940595149994
Valid Acc:  0.0
std:  0.0005213307074309263 
thres:  4.64800164103508e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  5%|▍         | 46/1000 [02:06<44:44,  2.81s/it]Epoch:   47
max of grad d_p:  tensor(0.0075, device='cuda:0')
min of grad d_p:  tensor(-0.0679, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0109, device='cuda:0') mean:  tensor(-1.3300e-05, device='cuda:0') min:  tensor(-0.0188, device='cuda:0') norm:  tensor(0.1075, device='cuda:0') MSE:  tensor(4.0368e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0039, device='cuda:0') mean:  tensor(2.5902e-05, device='cuda:0') min:  tensor(2.0464e-11, device='cuda:0') norm:  tensor(0.0280, device='cuda:0') MSE:  tensor(1.0497e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  47  
Training Loss: 0.04538746178150177
Test Loss:  0.04650374501943588
Test Acc:  0.0
Valid Loss:  0.05578950047492981
Valid Acc:  0.0
std:  0.0005184762938900915 
thres:  4.61144782602787e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  5%|▍         | 47/1000 [02:08<44:12,  2.78s/it]Epoch:   48
max of grad d_p:  tensor(0.0075, device='cuda:0')
min of grad d_p:  tensor(-0.0675, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0107, device='cuda:0') mean:  tensor(-1.4051e-05, device='cuda:0') min:  tensor(-0.0178, device='cuda:0') norm:  tensor(0.1122, device='cuda:0') MSE:  tensor(4.2104e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.9828e-05, device='cuda:0') mean:  tensor(6.2216e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.7249e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0061, device='cuda:0')
min of d_p_list:  tensor(-0.0044, device='cuda:0')
Epoch:  48  
Training Loss: 0.04502588510513306
Test Loss:  0.04608695209026337
Test Acc:  0.0
Valid Loss:  0.055286966264247894
Valid Acc:  0.0
std:  0.0005138115447736961 
thres:  4.574941545724869e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  5%|▍         | 48/1000 [02:11<45:17,  2.85s/it]Epoch:   49
max of grad d_p:  tensor(0.0069, device='cuda:0')
min of grad d_p:  tensor(-0.0672, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0103, device='cuda:0') mean:  tensor(-1.4280e-05, device='cuda:0') min:  tensor(-0.0210, device='cuda:0') norm:  tensor(0.1109, device='cuda:0') MSE:  tensor(4.1639e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(7.2774e-07, device='cuda:0') min:  tensor(8.2423e-13, device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.9861e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  49  
Training Loss: 0.04467269778251648
Test Loss:  0.04567883908748627
Test Acc:  0.0
Valid Loss:  0.05480080842971802
Valid Acc:  0.0
std:  0.0005070206676228456 
thres:  4.538731873035431e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  5%|▍         | 49/1000 [02:14<45:10,  2.85s/it]Epoch:   50
max of grad d_p:  tensor(0.0071, device='cuda:0')
min of grad d_p:  tensor(-0.0668, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0103, device='cuda:0') mean:  tensor(-1.3781e-05, device='cuda:0') min:  tensor(-0.0190, device='cuda:0') norm:  tensor(0.1123, device='cuda:0') MSE:  tensor(4.2158e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.5490e-05, device='cuda:0') mean:  tensor(6.6321e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.7341e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  50  
Training Loss: 0.04432301968336105
Test Loss:  0.04527117311954498
Test Acc:  0.0
Valid Loss:  0.05431761592626572
Valid Acc:  0.0
std:  0.0005031948199069292 
thres:  4.5030745863914496e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  5%|▌         | 50/1000 [02:17<44:38,  2.82s/it]Epoch:   51
max of grad d_p:  tensor(0.0072, device='cuda:0')
min of grad d_p:  tensor(-0.0665, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0089, device='cuda:0') mean:  tensor(-1.3972e-05, device='cuda:0') min:  tensor(-0.0207, device='cuda:0') norm:  tensor(0.1096, device='cuda:0') MSE:  tensor(4.1148e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(1.0542e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.4644e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0030, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  51  
Training Loss: 0.04397793486714363
Test Loss:  0.04486837983131409
Test Acc:  0.0
Valid Loss:  0.053841911256313324
Valid Acc:  0.0
std:  0.0004980940862530096 
thres:  4.46773998439312e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  5%|▌         | 51/1000 [02:20<43:30,  2.75s/it]Epoch:   52
max of grad d_p:  tensor(0.0073, device='cuda:0')
min of grad d_p:  tensor(-0.0662, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0119, device='cuda:0') mean:  tensor(-1.3594e-05, device='cuda:0') min:  tensor(-0.0175, device='cuda:0') norm:  tensor(0.1209, device='cuda:0') MSE:  tensor(4.5399e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(1.1656e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(5.0314e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0082, device='cuda:0')
min of d_p_list:  tensor(-0.0084, device='cuda:0')
Epoch:  52  
Training Loss: 0.04362129420042038
Test Loss:  0.044407185167074203
Test Acc:  0.0
Valid Loss:  0.0533195436000824
Valid Acc:  0.0
std:  0.0004955381284981915 
thres:  4.4324166327714925e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  5%|▌         | 52/1000 [02:22<43:33,  2.76s/it]Epoch:   53
max of grad d_p:  tensor(0.0061, device='cuda:0')
min of grad d_p:  tensor(-0.0657, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0092, device='cuda:0') mean:  tensor(-1.4540e-05, device='cuda:0') min:  tensor(-0.0208, device='cuda:0') norm:  tensor(0.1203, device='cuda:0') MSE:  tensor(4.5157e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.2149e-05, device='cuda:0') mean:  tensor(5.8213e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.4471e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  53  
Training Loss: 0.043283611536026
Test Loss:  0.04401686415076256
Test Acc:  0.0
Valid Loss:  0.052854023873806
Valid Acc:  0.0
std:  0.0004921446490578168 
thres:  4.397571161389351e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  5%|▌         | 53/1000 [02:25<45:28,  2.88s/it]Epoch:   54
max of grad d_p:  tensor(0.0062, device='cuda:0')
min of grad d_p:  tensor(-0.0654, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0122, device='cuda:0') mean:  tensor(-1.4854e-05, device='cuda:0') min:  tensor(-0.0248, device='cuda:0') norm:  tensor(0.1302, device='cuda:0') MSE:  tensor(4.8879e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.5521e-05, device='cuda:0') mean:  tensor(6.6476e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.7607e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0073, device='cuda:0')
min of d_p_list:  tensor(-0.0057, device='cuda:0')
Epoch:  54  
Training Loss: 0.04297129809856415
Test Loss:  0.04368460178375244
Test Acc:  0.0
Valid Loss:  0.052445508539676666
Valid Acc:  0.0
std:  0.00048065297077936513 
thres:  4.3635431677103044e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  5%|▌         | 54/1000 [02:28<45:33,  2.89s/it]Epoch:   55
max of grad d_p:  tensor(0.0061, device='cuda:0')
min of grad d_p:  tensor(-0.0652, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0125, device='cuda:0') mean:  tensor(-1.4823e-05, device='cuda:0') min:  tensor(-0.0239, device='cuda:0') norm:  tensor(0.1276, device='cuda:0') MSE:  tensor(4.7886e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.6230e-05, device='cuda:0') mean:  tensor(5.5864e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.3968e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0017, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  55  
Training Loss: 0.0426434651017189
Test Loss:  0.043304331600666046
Test Acc:  0.0
Valid Loss:  0.051992267370224
Valid Acc:  0.0
std:  0.0004695052914252598 
thres:  4.329952076077461e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  6%|▌         | 55/1000 [02:31<45:49,  2.91s/it]Epoch:   56
max of grad d_p:  tensor(0.0060, device='cuda:0')
min of grad d_p:  tensor(-0.0648, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0114, device='cuda:0') mean:  tensor(-1.4755e-05, device='cuda:0') min:  tensor(-0.0180, device='cuda:0') norm:  tensor(0.1199, device='cuda:0') MSE:  tensor(4.5023e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.3174e-05, device='cuda:0') mean:  tensor(5.9487e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.5963e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  56  
Training Loss: 0.04231812059879303
Test Loss:  0.04292432218790054
Test Acc:  0.0
Valid Loss:  0.05154239758849144
Valid Acc:  0.0
std:  0.00045914703320712956 
thres:  4.296755790710449e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  6%|▌         | 56/1000 [02:34<46:05,  2.93s/it]Epoch:   57
max of grad d_p:  tensor(0.0059, device='cuda:0')
min of grad d_p:  tensor(-0.0645, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0098, device='cuda:0') mean:  tensor(-1.6134e-05, device='cuda:0') min:  tensor(-0.0238, device='cuda:0') norm:  tensor(0.1255, device='cuda:0') MSE:  tensor(4.7120e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.6385e-05, device='cuda:0') mean:  tensor(6.4910e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.7222e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0083, device='cuda:0')
min of d_p_list:  tensor(-0.0090, device='cuda:0')
Epoch:  57  
Training Loss: 0.041977811604738235
Test Loss:  0.04250665754079819
Test Acc:  0.0
Valid Loss:  0.051053985953330994
Valid Acc:  0.0
std:  0.00046175742200895976 
thres:  4.263886138796806e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  6%|▌         | 57/1000 [02:37<46:33,  2.96s/it]Epoch:   58
max of grad d_p:  tensor(0.0059, device='cuda:0')
min of grad d_p:  tensor(-0.0642, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0111, device='cuda:0') mean:  tensor(-1.5633e-05, device='cuda:0') min:  tensor(-0.0256, device='cuda:0') norm:  tensor(0.1267, device='cuda:0') MSE:  tensor(4.7549e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.5394e-05, device='cuda:0') mean:  tensor(6.7724e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.7936e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0016, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  58  
Training Loss: 0.041656579822301865
Test Loss:  0.04213409870862961
Test Acc:  0.0
Valid Loss:  0.050609804689884186
Valid Acc:  0.0
std:  0.00046601018556162243 
thres:  4.2313455045223236e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  6%|▌         | 58/1000 [02:40<46:18,  2.95s/it]Epoch:   59
max of grad d_p:  tensor(0.0059, device='cuda:0')
min of grad d_p:  tensor(-0.0639, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0110, device='cuda:0') mean:  tensor(-1.6403e-05, device='cuda:0') min:  tensor(-0.0251, device='cuda:0') norm:  tensor(0.1269, device='cuda:0') MSE:  tensor(4.7642e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.4817e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0017, device='cuda:0') MSE:  tensor(6.3339e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0018, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  59  
Training Loss: 0.0413389652967453
Test Loss:  0.04176100343465805
Test Acc:  0.0
Valid Loss:  0.05017025023698807
Valid Acc:  0.0
std:  0.0004625577103706805 
thres:  4.198698848485947e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  6%|▌         | 59/1000 [02:43<45:27,  2.90s/it]Epoch:   60
max of grad d_p:  tensor(0.0060, device='cuda:0')
min of grad d_p:  tensor(-0.0636, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0098, device='cuda:0') mean:  tensor(-1.5566e-05, device='cuda:0') min:  tensor(-0.0252, device='cuda:0') norm:  tensor(0.1224, device='cuda:0') MSE:  tensor(4.5947e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.8940e-05, device='cuda:0') mean:  tensor(7.9080e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.2811e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0063, device='cuda:0')
min of d_p_list:  tensor(-0.0100, device='cuda:0')
Epoch:  60  
Training Loss: 0.04103982448577881
Test Loss:  0.041432611644268036
Test Acc:  0.0
Valid Loss:  0.04978358745574951
Valid Acc:  0.0
std:  0.00045202292525258956 
thres:  4.166626036167145e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  6%|▌         | 60/1000 [02:46<43:53,  2.80s/it]Epoch:   61
max of grad d_p:  tensor(0.0066, device='cuda:0')
min of grad d_p:  tensor(-0.0632, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0088, device='cuda:0') mean:  tensor(-1.4041e-05, device='cuda:0') min:  tensor(-0.0216, device='cuda:0') norm:  tensor(0.1126, device='cuda:0') MSE:  tensor(4.2254e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(4.4728e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0051, device='cuda:0') MSE:  tensor(1.9152e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0123, device='cuda:0')
min of d_p_list:  tensor(-0.0114, device='cuda:0')
Epoch:  61  
Training Loss: 0.04072906821966171
Test Loss:  0.041013993322849274
Test Acc:  0.0
Valid Loss:  0.049318984150886536
Valid Acc:  0.0
std:  0.00044045737009375865 
thres:  4.134844988584518e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  6%|▌         | 61/1000 [02:48<44:04,  2.82s/it]Epoch:   62
max of grad d_p:  tensor(0.0064, device='cuda:0')
min of grad d_p:  tensor(-0.0628, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0123, device='cuda:0') mean:  tensor(-1.7506e-05, device='cuda:0') min:  tensor(-0.0261, device='cuda:0') norm:  tensor(0.1383, device='cuda:0') MSE:  tensor(5.1906e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.8472e-06, device='cuda:0') min:  tensor(2.1316e-13, device='cuda:0') norm:  tensor(0.0021, device='cuda:0') MSE:  tensor(7.9014e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0181, device='cuda:0')
min of d_p_list:  tensor(-0.0080, device='cuda:0')
Epoch:  62  
Training Loss: 0.04037116467952728
Test Loss:  0.040612053126096725
Test Acc:  0.0
Valid Loss:  0.048818543553352356
Valid Acc:  0.0
std:  0.00045005350952334486 
thres:  4.1027120500803e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  6%|▌         | 62/1000 [02:51<43:09,  2.76s/it]Epoch:   63
max of grad d_p:  tensor(0.0066, device='cuda:0')
min of grad d_p:  tensor(-0.0622, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0127, device='cuda:0') mean:  tensor(-1.6775e-05, device='cuda:0') min:  tensor(-0.0244, device='cuda:0') norm:  tensor(0.1344, device='cuda:0') MSE:  tensor(5.0432e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.8142e-05, device='cuda:0') mean:  tensor(6.4519e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.7647e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0035, device='cuda:0')
Epoch:  63  
Training Loss: 0.04006931930780411
Test Loss:  0.04025818780064583
Test Acc:  0.0
Valid Loss:  0.04840242490172386
Valid Acc:  0.0
std:  0.0004538778925841026 
thres:  4.0709668397903444e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  6%|▋         | 63/1000 [02:54<43:54,  2.81s/it]Epoch:   64
max of grad d_p:  tensor(0.0066, device='cuda:0')
min of grad d_p:  tensor(-0.0619, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0105, device='cuda:0') mean:  tensor(-1.5661e-05, device='cuda:0') min:  tensor(-0.0206, device='cuda:0') norm:  tensor(0.1245, device='cuda:0') MSE:  tensor(4.6732e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.7294e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0020, device='cuda:0') MSE:  tensor(7.4495e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0027, device='cuda:0')
Epoch:  64  
Training Loss: 0.03976795822381973
Test Loss:  0.03990276902914047
Test Acc:  0.0
Valid Loss:  0.047980040311813354
Valid Acc:  0.0
std:  0.000453258541525097 
thres:  4.039546698331833e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  6%|▋         | 64/1000 [02:57<44:28,  2.85s/it]Epoch:   65
max of grad d_p:  tensor(0.0066, device='cuda:0')
min of grad d_p:  tensor(-0.0616, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0115, device='cuda:0') mean:  tensor(-1.6599e-05, device='cuda:0') min:  tensor(-0.0231, device='cuda:0') norm:  tensor(0.1283, device='cuda:0') MSE:  tensor(4.8155e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(8.4108e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.4593e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  65  
Training Loss: 0.0394684299826622
Test Loss:  0.03955145180225372
Test Acc:  0.0
Valid Loss:  0.04756239801645279
Valid Acc:  0.0
std:  0.00044216770575216703 
thres:  4.0081188082695006e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  6%|▋         | 65/1000 [03:00<44:48,  2.88s/it]Epoch:   66
max of grad d_p:  tensor(0.0067, device='cuda:0')
min of grad d_p:  tensor(-0.0613, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0108, device='cuda:0') mean:  tensor(-1.7327e-05, device='cuda:0') min:  tensor(-0.0223, device='cuda:0') norm:  tensor(0.1357, device='cuda:0') MSE:  tensor(5.0936e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.4467e-05, device='cuda:0') mean:  tensor(7.0621e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.9537e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0286, device='cuda:0')
min of d_p_list:  tensor(-0.0348, device='cuda:0')
Epoch:  66  
Training Loss: 0.038972802460193634
Test Loss:  0.03887961804866791
Test Acc:  0.0
Valid Loss:  0.046805329620838165
Valid Acc:  0.0
std:  0.00048361917512986137 
thres:  3.972993493080139e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  7%|▋         | 66/1000 [03:03<44:46,  2.88s/it]Epoch:   67
max of grad d_p:  tensor(0.0075, device='cuda:0')
min of grad d_p:  tensor(-0.0595, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0092, device='cuda:0') mean:  tensor(-2.0251e-05, device='cuda:0') min:  tensor(-0.0320, device='cuda:0') norm:  tensor(0.1588, device='cuda:0') MSE:  tensor(5.9598e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.8781e-05, device='cuda:0') mean:  tensor(7.1362e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.9640e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0022, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  67  
Training Loss: 0.038681596517562866
Test Loss:  0.03853766620159149
Test Acc:  0.0
Valid Loss:  0.046399638056755066
Valid Acc:  0.0
std:  0.0005072173609020246 
thres:  3.9392021298408504e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  7%|▋         | 67/1000 [03:06<45:20,  2.92s/it]Epoch:   68
max of grad d_p:  tensor(0.0075, device='cuda:0')
min of grad d_p:  tensor(-0.0592, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0087, device='cuda:0') mean:  tensor(-1.8558e-05, device='cuda:0') min:  tensor(-0.0282, device='cuda:0') norm:  tensor(0.1460, device='cuda:0') MSE:  tensor(5.4791e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(8.6150e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.6303e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0074, device='cuda:0')
min of d_p_list:  tensor(-0.0032, device='cuda:0')
Epoch:  68  
Training Loss: 0.038395076990127563
Test Loss:  0.03822150081396103
Test Acc:  0.0
Valid Loss:  0.04600854218006134
Valid Acc:  0.0
std:  0.0005021743021351887 
thres:  3.90571728348732e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  7%|▋         | 68/1000 [03:08<43:55,  2.83s/it]Epoch:   69
max of grad d_p:  tensor(0.0076, device='cuda:0')
min of grad d_p:  tensor(-0.0589, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0074, device='cuda:0') mean:  tensor(-1.7653e-05, device='cuda:0') min:  tensor(-0.0274, device='cuda:0') norm:  tensor(0.1384, device='cuda:0') MSE:  tensor(5.1941e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(8.3399e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.5212e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  69  
Training Loss: 0.038112230598926544
Test Loss:  0.03788883239030838
Test Acc:  0.0
Valid Loss:  0.045614201575517654
Valid Acc:  0.0
std:  0.0004691073043971754 
thres:  3.872602730989457e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  7%|▋         | 69/1000 [03:11<42:52,  2.76s/it]Epoch:   70
max of grad d_p:  tensor(0.0076, device='cuda:0')
min of grad d_p:  tensor(-0.0586, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0077, device='cuda:0') mean:  tensor(-1.7346e-05, device='cuda:0') min:  tensor(-0.0285, device='cuda:0') norm:  tensor(0.1380, device='cuda:0') MSE:  tensor(5.1805e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.0910e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.6751e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  70  
Training Loss: 0.037834107875823975
Test Loss:  0.0375618040561676
Test Acc:  0.0
Valid Loss:  0.04522714018821716
Valid Acc:  0.0
std:  0.00040260777780717433 
thres:  3.839916288852692e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  7%|▋         | 70/1000 [03:14<41:59,  2.71s/it]Epoch:   71
max of grad d_p:  tensor(0.0077, device='cuda:0')
min of grad d_p:  tensor(-0.0583, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0088, device='cuda:0') mean:  tensor(-1.7244e-05, device='cuda:0') min:  tensor(-0.0251, device='cuda:0') norm:  tensor(0.1340, device='cuda:0') MSE:  tensor(5.0312e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(9.5744e-07, device='cuda:0') min:  tensor(6.9917e-12, device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.0479e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0027, device='cuda:0')
Epoch:  71  
Training Loss: 0.03755887597799301
Test Loss:  0.037234775722026825
Test Acc:  0.0
Valid Loss:  0.04484126716852188
Valid Acc:  0.0
std:  0.0003968997929385072 
thres:  3.811637759208679e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  7%|▋         | 71/1000 [03:17<44:15,  2.86s/it]Epoch:   72
max of grad d_p:  tensor(0.0077, device='cuda:0')
min of grad d_p:  tensor(-0.0580, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0091, device='cuda:0') mean:  tensor(-1.7800e-05, device='cuda:0') min:  tensor(-0.0258, device='cuda:0') norm:  tensor(0.1404, device='cuda:0') MSE:  tensor(5.2687e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(9.3781e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(3.9565e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0016, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  72  
Training Loss: 0.03728603199124336
Test Loss:  0.03692207112908363
Test Acc:  0.0
Valid Loss:  0.04446322098374367
Valid Acc:  0.0
std:  0.0003919511555978835 
thres:  3.783726468682289e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  7%|▋         | 72/1000 [03:19<43:10,  2.79s/it]Epoch:   73
max of grad d_p:  tensor(0.0077, device='cuda:0')
min of grad d_p:  tensor(-0.0577, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0096, device='cuda:0') mean:  tensor(-1.7854e-05, device='cuda:0') min:  tensor(-0.0263, device='cuda:0') norm:  tensor(0.1478, device='cuda:0') MSE:  tensor(5.5469e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(1.0600e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.5845e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  73  
Training Loss: 0.03701400011777878
Test Loss:  0.036600466817617416
Test Acc:  0.0
Valid Loss:  0.04408125579357147
Valid Acc:  0.0
std:  0.00038814014513589455 
thres:  3.756104931235314e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  7%|▋         | 73/1000 [03:22<42:57,  2.78s/it]Epoch:   74
max of grad d_p:  tensor(0.0077, device='cuda:0')
min of grad d_p:  tensor(-0.0574, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0098, device='cuda:0') mean:  tensor(-1.8632e-05, device='cuda:0') min:  tensor(-0.0289, device='cuda:0') norm:  tensor(0.1473, device='cuda:0') MSE:  tensor(5.5288e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(9.8005e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.4979e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0018, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  74  
Training Loss: 0.03674411028623581
Test Loss:  0.036284931004047394
Test Acc:  0.0
Valid Loss:  0.04370424896478653
Valid Acc:  0.0
std:  0.00038535744058107175 
thres:  3.7287425249814987e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  7%|▋         | 74/1000 [03:25<43:58,  2.85s/it]Epoch:   75
max of grad d_p:  tensor(0.0077, device='cuda:0')
min of grad d_p:  tensor(-0.0571, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0099, device='cuda:0') mean:  tensor(-1.6847e-05, device='cuda:0') min:  tensor(-0.0253, device='cuda:0') norm:  tensor(0.1450, device='cuda:0') MSE:  tensor(5.4443e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(2.2685e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0026, device='cuda:0') MSE:  tensor(9.6326e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0033, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  75  
Training Loss: 0.03647386282682419
Test Loss:  0.035968467593193054
Test Acc:  0.0
Valid Loss:  0.04332325607538223
Valid Acc:  0.0
std:  0.0003835284575915749 
thres:  3.701537624001503e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  8%|▊         | 75/1000 [03:28<43:13,  2.80s/it]Epoch:   76
max of grad d_p:  tensor(0.0077, device='cuda:0')
min of grad d_p:  tensor(-0.0568, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0091, device='cuda:0') mean:  tensor(-1.8685e-05, device='cuda:0') min:  tensor(-0.0278, device='cuda:0') norm:  tensor(0.1477, device='cuda:0') MSE:  tensor(5.5440e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(8.8967e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.7371e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0020, device='cuda:0')
min of d_p_list:  tensor(-0.0023, device='cuda:0')
Epoch:  76  
Training Loss: 0.03620738908648491
Test Loss:  0.03565442934632301
Test Acc:  0.0
Valid Loss:  0.04295199364423752
Valid Acc:  0.0
std:  0.000381475634979952 
thres:  3.674507886171341e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  8%|▊         | 76/1000 [03:31<43:45,  2.84s/it]Epoch:   77
max of grad d_p:  tensor(0.0077, device='cuda:0')
min of grad d_p:  tensor(-0.0565, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0099, device='cuda:0') mean:  tensor(-1.9686e-05, device='cuda:0') min:  tensor(-0.0284, device='cuda:0') norm:  tensor(0.1515, device='cuda:0') MSE:  tensor(5.6859e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.1865e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0014, device='cuda:0') MSE:  tensor(5.3575e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0022, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  77  
Training Loss: 0.035940833389759064
Test Loss:  0.03533852845430374
Test Acc:  0.0
Valid Loss:  0.04257989674806595
Valid Acc:  0.0
std:  0.0003794435230019201 
thres:  3.647603914141655e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  8%|▊         | 77/1000 [03:33<42:35,  2.77s/it]Epoch:   78
max of grad d_p:  tensor(0.0078, device='cuda:0')
min of grad d_p:  tensor(-0.0562, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0091, device='cuda:0') mean:  tensor(-1.8013e-05, device='cuda:0') min:  tensor(-0.0286, device='cuda:0') norm:  tensor(0.1421, device='cuda:0') MSE:  tensor(5.3331e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.4195e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0016, device='cuda:0') MSE:  tensor(5.9005e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0024, device='cuda:0')
min of d_p_list:  tensor(-0.0044, device='cuda:0')
Epoch:  78  
Training Loss: 0.035684697329998016
Test Loss:  0.03503687307238579
Test Acc:  0.0
Valid Loss:  0.042224861681461334
Valid Acc:  0.0
std:  0.00037504602539708805 
thres:  3.62101785838604e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  8%|▊         | 78/1000 [03:37<43:58,  2.86s/it]Epoch:   79
max of grad d_p:  tensor(0.0078, device='cuda:0')
min of grad d_p:  tensor(-0.0560, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0095, device='cuda:0') mean:  tensor(-1.9064e-05, device='cuda:0') min:  tensor(-0.0275, device='cuda:0') norm:  tensor(0.1481, device='cuda:0') MSE:  tensor(5.5606e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(7.9006e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.3723e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0120, device='cuda:0')
min of d_p_list:  tensor(-0.0139, device='cuda:0')
Epoch:  79  
Training Loss: 0.035454344004392624
Test Loss:  0.03472498059272766
Test Acc:  0.0
Valid Loss:  0.041898664087057114
Valid Acc:  0.0
std:  0.0003624364888342694 
thres:  3.595222532749176e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  8%|▊         | 79/1000 [03:39<43:22,  2.83s/it]Epoch:   80
max of grad d_p:  tensor(0.0082, device='cuda:0')
min of grad d_p:  tensor(-0.0557, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0090, device='cuda:0') mean:  tensor(-1.8933e-05, device='cuda:0') min:  tensor(-0.0290, device='cuda:0') norm:  tensor(0.1482, device='cuda:0') MSE:  tensor(5.5635e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(8.0433e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.4108e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  80  
Training Loss: 0.03520005941390991
Test Loss:  0.0344245545566082
Test Acc:  0.0
Valid Loss:  0.04154088720679283
Valid Acc:  0.0
std:  0.000353817437695426 
thres:  3.56974646449089e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  8%|▊         | 80/1000 [03:42<42:17,  2.76s/it]Epoch:   81
max of grad d_p:  tensor(0.0082, device='cuda:0')
min of grad d_p:  tensor(-0.0554, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0087, device='cuda:0') mean:  tensor(-1.8427e-05, device='cuda:0') min:  tensor(-0.0286, device='cuda:0') norm:  tensor(0.1442, device='cuda:0') MSE:  tensor(5.4142e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.1310e-06, device='cuda:0') min:  tensor(1.1369e-13, device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.7259e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  81  
Training Loss: 0.03495042026042938
Test Loss:  0.034129753708839417
Test Acc:  0.0
Valid Loss:  0.04118972271680832
Valid Acc:  0.0
std:  0.00034870966330673744 
thres:  3.5446070879697794e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  8%|▊         | 81/1000 [03:45<41:59,  2.74s/it]Epoch:   82
max of grad d_p:  tensor(0.0082, device='cuda:0')
min of grad d_p:  tensor(-0.0551, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0094, device='cuda:0') mean:  tensor(-1.9192e-05, device='cuda:0') min:  tensor(-0.0296, device='cuda:0') norm:  tensor(0.1511, device='cuda:0') MSE:  tensor(5.6731e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(2.4442e-06, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0029, device='cuda:0') MSE:  tensor(1.0994e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0022, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  82  
Training Loss: 0.03469773381948471
Test Loss:  0.03383081406354904
Test Acc:  0.0
Valid Loss:  0.040831558406353
Valid Acc:  0.0
std:  0.0003504714688588732 
thres:  3.519745096564293e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  8%|▊         | 82/1000 [03:47<41:41,  2.73s/it]Epoch:   83
max of grad d_p:  tensor(0.0082, device='cuda:0')
min of grad d_p:  tensor(-0.0549, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0086, device='cuda:0') mean:  tensor(-1.7642e-05, device='cuda:0') min:  tensor(-0.0289, device='cuda:0') norm:  tensor(0.1410, device='cuda:0') MSE:  tensor(5.2931e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(9.8372e-07, device='cuda:0') min:  tensor(1.3642e-12, device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.3153e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  83  
Training Loss: 0.0344516858458519
Test Loss:  0.03353605791926384
Test Acc:  0.0
Valid Loss:  0.040482230484485626
Valid Acc:  0.0
std:  0.00035463907927156535 
thres:  3.495084866881371e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  8%|▊         | 83/1000 [03:50<41:32,  2.72s/it]Epoch:   84
max of grad d_p:  tensor(0.0083, device='cuda:0')
min of grad d_p:  tensor(-0.0546, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0090, device='cuda:0') mean:  tensor(-1.7832e-05, device='cuda:0') min:  tensor(-0.0291, device='cuda:0') norm:  tensor(0.1422, device='cuda:0') MSE:  tensor(5.3371e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.5644e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0017, device='cuda:0') MSE:  tensor(6.4251e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0147, device='cuda:0')
min of d_p_list:  tensor(-0.0189, device='cuda:0')
Epoch:  84  
Training Loss: 0.034146495163440704
Test Loss:  0.03314150124788284
Test Acc:  0.0
Valid Loss:  0.04001994431018829
Valid Acc:  0.0
std:  0.0003688435096984002 
thres:  3.4689278900623326e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  8%|▊         | 84/1000 [03:53<41:39,  2.73s/it]Epoch:   85
max of grad d_p:  tensor(0.0079, device='cuda:0')
min of grad d_p:  tensor(-0.0542, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0141, device='cuda:0') mean:  tensor(-2.0309e-05, device='cuda:0') min:  tensor(-0.0343, device='cuda:0') norm:  tensor(0.1658, device='cuda:0') MSE:  tensor(6.2226e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0011, device='cuda:0') mean:  tensor(8.7620e-06, device='cuda:0') min:  tensor(8.5265e-13, device='cuda:0') norm:  tensor(0.0098, device='cuda:0') MSE:  tensor(3.6642e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0139, device='cuda:0')
min of d_p_list:  tensor(-0.0078, device='cuda:0')
Epoch:  85  
Training Loss: 0.033898524940013885
Test Loss:  0.032852429896593094
Test Acc:  0.0
Valid Loss:  0.03965284675359726
Valid Acc:  0.0
std:  0.00037571914227289626 
thres:  3.442897200584412e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  8%|▊         | 85/1000 [03:55<41:42,  2.73s/it]Epoch:   86
max of grad d_p:  tensor(0.0079, device='cuda:0')
min of grad d_p:  tensor(-0.0539, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0095, device='cuda:0') mean:  tensor(-1.9164e-05, device='cuda:0') min:  tensor(-0.0298, device='cuda:0') norm:  tensor(0.1473, device='cuda:0') MSE:  tensor(5.5306e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.9913e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0024, device='cuda:0') MSE:  tensor(8.8619e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0060, device='cuda:0')
Epoch:  86  
Training Loss: 0.03366447612643242
Test Loss:  0.032573286443948746
Test Acc:  0.0
Valid Loss:  0.03932875394821167
Valid Acc:  0.0
std:  0.0003708475626525293 
thres:  3.4171783179044724e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  9%|▊         | 86/1000 [03:58<41:40,  2.74s/it]Epoch:   87
max of grad d_p:  tensor(0.0079, device='cuda:0')
min of grad d_p:  tensor(-0.0536, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0101, device='cuda:0') mean:  tensor(-1.8727e-05, device='cuda:0') min:  tensor(-0.0299, device='cuda:0') norm:  tensor(0.1469, device='cuda:0') MSE:  tensor(5.5131e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.1025e-06, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.7750e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  87  
Training Loss: 0.03342738747596741
Test Loss:  0.03229018300771713
Test Acc:  0.0
Valid Loss:  0.03899301216006279
Valid Acc:  0.0
std:  0.00035843674301326616 
thres:  3.3917713910341265e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  9%|▊         | 87/1000 [04:01<41:07,  2.70s/it]Epoch:   88
max of grad d_p:  tensor(0.0079, device='cuda:0')
min of grad d_p:  tensor(-0.0534, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0103, device='cuda:0') mean:  tensor(-2.1387e-05, device='cuda:0') min:  tensor(-0.0351, device='cuda:0') norm:  tensor(0.1662, device='cuda:0') MSE:  tensor(6.2375e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(8.4977e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.6543e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0016, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  88  
Training Loss: 0.03319235146045685
Test Loss:  0.03201058879494667
Test Acc:  0.0
Valid Loss:  0.03866032883524895
Valid Acc:  0.0
std:  0.0003365188050173337 
thres:  3.366584703326225e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  9%|▉         | 88/1000 [04:03<40:51,  2.69s/it]Epoch:   89
max of grad d_p:  tensor(0.0080, device='cuda:0')
min of grad d_p:  tensor(-0.0531, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0121, device='cuda:0') mean:  tensor(-2.2641e-05, device='cuda:0') min:  tensor(-0.0363, device='cuda:0') norm:  tensor(0.1735, device='cuda:0') MSE:  tensor(6.5120e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.0710e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.5392e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0025, device='cuda:0')
min of d_p_list:  tensor(-0.0039, device='cuda:0')
Epoch:  89  
Training Loss: 0.0329650416970253
Test Loss:  0.0317334346473217
Test Acc:  0.0
Valid Loss:  0.038331761956214905
Valid Acc:  0.0
std:  0.0003308061566067427 
thres:  3.342955633997917e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  9%|▉         | 89/1000 [04:06<41:53,  2.76s/it]Epoch:   90
max of grad d_p:  tensor(0.0081, device='cuda:0')
min of grad d_p:  tensor(-0.0528, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0098, device='cuda:0') mean:  tensor(-1.8316e-05, device='cuda:0') min:  tensor(-0.0315, device='cuda:0') norm:  tensor(0.1489, device='cuda:0') MSE:  tensor(5.5907e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(8.7964e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.7368e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  90  
Training Loss: 0.03273449093103409
Test Loss:  0.031462736427783966
Test Acc:  0.0
Valid Loss:  0.038006462156772614
Valid Acc:  0.0
std:  0.00032843657114450125 
thres:  3.3196749538183214e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  9%|▉         | 90/1000 [04:09<41:52,  2.76s/it]Epoch:   91
max of grad d_p:  tensor(0.0081, device='cuda:0')
min of grad d_p:  tensor(-0.0526, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0107, device='cuda:0') mean:  tensor(-2.0054e-05, device='cuda:0') min:  tensor(-0.0336, device='cuda:0') norm:  tensor(0.1628, device='cuda:0') MSE:  tensor(6.1126e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(8.2385e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.5386e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0046, device='cuda:0')
min of d_p_list:  tensor(-0.0085, device='cuda:0')
Epoch:  91  
Training Loss: 0.032491423189640045
Test Loss:  0.031164320185780525
Test Acc:  0.0
Valid Loss:  0.03765562176704407
Valid Acc:  0.0
std:  0.00032950246263611964 
thres:  3.2962138950824744e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  9%|▉         | 91/1000 [04:12<41:35,  2.75s/it]Epoch:   92
max of grad d_p:  tensor(0.0079, device='cuda:0')
min of grad d_p:  tensor(-0.0523, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0125, device='cuda:0') mean:  tensor(-2.2117e-05, device='cuda:0') min:  tensor(-0.0374, device='cuda:0') norm:  tensor(0.1746, device='cuda:0') MSE:  tensor(6.5540e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(8.0045e-07, device='cuda:0') min:  tensor(4.5475e-13, device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.4174e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  92  
Training Loss: 0.03226751089096069
Test Loss:  0.030896605923771858
Test Acc:  0.0
Valid Loss:  0.03733895346522331
Valid Acc:  0.0
std:  0.0003285874548213996 
thres:  3.27301636338234e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  9%|▉         | 92/1000 [04:15<41:03,  2.71s/it]Epoch:   93
max of grad d_p:  tensor(0.0079, device='cuda:0')
min of grad d_p:  tensor(-0.0520, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0095, device='cuda:0') mean:  tensor(-2.0778e-05, device='cuda:0') min:  tensor(-0.0380, device='cuda:0') norm:  tensor(0.1696, device='cuda:0') MSE:  tensor(6.3667e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(7.6862e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.4035e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0157, device='cuda:0')
min of d_p_list:  tensor(-0.0205, device='cuda:0')
Epoch:  93  
Training Loss: 0.032013189047575
Test Loss:  0.030544759705662727
Test Acc:  0.0
Valid Loss:  0.03693876788020134
Valid Acc:  0.0
std:  0.00033532036871543097 
thres:  3.2494331151247026e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  9%|▉         | 93/1000 [04:17<40:53,  2.71s/it]Epoch:   94
max of grad d_p:  tensor(0.0084, device='cuda:0')
min of grad d_p:  tensor(-0.0519, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0103, device='cuda:0') mean:  tensor(-1.9894e-05, device='cuda:0') min:  tensor(-0.0316, device='cuda:0') norm:  tensor(0.1544, device='cuda:0') MSE:  tensor(5.7955e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(9.0623e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.1214e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0039, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  94  
Training Loss: 0.03178878128528595
Test Loss:  0.03028213605284691
Test Acc:  0.0
Valid Loss:  0.03662049025297165
Valid Acc:  0.0
std:  0.0003351755458212987 
thres:  3.225907906889915e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  9%|▉         | 94/1000 [04:20<41:14,  2.73s/it]Epoch:   95
max of grad d_p:  tensor(0.0084, device='cuda:0')
min of grad d_p:  tensor(-0.0516, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0099, device='cuda:0') mean:  tensor(-1.8925e-05, device='cuda:0') min:  tensor(-0.0314, device='cuda:0') norm:  tensor(0.1501, device='cuda:0') MSE:  tensor(5.6343e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.0896e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.8886e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0477, device='cuda:0')
min of d_p_list:  tensor(-0.0706, device='cuda:0')
Epoch:  95  
Training Loss: 0.03151116147637367
Test Loss:  0.029514741152524948
Test Acc:  0.0
Valid Loss:  0.035947494208812714
Valid Acc:  0.0
std:  0.00034518705891315967 
thres:  3.201441317796707e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 10%|▉         | 95/1000 [04:23<40:26,  2.68s/it]Epoch:   96
max of grad d_p:  tensor(0.0091, device='cuda:0')
min of grad d_p:  tensor(-0.0491, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0110, device='cuda:0') mean:  tensor(-2.3341e-05, device='cuda:0') min:  tensor(-0.0310, device='cuda:0') norm:  tensor(0.1769, device='cuda:0') MSE:  tensor(6.6419e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.0777e-06, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.7931e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0030, device='cuda:0')
min of d_p_list:  tensor(-0.0036, device='cuda:0')
Epoch:  96  
Training Loss: 0.03129815310239792
Test Loss:  0.02926894836127758
Test Acc:  0.0
Valid Loss:  0.03565049171447754
Valid Acc:  0.0
std:  0.00034539304353223374 
thres:  3.177575916051865e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 10%|▉         | 96/1000 [04:26<41:32,  2.76s/it]Epoch:   97
max of grad d_p:  tensor(0.0090, device='cuda:0')
min of grad d_p:  tensor(-0.0488, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0110, device='cuda:0') mean:  tensor(-2.1673e-05, device='cuda:0') min:  tensor(-0.0285, device='cuda:0') norm:  tensor(0.1637, device='cuda:0') MSE:  tensor(6.1464e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(2.0247e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0024, device='cuda:0') MSE:  tensor(9.0875e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0346, device='cuda:0')
min of d_p_list:  tensor(-0.0308, device='cuda:0')
Epoch:  97  
Training Loss: 0.030942516401410103
Test Loss:  0.028916727751493454
Test Acc:  0.0
Valid Loss:  0.03512246161699295
Valid Acc:  0.0
std:  0.00037358624823418806 
thres:  3.151076026260853e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 10%|▉         | 97/1000 [04:28<40:39,  2.70s/it]Epoch:   98
max of grad d_p:  tensor(0.0092, device='cuda:0')
min of grad d_p:  tensor(-0.0478, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0118, device='cuda:0') mean:  tensor(-2.4256e-05, device='cuda:0') min:  tensor(-0.0281, device='cuda:0') norm:  tensor(0.1858, device='cuda:0') MSE:  tensor(6.9748e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.0884e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.7720e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0152, device='cuda:0')
min of d_p_list:  tensor(-0.0132, device='cuda:0')
Epoch:  98  
Training Loss: 0.030674513429403305
Test Loss:  0.02863190323114395
Test Acc:  0.0
Valid Loss:  0.03473712503910065
Valid Acc:  0.0
std:  0.0003965594594241554 
thres:  3.1243025138974194e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 10%|▉         | 98/1000 [04:31<40:45,  2.71s/it]Epoch:   99
max of grad d_p:  tensor(0.0088, device='cuda:0')
min of grad d_p:  tensor(-0.0473, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0128, device='cuda:0') mean:  tensor(-2.1819e-05, device='cuda:0') min:  tensor(-0.0241, device='cuda:0') norm:  tensor(0.1684, device='cuda:0') MSE:  tensor(6.3204e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.4479e-06, device='cuda:0') min:  tensor(9.0949e-13, device='cuda:0') norm:  tensor(0.0018, device='cuda:0') MSE:  tensor(6.6136e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0056, device='cuda:0')
min of d_p_list:  tensor(-0.0041, device='cuda:0')
Epoch:  99  
Training Loss: 0.030439505353569984
Test Loss:  0.028369244188070297
Test Acc:  0.0
Valid Loss:  0.03441161662340164
Valid Acc:  0.0
std:  0.0003924237991282515 
thres:  3.0973169952631e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 10%|▉         | 99/1000 [04:33<40:34,  2.70s/it]Epoch:   100
max of grad d_p:  tensor(0.0087, device='cuda:0')
min of grad d_p:  tensor(-0.0470, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0132, device='cuda:0') mean:  tensor(-2.3159e-05, device='cuda:0') min:  tensor(-0.0304, device='cuda:0') norm:  tensor(0.1749, device='cuda:0') MSE:  tensor(6.5644e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(2.0664e-06, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0025, device='cuda:0') MSE:  tensor(9.5106e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0156, device='cuda:0')
min of d_p_list:  tensor(-0.0175, device='cuda:0')
Epoch:  100  
Training Loss: 0.0301351398229599
Test Loss:  0.0279807448387146
Test Acc:  0.0
Valid Loss:  0.033932387828826904
Valid Acc:  0.0
std:  0.00040103732771305117 
thres:  3.069796562194825e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 10%|█         | 100/1000 [04:36<40:31,  2.70s/it]Epoch:   101
max of grad d_p:  tensor(0.0092, device='cuda:0')
min of grad d_p:  tensor(-0.0464, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0156, device='cuda:0') mean:  tensor(-2.3701e-05, device='cuda:0') min:  tensor(-0.0362, device='cuda:0') norm:  tensor(0.1805, device='cuda:0') MSE:  tensor(6.7763e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(8.8749e-07, device='cuda:0') min:  tensor(6.3665e-12, device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.3013e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0067, device='cuda:0')
min of d_p_list:  tensor(-0.0094, device='cuda:0')
Epoch:  101  
Training Loss: 0.029960190877318382
Test Loss:  0.02779524400830269
Test Acc:  0.0
Valid Loss:  0.03370506316423416
Valid Acc:  0.0
std:  0.00035502469493636454 
thres:  3.0430373176932334e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 10%|█         | 101/1000 [04:39<40:31,  2.70s/it]Epoch:   102
max of grad d_p:  tensor(0.0089, device='cuda:0')
min of grad d_p:  tensor(-0.0461, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0158, device='cuda:0') mean:  tensor(-2.2821e-05, device='cuda:0') min:  tensor(-0.0373, device='cuda:0') norm:  tensor(0.1758, device='cuda:0') MSE:  tensor(6.6006e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.2834e-06, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0016, device='cuda:0') MSE:  tensor(6.0609e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0065, device='cuda:0')
min of d_p_list:  tensor(-0.0067, device='cuda:0')
Epoch:  102  
Training Loss: 0.029740048572421074
Test Loss:  0.027529269456863403
Test Acc:  0.0
Valid Loss:  0.03338906168937683
Valid Acc:  0.0
std:  0.0003332519381302138 
thres:  3.018987961113453e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 10%|█         | 102/1000 [04:42<39:59,  2.67s/it]Epoch:   103
max of grad d_p:  tensor(0.0091, device='cuda:0')
min of grad d_p:  tensor(-0.0458, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0142, device='cuda:0') mean:  tensor(-2.4143e-05, device='cuda:0') min:  tensor(-0.0382, device='cuda:0') norm:  tensor(0.1823, device='cuda:0') MSE:  tensor(6.8435e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0009, device='cuda:0') mean:  tensor(3.9730e-06, device='cuda:0') min:  tensor(6.8212e-13, device='cuda:0') norm:  tensor(0.0054, device='cuda:0') MSE:  tensor(2.0100e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0037, device='cuda:0')
min of d_p_list:  tensor(-0.0043, device='cuda:0')
Epoch:  103  
Training Loss: 0.029538430273532867
Test Loss:  0.027281969785690308
Test Acc:  0.0
Valid Loss:  0.033100683242082596
Valid Acc:  0.0
std:  0.00031198191793085814 
thres:  2.996266297996044e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 10%|█         | 103/1000 [04:44<40:20,  2.70s/it]Epoch:   104
max of grad d_p:  tensor(0.0091, device='cuda:0')
min of grad d_p:  tensor(-0.0456, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0153, device='cuda:0') mean:  tensor(-2.3172e-05, device='cuda:0') min:  tensor(-0.0272, device='cuda:0') norm:  tensor(0.1800, device='cuda:0') MSE:  tensor(6.7557e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(9.0627e-07, device='cuda:0') min:  tensor(5.0022e-12, device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.2021e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0178, device='cuda:0')
min of d_p_list:  tensor(-0.0148, device='cuda:0')
Epoch:  104  
Training Loss: 0.02929055690765381
Test Loss:  0.026988785713911057
Test Acc:  0.0
Valid Loss:  0.03272423520684242
Valid Acc:  0.0
std:  0.0002989966563245518 
thres:  2.973287329077721e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 10%|█         | 104/1000 [04:47<39:34,  2.65s/it]Epoch:   105
max of grad d_p:  tensor(0.0093, device='cuda:0')
min of grad d_p:  tensor(-0.0451, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0141, device='cuda:0') mean:  tensor(-2.3155e-05, device='cuda:0') min:  tensor(-0.0371, device='cuda:0') norm:  tensor(0.1758, device='cuda:0') MSE:  tensor(6.5974e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(2.0598e-06, device='cuda:0') min:  tensor(1.4779e-12, device='cuda:0') norm:  tensor(0.0029, device='cuda:0') MSE:  tensor(1.0735e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0044, device='cuda:0')
min of d_p_list:  tensor(-0.0055, device='cuda:0')
Epoch:  105  
Training Loss: 0.02908008173108101
Test Loss:  0.026732344180345535
Test Acc:  0.0
Valid Loss:  0.032419852912425995
Valid Acc:  0.0
std:  0.00031262883568691785 
thres:  2.952186167240143e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 10%|█         | 105/1000 [04:50<41:42,  2.80s/it]Epoch:   106
max of grad d_p:  tensor(0.0095, device='cuda:0')
min of grad d_p:  tensor(-0.0449, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0144, device='cuda:0') mean:  tensor(-2.5070e-05, device='cuda:0') min:  tensor(-0.0351, device='cuda:0') norm:  tensor(0.1939, device='cuda:0') MSE:  tensor(7.2795e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0011, device='cuda:0') mean:  tensor(4.8399e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0060, device='cuda:0') MSE:  tensor(2.2610e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0236, device='cuda:0')
min of d_p_list:  tensor(-0.0252, device='cuda:0')
Epoch:  106  
Training Loss: 0.028343383222818375
Test Loss:  0.025907466188073158
Test Acc:  0.0
Valid Loss:  0.031319282948970795
Valid Acc:  0.0
std:  0.0004821928059258817 
thres:  2.919850014150143e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 11%|█         | 106/1000 [04:53<41:08,  2.76s/it]Epoch:   107
max of grad d_p:  tensor(0.0100, device='cuda:0')
min of grad d_p:  tensor(-0.0402, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0129, device='cuda:0') mean:  tensor(-2.4377e-05, device='cuda:0') min:  tensor(-0.0287, device='cuda:0') norm:  tensor(0.1870, device='cuda:0') MSE:  tensor(7.0191e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.7684e-06, device='cuda:0') min:  tensor(2.3874e-12, device='cuda:0') norm:  tensor(0.0023, device='cuda:0') MSE:  tensor(8.4888e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0039, device='cuda:0')
min of d_p_list:  tensor(-0.0027, device='cuda:0')
Epoch:  107  
Training Loss: 0.02814873307943344
Test Loss:  0.025674762204289436
Test Acc:  0.0
Valid Loss:  0.03104015812277794
Valid Acc:  0.0
std:  0.0005412630954277594 
thres:  2.88802370429039e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 11%|█         | 107/1000 [04:55<41:16,  2.77s/it]Epoch:   108
max of grad d_p:  tensor(0.0101, device='cuda:0')
min of grad d_p:  tensor(-0.0400, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0114, device='cuda:0') mean:  tensor(-2.5518e-05, device='cuda:0') min:  tensor(-0.0296, device='cuda:0') norm:  tensor(0.1901, device='cuda:0') MSE:  tensor(7.1361e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(8.9019e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.2844e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1711, device='cuda:0')
min of d_p_list:  tensor(-0.1610, device='cuda:0')
Epoch:  108  
Training Loss: 0.02528925985097885
Test Loss:  0.01953759230673313
Test Acc:  0.0
Valid Loss:  0.023330992087721825
Valid Acc:  0.0
std:  0.0014363591264345233 
thres:  2.8030402958393098e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 11%|█         | 108/1000 [04:59<43:13,  2.91s/it]Epoch:   109
max of grad d_p:  tensor(0.0181, device='cuda:0')
min of grad d_p:  tensor(-0.0197, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0157, device='cuda:0') mean:  tensor(-2.1997e-05, device='cuda:0') min:  tensor(-0.0376, device='cuda:0') norm:  tensor(0.1834, device='cuda:0') MSE:  tensor(6.8859e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.0557e-06, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.8670e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0043, device='cuda:0')
min of d_p_list:  tensor(-0.0041, device='cuda:0')
Epoch:  109  
Training Loss: 0.025098172947764397
Test Loss:  0.019340787082910538
Test Acc:  0.0
Valid Loss:  0.02309388481080532
Valid Acc:  0.0
std:  0.0016619510165119397 
thres:  2.7191926166415212e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 11%|█         | 109/1000 [05:02<43:37,  2.94s/it]Epoch:   110
max of grad d_p:  tensor(0.0181, device='cuda:0')
min of grad d_p:  tensor(-0.0199, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0191, device='cuda:0') mean:  tensor(-2.4727e-05, device='cuda:0') min:  tensor(-0.0384, device='cuda:0') norm:  tensor(0.2064, device='cuda:0') MSE:  tensor(7.7494e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(8.1387e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.6045e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0087, device='cuda:0')
min of d_p_list:  tensor(-0.0047, device='cuda:0')
Epoch:  110  
Training Loss: 0.0249162707477808
Test Loss:  0.01914607547223568
Test Acc:  0.0
Valid Loss:  0.02286142110824585
Valid Acc:  0.0
std:  0.0015463775524416298 
thres:  2.6359163969755176e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 11%|█         | 110/1000 [05:04<42:25,  2.86s/it]Epoch:   111
max of grad d_p:  tensor(0.0181, device='cuda:0')
min of grad d_p:  tensor(-0.0195, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0171, device='cuda:0') mean:  tensor(-2.2648e-05, device='cuda:0') min:  tensor(-0.0374, device='cuda:0') norm:  tensor(0.1945, device='cuda:0') MSE:  tensor(7.3009e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.0663e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.6142e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0018, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  111  
Training Loss: 0.024733658879995346
Test Loss:  0.018957074731588364
Test Acc:  0.0
Valid Loss:  0.022632401436567307
Valid Acc:  0.0
std:  0.0012692940132098165 
thres:  2.5637219101190565e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 11%|█         | 111/1000 [05:07<42:09,  2.85s/it]Epoch:   112
max of grad d_p:  tensor(0.0181, device='cuda:0')
min of grad d_p:  tensor(-0.0196, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0163, device='cuda:0') mean:  tensor(-2.2895e-05, device='cuda:0') min:  tensor(-0.0463, device='cuda:0') norm:  tensor(0.2111, device='cuda:0') MSE:  tensor(7.9235e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.1018e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0014, device='cuda:0') MSE:  tensor(5.1219e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0022, device='cuda:0')
min of d_p_list:  tensor(-0.0042, device='cuda:0')
Epoch:  112  
Training Loss: 0.02455078810453415
Test Loss:  0.01876816153526306
Test Acc:  0.0
Valid Loss:  0.022409651428461075
Valid Acc:  0.0
std:  0.00026043221726864167 
thres:  2.491763010621071e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 11%|█         | 112/1000 [05:10<41:51,  2.83s/it]Epoch:   113
max of grad d_p:  tensor(0.0181, device='cuda:0')
min of grad d_p:  tensor(-0.0195, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0168, device='cuda:0') mean:  tensor(-2.3238e-05, device='cuda:0') min:  tensor(-0.0412, device='cuda:0') norm:  tensor(0.2005, device='cuda:0') MSE:  tensor(7.5274e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.7085e-06, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0020, device='cuda:0') MSE:  tensor(7.6476e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0037, device='cuda:0')
min of d_p_list:  tensor(-0.0037, device='cuda:0')
Epoch:  113  
Training Loss: 0.024370625615119934
Test Loss:  0.01858079433441162
Test Acc:  0.0
Valid Loss:  0.022187303751707077
Valid Acc:  0.0
std:  0.00025746928872233594 
thres:  2.4733903259038923e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 11%|█▏        | 113/1000 [05:13<42:48,  2.90s/it]Epoch:   114
max of grad d_p:  tensor(0.0180, device='cuda:0')
min of grad d_p:  tensor(-0.0194, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0171, device='cuda:0') mean:  tensor(-2.3328e-05, device='cuda:0') min:  tensor(-0.0407, device='cuda:0') norm:  tensor(0.2039, device='cuda:0') MSE:  tensor(7.6535e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.7895e-05, device='cuda:0') mean:  tensor(6.5215e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.7766e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0017, device='cuda:0')
min of d_p_list:  tensor(-0.0025, device='cuda:0')
Epoch:  114  
Training Loss: 0.024197038263082504
Test Loss:  0.01839667558670044
Test Acc:  0.0
Valid Loss:  0.021965064108371735
Valid Acc:  0.0
std:  0.0002547842408579138 
thres:  2.4553676322102546e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 11%|█▏        | 114/1000 [05:16<42:19,  2.87s/it]Epoch:   115
max of grad d_p:  tensor(0.0181, device='cuda:0')
min of grad d_p:  tensor(-0.0193, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0161, device='cuda:0') mean:  tensor(-2.3586e-05, device='cuda:0') min:  tensor(-0.0426, device='cuda:0') norm:  tensor(0.2043, device='cuda:0') MSE:  tensor(7.6682e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0032, device='cuda:0') mean:  tensor(8.9218e-06, device='cuda:0') min:  tensor(7.9581e-12, device='cuda:0') norm:  tensor(0.0114, device='cuda:0') MSE:  tensor(4.2709e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0032, device='cuda:0')
Epoch:  115  
Training Loss: 0.024021852761507034
Test Loss:  0.018214646726846695
Test Acc:  0.0
Valid Loss:  0.02174789272248745
Valid Acc:  0.0
std:  0.00025137220299200144 
thres:  2.437479272484779e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 12%|█▏        | 115/1000 [05:19<41:56,  2.84s/it]Epoch:   116
max of grad d_p:  tensor(0.0180, device='cuda:0')
min of grad d_p:  tensor(-0.0193, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0179, device='cuda:0') mean:  tensor(-2.4896e-05, device='cuda:0') min:  tensor(-0.0444, device='cuda:0') norm:  tensor(0.2161, device='cuda:0') MSE:  tensor(8.1121e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(7.0782e-07, device='cuda:0') min:  tensor(4.5475e-13, device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.2229e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0049, device='cuda:0')
Epoch:  116  
Training Loss: 0.02384926937520504
Test Loss:  0.018038108944892883
Test Acc:  0.0
Valid Loss:  0.02153768762946129
Valid Acc:  0.0
std:  0.00024775021156720086 
thres:  2.4197914823889733e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 12%|█▏        | 116/1000 [05:21<40:38,  2.76s/it]Epoch:   117
max of grad d_p:  tensor(0.0179, device='cuda:0')
min of grad d_p:  tensor(-0.0192, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0159, device='cuda:0') mean:  tensor(-2.1365e-05, device='cuda:0') min:  tensor(-0.0370, device='cuda:0') norm:  tensor(0.1961, device='cuda:0') MSE:  tensor(7.3628e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.2255e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0016, device='cuda:0') MSE:  tensor(6.1799e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  117  
Training Loss: 0.02367587760090828
Test Loss:  0.017852695658802986
Test Acc:  0.0
Valid Loss:  0.021311605349183083
Valid Acc:  0.0
std:  0.00024568698328255944 
thres:  2.402293272316456e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 12%|█▏        | 117/1000 [05:24<39:54,  2.71s/it]Epoch:   118
max of grad d_p:  tensor(0.0179, device='cuda:0')
min of grad d_p:  tensor(-0.0194, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0175, device='cuda:0') mean:  tensor(-2.1582e-05, device='cuda:0') min:  tensor(-0.0424, device='cuda:0') norm:  tensor(0.2036, device='cuda:0') MSE:  tensor(7.6430e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.9168e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.2241e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0050, device='cuda:0')
min of d_p_list:  tensor(-0.0060, device='cuda:0')
Epoch:  118  
Training Loss: 0.023511048406362534
Test Loss:  0.017688436433672905
Test Acc:  0.0
Valid Loss:  0.021117819473147392
Valid Acc:  0.0
std:  0.00024296957829365127 
thres:  2.385101728141308e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 12%|█▏        | 118/1000 [05:27<40:22,  2.75s/it]Epoch:   119
max of grad d_p:  tensor(0.0179, device='cuda:0')
min of grad d_p:  tensor(-0.0195, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0175, device='cuda:0') mean:  tensor(-2.4071e-05, device='cuda:0') min:  tensor(-0.0426, device='cuda:0') norm:  tensor(0.2106, device='cuda:0') MSE:  tensor(7.9063e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(5.6024e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.9016e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0066, device='cuda:0')
min of d_p_list:  tensor(-0.0050, device='cuda:0')
Epoch:  119  
Training Loss: 0.02334822155535221
Test Loss:  0.0175185427069664
Test Acc:  0.0
Valid Loss:  0.02091185562312603
Valid Acc:  0.0
std:  0.0002383888175255527 
thres:  2.368125393986702e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 12%|█▏        | 119/1000 [05:30<41:19,  2.81s/it]Epoch:   120
max of grad d_p:  tensor(0.0179, device='cuda:0')
min of grad d_p:  tensor(-0.0196, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0173, device='cuda:0') mean:  tensor(-2.2887e-05, device='cuda:0') min:  tensor(-0.0378, device='cuda:0') norm:  tensor(0.2124, device='cuda:0') MSE:  tensor(7.9718e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.3987e-05, device='cuda:0') mean:  tensor(3.1224e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4823e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0036, device='cuda:0')
min of d_p_list:  tensor(-0.0051, device='cuda:0')
Epoch:  120  
Training Loss: 0.023183830082416534
Test Loss:  0.017346039414405823
Test Acc:  0.0
Valid Loss:  0.020709358155727386
Valid Acc:  0.0
std:  0.00023456882833424678 
thres:  2.351364940404892e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 12%|█▏        | 120/1000 [05:32<40:27,  2.76s/it]Epoch:   121
max of grad d_p:  tensor(0.0178, device='cuda:0')
min of grad d_p:  tensor(-0.0189, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0178, device='cuda:0') mean:  tensor(-2.3688e-05, device='cuda:0') min:  tensor(-0.0429, device='cuda:0') norm:  tensor(0.2110, device='cuda:0') MSE:  tensor(7.9193e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.6018e-05, device='cuda:0') mean:  tensor(4.5787e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.0912e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0031, device='cuda:0')
Epoch:  121  
Training Loss: 0.023017115890979767
Test Loss:  0.01717238686978817
Test Acc:  0.0
Valid Loss:  0.020498860627412796
Valid Acc:  0.0
std:  0.00023260333464110693 
thres:  2.3347218707203866e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 12%|█▏        | 121/1000 [05:35<40:19,  2.75s/it]Epoch:   122
max of grad d_p:  tensor(0.0178, device='cuda:0')
min of grad d_p:  tensor(-0.0183, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0170, device='cuda:0') mean:  tensor(-2.3112e-05, device='cuda:0') min:  tensor(-0.0440, device='cuda:0') norm:  tensor(0.2177, device='cuda:0') MSE:  tensor(8.1736e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(7.5250e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.5977e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0031, device='cuda:0')
min of d_p_list:  tensor(-0.0054, device='cuda:0')
Epoch:  122  
Training Loss: 0.022857695817947388
Test Loss:  0.017012134194374084
Test Acc:  0.0
Valid Loss:  0.020311526954174042
Valid Acc:  0.0
std:  0.00023162610437167956 
thres:  2.3183582350611687e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 12%|█▏        | 122/1000 [05:38<40:24,  2.76s/it]Epoch:   123
max of grad d_p:  tensor(0.0178, device='cuda:0')
min of grad d_p:  tensor(-0.0183, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0183, device='cuda:0') mean:  tensor(-2.4548e-05, device='cuda:0') min:  tensor(-0.0506, device='cuda:0') norm:  tensor(0.2252, device='cuda:0') MSE:  tensor(8.4534e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(8.2314e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.0083e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0094, device='cuda:0')
min of d_p_list:  tensor(-0.0067, device='cuda:0')
Epoch:  123  
Training Loss: 0.022694647312164307
Test Loss:  0.01684311032295227
Test Acc:  0.0
Valid Loss:  0.02010493539273739
Valid Acc:  0.0
std:  0.00023098682471643824 
thres:  2.302030213177204e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 12%|█▏        | 123/1000 [05:40<40:10,  2.75s/it]Epoch:   124
max of grad d_p:  tensor(0.0178, device='cuda:0')
min of grad d_p:  tensor(-0.0184, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0160, device='cuda:0') mean:  tensor(-2.1682e-05, device='cuda:0') min:  tensor(-0.0464, device='cuda:0') norm:  tensor(0.2138, device='cuda:0') MSE:  tensor(8.0245e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0033, device='cuda:0') mean:  tensor(1.0435e-05, device='cuda:0') min:  tensor(1.6371e-11, device='cuda:0') norm:  tensor(0.0144, device='cuda:0') MSE:  tensor(5.4168e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  124  
Training Loss: 0.0225352980196476
Test Loss:  0.01667345128953457
Test Acc:  0.0
Valid Loss:  0.019901664927601814
Valid Acc:  0.0
std:  0.00022904299657439153 
thres:  2.2857717424631118e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 12%|█▏        | 124/1000 [05:43<40:33,  2.78s/it]Epoch:   125
max of grad d_p:  tensor(0.0178, device='cuda:0')
min of grad d_p:  tensor(-0.0185, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0168, device='cuda:0') mean:  tensor(-2.2830e-05, device='cuda:0') min:  tensor(-0.0545, device='cuda:0') norm:  tensor(0.2264, device='cuda:0') MSE:  tensor(8.4992e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.8145e-05, device='cuda:0') mean:  tensor(3.7930e-07, device='cuda:0') min:  tensor(9.0949e-13, device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7594e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0022, device='cuda:0')
min of d_p_list:  tensor(-0.0037, device='cuda:0')
Epoch:  125  
Training Loss: 0.02237878181040287
Test Loss:  0.01651175692677498
Test Acc:  0.0
Valid Loss:  0.019712334498763084
Valid Acc:  0.0
std:  0.00022614720177475928 
thres:  2.2696707770228385e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 12%|█▎        | 125/1000 [05:46<40:29,  2.78s/it]Epoch:   126
max of grad d_p:  tensor(0.0177, device='cuda:0')
min of grad d_p:  tensor(-0.0186, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0168, device='cuda:0') mean:  tensor(-2.2892e-05, device='cuda:0') min:  tensor(-0.0473, device='cuda:0') norm:  tensor(0.2202, device='cuda:0') MSE:  tensor(8.2648e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0011, device='cuda:0') mean:  tensor(6.5481e-06, device='cuda:0') min:  tensor(7.2760e-12, device='cuda:0') norm:  tensor(0.0080, device='cuda:0') MSE:  tensor(3.0042e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0285, device='cuda:0')
min of d_p_list:  tensor(-0.0251, device='cuda:0')
Epoch:  126  
Training Loss: 0.022418703883886337
Test Loss:  0.01662566512823105
Test Acc:  0.0
Valid Loss:  0.019688591361045837
Valid Acc:  0.0
std:  0.00017816744668086945 
thres:  2.2577025368809698e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 13%|█▎        | 126/1000 [05:49<39:49,  2.73s/it]Epoch:   127
max of grad d_p:  tensor(0.0218, device='cuda:0')
min of grad d_p:  tensor(-0.0212, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0176, device='cuda:0') mean:  tensor(-2.4789e-05, device='cuda:0') min:  tensor(-0.0420, device='cuda:0') norm:  tensor(0.2223, device='cuda:0') MSE:  tensor(8.3430e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.0330e-05, device='cuda:0') mean:  tensor(3.8917e-07, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8068e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0029, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  127  
Training Loss: 0.02226579375565052
Test Loss:  0.016462553292512894
Test Acc:  0.0
Valid Loss:  0.019490227103233337
Valid Acc:  0.0
std:  0.00014610804291630172 
thres:  2.2458644956350324e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 13%|█▎        | 127/1000 [05:51<40:11,  2.76s/it]Epoch:   128
max of grad d_p:  tensor(0.0218, device='cuda:0')
min of grad d_p:  tensor(-0.0211, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0176, device='cuda:0') mean:  tensor(-2.4475e-05, device='cuda:0') min:  tensor(-0.0381, device='cuda:0') norm:  tensor(0.2157, device='cuda:0') MSE:  tensor(8.0970e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.7513e-05, device='cuda:0') mean:  tensor(4.4312e-07, device='cuda:0') min:  tensor(2.2737e-13, device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9887e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0122, device='cuda:0')
min of d_p_list:  tensor(-0.0069, device='cuda:0')
Epoch:  128  
Training Loss: 0.0221059899777174
Test Loss:  0.016293834894895554
Test Acc:  0.0
Valid Loss:  0.019283102825284004
Valid Acc:  0.0
std:  0.00014567273701648735 
thres:  2.2340913489460943e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 13%|█▎        | 128/1000 [05:54<41:05,  2.83s/it]Epoch:   129
max of grad d_p:  tensor(0.0218, device='cuda:0')
min of grad d_p:  tensor(-0.0220, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0179, device='cuda:0') mean:  tensor(-2.5113e-05, device='cuda:0') min:  tensor(-0.0411, device='cuda:0') norm:  tensor(0.2273, device='cuda:0') MSE:  tensor(8.5324e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.7516e-05, device='cuda:0') mean:  tensor(3.5159e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5088e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0056, device='cuda:0')
min of d_p_list:  tensor(-0.0027, device='cuda:0')
Epoch:  129  
Training Loss: 0.02195165306329727
Test Loss:  0.016125766560435295
Test Acc:  0.0
Valid Loss:  0.01908671110868454
Valid Acc:  0.0
std:  0.00017419114692542633 
thres:  2.2224184498190877e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 13%|█▎        | 129/1000 [05:57<39:58,  2.75s/it]Epoch:   130
max of grad d_p:  tensor(0.0217, device='cuda:0')
min of grad d_p:  tensor(-0.0223, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0187, device='cuda:0') mean:  tensor(-2.6582e-05, device='cuda:0') min:  tensor(-0.0434, device='cuda:0') norm:  tensor(0.2409, device='cuda:0') MSE:  tensor(9.0421e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.7260e-07, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.2718e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0022, device='cuda:0')
min of d_p_list:  tensor(-0.0036, device='cuda:0')
Epoch:  130  
Training Loss: 0.021800531074404716
Test Loss:  0.015969168394804
Test Acc:  0.0
Valid Loss:  0.018906470388174057
Valid Acc:  0.0
std:  0.00021928059200123612 
thres:  2.210853435099125e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 13%|█▎        | 130/1000 [06:00<39:37,  2.73s/it]Epoch:   131
max of grad d_p:  tensor(0.0216, device='cuda:0')
min of grad d_p:  tensor(-0.0223, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0183, device='cuda:0') mean:  tensor(-2.5213e-05, device='cuda:0') min:  tensor(-0.0432, device='cuda:0') norm:  tensor(0.2345, device='cuda:0') MSE:  tensor(8.8040e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(7.6422e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.5350e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1020, device='cuda:0')
min of d_p_list:  tensor(-0.1514, device='cuda:0')
Epoch:  131  
Training Loss: 0.02138695679605007
Test Loss:  0.015953894704580307
Test Acc:  0.0
Valid Loss:  0.01421481091529131
Valid Acc:  0.0
std:  0.0003006621054103329 
thres:  2.1902184933423997e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 13%|█▎        | 131/1000 [06:03<40:05,  2.77s/it]Epoch:   132
max of grad d_p:  tensor(0.0990, device='cuda:0')
min of grad d_p:  tensor(-0.0144, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0166, device='cuda:0') mean:  tensor(-2.4301e-05, device='cuda:0') min:  tensor(-0.0498, device='cuda:0') norm:  tensor(0.2943, device='cuda:0') MSE:  tensor(1.1049e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0018, device='cuda:0') mean:  tensor(7.4830e-06, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0090, device='cuda:0') MSE:  tensor(3.3712e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0019, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  132  
Training Loss: 0.021240683272480965
Test Loss:  0.01579388789832592
Test Acc:  0.0
Valid Loss:  0.01407109759747982
Valid Acc:  0.0
std:  0.00033081453397257977 
thres:  2.1697162836790085e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 13%|█▎        | 132/1000 [06:05<39:11,  2.71s/it]Epoch:   133
max of grad d_p:  tensor(0.0985, device='cuda:0')
min of grad d_p:  tensor(-0.0143, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0174, device='cuda:0') mean:  tensor(-2.3660e-05, device='cuda:0') min:  tensor(-0.0484, device='cuda:0') norm:  tensor(0.2933, device='cuda:0') MSE:  tensor(1.1011e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.8406e-05, device='cuda:0') mean:  tensor(4.3339e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.0781e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0018, device='cuda:0')
min of d_p_list:  tensor(-0.0052, device='cuda:0')
Epoch:  133  
Training Loss: 0.021099433302879333
Test Loss:  0.015637565404176712
Test Acc:  0.0
Valid Loss:  0.01393493264913559
Valid Acc:  0.0
std:  0.00032701711761179235 
thres:  2.1495851501822472e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 13%|█▎        | 133/1000 [06:08<39:44,  2.75s/it]Epoch:   134
max of grad d_p:  tensor(0.0980, device='cuda:0')
min of grad d_p:  tensor(-0.0144, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0167, device='cuda:0') mean:  tensor(-2.2421e-05, device='cuda:0') min:  tensor(-0.0443, device='cuda:0') norm:  tensor(0.2707, device='cuda:0') MSE:  tensor(1.0162e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(9.0932e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.3985e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0032, device='cuda:0')
min of d_p_list:  tensor(-0.0036, device='cuda:0')
Epoch:  134  
Training Loss: 0.02095884457230568
Test Loss:  0.0154802855104208
Test Acc:  0.0
Valid Loss:  0.0137957027181983
Valid Acc:  0.0
std:  0.00028920187240224116 
thres:  2.1297289803624155e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 13%|█▎        | 134/1000 [06:11<40:38,  2.82s/it]Epoch:   135
max of grad d_p:  tensor(0.0975, device='cuda:0')
min of grad d_p:  tensor(-0.0143, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0188, device='cuda:0') mean:  tensor(-2.2869e-05, device='cuda:0') min:  tensor(-0.0591, device='cuda:0') norm:  tensor(0.2906, device='cuda:0') MSE:  tensor(1.0907e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.8337e-05, device='cuda:0') mean:  tensor(3.1709e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4082e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0019, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  135  
Training Loss: 0.02081761322915554
Test Loss:  0.01532698143273592
Test Acc:  0.0
Valid Loss:  0.013658395037055016
Valid Acc:  0.0
std:  0.00020089846011359095 
thres:  2.110070623457432e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 14%|█▎        | 135/1000 [06:14<39:51,  2.76s/it]Epoch:   136
max of grad d_p:  tensor(0.0970, device='cuda:0')
min of grad d_p:  tensor(-0.0143, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0163, device='cuda:0') mean:  tensor(-2.1703e-05, device='cuda:0') min:  tensor(-0.0533, device='cuda:0') norm:  tensor(0.2732, device='cuda:0') MSE:  tensor(1.0255e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.7956e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2241e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0049, device='cuda:0')
min of d_p_list:  tensor(-0.0027, device='cuda:0')
Epoch:  136  
Training Loss: 0.020678527653217316
Test Loss:  0.015189426019787788
Test Acc:  0.0
Valid Loss:  0.013531388714909554
Valid Acc:  0.0
std:  0.0001988577164248531 
thres:  2.095902040600777e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 14%|█▎        | 136/1000 [06:16<40:01,  2.78s/it]Epoch:   137
max of grad d_p:  tensor(0.0965, device='cuda:0')
min of grad d_p:  tensor(-0.0144, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0214, device='cuda:0') mean:  tensor(-2.4859e-05, device='cuda:0') min:  tensor(-0.0502, device='cuda:0') norm:  tensor(0.2984, device='cuda:0') MSE:  tensor(1.1202e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.7317e-05, device='cuda:0') mean:  tensor(3.8974e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7295e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0046, device='cuda:0')
min of d_p_list:  tensor(-0.0033, device='cuda:0')
Epoch:  137  
Training Loss: 0.020539235323667526
Test Loss:  0.015047555789351463
Test Acc:  0.0
Valid Loss:  0.013407986611127853
Valid Acc:  0.0
std:  0.00019809172468082778 
thres:  2.0818730816245078e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 14%|█▎        | 137/1000 [06:19<39:09,  2.72s/it]Epoch:   138
max of grad d_p:  tensor(0.0960, device='cuda:0')
min of grad d_p:  tensor(-0.0144, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0197, device='cuda:0') mean:  tensor(-2.3289e-05, device='cuda:0') min:  tensor(-0.0528, device='cuda:0') norm:  tensor(0.2983, device='cuda:0') MSE:  tensor(1.1199e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.3840e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7515e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0019, device='cuda:0')
min of d_p_list:  tensor(-0.0031, device='cuda:0')
Epoch:  138  
Training Loss: 0.020402198657393456
Test Loss:  0.014896285720169544
Test Acc:  0.0
Valid Loss:  0.013271816074848175
Valid Acc:  0.0
std:  0.00019681442026279534 
thres:  2.0679283887147903e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 14%|█▍        | 138/1000 [06:22<39:46,  2.77s/it]Epoch:   139
max of grad d_p:  tensor(0.0956, device='cuda:0')
min of grad d_p:  tensor(-0.0143, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0156, device='cuda:0') mean:  tensor(-2.2430e-05, device='cuda:0') min:  tensor(-0.0459, device='cuda:0') norm:  tensor(0.2737, device='cuda:0') MSE:  tensor(1.0275e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(1.6729e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0022, device='cuda:0') MSE:  tensor(8.3834e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  139  
Training Loss: 0.02026592195034027
Test Loss:  0.014749674126505852
Test Acc:  0.0
Valid Loss:  0.01314256340265274
Valid Acc:  0.0
std:  0.0001951231109971804 
thres:  2.054069936275482e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 14%|█▍        | 139/1000 [06:25<40:16,  2.81s/it]Epoch:   140
max of grad d_p:  tensor(0.0951, device='cuda:0')
min of grad d_p:  tensor(-0.0143, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0187, device='cuda:0') mean:  tensor(-2.2281e-05, device='cuda:0') min:  tensor(-0.0601, device='cuda:0') norm:  tensor(0.2848, device='cuda:0') MSE:  tensor(1.0692e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.7360e-05, device='cuda:0') mean:  tensor(5.4458e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.3446e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0018, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  140  
Training Loss: 0.02013169601559639
Test Loss:  0.01460699737071991
Test Acc:  0.0
Valid Loss:  0.013018563389778137
Valid Acc:  0.0
std:  0.00019332413508744623 
thres:  2.040351592004299e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 14%|█▍        | 140/1000 [06:28<40:33,  2.83s/it]Epoch:   141
max of grad d_p:  tensor(0.0946, device='cuda:0')
min of grad d_p:  tensor(-0.0142, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0178, device='cuda:0') mean:  tensor(-2.4530e-05, device='cuda:0') min:  tensor(-0.0491, device='cuda:0') norm:  tensor(0.2954, device='cuda:0') MSE:  tensor(1.1090e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.0390e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0014, device='cuda:0') MSE:  tensor(5.1750e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0038, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  141  
Training Loss: 0.019998207688331604
Test Loss:  0.014469928108155727
Test Acc:  0.0
Valid Loss:  0.012894626706838608
Valid Acc:  0.0
std:  0.00019128374966086005 
thres:  2.026745192706585e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 14%|█▍        | 141/1000 [06:30<40:06,  2.80s/it]Epoch:   142
max of grad d_p:  tensor(0.0941, device='cuda:0')
min of grad d_p:  tensor(-0.0142, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0197, device='cuda:0') mean:  tensor(-2.6890e-05, device='cuda:0') min:  tensor(-0.0492, device='cuda:0') norm:  tensor(0.3148, device='cuda:0') MSE:  tensor(1.1817e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(9.2964e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.7455e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0020, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  142  
Training Loss: 0.01986750029027462
Test Loss:  0.014327260665595531
Test Acc:  0.0
Valid Loss:  0.012765966355800629
Valid Acc:  0.0
std:  0.00018910149153708865 
thres:  2.013310492038727e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 14%|█▍        | 142/1000 [06:33<39:01,  2.73s/it]Epoch:   143
max of grad d_p:  tensor(0.0937, device='cuda:0')
min of grad d_p:  tensor(-0.0141, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0174, device='cuda:0') mean:  tensor(-2.4435e-05, device='cuda:0') min:  tensor(-0.0536, device='cuda:0') norm:  tensor(0.2898, device='cuda:0') MSE:  tensor(1.0879e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.1628e-05, device='cuda:0') mean:  tensor(3.9068e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8642e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0043, device='cuda:0')
Epoch:  143  
Training Loss: 0.019735362380743027
Test Loss:  0.014184650033712387
Test Acc:  0.0
Valid Loss:  0.012633046135306358
Valid Acc:  0.0
std:  0.00018743021905928207 
thres:  1.9999737665057184e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 14%|█▍        | 143/1000 [06:36<39:03,  2.73s/it]Epoch:   144
max of grad d_p:  tensor(0.0932, device='cuda:0')
min of grad d_p:  tensor(-0.0141, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0195, device='cuda:0') mean:  tensor(-2.3303e-05, device='cuda:0') min:  tensor(-0.0649, device='cuda:0') norm:  tensor(0.3031, device='cuda:0') MSE:  tensor(1.1376e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.0032e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.3350e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0050, device='cuda:0')
min of d_p_list:  tensor(-0.0073, device='cuda:0')
Epoch:  144  
Training Loss: 0.019627917557954788
Test Loss:  0.014062266796827316
Test Acc:  0.0
Valid Loss:  0.012518462724983692
Valid Acc:  0.0
std:  0.0001797980158157401 
thres:  1.9872136786580085e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 14%|█▍        | 144/1000 [06:39<40:07,  2.81s/it]Epoch:   145
max of grad d_p:  tensor(0.0929, device='cuda:0')
min of grad d_p:  tensor(-0.0138, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0201, device='cuda:0') mean:  tensor(-2.4560e-05, device='cuda:0') min:  tensor(-0.0474, device='cuda:0') norm:  tensor(0.2934, device='cuda:0') MSE:  tensor(1.1013e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.3096e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.4667e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0017, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  145  
Training Loss: 0.019500140100717545
Test Loss:  0.013926221057772636
Test Acc:  0.0
Valid Loss:  0.012394310906529427
Valid Acc:  0.0
std:  0.00017485685497450225 
thres:  1.9745825603604316e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 14%|█▍        | 145/1000 [06:42<40:40,  2.85s/it]Epoch:   146
max of grad d_p:  tensor(0.0925, device='cuda:0')
min of grad d_p:  tensor(-0.0137, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0168, device='cuda:0') mean:  tensor(-2.2968e-05, device='cuda:0') min:  tensor(-0.0422, device='cuda:0') norm:  tensor(0.2744, device='cuda:0') MSE:  tensor(1.0299e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.3903e-05, device='cuda:0') mean:  tensor(3.5780e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5644e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0029, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  146  
Training Loss: 0.019373558461666107
Test Loss:  0.013793165795505047
Test Acc:  0.0
Valid Loss:  0.012273370288312435
Valid Acc:  0.0
std:  0.00017304529791858624 
thres:  1.9620895758271216e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 15%|█▍        | 146/1000 [06:44<39:50,  2.80s/it]Epoch:   147
max of grad d_p:  tensor(0.0920, device='cuda:0')
min of grad d_p:  tensor(-0.0136, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0187, device='cuda:0') mean:  tensor(-2.3768e-05, device='cuda:0') min:  tensor(-0.0439, device='cuda:0') norm:  tensor(0.2897, device='cuda:0') MSE:  tensor(1.0875e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.5497e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.5947e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0027, device='cuda:0')
Epoch:  147  
Training Loss: 0.01924826018512249
Test Loss:  0.013661140576004982
Test Acc:  0.0
Valid Loss:  0.01215483620762825
Valid Acc:  0.0
std:  0.00017382473314471702 
thres:  1.9497047737240793e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 15%|█▍        | 147/1000 [06:47<40:29,  2.85s/it]Epoch:   148
max of grad d_p:  tensor(0.0915, device='cuda:0')
min of grad d_p:  tensor(-0.0136, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0179, device='cuda:0') mean:  tensor(-2.4024e-05, device='cuda:0') min:  tensor(-0.0533, device='cuda:0') norm:  tensor(0.2921, device='cuda:0') MSE:  tensor(1.0966e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.5717e-05, device='cuda:0') mean:  tensor(3.0676e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.3729e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0048, device='cuda:0')
min of d_p_list:  tensor(-0.0038, device='cuda:0')
Epoch:  148  
Training Loss: 0.019123975187540054
Test Loss:  0.013516038656234741
Test Acc:  0.0
Valid Loss:  0.012028461322188377
Valid Acc:  0.0
std:  0.0001781603700570079 
thres:  1.9374770298600196e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 15%|█▍        | 148/1000 [06:50<40:52,  2.88s/it]Epoch:   149
max of grad d_p:  tensor(0.0911, device='cuda:0')
min of grad d_p:  tensor(-0.0135, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0208, device='cuda:0') mean:  tensor(-2.7323e-05, device='cuda:0') min:  tensor(-0.0472, device='cuda:0') norm:  tensor(0.3185, device='cuda:0') MSE:  tensor(1.1956e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.0760e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.8438e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0016, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  149  
Training Loss: 0.01899956911802292
Test Loss:  0.013381683267652988
Test Acc:  0.0
Valid Loss:  0.011908356100320816
Valid Acc:  0.0
std:  0.0001768805392852078 
thres:  1.9249100610613822e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 15%|█▍        | 149/1000 [06:53<41:10,  2.90s/it]Epoch:   150
max of grad d_p:  tensor(0.0906, device='cuda:0')
min of grad d_p:  tensor(-0.0134, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0211, device='cuda:0') mean:  tensor(-2.6016e-05, device='cuda:0') min:  tensor(-0.0468, device='cuda:0') norm:  tensor(0.3082, device='cuda:0') MSE:  tensor(1.1569e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.5038e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.5405e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  150  
Training Loss: 0.01887722872197628
Test Loss:  0.013250824064016342
Test Acc:  0.0
Valid Loss:  0.011791946366429329
Valid Acc:  0.0
std:  0.00017555499691172425 
thres:  1.912451833486557e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 15%|█▌        | 150/1000 [06:56<41:12,  2.91s/it]Epoch:   151
max of grad d_p:  tensor(0.0902, device='cuda:0')
min of grad d_p:  tensor(-0.0134, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0228, device='cuda:0') mean:  tensor(-2.8489e-05, device='cuda:0') min:  tensor(-0.0495, device='cuda:0') norm:  tensor(0.3331, device='cuda:0') MSE:  tensor(1.2503e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(5.6741e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.8451e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0037, device='cuda:0')
min of d_p_list:  tensor(-0.0027, device='cuda:0')
Epoch:  151  
Training Loss: 0.018760159611701965
Test Loss:  0.013122888281941414
Test Acc:  0.0
Valid Loss:  0.011680196970701218
Valid Acc:  0.0
std:  0.00017296383972639827 
thres:  1.9001838564872743e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 15%|█▌        | 151/1000 [06:59<41:12,  2.91s/it]Epoch:   152
max of grad d_p:  tensor(0.0897, device='cuda:0')
min of grad d_p:  tensor(-0.0133, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0205, device='cuda:0') mean:  tensor(-2.5622e-05, device='cuda:0') min:  tensor(-0.0444, device='cuda:0') norm:  tensor(0.3028, device='cuda:0') MSE:  tensor(1.1364e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.5888e-05, device='cuda:0') mean:  tensor(3.9606e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7669e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0023, device='cuda:0')
min of d_p_list:  tensor(-0.0034, device='cuda:0')
Epoch:  152  
Training Loss: 0.01864689029753208
Test Loss:  0.012991612777113914
Test Acc:  0.0
Valid Loss:  0.01155836321413517
Valid Acc:  0.0
std:  0.00016883006751525122 
thres:  1.8881564587354662e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 15%|█▌        | 152/1000 [07:02<41:18,  2.92s/it]Epoch:   153
max of grad d_p:  tensor(0.0893, device='cuda:0')
min of grad d_p:  tensor(-0.0131, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0209, device='cuda:0') mean:  tensor(-2.5872e-05, device='cuda:0') min:  tensor(-0.0541, device='cuda:0') norm:  tensor(0.3234, device='cuda:0') MSE:  tensor(1.2139e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.1829e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.4819e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0041, device='cuda:0')
min of d_p_list:  tensor(-0.0050, device='cuda:0')
Epoch:  153  
Training Loss: 0.018527144566178322
Test Loss:  0.012856541201472282
Test Acc:  0.0
Valid Loss:  0.01144163217395544
Valid Acc:  0.0
std:  0.0001662090567300158 
thres:  1.8762198463082314e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 15%|█▌        | 153/1000 [07:05<41:10,  2.92s/it]Epoch:   154
max of grad d_p:  tensor(0.0889, device='cuda:0')
min of grad d_p:  tensor(-0.0131, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0212, device='cuda:0') mean:  tensor(-2.6416e-05, device='cuda:0') min:  tensor(-0.0496, device='cuda:0') norm:  tensor(0.3105, device='cuda:0') MSE:  tensor(1.1656e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.1734e-05, device='cuda:0') mean:  tensor(3.7165e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.6117e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0019, device='cuda:0')
min of d_p_list:  tensor(-0.0034, device='cuda:0')
Epoch:  154  
Training Loss: 0.018411856144666672
Test Loss:  0.012732353061437607
Test Acc:  0.0
Valid Loss:  0.011331174522638321
Valid Acc:  0.0
std:  0.00016458484567606765 
thres:  1.8644655868411064e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 15%|█▌        | 154/1000 [07:08<42:43,  3.03s/it]Epoch:   155
max of grad d_p:  tensor(0.0885, device='cuda:0')
min of grad d_p:  tensor(-0.0131, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0211, device='cuda:0') mean:  tensor(-2.5890e-05, device='cuda:0') min:  tensor(-0.0732, device='cuda:0') norm:  tensor(0.3284, device='cuda:0') MSE:  tensor(1.2327e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.9130e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9669e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0016, device='cuda:0')
min of d_p_list:  tensor(-0.0038, device='cuda:0')
Epoch:  155  
Training Loss: 0.01829434186220169
Test Loss:  0.012609384953975677
Test Acc:  0.0
Valid Loss:  0.01122231688350439
Valid Acc:  0.0
std:  0.00016499649063085681 
thres:  1.8528078496456147e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 16%|█▌        | 155/1000 [07:11<42:47,  3.04s/it]Epoch:   156
max of grad d_p:  tensor(0.0880, device='cuda:0')
min of grad d_p:  tensor(-0.0130, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0193, device='cuda:0') mean:  tensor(-2.9318e-05, device='cuda:0') min:  tensor(-0.0497, device='cuda:0') norm:  tensor(0.3468, device='cuda:0') MSE:  tensor(1.3016e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(9.7664e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.6832e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  156  
Training Loss: 0.01817840337753296
Test Loss:  0.012484985403716564
Test Acc:  0.0
Valid Loss:  0.011111168190836906
Valid Acc:  0.0
std:  0.0001654340902860069 
thres:  1.8411727249622347e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 16%|█▌        | 156/1000 [07:14<42:29,  3.02s/it]Epoch:   157
max of grad d_p:  tensor(0.0876, device='cuda:0')
min of grad d_p:  tensor(-0.0129, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0245, device='cuda:0') mean:  tensor(-2.7211e-05, device='cuda:0') min:  tensor(-0.0469, device='cuda:0') norm:  tensor(0.3150, device='cuda:0') MSE:  tensor(1.1825e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.1908e-05, device='cuda:0') mean:  tensor(3.8552e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.6757e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0030, device='cuda:0')
min of d_p_list:  tensor(-0.0029, device='cuda:0')
Epoch:  157  
Training Loss: 0.018065495416522026
Test Loss:  0.012368176132440567
Test Acc:  0.0
Valid Loss:  0.0110043715685606
Valid Acc:  0.0
std:  0.00016359279492732194 
thres:  1.8295448273420334e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 16%|█▌        | 157/1000 [07:17<42:05,  3.00s/it]Epoch:   158
max of grad d_p:  tensor(0.0872, device='cuda:0')
min of grad d_p:  tensor(-0.0129, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0176, device='cuda:0') mean:  tensor(-2.4688e-05, device='cuda:0') min:  tensor(-0.0618, device='cuda:0') norm:  tensor(0.3027, device='cuda:0') MSE:  tensor(1.1364e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.9708e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8336e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0023, device='cuda:0')
min of d_p_list:  tensor(-0.0044, device='cuda:0')
Epoch:  158  
Training Loss: 0.01795259118080139
Test Loss:  0.012250280939042568
Test Acc:  0.0
Valid Loss:  0.010900981724262238
Valid Acc:  0.0
std:  0.00016227045825557065 
thres:  1.818053759634495e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 16%|█▌        | 158/1000 [07:20<41:53,  2.99s/it]Epoch:   159
max of grad d_p:  tensor(0.0867, device='cuda:0')
min of grad d_p:  tensor(-0.0129, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0224, device='cuda:0') mean:  tensor(-2.5228e-05, device='cuda:0') min:  tensor(-0.0471, device='cuda:0') norm:  tensor(0.3007, device='cuda:0') MSE:  tensor(1.1288e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0770, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(4.1837e-11, device='cuda:0') norm:  tensor(0.5825, device='cuda:0') MSE:  tensor(2.1867e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0034, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  159  
Training Loss: 0.01784045249223709
Test Loss:  0.012132308445870876
Test Acc:  0.0
Valid Loss:  0.010796274989843369
Valid Acc:  0.0
std:  0.0001603169913320316 
thres:  1.8066256865859034e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 16%|█▌        | 159/1000 [07:23<41:07,  2.93s/it]Epoch:   160
max of grad d_p:  tensor(0.0863, device='cuda:0')
min of grad d_p:  tensor(-0.0128, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0227, device='cuda:0') mean:  tensor(-2.6907e-05, device='cuda:0') min:  tensor(-0.0465, device='cuda:0') norm:  tensor(0.3180, device='cuda:0') MSE:  tensor(1.1936e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.4260e-05, device='cuda:0') mean:  tensor(6.0137e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.7257e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0019, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  160  
Training Loss: 0.017730258405208588
Test Loss:  0.012011943385004997
Test Acc:  0.0
Valid Loss:  0.010688933543860912
Valid Acc:  0.0
std:  0.00015858238190981537 
thres:  1.7953440174460414e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 16%|█▌        | 160/1000 [07:26<40:28,  2.89s/it]Epoch:   161
max of grad d_p:  tensor(0.0859, device='cuda:0')
min of grad d_p:  tensor(-0.0127, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0235, device='cuda:0') mean:  tensor(-2.7758e-05, device='cuda:0') min:  tensor(-0.0483, device='cuda:0') norm:  tensor(0.3199, device='cuda:0') MSE:  tensor(1.2008e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.4209e-05, device='cuda:0') mean:  tensor(4.4128e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(2.0111e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0023, device='cuda:0')
Epoch:  161  
Training Loss: 0.017621174454689026
Test Loss:  0.011893796734511852
Test Acc:  0.0
Valid Loss:  0.010583875700831413
Valid Acc:  0.0
std:  0.00015711976996465274 
thres:  1.7841994389891627e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 16%|█▌        | 161/1000 [07:29<41:06,  2.94s/it]Epoch:   162
max of grad d_p:  tensor(0.0854, device='cuda:0')
min of grad d_p:  tensor(-0.0127, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0220, device='cuda:0') mean:  tensor(-2.3411e-05, device='cuda:0') min:  tensor(-0.0436, device='cuda:0') norm:  tensor(0.2816, device='cuda:0') MSE:  tensor(1.0569e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.0697e-05, device='cuda:0') mean:  tensor(2.5367e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.1848e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0075, device='cuda:0')
min of d_p_list:  tensor(-0.0081, device='cuda:0')
Epoch:  162  
Training Loss: 0.01751701906323433
Test Loss:  0.011791691184043884
Test Acc:  0.0
Valid Loss:  0.010496875271201134
Valid Acc:  0.0
std:  0.00015422328136617061 
thres:  1.7732299119234084e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 16%|█▌        | 162/1000 [07:31<39:54,  2.86s/it]Epoch:   163
max of grad d_p:  tensor(0.0853, device='cuda:0')
min of grad d_p:  tensor(-0.0128, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0245, device='cuda:0') mean:  tensor(-2.7909e-05, device='cuda:0') min:  tensor(-0.0466, device='cuda:0') norm:  tensor(0.3186, device='cuda:0') MSE:  tensor(1.1961e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.2622e-05, device='cuda:0') mean:  tensor(5.0115e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2468e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0025, device='cuda:0')
Epoch:  163  
Training Loss: 0.017408493906259537
Test Loss:  0.011674918234348297
Test Acc:  0.0
Valid Loss:  0.01039372943341732
Valid Acc:  0.0
std:  0.00015233972384370983 
thres:  1.7623479664325715e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 16%|█▋        | 163/1000 [07:34<39:00,  2.80s/it]Epoch:   164
max of grad d_p:  tensor(0.0849, device='cuda:0')
min of grad d_p:  tensor(-0.0127, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0265, device='cuda:0') mean:  tensor(-2.9435e-05, device='cuda:0') min:  tensor(-0.0465, device='cuda:0') norm:  tensor(0.3342, device='cuda:0') MSE:  tensor(1.2544e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.2566e-05, device='cuda:0') mean:  tensor(4.3377e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(2.0116e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  164  
Training Loss: 0.01730053499341011
Test Loss:  0.011563347652554512
Test Acc:  0.0
Valid Loss:  0.010294921696186066
Valid Acc:  0.0
std:  0.00015162508276462695 
thres:  1.751549616456032e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 16%|█▋        | 164/1000 [07:37<39:01,  2.80s/it]Epoch:   165
max of grad d_p:  tensor(0.0844, device='cuda:0')
min of grad d_p:  tensor(-0.0126, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0230, device='cuda:0') mean:  tensor(-2.7297e-05, device='cuda:0') min:  tensor(-0.0438, device='cuda:0') norm:  tensor(0.3033, device='cuda:0') MSE:  tensor(1.1386e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.7354e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.6769e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0031, device='cuda:0')
min of d_p_list:  tensor(-0.0043, device='cuda:0')
Epoch:  165  
Training Loss: 0.01719450205564499
Test Loss:  0.011449835263192654
Test Acc:  0.0
Valid Loss:  0.010193239897489548
Valid Acc:  0.0
std:  0.00015129987002468844 
thres:  1.7408344894647598e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 16%|█▋        | 165/1000 [07:40<38:28,  2.76s/it]Epoch:   166
max of grad d_p:  tensor(0.0840, device='cuda:0')
min of grad d_p:  tensor(-0.0126, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0247, device='cuda:0') mean:  tensor(-2.9461e-05, device='cuda:0') min:  tensor(-0.0637, device='cuda:0') norm:  tensor(0.3394, device='cuda:0') MSE:  tensor(1.2740e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.5251e-05, device='cuda:0') mean:  tensor(3.0540e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.3232e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  166  
Training Loss: 0.01708913780748844
Test Loss:  0.011339490301907063
Test Acc:  0.0
Valid Loss:  0.010095678269863129
Valid Acc:  0.0
std:  0.00015128938985914123 
thres:  1.7301937565207483e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 17%|█▋        | 166/1000 [07:42<37:38,  2.71s/it]Epoch:   167
max of grad d_p:  tensor(0.0836, device='cuda:0')
min of grad d_p:  tensor(-0.0125, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0242, device='cuda:0') mean:  tensor(-2.5043e-05, device='cuda:0') min:  tensor(-0.0644, device='cuda:0') norm:  tensor(0.3184, device='cuda:0') MSE:  tensor(1.1953e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(7.2489e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.5243e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  167  
Training Loss: 0.016984062269330025
Test Loss:  0.011226272210478783
Test Acc:  0.0
Valid Loss:  0.00999709777534008
Valid Acc:  0.0
std:  0.00014994563116123972 
thres:  1.719534620642662e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 17%|█▋        | 167/1000 [07:45<39:21,  2.83s/it]Epoch:   168
max of grad d_p:  tensor(0.0832, device='cuda:0')
min of grad d_p:  tensor(-0.0124, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0253, device='cuda:0') mean:  tensor(-2.9820e-05, device='cuda:0') min:  tensor(-0.0479, device='cuda:0') norm:  tensor(0.3342, device='cuda:0') MSE:  tensor(1.2547e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(2.3808e-06, device='cuda:0') min:  tensor(2.2737e-13, device='cuda:0') norm:  tensor(0.0031, device='cuda:0') MSE:  tensor(1.1558e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  168  
Training Loss: 0.016880765557289124
Test Loss:  0.011117789894342422
Test Acc:  0.0
Valid Loss:  0.009901029989123344
Valid Acc:  0.0
std:  0.00014849111914724808 
thres:  1.708980053663254e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 17%|█▋        | 168/1000 [07:48<39:38,  2.86s/it]Epoch:   169
max of grad d_p:  tensor(0.0828, device='cuda:0')
min of grad d_p:  tensor(-0.0124, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0244, device='cuda:0') mean:  tensor(-2.9021e-05, device='cuda:0') min:  tensor(-0.0450, device='cuda:0') norm:  tensor(0.3186, device='cuda:0') MSE:  tensor(1.1960e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(7.7537e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.7839e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0059, device='cuda:0')
min of d_p_list:  tensor(-0.0052, device='cuda:0')
Epoch:  169  
Training Loss: 0.01677885837852955
Test Loss:  0.010999656282365322
Test Acc:  0.0
Valid Loss:  0.00979834794998169
Valid Acc:  0.0
std:  0.0001470338591194344 
thres:  1.6985465213656424e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 17%|█▋        | 169/1000 [07:51<39:37,  2.86s/it]Epoch:   170
max of grad d_p:  tensor(0.0823, device='cuda:0')
min of grad d_p:  tensor(-0.0124, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0236, device='cuda:0') mean:  tensor(-2.5214e-05, device='cuda:0') min:  tensor(-0.0686, device='cuda:0') norm:  tensor(0.3161, device='cuda:0') MSE:  tensor(1.1867e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.7181e-07, device='cuda:0') min:  tensor(1.5916e-12, device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.2114e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0412, device='cuda:0')
min of d_p_list:  tensor(-0.1595, device='cuda:0')
Epoch:  170  
Training Loss: 0.01774546317756176
Test Loss:  0.011908089742064476
Test Acc:  0.0
Valid Loss:  0.01055285707116127
Valid Acc:  0.0
std:  0.00034096441189564446 
thres:  1.7095657438039777e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 17%|█▋        | 170/1000 [07:54<39:22,  2.85s/it]Epoch:   171
max of grad d_p:  tensor(0.0869, device='cuda:0')
min of grad d_p:  tensor(-0.0138, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0214, device='cuda:0') mean:  tensor(-2.0707e-05, device='cuda:0') min:  tensor(-0.0524, device='cuda:0') norm:  tensor(0.2777, device='cuda:0') MSE:  tensor(1.0423e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.2157e-05, device='cuda:0') mean:  tensor(2.7160e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.2414e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  171  
Training Loss: 0.017635049298405647
Test Loss:  0.011794406920671463
Test Acc:  0.0
Valid Loss:  0.01045377179980278
Valid Acc:  0.0
std:  0.0004031329441164663 
thres:  1.720483973622322e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 17%|█▋        | 171/1000 [07:57<39:33,  2.86s/it]Epoch:   172
max of grad d_p:  tensor(0.0865, device='cuda:0')
min of grad d_p:  tensor(-0.0138, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0224, device='cuda:0') mean:  tensor(-2.2529e-05, device='cuda:0') min:  tensor(-0.0767, device='cuda:0') norm:  tensor(0.3099, device='cuda:0') MSE:  tensor(1.1632e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.5461e-05, device='cuda:0') mean:  tensor(3.0883e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5181e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0019, device='cuda:0')
min of d_p_list:  tensor(-0.0048, device='cuda:0')
Epoch:  172  
Training Loss: 0.017529109492897987
Test Loss:  0.011683092452585697
Test Acc:  0.0
Valid Loss:  0.010353190824389458
Valid Acc:  0.0
std:  0.00040238631765564714 
thres:  1.7313849180936813e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 17%|█▋        | 172/1000 [08:00<39:07,  2.83s/it]Epoch:   173
max of grad d_p:  tensor(0.0861, device='cuda:0')
min of grad d_p:  tensor(-0.0137, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0233, device='cuda:0') mean:  tensor(-2.1317e-05, device='cuda:0') min:  tensor(-0.0666, device='cuda:0') norm:  tensor(0.2897, device='cuda:0') MSE:  tensor(1.0875e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.4434e-07, device='cuda:0') min:  tensor(1.7053e-12, device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2211e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0028, device='cuda:0')
min of d_p_list:  tensor(-0.0023, device='cuda:0')
Epoch:  173  
Training Loss: 0.017423126846551895
Test Loss:  0.01157999224960804
Test Acc:  0.0
Valid Loss:  0.010263200849294662
Valid Acc:  0.0
std:  0.0003391527009164661 
thres:  1.7422321438789367e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 17%|█▋        | 173/1000 [08:02<38:23,  2.79s/it]Epoch:   174
max of grad d_p:  tensor(0.0856, device='cuda:0')
min of grad d_p:  tensor(-0.0136, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0219, device='cuda:0') mean:  tensor(-2.0886e-05, device='cuda:0') min:  tensor(-0.0730, device='cuda:0') norm:  tensor(0.2987, device='cuda:0') MSE:  tensor(1.1214e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(6.3298e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.3414e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0149, device='cuda:0')
min of d_p_list:  tensor(-0.0081, device='cuda:0')
Epoch:  174  
Training Loss: 0.017328016459941864
Test Loss:  0.011488518677651882
Test Acc:  0.0
Valid Loss:  0.010167361237108707
Valid Acc:  0.0
std:  0.00014809224971960896 
thres:  1.7532153055071832e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 17%|█▋        | 174/1000 [08:05<37:37,  2.73s/it]Epoch:   175
max of grad d_p:  tensor(0.0854, device='cuda:0')
min of grad d_p:  tensor(-0.0135, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0229, device='cuda:0') mean:  tensor(-2.4718e-05, device='cuda:0') min:  tensor(-0.0749, device='cuda:0') norm:  tensor(0.3347, device='cuda:0') MSE:  tensor(1.2565e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.7408e-05, device='cuda:0') mean:  tensor(4.1552e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.0755e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0030, device='cuda:0')
Epoch:  175  
Training Loss: 0.017221691086888313
Test Loss:  0.011380227282643318
Test Acc:  0.0
Valid Loss:  0.01007016934454441
Valid Acc:  0.0
std:  0.00014537851070437009 
thres:  1.742739863693714e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 18%|█▊        | 175/1000 [08:07<37:08,  2.70s/it]Epoch:   176
max of grad d_p:  tensor(0.0849, device='cuda:0')
min of grad d_p:  tensor(-0.0134, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0261, device='cuda:0') mean:  tensor(-2.4647e-05, device='cuda:0') min:  tensor(-0.0628, device='cuda:0') norm:  tensor(0.3263, device='cuda:0') MSE:  tensor(1.2249e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.8040e-05, device='cuda:0') mean:  tensor(3.3668e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5711e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  176  
Training Loss: 0.017115304246544838
Test Loss:  0.011272285133600235
Test Acc:  0.0
Valid Loss:  0.00997535977512598
Valid Acc:  0.0
std:  0.00014555527087150067 
thres:  1.7323449626564977e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 18%|█▊        | 176/1000 [08:10<36:53,  2.69s/it]Epoch:   177
max of grad d_p:  tensor(0.0845, device='cuda:0')
min of grad d_p:  tensor(-0.0133, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0264, device='cuda:0') mean:  tensor(-2.4790e-05, device='cuda:0') min:  tensor(-0.0642, device='cuda:0') norm:  tensor(0.3199, device='cuda:0') MSE:  tensor(1.2009e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.9510e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.4584e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0046, device='cuda:0')
min of d_p_list:  tensor(-0.0043, device='cuda:0')
Epoch:  177  
Training Loss: 0.01702137105166912
Test Loss:  0.011172622442245483
Test Acc:  0.0
Valid Loss:  0.009880583733320236
Valid Acc:  0.0
std:  0.00014375500286465033 
thres:  1.7221901938319204e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 18%|█▊        | 177/1000 [08:13<37:07,  2.71s/it]Epoch:   178
max of grad d_p:  tensor(0.0842, device='cuda:0')
min of grad d_p:  tensor(-0.0132, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0249, device='cuda:0') mean:  tensor(-2.4179e-05, device='cuda:0') min:  tensor(-0.0579, device='cuda:0') norm:  tensor(0.3064, device='cuda:0') MSE:  tensor(1.1501e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.4105e-05, device='cuda:0') mean:  tensor(3.5904e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7492e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  178  
Training Loss: 0.01691805198788643
Test Loss:  0.011064911261200905
Test Acc:  0.0
Valid Loss:  0.009786425158381462
Valid Acc:  0.0
std:  0.00014431958311791036 
thres:  1.712088696658611e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 18%|█▊        | 178/1000 [08:16<37:46,  2.76s/it]Epoch:   179
max of grad d_p:  tensor(0.0837, device='cuda:0')
min of grad d_p:  tensor(-0.0132, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0236, device='cuda:0') mean:  tensor(-2.4044e-05, device='cuda:0') min:  tensor(-0.0742, device='cuda:0') norm:  tensor(0.3300, device='cuda:0') MSE:  tensor(1.2389e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(3.5220e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0045, device='cuda:0') MSE:  tensor(1.6917e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  179  
Training Loss: 0.016815844923257828
Test Loss:  0.010956943035125732
Test Acc:  0.0
Valid Loss:  0.009692664258182049
Valid Acc:  0.0
std:  0.00014270584777006516 
thres:  1.7018452659249306e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 18%|█▊        | 179/1000 [08:18<37:10,  2.72s/it]Epoch:   180
max of grad d_p:  tensor(0.0833, device='cuda:0')
min of grad d_p:  tensor(-0.0131, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0246, device='cuda:0') mean:  tensor(-2.2498e-05, device='cuda:0') min:  tensor(-0.0558, device='cuda:0') norm:  tensor(0.2899, device='cuda:0') MSE:  tensor(1.0881e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.5412e-05, device='cuda:0') mean:  tensor(4.9741e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2122e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  180  
Training Loss: 0.01671450026333332
Test Loss:  0.010852697305381298
Test Acc:  0.0
Valid Loss:  0.009601090103387833
Valid Acc:  0.0
std:  0.00014244822859767572 
thres:  1.691701449453831e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 18%|█▊        | 180/1000 [08:21<37:17,  2.73s/it]Epoch:   181
max of grad d_p:  tensor(0.0829, device='cuda:0')
min of grad d_p:  tensor(-0.0130, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0248, device='cuda:0') mean:  tensor(-2.3848e-05, device='cuda:0') min:  tensor(-0.0582, device='cuda:0') norm:  tensor(0.3056, device='cuda:0') MSE:  tensor(1.1471e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.5312e-05, device='cuda:0') mean:  tensor(3.5838e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.6171e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  181  
Training Loss: 0.016614479944109917
Test Loss:  0.010749612003564835
Test Acc:  0.0
Valid Loss:  0.00951015017926693
Valid Acc:  0.0
std:  0.0001438755164878932 
thres:  1.6816849634051322e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 18%|█▊        | 181/1000 [08:24<37:41,  2.76s/it]Epoch:   182
max of grad d_p:  tensor(0.0825, device='cuda:0')
min of grad d_p:  tensor(-0.0129, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0289, device='cuda:0') mean:  tensor(-2.5687e-05, device='cuda:0') min:  tensor(-0.0735, device='cuda:0') norm:  tensor(0.3297, device='cuda:0') MSE:  tensor(1.2376e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.7468e-05, device='cuda:0') mean:  tensor(5.0074e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.1641e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  182  
Training Loss: 0.01651705801486969
Test Loss:  0.010644200257956982
Test Acc:  0.0
Valid Loss:  0.009414257481694221
Valid Acc:  0.0
std:  0.00014190172519970923 
thres:  1.6715987026691436e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 18%|█▊        | 182/1000 [08:27<38:30,  2.82s/it]Epoch:   183
max of grad d_p:  tensor(0.0821, device='cuda:0')
min of grad d_p:  tensor(-0.0129, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0278, device='cuda:0') mean:  tensor(-2.5980e-05, device='cuda:0') min:  tensor(-0.0641, device='cuda:0') norm:  tensor(0.3397, device='cuda:0') MSE:  tensor(1.2751e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0009, device='cuda:0') mean:  tensor(4.3952e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0052, device='cuda:0') MSE:  tensor(1.9413e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0034, device='cuda:0')
min of d_p_list:  tensor(-0.0039, device='cuda:0')
Epoch:  183  
Training Loss: 0.01642412506043911
Test Loss:  0.010546413250267506
Test Acc:  0.0
Valid Loss:  0.009317299351096153
Valid Acc:  0.0
std:  0.0001387378066308531 
thres:  1.6617201641201973e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 18%|█▊        | 183/1000 [08:30<37:54,  2.78s/it]Epoch:   184
max of grad d_p:  tensor(0.0818, device='cuda:0')
min of grad d_p:  tensor(-0.0128, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0233, device='cuda:0') mean:  tensor(-2.2541e-05, device='cuda:0') min:  tensor(-0.0601, device='cuda:0') norm:  tensor(0.2901, device='cuda:0') MSE:  tensor(1.0888e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.0481e-05, device='cuda:0') mean:  tensor(2.7337e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.2344e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  184  
Training Loss: 0.016326937824487686
Test Loss:  0.010445889085531235
Test Acc:  0.0
Valid Loss:  0.009228792041540146
Valid Acc:  0.0
std:  0.00013654947417383615 
thres:  1.6519420221447943e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 18%|█▊        | 184/1000 [08:32<37:30,  2.76s/it]Epoch:   185
max of grad d_p:  tensor(0.0813, device='cuda:0')
min of grad d_p:  tensor(-0.0127, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0256, device='cuda:0') mean:  tensor(-2.5036e-05, device='cuda:0') min:  tensor(-0.0611, device='cuda:0') norm:  tensor(0.3210, device='cuda:0') MSE:  tensor(1.2048e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.6717e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0022, device='cuda:0') MSE:  tensor(8.3185e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0200, device='cuda:0')
min of d_p_list:  tensor(-0.0231, device='cuda:0')
Epoch:  185  
Training Loss: 0.016233883798122406
Test Loss:  0.010364462621510029
Test Acc:  0.0
Valid Loss:  0.009183757938444614
Valid Acc:  0.0
std:  0.00013454009325322323 
thres:  1.6423296928405764e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 18%|█▊        | 185/1000 [08:35<37:10,  2.74s/it]Epoch:   186
max of grad d_p:  tensor(0.0814, device='cuda:0')
min of grad d_p:  tensor(-0.0126, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0232, device='cuda:0') mean:  tensor(-2.6484e-05, device='cuda:0') min:  tensor(-0.0614, device='cuda:0') norm:  tensor(0.3220, device='cuda:0') MSE:  tensor(1.2089e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.7935e-05, device='cuda:0') mean:  tensor(3.8744e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7048e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  186  
Training Loss: 0.01613827794790268
Test Loss:  0.010264096781611443
Test Acc:  0.0
Valid Loss:  0.0090952068567276
Valid Acc:  0.0
std:  0.00013404207472123052 
thres:  1.6328056529164315e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 19%|█▊        | 186/1000 [08:38<36:42,  2.71s/it]Epoch:   187
max of grad d_p:  tensor(0.0810, device='cuda:0')
min of grad d_p:  tensor(-0.0125, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0262, device='cuda:0') mean:  tensor(-2.7141e-05, device='cuda:0') min:  tensor(-0.0574, device='cuda:0') norm:  tensor(0.3232, device='cuda:0') MSE:  tensor(1.2133e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(7.4683e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.1677e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  187  
Training Loss: 0.01604439504444599
Test Loss:  0.01016458310186863
Test Acc:  0.0
Valid Loss:  0.009008141234517097
Valid Acc:  0.0
std:  0.00013408699308260503 
thres:  1.6233523935079575e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 19%|█▊        | 187/1000 [08:41<37:44,  2.79s/it]Epoch:   188
max of grad d_p:  tensor(0.0806, device='cuda:0')
min of grad d_p:  tensor(-0.0125, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0241, device='cuda:0') mean:  tensor(-2.6594e-05, device='cuda:0') min:  tensor(-0.0772, device='cuda:0') norm:  tensor(0.3242, device='cuda:0') MSE:  tensor(1.2170e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.3460e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.4491e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0016, device='cuda:0')
min of d_p_list:  tensor(-0.0029, device='cuda:0')
Epoch:  188  
Training Loss: 0.01595120318233967
Test Loss:  0.010065343230962753
Test Acc:  0.0
Valid Loss:  0.008922227658331394
Valid Acc:  0.0
std:  0.000133072766899887 
thres:  1.6138939559459684e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 19%|█▉        | 188/1000 [08:43<37:15,  2.75s/it]Epoch:   189
max of grad d_p:  tensor(0.0802, device='cuda:0')
min of grad d_p:  tensor(-0.0124, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0246, device='cuda:0') mean:  tensor(-2.6355e-05, device='cuda:0') min:  tensor(-0.0549, device='cuda:0') norm:  tensor(0.3074, device='cuda:0') MSE:  tensor(1.1540e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0605, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(1.5643e-10, device='cuda:0') norm:  tensor(0.2901, device='cuda:0') MSE:  tensor(1.0888e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0082, device='cuda:0')
Epoch:  189  
Training Loss: 0.015859214588999748
Test Loss:  0.009965924546122551
Test Acc:  0.0
Valid Loss:  0.008835196495056152
Valid Acc:  0.0
std:  0.00013243225656476028 
thres:  1.60453949123621e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 19%|█▉        | 189/1000 [08:46<37:34,  2.78s/it]Epoch:   190
max of grad d_p:  tensor(0.0799, device='cuda:0')
min of grad d_p:  tensor(-0.0123, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0257, device='cuda:0') mean:  tensor(-2.7423e-05, device='cuda:0') min:  tensor(-0.0601, device='cuda:0') norm:  tensor(0.3201, device='cuda:0') MSE:  tensor(1.2017e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.1336e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0014, device='cuda:0') MSE:  tensor(5.3406e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0025, device='cuda:0')
Epoch:  190  
Training Loss: 0.015767401084303856
Test Loss:  0.009870991110801697
Test Acc:  0.0
Valid Loss:  0.00875295139849186
Valid Acc:  0.0
std:  0.0001310898903952416 
thres:  1.595209836959839e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 19%|█▉        | 190/1000 [08:49<37:16,  2.76s/it]Epoch:   191
max of grad d_p:  tensor(0.0795, device='cuda:0')
min of grad d_p:  tensor(-0.0122, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0263, device='cuda:0') mean:  tensor(-2.5464e-05, device='cuda:0') min:  tensor(-0.0663, device='cuda:0') norm:  tensor(0.3177, device='cuda:0') MSE:  tensor(1.1925e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.8241e-05, device='cuda:0') mean:  tensor(4.6330e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.1757e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0045, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  191  
Training Loss: 0.015676142647862434
Test Loss:  0.009775253012776375
Test Acc:  0.0
Valid Loss:  0.008664789609611034
Valid Acc:  0.0
std:  0.0001301519993636461 
thres:  1.585967130959034e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 19%|█▉        | 191/1000 [08:52<36:58,  2.74s/it]Epoch:   192
max of grad d_p:  tensor(0.0791, device='cuda:0')
min of grad d_p:  tensor(-0.0122, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0252, device='cuda:0') mean:  tensor(-2.5305e-05, device='cuda:0') min:  tensor(-0.0523, device='cuda:0') norm:  tensor(0.2956, device='cuda:0') MSE:  tensor(1.1096e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.3081e-05, device='cuda:0') mean:  tensor(4.3369e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.0821e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0078, device='cuda:0')
min of d_p_list:  tensor(-0.0052, device='cuda:0')
Epoch:  192  
Training Loss: 0.015604306012392044
Test Loss:  0.009692957624793053
Test Acc:  0.0
Valid Loss:  0.008587047457695007
Valid Acc:  0.0
std:  0.0001241375207252741 
thres:  1.577165350317955e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 19%|█▉        | 192/1000 [08:54<36:57,  2.74s/it]Epoch:   193
max of grad d_p:  tensor(0.0788, device='cuda:0')
min of grad d_p:  tensor(-0.0121, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0277, device='cuda:0') mean:  tensor(-2.6315e-05, device='cuda:0') min:  tensor(-0.0549, device='cuda:0') norm:  tensor(0.3108, device='cuda:0') MSE:  tensor(1.1667e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(8.9364e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.3078e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  193  
Training Loss: 0.015515238046646118
Test Loss:  0.009602177888154984
Test Acc:  0.0
Valid Loss:  0.008506893180310726
Valid Acc:  0.0
std:  0.00012045604958969654 
thres:  1.568446047604084e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 19%|█▉        | 193/1000 [08:57<38:16,  2.85s/it]Epoch:   194
max of grad d_p:  tensor(0.0784, device='cuda:0')
min of grad d_p:  tensor(-0.0120, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0241, device='cuda:0') mean:  tensor(-2.7244e-05, device='cuda:0') min:  tensor(-0.0535, device='cuda:0') norm:  tensor(0.3248, device='cuda:0') MSE:  tensor(1.2192e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.8692e-05, device='cuda:0') mean:  tensor(3.1334e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4462e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0007, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  194  
Training Loss: 0.015426762402057648
Test Loss:  0.009508764371275902
Test Acc:  0.0
Valid Loss:  0.008424289524555206
Valid Acc:  0.0
std:  0.00011917601936142034 
thres:  1.559797003865242e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 19%|█▉        | 194/1000 [09:01<39:43,  2.96s/it]Epoch:   195
max of grad d_p:  tensor(0.0780, device='cuda:0')
min of grad d_p:  tensor(-0.0119, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0272, device='cuda:0') mean:  tensor(-2.6527e-05, device='cuda:0') min:  tensor(-0.0511, device='cuda:0') norm:  tensor(0.3096, device='cuda:0') MSE:  tensor(1.1620e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.5616e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(3.1265e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0030, device='cuda:0')
Epoch:  195  
Training Loss: 0.015338131226599216
Test Loss:  0.009410910308361053
Test Acc:  0.0
Valid Loss:  0.008344434201717377
Valid Acc:  0.0
std:  0.00012080515289183406 
thres:  1.551211606711149e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 20%|█▉        | 195/1000 [09:03<38:30,  2.87s/it]Epoch:   196
max of grad d_p:  tensor(0.0776, device='cuda:0')
min of grad d_p:  tensor(-0.0119, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0257, device='cuda:0') mean:  tensor(-2.5948e-05, device='cuda:0') min:  tensor(-0.0641, device='cuda:0') norm:  tensor(0.3125, device='cuda:0') MSE:  tensor(1.1731e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.8392e-05, device='cuda:0') mean:  tensor(3.2718e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5182e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0037, device='cuda:0')
min of d_p_list:  tensor(-0.0069, device='cuda:0')
Epoch:  196  
Training Loss: 0.015257425606250763
Test Loss:  0.00932016596198082
Test Acc:  0.0
Valid Loss:  0.008272135630249977
Valid Acc:  0.0
std:  0.0001231804727215286 
thres:  1.5428372658789158e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 20%|█▉        | 196/1000 [09:06<38:26,  2.87s/it]Epoch:   197
max of grad d_p:  tensor(0.0774, device='cuda:0')
min of grad d_p:  tensor(-0.0118, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0256, device='cuda:0') mean:  tensor(-2.9758e-05, device='cuda:0') min:  tensor(-0.0572, device='cuda:0') norm:  tensor(0.3370, device='cuda:0') MSE:  tensor(1.2649e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.7706e-05, device='cuda:0') mean:  tensor(2.8045e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.3089e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  197  
Training Loss: 0.015171056613326073
Test Loss:  0.009229348041117191
Test Acc:  0.0
Valid Loss:  0.008194200694561005
Valid Acc:  0.0
std:  0.00012131375707980816 
thres:  1.5341722778975963e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 20%|█▉        | 197/1000 [09:09<38:27,  2.87s/it]Epoch:   198
max of grad d_p:  tensor(0.0770, device='cuda:0')
min of grad d_p:  tensor(-0.0117, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0305, device='cuda:0') mean:  tensor(-2.9400e-05, device='cuda:0') min:  tensor(-0.0591, device='cuda:0') norm:  tensor(0.3456, device='cuda:0') MSE:  tensor(1.2972e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.6095e-05, device='cuda:0') mean:  tensor(2.7961e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.2814e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  198  
Training Loss: 0.015085749328136444
Test Loss:  0.009140840731561184
Test Acc:  0.0
Valid Loss:  0.008116062730550766
Valid Acc:  0.0
std:  0.00012008987121212482 
thres:  1.5255825035274029e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 20%|█▉        | 198/1000 [09:12<37:29,  2.81s/it]Epoch:   199
max of grad d_p:  tensor(0.0766, device='cuda:0')
min of grad d_p:  tensor(-0.0116, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0264, device='cuda:0') mean:  tensor(-2.8384e-05, device='cuda:0') min:  tensor(-0.0696, device='cuda:0') norm:  tensor(0.3419, device='cuda:0') MSE:  tensor(1.2834e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.4278e-05, device='cuda:0') mean:  tensor(2.6847e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.3776e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0029, device='cuda:0')
Epoch:  199  
Training Loss: 0.015001516789197922
Test Loss:  0.009053654968738556
Test Acc:  0.0
Valid Loss:  0.008040878921747208
Valid Acc:  0.0
std:  0.00011949411721655855 
thres:  1.5170775912702084e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 20%|█▉        | 199/1000 [09:15<37:34,  2.81s/it]Epoch:   200
max of grad d_p:  tensor(0.0762, device='cuda:0')
min of grad d_p:  tensor(-0.0116, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0257, device='cuda:0') mean:  tensor(-2.8829e-05, device='cuda:0') min:  tensor(-0.0654, device='cuda:0') norm:  tensor(0.3291, device='cuda:0') MSE:  tensor(1.2355e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.2972e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0017, device='cuda:0') MSE:  tensor(6.4469e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0007, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  200  
Training Loss: 0.014918113127350807
Test Loss:  0.008965999819338322
Test Acc:  0.0
Valid Loss:  0.00796441175043583
Valid Acc:  0.0
std:  0.00011995154148190942 
thres:  1.5086772292852403e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 20%|██        | 200/1000 [09:17<37:39,  2.82s/it]Epoch:   201
max of grad d_p:  tensor(0.0758, device='cuda:0')
min of grad d_p:  tensor(-0.0115, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0270, device='cuda:0') mean:  tensor(-3.0937e-05, device='cuda:0') min:  tensor(-0.0525, device='cuda:0') norm:  tensor(0.3411, device='cuda:0') MSE:  tensor(1.2805e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0010, device='cuda:0') mean:  tensor(7.2722e-06, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0087, device='cuda:0') MSE:  tensor(3.2818e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  201  
Training Loss: 0.014835309237241745
Test Loss:  0.008879778906702995
Test Acc:  0.0
Valid Loss:  0.007888932712376118
Valid Acc:  0.0
std:  0.00011867310620824639 
thres:  1.5002349019050599e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 20%|██        | 201/1000 [09:20<36:35,  2.75s/it]Epoch:   202
max of grad d_p:  tensor(0.0755, device='cuda:0')
min of grad d_p:  tensor(-0.0114, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0298, device='cuda:0') mean:  tensor(-3.0033e-05, device='cuda:0') min:  tensor(-0.0496, device='cuda:0') norm:  tensor(0.3310, device='cuda:0') MSE:  tensor(1.2426e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.6190e-06, device='cuda:0') min:  tensor(4.5475e-13, device='cuda:0') norm:  tensor(0.0019, device='cuda:0') MSE:  tensor(7.2059e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0009, device='cuda:0')
Epoch:  202  
Training Loss: 0.014753585681319237
Test Loss:  0.008793143555521965
Test Acc:  0.0
Valid Loss:  0.007813163101673126
Valid Acc:  0.0
std:  0.00011745729496669556 
thres:  1.4918854832649231e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 20%|██        | 202/1000 [09:23<36:09,  2.72s/it]Epoch:   203
max of grad d_p:  tensor(0.0751, device='cuda:0')
min of grad d_p:  tensor(-0.0113, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0293, device='cuda:0') mean:  tensor(-2.8292e-05, device='cuda:0') min:  tensor(-0.0787, device='cuda:0') norm:  tensor(0.3500, device='cuda:0') MSE:  tensor(1.3136e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0016, device='cuda:0') mean:  tensor(5.6787e-06, device='cuda:0') min:  tensor(2.7285e-12, device='cuda:0') norm:  tensor(0.0076, device='cuda:0') MSE:  tensor(2.8495e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  203  
Training Loss: 0.014673545956611633
Test Loss:  0.0087113743647933
Test Acc:  0.0
Valid Loss:  0.007740401662886143
Valid Acc:  0.0
std:  0.0001160357090244899 
thres:  1.4836414158344269e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 20%|██        | 203/1000 [09:25<36:10,  2.72s/it]Epoch:   204
max of grad d_p:  tensor(0.0747, device='cuda:0')
min of grad d_p:  tensor(-0.0113, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0255, device='cuda:0') mean:  tensor(-2.9594e-05, device='cuda:0') min:  tensor(-0.0529, device='cuda:0') norm:  tensor(0.3338, device='cuda:0') MSE:  tensor(1.2531e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.0847e-05, device='cuda:0') mean:  tensor(3.7107e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7943e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  204  
Training Loss: 0.014593817293643951
Test Loss:  0.008630073629319668
Test Acc:  0.0
Valid Loss:  0.007666607387363911
Valid Acc:  0.0
std:  0.00011460542147447874 
thres:  1.4754874259233475e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 20%|██        | 204/1000 [09:28<36:28,  2.75s/it]Epoch:   205
max of grad d_p:  tensor(0.0743, device='cuda:0')
min of grad d_p:  tensor(-0.0112, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0271, device='cuda:0') mean:  tensor(-2.8732e-05, device='cuda:0') min:  tensor(-0.0573, device='cuda:0') norm:  tensor(0.3220, device='cuda:0') MSE:  tensor(1.2087e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(1.3965e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0019, device='cuda:0') MSE:  tensor(7.0792e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0016, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  205  
Training Loss: 0.014514859765768051
Test Loss:  0.008545145392417908
Test Acc:  0.0
Valid Loss:  0.0075946408323943615
Valid Acc:  0.0
std:  0.00011323372946290515 
thres:  1.4674223586916924e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 20%|██        | 205/1000 [09:31<36:07,  2.73s/it]Epoch:   206
max of grad d_p:  tensor(0.0740, device='cuda:0')
min of grad d_p:  tensor(-0.0111, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0277, device='cuda:0') mean:  tensor(-3.0010e-05, device='cuda:0') min:  tensor(-0.0526, device='cuda:0') norm:  tensor(0.3372, device='cuda:0') MSE:  tensor(1.2658e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.0505e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8614e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0047, device='cuda:0')
Epoch:  206  
Training Loss: 0.014437075704336166
Test Loss:  0.008465227670967579
Test Acc:  0.0
Valid Loss:  0.007523839361965656
Valid Acc:  0.0
std:  0.00011196600338162132 
thres:  1.4594576880335808e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 21%|██        | 206/1000 [09:34<36:12,  2.74s/it]Epoch:   207
max of grad d_p:  tensor(0.0736, device='cuda:0')
min of grad d_p:  tensor(-0.0111, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0260, device='cuda:0') mean:  tensor(-2.8172e-05, device='cuda:0') min:  tensor(-0.0557, device='cuda:0') norm:  tensor(0.3207, device='cuda:0') MSE:  tensor(1.2040e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.2860e-05, device='cuda:0') mean:  tensor(4.3028e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9834e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0034, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  207  
Training Loss: 0.014359958469867706
Test Loss:  0.008385790511965752
Test Acc:  0.0
Valid Loss:  0.007451590616255999
Valid Acc:  0.0
std:  0.00011086519109949292 
thres:  1.4515851438045503e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 21%|██        | 207/1000 [09:37<37:10,  2.81s/it]Epoch:   208
max of grad d_p:  tensor(0.0733, device='cuda:0')
min of grad d_p:  tensor(-0.0110, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0294, device='cuda:0') mean:  tensor(-3.0690e-05, device='cuda:0') min:  tensor(-0.0629, device='cuda:0') norm:  tensor(0.3522, device='cuda:0') MSE:  tensor(1.3220e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.8603e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.3295e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  208  
Training Loss: 0.014282526448369026
Test Loss:  0.008301720023155212
Test Acc:  0.0
Valid Loss:  0.00737965852022171
Valid Acc:  0.0
std:  0.00010995380070202282 
thres:  1.443764753639698e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 21%|██        | 208/1000 [09:39<36:15,  2.75s/it]Epoch:   209
max of grad d_p:  tensor(0.0729, device='cuda:0')
min of grad d_p:  tensor(-0.0110, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0304, device='cuda:0') mean:  tensor(-3.1070e-05, device='cuda:0') min:  tensor(-0.0559, device='cuda:0') norm:  tensor(0.3613, device='cuda:0') MSE:  tensor(1.3563e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.5182e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8932e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0282, device='cuda:0')
min of d_p_list:  tensor(-0.0222, device='cuda:0')
Epoch:  209  
Training Loss: 0.014036029577255249
Test Loss:  0.008069373667240143
Test Acc:  0.0
Valid Loss:  0.007239754311740398
Valid Acc:  0.0
std:  0.00016439693194209406 
thres:  1.432608999311924e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 21%|██        | 209/1000 [09:42<35:37,  2.70s/it]Epoch:   210
max of grad d_p:  tensor(0.0695, device='cuda:0')
min of grad d_p:  tensor(-0.0109, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0276, device='cuda:0') mean:  tensor(-2.6841e-05, device='cuda:0') min:  tensor(-0.0483, device='cuda:0') norm:  tensor(0.3206, device='cuda:0') MSE:  tensor(1.2036e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.4031e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.6138e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0036, device='cuda:0')
min of d_p_list:  tensor(-0.0029, device='cuda:0')
Epoch:  210  
Training Loss: 0.013962063938379288
Test Loss:  0.00799181405454874
Test Acc:  0.0
Valid Loss:  0.00717386556789279
Valid Acc:  0.0
std:  0.00018487620304832782 
thres:  1.4215530827641487e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 21%|██        | 210/1000 [09:44<35:32,  2.70s/it]Epoch:   211
max of grad d_p:  tensor(0.0691, device='cuda:0')
min of grad d_p:  tensor(-0.0108, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0288, device='cuda:0') mean:  tensor(-2.6737e-05, device='cuda:0') min:  tensor(-0.0761, device='cuda:0') norm:  tensor(0.3461, device='cuda:0') MSE:  tensor(1.2992e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0024, device='cuda:0') mean:  tensor(1.1500e-05, device='cuda:0') min:  tensor(4.2292e-11, device='cuda:0') norm:  tensor(0.0134, device='cuda:0') MSE:  tensor(5.0299e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0071, device='cuda:0')
min of d_p_list:  tensor(-0.0044, device='cuda:0')
Epoch:  211  
Training Loss: 0.013889789581298828
Test Loss:  0.007909504696726799
Test Acc:  0.0
Valid Loss:  0.007098023779690266
Valid Acc:  0.0
std:  0.00018331222509870574 
thres:  1.4106073603034019e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 21%|██        | 211/1000 [09:47<35:54,  2.73s/it]Epoch:   212
max of grad d_p:  tensor(0.0688, device='cuda:0')
min of grad d_p:  tensor(-0.0107, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0317, device='cuda:0') mean:  tensor(-2.6745e-05, device='cuda:0') min:  tensor(-0.0538, device='cuda:0') norm:  tensor(0.3437, device='cuda:0') MSE:  tensor(1.2900e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.2420e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0017, device='cuda:0') MSE:  tensor(6.2952e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0033, device='cuda:0')
min of d_p_list:  tensor(-0.0040, device='cuda:0')
Epoch:  212  
Training Loss: 0.013820274733006954
Test Loss:  0.007836748845875263
Test Acc:  0.0
Valid Loss:  0.007032920606434345
Valid Acc:  0.0
std:  0.00015936663433001536 
thres:  1.399813685566187e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 21%|██        | 212/1000 [09:50<36:51,  2.81s/it]Epoch:   213
max of grad d_p:  tensor(0.0685, device='cuda:0')
min of grad d_p:  tensor(-0.0107, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0315, device='cuda:0') mean:  tensor(-2.8344e-05, device='cuda:0') min:  tensor(-0.0827, device='cuda:0') norm:  tensor(0.3842, device='cuda:0') MSE:  tensor(1.4422e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0010, device='cuda:0') mean:  tensor(5.0118e-06, device='cuda:0') min:  tensor(3.2969e-12, device='cuda:0') norm:  tensor(0.0064, device='cuda:0') MSE:  tensor(2.4141e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  213  
Training Loss: 0.013748643919825554
Test Loss:  0.007760860025882721
Test Acc:  0.0
Valid Loss:  0.006965909153223038
Valid Acc:  0.0
std:  0.00010134277914451603 
thres:  1.3891360349953174e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 21%|██▏       | 213/1000 [09:53<35:55,  2.74s/it]Epoch:   214
max of grad d_p:  tensor(0.0681, device='cuda:0')
min of grad d_p:  tensor(-0.0106, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0321, device='cuda:0') mean:  tensor(-2.8687e-05, device='cuda:0') min:  tensor(-0.0526, device='cuda:0') norm:  tensor(0.3549, device='cuda:0') MSE:  tensor(1.3321e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.3860e-05, device='cuda:0') mean:  tensor(5.1279e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.1281e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  214  
Training Loss: 0.013677898794412613
Test Loss:  0.0076870364136993885
Test Acc:  0.0
Valid Loss:  0.006900405045598745
Valid Acc:  0.0
std:  0.00010033634761679529 
thres:  1.3819734193384648e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 21%|██▏       | 214/1000 [09:55<35:06,  2.68s/it]Epoch:   215
max of grad d_p:  tensor(0.0678, device='cuda:0')
min of grad d_p:  tensor(-0.0105, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0343, device='cuda:0') mean:  tensor(-2.7836e-05, device='cuda:0') min:  tensor(-0.0746, device='cuda:0') norm:  tensor(0.3783, device='cuda:0') MSE:  tensor(1.4202e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.7714e-05, device='cuda:0') mean:  tensor(4.3282e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9172e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  215  
Training Loss: 0.013609535060822964
Test Loss:  0.0076174670830369
Test Acc:  0.0
Valid Loss:  0.006836218759417534
Valid Acc:  0.0
std:  9.940574468571973e-05 
thres:  1.3749228417873383e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 22%|██▏       | 215/1000 [09:58<36:03,  2.76s/it]Epoch:   216
max of grad d_p:  tensor(0.0675, device='cuda:0')
min of grad d_p:  tensor(-0.0105, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0351, device='cuda:0') mean:  tensor(-3.0863e-05, device='cuda:0') min:  tensor(-0.0574, device='cuda:0') norm:  tensor(0.3633, device='cuda:0') MSE:  tensor(1.3638e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(7.8266e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.6834e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0028, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  216  
Training Loss: 0.013542315922677517
Test Loss:  0.0075452798046171665
Test Acc:  0.0
Valid Loss:  0.006770934909582138
Valid Acc:  0.0
std:  9.830082573421334e-05 
thres:  1.367973368614912e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 22%|██▏       | 216/1000 [10:01<36:26,  2.79s/it]Epoch:   217
max of grad d_p:  tensor(0.0672, device='cuda:0')
min of grad d_p:  tensor(-0.0104, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0299, device='cuda:0') mean:  tensor(-2.6998e-05, device='cuda:0') min:  tensor(-0.0479, device='cuda:0') norm:  tensor(0.3199, device='cuda:0') MSE:  tensor(1.2007e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.6040e-05, device='cuda:0') mean:  tensor(5.1269e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2804e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0034, device='cuda:0')
Epoch:  217  
Training Loss: 0.013474364764988422
Test Loss:  0.007475145626813173
Test Acc:  0.0
Valid Loss:  0.006708887871354818
Valid Acc:  0.0
std:  9.675652787490636e-05 
thres:  1.3610551692545414e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 22%|██▏       | 217/1000 [10:04<36:24,  2.79s/it]Epoch:   218
max of grad d_p:  tensor(0.0668, device='cuda:0')
min of grad d_p:  tensor(-0.0104, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0310, device='cuda:0') mean:  tensor(-2.7493e-05, device='cuda:0') min:  tensor(-0.0504, device='cuda:0') norm:  tensor(0.3367, device='cuda:0') MSE:  tensor(1.2638e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.5260e-07, device='cuda:0') min:  tensor(7.9581e-13, device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.3810e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0007, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  218  
Training Loss: 0.013406822457909584
Test Loss:  0.007403533905744553
Test Acc:  0.0
Valid Loss:  0.006645438261330128
Valid Acc:  0.0
std:  9.578818703459704e-05 
thres:  1.354218740016222e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 22%|██▏       | 218/1000 [10:07<36:59,  2.84s/it]Epoch:   219
max of grad d_p:  tensor(0.0665, device='cuda:0')
min of grad d_p:  tensor(-0.0103, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0329, device='cuda:0') mean:  tensor(-2.8384e-05, device='cuda:0') min:  tensor(-0.0681, device='cuda:0') norm:  tensor(0.3759, device='cuda:0') MSE:  tensor(1.4108e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0011, device='cuda:0') mean:  tensor(6.3733e-06, device='cuda:0') min:  tensor(9.0949e-13, device='cuda:0') norm:  tensor(0.0083, device='cuda:0') MSE:  tensor(3.1269e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0064, device='cuda:0')
min of d_p_list:  tensor(-0.0080, device='cuda:0')
Epoch:  219  
Training Loss: 0.013356875628232956
Test Loss:  0.0073484331369400024
Test Acc:  0.0
Valid Loss:  0.006588751915842295
Valid Acc:  0.0
std:  9.076186370745192e-05 
thres:  1.347798276692629e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 22%|██▏       | 219/1000 [10:10<36:38,  2.81s/it]Epoch:   220
max of grad d_p:  tensor(0.0662, device='cuda:0')
min of grad d_p:  tensor(-0.0103, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0289, device='cuda:0') mean:  tensor(-2.6143e-05, device='cuda:0') min:  tensor(-0.0519, device='cuda:0') norm:  tensor(0.3462, device='cuda:0') MSE:  tensor(1.2995e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(7.5759e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.8551e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0006, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  220  
Training Loss: 0.013290620408952236
Test Loss:  0.007278528995811939
Test Acc:  0.0
Valid Loss:  0.006525809410959482
Valid Acc:  0.0
std:  8.791577291795222e-05 
thres:  1.3414199836552144e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 22%|██▏       | 220/1000 [10:12<36:05,  2.78s/it]Epoch:   221
max of grad d_p:  tensor(0.0659, device='cuda:0')
min of grad d_p:  tensor(-0.0102, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0255, device='cuda:0') mean:  tensor(-2.5194e-05, device='cuda:0') min:  tensor(-0.0543, device='cuda:0') norm:  tensor(0.3200, device='cuda:0') MSE:  tensor(1.2011e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.3512e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.8179e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  221  
Training Loss: 0.013226520270109177
Test Loss:  0.00720923813059926
Test Acc:  0.0
Valid Loss:  0.006463019642978907
Valid Acc:  0.0
std:  8.661457722430744e-05 
thres:  1.3351040706038476e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 22%|██▏       | 221/1000 [10:15<35:18,  2.72s/it]Epoch:   222
max of grad d_p:  tensor(0.0656, device='cuda:0')
min of grad d_p:  tensor(-0.0102, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0283, device='cuda:0') mean:  tensor(-2.5080e-05, device='cuda:0') min:  tensor(-0.0530, device='cuda:0') norm:  tensor(0.3271, device='cuda:0') MSE:  tensor(1.2277e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(7.5073e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.4713e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0209, device='cuda:0')
min of d_p_list:  tensor(-0.0300, device='cuda:0')
Epoch:  222  
Training Loss: 0.013225606642663479
Test Loss:  0.007188166491687298
Test Acc:  0.0
Valid Loss:  0.0064885178580880165
Valid Acc:  0.0
std:  7.163684107088158e-05 
thres:  1.3301289081573487e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 22%|██▏       | 222/1000 [10:17<34:26,  2.66s/it]Epoch:   223
max of grad d_p:  tensor(0.0652, device='cuda:0')
min of grad d_p:  tensor(-0.0103, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0312, device='cuda:0') mean:  tensor(-2.5696e-05, device='cuda:0') min:  tensor(-0.0560, device='cuda:0') norm:  tensor(0.3617, device='cuda:0') MSE:  tensor(1.3578e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.2342e-05, device='cuda:0') mean:  tensor(3.4758e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4984e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0016, device='cuda:0')
min of d_p_list:  tensor(-0.0031, device='cuda:0')
Epoch:  223  
Training Loss: 0.013159617781639099
Test Loss:  0.007118230685591698
Test Acc:  0.0
Valid Loss:  0.006430234294384718
Valid Acc:  0.0
std:  6.688889041279928e-05 
thres:  1.3251848146319389e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 22%|██▏       | 223/1000 [10:20<34:28,  2.66s/it]Epoch:   224
max of grad d_p:  tensor(0.0648, device='cuda:0')
min of grad d_p:  tensor(-0.0102, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0307, device='cuda:0') mean:  tensor(-2.7214e-05, device='cuda:0') min:  tensor(-0.0682, device='cuda:0') norm:  tensor(0.3546, device='cuda:0') MSE:  tensor(1.3310e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.3003e-05, device='cuda:0') mean:  tensor(4.3756e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(2.0246e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0043, device='cuda:0')
min of d_p_list:  tensor(-0.0023, device='cuda:0')
Epoch:  224  
Training Loss: 0.01310009229928255
Test Loss:  0.0070527661591768265
Test Acc:  0.0
Valid Loss:  0.006366962566971779
Valid Acc:  0.0
std:  6.508786038989259e-05 
thres:  1.320049148052931e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 22%|██▏       | 224/1000 [10:23<34:23,  2.66s/it]Epoch:   225
max of grad d_p:  tensor(0.0646, device='cuda:0')
min of grad d_p:  tensor(-0.0102, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0330, device='cuda:0') mean:  tensor(-2.5035e-05, device='cuda:0') min:  tensor(-0.0618, device='cuda:0') norm:  tensor(0.3593, device='cuda:0') MSE:  tensor(1.3488e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.7857e-05, device='cuda:0') mean:  tensor(2.8695e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.3092e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0006, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  225  
Training Loss: 0.013036350719630718
Test Loss:  0.006985028274357319
Test Acc:  0.0
Valid Loss:  0.006306728348135948
Valid Acc:  0.0
std:  7.358056607398635e-05 
thres:  1.3149637542665005e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 22%|██▎       | 225/1000 [10:26<34:54,  2.70s/it]Epoch:   226
max of grad d_p:  tensor(0.0642, device='cuda:0')
min of grad d_p:  tensor(-0.0101, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0314, device='cuda:0') mean:  tensor(-2.2918e-05, device='cuda:0') min:  tensor(-0.0718, device='cuda:0') norm:  tensor(0.3562, device='cuda:0') MSE:  tensor(1.3372e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.4707e-07, device='cuda:0') min:  tensor(2.7285e-12, device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.8826e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  226  
Training Loss: 0.012972792610526085
Test Loss:  0.006918009370565414
Test Acc:  0.0
Valid Loss:  0.006247349549084902
Valid Acc:  0.0
std:  8.894732116854677e-05 
thres:  1.3098892010748386e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 23%|██▎       | 226/1000 [10:28<34:28,  2.67s/it]Epoch:   227
max of grad d_p:  tensor(0.0639, device='cuda:0')
min of grad d_p:  tensor(-0.0101, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0302, device='cuda:0') mean:  tensor(-2.5924e-05, device='cuda:0') min:  tensor(-0.0656, device='cuda:0') norm:  tensor(0.3735, device='cuda:0') MSE:  tensor(1.4019e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.0079e-05, device='cuda:0') mean:  tensor(2.8659e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.2978e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  227  
Training Loss: 0.012909437529742718
Test Loss:  0.006851257756352425
Test Acc:  0.0
Valid Loss:  0.006188344210386276
Valid Acc:  0.0
std:  8.877156138542649e-05 
thres:  1.3035658188164235e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 23%|██▎       | 227/1000 [10:31<35:18,  2.74s/it]Epoch:   228
max of grad d_p:  tensor(0.0636, device='cuda:0')
min of grad d_p:  tensor(-0.0100, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-2.8258e-05, device='cuda:0') min:  tensor(-0.0574, device='cuda:0') norm:  tensor(0.3944, device='cuda:0') MSE:  tensor(1.4804e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.9041e-05, device='cuda:0') mean:  tensor(4.0179e-07, device='cuda:0') min:  tensor(9.0949e-13, device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.0654e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  228  
Training Loss: 0.012846091762185097
Test Loss:  0.006786436308175325
Test Acc:  0.0
Valid Loss:  0.00613415939733386
Valid Acc:  0.0
std:  8.979051912440247e-05 
thres:  1.2972952984273433e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 23%|██▎       | 228/1000 [10:34<37:23,  2.91s/it]Epoch:   229
max of grad d_p:  tensor(0.0633, device='cuda:0')
min of grad d_p:  tensor(-0.0100, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0331, device='cuda:0') mean:  tensor(-2.4466e-05, device='cuda:0') min:  tensor(-0.0581, device='cuda:0') norm:  tensor(0.3498, device='cuda:0') MSE:  tensor(1.3132e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.7480e-07, device='cuda:0') min:  tensor(7.9581e-13, device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.4269e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0019, device='cuda:0')
min of d_p_list:  tensor(-0.0030, device='cuda:0')
Epoch:  229  
Training Loss: 0.012783769518136978
Test Loss:  0.0067207664251327515
Test Acc:  0.0
Valid Loss:  0.006077316589653492
Valid Acc:  0.0
std:  8.935954866406875e-05 
thres:  1.290968842804432e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 23%|██▎       | 229/1000 [10:37<36:06,  2.81s/it]Epoch:   230
max of grad d_p:  tensor(0.0630, device='cuda:0')
min of grad d_p:  tensor(-0.0099, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0308, device='cuda:0') mean:  tensor(-2.4575e-05, device='cuda:0') min:  tensor(-0.0540, device='cuda:0') norm:  tensor(0.3279, device='cuda:0') MSE:  tensor(1.2308e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(8.8900e-07, device='cuda:0') min:  tensor(7.9581e-13, device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.0200e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  230  
Training Loss: 0.01272270455956459
Test Loss:  0.006655978038907051
Test Acc:  0.0
Valid Loss:  0.006019791588187218
Valid Acc:  0.0
std:  8.851044334327045e-05 
thres:  1.2846959196031094e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 23%|██▎       | 230/1000 [10:40<36:57,  2.88s/it]Epoch:   231
max of grad d_p:  tensor(0.0627, device='cuda:0')
min of grad d_p:  tensor(-0.0099, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0337, device='cuda:0') mean:  tensor(-2.5395e-05, device='cuda:0') min:  tensor(-0.0576, device='cuda:0') norm:  tensor(0.3513, device='cuda:0') MSE:  tensor(1.3187e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.7946e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0022, device='cuda:0') MSE:  tensor(8.2385e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0006, device='cuda:0')
min of d_p_list:  tensor(-0.0009, device='cuda:0')
Epoch:  231  
Training Loss: 0.012662472203373909
Test Loss:  0.006592117249965668
Test Acc:  0.0
Valid Loss:  0.005963513627648354
Valid Acc:  0.0
std:  8.730652225500315e-05 
thres:  1.2784895114600659e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 23%|██▎       | 231/1000 [10:43<38:08,  2.98s/it]Epoch:   232
max of grad d_p:  tensor(0.0623, device='cuda:0')
min of grad d_p:  tensor(-0.0098, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-2.7380e-05, device='cuda:0') min:  tensor(-0.0584, device='cuda:0') norm:  tensor(0.3609, device='cuda:0') MSE:  tensor(1.3546e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(8.9205e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.4870e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  232  
Training Loss: 0.012605411000549793
Test Loss:  0.006533003877848387
Test Acc:  0.0
Valid Loss:  0.005910000763833523
Valid Acc:  0.0
std:  8.52401924891122e-05 
thres:  1.2724089808762075e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 23%|██▎       | 232/1000 [10:46<37:29,  2.93s/it]Epoch:   233
max of grad d_p:  tensor(0.0620, device='cuda:0')
min of grad d_p:  tensor(-0.0098, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0316, device='cuda:0') mean:  tensor(-2.5316e-05, device='cuda:0') min:  tensor(-0.0663, device='cuda:0') norm:  tensor(0.3552, device='cuda:0') MSE:  tensor(1.3332e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.5223e-06, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0019, device='cuda:0') MSE:  tensor(7.0548e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  233  
Training Loss: 0.012546765618026257
Test Loss:  0.006470693275332451
Test Acc:  0.0
Valid Loss:  0.005854274146258831
Valid Acc:  0.0
std:  8.3629678874887e-05 
thres:  1.2664224579930305e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 23%|██▎       | 233/1000 [10:49<38:26,  3.01s/it]Epoch:   234
max of grad d_p:  tensor(0.0617, device='cuda:0')
min of grad d_p:  tensor(-0.0097, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0358, device='cuda:0') mean:  tensor(-2.7508e-05, device='cuda:0') min:  tensor(-0.0625, device='cuda:0') norm:  tensor(0.3714, device='cuda:0') MSE:  tensor(1.3940e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.0355e-05, device='cuda:0') mean:  tensor(4.3545e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9567e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0024, device='cuda:0')
min of d_p_list:  tensor(-0.0042, device='cuda:0')
Epoch:  234  
Training Loss: 0.012497346848249435
Test Loss:  0.006417439319193363
Test Acc:  0.0
Valid Loss:  0.00579533725976944
Valid Acc:  0.0
std:  8.014887629729718e-05 
thres:  1.2606940045952798e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 23%|██▎       | 234/1000 [10:52<37:08,  2.91s/it]Epoch:   235
max of grad d_p:  tensor(0.0615, device='cuda:0')
min of grad d_p:  tensor(-0.0096, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0327, device='cuda:0') mean:  tensor(-2.4431e-05, device='cuda:0') min:  tensor(-0.0869, device='cuda:0') norm:  tensor(0.3867, device='cuda:0') MSE:  tensor(1.4516e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(8.8789e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.3366e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0006, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  235  
Training Loss: 0.012439273297786713
Test Loss:  0.006356768310070038
Test Acc:  0.0
Valid Loss:  0.005741140339523554
Valid Acc:  0.0
std:  7.843885727980903e-05 
thres:  1.2550253793597222e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 24%|██▎       | 235/1000 [10:55<36:31,  2.86s/it]Epoch:   236
max of grad d_p:  tensor(0.0612, device='cuda:0')
min of grad d_p:  tensor(-0.0096, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0347, device='cuda:0') mean:  tensor(-2.4704e-05, device='cuda:0') min:  tensor(-0.0575, device='cuda:0') norm:  tensor(0.3619, device='cuda:0') MSE:  tensor(1.3585e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.6838e-05, device='cuda:0') mean:  tensor(3.3644e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4191e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0006, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  236  
Training Loss: 0.01238183118402958
Test Loss:  0.006296306848526001
Test Acc:  0.0
Valid Loss:  0.005687298718839884
Valid Acc:  0.0
std:  7.846604262972897e-05 
thres:  1.2494125589728354e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 24%|██▎       | 236/1000 [10:58<36:50,  2.89s/it]Epoch:   237
max of grad d_p:  tensor(0.0609, device='cuda:0')
min of grad d_p:  tensor(-0.0095, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0350, device='cuda:0') mean:  tensor(-2.5019e-05, device='cuda:0') min:  tensor(-0.0547, device='cuda:0') norm:  tensor(0.3610, device='cuda:0') MSE:  tensor(1.3549e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.9401e-05, device='cuda:0') mean:  tensor(2.8001e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.2657e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0008, device='cuda:0')
Epoch:  237  
Training Loss: 0.012324882671236992
Test Loss:  0.006236410234123468
Test Acc:  0.0
Valid Loss:  0.005633803084492683
Valid Acc:  0.0
std:  7.912533515660333e-05 
thres:  1.2438019923865795e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 24%|██▎       | 237/1000 [11:01<37:18,  2.93s/it]Epoch:   238
max of grad d_p:  tensor(0.0606, device='cuda:0')
min of grad d_p:  tensor(-0.0095, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0320, device='cuda:0') mean:  tensor(-2.4783e-05, device='cuda:0') min:  tensor(-0.0589, device='cuda:0') norm:  tensor(0.3454, device='cuda:0') MSE:  tensor(1.2966e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.3814e-06, device='cuda:0') min:  tensor(9.0949e-13, device='cuda:0') norm:  tensor(0.0016, device='cuda:0') MSE:  tensor(6.1913e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0006, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  238  
Training Loss: 0.012268838472664356
Test Loss:  0.006176873110234737
Test Acc:  0.0
Valid Loss:  0.0055809058248996735
Valid Acc:  0.0
std:  8.081105261609366e-05 
thres:  1.2382434494793417e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 24%|██▍       | 238/1000 [11:04<37:16,  2.93s/it]Epoch:   239
max of grad d_p:  tensor(0.0603, device='cuda:0')
min of grad d_p:  tensor(-0.0094, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0329, device='cuda:0') mean:  tensor(-2.7182e-05, device='cuda:0') min:  tensor(-0.0617, device='cuda:0') norm:  tensor(0.3656, device='cuda:0') MSE:  tensor(1.3725e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.8174e-05, device='cuda:0') mean:  tensor(4.1308e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8607e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  239  
Training Loss: 0.0122140571475029
Test Loss:  0.006121085025370121
Test Acc:  0.0
Valid Loss:  0.0055306702852249146
Valid Acc:  0.0
std:  7.968387831748972e-05 
thres:  1.2325776554644108e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 24%|██▍       | 239/1000 [11:06<37:12,  2.93s/it]Epoch:   240
max of grad d_p:  tensor(0.0600, device='cuda:0')
min of grad d_p:  tensor(-0.0094, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0323, device='cuda:0') mean:  tensor(-2.5055e-05, device='cuda:0') min:  tensor(-0.0553, device='cuda:0') norm:  tensor(0.3556, device='cuda:0') MSE:  tensor(1.3347e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.2136e-05, device='cuda:0') mean:  tensor(3.9485e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7405e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0005, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  240  
Training Loss: 0.012159053236246109
Test Loss:  0.0060632857494056225
Test Acc:  0.0
Valid Loss:  0.0054793767631053925
Valid Acc:  0.0
std:  7.868684761036074e-05 
thres:  1.2269732542335987e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 24%|██▍       | 240/1000 [11:10<37:31,  2.96s/it]Epoch:   241
max of grad d_p:  tensor(0.0597, device='cuda:0')
min of grad d_p:  tensor(-0.0093, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0327, device='cuda:0') mean:  tensor(-2.8344e-05, device='cuda:0') min:  tensor(-0.0722, device='cuda:0') norm:  tensor(0.3768, device='cuda:0') MSE:  tensor(1.4144e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.5814e-05, device='cuda:0') mean:  tensor(3.2590e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4322e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0025, device='cuda:0')
min of d_p_list:  tensor(-0.0033, device='cuda:0')
Epoch:  241  
Training Loss: 0.012106039561331272
Test Loss:  0.006008301395922899
Test Acc:  0.0
Valid Loss:  0.005428209435194731
Valid Acc:  0.0
std:  7.742762125343802e-05 
thres:  1.2214574217796325e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 24%|██▍       | 241/1000 [11:13<38:35,  3.05s/it]Epoch:   242
max of grad d_p:  tensor(0.0594, device='cuda:0')
min of grad d_p:  tensor(-0.0093, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0349, device='cuda:0') mean:  tensor(-2.5834e-05, device='cuda:0') min:  tensor(-0.0589, device='cuda:0') norm:  tensor(0.3832, device='cuda:0') MSE:  tensor(1.4383e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0023, device='cuda:0') mean:  tensor(1.1208e-05, device='cuda:0') min:  tensor(1.7280e-11, device='cuda:0') norm:  tensor(0.0134, device='cuda:0') MSE:  tensor(5.0202e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0157, device='cuda:0')
min of d_p_list:  tensor(-0.0177, device='cuda:0')
Epoch:  242  
Training Loss: 0.012041157111525536
Test Loss:  0.005923406220972538
Test Acc:  0.0
Valid Loss:  0.005362470634281635
Valid Acc:  0.0
std:  7.972538098369462e-05 
thres:  1.2157829105854034e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 24%|██▍       | 242/1000 [11:16<39:34,  3.13s/it]Epoch:   243
max of grad d_p:  tensor(0.0595, device='cuda:0')
min of grad d_p:  tensor(-0.0093, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0325, device='cuda:0') mean:  tensor(-2.4916e-05, device='cuda:0') min:  tensor(-0.0546, device='cuda:0') norm:  tensor(0.3520, device='cuda:0') MSE:  tensor(1.3215e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.0827e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.8022e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  243  
Training Loss: 0.011987552978098392
Test Loss:  0.005866929888725281
Test Acc:  0.0
Valid Loss:  0.005312676541507244
Valid Acc:  0.0
std:  8.078026508765572e-05 
thres:  1.2101572006940842e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 24%|██▍       | 243/1000 [11:19<39:55,  3.16s/it]Epoch:   244
max of grad d_p:  tensor(0.0592, device='cuda:0')
min of grad d_p:  tensor(-0.0092, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0318, device='cuda:0') mean:  tensor(-2.7087e-05, device='cuda:0') min:  tensor(-0.0570, device='cuda:0') norm:  tensor(0.3696, device='cuda:0') MSE:  tensor(1.3874e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.7400e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.3199e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  244  
Training Loss: 0.011934440582990646
Test Loss:  0.005811448674649
Test Acc:  0.0
Valid Loss:  0.005263566970825195
Valid Acc:  0.0
std:  8.033701205868534e-05 
thres:  1.2045648694038392e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 24%|██▍       | 244/1000 [11:22<39:18,  3.12s/it]Epoch:   245
max of grad d_p:  tensor(0.0589, device='cuda:0')
min of grad d_p:  tensor(-0.0092, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0349, device='cuda:0') mean:  tensor(-2.8173e-05, device='cuda:0') min:  tensor(-0.0553, device='cuda:0') norm:  tensor(0.3780, device='cuda:0') MSE:  tensor(1.4188e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.4829e-05, device='cuda:0') mean:  tensor(3.5928e-07, device='cuda:0') min:  tensor(1.3642e-12, device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7793e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  245  
Training Loss: 0.011882520280778408
Test Loss:  0.005755802616477013
Test Acc:  0.0
Valid Loss:  0.005213869269937277
Valid Acc:  0.0
std:  7.839179990282685e-05 
thres:  1.1990342102944852e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 24%|██▍       | 245/1000 [11:25<38:56,  3.09s/it]Epoch:   246
max of grad d_p:  tensor(0.0586, device='cuda:0')
min of grad d_p:  tensor(-0.0091, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-2.8348e-05, device='cuda:0') min:  tensor(-0.0574, device='cuda:0') norm:  tensor(0.3819, device='cuda:0') MSE:  tensor(1.4335e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(9.7804e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.9710e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  246  
Training Loss: 0.011830242350697517
Test Loss:  0.005699964240193367
Test Acc:  0.0
Valid Loss:  0.0051651219837367535
Valid Acc:  0.0
std:  7.451118033413804e-05 
thres:  1.1935182660818102e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 25%|██▍       | 246/1000 [11:28<38:25,  3.06s/it]Epoch:   247
max of grad d_p:  tensor(0.0583, device='cuda:0')
min of grad d_p:  tensor(-0.0091, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0349, device='cuda:0') mean:  tensor(-2.6606e-05, device='cuda:0') min:  tensor(-0.0557, device='cuda:0') norm:  tensor(0.3630, device='cuda:0') MSE:  tensor(1.3627e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.5707e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8829e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  247  
Training Loss: 0.01177919190376997
Test Loss:  0.005647122859954834
Test Acc:  0.0
Valid Loss:  0.0051167006604373455
Valid Acc:  0.0
std:  7.367083281836156e-05 
thres:  1.1882789619266986e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 25%|██▍       | 247/1000 [11:31<37:20,  2.98s/it]Epoch:   248
max of grad d_p:  tensor(0.0580, device='cuda:0')
min of grad d_p:  tensor(-0.0090, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0336, device='cuda:0') mean:  tensor(-2.5774e-05, device='cuda:0') min:  tensor(-0.0541, device='cuda:0') norm:  tensor(0.3532, device='cuda:0') MSE:  tensor(1.3260e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(2.2657e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0030, device='cuda:0') MSE:  tensor(1.1348e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0089, device='cuda:0')
min of d_p_list:  tensor(-0.0033, device='cuda:0')
Epoch:  248  
Training Loss: 0.011727376841008663
Test Loss:  0.005588441155850887
Test Acc:  0.0
Valid Loss:  0.005056292284280062
Valid Acc:  0.0
std:  7.317978391728304e-05 
thres:  1.1830754391849042e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 25%|██▍       | 248/1000 [11:34<37:19,  2.98s/it]Epoch:   249
max of grad d_p:  tensor(0.0577, device='cuda:0')
min of grad d_p:  tensor(-0.0089, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0364, device='cuda:0') mean:  tensor(-2.7861e-05, device='cuda:0') min:  tensor(-0.0577, device='cuda:0') norm:  tensor(0.3823, device='cuda:0') MSE:  tensor(1.4352e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.4296e-05, device='cuda:0') mean:  tensor(3.5120e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.6013e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0016, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  249  
Training Loss: 0.011676724068820477
Test Loss:  0.0055320849642157555
Test Acc:  0.0
Valid Loss:  0.005008406937122345
Valid Acc:  0.0
std:  7.275624744931105e-05 
thres:  1.1779211089015007e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 25%|██▍       | 249/1000 [11:37<37:02,  2.96s/it]Epoch:   250
max of grad d_p:  tensor(0.0574, device='cuda:0')
min of grad d_p:  tensor(-0.0089, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0351, device='cuda:0') mean:  tensor(-2.8506e-05, device='cuda:0') min:  tensor(-0.0547, device='cuda:0') norm:  tensor(0.3881, device='cuda:0') MSE:  tensor(1.4569e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.4565e-05, device='cuda:0') mean:  tensor(3.9647e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7548e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  250  
Training Loss: 0.011626604944467545
Test Loss:  0.00547878909856081
Test Acc:  0.0
Valid Loss:  0.004961905535310507
Valid Acc:  0.0
std:  7.208976639376809e-05 
thres:  1.1728028021752835e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 25%|██▌       | 250/1000 [11:40<36:34,  2.93s/it]Epoch:   251
max of grad d_p:  tensor(0.0571, device='cuda:0')
min of grad d_p:  tensor(-0.0088, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0313, device='cuda:0') mean:  tensor(-2.7872e-05, device='cuda:0') min:  tensor(-0.0621, device='cuda:0') norm:  tensor(0.3641, device='cuda:0') MSE:  tensor(1.3666e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.9519e-05, device='cuda:0') mean:  tensor(3.2416e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4580e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0017, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  251  
Training Loss: 0.011577725410461426
Test Loss:  0.005427519790828228
Test Acc:  0.0
Valid Loss:  0.0049149408005177975
Valid Acc:  0.0
std:  7.123877735012733e-05 
thres:  1.1677524633705616e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 25%|██▌       | 251/1000 [11:43<36:33,  2.93s/it]Epoch:   252
max of grad d_p:  tensor(0.0568, device='cuda:0')
min of grad d_p:  tensor(-0.0088, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0388, device='cuda:0') mean:  tensor(-2.7603e-05, device='cuda:0') min:  tensor(-0.0505, device='cuda:0') norm:  tensor(0.3771, device='cuda:0') MSE:  tensor(1.4154e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.3724e-05, device='cuda:0') mean:  tensor(3.4294e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4945e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  252  
Training Loss: 0.011528877541422844
Test Loss:  0.0053764646872878075
Test Acc:  0.0
Valid Loss:  0.004869670607149601
Valid Acc:  0.0
std:  7.014711003888911e-05 
thres:  1.162746176123619e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 25%|██▌       | 252/1000 [11:45<35:24,  2.84s/it]Epoch:   253
max of grad d_p:  tensor(0.0565, device='cuda:0')
min of grad d_p:  tensor(-0.0087, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0307, device='cuda:0') mean:  tensor(-2.7542e-05, device='cuda:0') min:  tensor(-0.0595, device='cuda:0') norm:  tensor(0.3757, device='cuda:0') MSE:  tensor(1.4102e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.0616e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0015, device='cuda:0') MSE:  tensor(5.4839e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  253  
Training Loss: 0.011480594985187054
Test Loss:  0.005326834041625261
Test Acc:  0.0
Valid Loss:  0.00482562929391861
Valid Acc:  0.0
std:  6.929596684168052e-05 
thres:  1.157810539007187e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 25%|██▌       | 253/1000 [11:48<35:13,  2.83s/it]Epoch:   254
max of grad d_p:  tensor(0.0563, device='cuda:0')
min of grad d_p:  tensor(-0.0087, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0345, device='cuda:0') mean:  tensor(-2.7457e-05, device='cuda:0') min:  tensor(-0.0595, device='cuda:0') norm:  tensor(0.3844, device='cuda:0') MSE:  tensor(1.4428e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(7.9442e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.4131e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0008, device='cuda:0')
Epoch:  254  
Training Loss: 0.011433098465204239
Test Loss:  0.005276530049741268
Test Acc:  0.0
Valid Loss:  0.0047797574661672115
Valid Acc:  0.0
std:  6.84694568644832e-05 
thres:  1.1529380269348622e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 25%|██▌       | 254/1000 [11:51<34:29,  2.77s/it]Epoch:   255
max of grad d_p:  tensor(0.0560, device='cuda:0')
min of grad d_p:  tensor(-0.0086, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0380, device='cuda:0') mean:  tensor(-2.8507e-05, device='cuda:0') min:  tensor(-0.0595, device='cuda:0') norm:  tensor(0.3873, device='cuda:0') MSE:  tensor(1.4537e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.3786e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.6008e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0004, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  255  
Training Loss: 0.011385596357285976
Test Loss:  0.005226597189903259
Test Acc:  0.0
Valid Loss:  0.00473578367382288
Valid Acc:  0.0
std:  6.788885138753458e-05 
thres:  1.1481178551912307e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 26%|██▌       | 255/1000 [11:54<33:53,  2.73s/it]Epoch:   256
max of grad d_p:  tensor(0.0557, device='cuda:0')
min of grad d_p:  tensor(-0.0086, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0357, device='cuda:0') mean:  tensor(-2.5148e-05, device='cuda:0') min:  tensor(-0.0791, device='cuda:0') norm:  tensor(0.4124, device='cuda:0') MSE:  tensor(1.5481e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(8.5825e-07, device='cuda:0') min:  tensor(2.0464e-12, device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.1332e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  256  
Training Loss: 0.011338332667946815
Test Loss:  0.005177500657737255
Test Acc:  0.0
Valid Loss:  0.004691765643656254
Valid Acc:  0.0
std:  6.732956906150513e-05 
thres:  1.1433300003409387e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 26%|██▌       | 256/1000 [11:56<33:12,  2.68s/it]Epoch:   257
max of grad d_p:  tensor(0.0554, device='cuda:0')
min of grad d_p:  tensor(-0.0085, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0370, device='cuda:0') mean:  tensor(-2.8822e-05, device='cuda:0') min:  tensor(-0.0607, device='cuda:0') norm:  tensor(0.3793, device='cuda:0') MSE:  tensor(1.4239e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.0382e-05, device='cuda:0') mean:  tensor(4.2547e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8370e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0005, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  257  
Training Loss: 0.011292424984276295
Test Loss:  0.0051293689757585526
Test Acc:  0.0
Valid Loss:  0.004649001639336348
Valid Acc:  0.0
std:  6.662596676498766e-05 
thres:  1.1386009491980075e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 26%|██▌       | 257/1000 [11:59<34:13,  2.76s/it]Epoch:   258
max of grad d_p:  tensor(0.0552, device='cuda:0')
min of grad d_p:  tensor(-0.0085, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0365, device='cuda:0') mean:  tensor(-2.9750e-05, device='cuda:0') min:  tensor(-0.0666, device='cuda:0') norm:  tensor(0.3875, device='cuda:0') MSE:  tensor(1.4546e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.2330e-05, device='cuda:0') mean:  tensor(3.3626e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5338e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  258  
Training Loss: 0.011248971335589886
Test Loss:  0.005081831943243742
Test Acc:  0.0
Valid Loss:  0.004604446701705456
Valid Acc:  0.0
std:  6.526597123757347e-05 
thres:  1.1339684762060644e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 26%|██▌       | 258/1000 [12:02<34:40,  2.80s/it]Epoch:   259
max of grad d_p:  tensor(0.0549, device='cuda:0')
min of grad d_p:  tensor(-0.0084, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0343, device='cuda:0') mean:  tensor(-2.6257e-05, device='cuda:0') min:  tensor(-0.0541, device='cuda:0') norm:  tensor(0.3657, device='cuda:0') MSE:  tensor(1.3727e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(7.8969e-07, device='cuda:0') min:  tensor(2.2737e-13, device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.5539e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0032, device='cuda:0')
min of d_p_list:  tensor(-0.0055, device='cuda:0')
Epoch:  259  
Training Loss: 0.011207870207726955
Test Loss:  0.005036721006035805
Test Acc:  0.0
Valid Loss:  0.004563699942082167
Valid Acc:  0.0
std:  6.293113412907257e-05 
thres:  1.1294639110565186e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 26%|██▌       | 259/1000 [12:05<35:28,  2.87s/it]Epoch:   260
max of grad d_p:  tensor(0.0546, device='cuda:0')
min of grad d_p:  tensor(-0.0084, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0380, device='cuda:0') mean:  tensor(-2.8947e-05, device='cuda:0') min:  tensor(-0.0632, device='cuda:0') norm:  tensor(0.3870, device='cuda:0') MSE:  tensor(1.4526e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.9645e-05, device='cuda:0') mean:  tensor(4.4522e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9922e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0008, device='cuda:0')
Epoch:  260  
Training Loss: 0.011163945309817791
Test Loss:  0.004989984445273876
Test Acc:  0.0
Valid Loss:  0.004521651659160852
Valid Acc:  0.0
std:  6.129184230854985e-05 
thres:  1.1250308901071549e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 26%|██▌       | 260/1000 [12:08<34:32,  2.80s/it]Epoch:   261
max of grad d_p:  tensor(0.0544, device='cuda:0')
min of grad d_p:  tensor(-0.0084, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0351, device='cuda:0') mean:  tensor(-2.7351e-05, device='cuda:0') min:  tensor(-0.0581, device='cuda:0') norm:  tensor(0.3704, device='cuda:0') MSE:  tensor(1.3905e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.0861e-05, device='cuda:0') mean:  tensor(3.7173e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7260e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0006, device='cuda:0')
min of d_p_list:  tensor(-0.0009, device='cuda:0')
Epoch:  261  
Training Loss: 0.011119212955236435
Test Loss:  0.0049424744211137295
Test Acc:  0.0
Valid Loss:  0.004479589872062206
Valid Acc:  0.0
std:  6.1022493308150594e-05 
thres:  1.1206484958529473e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 26%|██▌       | 261/1000 [12:10<34:04,  2.77s/it]Epoch:   262
max of grad d_p:  tensor(0.0541, device='cuda:0')
min of grad d_p:  tensor(-0.0083, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0286, device='cuda:0') mean:  tensor(-2.4784e-05, device='cuda:0') min:  tensor(-0.0502, device='cuda:0') norm:  tensor(0.3384, device='cuda:0') MSE:  tensor(1.2702e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.3866e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0016, device='cuda:0') MSE:  tensor(6.1452e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  262  
Training Loss: 0.011075129732489586
Test Loss:  0.0048959823325276375
Test Acc:  0.0
Valid Loss:  0.004438027739524841
Valid Acc:  0.0
std:  6.17151286809511e-05 
thres:  1.116302590817213e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 26%|██▌       | 262/1000 [12:13<33:14,  2.70s/it]Epoch:   263
max of grad d_p:  tensor(0.0538, device='cuda:0')
min of grad d_p:  tensor(-0.0083, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0349, device='cuda:0') mean:  tensor(-2.8055e-05, device='cuda:0') min:  tensor(-0.0623, device='cuda:0') norm:  tensor(0.4152, device='cuda:0') MSE:  tensor(1.5587e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.2348e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(3.0178e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  263  
Training Loss: 0.011030934751033783
Test Loss:  0.004848995711654425
Test Acc:  0.0
Valid Loss:  0.004397674463689327
Valid Acc:  0.0
std:  6.260551477255129e-05 
thres:  1.1119418591260912e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 26%|██▋       | 263/1000 [12:16<33:10,  2.70s/it]Epoch:   264
max of grad d_p:  tensor(0.0535, device='cuda:0')
min of grad d_p:  tensor(-0.0082, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0321, device='cuda:0') mean:  tensor(-2.6543e-05, device='cuda:0') min:  tensor(-0.0566, device='cuda:0') norm:  tensor(0.3791, device='cuda:0') MSE:  tensor(1.4229e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.0542e-05, device='cuda:0') mean:  tensor(4.2296e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9185e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  264  
Training Loss: 0.010987578891217709
Test Loss:  0.004804439377039671
Test Acc:  0.0
Valid Loss:  0.004358316771686077
Valid Acc:  0.0
std:  6.236925143984045e-05 
thres:  1.1075360327959061e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 26%|██▋       | 264/1000 [12:18<33:36,  2.74s/it]Epoch:   265
max of grad d_p:  tensor(0.0533, device='cuda:0')
min of grad d_p:  tensor(-0.0082, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0320, device='cuda:0') mean:  tensor(-2.5298e-05, device='cuda:0') min:  tensor(-0.0527, device='cuda:0') norm:  tensor(0.3657, device='cuda:0') MSE:  tensor(1.3726e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.0047e-05, device='cuda:0') mean:  tensor(3.6470e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.6230e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0056, device='cuda:0')
min of d_p_list:  tensor(-0.0037, device='cuda:0')
Epoch:  265  
Training Loss: 0.010947641916573048
Test Loss:  0.004763664677739143
Test Acc:  0.0
Valid Loss:  0.004316302947700024
Valid Acc:  0.0
std:  6.092106308338268e-05 
thres:  1.1032099649310114e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 26%|██▋       | 265/1000 [12:21<33:31,  2.74s/it]Epoch:   266
max of grad d_p:  tensor(0.0530, device='cuda:0')
min of grad d_p:  tensor(-0.0081, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0404, device='cuda:0') mean:  tensor(-2.8988e-05, device='cuda:0') min:  tensor(-0.0581, device='cuda:0') norm:  tensor(0.4163, device='cuda:0') MSE:  tensor(1.5627e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.2225e-05, device='cuda:0') mean:  tensor(3.6783e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.6379e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0038, device='cuda:0')
min of d_p_list:  tensor(-0.0045, device='cuda:0')
Epoch:  266  
Training Loss: 0.010906346142292023
Test Loss:  0.004719375167042017
Test Acc:  0.0
Valid Loss:  0.0042746723629534245
Valid Acc:  0.0
std:  5.953089967968011e-05 
thres:  1.098952628672123e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 27%|██▋       | 266/1000 [12:24<33:33,  2.74s/it]Epoch:   267
max of grad d_p:  tensor(0.0527, device='cuda:0')
min of grad d_p:  tensor(-0.0081, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0295, device='cuda:0') mean:  tensor(-2.5691e-05, device='cuda:0') min:  tensor(-0.0552, device='cuda:0') norm:  tensor(0.3603, device='cuda:0') MSE:  tensor(1.3523e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.6346e-05, device='cuda:0') mean:  tensor(2.9304e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.3680e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  267  
Training Loss: 0.010863806121051311
Test Loss:  0.004674468655139208
Test Acc:  0.0
Valid Loss:  0.0042367372661828995
Valid Acc:  0.0
std:  5.876345201186441e-05 
thres:  1.0947261564433575e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 27%|██▋       | 267/1000 [12:27<33:58,  2.78s/it]Epoch:   268
max of grad d_p:  tensor(0.0525, device='cuda:0')
min of grad d_p:  tensor(-0.0080, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0339, device='cuda:0') mean:  tensor(-2.6373e-05, device='cuda:0') min:  tensor(-0.0652, device='cuda:0') norm:  tensor(0.3745, device='cuda:0') MSE:  tensor(1.4058e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.9601e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.3169e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0004, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  268  
Training Loss: 0.010822266340255737
Test Loss:  0.004630872514098883
Test Acc:  0.0
Valid Loss:  0.004198048263788223
Valid Acc:  0.0
std:  5.8617095188794474e-05 
thres:  1.0905527882277966e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 27%|██▋       | 268/1000 [12:29<33:46,  2.77s/it]Epoch:   269
max of grad d_p:  tensor(0.0522, device='cuda:0')
min of grad d_p:  tensor(-0.0080, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0322, device='cuda:0') mean:  tensor(-2.5558e-05, device='cuda:0') min:  tensor(-0.0537, device='cuda:0') norm:  tensor(0.3723, device='cuda:0') MSE:  tensor(1.3976e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.2548e-05, device='cuda:0') mean:  tensor(3.9150e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8817e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0039, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  269  
Training Loss: 0.01078002154827118
Test Loss:  0.004588961601257324
Test Acc:  0.0
Valid Loss:  0.004161202348768711
Valid Acc:  0.0
std:  5.9301401210173e-05 
thres:  1.086401641368866e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 27%|██▋       | 269/1000 [12:32<33:21,  2.74s/it]Epoch:   270
max of grad d_p:  tensor(0.0520, device='cuda:0')
min of grad d_p:  tensor(-0.0079, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0318, device='cuda:0') mean:  tensor(-2.6273e-05, device='cuda:0') min:  tensor(-0.0540, device='cuda:0') norm:  tensor(0.3802, device='cuda:0') MSE:  tensor(1.4270e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.0835e-05, device='cuda:0') mean:  tensor(4.2285e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(2.0339e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  270  
Training Loss: 0.010739991441369057
Test Loss:  0.004547403194010258
Test Acc:  0.0
Valid Loss:  0.004121772479265928
Valid Acc:  0.0
std:  5.890416960313148e-05 
thres:  1.082248631864786e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 27%|██▋       | 270/1000 [12:35<33:35,  2.76s/it]Epoch:   271
max of grad d_p:  tensor(0.0517, device='cuda:0')
min of grad d_p:  tensor(-0.0079, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0357, device='cuda:0') mean:  tensor(-2.9176e-05, device='cuda:0') min:  tensor(-0.0641, device='cuda:0') norm:  tensor(0.4222, device='cuda:0') MSE:  tensor(1.5848e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.6003e-05, device='cuda:0') mean:  tensor(4.2367e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8200e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0003, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  271  
Training Loss: 0.010699547827243805
Test Loss:  0.004504885990172625
Test Acc:  0.0
Valid Loss:  0.0040838345885276794
Valid Acc:  0.0
std:  5.809784851247328e-05 
thres:  1.0781126655638218e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 27%|██▋       | 271/1000 [12:38<33:24,  2.75s/it]Epoch:   272
max of grad d_p:  tensor(0.0514, device='cuda:0')
min of grad d_p:  tensor(-0.0078, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0396, device='cuda:0') mean:  tensor(-2.8189e-05, device='cuda:0') min:  tensor(-0.0605, device='cuda:0') norm:  tensor(0.4077, device='cuda:0') MSE:  tensor(1.5303e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(7.9693e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.7064e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0007, device='cuda:0')
min of d_p_list:  tensor(-0.0007, device='cuda:0')
Epoch:  272  
Training Loss: 0.010659478604793549
Test Loss:  0.004462486132979393
Test Acc:  0.0
Valid Loss:  0.004046294838190079
Valid Acc:  0.0
std:  5.7426836065014965e-05 
thres:  1.0740261152386665e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 27%|██▋       | 272/1000 [12:40<32:48,  2.70s/it]Epoch:   273
max of grad d_p:  tensor(0.0512, device='cuda:0')
min of grad d_p:  tensor(-0.0078, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0348, device='cuda:0') mean:  tensor(-2.6647e-05, device='cuda:0') min:  tensor(-0.0543, device='cuda:0') norm:  tensor(0.3812, device='cuda:0') MSE:  tensor(1.4309e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.9812e-05, device='cuda:0') mean:  tensor(7.1492e-07, device='cuda:0') min:  tensor(2.2737e-12, device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(3.0788e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0007, device='cuda:0')
Epoch:  273  
Training Loss: 0.01062060333788395
Test Loss:  0.00442119874060154
Test Acc:  0.0
Valid Loss:  0.0040091536939144135
Valid Acc:  0.0
std:  5.647788227473544e-05 
thres:  1.0699928551912308e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 27%|██▋       | 273/1000 [12:43<33:12,  2.74s/it]Epoch:   274
max of grad d_p:  tensor(0.0509, device='cuda:0')
min of grad d_p:  tensor(-0.0077, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0354, device='cuda:0') mean:  tensor(-2.8380e-05, device='cuda:0') min:  tensor(-0.0656, device='cuda:0') norm:  tensor(0.3845, device='cuda:0') MSE:  tensor(1.4434e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.1747e-05, device='cuda:0') mean:  tensor(6.1813e-07, device='cuda:0') min:  tensor(1.3074e-12, device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.6103e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0016, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  274  
Training Loss: 0.01058148592710495
Test Loss:  0.004378840327262878
Test Acc:  0.0
Valid Loss:  0.003972068428993225
Valid Acc:  0.0
std:  5.599865116649974e-05 
thres:  1.0660221427679062e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 27%|██▋       | 274/1000 [12:46<32:45,  2.71s/it]Epoch:   275
max of grad d_p:  tensor(0.0507, device='cuda:0')
min of grad d_p:  tensor(-0.0077, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0391, device='cuda:0') mean:  tensor(-2.8214e-05, device='cuda:0') min:  tensor(-0.0646, device='cuda:0') norm:  tensor(0.3966, device='cuda:0') MSE:  tensor(1.4889e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.1242e-05, device='cuda:0') mean:  tensor(3.4285e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4327e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0832, device='cuda:0')
min of d_p_list:  tensor(-0.0683, device='cuda:0')
Epoch:  275  
Training Loss: 0.01078223530203104
Test Loss:  0.004480354022234678
Test Acc:  0.0
Valid Loss:  0.00421301182359457
Valid Acc:  0.0
std:  6.906007002586833e-05 
thres:  1.0668670199811458e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 28%|██▊       | 275/1000 [12:48<32:16,  2.67s/it]Epoch:   276
max of grad d_p:  tensor(0.0464, device='cuda:0')
min of grad d_p:  tensor(-0.0086, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0311, device='cuda:0') mean:  tensor(-2.7141e-05, device='cuda:0') min:  tensor(-0.0582, device='cuda:0') norm:  tensor(0.3633, device='cuda:0') MSE:  tensor(1.3638e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.9790e-05, device='cuda:0') mean:  tensor(4.2468e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8725e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0006, device='cuda:0')
min of d_p_list:  tensor(-0.0009, device='cuda:0')
Epoch:  276  
Training Loss: 0.010742176324129105
Test Loss:  0.0044386484660208225
Test Acc:  0.0
Valid Loss:  0.004175114911049604
Valid Acc:  0.0
std:  7.474322851857502e-05 
thres:  1.067719589918852e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 28%|██▊       | 276/1000 [12:51<32:35,  2.70s/it]Epoch:   277
max of grad d_p:  tensor(0.0461, device='cuda:0')
min of grad d_p:  tensor(-0.0085, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0374, device='cuda:0') mean:  tensor(-2.8192e-05, device='cuda:0') min:  tensor(-0.0581, device='cuda:0') norm:  tensor(0.3955, device='cuda:0') MSE:  tensor(1.4846e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.2723e-05, device='cuda:0') mean:  tensor(4.4891e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.0970e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  277  
Training Loss: 0.010701705701649189
Test Loss:  0.00439629377797246
Test Acc:  0.0
Valid Loss:  0.0041373614221811295
Valid Acc:  0.0
std:  7.464978687325444e-05 
thres:  1.0685641318559647e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 28%|██▊       | 277/1000 [12:54<32:27,  2.69s/it]Epoch:   278
max of grad d_p:  tensor(0.0459, device='cuda:0')
min of grad d_p:  tensor(-0.0085, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0385, device='cuda:0') mean:  tensor(-2.8020e-05, device='cuda:0') min:  tensor(-0.0525, device='cuda:0') norm:  tensor(0.3910, device='cuda:0') MSE:  tensor(1.4676e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.1381e-05, device='cuda:0') mean:  tensor(4.4429e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(2.0021e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0005, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  278  
Training Loss: 0.010661827400326729
Test Loss:  0.004355297423899174
Test Acc:  0.0
Valid Loss:  0.004099631682038307
Valid Acc:  0.0
std:  6.908000073463525e-05 
thres:  1.0693886131048204e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 28%|██▊       | 278/1000 [12:56<32:16,  2.68s/it]Epoch:   279
max of grad d_p:  tensor(0.0457, device='cuda:0')
min of grad d_p:  tensor(-0.0084, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0349, device='cuda:0') mean:  tensor(-2.7444e-05, device='cuda:0') min:  tensor(-0.0527, device='cuda:0') norm:  tensor(0.3571, device='cuda:0') MSE:  tensor(1.3406e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(4.9756e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.6735e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0063, device='cuda:0')
min of d_p_list:  tensor(-0.0045, device='cuda:0')
Epoch:  279  
Training Loss: 0.010630697011947632
Test Loss:  0.004326843656599522
Test Acc:  0.0
Valid Loss:  0.004072904586791992
Valid Acc:  0.0
std:  5.428617735561907e-05 
thres:  1.070372834801674e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 28%|██▊       | 279/1000 [12:59<33:01,  2.75s/it]Epoch:   280
max of grad d_p:  tensor(0.0456, device='cuda:0')
min of grad d_p:  tensor(-0.0084, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0411, device='cuda:0') mean:  tensor(-3.0839e-05, device='cuda:0') min:  tensor(-0.0667, device='cuda:0') norm:  tensor(0.4341, device='cuda:0') MSE:  tensor(1.6297e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.4681e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7162e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  280  
Training Loss: 0.010591202415525913
Test Loss:  0.004285669885575771
Test Acc:  0.0
Valid Loss:  0.004036128520965576
Valid Acc:  0.0
std:  5.279199971294653e-05 
thres:  1.0665521770715715e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 28%|██▊       | 280/1000 [13:02<32:29,  2.71s/it]Epoch:   281
max of grad d_p:  tensor(0.0454, device='cuda:0')
min of grad d_p:  tensor(-0.0084, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0361, device='cuda:0') mean:  tensor(-2.7976e-05, device='cuda:0') min:  tensor(-0.0489, device='cuda:0') norm:  tensor(0.3562, device='cuda:0') MSE:  tensor(1.3370e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.3433e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0016, device='cuda:0') MSE:  tensor(6.1826e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0029, device='cuda:0')
min of d_p_list:  tensor(-0.0058, device='cuda:0')
Epoch:  281  
Training Loss: 0.010555443353950977
Test Loss:  0.004252910614013672
Test Acc:  0.0
Valid Loss:  0.004013395868241787
Valid Acc:  0.0
std:  5.138574319122801e-05 
thres:  1.0628175176680088e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 28%|██▊       | 281/1000 [13:05<33:49,  2.82s/it]Epoch:   282
max of grad d_p:  tensor(0.0452, device='cuda:0')
min of grad d_p:  tensor(-0.0083, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-2.6815e-05, device='cuda:0') min:  tensor(-0.0680, device='cuda:0') norm:  tensor(0.3929, device='cuda:0') MSE:  tensor(1.4750e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.4802e-07, device='cuda:0') min:  tensor(6.8212e-13, device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.6958e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  282  
Training Loss: 0.010515855625271797
Test Loss:  0.004213385283946991
Test Acc:  0.0
Valid Loss:  0.003976848442107439
Valid Acc:  0.0
std:  5.196800239571619e-05 
thres:  1.059100516140461e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 28%|██▊       | 282/1000 [13:08<34:23,  2.87s/it]Epoch:   283
max of grad d_p:  tensor(0.0449, device='cuda:0')
min of grad d_p:  tensor(-0.0083, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0329, device='cuda:0') mean:  tensor(-2.6633e-05, device='cuda:0') min:  tensor(-0.0490, device='cuda:0') norm:  tensor(0.3495, device='cuda:0') MSE:  tensor(1.3120e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(8.8476e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.3427e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  283  
Training Loss: 0.010478016920387745
Test Loss:  0.004174079746007919
Test Acc:  0.0
Valid Loss:  0.003940938040614128
Valid Acc:  0.0
std:  5.384544723571213e-05 
thres:  1.0554243065416813e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 28%|██▊       | 283/1000 [13:11<34:40,  2.90s/it]Epoch:   284
max of grad d_p:  tensor(0.0447, device='cuda:0')
min of grad d_p:  tensor(-0.0082, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0360, device='cuda:0') mean:  tensor(-2.6955e-05, device='cuda:0') min:  tensor(-0.0627, device='cuda:0') norm:  tensor(0.3861, device='cuda:0') MSE:  tensor(1.4491e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.8627e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.8105e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  284  
Training Loss: 0.010440932586789131
Test Loss:  0.004134895280003548
Test Acc:  0.0
Valid Loss:  0.003905731253325939
Valid Acc:  0.0
std:  5.345766952574542e-05 
thres:  1.0516290180385113e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 28%|██▊       | 284/1000 [13:14<35:02,  2.94s/it]Epoch:   285
max of grad d_p:  tensor(0.0445, device='cuda:0')
min of grad d_p:  tensor(-0.0082, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0397, device='cuda:0') mean:  tensor(-2.9894e-05, device='cuda:0') min:  tensor(-0.0442, device='cuda:0') norm:  tensor(0.3809, device='cuda:0') MSE:  tensor(1.4299e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.0337e-05, device='cuda:0') mean:  tensor(3.6057e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7773e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0038, device='cuda:0')
min of d_p_list:  tensor(-0.0034, device='cuda:0')
Epoch:  285  
Training Loss: 0.010403570719063282
Test Loss:  0.004093775525689125
Test Acc:  0.0
Valid Loss:  0.003867252729833126
Valid Acc:  0.0
std:  5.35561675981827e-05 
thres:  1.0478763841092587e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 28%|██▊       | 285/1000 [13:17<34:20,  2.88s/it]Epoch:   286
max of grad d_p:  tensor(0.0443, device='cuda:0')
min of grad d_p:  tensor(-0.0081, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-2.9399e-05, device='cuda:0') min:  tensor(-0.0499, device='cuda:0') norm:  tensor(0.3811, device='cuda:0') MSE:  tensor(1.4304e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.4689e-05, device='cuda:0') mean:  tensor(4.7074e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.0793e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0045, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  286  
Training Loss: 0.010367141105234623
Test Loss:  0.004053207580000162
Test Acc:  0.0
Valid Loss:  0.0038303453475236893
Valid Acc:  0.0
std:  5.259212019478317e-05 
thres:  1.0441103391349316e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 29%|██▊       | 286/1000 [13:20<35:15,  2.96s/it]Epoch:   287
max of grad d_p:  tensor(0.0441, device='cuda:0')
min of grad d_p:  tensor(-0.0081, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0384, device='cuda:0') mean:  tensor(-3.2806e-05, device='cuda:0') min:  tensor(-0.0570, device='cuda:0') norm:  tensor(0.4086, device='cuda:0') MSE:  tensor(1.5339e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.6377e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(3.1424e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0007, device='cuda:0')
min of d_p_list:  tensor(-0.0005, device='cuda:0')
Epoch:  287  
Training Loss: 0.0103302001953125
Test Loss:  0.004014979116618633
Test Acc:  0.0
Valid Loss:  0.0037954850122332573
Valid Acc:  0.0
std:  5.224498102787915e-05 
thres:  1.0403972305357455e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 29%|██▊       | 287/1000 [13:23<35:28,  2.99s/it]Epoch:   288
max of grad d_p:  tensor(0.0439, device='cuda:0')
min of grad d_p:  tensor(-0.0081, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0394, device='cuda:0') mean:  tensor(-3.0911e-05, device='cuda:0') min:  tensor(-0.0472, device='cuda:0') norm:  tensor(0.3964, device='cuda:0') MSE:  tensor(1.4879e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(4.7081e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.3261e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  288  
Training Loss: 0.010294951498508453
Test Loss:  0.0039778659120202065
Test Acc:  0.0
Valid Loss:  0.0037625145632773638
Valid Acc:  0.0
std:  5.166823354145677e-05 
thres:  1.0367359220981597e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 29%|██▉       | 288/1000 [13:26<36:01,  3.04s/it]Epoch:   289
max of grad d_p:  tensor(0.0437, device='cuda:0')
min of grad d_p:  tensor(-0.0080, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0390, device='cuda:0') mean:  tensor(-2.7135e-05, device='cuda:0') min:  tensor(-0.0611, device='cuda:0') norm:  tensor(0.3887, device='cuda:0') MSE:  tensor(1.4590e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.1099e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(2.0095e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  289  
Training Loss: 0.010258335620164871
Test Loss:  0.003940907306969166
Test Acc:  0.0
Valid Loss:  0.003727932460606098
Valid Acc:  0.0
std:  5.128899827680832e-05 
thres:  1.0330839827656746e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 29%|██▉       | 289/1000 [13:29<35:51,  3.03s/it]Epoch:   290
max of grad d_p:  tensor(0.0434, device='cuda:0')
min of grad d_p:  tensor(-0.0080, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0385, device='cuda:0') mean:  tensor(-2.9010e-05, device='cuda:0') min:  tensor(-0.0470, device='cuda:0') norm:  tensor(0.3789, device='cuda:0') MSE:  tensor(1.4221e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.3061e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.4270e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0051, device='cuda:0')
min of d_p_list:  tensor(-0.0038, device='cuda:0')
Epoch:  290  
Training Loss: 0.010232517495751381
Test Loss:  0.003911363426595926
Test Acc:  0.0
Valid Loss:  0.003702085465192795
Valid Acc:  0.0
std:  4.832900592115137e-05 
thres:  1.0296629182994367e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 29%|██▉       | 290/1000 [13:32<36:05,  3.05s/it]Epoch:   291
max of grad d_p:  tensor(0.0433, device='cuda:0')
min of grad d_p:  tensor(-0.0079, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0367, device='cuda:0') mean:  tensor(-2.7369e-05, device='cuda:0') min:  tensor(-0.0443, device='cuda:0') norm:  tensor(0.3567, device='cuda:0') MSE:  tensor(1.3390e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.8794e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2138e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0036, device='cuda:0')
Epoch:  291  
Training Loss: 0.010195713490247726
Test Loss:  0.0038746821228414774
Test Acc:  0.0
Valid Loss:  0.003670394653454423
Valid Acc:  0.0
std:  4.693191770028646e-05 
thres:  1.0262343659996986e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 29%|██▉       | 291/1000 [13:35<35:27,  3.00s/it]Epoch:   292
max of grad d_p:  tensor(0.0431, device='cuda:0')
min of grad d_p:  tensor(-0.0079, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0358, device='cuda:0') mean:  tensor(-2.6990e-05, device='cuda:0') min:  tensor(-0.0618, device='cuda:0') norm:  tensor(0.3812, device='cuda:0') MSE:  tensor(1.4308e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.1511e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(2.0412e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0020, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  292  
Training Loss: 0.010161012411117554
Test Loss:  0.003838048782199621
Test Acc:  0.0
Valid Loss:  0.003637184388935566
Valid Acc:  0.0
std:  4.680093128435191e-05 
thres:  1.0228506103157998e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 29%|██▉       | 292/1000 [13:38<35:47,  3.03s/it]Epoch:   293
max of grad d_p:  tensor(0.0429, device='cuda:0')
min of grad d_p:  tensor(-0.0079, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0406, device='cuda:0') mean:  tensor(-3.0502e-05, device='cuda:0') min:  tensor(-0.0507, device='cuda:0') norm:  tensor(0.3939, device='cuda:0') MSE:  tensor(1.4785e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(9.1811e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.7754e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0009, device='cuda:0')
Epoch:  293  
Training Loss: 0.010126220993697643
Test Loss:  0.0038020596839487553
Test Acc:  0.0
Valid Loss:  0.003604683093726635
Valid Acc:  0.0
std:  4.754974710491975e-05 
thres:  1.0194760002195835e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 29%|██▉       | 293/1000 [13:41<35:23,  3.00s/it]Epoch:   294
max of grad d_p:  tensor(0.0427, device='cuda:0')
min of grad d_p:  tensor(-0.0078, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0424, device='cuda:0') mean:  tensor(-2.7081e-05, device='cuda:0') min:  tensor(-0.0670, device='cuda:0') norm:  tensor(0.3919, device='cuda:0') MSE:  tensor(1.4711e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.9586e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.4282e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0055, device='cuda:0')
Epoch:  294  
Training Loss: 0.010092447511851788
Test Loss:  0.0037678552325814962
Test Acc:  0.0
Valid Loss:  0.0035760398022830486
Valid Acc:  0.0
std:  4.945119985000656e-05 
thres:  1.016158238053322e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 29%|██▉       | 294/1000 [13:44<34:36,  2.94s/it]Epoch:   295
max of grad d_p:  tensor(0.0425, device='cuda:0')
min of grad d_p:  tensor(-0.0078, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0386, device='cuda:0') mean:  tensor(-2.8170e-05, device='cuda:0') min:  tensor(-0.0576, device='cuda:0') norm:  tensor(0.4054, device='cuda:0') MSE:  tensor(1.5219e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.0073e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2813e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  295  
Training Loss: 0.010057875886559486
Test Loss:  0.0037317024543881416
Test Acc:  0.0
Valid Loss:  0.0035457483027130365
Valid Acc:  0.0
std:  4.8683495811433415e-05 
thres:  1.012665405869484e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 30%|██▉       | 295/1000 [13:47<34:34,  2.94s/it]Epoch:   296
max of grad d_p:  tensor(0.0423, device='cuda:0')
min of grad d_p:  tensor(-0.0077, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0444, device='cuda:0') mean:  tensor(-3.0967e-05, device='cuda:0') min:  tensor(-0.0531, device='cuda:0') norm:  tensor(0.4095, device='cuda:0') MSE:  tensor(1.5372e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(8.8685e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.8852e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0006, device='cuda:0')
Epoch:  296  
Training Loss: 0.010023567825555801
Test Loss:  0.0036966868210583925
Test Acc:  0.0
Valid Loss:  0.003513960400596261
Valid Acc:  0.0
std:  4.854102228847796e-05 
thres:  1.0092224925756454e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 30%|██▉       | 296/1000 [13:50<34:43,  2.96s/it]Epoch:   297
max of grad d_p:  tensor(0.0420, device='cuda:0')
min of grad d_p:  tensor(-0.0077, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0392, device='cuda:0') mean:  tensor(-2.8594e-05, device='cuda:0') min:  tensor(-0.0531, device='cuda:0') norm:  tensor(0.3971, device='cuda:0') MSE:  tensor(1.4906e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.2663e-06, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0016, device='cuda:0') MSE:  tensor(5.8420e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0004, device='cuda:0')
min of d_p_list:  tensor(-0.0006, device='cuda:0')
Epoch:  297  
Training Loss: 0.009990357793867588
Test Loss:  0.0036619394086301327
Test Acc:  0.0
Valid Loss:  0.003482311964035034
Valid Acc:  0.0
std:  4.817000926565487e-05 
thres:  1.005809400230646e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 30%|██▉       | 297/1000 [13:53<34:39,  2.96s/it]Epoch:   298
max of grad d_p:  tensor(0.0418, device='cuda:0')
min of grad d_p:  tensor(-0.0077, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0361, device='cuda:0') mean:  tensor(-2.8777e-05, device='cuda:0') min:  tensor(-0.0645, device='cuda:0') norm:  tensor(0.3831, device='cuda:0') MSE:  tensor(1.4381e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.2732e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0015, device='cuda:0') MSE:  tensor(5.6556e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0029, device='cuda:0')
Epoch:  298  
Training Loss: 0.009958080016076565
Test Loss:  0.003627168945968151
Test Acc:  0.0
Valid Loss:  0.0034526085946708918
Valid Acc:  0.0
std:  4.755834685472515e-05 
thres:  1.0024465806782244e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 30%|██▉       | 298/1000 [13:55<33:31,  2.87s/it]Epoch:   299
max of grad d_p:  tensor(0.0416, device='cuda:0')
min of grad d_p:  tensor(-0.0076, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0399, device='cuda:0') mean:  tensor(-3.0192e-05, device='cuda:0') min:  tensor(-0.0543, device='cuda:0') norm:  tensor(0.4022, device='cuda:0') MSE:  tensor(1.5097e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(4.6182e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.3612e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0006, device='cuda:0')
min of d_p_list:  tensor(-0.0008, device='cuda:0')
Epoch:  299  
Training Loss: 0.009925495833158493
Test Loss:  0.00359335751272738
Test Acc:  0.0
Valid Loss:  0.0034216030035167933
Valid Acc:  0.0
std:  4.670749967402242e-05 
thres:  9.991075471043587e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 30%|██▉       | 299/1000 [13:58<33:06,  2.83s/it]Epoch:   300
max of grad d_p:  tensor(0.0414, device='cuda:0')
min of grad d_p:  tensor(-0.0076, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0380, device='cuda:0') mean:  tensor(-2.8626e-05, device='cuda:0') min:  tensor(-0.0663, device='cuda:0') norm:  tensor(0.4021, device='cuda:0') MSE:  tensor(1.5095e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.3117e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.4141e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  300  
Training Loss: 0.009892307221889496
Test Loss:  0.0035587649326771498
Test Acc:  0.0
Valid Loss:  0.003392530605196953
Valid Acc:  0.0
std:  4.6299519679454544e-05 
thres:  9.95796173810959e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 30%|███       | 300/1000 [14:01<33:08,  2.84s/it]Epoch:   301
max of grad d_p:  tensor(0.0412, device='cuda:0')
min of grad d_p:  tensor(-0.0076, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0400, device='cuda:0') mean:  tensor(-3.1884e-05, device='cuda:0') min:  tensor(-0.0510, device='cuda:0') norm:  tensor(0.3967, device='cuda:0') MSE:  tensor(1.4891e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.5469e-05, device='cuda:0') mean:  tensor(4.5086e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.0957e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0006, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  301  
Training Loss: 0.009860634803771973
Test Loss:  0.0035260936710983515
Test Acc:  0.0
Valid Loss:  0.0033619417808949947
Valid Acc:  0.0
std:  4.599384118070063e-05 
thres:  9.925375133752823e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 30%|███       | 301/1000 [14:04<32:27,  2.79s/it]Epoch:   302
max of grad d_p:  tensor(0.0410, device='cuda:0')
min of grad d_p:  tensor(-0.0075, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0426, device='cuda:0') mean:  tensor(-3.0495e-05, device='cuda:0') min:  tensor(-0.0511, device='cuda:0') norm:  tensor(0.4074, device='cuda:0') MSE:  tensor(1.5294e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.0293e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0014, device='cuda:0') MSE:  tensor(5.3373e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  302  
Training Loss: 0.009828993119299412
Test Loss:  0.003493699710816145
Test Acc:  0.0
Valid Loss:  0.0033328994177281857
Valid Acc:  0.0
std:  4.568632637362154e-05 
thres:  9.893102198839188e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 30%|███       | 302/1000 [14:07<32:42,  2.81s/it]Epoch:   303
max of grad d_p:  tensor(0.0408, device='cuda:0')
min of grad d_p:  tensor(-0.0075, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0404, device='cuda:0') mean:  tensor(-3.0692e-05, device='cuda:0') min:  tensor(-0.0564, device='cuda:0') norm:  tensor(0.4030, device='cuda:0') MSE:  tensor(1.5127e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.2410e-06, device='cuda:0') min:  tensor(1.2506e-12, device='cuda:0') norm:  tensor(0.0015, device='cuda:0') MSE:  tensor(5.4812e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0053, device='cuda:0')
min of d_p_list:  tensor(-0.0045, device='cuda:0')
Epoch:  303  
Training Loss: 0.00979664921760559
Test Loss:  0.003461673855781555
Test Acc:  0.0
Valid Loss:  0.003300950862467289
Valid Acc:  0.0
std:  4.5398859907501374e-05 
thres:  9.860816039144993e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 30%|███       | 303/1000 [14:09<32:27,  2.79s/it]Epoch:   304
max of grad d_p:  tensor(0.0406, device='cuda:0')
min of grad d_p:  tensor(-0.0074, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0401, device='cuda:0') mean:  tensor(-2.9228e-05, device='cuda:0') min:  tensor(-0.0569, device='cuda:0') norm:  tensor(0.3930, device='cuda:0') MSE:  tensor(1.4751e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.3234e-05, device='cuda:0') mean:  tensor(3.9935e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8072e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0018, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  304  
Training Loss: 0.009763868525624275
Test Loss:  0.003430087585002184
Test Acc:  0.0
Valid Loss:  0.0032733685802668333
Valid Acc:  0.0
std:  4.537829816238917e-05 
thres:  9.82849057763815e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 30%|███       | 304/1000 [14:12<33:32,  2.89s/it]Epoch:   305
max of grad d_p:  tensor(0.0405, device='cuda:0')
min of grad d_p:  tensor(-0.0074, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0434, device='cuda:0') mean:  tensor(-2.9661e-05, device='cuda:0') min:  tensor(-0.0511, device='cuda:0') norm:  tensor(0.4051, device='cuda:0') MSE:  tensor(1.5206e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.2645e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.0877e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0045, device='cuda:0')
min of d_p_list:  tensor(-0.0037, device='cuda:0')
Epoch:  305  
Training Loss: 0.009736279025673866
Test Loss:  0.003400554182007909
Test Acc:  0.0
Valid Loss:  0.0032495169434696436
Valid Acc:  0.0
std:  4.440134311002674e-05 
thres:  9.797284938395024e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 30%|███       | 305/1000 [14:15<33:33,  2.90s/it]Epoch:   306
max of grad d_p:  tensor(0.0404, device='cuda:0')
min of grad d_p:  tensor(-0.0074, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0394, device='cuda:0') mean:  tensor(-2.8818e-05, device='cuda:0') min:  tensor(-0.0603, device='cuda:0') norm:  tensor(0.3932, device='cuda:0') MSE:  tensor(1.4759e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0022, device='cuda:0') mean:  tensor(4.6444e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0070, device='cuda:0') MSE:  tensor(2.6300e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0009, device='cuda:0')
Epoch:  306  
Training Loss: 0.009705639444291592
Test Loss:  0.003367875935509801
Test Acc:  0.0
Valid Loss:  0.0032196100801229477
Valid Acc:  0.0
std:  4.344738243891252e-05 
thres:  9.766285866498947e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 31%|███       | 306/1000 [14:18<32:10,  2.78s/it]Epoch:   307
max of grad d_p:  tensor(0.0402, device='cuda:0')
min of grad d_p:  tensor(-0.0073, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0352, device='cuda:0') mean:  tensor(-3.1230e-05, device='cuda:0') min:  tensor(-0.0477, device='cuda:0') norm:  tensor(0.3814, device='cuda:0') MSE:  tensor(1.4319e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(9.0463e-07, device='cuda:0') min:  tensor(3.6380e-12, device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.1874e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0006, device='cuda:0')
min of d_p_list:  tensor(-0.0008, device='cuda:0')
Epoch:  307  
Training Loss: 0.009675607085227966
Test Loss:  0.0033362985122948885
Test Acc:  0.0
Valid Loss:  0.0031914501450955868
Valid Acc:  0.0
std:  4.24814357886861e-05 
thres:  9.735608659684657e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 31%|███       | 307/1000 [14:21<31:43,  2.75s/it]Epoch:   308
max of grad d_p:  tensor(0.0400, device='cuda:0')
min of grad d_p:  tensor(-0.0073, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0424, device='cuda:0') mean:  tensor(-2.8819e-05, device='cuda:0') min:  tensor(-0.0549, device='cuda:0') norm:  tensor(0.3934, device='cuda:0') MSE:  tensor(1.4766e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(5.0155e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.4794e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0019, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  308  
Training Loss: 0.009644596837460995
Test Loss:  0.0033050752244889736
Test Acc:  0.0
Valid Loss:  0.0031629616860300303
Valid Acc:  0.0
std:  4.232393825008939e-05 
thres:  9.705198183655738e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 31%|███       | 308/1000 [14:23<31:06,  2.70s/it]Epoch:   309
max of grad d_p:  tensor(0.0398, device='cuda:0')
min of grad d_p:  tensor(-0.0072, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0436, device='cuda:0') mean:  tensor(-3.1082e-05, device='cuda:0') min:  tensor(-0.0657, device='cuda:0') norm:  tensor(0.4232, device='cuda:0') MSE:  tensor(1.5884e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0051, device='cuda:0') mean:  tensor(1.7971e-05, device='cuda:0') min:  tensor(1.3733e-10, device='cuda:0') norm:  tensor(0.0245, device='cuda:0') MSE:  tensor(9.2119e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  309  
Training Loss: 0.009614772163331509
Test Loss:  0.003274155780673027
Test Acc:  0.0
Valid Loss:  0.003135917242616415
Valid Acc:  0.0
std:  4.300067399511968e-05 
thres:  9.675378911197186e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 31%|███       | 309/1000 [14:26<30:50,  2.68s/it]Epoch:   310
max of grad d_p:  tensor(0.0396, device='cuda:0')
min of grad d_p:  tensor(-0.0072, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0370, device='cuda:0') mean:  tensor(-2.6881e-05, device='cuda:0') min:  tensor(-0.0546, device='cuda:0') norm:  tensor(0.3633, device='cuda:0') MSE:  tensor(1.3637e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(2.1728e-06, device='cuda:0') min:  tensor(9.5497e-12, device='cuda:0') norm:  tensor(0.0027, device='cuda:0') MSE:  tensor(1.0042e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0114, device='cuda:0')
min of d_p_list:  tensor(-0.0224, device='cuda:0')
Epoch:  310  
Training Loss: 0.009608925320208073
Test Loss:  0.0032585272565484047
Test Acc:  0.0
Valid Loss:  0.003133891150355339
Valid Acc:  0.0
std:  3.662991229330113e-05 
thres:  9.649908170104027e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 31%|███       | 310/1000 [14:29<31:23,  2.73s/it]Epoch:   311
max of grad d_p:  tensor(0.0403, device='cuda:0')
min of grad d_p:  tensor(-0.0071, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0404, device='cuda:0') mean:  tensor(-3.1269e-05, device='cuda:0') min:  tensor(-0.0494, device='cuda:0') norm:  tensor(0.3840, device='cuda:0') MSE:  tensor(1.4414e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.1061e-07, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.7280e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  311  
Training Loss: 0.009577689692378044
Test Loss:  0.003228007350116968
Test Acc:  0.0
Valid Loss:  0.0031052683480083942
Valid Acc:  0.0
std:  3.329882332039893e-05 
thres:  9.624318219721317e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 31%|███       | 311/1000 [14:31<31:27,  2.74s/it]Epoch:   312
max of grad d_p:  tensor(0.0401, device='cuda:0')
min of grad d_p:  tensor(-0.0071, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0405, device='cuda:0') mean:  tensor(-3.1841e-05, device='cuda:0') min:  tensor(-0.0597, device='cuda:0') norm:  tensor(0.4099, device='cuda:0') MSE:  tensor(1.5387e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(2.0623e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0026, device='cuda:0') MSE:  tensor(9.8930e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0018, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  312  
Training Loss: 0.009548662230372429
Test Loss:  0.0031977887265384197
Test Acc:  0.0
Valid Loss:  0.0030750450678169727
Valid Acc:  0.0
std:  3.2906959559208776e-05 
thres:  9.59892924875021e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 31%|███       | 312/1000 [14:35<32:39,  2.85s/it]Epoch:   313
max of grad d_p:  tensor(0.0399, device='cuda:0')
min of grad d_p:  tensor(-0.0071, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0396, device='cuda:0') mean:  tensor(-2.9607e-05, device='cuda:0') min:  tensor(-0.0626, device='cuda:0') norm:  tensor(0.3976, device='cuda:0') MSE:  tensor(1.4924e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0009, device='cuda:0') mean:  tensor(3.7452e-06, device='cuda:0') min:  tensor(9.5071e-12, device='cuda:0') norm:  tensor(0.0048, device='cuda:0') MSE:  tensor(1.7832e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  313  
Training Loss: 0.009518381208181381
Test Loss:  0.003166891634464264
Test Acc:  0.0
Valid Loss:  0.0030465549789369106
Valid Acc:  0.0
std:  3.641626313362613e-05 
thres:  9.573686122894287e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 31%|███▏      | 313/1000 [14:38<33:17,  2.91s/it]Epoch:   314
max of grad d_p:  tensor(0.0397, device='cuda:0')
min of grad d_p:  tensor(-0.0070, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0391, device='cuda:0') mean:  tensor(-3.2061e-05, device='cuda:0') min:  tensor(-0.0684, device='cuda:0') norm:  tensor(0.4092, device='cuda:0') MSE:  tensor(1.5360e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.0266e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.3794e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  314  
Training Loss: 0.009489505551755428
Test Loss:  0.003137964755296707
Test Acc:  0.0
Valid Loss:  0.0030206257943063974
Valid Acc:  0.0
std:  4.216795500470099e-05 
thres:  9.548632800579071e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 31%|███▏      | 314/1000 [14:40<33:10,  2.90s/it]Epoch:   315
max of grad d_p:  tensor(0.0395, device='cuda:0')
min of grad d_p:  tensor(-0.0070, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0404, device='cuda:0') mean:  tensor(-3.3418e-05, device='cuda:0') min:  tensor(-0.0542, device='cuda:0') norm:  tensor(0.3884, device='cuda:0') MSE:  tensor(1.4578e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(9.6093e-07, device='cuda:0') min:  tensor(5.4570e-12, device='cuda:0') norm:  tensor(0.0014, device='cuda:0') MSE:  tensor(5.2789e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  315  
Training Loss: 0.009461166337132454
Test Loss:  0.003108816221356392
Test Acc:  0.0
Valid Loss:  0.0029952775221318007
Valid Acc:  0.0
std:  4.1326342773415375e-05 
thres:  9.519081003963948e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 32%|███▏      | 315/1000 [14:43<32:04,  2.81s/it]Epoch:   316
max of grad d_p:  tensor(0.0393, device='cuda:0')
min of grad d_p:  tensor(-0.0070, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0395, device='cuda:0') mean:  tensor(-2.8206e-05, device='cuda:0') min:  tensor(-0.0739, device='cuda:0') norm:  tensor(0.4074, device='cuda:0') MSE:  tensor(1.5291e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0060, device='cuda:0') mean:  tensor(1.8308e-05, device='cuda:0') min:  tensor(4.5929e-11, device='cuda:0') norm:  tensor(0.0267, device='cuda:0') MSE:  tensor(1.0010e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0054, device='cuda:0')
min of d_p_list:  tensor(-0.0074, device='cuda:0')
Epoch:  316  
Training Loss: 0.009432032704353333
Test Loss:  0.0030780076049268246
Test Acc:  0.0
Valid Loss:  0.00296638160943985
Valid Acc:  0.0
std:  4.108179526389171e-05 
thres:  9.489949606359006e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 32%|███▏      | 316/1000 [14:46<31:31,  2.77s/it]Epoch:   317
max of grad d_p:  tensor(0.0392, device='cuda:0')
min of grad d_p:  tensor(-0.0069, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0428, device='cuda:0') mean:  tensor(-2.8333e-05, device='cuda:0') min:  tensor(-0.0525, device='cuda:0') norm:  tensor(0.3776, device='cuda:0') MSE:  tensor(1.4175e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.3462e-07, device='cuda:0') min:  tensor(2.0464e-12, device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.4421e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  317  
Training Loss: 0.009403148666024208
Test Loss:  0.0030487636104226112
Test Acc:  0.0
Valid Loss:  0.0029402386862784624
Valid Acc:  0.0
std:  4.072090630897133e-05 
thres:  9.46084689348936e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 32%|███▏      | 317/1000 [14:49<32:15,  2.83s/it]Epoch:   318
max of grad d_p:  tensor(0.0390, device='cuda:0')
min of grad d_p:  tensor(-0.0069, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0435, device='cuda:0') mean:  tensor(-3.2681e-05, device='cuda:0') min:  tensor(-0.0639, device='cuda:0') norm:  tensor(0.3956, device='cuda:0') MSE:  tensor(1.4848e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.0373e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.9160e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  318  
Training Loss: 0.009375390596687794
Test Loss:  0.003020375967025757
Test Acc:  0.0
Valid Loss:  0.002914742100983858
Valid Acc:  0.0
std:  4.048278486965831e-05 
thres:  9.432248771190644e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 32%|███▏      | 318/1000 [14:51<31:29,  2.77s/it]Epoch:   319
max of grad d_p:  tensor(0.0388, device='cuda:0')
min of grad d_p:  tensor(-0.0069, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0415, device='cuda:0') mean:  tensor(-3.3918e-05, device='cuda:0') min:  tensor(-0.0508, device='cuda:0') norm:  tensor(0.4087, device='cuda:0') MSE:  tensor(1.5341e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.0217e-05, device='cuda:0') mean:  tensor(4.7842e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2022e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0039, device='cuda:0')
Epoch:  319  
Training Loss: 0.00934842973947525
Test Loss:  0.0029927659779787064
Test Acc:  0.0
Valid Loss:  0.0028893195558339357
Valid Acc:  0.0
std:  3.9902615325251295e-05 
thres:  9.404033608734607e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 32%|███▏      | 319/1000 [14:54<32:04,  2.83s/it]Epoch:   320
max of grad d_p:  tensor(0.0387, device='cuda:0')
min of grad d_p:  tensor(-0.0068, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0425, device='cuda:0') mean:  tensor(-3.2180e-05, device='cuda:0') min:  tensor(-0.0497, device='cuda:0') norm:  tensor(0.3842, device='cuda:0') MSE:  tensor(1.4420e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.0545e-06, device='cuda:0') min:  tensor(4.5475e-13, device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.8337e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0034, device='cuda:0')
Epoch:  320  
Training Loss: 0.00932152196764946
Test Loss:  0.0029659527353942394
Test Acc:  0.0
Valid Loss:  0.002864216919988394
Valid Acc:  0.0
std:  3.9000014932552264e-05 
thres:  9.37610473483801e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 32%|███▏      | 320/1000 [14:57<32:24,  2.86s/it]Epoch:   321
max of grad d_p:  tensor(0.0385, device='cuda:0')
min of grad d_p:  tensor(-0.0068, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0418, device='cuda:0') mean:  tensor(-3.1103e-05, device='cuda:0') min:  tensor(-0.0584, device='cuda:0') norm:  tensor(0.3867, device='cuda:0') MSE:  tensor(1.4517e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.8326e-06, device='cuda:0') min:  tensor(9.0949e-13, device='cuda:0') norm:  tensor(0.0024, device='cuda:0') MSE:  tensor(8.9125e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0017, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  321  
Training Loss: 0.009294847957789898
Test Loss:  0.0029378687031567097
Test Acc:  0.0
Valid Loss:  0.0028394837863743305
Valid Acc:  0.0
std:  3.825127691437551e-05 
thres:  9.348667785525322e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 32%|███▏      | 321/1000 [15:00<33:11,  2.93s/it]Epoch:   322
max of grad d_p:  tensor(0.0383, device='cuda:0')
min of grad d_p:  tensor(-0.0067, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0408, device='cuda:0') mean:  tensor(-3.3359e-05, device='cuda:0') min:  tensor(-0.0503, device='cuda:0') norm:  tensor(0.3951, device='cuda:0') MSE:  tensor(1.4832e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.9294e-05, device='cuda:0') mean:  tensor(4.0957e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9699e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  322  
Training Loss: 0.009268593043088913
Test Loss:  0.002910358365625143
Test Acc:  0.0
Valid Loss:  0.0028150994330644608
Valid Acc:  0.0
std:  3.7785065387063844e-05 
thres:  9.321756660938263e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 32%|███▏      | 322/1000 [15:03<32:44,  2.90s/it]Epoch:   323
max of grad d_p:  tensor(0.0381, device='cuda:0')
min of grad d_p:  tensor(-0.0067, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0457, device='cuda:0') mean:  tensor(-3.3428e-05, device='cuda:0') min:  tensor(-0.0766, device='cuda:0') norm:  tensor(0.4548, device='cuda:0') MSE:  tensor(1.7074e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(7.6483e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.8656e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  323  
Training Loss: 0.009241955354809761
Test Loss:  0.0028828950598835945
Test Acc:  0.0
Valid Loss:  0.0027907327748835087
Valid Acc:  0.0
std:  3.760109698491179e-05 
thres:  9.295069612562657e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 32%|███▏      | 323/1000 [15:06<31:47,  2.82s/it]Epoch:   324
max of grad d_p:  tensor(0.0379, device='cuda:0')
min of grad d_p:  tensor(-0.0067, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0385, device='cuda:0') mean:  tensor(-3.0462e-05, device='cuda:0') min:  tensor(-0.0555, device='cuda:0') norm:  tensor(0.3706, device='cuda:0') MSE:  tensor(1.3910e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(8.1132e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.8439e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  324  
Training Loss: 0.009215263649821281
Test Loss:  0.0028555907774716616
Test Acc:  0.0
Valid Loss:  0.0027658590115606785
Valid Acc:  0.0
std:  3.753467604908172e-05 
thres:  9.268436394631863e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 32%|███▏      | 324/1000 [15:08<31:05,  2.76s/it]Epoch:   325
max of grad d_p:  tensor(0.0377, device='cuda:0')
min of grad d_p:  tensor(-0.0066, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0464, device='cuda:0') mean:  tensor(-3.4405e-05, device='cuda:0') min:  tensor(-0.0561, device='cuda:0') norm:  tensor(0.4258, device='cuda:0') MSE:  tensor(1.5982e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.0458e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0016, device='cuda:0') MSE:  tensor(5.8653e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0113, device='cuda:0')
min of d_p_list:  tensor(-0.0087, device='cuda:0')
Epoch:  325  
Training Loss: 0.009183716960251331
Test Loss:  0.0028213721234351397
Test Acc:  0.0
Valid Loss:  0.0027232214342802763
Valid Acc:  0.0
std:  3.900133335386985e-05 
thres:  9.240875393152238e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 32%|███▎      | 325/1000 [15:11<31:50,  2.83s/it]Epoch:   326
max of grad d_p:  tensor(0.0376, device='cuda:0')
min of grad d_p:  tensor(-0.0066, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0404, device='cuda:0') mean:  tensor(-3.2676e-05, device='cuda:0') min:  tensor(-0.0619, device='cuda:0') norm:  tensor(0.3951, device='cuda:0') MSE:  tensor(1.4832e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(7.2243e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.3272e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  326  
Training Loss: 0.009157254360616207
Test Loss:  0.002794664353132248
Test Acc:  0.0
Valid Loss:  0.002698535332456231
Valid Acc:  0.0
std:  3.9745590369459834e-05 
thres:  9.2133566737175e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 33%|███▎      | 326/1000 [15:14<32:08,  2.86s/it]Epoch:   327
max of grad d_p:  tensor(0.0374, device='cuda:0')
min of grad d_p:  tensor(-0.0066, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0424, device='cuda:0') mean:  tensor(-3.3019e-05, device='cuda:0') min:  tensor(-0.0572, device='cuda:0') norm:  tensor(0.3885, device='cuda:0') MSE:  tensor(1.4582e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.0087e-05, device='cuda:0') mean:  tensor(2.8540e-07, device='cuda:0') min:  tensor(9.0949e-13, device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.3366e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  327  
Training Loss: 0.009131789207458496
Test Loss:  0.0027685430832207203
Test Acc:  0.0
Valid Loss:  0.0026750927790999413
Valid Acc:  0.0
std:  3.9389584742730926e-05 
thres:  9.185995906591416e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 33%|███▎      | 327/1000 [15:17<32:21,  2.88s/it]Epoch:   328
max of grad d_p:  tensor(0.0372, device='cuda:0')
min of grad d_p:  tensor(-0.0066, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0425, device='cuda:0') mean:  tensor(-3.2828e-05, device='cuda:0') min:  tensor(-0.0733, device='cuda:0') norm:  tensor(0.4105, device='cuda:0') MSE:  tensor(1.5408e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.1620e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.5759e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0261, device='cuda:0')
min of d_p_list:  tensor(-0.0216, device='cuda:0')
Epoch:  328  
Training Loss: 0.009151289239525795
Test Loss:  0.00278476276434958
Test Acc:  0.0
Valid Loss:  0.002699732780456543
Valid Acc:  0.0
std:  2.893690008549269e-05 
thres:  9.167862683534623e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 33%|███▎      | 328/1000 [15:20<32:30,  2.90s/it]Epoch:   329
max of grad d_p:  tensor(0.0368, device='cuda:0')
min of grad d_p:  tensor(-0.0068, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0429, device='cuda:0') mean:  tensor(-3.4096e-05, device='cuda:0') min:  tensor(-0.0500, device='cuda:0') norm:  tensor(0.3960, device='cuda:0') MSE:  tensor(1.4866e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(1.3490e-06, device='cuda:0') min:  tensor(3.1832e-12, device='cuda:0') norm:  tensor(0.0017, device='cuda:0') MSE:  tensor(6.2658e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0134, device='cuda:0')
min of d_p_list:  tensor(-0.0115, device='cuda:0')
Epoch:  329  
Training Loss: 0.009140714071691036
Test Loss:  0.0027733142487704754
Test Acc:  0.0
Valid Loss:  0.002678965451195836
Valid Acc:  0.0
std:  1.7694001995219274e-05 
thres:  9.152952767908573e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 33%|███▎      | 329/1000 [15:23<31:56,  2.86s/it]Epoch:   330
max of grad d_p:  tensor(0.0370, device='cuda:0')
min of grad d_p:  tensor(-0.0067, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0432, device='cuda:0') mean:  tensor(-3.3621e-05, device='cuda:0') min:  tensor(-0.0561, device='cuda:0') norm:  tensor(0.3982, device='cuda:0') MSE:  tensor(1.4948e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0069, device='cuda:0') mean:  tensor(2.3114e-05, device='cuda:0') min:  tensor(1.6030e-11, device='cuda:0') norm:  tensor(0.0304, device='cuda:0') MSE:  tensor(1.1421e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0025, device='cuda:0')
Epoch:  330  
Training Loss: 0.009113846346735954
Test Loss:  0.0027477312833070755
Test Acc:  0.0
Valid Loss:  0.0026554595679044724
Valid Acc:  0.0
std:  1.530937394447671e-05 
thres:  9.138978645205497e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 33%|███▎      | 330/1000 [15:26<31:45,  2.84s/it]Epoch:   331
max of grad d_p:  tensor(0.0368, device='cuda:0')
min of grad d_p:  tensor(-0.0067, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0417, device='cuda:0') mean:  tensor(-3.1946e-05, device='cuda:0') min:  tensor(-0.0606, device='cuda:0') norm:  tensor(0.4063, device='cuda:0') MSE:  tensor(1.5251e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(5.6376e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(3.0263e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0399, device='cuda:0')
min of d_p_list:  tensor(-0.0171, device='cuda:0')
Epoch:  331  
Training Loss: 0.009168388321995735
Test Loss:  0.0027865134179592133
Test Acc:  0.0
Valid Loss:  0.002687719650566578
Valid Acc:  0.0
std:  1.831949207151736e-05 
thres:  9.141205437481403e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 33%|███▎      | 331/1000 [15:28<30:56,  2.77s/it]Epoch:   332
max of grad d_p:  tensor(0.0381, device='cuda:0')
min of grad d_p:  tensor(-0.0068, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0440, device='cuda:0') mean:  tensor(-3.2958e-05, device='cuda:0') min:  tensor(-0.0587, device='cuda:0') norm:  tensor(0.4032, device='cuda:0') MSE:  tensor(1.5136e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.1147e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5439e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0016, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  332  
Training Loss: 0.009141089394688606
Test Loss:  0.002760888310149312
Test Acc:  0.0
Valid Loss:  0.002664541359990835
Valid Acc:  0.0
std:  1.773171356848726e-05 
thres:  9.143065474927426e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 33%|███▎      | 332/1000 [15:31<30:14,  2.72s/it]Epoch:   333
max of grad d_p:  tensor(0.0380, device='cuda:0')
min of grad d_p:  tensor(-0.0067, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0341, device='cuda:0') mean:  tensor(-3.1285e-05, device='cuda:0') min:  tensor(-0.0585, device='cuda:0') norm:  tensor(0.3578, device='cuda:0') MSE:  tensor(1.3431e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(7.2700e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.4601e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0214, device='cuda:0')
min of d_p_list:  tensor(-0.0160, device='cuda:0')
Epoch:  333  
Training Loss: 0.00911698117852211
Test Loss:  0.0027402834966778755
Test Acc:  0.0
Valid Loss:  0.002638577949255705
Valid Acc:  0.0
std:  1.9745480167363947e-05 
thres:  9.136203862726688e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 33%|███▎      | 333/1000 [15:34<31:11,  2.81s/it]Epoch:   334
max of grad d_p:  tensor(0.0382, device='cuda:0')
min of grad d_p:  tensor(-0.0067, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0425, device='cuda:0') mean:  tensor(-3.1867e-05, device='cuda:0') min:  tensor(-0.0533, device='cuda:0') norm:  tensor(0.3845, device='cuda:0') MSE:  tensor(1.4434e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.7491e-07, device='cuda:0') min:  tensor(1.1369e-13, device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.1506e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0030, device='cuda:0')
min of d_p_list:  tensor(-0.0033, device='cuda:0')
Epoch:  334  
Training Loss: 0.009091616608202457
Test Loss:  0.0027118416037410498
Test Acc:  0.0
Valid Loss:  0.002612500451505184
Valid Acc:  0.0
std:  2.6210642998991154e-05 
thres:  9.126384370028973e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 33%|███▎      | 334/1000 [15:37<31:26,  2.83s/it]Epoch:   335
max of grad d_p:  tensor(0.0380, device='cuda:0')
min of grad d_p:  tensor(-0.0066, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0408, device='cuda:0') mean:  tensor(-3.0807e-05, device='cuda:0') min:  tensor(-0.0582, device='cuda:0') norm:  tensor(0.3815, device='cuda:0') MSE:  tensor(1.4320e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.4550e-07, device='cuda:0') min:  tensor(1.1369e-13, device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.6775e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0142, device='cuda:0')
min of d_p_list:  tensor(-0.0171, device='cuda:0')
Epoch:  335  
Training Loss: 0.009110715240240097
Test Loss:  0.002718324074521661
Test Acc:  0.0
Valid Loss:  0.002620639279484749
Valid Acc:  0.0
std:  2.653807780066031e-05 
thres:  9.1257581487298e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 34%|███▎      | 335/1000 [15:40<31:50,  2.87s/it]Epoch:   336
max of grad d_p:  tensor(0.0382, device='cuda:0')
min of grad d_p:  tensor(-0.0066, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0419, device='cuda:0') mean:  tensor(-3.4808e-05, device='cuda:0') min:  tensor(-0.0728, device='cuda:0') norm:  tensor(0.4059, device='cuda:0') MSE:  tensor(1.5238e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.2692e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.2073e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  336  
Training Loss: 0.00908572319895029
Test Loss:  0.0026920856907963753
Test Acc:  0.0
Valid Loss:  0.002595935482531786
Valid Acc:  0.0
std:  1.969826837217006e-05 
thres:  9.109225124120712e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 34%|███▎      | 336/1000 [15:43<32:18,  2.92s/it]Epoch:   337
max of grad d_p:  tensor(0.0380, device='cuda:0')
min of grad d_p:  tensor(-0.0066, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0361, device='cuda:0') mean:  tensor(-3.3372e-05, device='cuda:0') min:  tensor(-0.0692, device='cuda:0') norm:  tensor(0.3870, device='cuda:0') MSE:  tensor(1.4527e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(6.0193e-07, device='cuda:0') min:  tensor(6.8212e-13, device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.8191e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0064, device='cuda:0')
min of d_p_list:  tensor(-0.0075, device='cuda:0')
Epoch:  337  
Training Loss: 0.009059925563633442
Test Loss:  0.00266549875959754
Test Acc:  0.0
Valid Loss:  0.0025749709457159042
Valid Acc:  0.0
std:  2.018767106634145e-05 
thres:  9.09299235790968e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 34%|███▎      | 337/1000 [15:46<32:44,  2.96s/it]Epoch:   338
max of grad d_p:  tensor(0.0378, device='cuda:0')
min of grad d_p:  tensor(-0.0065, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0408, device='cuda:0') mean:  tensor(-3.3167e-05, device='cuda:0') min:  tensor(-0.0623, device='cuda:0') norm:  tensor(0.3884, device='cuda:0') MSE:  tensor(1.4579e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0011, device='cuda:0') mean:  tensor(3.8205e-06, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0053, device='cuda:0') MSE:  tensor(1.9848e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0032, device='cuda:0')
min of d_p_list:  tensor(-0.0023, device='cuda:0')
Epoch:  338  
Training Loss: 0.009035566821694374
Test Loss:  0.002641361439600587
Test Acc:  0.0
Valid Loss:  0.0025541470386087894
Valid Acc:  0.0
std:  2.6207935863471535e-05 
thres:  9.076709486544133e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 34%|███▍      | 338/1000 [15:49<32:20,  2.93s/it]Epoch:   339
max of grad d_p:  tensor(0.0376, device='cuda:0')
min of grad d_p:  tensor(-0.0065, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-3.1161e-05, device='cuda:0') min:  tensor(-0.0590, device='cuda:0') norm:  tensor(0.3635, device='cuda:0') MSE:  tensor(1.3646e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0016, device='cuda:0') mean:  tensor(7.4187e-06, device='cuda:0') min:  tensor(4.0927e-12, device='cuda:0') norm:  tensor(0.0100, device='cuda:0') MSE:  tensor(3.7584e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0029, device='cuda:0')
min of d_p_list:  tensor(-0.0040, device='cuda:0')
Epoch:  339  
Training Loss: 0.0090109221637249
Test Loss:  0.0026149507611989975
Test Acc:  0.0
Valid Loss:  0.002531531034037471
Valid Acc:  0.0
std:  3.532056173051812e-05 
thres:  9.06057059764862e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 34%|███▍      | 339/1000 [15:51<31:13,  2.83s/it]Epoch:   340
max of grad d_p:  tensor(0.0375, device='cuda:0')
min of grad d_p:  tensor(-0.0065, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0410, device='cuda:0') mean:  tensor(-3.1979e-05, device='cuda:0') min:  tensor(-0.0610, device='cuda:0') norm:  tensor(0.3828, device='cuda:0') MSE:  tensor(1.4368e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.8069e-05, device='cuda:0') mean:  tensor(3.9596e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9028e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0024, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  340  
Training Loss: 0.00898646004498005
Test Loss:  0.002589842304587364
Test Acc:  0.0
Valid Loss:  0.0025073611177504063
Valid Acc:  0.0
std:  3.5007794935380805e-05 
thres:  9.035719558596612e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 34%|███▍      | 340/1000 [15:54<31:28,  2.86s/it]Epoch:   341
max of grad d_p:  tensor(0.0373, device='cuda:0')
min of grad d_p:  tensor(-0.0064, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0356, device='cuda:0') mean:  tensor(-3.0682e-05, device='cuda:0') min:  tensor(-0.0550, device='cuda:0') norm:  tensor(0.3773, device='cuda:0') MSE:  tensor(1.4163e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.5988e-05, device='cuda:0') mean:  tensor(3.2469e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5053e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0062, device='cuda:0')
min of d_p_list:  tensor(-0.0057, device='cuda:0')
Epoch:  341  
Training Loss: 0.008961256593465805
Test Loss:  0.0025648772716522217
Test Acc:  0.0
Valid Loss:  0.002483946271240711
Valid Acc:  0.0
std:  3.485315045293248e-05 
thres:  9.010826237499713e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 34%|███▍      | 341/1000 [15:57<31:20,  2.85s/it]Epoch:   342
max of grad d_p:  tensor(0.0372, device='cuda:0')
min of grad d_p:  tensor(-0.0064, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0421, device='cuda:0') mean:  tensor(-3.1412e-05, device='cuda:0') min:  tensor(-0.0583, device='cuda:0') norm:  tensor(0.3827, device='cuda:0') MSE:  tensor(1.4367e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(7.1161e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.8490e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0006, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  342  
Training Loss: 0.008937502279877663
Test Loss:  0.002540537854656577
Test Acc:  0.0
Valid Loss:  0.002461702097207308
Valid Acc:  0.0
std:  3.476169540151431e-05 
thres:  8.98634158074856e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 34%|███▍      | 342/1000 [16:00<30:49,  2.81s/it]Epoch:   343
max of grad d_p:  tensor(0.0370, device='cuda:0')
min of grad d_p:  tensor(-0.0064, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0374, device='cuda:0') mean:  tensor(-3.1135e-05, device='cuda:0') min:  tensor(-0.0536, device='cuda:0') norm:  tensor(0.3725, device='cuda:0') MSE:  tensor(1.3984e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0008, device='cuda:0') mean:  tensor(4.0669e-06, device='cuda:0') min:  tensor(1.2506e-11, device='cuda:0') norm:  tensor(0.0053, device='cuda:0') MSE:  tensor(1.9856e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0007, device='cuda:0')
Epoch:  343  
Training Loss: 0.00891499686986208
Test Loss:  0.0025168955326080322
Test Acc:  0.0
Valid Loss:  0.002440225798636675
Valid Acc:  0.0
std:  3.406287745999006e-05 
thres:  8.962227590382099e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 34%|███▍      | 343/1000 [16:03<30:23,  2.78s/it]Epoch:   344
max of grad d_p:  tensor(0.0368, device='cuda:0')
min of grad d_p:  tensor(-0.0064, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-2.9601e-05, device='cuda:0') min:  tensor(-0.0622, device='cuda:0') norm:  tensor(0.3595, device='cuda:0') MSE:  tensor(1.3496e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0043, device='cuda:0') mean:  tensor(1.1302e-05, device='cuda:0') min:  tensor(7.2760e-12, device='cuda:0') norm:  tensor(0.0153, device='cuda:0') MSE:  tensor(5.7432e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  344  
Training Loss: 0.008894247934222221
Test Loss:  0.0024957528803497553
Test Acc:  0.0
Valid Loss:  0.0024175841826945543
Valid Acc:  0.0
std:  3.264627120159559e-05 
thres:  8.938892744481564e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 34%|███▍      | 344/1000 [16:05<29:45,  2.72s/it]Epoch:   345
max of grad d_p:  tensor(0.0366, device='cuda:0')
min of grad d_p:  tensor(-0.0063, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0409, device='cuda:0') mean:  tensor(-3.2729e-05, device='cuda:0') min:  tensor(-0.0670, device='cuda:0') norm:  tensor(0.3748, device='cuda:0') MSE:  tensor(1.4068e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0058, device='cuda:0') mean:  tensor(1.7924e-05, device='cuda:0') min:  tensor(2.9104e-11, device='cuda:0') norm:  tensor(0.0254, device='cuda:0') MSE:  tensor(9.5213e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0051, device='cuda:0')
min of d_p_list:  tensor(-0.0050, device='cuda:0')
Epoch:  345  
Training Loss: 0.008874637074768543
Test Loss:  0.002472946885973215
Test Acc:  0.0
Valid Loss:  0.002397174946963787
Valid Acc:  0.0
std:  3.0640374661585046e-05 
thres:  8.916528150439262e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 34%|███▍      | 345/1000 [16:08<29:45,  2.73s/it]Epoch:   346
max of grad d_p:  tensor(0.0365, device='cuda:0')
min of grad d_p:  tensor(-0.0063, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0406, device='cuda:0') mean:  tensor(-2.7772e-05, device='cuda:0') min:  tensor(-0.0597, device='cuda:0') norm:  tensor(0.3414, device='cuda:0') MSE:  tensor(1.2816e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.1891e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(2.0228e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0048, device='cuda:0')
min of d_p_list:  tensor(-0.0030, device='cuda:0')
Epoch:  346  
Training Loss: 0.008852940052747726
Test Loss:  0.002449768828228116
Test Acc:  0.0
Valid Loss:  0.0023784900549799204
Valid Acc:  0.0
std:  2.9632687191123673e-05 
thres:  8.894864842295648e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 35%|███▍      | 346/1000 [16:10<29:16,  2.69s/it]Epoch:   347
max of grad d_p:  tensor(0.0363, device='cuda:0')
min of grad d_p:  tensor(-0.0063, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0406, device='cuda:0') mean:  tensor(-2.9940e-05, device='cuda:0') min:  tensor(-0.0552, device='cuda:0') norm:  tensor(0.3986, device='cuda:0') MSE:  tensor(1.4963e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.9283e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.4913e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0019, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  347  
Training Loss: 0.008829953148961067
Test Loss:  0.002426316263154149
Test Acc:  0.0
Valid Loss:  0.002358298283070326
Valid Acc:  0.0
std:  2.9908843129262305e-05 
thres:  8.873355016112327e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 35%|███▍      | 347/1000 [16:14<30:27,  2.80s/it]Epoch:   348
max of grad d_p:  tensor(0.0361, device='cuda:0')
min of grad d_p:  tensor(-0.0062, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0470, device='cuda:0') mean:  tensor(-3.3683e-05, device='cuda:0') min:  tensor(-0.0605, device='cuda:0') norm:  tensor(0.4221, device='cuda:0') MSE:  tensor(1.5845e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.9104e-05, device='cuda:0') mean:  tensor(3.5483e-07, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7368e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0038, device='cuda:0')
min of d_p_list:  tensor(-0.0041, device='cuda:0')
Epoch:  348  
Training Loss: 0.008807016536593437
Test Loss:  0.0024037130642682314
Test Acc:  0.0
Valid Loss:  0.0023345905356109142
Valid Acc:  0.0
std:  3.1008043773366895e-05 
thres:  8.8517589494586e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 35%|███▍      | 348/1000 [16:16<29:43,  2.73s/it]Epoch:   349
max of grad d_p:  tensor(0.0360, device='cuda:0')
min of grad d_p:  tensor(-0.0062, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0412, device='cuda:0') mean:  tensor(-3.1241e-05, device='cuda:0') min:  tensor(-0.0554, device='cuda:0') norm:  tensor(0.3976, device='cuda:0') MSE:  tensor(1.4925e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0011, device='cuda:0') mean:  tensor(5.3106e-06, device='cuda:0') min:  tensor(5.4570e-12, device='cuda:0') norm:  tensor(0.0069, device='cuda:0') MSE:  tensor(2.5733e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0019, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  349  
Training Loss: 0.008783724159002304
Test Loss:  0.0023814085870981216
Test Acc:  0.0
Valid Loss:  0.0023140818811953068
Valid Acc:  0.0
std:  3.2211214822391504e-05 
thres:  8.829654194414616e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 35%|███▍      | 349/1000 [16:19<29:28,  2.72s/it]Epoch:   350
max of grad d_p:  tensor(0.0358, device='cuda:0')
min of grad d_p:  tensor(-0.0062, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0443, device='cuda:0') mean:  tensor(-3.3475e-05, device='cuda:0') min:  tensor(-0.0683, device='cuda:0') norm:  tensor(0.4077, device='cuda:0') MSE:  tensor(1.5306e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.3908e-05, device='cuda:0') mean:  tensor(4.2089e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9755e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0148, device='cuda:0')
min of d_p_list:  tensor(-0.0254, device='cuda:0')
Epoch:  350  
Training Loss: 0.008788850158452988
Test Loss:  0.0023897294886410236
Test Acc:  0.0
Valid Loss:  0.002315039746463299
Valid Acc:  0.0
std:  2.5913095628685147e-05 
thres:  8.812496811151505e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 35%|███▌      | 350/1000 [16:22<29:58,  2.77s/it]Epoch:   351
max of grad d_p:  tensor(0.0360, device='cuda:0')
min of grad d_p:  tensor(-0.0060, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0396, device='cuda:0') mean:  tensor(-3.3068e-05, device='cuda:0') min:  tensor(-0.0724, device='cuda:0') norm:  tensor(0.4165, device='cuda:0') MSE:  tensor(1.5636e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1217, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(1.7135e-09, device='cuda:0') norm:  tensor(0.8513, device='cuda:0') MSE:  tensor(3.1956e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0024, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  351  
Training Loss: 0.008767208084464073
Test Loss:  0.0023683705367147923
Test Acc:  0.0
Valid Loss:  0.0022942358627915382
Valid Acc:  0.0
std:  2.1460948358856466e-05 
thres:  8.795350417494775e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 35%|███▌      | 351/1000 [16:24<29:30,  2.73s/it]Epoch:   352
max of grad d_p:  tensor(0.0359, device='cuda:0')
min of grad d_p:  tensor(-0.0060, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0403, device='cuda:0') mean:  tensor(-3.3821e-05, device='cuda:0') min:  tensor(-0.0732, device='cuda:0') norm:  tensor(0.4326, device='cuda:0') MSE:  tensor(1.6238e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.9190e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8131e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0017, device='cuda:0')
min of d_p_list:  tensor(-0.0052, device='cuda:0')
Epoch:  352  
Training Loss: 0.008744342252612114
Test Loss:  0.002348601818084717
Test Acc:  0.0
Valid Loss:  0.0022762874141335487
Valid Acc:  0.0
std:  2.1173097399017886e-05 
thres:  8.778228238224984e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 35%|███▌      | 352/1000 [16:27<29:43,  2.75s/it]Epoch:   353
max of grad d_p:  tensor(0.0357, device='cuda:0')
min of grad d_p:  tensor(-0.0060, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0426, device='cuda:0') mean:  tensor(-3.1196e-05, device='cuda:0') min:  tensor(-0.0689, device='cuda:0') norm:  tensor(0.3956, device='cuda:0') MSE:  tensor(1.4850e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.2568e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0018, device='cuda:0') MSE:  tensor(6.6406e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  353  
Training Loss: 0.008722778409719467
Test Loss:  0.0023261667229235172
Test Acc:  0.0
Valid Loss:  0.002255162224173546
Valid Acc:  0.0
std:  2.4771779192599332e-05 
thres:  8.76138061285019e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 35%|███▌      | 353/1000 [16:30<30:05,  2.79s/it]Epoch:   354
max of grad d_p:  tensor(0.0355, device='cuda:0')
min of grad d_p:  tensor(-0.0059, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0460, device='cuda:0') mean:  tensor(-3.6113e-05, device='cuda:0') min:  tensor(-0.0819, device='cuda:0') norm:  tensor(0.4312, device='cuda:0') MSE:  tensor(1.6185e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.6996e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2827e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0020, device='cuda:0')
min of d_p_list:  tensor(-0.0036, device='cuda:0')
Epoch:  354  
Training Loss: 0.008703584782779217
Test Loss:  0.002306105801835656
Test Acc:  0.0
Valid Loss:  0.002237208653241396
Valid Acc:  0.0
std:  3.04133694828127e-05 
thres:  8.745352737605572e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 35%|███▌      | 354/1000 [16:33<29:20,  2.72s/it]Epoch:   355
max of grad d_p:  tensor(0.0354, device='cuda:0')
min of grad d_p:  tensor(-0.0059, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0462, device='cuda:0') mean:  tensor(-3.4711e-05, device='cuda:0') min:  tensor(-0.0706, device='cuda:0') norm:  tensor(0.4397, device='cuda:0') MSE:  tensor(1.6506e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.0387e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9085e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  355  
Training Loss: 0.008682208135724068
Test Loss:  0.0022844774648547173
Test Acc:  0.0
Valid Loss:  0.0022171074524521828
Valid Acc:  0.0
std:  2.981803528250562e-05 
thres:  8.72402433305979e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 36%|███▌      | 355/1000 [16:35<29:48,  2.77s/it]Epoch:   356
max of grad d_p:  tensor(0.0352, device='cuda:0')
min of grad d_p:  tensor(-0.0059, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0402, device='cuda:0') mean:  tensor(-3.0538e-05, device='cuda:0') min:  tensor(-0.0629, device='cuda:0') norm:  tensor(0.3882, device='cuda:0') MSE:  tensor(1.4572e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0065, device='cuda:0') mean:  tensor(3.2270e-05, device='cuda:0') min:  tensor(5.6389e-11, device='cuda:0') norm:  tensor(0.0462, device='cuda:0') MSE:  tensor(1.7335e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  356  
Training Loss: 0.008661109954118729
Test Loss:  0.0022626437712460756
Test Acc:  0.0
Valid Loss:  0.002197252120822668
Valid Acc:  0.0
std:  2.92834293762881e-05 
thres:  8.70280470699072e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 36%|███▌      | 356/1000 [16:38<29:06,  2.71s/it]Epoch:   357
max of grad d_p:  tensor(0.0350, device='cuda:0')
min of grad d_p:  tensor(-0.0058, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0427, device='cuda:0') mean:  tensor(-3.3468e-05, device='cuda:0') min:  tensor(-0.0769, device='cuda:0') norm:  tensor(0.4159, device='cuda:0') MSE:  tensor(1.5611e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(9.1395e-07, device='cuda:0') min:  tensor(2.0464e-12, device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.8200e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0203, device='cuda:0')
min of d_p_list:  tensor(-0.0145, device='cuda:0')
Epoch:  357  
Training Loss: 0.008669721893966198
Test Loss:  0.0022561782971024513
Test Acc:  0.0
Valid Loss:  0.0021688605193048716
Valid Acc:  0.0
std:  2.2552434088839134e-05 
thres:  8.687880635261536e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 36%|███▌      | 357/1000 [16:41<29:07,  2.72s/it]Epoch:   358
max of grad d_p:  tensor(0.0355, device='cuda:0')
min of grad d_p:  tensor(-0.0057, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0415, device='cuda:0') mean:  tensor(-3.1304e-05, device='cuda:0') min:  tensor(-0.0647, device='cuda:0') norm:  tensor(0.4135, device='cuda:0') MSE:  tensor(1.5523e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0045, device='cuda:0') mean:  tensor(1.2430e-05, device='cuda:0') min:  tensor(5.4570e-12, device='cuda:0') norm:  tensor(0.0179, device='cuda:0') MSE:  tensor(6.7336e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0020, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  358  
Training Loss: 0.0086470115929842
Test Loss:  0.002234627492725849
Test Acc:  0.0
Valid Loss:  0.002149411477148533
Valid Acc:  0.0
std:  1.9221671454730827e-05 
thres:  8.672727271914483e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 36%|███▌      | 358/1000 [16:43<28:53,  2.70s/it]Epoch:   359
max of grad d_p:  tensor(0.0353, device='cuda:0')
min of grad d_p:  tensor(-0.0057, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0405, device='cuda:0') mean:  tensor(-2.9409e-05, device='cuda:0') min:  tensor(-0.0693, device='cuda:0') norm:  tensor(0.3770, device='cuda:0') MSE:  tensor(1.4151e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(2.7714e-07, device='cuda:0') min:  tensor(9.0949e-13, device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.3279e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0576, device='cuda:0')
min of d_p_list:  tensor(-0.0346, device='cuda:0')
Epoch:  359  
Training Loss: 0.008818931877613068
Test Loss:  0.00238593015819788
Test Acc:  0.0
Valid Loss:  0.002269304823130369
Valid Acc:  0.0
std:  6.262583102994777e-05 
thres:  8.695796690881253e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 36%|███▌      | 359/1000 [16:46<28:35,  2.68s/it]Epoch:   360
max of grad d_p:  tensor(0.0377, device='cuda:0')
min of grad d_p:  tensor(-0.0059, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0442, device='cuda:0') mean:  tensor(-2.8754e-05, device='cuda:0') min:  tensor(-0.0774, device='cuda:0') norm:  tensor(0.4121, device='cuda:0') MSE:  tensor(1.5468e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.8328e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8498e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0103, device='cuda:0')
min of d_p_list:  tensor(-0.0137, device='cuda:0')
Epoch:  360  
Training Loss: 0.008815914392471313
Test Loss:  0.002385905012488365
Test Acc:  0.0
Valid Loss:  0.002272268757224083
Valid Acc:  0.0
std:  7.781788270867422e-05 
thres:  8.722537942230702e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 36%|███▌      | 360/1000 [16:49<28:27,  2.67s/it]Epoch:   361
max of grad d_p:  tensor(0.0384, device='cuda:0')
min of grad d_p:  tensor(-0.0060, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0479, device='cuda:0') mean:  tensor(-2.9991e-05, device='cuda:0') min:  tensor(-0.0685, device='cuda:0') norm:  tensor(0.4292, device='cuda:0') MSE:  tensor(1.6112e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0008, device='cuda:0') mean:  tensor(4.7898e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0064, device='cuda:0') MSE:  tensor(2.4022e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  361  
Training Loss: 0.008795566856861115
Test Loss:  0.0023648287169635296
Test Acc:  0.0
Valid Loss:  0.002251675119623542
Valid Acc:  0.0
std:  7.512949787653489e-05 
thres:  8.749429322779178e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 36%|███▌      | 361/1000 [16:51<28:12,  2.65s/it]Epoch:   362
max of grad d_p:  tensor(0.0382, device='cuda:0')
min of grad d_p:  tensor(-0.0060, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0439, device='cuda:0') mean:  tensor(-2.8678e-05, device='cuda:0') min:  tensor(-0.0768, device='cuda:0') norm:  tensor(0.3979, device='cuda:0') MSE:  tensor(1.4938e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.3409e-05, device='cuda:0') mean:  tensor(3.8052e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7674e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0031, device='cuda:0')
min of d_p_list:  tensor(-0.0025, device='cuda:0')
Epoch:  362  
Training Loss: 0.008774366229772568
Test Loss:  0.0023449426516890526
Test Acc:  0.0
Valid Loss:  0.0022349683567881584
Valid Acc:  0.0
std:  6.371921998118087e-05 
thres:  8.770358189940454e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 36%|███▌      | 362/1000 [16:54<29:00,  2.73s/it]Epoch:   363
max of grad d_p:  tensor(0.0381, device='cuda:0')
min of grad d_p:  tensor(-0.0059, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0384, device='cuda:0') mean:  tensor(-2.5280e-05, device='cuda:0') min:  tensor(-0.0635, device='cuda:0') norm:  tensor(0.3608, device='cuda:0') MSE:  tensor(1.3543e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.9234e-07, device='cuda:0') min:  tensor(2.2737e-13, device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2179e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0022, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  363  
Training Loss: 0.0087517648935318
Test Loss:  0.0023226668126881123
Test Acc:  0.0
Valid Loss:  0.0022152066230773926
Valid Acc:  0.0
std:  2.5445517760812622e-05 
thres:  8.791308850049972e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 36%|███▋      | 363/1000 [16:57<28:42,  2.70s/it]Epoch:   364
max of grad d_p:  tensor(0.0379, device='cuda:0')
min of grad d_p:  tensor(-0.0059, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0447, device='cuda:0') mean:  tensor(-2.9322e-05, device='cuda:0') min:  tensor(-0.0849, device='cuda:0') norm:  tensor(0.4222, device='cuda:0') MSE:  tensor(1.5848e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.8242e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.3513e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0089, device='cuda:0')
min of d_p_list:  tensor(-0.0217, device='cuda:0')
Epoch:  364  
Training Loss: 0.00874606054276228
Test Loss:  0.002322438405826688
Test Acc:  0.0
Valid Loss:  0.002214464358985424
Valid Acc:  0.0
std:  2.630476474953539e-05 
thres:  8.776734583079815e-06
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 36%|███▋      | 364/1000 [17:00<28:31,  2.69s/it]Epoch:   365
max of grad d_p:  tensor(0.0380, device='cuda:0')
min of grad d_p:  tensor(-0.0060, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-2.6333e-05, device='cuda:0') min:  tensor(-0.0677, device='cuda:0') norm:  tensor(0.3868, device='cuda:0') MSE:  tensor(1.4518e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0022, device='cuda:0') mean:  tensor(4.2878e-06, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0065, device='cuda:0') MSE:  tensor(2.4337e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1557, device='cuda:0')
min of d_p_list:  tensor(-0.1064, device='cuda:0')
Epoch:  365  
Training Loss: 0.0560416616499424
Test Loss:  0.039220571517944336
Test Acc:  0.0
Valid Loss:  0.041240230202674866
Valid Acc:  0.0
std:  0.018909896956230673 
thres:  1.8221884034574034e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 36%|███▋      | 365/1000 [17:02<28:19,  2.68s/it]Epoch:   366
max of grad d_p:  tensor(0.2862, device='cuda:0')
min of grad d_p:  tensor(-0.0766, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0537, device='cuda:0') mean:  tensor(-3.9499e-05, device='cuda:0') min:  tensor(-0.0527, device='cuda:0') norm:  tensor(0.4752, device='cuda:0') MSE:  tensor(1.7839e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(4.4231e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.4433e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  366  
Training Loss: 0.05554751306772232
Test Loss:  0.03882980719208717
Test Acc:  0.0
Valid Loss:  0.04082595556974411
Valid Acc:  0.0
std:  0.023043954724660504 
thres:  2.7572273276746274e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 37%|███▋      | 366/1000 [17:05<28:11,  2.67s/it]Epoch:   367
max of grad d_p:  tensor(0.2847, device='cuda:0')
min of grad d_p:  tensor(-0.0762, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0482, device='cuda:0') mean:  tensor(-3.5184e-05, device='cuda:0') min:  tensor(-0.0450, device='cuda:0') norm:  tensor(0.4092, device='cuda:0') MSE:  tensor(1.5362e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(4.4884e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.4028e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  367  
Training Loss: 0.055059198290109634
Test Loss:  0.03843849152326584
Test Acc:  0.0
Valid Loss:  0.040418125689029694
Valid Acc:  0.0
std:  0.022929595933351685 
thres:  3.682923968881369e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 37%|███▋      | 367/1000 [17:07<27:43,  2.63s/it]Epoch:   368
max of grad d_p:  tensor(0.2833, device='cuda:0')
min of grad d_p:  tensor(-0.0759, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0544, device='cuda:0') mean:  tensor(-3.5567e-05, device='cuda:0') min:  tensor(-0.0530, device='cuda:0') norm:  tensor(0.4600, device='cuda:0') MSE:  tensor(1.7268e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.2764e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0016, device='cuda:0') MSE:  tensor(6.1718e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  368  
Training Loss: 0.054573968052864075
Test Loss:  0.038050033152103424
Test Acc:  0.0
Valid Loss:  0.04000682756304741
Valid Acc:  0.0
std:  0.018630232321112432 
thres:  4.599368032068015e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 37%|███▋      | 368/1000 [17:10<27:40,  2.63s/it]Epoch:   369
max of grad d_p:  tensor(0.2819, device='cuda:0')
min of grad d_p:  tensor(-0.0755, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0431, device='cuda:0') mean:  tensor(-3.3669e-05, device='cuda:0') min:  tensor(-0.0458, device='cuda:0') norm:  tensor(0.3977, device='cuda:0') MSE:  tensor(1.4930e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(7.8372e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(3.9906e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0023, device='cuda:0')
Epoch:  369  
Training Loss: 0.05409958213567734
Test Loss:  0.037679482251405716
Test Acc:  0.0
Valid Loss:  0.03961596637964249
Valid Acc:  0.0
std:  0.000687002566421103 
thres:  5.506438463926315e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 37%|███▋      | 369/1000 [17:13<27:52,  2.65s/it]Epoch:   370
max of grad d_p:  tensor(0.2805, device='cuda:0')
min of grad d_p:  tensor(-0.0753, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0508, device='cuda:0') mean:  tensor(-3.7166e-05, device='cuda:0') min:  tensor(-0.0537, device='cuda:0') norm:  tensor(0.4518, device='cuda:0') MSE:  tensor(1.6959e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.0216e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0014, device='cuda:0') MSE:  tensor(5.4327e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  370  
Training Loss: 0.053625624626874924
Test Loss:  0.03730473667383194
Test Acc:  0.0
Valid Loss:  0.03922191262245178
Valid Acc:  0.0
std:  0.0006793196110262942 
thres:  5.458117723464966e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 37%|███▋      | 370/1000 [17:15<27:49,  2.65s/it]Epoch:   371
max of grad d_p:  tensor(0.2791, device='cuda:0')
min of grad d_p:  tensor(-0.0750, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0518, device='cuda:0') mean:  tensor(-3.7692e-05, device='cuda:0') min:  tensor(-0.0515, device='cuda:0') norm:  tensor(0.4568, device='cuda:0') MSE:  tensor(1.7149e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.5744e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.4232e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0007, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  371  
Training Loss: 0.05315510928630829
Test Loss:  0.03693026304244995
Test Acc:  0.0
Valid Loss:  0.038826487958431244
Valid Acc:  0.0
std:  0.0006726843762071591 
thres:  5.410269647836685e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 37%|███▋      | 371/1000 [17:18<29:22,  2.80s/it]Epoch:   372
max of grad d_p:  tensor(0.2777, device='cuda:0')
min of grad d_p:  tensor(-0.0747, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0489, device='cuda:0') mean:  tensor(-3.5434e-05, device='cuda:0') min:  tensor(-0.0482, device='cuda:0') norm:  tensor(0.4257, device='cuda:0') MSE:  tensor(1.5979e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.7013e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0021, device='cuda:0') MSE:  tensor(7.7401e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0017, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  372  
Training Loss: 0.05268906056880951
Test Loss:  0.03656301274895668
Test Acc:  0.0
Valid Loss:  0.038439035415649414
Valid Acc:  0.0
std:  0.0006667055654939312 
thres:  5.3628668934106826e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 37%|███▋      | 372/1000 [17:22<30:25,  2.91s/it]Epoch:   373
max of grad d_p:  tensor(0.2763, device='cuda:0')
min of grad d_p:  tensor(-0.0743, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0526, device='cuda:0') mean:  tensor(-3.7095e-05, device='cuda:0') min:  tensor(-0.0515, device='cuda:0') norm:  tensor(0.4570, device='cuda:0') MSE:  tensor(1.7153e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.1762e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.0927e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0031, device='cuda:0')
Epoch:  373  
Training Loss: 0.05222699046134949
Test Loss:  0.03621159493923187
Test Acc:  0.0
Valid Loss:  0.038068465888500214
Valid Acc:  0.0
std:  0.0006621076814773725 
thres:  5.315927341580391e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 37%|███▋      | 373/1000 [17:24<30:08,  2.88s/it]Epoch:   374
max of grad d_p:  tensor(0.2750, device='cuda:0')
min of grad d_p:  tensor(-0.0740, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0529, device='cuda:0') mean:  tensor(-3.7928e-05, device='cuda:0') min:  tensor(-0.0574, device='cuda:0') norm:  tensor(0.4775, device='cuda:0') MSE:  tensor(1.7925e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(2.8763e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.6553e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0060, device='cuda:0')
min of d_p_list:  tensor(-0.0060, device='cuda:0')
Epoch:  374  
Training Loss: 0.05179324001073837
Test Loss:  0.03586333617568016
Test Acc:  0.0
Valid Loss:  0.03770815581083298
Valid Acc:  0.0
std:  0.0006496086337154166 
thres:  5.269800499081612e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 37%|███▋      | 374/1000 [17:27<29:04,  2.79s/it]Epoch:   375
max of grad d_p:  tensor(0.2737, device='cuda:0')
min of grad d_p:  tensor(-0.0737, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0552, device='cuda:0') mean:  tensor(-3.9077e-05, device='cuda:0') min:  tensor(-0.0543, device='cuda:0') norm:  tensor(0.4875, device='cuda:0') MSE:  tensor(1.8298e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(5.7675e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.8118e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0017, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  375  
Training Loss: 0.05134101212024689
Test Loss:  0.0354948528110981
Test Acc:  0.0
Valid Loss:  0.03732394054532051
Valid Acc:  0.0
std:  0.0006398464636885392 
thres:  5.2241082489490516e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 38%|███▊      | 375/1000 [17:30<29:07,  2.80s/it]Epoch:   376
max of grad d_p:  tensor(0.2723, device='cuda:0')
min of grad d_p:  tensor(-0.0733, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0525, device='cuda:0') mean:  tensor(-3.6309e-05, device='cuda:0') min:  tensor(-0.0490, device='cuda:0') norm:  tensor(0.4538, device='cuda:0') MSE:  tensor(1.7033e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(4.4016e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.4033e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0018, device='cuda:0')
min of d_p_list:  tensor(-0.0040, device='cuda:0')
Epoch:  376  
Training Loss: 0.05089253932237625
Test Loss:  0.03514014929533005
Test Acc:  0.0
Valid Loss:  0.036949239671230316
Valid Acc:  0.0
std:  0.0006334503303978528 
thres:  5.1788568496704105e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 38%|███▊      | 376/1000 [17:33<29:50,  2.87s/it]Epoch:   377
max of grad d_p:  tensor(0.2709, device='cuda:0')
min of grad d_p:  tensor(-0.0730, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0473, device='cuda:0') mean:  tensor(-3.6201e-05, device='cuda:0') min:  tensor(-0.0483, device='cuda:0') norm:  tensor(0.4326, device='cuda:0') MSE:  tensor(1.6239e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(3.6433e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(2.0027e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0104, device='cuda:0')
min of d_p_list:  tensor(-0.0104, device='cuda:0')
Epoch:  377  
Training Loss: 0.05043919384479523
Test Loss:  0.034705184400081635
Test Acc:  0.0
Valid Loss:  0.0364963598549366
Valid Acc:  0.0
std:  0.0006330627977586264 
thres:  5.133859515190124e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 38%|███▊      | 377/1000 [17:36<29:10,  2.81s/it]Epoch:   378
max of grad d_p:  tensor(0.2695, device='cuda:0')
min of grad d_p:  tensor(-0.0732, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0543, device='cuda:0') mean:  tensor(-3.9119e-05, device='cuda:0') min:  tensor(-0.0557, device='cuda:0') norm:  tensor(0.4741, device='cuda:0') MSE:  tensor(1.7798e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.2592e-05, device='cuda:0') mean:  tensor(2.7074e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5082e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0009, device='cuda:0')
Epoch:  378  
Training Loss: 0.05000022053718567
Test Loss:  0.03435317799448967
Test Acc:  0.0
Valid Loss:  0.03612525761127472
Valid Acc:  0.0
std:  0.0006346876482118144 
thres:  5.089324116706848e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 38%|███▊      | 378/1000 [17:38<28:41,  2.77s/it]Epoch:   379
max of grad d_p:  tensor(0.2682, device='cuda:0')
min of grad d_p:  tensor(-0.0728, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0549, device='cuda:0') mean:  tensor(-3.9639e-05, device='cuda:0') min:  tensor(-0.0523, device='cuda:0') norm:  tensor(0.4897, device='cuda:0') MSE:  tensor(1.8383e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.0687e-05, device='cuda:0') mean:  tensor(2.7602e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4298e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0008, device='cuda:0')
Epoch:  379  
Training Loss: 0.049568332731723785
Test Loss:  0.034003764390945435
Test Acc:  0.0
Valid Loss:  0.0357600636780262
Valid Acc:  0.0
std:  0.0006276119848060885 
thres:  5.0448259711265564e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 38%|███▊      | 379/1000 [17:41<28:11,  2.72s/it]Epoch:   380
max of grad d_p:  tensor(0.2668, device='cuda:0')
min of grad d_p:  tensor(-0.0725, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0564, device='cuda:0') mean:  tensor(-3.8531e-05, device='cuda:0') min:  tensor(-0.0559, device='cuda:0') norm:  tensor(0.4796, device='cuda:0') MSE:  tensor(1.8003e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.4809e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(3.1733e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0007, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  380  
Training Loss: 0.049137722700834274
Test Loss:  0.033662065863609314
Test Acc:  0.0
Valid Loss:  0.035399794578552246
Valid Acc:  0.0
std:  0.0006195300729085396 
thres:  5.0007601827383045e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 38%|███▊      | 380/1000 [17:44<28:04,  2.72s/it]Epoch:   381
max of grad d_p:  tensor(0.2655, device='cuda:0')
min of grad d_p:  tensor(-0.0721, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0533, device='cuda:0') mean:  tensor(-3.6962e-05, device='cuda:0') min:  tensor(-0.0544, device='cuda:0') norm:  tensor(0.4679, device='cuda:0') MSE:  tensor(1.7563e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(3.9625e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.1951e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0027, device='cuda:0')
Epoch:  381  
Training Loss: 0.048712968826293945
Test Loss:  0.0333251990377903
Test Acc:  0.0
Valid Loss:  0.03504517301917076
Valid Acc:  0.0
std:  0.000610236394223732 
thres:  4.957168772816658e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 38%|███▊      | 381/1000 [17:46<28:10,  2.73s/it]Epoch:   382
max of grad d_p:  tensor(0.2642, device='cuda:0')
min of grad d_p:  tensor(-0.0719, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0501, device='cuda:0') mean:  tensor(-3.9483e-05, device='cuda:0') min:  tensor(-0.0544, device='cuda:0') norm:  tensor(0.4734, device='cuda:0') MSE:  tensor(1.7770e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0012, device='cuda:0') mean:  tensor(4.4897e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0062, device='cuda:0') MSE:  tensor(2.3106e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0005, device='cuda:0')
min of d_p_list:  tensor(-0.0003, device='cuda:0')
Epoch:  382  
Training Loss: 0.048292312771081924
Test Loss:  0.03299177065491676
Test Acc:  0.0
Valid Loss:  0.03469441831111908
Valid Acc:  0.0
std:  0.0006040456992098335 
thres:  4.914231151342392e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 38%|███▊      | 382/1000 [17:49<28:48,  2.80s/it]Epoch:   383
max of grad d_p:  tensor(0.2629, device='cuda:0')
min of grad d_p:  tensor(-0.0716, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0536, device='cuda:0') mean:  tensor(-3.8247e-05, device='cuda:0') min:  tensor(-0.0530, device='cuda:0') norm:  tensor(0.4677, device='cuda:0') MSE:  tensor(1.7557e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.0708e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(2.0458e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0037, device='cuda:0')
min of d_p_list:  tensor(-0.0023, device='cuda:0')
Epoch:  383  
Training Loss: 0.04787503182888031
Test Loss:  0.03267546743154526
Test Acc:  0.0
Valid Loss:  0.034361448138952255
Valid Acc:  0.0
std:  0.0005985082339104244 
thres:  4.871727377176285e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 38%|███▊      | 383/1000 [17:52<28:30,  2.77s/it]Epoch:   384
max of grad d_p:  tensor(0.2616, device='cuda:0')
min of grad d_p:  tensor(-0.0712, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0549, device='cuda:0') mean:  tensor(-3.9854e-05, device='cuda:0') min:  tensor(-0.0545, device='cuda:0') norm:  tensor(0.4840, device='cuda:0') MSE:  tensor(1.8167e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.0890e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0014, device='cuda:0') MSE:  tensor(5.3318e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0006, device='cuda:0')
Epoch:  384  
Training Loss: 0.0474628284573555
Test Loss:  0.032349228858947754
Test Acc:  0.0
Valid Loss:  0.03401719406247139
Valid Acc:  0.0
std:  0.0005922436278973393 
thres:  4.829617291688919e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 38%|███▊      | 384/1000 [17:55<29:14,  2.85s/it]Epoch:   385
max of grad d_p:  tensor(0.2603, device='cuda:0')
min of grad d_p:  tensor(-0.0709, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0526, device='cuda:0') mean:  tensor(-3.8017e-05, device='cuda:0') min:  tensor(-0.0503, device='cuda:0') norm:  tensor(0.4592, device='cuda:0') MSE:  tensor(1.7238e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0092, device='cuda:0') mean:  tensor(5.3985e-05, device='cuda:0') min:  tensor(4.3656e-11, device='cuda:0') norm:  tensor(0.0666, device='cuda:0') MSE:  tensor(2.4983e-07, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  385  
Training Loss: 0.04705600440502167
Test Loss:  0.032018791884183884
Test Acc:  0.0
Valid Loss:  0.0336688794195652
Valid Acc:  0.0
std:  0.0005859802488600639 
thres:  4.7879829257726675e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 38%|███▊      | 385/1000 [17:58<30:11,  2.95s/it]Epoch:   386
max of grad d_p:  tensor(0.2590, device='cuda:0')
min of grad d_p:  tensor(-0.0705, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0510, device='cuda:0') mean:  tensor(-3.4812e-05, device='cuda:0') min:  tensor(-0.0507, device='cuda:0') norm:  tensor(0.4308, device='cuda:0') MSE:  tensor(1.6173e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(4.5562e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.5651e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0043, device='cuda:0')
min of d_p_list:  tensor(-0.0045, device='cuda:0')
Epoch:  386  
Training Loss: 0.04666765779256821
Test Loss:  0.031674474477767944
Test Acc:  0.0
Valid Loss:  0.03331702947616577
Valid Acc:  0.0
std:  0.0005754029780191286 
thres:  4.747076705098152e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 39%|███▊      | 386/1000 [18:01<29:29,  2.88s/it]Epoch:   387
max of grad d_p:  tensor(0.2577, device='cuda:0')
min of grad d_p:  tensor(-0.0699, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0530, device='cuda:0') mean:  tensor(-3.7241e-05, device='cuda:0') min:  tensor(-0.0516, device='cuda:0') norm:  tensor(0.4479, device='cuda:0') MSE:  tensor(1.6814e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(5.6013e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.9747e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  387  
Training Loss: 0.04626678675413132
Test Loss:  0.0313643142580986
Test Acc:  0.0
Valid Loss:  0.03298937529325485
Valid Acc:  0.0
std:  0.000567366370431993 
thres:  4.7065661847591405e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 39%|███▊      | 387/1000 [18:04<29:02,  2.84s/it]Epoch:   388
max of grad d_p:  tensor(0.2564, device='cuda:0')
min of grad d_p:  tensor(-0.0695, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0521, device='cuda:0') mean:  tensor(-3.7480e-05, device='cuda:0') min:  tensor(-0.0504, device='cuda:0') norm:  tensor(0.4526, device='cuda:0') MSE:  tensor(1.6991e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.2988e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0018, device='cuda:0') MSE:  tensor(6.8996e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  388  
Training Loss: 0.045869700610637665
Test Loss:  0.03105698898434639
Test Acc:  0.0
Valid Loss:  0.03266299143433571
Valid Acc:  0.0
std:  0.0005622269730630966 
thres:  4.6664595603942874e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 39%|███▉      | 388/1000 [18:06<28:17,  2.77s/it]Epoch:   389
max of grad d_p:  tensor(0.2551, device='cuda:0')
min of grad d_p:  tensor(-0.0692, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0552, device='cuda:0') mean:  tensor(-3.9987e-05, device='cuda:0') min:  tensor(-0.0538, device='cuda:0') norm:  tensor(0.4791, device='cuda:0') MSE:  tensor(1.7984e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(5.6001e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.9891e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  389  
Training Loss: 0.04547804594039917
Test Loss:  0.03074434958398342
Test Acc:  0.0
Valid Loss:  0.032334715127944946
Valid Acc:  0.0
std:  0.0005591686568583335 
thres:  4.626763910055161e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 39%|███▉      | 389/1000 [18:09<28:08,  2.76s/it]Epoch:   390
max of grad d_p:  tensor(0.2539, device='cuda:0')
min of grad d_p:  tensor(-0.0689, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0525, device='cuda:0') mean:  tensor(-3.6206e-05, device='cuda:0') min:  tensor(-0.0566, device='cuda:0') norm:  tensor(0.4568, device='cuda:0') MSE:  tensor(1.7146e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.9829e-05, device='cuda:0') mean:  tensor(4.6118e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2045e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  390  
Training Loss: 0.04508885741233826
Test Loss:  0.030439531430602074
Test Acc:  0.0
Valid Loss:  0.03201208636164665
Valid Acc:  0.0
std:  0.000558107676183373 
thres:  4.587420970201492e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 39%|███▉      | 390/1000 [18:12<28:35,  2.81s/it]Epoch:   391
max of grad d_p:  tensor(0.2526, device='cuda:0')
min of grad d_p:  tensor(-0.0687, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0506, device='cuda:0') mean:  tensor(-3.6351e-05, device='cuda:0') min:  tensor(-0.0479, device='cuda:0') norm:  tensor(0.4403, device='cuda:0') MSE:  tensor(1.6529e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(2.9995e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.6519e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  391  
Training Loss: 0.04470381140708923
Test Loss:  0.03013387694954872
Test Acc:  0.0
Valid Loss:  0.03169087693095207
Valid Acc:  0.0
std:  0.0005525132871315528 
thres:  4.5481440424919124e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 39%|███▉      | 391/1000 [18:15<28:40,  2.82s/it]Epoch:   392
max of grad d_p:  tensor(0.2513, device='cuda:0')
min of grad d_p:  tensor(-0.0683, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0555, device='cuda:0') mean:  tensor(-3.6263e-05, device='cuda:0') min:  tensor(-0.0517, device='cuda:0') norm:  tensor(0.4661, device='cuda:0') MSE:  tensor(1.7496e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(7.7553e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.1800e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  392  
Training Loss: 0.04432249814271927
Test Loss:  0.029832761734724045
Test Acc:  0.0
Valid Loss:  0.03137531876564026
Valid Acc:  0.0
std:  0.0005471163273116257 
thres:  4.509258270263672e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 39%|███▉      | 392/1000 [18:18<28:53,  2.85s/it]Epoch:   393
max of grad d_p:  tensor(0.2501, device='cuda:0')
min of grad d_p:  tensor(-0.0680, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0507, device='cuda:0') mean:  tensor(-3.8772e-05, device='cuda:0') min:  tensor(-0.0527, device='cuda:0') norm:  tensor(0.4649, device='cuda:0') MSE:  tensor(1.7449e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.4466e-05, device='cuda:0') mean:  tensor(3.5933e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8570e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0103, device='cuda:0')
min of d_p_list:  tensor(-0.0139, device='cuda:0')
Epoch:  393  
Training Loss: 0.04394659399986267
Test Loss:  0.029570069164037704
Test Acc:  0.0
Valid Loss:  0.03109944984316826
Valid Acc:  0.0
std:  0.0005415517398593584 
thres:  4.4707961380481724e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 39%|███▉      | 393/1000 [18:21<29:08,  2.88s/it]Epoch:   394
max of grad d_p:  tensor(0.2489, device='cuda:0')
min of grad d_p:  tensor(-0.0669, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0470, device='cuda:0') mean:  tensor(-3.5189e-05, device='cuda:0') min:  tensor(-0.0441, device='cuda:0') norm:  tensor(0.4173, device='cuda:0') MSE:  tensor(1.5664e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.8877e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.8019e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  394  
Training Loss: 0.04357229918241501
Test Loss:  0.02927689626812935
Test Acc:  0.0
Valid Loss:  0.03078998439013958
Valid Acc:  0.0
std:  0.000536043970641313 
thres:  4.432681202888489e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 39%|███▉      | 394/1000 [18:24<29:54,  2.96s/it]Epoch:   395
max of grad d_p:  tensor(0.2477, device='cuda:0')
min of grad d_p:  tensor(-0.0666, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0542, device='cuda:0') mean:  tensor(-3.8446e-05, device='cuda:0') min:  tensor(-0.0511, device='cuda:0') norm:  tensor(0.4653, device='cuda:0') MSE:  tensor(1.7465e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(1.9777e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0025, device='cuda:0') MSE:  tensor(9.3890e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  395  
Training Loss: 0.043201059103012085
Test Loss:  0.02898354083299637
Test Acc:  0.0
Valid Loss:  0.030479149892926216
Valid Acc:  0.0
std:  0.0005311432357912803 
thres:  4.394925236701965e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 40%|███▉      | 395/1000 [18:27<29:08,  2.89s/it]Epoch:   396
max of grad d_p:  tensor(0.2464, device='cuda:0')
min of grad d_p:  tensor(-0.0663, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0444, device='cuda:0') mean:  tensor(-3.4462e-05, device='cuda:0') min:  tensor(-0.0422, device='cuda:0') norm:  tensor(0.4107, device='cuda:0') MSE:  tensor(1.5416e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0038, device='cuda:0') mean:  tensor(1.0595e-05, device='cuda:0') min:  tensor(1.4552e-11, device='cuda:0') norm:  tensor(0.0147, device='cuda:0') MSE:  tensor(5.5284e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0017, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  396  
Training Loss: 0.04283568263053894
Test Loss:  0.028709637001156807
Test Acc:  0.0
Valid Loss:  0.030191771686077118
Valid Acc:  0.0
std:  0.0005259777319495753 
thres:  4.357562661170959e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 40%|███▉      | 396/1000 [18:29<28:47,  2.86s/it]Epoch:   397
max of grad d_p:  tensor(0.2452, device='cuda:0')
min of grad d_p:  tensor(-0.0660, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0462, device='cuda:0') mean:  tensor(-3.4487e-05, device='cuda:0') min:  tensor(-0.0471, device='cuda:0') norm:  tensor(0.4049, device='cuda:0') MSE:  tensor(1.5197e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.9993e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9196e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  397  
Training Loss: 0.042471885681152344
Test Loss:  0.02840503677725792
Test Acc:  0.0
Valid Loss:  0.029870979487895966
Valid Acc:  0.0
std:  0.0005212938775599402 
thres:  4.320550411939621e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 40%|███▉      | 397/1000 [18:32<29:26,  2.93s/it]Epoch:   398
max of grad d_p:  tensor(0.2440, device='cuda:0')
min of grad d_p:  tensor(-0.0656, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0452, device='cuda:0') mean:  tensor(-3.5176e-05, device='cuda:0') min:  tensor(-0.0424, device='cuda:0') norm:  tensor(0.4097, device='cuda:0') MSE:  tensor(1.5380e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0010, device='cuda:0') mean:  tensor(3.0057e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0044, device='cuda:0') MSE:  tensor(1.6426e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0257, device='cuda:0')
min of d_p_list:  tensor(-0.0239, device='cuda:0')
Epoch:  398  
Training Loss: 0.04223647713661194
Test Loss:  0.028219224885106087
Test Acc:  0.0
Valid Loss:  0.02968022972345352
Valid Acc:  0.0
std:  0.000482418009437185 
thres:  4.286348074674606e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 40%|███▉      | 398/1000 [18:35<29:13,  2.91s/it]Epoch:   399
max of grad d_p:  tensor(0.2435, device='cuda:0')
min of grad d_p:  tensor(-0.0650, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0547, device='cuda:0') mean:  tensor(-3.9534e-05, device='cuda:0') min:  tensor(-0.0526, device='cuda:0') norm:  tensor(0.4886, device='cuda:0') MSE:  tensor(1.8341e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(4.4240e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.5767e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0073, device='cuda:0')
min of d_p_list:  tensor(-0.0211, device='cuda:0')
Epoch:  399  
Training Loss: 0.04192786663770676
Test Loss:  0.02799845114350319
Test Acc:  0.0
Valid Loss:  0.029426809400320053
Valid Acc:  0.0
std:  0.0004462631928843769 
thres:  4.253459423780441e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 40%|███▉      | 399/1000 [18:38<28:47,  2.87s/it]Epoch:   400
max of grad d_p:  tensor(0.2425, device='cuda:0')
min of grad d_p:  tensor(-0.0643, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0489, device='cuda:0') mean:  tensor(-3.4177e-05, device='cuda:0') min:  tensor(-0.0431, device='cuda:0') norm:  tensor(0.4084, device='cuda:0') MSE:  tensor(1.5329e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(9.8621e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.7172e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0025, device='cuda:0')
Epoch:  400  
Training Loss: 0.04157290980219841
Test Loss:  0.027709197252988815
Test Acc:  0.0
Valid Loss:  0.029121162369847298
Valid Acc:  0.0
std:  0.00043502682551753907 
thres:  4.2208964377641674e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 40%|████      | 400/1000 [18:41<28:40,  2.87s/it]Epoch:   401
max of grad d_p:  tensor(0.2413, device='cuda:0')
min of grad d_p:  tensor(-0.0640, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0582, device='cuda:0') mean:  tensor(-3.9905e-05, device='cuda:0') min:  tensor(-0.0503, device='cuda:0') norm:  tensor(0.4909, device='cuda:0') MSE:  tensor(1.8429e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0024, device='cuda:0') mean:  tensor(7.4002e-06, device='cuda:0') min:  tensor(7.2760e-12, device='cuda:0') norm:  tensor(0.0111, device='cuda:0') MSE:  tensor(4.1575e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0087, device='cuda:0')
min of d_p_list:  tensor(-0.0131, device='cuda:0')
Epoch:  401  
Training Loss: 0.04123073071241379
Test Loss:  0.027439814060926437
Test Acc:  0.0
Valid Loss:  0.028842849656939507
Valid Acc:  0.0
std:  0.00044614636566293127 
thres:  4.188797399401665e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 40%|████      | 401/1000 [18:44<28:45,  2.88s/it]Epoch:   402
max of grad d_p:  tensor(0.2402, device='cuda:0')
min of grad d_p:  tensor(-0.0636, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0496, device='cuda:0') mean:  tensor(-3.5673e-05, device='cuda:0') min:  tensor(-0.0451, device='cuda:0') norm:  tensor(0.4400, device='cuda:0') MSE:  tensor(1.6515e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0031, device='cuda:0') mean:  tensor(1.0411e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0142, device='cuda:0') MSE:  tensor(5.3484e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  402  
Training Loss: 0.040884315967559814
Test Loss:  0.027159597724676132
Test Acc:  0.0
Valid Loss:  0.028548823669552803
Valid Acc:  0.0
std:  0.0004811515259386644 
thres:  4.157046005129815e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 40%|████      | 402/1000 [18:47<28:40,  2.88s/it]Epoch:   403
max of grad d_p:  tensor(0.2390, device='cuda:0')
min of grad d_p:  tensor(-0.0633, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0485, device='cuda:0') mean:  tensor(-3.2323e-05, device='cuda:0') min:  tensor(-0.0473, device='cuda:0') norm:  tensor(0.3919, device='cuda:0') MSE:  tensor(1.4711e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.1630e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(3.0213e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0089, device='cuda:0')
min of d_p_list:  tensor(-0.0102, device='cuda:0')
Epoch:  403  
Training Loss: 0.0405716709792614
Test Loss:  0.026850318536162376
Test Acc:  0.0
Valid Loss:  0.02820386365056038
Valid Acc:  0.0
std:  0.0004810860419395277 
thres:  4.123749881982804e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 40%|████      | 403/1000 [18:49<27:52,  2.80s/it]Epoch:   404
max of grad d_p:  tensor(0.2380, device='cuda:0')
min of grad d_p:  tensor(-0.0627, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0601, device='cuda:0') mean:  tensor(-4.0789e-05, device='cuda:0') min:  tensor(-0.0555, device='cuda:0') norm:  tensor(0.5202, device='cuda:0') MSE:  tensor(1.9528e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.8418e-05, device='cuda:0') mean:  tensor(2.6620e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.3650e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  404  
Training Loss: 0.040230587124824524
Test Loss:  0.026576532050967216
Test Acc:  0.0
Valid Loss:  0.02791684865951538
Valid Acc:  0.0
std:  0.00047293356559827 
thres:  4.089804291725159e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 40%|████      | 404/1000 [18:52<27:46,  2.80s/it]Epoch:   405
max of grad d_p:  tensor(0.2368, device='cuda:0')
min of grad d_p:  tensor(-0.0624, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0524, device='cuda:0') mean:  tensor(-3.5074e-05, device='cuda:0') min:  tensor(-0.0437, device='cuda:0') norm:  tensor(0.4374, device='cuda:0') MSE:  tensor(1.6418e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.7358e-05, device='cuda:0') mean:  tensor(3.4513e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8141e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0020, device='cuda:0')
min of d_p_list:  tensor(-0.0034, device='cuda:0')
Epoch:  405  
Training Loss: 0.03989245370030403
Test Loss:  0.02631218358874321
Test Acc:  0.0
Valid Loss:  0.02763218805193901
Valid Acc:  0.0
std:  0.0004710219965377466 
thres:  4.056195169687271e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 40%|████      | 405/1000 [18:55<27:51,  2.81s/it]Epoch:   406
max of grad d_p:  tensor(0.2356, device='cuda:0')
min of grad d_p:  tensor(-0.0620, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0575, device='cuda:0') mean:  tensor(-4.0199e-05, device='cuda:0') min:  tensor(-0.0579, device='cuda:0') norm:  tensor(0.5078, device='cuda:0') MSE:  tensor(1.9060e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(4.6548e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.6098e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0016, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  406  
Training Loss: 0.03955845162272453
Test Loss:  0.026043377816677094
Test Acc:  0.0
Valid Loss:  0.02735116146504879
Valid Acc:  0.0
std:  0.0004711161560670463 
thres:  4.022749587893486e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 41%|████      | 406/1000 [18:58<28:15,  2.85s/it]Epoch:   407
max of grad d_p:  tensor(0.2345, device='cuda:0')
min of grad d_p:  tensor(-0.0617, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0524, device='cuda:0') mean:  tensor(-3.7685e-05, device='cuda:0') min:  tensor(-0.0488, device='cuda:0') norm:  tensor(0.4810, device='cuda:0') MSE:  tensor(1.8055e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.6958e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9431e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0032, device='cuda:0')
Epoch:  407  
Training Loss: 0.039227504283189774
Test Loss:  0.025781547650694847
Test Acc:  0.0
Valid Loss:  0.027073580771684647
Valid Acc:  0.0
std:  0.00047525103551353606 
thres:  3.989613354206086e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 41%|████      | 407/1000 [19:01<28:35,  2.89s/it]Epoch:   408
max of grad d_p:  tensor(0.2333, device='cuda:0')
min of grad d_p:  tensor(-0.0614, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0508, device='cuda:0') mean:  tensor(-3.5974e-05, device='cuda:0') min:  tensor(-0.0524, device='cuda:0') norm:  tensor(0.4537, device='cuda:0') MSE:  tensor(1.7032e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(2.7190e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4090e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0006, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  408  
Training Loss: 0.038900796324014664
Test Loss:  0.025526246055960655
Test Acc:  0.0
Valid Loss:  0.026804476976394653
Valid Acc:  0.0
std:  0.0004701698968761624 
thres:  3.956195861101151e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 41%|████      | 408/1000 [19:04<27:57,  2.83s/it]Epoch:   409
max of grad d_p:  tensor(0.2321, device='cuda:0')
min of grad d_p:  tensor(-0.0612, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0575, device='cuda:0') mean:  tensor(-3.8114e-05, device='cuda:0') min:  tensor(-0.0475, device='cuda:0') norm:  tensor(0.4864, device='cuda:0') MSE:  tensor(1.8260e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(1.5938e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0023, device='cuda:0') MSE:  tensor(8.6212e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0005, device='cuda:0')
min of d_p_list:  tensor(-0.0005, device='cuda:0')
Epoch:  409  
Training Loss: 0.03857896849513054
Test Loss:  0.025270553305745125
Test Acc:  0.0
Valid Loss:  0.02653762325644493
Valid Acc:  0.0
std:  0.0004645288620716969 
thres:  3.9231634885072714e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 41%|████      | 409/1000 [19:07<28:23,  2.88s/it]Epoch:   410
max of grad d_p:  tensor(0.2310, device='cuda:0')
min of grad d_p:  tensor(-0.0609, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0484, device='cuda:0') mean:  tensor(-3.5888e-05, device='cuda:0') min:  tensor(-0.0446, device='cuda:0') norm:  tensor(0.4314, device='cuda:0') MSE:  tensor(1.6194e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.1569e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7472e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0025, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  410  
Training Loss: 0.03825649619102478
Test Loss:  0.025023289024829865
Test Acc:  0.0
Valid Loss:  0.02627464383840561
Valid Acc:  0.0
std:  0.0004599734536080234 
thres:  3.890444338321686e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 41%|████      | 410/1000 [19:10<29:28,  3.00s/it]Epoch:   411
max of grad d_p:  tensor(0.2298, device='cuda:0')
min of grad d_p:  tensor(-0.0606, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0490, device='cuda:0') mean:  tensor(-3.5468e-05, device='cuda:0') min:  tensor(-0.0405, device='cuda:0') norm:  tensor(0.4295, device='cuda:0') MSE:  tensor(1.6123e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(9.1412e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.4413e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0008, device='cuda:0')
Epoch:  411  
Training Loss: 0.03793983906507492
Test Loss:  0.024777894839644432
Test Acc:  0.0
Valid Loss:  0.026018161326646805
Valid Acc:  0.0
std:  0.00045533093042278633 
thres:  3.8580720871686935e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 41%|████      | 411/1000 [19:12<28:17,  2.88s/it]Epoch:   412
max of grad d_p:  tensor(0.2287, device='cuda:0')
min of grad d_p:  tensor(-0.0604, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0561, device='cuda:0') mean:  tensor(-3.6926e-05, device='cuda:0') min:  tensor(-0.0481, device='cuda:0') norm:  tensor(0.4514, device='cuda:0') MSE:  tensor(1.6945e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(5.0928e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.6762e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  412  
Training Loss: 0.03762488067150116
Test Loss:  0.024529431015253067
Test Acc:  0.0
Valid Loss:  0.025754859670996666
Valid Acc:  0.0
std:  0.00045127652270995976 
thres:  3.826019614934921e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 41%|████      | 412/1000 [19:15<28:32,  2.91s/it]Epoch:   413
max of grad d_p:  tensor(0.2275, device='cuda:0')
min of grad d_p:  tensor(-0.0601, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0557, device='cuda:0') mean:  tensor(-3.6032e-05, device='cuda:0') min:  tensor(-0.0433, device='cuda:0') norm:  tensor(0.4547, device='cuda:0') MSE:  tensor(1.7067e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(8.2704e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.4312e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0057, device='cuda:0')
min of d_p_list:  tensor(-0.0052, device='cuda:0')
Epoch:  413  
Training Loss: 0.03731020539999008
Test Loss:  0.024279829114675522
Test Acc:  0.0
Valid Loss:  0.025487124919891357
Valid Acc:  0.0
std:  0.0004481897906723459 
thres:  3.7942077964544296e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 41%|████▏     | 413/1000 [19:18<27:48,  2.84s/it]Epoch:   414
max of grad d_p:  tensor(0.2264, device='cuda:0')
min of grad d_p:  tensor(-0.0597, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0514, device='cuda:0') mean:  tensor(-3.4085e-05, device='cuda:0') min:  tensor(-0.0426, device='cuda:0') norm:  tensor(0.4296, device='cuda:0') MSE:  tensor(1.6125e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.9694e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.3707e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0007, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  414  
Training Loss: 0.037002041935920715
Test Loss:  0.02403467707335949
Test Acc:  0.0
Valid Loss:  0.025229789316654205
Valid Acc:  0.0
std:  0.00044386240094117176 
thres:  3.7626692652702334e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 41%|████▏     | 414/1000 [19:21<28:42,  2.94s/it]Epoch:   415
max of grad d_p:  tensor(0.2253, device='cuda:0')
min of grad d_p:  tensor(-0.0594, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0511, device='cuda:0') mean:  tensor(-3.6186e-05, device='cuda:0') min:  tensor(-0.0448, device='cuda:0') norm:  tensor(0.4621, device='cuda:0') MSE:  tensor(1.7346e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.9809e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.7943e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0029, device='cuda:0')
Epoch:  415  
Training Loss: 0.036695871502161026
Test Loss:  0.02378802001476288
Test Acc:  0.0
Valid Loss:  0.024969493970274925
Valid Acc:  0.0
std:  0.0004399397204980822 
thres:  3.731456771492958e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 42%|████▏     | 415/1000 [19:24<29:14,  3.00s/it]Epoch:   416
max of grad d_p:  tensor(0.2242, device='cuda:0')
min of grad d_p:  tensor(-0.0590, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0537, device='cuda:0') mean:  tensor(-3.7515e-05, device='cuda:0') min:  tensor(-0.0453, device='cuda:0') norm:  tensor(0.4557, device='cuda:0') MSE:  tensor(1.7106e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.4205e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0017, device='cuda:0') MSE:  tensor(6.2851e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0036, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  416  
Training Loss: 0.036392100155353546
Test Loss:  0.023546911776065826
Test Acc:  0.0
Valid Loss:  0.024716554209589958
Valid Acc:  0.0
std:  0.0004355726756774671 
thres:  3.7005019932985305e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 42%|████▏     | 416/1000 [19:27<28:47,  2.96s/it]Epoch:   417
max of grad d_p:  tensor(0.2231, device='cuda:0')
min of grad d_p:  tensor(-0.0586, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0489, device='cuda:0') mean:  tensor(-3.6020e-05, device='cuda:0') min:  tensor(-0.0440, device='cuda:0') norm:  tensor(0.4177, device='cuda:0') MSE:  tensor(1.5678e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.0938e-05, device='cuda:0') mean:  tensor(2.4167e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.2917e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0016, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  417  
Training Loss: 0.03609272092580795
Test Loss:  0.023301299661397934
Test Acc:  0.0
Valid Loss:  0.024459121748805046
Valid Acc:  0.0
std:  0.00043062216038261883 
thres:  3.669858798384666e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 42%|████▏     | 417/1000 [19:30<28:41,  2.95s/it]Epoch:   418
max of grad d_p:  tensor(0.2219, device='cuda:0')
min of grad d_p:  tensor(-0.0582, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0510, device='cuda:0') mean:  tensor(-3.8519e-05, device='cuda:0') min:  tensor(-0.0523, device='cuda:0') norm:  tensor(0.4488, device='cuda:0') MSE:  tensor(1.6849e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.6031e-05, device='cuda:0') mean:  tensor(2.6792e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5127e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0004, device='cuda:0')
Epoch:  418  
Training Loss: 0.0357976034283638
Test Loss:  0.023075032979249954
Test Acc:  0.0
Valid Loss:  0.024221785366535187
Valid Acc:  0.0
std:  0.00042597689741067675 
thres:  3.639606758952141e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 42%|████▏     | 418/1000 [19:33<28:38,  2.95s/it]Epoch:   419
max of grad d_p:  tensor(0.2208, device='cuda:0')
min of grad d_p:  tensor(-0.0580, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0564, device='cuda:0') mean:  tensor(-3.7070e-05, device='cuda:0') min:  tensor(-0.0459, device='cuda:0') norm:  tensor(0.4527, device='cuda:0') MSE:  tensor(1.6993e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.6783e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(2.0043e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0039, device='cuda:0')
min of d_p_list:  tensor(-0.0070, device='cuda:0')
Epoch:  419  
Training Loss: 0.03550243377685547
Test Loss:  0.02284371107816696
Test Acc:  0.0
Valid Loss:  0.02396972104907036
Valid Acc:  0.0
std:  0.00042163803010091845 
thres:  3.6096145957708364e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 42%|████▏     | 419/1000 [19:36<28:34,  2.95s/it]Epoch:   420
max of grad d_p:  tensor(0.2197, device='cuda:0')
min of grad d_p:  tensor(-0.0575, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0602, device='cuda:0') mean:  tensor(-3.9757e-05, device='cuda:0') min:  tensor(-0.0473, device='cuda:0') norm:  tensor(0.4505, device='cuda:0') MSE:  tensor(1.6910e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.3994e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.7916e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0020, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  420  
Training Loss: 0.03521149605512619
Test Loss:  0.022623790428042412
Test Acc:  0.0
Valid Loss:  0.023738432675600052
Valid Acc:  0.0
std:  0.00041740957584955656 
thres:  3.579927086830139e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 42%|████▏     | 420/1000 [19:39<28:34,  2.96s/it]Epoch:   421
max of grad d_p:  tensor(0.2186, device='cuda:0')
min of grad d_p:  tensor(-0.0573, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0504, device='cuda:0') mean:  tensor(-3.5947e-05, device='cuda:0') min:  tensor(-0.0471, device='cuda:0') norm:  tensor(0.4159, device='cuda:0') MSE:  tensor(1.5611e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.1169e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0016, device='cuda:0') MSE:  tensor(5.8458e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0007, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  421  
Training Loss: 0.0349234901368618
Test Loss:  0.022395271807909012
Test Acc:  0.0
Valid Loss:  0.023496733978390694
Valid Acc:  0.0
std:  0.0004136027124538153 
thres:  3.550554886460304e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 42%|████▏     | 421/1000 [19:42<28:33,  2.96s/it]Epoch:   422
max of grad d_p:  tensor(0.2176, device='cuda:0')
min of grad d_p:  tensor(-0.0570, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0558, device='cuda:0') mean:  tensor(-3.6171e-05, device='cuda:0') min:  tensor(-0.0454, device='cuda:0') norm:  tensor(0.4676, device='cuda:0') MSE:  tensor(1.7552e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(8.6666e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.5273e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  422  
Training Loss: 0.03463973104953766
Test Loss:  0.022165708243846893
Test Acc:  0.0
Valid Loss:  0.023257020860910416
Valid Acc:  0.0
std:  0.00040938235478875894 
thres:  3.521495088934898e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 42%|████▏     | 422/1000 [19:45<28:38,  2.97s/it]Epoch:   423
max of grad d_p:  tensor(0.2165, device='cuda:0')
min of grad d_p:  tensor(-0.0567, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0534, device='cuda:0') mean:  tensor(-3.7816e-05, device='cuda:0') min:  tensor(-0.0528, device='cuda:0') norm:  tensor(0.4768, device='cuda:0') MSE:  tensor(1.7899e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(3.9236e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.5745e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0045, device='cuda:0')
min of d_p_list:  tensor(-0.0065, device='cuda:0')
Epoch:  423  
Training Loss: 0.034368157386779785
Test Loss:  0.02191341482102871
Test Acc:  0.0
Valid Loss:  0.022986266762018204
Valid Acc:  0.0
std:  0.00040171672100496487 
thres:  3.492906168103218e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 42%|████▏     | 423/1000 [19:48<28:08,  2.93s/it]Epoch:   424
max of grad d_p:  tensor(0.2154, device='cuda:0')
min of grad d_p:  tensor(-0.0561, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0571, device='cuda:0') mean:  tensor(-4.1052e-05, device='cuda:0') min:  tensor(-0.0440, device='cuda:0') norm:  tensor(0.4744, device='cuda:0') MSE:  tensor(1.7808e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.8289e-05, device='cuda:0') mean:  tensor(3.3125e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5712e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0017, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  424  
Training Loss: 0.03408904746174812
Test Loss:  0.021694928407669067
Test Acc:  0.0
Valid Loss:  0.022758129984140396
Valid Acc:  0.0
std:  0.00039603478959782687 
thres:  3.464638441801071e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 42%|████▏     | 424/1000 [19:51<27:43,  2.89s/it]Epoch:   425
max of grad d_p:  tensor(0.2144, device='cuda:0')
min of grad d_p:  tensor(-0.0558, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0619, device='cuda:0') mean:  tensor(-4.0149e-05, device='cuda:0') min:  tensor(-0.0494, device='cuda:0') norm:  tensor(0.5119, device='cuda:0') MSE:  tensor(1.9217e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(8.5240e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.2309e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0052, device='cuda:0')
min of d_p_list:  tensor(-0.0041, device='cuda:0')
Epoch:  425  
Training Loss: 0.033812642097473145
Test Loss:  0.021472331136465073
Test Acc:  0.0
Valid Loss:  0.022522415965795517
Valid Acc:  0.0
std:  0.00039208019295615745 
thres:  3.43666136264801e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 42%|████▎     | 425/1000 [19:54<27:46,  2.90s/it]Epoch:   426
max of grad d_p:  tensor(0.2133, device='cuda:0')
min of grad d_p:  tensor(-0.0553, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0562, device='cuda:0') mean:  tensor(-3.7490e-05, device='cuda:0') min:  tensor(-0.0454, device='cuda:0') norm:  tensor(0.4681, device='cuda:0') MSE:  tensor(1.7570e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.5439e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.8265e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0018, device='cuda:0')
min of d_p_list:  tensor(-0.0027, device='cuda:0')
Epoch:  426  
Training Loss: 0.033540789037942886
Test Loss:  0.021245788782835007
Test Acc:  0.0
Valid Loss:  0.0222844947129488
Valid Acc:  0.0
std:  0.0003893935608019572 
thres:  3.4090073406696324e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 43%|████▎     | 426/1000 [19:57<27:47,  2.91s/it]Epoch:   427
max of grad d_p:  tensor(0.2123, device='cuda:0')
min of grad d_p:  tensor(-0.0551, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0494, device='cuda:0') mean:  tensor(-3.5333e-05, device='cuda:0') min:  tensor(-0.0436, device='cuda:0') norm:  tensor(0.4330, device='cuda:0') MSE:  tensor(1.6253e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.8336e-05, device='cuda:0') mean:  tensor(2.0374e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.0904e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  427  
Training Loss: 0.033270180225372314
Test Loss:  0.021033521741628647
Test Acc:  0.0
Valid Loss:  0.022060522809624672
Valid Acc:  0.0
std:  0.00038809899212016616 
thres:  3.381616324186325e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 43%|████▎     | 427/1000 [19:59<27:22,  2.87s/it]Epoch:   428
max of grad d_p:  tensor(0.2112, device='cuda:0')
min of grad d_p:  tensor(-0.0548, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0514, device='cuda:0') mean:  tensor(-3.8123e-05, device='cuda:0') min:  tensor(-0.0441, device='cuda:0') norm:  tensor(0.4418, device='cuda:0') MSE:  tensor(1.6584e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.5067e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.2255e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0004, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  428  
Training Loss: 0.03300227224826813
Test Loss:  0.020820077508687973
Test Acc:  0.0
Valid Loss:  0.02183600142598152
Valid Acc:  0.0
std:  0.0003841085027788796 
thres:  3.3542986214160926e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 43%|████▎     | 428/1000 [20:02<27:17,  2.86s/it]Epoch:   429
max of grad d_p:  tensor(0.2102, device='cuda:0')
min of grad d_p:  tensor(-0.0545, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0636, device='cuda:0') mean:  tensor(-3.8784e-05, device='cuda:0') min:  tensor(-0.0522, device='cuda:0') norm:  tensor(0.5166, device='cuda:0') MSE:  tensor(1.9391e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.7134e-05, device='cuda:0') mean:  tensor(2.8478e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.3562e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0006, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  429  
Training Loss: 0.03273690491914749
Test Loss:  0.020606666803359985
Test Acc:  0.0
Valid Loss:  0.02161072939634323
Valid Acc:  0.0
std:  0.00038042686195564413 
thres:  3.327255770564079e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 43%|████▎     | 429/1000 [20:05<26:45,  2.81s/it]Epoch:   430
max of grad d_p:  tensor(0.2091, device='cuda:0')
min of grad d_p:  tensor(-0.0543, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0529, device='cuda:0') mean:  tensor(-3.6835e-05, device='cuda:0') min:  tensor(-0.0425, device='cuda:0') norm:  tensor(0.4426, device='cuda:0') MSE:  tensor(1.6613e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(8.0880e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.7684e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0007, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  430  
Training Loss: 0.03247378021478653
Test Loss:  0.020402375608682632
Test Acc:  0.0
Valid Loss:  0.02139403112232685
Valid Acc:  0.0
std:  0.0003772179974230751 
thres:  3.300478532910347e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 43%|████▎     | 430/1000 [20:08<26:47,  2.82s/it]Epoch:   431
max of grad d_p:  tensor(0.2081, device='cuda:0')
min of grad d_p:  tensor(-0.0540, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0535, device='cuda:0') mean:  tensor(-3.5527e-05, device='cuda:0') min:  tensor(-0.0427, device='cuda:0') norm:  tensor(0.4436, device='cuda:0') MSE:  tensor(1.6652e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(2.9473e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0036, device='cuda:0') MSE:  tensor(1.3524e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  431  
Training Loss: 0.032212790101766586
Test Loss:  0.020199913531541824
Test Acc:  0.0
Valid Loss:  0.021180301904678345
Valid Acc:  0.0
std:  0.00037382009502890306 
thres:  3.2739185541868205e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 43%|████▎     | 431/1000 [20:10<26:16,  2.77s/it]Epoch:   432
max of grad d_p:  tensor(0.2070, device='cuda:0')
min of grad d_p:  tensor(-0.0537, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0512, device='cuda:0') mean:  tensor(-3.7510e-05, device='cuda:0') min:  tensor(-0.0444, device='cuda:0') norm:  tensor(0.4537, device='cuda:0') MSE:  tensor(1.7030e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(2.8553e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7476e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  432  
Training Loss: 0.03195478767156601
Test Loss:  0.019993068650364876
Test Acc:  0.0
Valid Loss:  0.020961778238415718
Valid Acc:  0.0
std:  0.00037039991040503217 
thres:  3.247610703110695e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 43%|████▎     | 432/1000 [20:13<25:48,  2.73s/it]Epoch:   433
max of grad d_p:  tensor(0.2060, device='cuda:0')
min of grad d_p:  tensor(-0.0534, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0489, device='cuda:0') mean:  tensor(-3.6860e-05, device='cuda:0') min:  tensor(-0.0466, device='cuda:0') norm:  tensor(0.4156, device='cuda:0') MSE:  tensor(1.5600e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.6611e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.3804e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0007, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  433  
Training Loss: 0.031700313091278076
Test Loss:  0.01979205384850502
Test Acc:  0.0
Valid Loss:  0.020749835297465324
Valid Acc:  0.0
std:  0.00036659714678954187 
thres:  3.2215715199708934e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 43%|████▎     | 433/1000 [20:16<25:35,  2.71s/it]Epoch:   434
max of grad d_p:  tensor(0.2050, device='cuda:0')
min of grad d_p:  tensor(-0.0532, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0595, device='cuda:0') mean:  tensor(-4.1913e-05, device='cuda:0') min:  tensor(-0.0483, device='cuda:0') norm:  tensor(0.5024, device='cuda:0') MSE:  tensor(1.8858e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(7.2422e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.3598e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  434  
Training Loss: 0.03145114704966545
Test Loss:  0.01958240196108818
Test Acc:  0.0
Valid Loss:  0.020526796579360962
Valid Acc:  0.0
std:  0.0003617342706453589 
thres:  3.195856362581253e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 43%|████▎     | 434/1000 [20:18<25:15,  2.68s/it]Epoch:   435
max of grad d_p:  tensor(0.2039, device='cuda:0')
min of grad d_p:  tensor(-0.0530, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0557, device='cuda:0') mean:  tensor(-3.9676e-05, device='cuda:0') min:  tensor(-0.0469, device='cuda:0') norm:  tensor(0.4829, device='cuda:0') MSE:  tensor(1.8127e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.1352e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.2542e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0006, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  435  
Training Loss: 0.031201504170894623
Test Loss:  0.019381793215870857
Test Acc:  0.0
Valid Loss:  0.020315464586019516
Valid Acc:  0.0
std:  0.00035727077438575845 
thres:  3.170410841703415e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 44%|████▎     | 435/1000 [20:21<25:25,  2.70s/it]Epoch:   436
max of grad d_p:  tensor(0.2029, device='cuda:0')
min of grad d_p:  tensor(-0.0527, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0456, device='cuda:0') mean:  tensor(-3.5265e-05, device='cuda:0') min:  tensor(-0.0436, device='cuda:0') norm:  tensor(0.4109, device='cuda:0') MSE:  tensor(1.5424e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.5849e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0020, device='cuda:0') MSE:  tensor(7.4754e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0005, device='cuda:0')
min of d_p_list:  tensor(-0.0006, device='cuda:0')
Epoch:  436  
Training Loss: 0.030954238027334213
Test Loss:  0.01918676495552063
Test Acc:  0.0
Valid Loss:  0.02011065185070038
Valid Acc:  0.0
std:  0.0003535448801229895 
thres:  3.145239800214768e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 44%|████▎     | 436/1000 [20:24<25:37,  2.73s/it]Epoch:   437
max of grad d_p:  tensor(0.2019, device='cuda:0')
min of grad d_p:  tensor(-0.0525, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0462, device='cuda:0') mean:  tensor(-3.5480e-05, device='cuda:0') min:  tensor(-0.0509, device='cuda:0') norm:  tensor(0.4027, device='cuda:0') MSE:  tensor(1.5117e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(3.1246e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0039, device='cuda:0') MSE:  tensor(1.4817e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0027, device='cuda:0')
Epoch:  437  
Training Loss: 0.030707933008670807
Test Loss:  0.018996357917785645
Test Acc:  0.0
Valid Loss:  0.019906282424926758
Valid Acc:  0.0
std:  0.00035096249024744563 
thres:  3.120302706956863e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 44%|████▎     | 437/1000 [20:27<25:39,  2.73s/it]Epoch:   438
max of grad d_p:  tensor(0.2009, device='cuda:0')
min of grad d_p:  tensor(-0.0521, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0536, device='cuda:0') mean:  tensor(-3.5874e-05, device='cuda:0') min:  tensor(-0.0438, device='cuda:0') norm:  tensor(0.4484, device='cuda:0') MSE:  tensor(1.6831e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(5.0552e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.8337e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  438  
Training Loss: 0.030464548617601395
Test Loss:  0.018808072432875633
Test Acc:  0.0
Valid Loss:  0.01970980130136013
Valid Acc:  0.0
std:  0.0003488574544295957 
thres:  3.09558741748333e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 44%|████▍     | 438/1000 [20:29<25:16,  2.70s/it]Epoch:   439
max of grad d_p:  tensor(0.1999, device='cuda:0')
min of grad d_p:  tensor(-0.0518, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0549, device='cuda:0') mean:  tensor(-3.9472e-05, device='cuda:0') min:  tensor(-0.0512, device='cuda:0') norm:  tensor(0.4777, device='cuda:0') MSE:  tensor(1.7933e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(7.9137e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.6763e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0006, device='cuda:0')
Epoch:  439  
Training Loss: 0.03022470325231552
Test Loss:  0.01862037181854248
Test Acc:  0.0
Valid Loss:  0.01951274648308754
Valid Acc:  0.0
std:  0.00034554028342144265 
thres:  3.071058541536331e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 44%|████▍     | 439/1000 [20:32<25:00,  2.67s/it]Epoch:   440
max of grad d_p:  tensor(0.1989, device='cuda:0')
min of grad d_p:  tensor(-0.0516, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0553, device='cuda:0') mean:  tensor(-4.0004e-05, device='cuda:0') min:  tensor(-0.0436, device='cuda:0') norm:  tensor(0.4747, device='cuda:0') MSE:  tensor(1.7820e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0028, device='cuda:0') mean:  tensor(5.9645e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0092, device='cuda:0') MSE:  tensor(3.4682e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0029, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  440  
Training Loss: 0.029990121722221375
Test Loss:  0.018441135063767433
Test Acc:  0.0
Valid Loss:  0.019326116889715195
Valid Acc:  0.0
std:  0.0003410476971179966 
thres:  3.0468308925628663e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 44%|████▍     | 440/1000 [20:34<24:56,  2.67s/it]Epoch:   441
max of grad d_p:  tensor(0.1979, device='cuda:0')
min of grad d_p:  tensor(-0.0515, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0501, device='cuda:0') mean:  tensor(-3.6412e-05, device='cuda:0') min:  tensor(-0.0410, device='cuda:0') norm:  tensor(0.4273, device='cuda:0') MSE:  tensor(1.6039e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(5.0292e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.4594e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0025, device='cuda:0')
min of d_p_list:  tensor(-0.0035, device='cuda:0')
Epoch:  441  
Training Loss: 0.029753902927041054
Test Loss:  0.01825963333249092
Test Acc:  0.0
Valid Loss:  0.019140053540468216
Valid Acc:  0.0
std:  0.0003369438015105427 
thres:  3.022824190557003e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 44%|████▍     | 441/1000 [20:37<25:31,  2.74s/it]Epoch:   442
max of grad d_p:  tensor(0.1969, device='cuda:0')
min of grad d_p:  tensor(-0.0511, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0481, device='cuda:0') mean:  tensor(-3.7349e-05, device='cuda:0') min:  tensor(-0.0424, device='cuda:0') norm:  tensor(0.4442, device='cuda:0') MSE:  tensor(1.6674e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.0316e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.8236e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  442  
Training Loss: 0.02952214889228344
Test Loss:  0.018081506714224815
Test Acc:  0.0
Valid Loss:  0.018956268206238747
Valid Acc:  0.0
std:  0.0003331373956086778 
thres:  2.9991085082292555e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 44%|████▍     | 442/1000 [20:40<25:10,  2.71s/it]Epoch:   443
max of grad d_p:  tensor(0.1959, device='cuda:0')
min of grad d_p:  tensor(-0.0509, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0533, device='cuda:0') mean:  tensor(-3.7743e-05, device='cuda:0') min:  tensor(-0.0457, device='cuda:0') norm:  tensor(0.4555, device='cuda:0') MSE:  tensor(1.7100e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(1.6059e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0024, device='cuda:0') MSE:  tensor(9.1607e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0069, device='cuda:0')
min of d_p_list:  tensor(-0.0061, device='cuda:0')
Epoch:  443  
Training Loss: 0.02929556556046009
Test Loss:  0.017914537340402603
Test Acc:  0.0
Valid Loss:  0.018780775368213654
Valid Acc:  0.0
std:  0.00032899180238142616 
thres:  2.9757288470864295e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 44%|████▍     | 443/1000 [20:43<26:29,  2.85s/it]Epoch:   444
max of grad d_p:  tensor(0.1950, device='cuda:0')
min of grad d_p:  tensor(-0.0508, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0520, device='cuda:0') mean:  tensor(-3.7149e-05, device='cuda:0') min:  tensor(-0.0425, device='cuda:0') norm:  tensor(0.4472, device='cuda:0') MSE:  tensor(1.6786e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(8.1667e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.6158e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0009, device='cuda:0')
Epoch:  444  
Training Loss: 0.029067272320389748
Test Loss:  0.017736991867423058
Test Acc:  0.0
Valid Loss:  0.018594756722450256
Valid Acc:  0.0
std:  0.0003258510296843641 
thres:  2.9525802284479142e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 44%|████▍     | 444/1000 [20:46<27:18,  2.95s/it]Epoch:   445
max of grad d_p:  tensor(0.1940, device='cuda:0')
min of grad d_p:  tensor(-0.0505, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0567, device='cuda:0') mean:  tensor(-3.9566e-05, device='cuda:0') min:  tensor(-0.0445, device='cuda:0') norm:  tensor(0.4693, device='cuda:0') MSE:  tensor(1.7615e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.2712e-05, device='cuda:0') mean:  tensor(1.9829e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.0124e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  445  
Training Loss: 0.028840534389019012
Test Loss:  0.01755867339670658
Test Acc:  0.0
Valid Loss:  0.01840723119676113
Valid Acc:  0.0
std:  0.0003226712905366786 
thres:  2.929588481783867e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 44%|████▍     | 445/1000 [20:50<28:20,  3.06s/it]Epoch:   446
max of grad d_p:  tensor(0.1930, device='cuda:0')
min of grad d_p:  tensor(-0.0502, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0531, device='cuda:0') mean:  tensor(-3.6060e-05, device='cuda:0') min:  tensor(-0.0418, device='cuda:0') norm:  tensor(0.4355, device='cuda:0') MSE:  tensor(1.6346e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.3539e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.6745e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0044, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  446  
Training Loss: 0.028622211888432503
Test Loss:  0.017382748425006866
Test Acc:  0.0
Valid Loss:  0.018223468214273453
Valid Acc:  0.0
std:  0.00031890234077755074 
thres:  2.906954661011696e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 45%|████▍     | 446/1000 [20:52<26:57,  2.92s/it]Epoch:   447
max of grad d_p:  tensor(0.1921, device='cuda:0')
min of grad d_p:  tensor(-0.0502, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0586, device='cuda:0') mean:  tensor(-4.0298e-05, device='cuda:0') min:  tensor(-0.0501, device='cuda:0') norm:  tensor(0.5039, device='cuda:0') MSE:  tensor(1.8914e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0016, device='cuda:0') mean:  tensor(3.6783e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0055, device='cuda:0') MSE:  tensor(2.0764e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  447  
Training Loss: 0.028399433940649033
Test Loss:  0.017206929624080658
Test Acc:  0.0
Valid Loss:  0.018036585301160812
Valid Acc:  0.0
std:  0.00031641678406855685 
thres:  2.8845003619790078e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 45%|████▍     | 447/1000 [20:55<26:34,  2.88s/it]Epoch:   448
max of grad d_p:  tensor(0.1911, device='cuda:0')
min of grad d_p:  tensor(-0.0499, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0518, device='cuda:0') mean:  tensor(-3.6938e-05, device='cuda:0') min:  tensor(-0.0423, device='cuda:0') norm:  tensor(0.4450, device='cuda:0') MSE:  tensor(1.6704e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.3376e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.5890e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0028, device='cuda:0')
min of d_p_list:  tensor(-0.0034, device='cuda:0')
Epoch:  448  
Training Loss: 0.028178222477436066
Test Loss:  0.017027996480464935
Test Acc:  0.0
Valid Loss:  0.01785198785364628
Valid Acc:  0.0
std:  0.00031384640274621724 
thres:  2.8621535003185274e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 45%|████▍     | 448/1000 [20:58<26:17,  2.86s/it]Epoch:   449
max of grad d_p:  tensor(0.1902, device='cuda:0')
min of grad d_p:  tensor(-0.0496, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0639, device='cuda:0') mean:  tensor(-4.3692e-05, device='cuda:0') min:  tensor(-0.0515, device='cuda:0') norm:  tensor(0.5271, device='cuda:0') MSE:  tensor(1.9788e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.3289e-05, device='cuda:0') mean:  tensor(4.6584e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.3653e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  449  
Training Loss: 0.027960028499364853
Test Loss:  0.01686350256204605
Test Acc:  0.0
Valid Loss:  0.017678337171673775
Valid Acc:  0.0
std:  0.000311836221562606 
thres:  2.840008623898029e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 45%|████▍     | 449/1000 [21:01<25:43,  2.80s/it]Epoch:   450
max of grad d_p:  tensor(0.1892, device='cuda:0')
min of grad d_p:  tensor(-0.0494, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0560, device='cuda:0') mean:  tensor(-4.1965e-05, device='cuda:0') min:  tensor(-0.0465, device='cuda:0') norm:  tensor(0.4841, device='cuda:0') MSE:  tensor(1.8172e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0613, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(3.2014e-10, device='cuda:0') norm:  tensor(0.3398, device='cuda:0') MSE:  tensor(1.2755e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0039, device='cuda:0')
min of d_p_list:  tensor(-0.0069, device='cuda:0')
Epoch:  450  
Training Loss: 0.027742603793740273
Test Loss:  0.016684673726558685
Test Acc:  0.0
Valid Loss:  0.017485160380601883
Valid Acc:  0.0
std:  0.0003109364629337173 
thres:  2.8180500119924547e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 45%|████▌     | 450/1000 [21:03<25:22,  2.77s/it]Epoch:   451
max of grad d_p:  tensor(0.1883, device='cuda:0')
min of grad d_p:  tensor(-0.0490, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0545, device='cuda:0') mean:  tensor(-3.9553e-05, device='cuda:0') min:  tensor(-0.0442, device='cuda:0') norm:  tensor(0.4782, device='cuda:0') MSE:  tensor(1.7950e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.2288e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7585e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0004, device='cuda:0')
min of d_p_list:  tensor(-0.0009, device='cuda:0')
Epoch:  451  
Training Loss: 0.027529552578926086
Test Loss:  0.016515519469976425
Test Acc:  0.0
Valid Loss:  0.017307907342910767
Valid Acc:  0.0
std:  0.00030765238867005724 
thres:  2.7961968258023265e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 45%|████▌     | 451/1000 [21:06<26:41,  2.92s/it]Epoch:   452
max of grad d_p:  tensor(0.1874, device='cuda:0')
min of grad d_p:  tensor(-0.0488, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0551, device='cuda:0') mean:  tensor(-3.7470e-05, device='cuda:0') min:  tensor(-0.0464, device='cuda:0') norm:  tensor(0.4521, device='cuda:0') MSE:  tensor(1.6969e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.9718e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0025, device='cuda:0') MSE:  tensor(9.3030e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0022, device='cuda:0')
min of d_p_list:  tensor(-0.0025, device='cuda:0')
Epoch:  452  
Training Loss: 0.027317624539136887
Test Loss:  0.016354955732822418
Test Acc:  0.0
Valid Loss:  0.017139296978712082
Valid Acc:  0.0
std:  0.0003042992769051676 
thres:  2.7745606377720835e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 45%|████▌     | 452/1000 [21:09<25:40,  2.81s/it]Epoch:   453
max of grad d_p:  tensor(0.1864, device='cuda:0')
min of grad d_p:  tensor(-0.0486, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0561, device='cuda:0') mean:  tensor(-3.7937e-05, device='cuda:0') min:  tensor(-0.0516, device='cuda:0') norm:  tensor(0.4975, device='cuda:0') MSE:  tensor(1.8673e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(2.5639e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0034, device='cuda:0') MSE:  tensor(1.2798e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0073, device='cuda:0')
min of d_p_list:  tensor(-0.0057, device='cuda:0')
Epoch:  453  
Training Loss: 0.027111921459436417
Test Loss:  0.016196858137845993
Test Acc:  0.0
Valid Loss:  0.016969189047813416
Valid Acc:  0.0
std:  0.0002999968544354853 
thres:  2.7532346174120904e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 45%|████▌     | 453/1000 [21:12<26:47,  2.94s/it]Epoch:   454
max of grad d_p:  tensor(0.1856, device='cuda:0')
min of grad d_p:  tensor(-0.0485, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0485, device='cuda:0') mean:  tensor(-3.7069e-05, device='cuda:0') min:  tensor(-0.0407, device='cuda:0') norm:  tensor(0.4219, device='cuda:0') MSE:  tensor(1.5838e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(7.1106e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(3.9620e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0123, device='cuda:0')
min of d_p_list:  tensor(-0.0085, device='cuda:0')
Epoch:  454  
Training Loss: 0.026917479932308197
Test Loss:  0.016081001609563828
Test Acc:  0.0
Valid Loss:  0.016854040324687958
Valid Acc:  0.0
std:  0.00029249184071230454 
thres:  2.732383646070957e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 45%|████▌     | 454/1000 [21:15<26:21,  2.90s/it]Epoch:   455
max of grad d_p:  tensor(0.1847, device='cuda:0')
min of grad d_p:  tensor(-0.0480, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0493, device='cuda:0') mean:  tensor(-3.5829e-05, device='cuda:0') min:  tensor(-0.0443, device='cuda:0') norm:  tensor(0.4068, device='cuda:0') MSE:  tensor(1.5272e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.7745e-05, device='cuda:0') mean:  tensor(2.6810e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.2594e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0007, device='cuda:0')
Epoch:  455  
Training Loss: 0.026712648570537567
Test Loss:  0.015919744968414307
Test Acc:  0.0
Valid Loss:  0.016685819253325462
Valid Acc:  0.0
std:  0.000287673561501614 
thres:  2.711784541606903e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 46%|████▌     | 455/1000 [21:18<25:36,  2.82s/it]Epoch:   456
max of grad d_p:  tensor(0.1838, device='cuda:0')
min of grad d_p:  tensor(-0.0478, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0480, device='cuda:0') mean:  tensor(-3.8293e-05, device='cuda:0') min:  tensor(-0.0582, device='cuda:0') norm:  tensor(0.4527, device='cuda:0') MSE:  tensor(1.6991e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.0456e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0013, device='cuda:0') MSE:  tensor(4.9945e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  456  
Training Loss: 0.026509400457143784
Test Loss:  0.01575401984155178
Test Acc:  0.0
Valid Loss:  0.016510996967554092
Valid Acc:  0.0
std:  0.0002850757091417882 
thres:  2.6913814991712573e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 46%|████▌     | 456/1000 [21:20<25:26,  2.81s/it]Epoch:   457
max of grad d_p:  tensor(0.1829, device='cuda:0')
min of grad d_p:  tensor(-0.0475, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0552, device='cuda:0') mean:  tensor(-4.0357e-05, device='cuda:0') min:  tensor(-0.0443, device='cuda:0') norm:  tensor(0.4668, device='cuda:0') MSE:  tensor(1.7524e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(7.4168e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(3.9811e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  457  
Training Loss: 0.02630774676799774
Test Loss:  0.015597721561789513
Test Acc:  0.0
Valid Loss:  0.016344770789146423
Valid Acc:  0.0
std:  0.000285175987204775 
thres:  2.6711839437484742e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 46%|████▌     | 457/1000 [21:23<24:47,  2.74s/it]Epoch:   458
max of grad d_p:  tensor(0.1820, device='cuda:0')
min of grad d_p:  tensor(-0.0472, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0590, device='cuda:0') mean:  tensor(-4.1738e-05, device='cuda:0') min:  tensor(-0.0476, device='cuda:0') norm:  tensor(0.4986, device='cuda:0') MSE:  tensor(1.8715e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(3.0586e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8835e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  458  
Training Loss: 0.026108531281352043
Test Loss:  0.015442823059856892
Test Acc:  0.0
Valid Loss:  0.016181718558073044
Valid Acc:  0.0
std:  0.0002860711294287303 
thres:  2.6511161401867868e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 46%|████▌     | 458/1000 [21:26<26:05,  2.89s/it]Epoch:   459
max of grad d_p:  tensor(0.1811, device='cuda:0')
min of grad d_p:  tensor(-0.0470, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0502, device='cuda:0') mean:  tensor(-3.6769e-05, device='cuda:0') min:  tensor(-0.0464, device='cuda:0') norm:  tensor(0.4410, device='cuda:0') MSE:  tensor(1.6556e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(6.4815e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.5631e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0033, device='cuda:0')
min of d_p_list:  tensor(-0.0060, device='cuda:0')
Epoch:  459  
Training Loss: 0.025931742042303085
Test Loss:  0.015291290357708931
Test Acc:  0.0
Valid Loss:  0.016020316630601883
Valid Acc:  0.0
std:  0.00027766154359726243 
thres:  2.6314013823866845e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 46%|████▌     | 459/1000 [21:29<26:46,  2.97s/it]Epoch:   460
max of grad d_p:  tensor(0.1802, device='cuda:0')
min of grad d_p:  tensor(-0.0468, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0546, device='cuda:0') mean:  tensor(-3.7851e-05, device='cuda:0') min:  tensor(-0.0469, device='cuda:0') norm:  tensor(0.4709, device='cuda:0') MSE:  tensor(1.7678e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.9849e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.2614e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  460  
Training Loss: 0.02573620341718197
Test Loss:  0.015135761350393295
Test Acc:  0.0
Valid Loss:  0.0158558189868927
Valid Acc:  0.0
std:  0.00027193596352150786 
thres:  2.6118724793195723e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 46%|████▌     | 460/1000 [21:32<25:49,  2.87s/it]Epoch:   461
max of grad d_p:  tensor(0.1793, device='cuda:0')
min of grad d_p:  tensor(-0.0466, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0564, device='cuda:0') mean:  tensor(-4.1227e-05, device='cuda:0') min:  tensor(-0.0456, device='cuda:0') norm:  tensor(0.4850, device='cuda:0') MSE:  tensor(1.8205e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(5.4370e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(3.0648e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0019, device='cuda:0')
min of d_p_list:  tensor(-0.0030, device='cuda:0')
Epoch:  461  
Training Loss: 0.02554156817495823
Test Loss:  0.014985424466431141
Test Acc:  0.0
Valid Loss:  0.01569768413901329
Valid Acc:  0.0
std:  0.0002694023992349882 
thres:  2.5925158336758615e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 46%|████▌     | 461/1000 [21:35<24:58,  2.78s/it]Epoch:   462
max of grad d_p:  tensor(0.1784, device='cuda:0')
min of grad d_p:  tensor(-0.0463, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0531, device='cuda:0') mean:  tensor(-3.6384e-05, device='cuda:0') min:  tensor(-0.0440, device='cuda:0') norm:  tensor(0.4403, device='cuda:0') MSE:  tensor(1.6528e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.1740e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0017, device='cuda:0') MSE:  tensor(6.2039e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  462  
Training Loss: 0.025349680334329605
Test Loss:  0.014831648208200932
Test Acc:  0.0
Valid Loss:  0.015536099672317505
Valid Acc:  0.0
std:  0.0002698558981624038 
thres:  2.5733545050024987e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 46%|████▌     | 462/1000 [21:37<24:29,  2.73s/it]Epoch:   463
max of grad d_p:  tensor(0.1775, device='cuda:0')
min of grad d_p:  tensor(-0.0460, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0521, device='cuda:0') mean:  tensor(-3.9039e-05, device='cuda:0') min:  tensor(-0.0453, device='cuda:0') norm:  tensor(0.4671, device='cuda:0') MSE:  tensor(1.7535e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.6945e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9198e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0696, device='cuda:0')
min of d_p_list:  tensor(-0.0703, device='cuda:0')
Epoch:  463  
Training Loss: 0.025130335241556168
Test Loss:  0.01470266841351986
Test Acc:  0.0
Valid Loss:  0.01530064269900322
Valid Acc:  0.0
std:  0.0002814195905614395 
thres:  2.5537905842065812e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 46%|████▋     | 463/1000 [21:40<24:57,  2.79s/it]Epoch:   464
max of grad d_p:  tensor(0.1771, device='cuda:0')
min of grad d_p:  tensor(-0.0452, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0564, device='cuda:0') mean:  tensor(-3.8871e-05, device='cuda:0') min:  tensor(-0.0498, device='cuda:0') norm:  tensor(0.4731, device='cuda:0') MSE:  tensor(1.7759e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.0463e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.9712e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  464  
Training Loss: 0.024944037199020386
Test Loss:  0.014554278925061226
Test Acc:  0.0
Valid Loss:  0.015144813805818558
Valid Acc:  0.0
std:  0.0002822926746641866 
thres:  2.5340364873409272e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 46%|████▋     | 464/1000 [21:43<25:02,  2.80s/it]Epoch:   465
max of grad d_p:  tensor(0.1762, device='cuda:0')
min of grad d_p:  tensor(-0.0450, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0626, device='cuda:0') mean:  tensor(-4.1547e-05, device='cuda:0') min:  tensor(-0.0562, device='cuda:0') norm:  tensor(0.5246, device='cuda:0') MSE:  tensor(1.9694e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.2754e-05, device='cuda:0') mean:  tensor(3.1179e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4815e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.5155, device='cuda:0')
min of d_p_list:  tensor(-0.2772, device='cuda:0')
Epoch:  465  
Training Loss: 0.1382104456424713
Test Loss:  0.10787956416606903
Test Acc:  0.0
Valid Loss:  0.10466289520263672
Valid Acc:  0.0
std:  0.04518806448079423 
thres:  4.7835213318467144e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 46%|████▋     | 465/1000 [21:46<24:35,  2.76s/it]Epoch:   466
max of grad d_p:  tensor(0.4609, device='cuda:0')
min of grad d_p:  tensor(-0.0649, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0366, device='cuda:0') mean:  tensor(-1.2237e-05, device='cuda:0') min:  tensor(-0.1624, device='cuda:0') norm:  tensor(0.3871, device='cuda:0') MSE:  tensor(1.4532e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(5.5236e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.6567e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0009, device='cuda:0')
Epoch:  466  
Training Loss: 0.13689815998077393
Test Loss:  0.1068115383386612
Test Acc:  0.0
Valid Loss:  0.1036236360669136
Valid Acc:  0.0
std:  0.05507258774430139 
thres:  7.010653167963028e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 47%|████▋     | 466/1000 [21:49<24:43,  2.78s/it]Epoch:   467
max of grad d_p:  tensor(0.4586, device='cuda:0')
min of grad d_p:  tensor(-0.0645, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0282, device='cuda:0') mean:  tensor(-7.3955e-06, device='cuda:0') min:  tensor(-0.1531, device='cuda:0') norm:  tensor(0.3463, device='cuda:0') MSE:  tensor(1.2999e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.9393e-05, device='cuda:0') mean:  tensor(4.5743e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2231e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0017, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  467  
Training Loss: 0.13559943437576294
Test Loss:  0.10575876384973526
Test Acc:  0.0
Valid Loss:  0.10260343551635742
Valid Acc:  0.0
std:  0.05480892721491514 
thres:  9.215648248791695e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 47%|████▋     | 467/1000 [21:51<25:05,  2.82s/it]Epoch:   468
max of grad d_p:  tensor(0.4563, device='cuda:0')
min of grad d_p:  tensor(-0.0641, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0285, device='cuda:0') mean:  tensor(-8.6066e-06, device='cuda:0') min:  tensor(-0.1386, device='cuda:0') norm:  tensor(0.3236, device='cuda:0') MSE:  tensor(1.2146e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.5520e-05, device='cuda:0') mean:  tensor(3.9832e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8934e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  468  
Training Loss: 0.1343158483505249
Test Loss:  0.1047181487083435
Test Acc:  0.0
Valid Loss:  0.10158585011959076
Valid Acc:  0.0
std:  0.04454369758545415 
thres:  0.0001139935851097107
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 47%|████▋     | 468/1000 [21:54<24:28,  2.76s/it]Epoch:   469
max of grad d_p:  tensor(0.4541, device='cuda:0')
min of grad d_p:  tensor(-0.0637, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0316, device='cuda:0') mean:  tensor(-9.8953e-06, device='cuda:0') min:  tensor(-0.1753, device='cuda:0') norm:  tensor(0.3806, device='cuda:0') MSE:  tensor(1.4288e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(2.9572e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0039, device='cuda:0') MSE:  tensor(1.4662e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0121, device='cuda:0')
min of d_p_list:  tensor(-0.0131, device='cuda:0')
Epoch:  469  
Training Loss: 0.13323745131492615
Test Loss:  0.10391917824745178
Test Acc:  0.0
Valid Loss:  0.10080217570066452
Valid Acc:  0.0
std:  0.0017729449045055562 
thres:  0.00013565226793289185
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 47%|████▋     | 469/1000 [21:57<24:19,  2.75s/it]Epoch:   470
max of grad d_p:  tensor(0.4522, device='cuda:0')
min of grad d_p:  tensor(-0.0637, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0323, device='cuda:0') mean:  tensor(-1.0667e-05, device='cuda:0') min:  tensor(-0.1303, device='cuda:0') norm:  tensor(0.3361, device='cuda:0') MSE:  tensor(1.2617e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.4135e-05, device='cuda:0') mean:  tensor(3.0300e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4236e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0044, device='cuda:0')
min of d_p_list:  tensor(-0.0025, device='cuda:0')
Epoch:  470  
Training Loss: 0.13199618458747864
Test Loss:  0.10291588306427002
Test Acc:  0.0
Valid Loss:  0.09982316195964813
Valid Acc:  0.0
std:  0.0017213908513152919 
thres:  0.0001344094157218933
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 47%|████▋     | 470/1000 [22:00<24:28,  2.77s/it]Epoch:   471
max of grad d_p:  tensor(0.4500, device='cuda:0')
min of grad d_p:  tensor(-0.0633, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0361, device='cuda:0') mean:  tensor(-1.3449e-05, device='cuda:0') min:  tensor(-0.1561, device='cuda:0') norm:  tensor(0.3749, device='cuda:0') MSE:  tensor(1.4073e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.7111e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.4035e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0009, device='cuda:0')
Epoch:  471  
Training Loss: 0.1307469606399536
Test Loss:  0.10188987851142883
Test Acc:  0.0
Valid Loss:  0.09883302450180054
Valid Acc:  0.0
std:  0.0017010708915252749 
thres:  0.00013317917585372924
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 47%|████▋     | 471/1000 [22:02<23:49,  2.70s/it]Epoch:   472
max of grad d_p:  tensor(0.4478, device='cuda:0')
min of grad d_p:  tensor(-0.0628, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0316, device='cuda:0') mean:  tensor(-8.9875e-06, device='cuda:0') min:  tensor(-0.1526, device='cuda:0') norm:  tensor(0.3538, device='cuda:0') MSE:  tensor(1.3280e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.0016e-05, device='cuda:0') mean:  tensor(3.1557e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5673e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0017, device='cuda:0')
min of d_p_list:  tensor(-0.0009, device='cuda:0')
Epoch:  472  
Training Loss: 0.129510760307312
Test Loss:  0.10088042914867401
Test Acc:  0.0
Valid Loss:  0.0978560745716095
Valid Acc:  0.0
std:  0.0017119253380522513 
thres:  0.00013196144104003906
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 47%|████▋     | 472/1000 [22:05<23:38,  2.69s/it]Epoch:   473
max of grad d_p:  tensor(0.4456, device='cuda:0')
min of grad d_p:  tensor(-0.0624, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0332, device='cuda:0') mean:  tensor(-9.7920e-06, device='cuda:0') min:  tensor(-0.1634, device='cuda:0') norm:  tensor(0.3687, device='cuda:0') MSE:  tensor(1.3840e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.2263e-05, device='cuda:0') mean:  tensor(2.2389e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.1364e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0025, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  473  
Training Loss: 0.12829184532165527
Test Loss:  0.09989223629236221
Test Acc:  0.0
Valid Loss:  0.09688910096883774
Valid Acc:  0.0
std:  0.0017503381541674713 
thres:  0.00013075664043426513
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 47%|████▋     | 473/1000 [22:08<23:52,  2.72s/it]Epoch:   474
max of grad d_p:  tensor(0.4433, device='cuda:0')
min of grad d_p:  tensor(-0.0621, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0301, device='cuda:0') mean:  tensor(-9.7282e-06, device='cuda:0') min:  tensor(-0.1415, device='cuda:0') norm:  tensor(0.3340, device='cuda:0') MSE:  tensor(1.2537e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.6282e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.5525e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0104, device='cuda:0')
min of d_p_list:  tensor(-0.0094, device='cuda:0')
Epoch:  474  
Training Loss: 0.12713992595672607
Test Loss:  0.09896659106016159
Test Acc:  0.0
Valid Loss:  0.09602738916873932
Valid Acc:  0.0
std:  0.0017209681087880717 
thres:  0.00012953713536262512
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 47%|████▋     | 474/1000 [22:10<23:42,  2.70s/it]Epoch:   475
max of grad d_p:  tensor(0.4413, device='cuda:0')
min of grad d_p:  tensor(-0.0616, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0368, device='cuda:0') mean:  tensor(-1.2301e-05, device='cuda:0') min:  tensor(-0.1801, device='cuda:0') norm:  tensor(0.4091, device='cuda:0') MSE:  tensor(1.5356e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.1496e-05, device='cuda:0') mean:  tensor(2.8273e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.3670e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0019, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  475  
Training Loss: 0.12593874335289001
Test Loss:  0.09799084812402725
Test Acc:  0.0
Valid Loss:  0.09507422894239426
Valid Acc:  0.0
std:  0.0016953842786048149 
thres:  0.00012832564711570742
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 48%|████▊     | 475/1000 [22:13<23:26,  2.68s/it]Epoch:   476
max of grad d_p:  tensor(0.4391, device='cuda:0')
min of grad d_p:  tensor(-0.0612, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0286, device='cuda:0') mean:  tensor(-1.0550e-05, device='cuda:0') min:  tensor(-0.1193, device='cuda:0') norm:  tensor(0.3179, device='cuda:0') MSE:  tensor(1.1935e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.9439e-05, device='cuda:0') mean:  tensor(2.7934e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4330e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0032, device='cuda:0')
min of d_p_list:  tensor(-0.0025, device='cuda:0')
Epoch:  476  
Training Loss: 0.12476055324077606
Test Loss:  0.09702929854393005
Test Acc:  0.0
Valid Loss:  0.09413439780473709
Valid Acc:  0.0
std:  0.0016763865726789622 
thres:  0.00012712836563587187
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 48%|████▊     | 476/1000 [22:16<24:22,  2.79s/it]Epoch:   477
max of grad d_p:  tensor(0.4369, device='cuda:0')
min of grad d_p:  tensor(-0.0611, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0318, device='cuda:0') mean:  tensor(-9.8420e-06, device='cuda:0') min:  tensor(-0.1674, device='cuda:0') norm:  tensor(0.3727, device='cuda:0') MSE:  tensor(1.3989e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(2.2880e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0032, device='cuda:0') MSE:  tensor(1.2117e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0028, device='cuda:0')
min of d_p_list:  tensor(-0.0052, device='cuda:0')
Epoch:  477  
Training Loss: 0.12360174208879471
Test Loss:  0.09609130769968033
Test Acc:  0.0
Valid Loss:  0.09321539103984833
Valid Acc:  0.0
std:  0.001663089276992106 
thres:  0.00012594656199216842
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 48%|████▊     | 477/1000 [22:19<24:00,  2.75s/it]Epoch:   478
max of grad d_p:  tensor(0.4348, device='cuda:0')
min of grad d_p:  tensor(-0.0608, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0300, device='cuda:0') mean:  tensor(-9.7370e-06, device='cuda:0') min:  tensor(-0.1498, device='cuda:0') norm:  tensor(0.3446, device='cuda:0') MSE:  tensor(1.2936e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(8.1857e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.2947e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0028, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  478  
Training Loss: 0.12243737280368805
Test Loss:  0.09514439105987549
Test Acc:  0.0
Valid Loss:  0.09229324012994766
Valid Acc:  0.0
std:  0.001660627284400843 
thres:  0.00012477566748857498
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 48%|████▊     | 478/1000 [22:22<24:33,  2.82s/it]Epoch:   479
max of grad d_p:  tensor(0.4326, device='cuda:0')
min of grad d_p:  tensor(-0.0603, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0345, device='cuda:0') mean:  tensor(-9.5453e-06, device='cuda:0') min:  tensor(-0.1824, device='cuda:0') norm:  tensor(0.4047, device='cuda:0') MSE:  tensor(1.5192e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(3.3909e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7575e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  479  
Training Loss: 0.12128494679927826
Test Loss:  0.09419706463813782
Test Acc:  0.0
Valid Loss:  0.09137433767318726
Valid Acc:  0.0
std:  0.001644850846010845 
thres:  0.00012360467165708542
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 48%|████▊     | 479/1000 [22:25<24:49,  2.86s/it]Epoch:   480
max of grad d_p:  tensor(0.4305, device='cuda:0')
min of grad d_p:  tensor(-0.0598, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0300, device='cuda:0') mean:  tensor(-9.3168e-06, device='cuda:0') min:  tensor(-0.1444, device='cuda:0') norm:  tensor(0.3387, device='cuda:0') MSE:  tensor(1.2713e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(3.5438e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7885e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  480  
Training Loss: 0.12013913691043854
Test Loss:  0.0932621955871582
Test Acc:  0.0
Valid Loss:  0.09046687185764313
Valid Acc:  0.0
std:  0.0016347859156298568 
thres:  0.00012244475036859512
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 48%|████▊     | 480/1000 [22:27<24:19,  2.81s/it]Epoch:   481
max of grad d_p:  tensor(0.4283, device='cuda:0')
min of grad d_p:  tensor(-0.0593, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0290, device='cuda:0') mean:  tensor(-9.1348e-06, device='cuda:0') min:  tensor(-0.1533, device='cuda:0') norm:  tensor(0.3454, device='cuda:0') MSE:  tensor(1.2966e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(8.4703e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.3949e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0035, device='cuda:0')
Epoch:  481  
Training Loss: 0.11901164054870605
Test Loss:  0.092343270778656
Test Acc:  0.0
Valid Loss:  0.08957494795322418
Valid Acc:  0.0
std:  0.0016233253287075448 
thres:  0.00012129496783018112
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 48%|████▊     | 481/1000 [22:30<23:48,  2.75s/it]Epoch:   482
max of grad d_p:  tensor(0.4262, device='cuda:0')
min of grad d_p:  tensor(-0.0589, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0298, device='cuda:0') mean:  tensor(-1.2937e-05, device='cuda:0') min:  tensor(-0.1539, device='cuda:0') norm:  tensor(0.3465, device='cuda:0') MSE:  tensor(1.3007e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(7.3623e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.7305e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0033, device='cuda:0')
min of d_p_list:  tensor(-0.0027, device='cuda:0')
Epoch:  482  
Training Loss: 0.11788798868656158
Test Loss:  0.09144210815429688
Test Acc:  0.0
Valid Loss:  0.08869430422782898
Valid Acc:  0.0
std:  0.0016082804127805217 
thres:  0.0001201522171497345
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 48%|████▊     | 482/1000 [22:32<23:24,  2.71s/it]Epoch:   483
max of grad d_p:  tensor(0.4241, device='cuda:0')
min of grad d_p:  tensor(-0.0585, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0341, device='cuda:0') mean:  tensor(-1.0856e-05, device='cuda:0') min:  tensor(-0.1728, device='cuda:0') norm:  tensor(0.3915, device='cuda:0') MSE:  tensor(1.4695e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(8.0567e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.2603e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0017, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  483  
Training Loss: 0.11678238213062286
Test Loss:  0.09053526818752289
Test Acc:  0.0
Valid Loss:  0.08782404661178589
Valid Acc:  0.0
std:  0.0015919106269770167 
thres:  0.00011902121901512147
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 48%|████▊     | 483/1000 [22:35<23:44,  2.75s/it]Epoch:   484
max of grad d_p:  tensor(0.4220, device='cuda:0')
min of grad d_p:  tensor(-0.0581, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0311, device='cuda:0') mean:  tensor(-1.0412e-05, device='cuda:0') min:  tensor(-0.1441, device='cuda:0') norm:  tensor(0.3473, device='cuda:0') MSE:  tensor(1.3037e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.7998e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.4194e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  484  
Training Loss: 0.11568409949541092
Test Loss:  0.0896393209695816
Test Acc:  0.0
Valid Loss:  0.08695376664400101
Valid Acc:  0.0
std:  0.001575366771595354 
thres:  0.00011790104955434799
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 48%|████▊     | 484/1000 [22:38<23:50,  2.77s/it]Epoch:   485
max of grad d_p:  tensor(0.4199, device='cuda:0')
min of grad d_p:  tensor(-0.0577, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0294, device='cuda:0') mean:  tensor(-1.0626e-05, device='cuda:0') min:  tensor(-0.1689, device='cuda:0') norm:  tensor(0.3671, device='cuda:0') MSE:  tensor(1.3778e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.5540e-05, device='cuda:0') mean:  tensor(3.8178e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(2.0030e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0009, device='cuda:0')
Epoch:  485  
Training Loss: 0.11459563672542572
Test Loss:  0.08875108510255814
Test Acc:  0.0
Valid Loss:  0.08609464019536972
Valid Acc:  0.0
std:  0.0015607397234066913 
thres:  0.00011679234951734543
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 48%|████▊     | 485/1000 [22:41<23:23,  2.73s/it]Epoch:   486
max of grad d_p:  tensor(0.4178, device='cuda:0')
min of grad d_p:  tensor(-0.0572, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0290, device='cuda:0') mean:  tensor(-1.1878e-05, device='cuda:0') min:  tensor(-0.1476, device='cuda:0') norm:  tensor(0.3467, device='cuda:0') MSE:  tensor(1.3015e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.1570e-05, device='cuda:0') mean:  tensor(3.5256e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8437e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0023, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  486  
Training Loss: 0.1135185956954956
Test Loss:  0.08786675333976746
Test Acc:  0.0
Valid Loss:  0.08524484932422638
Valid Acc:  0.0
std:  0.0015451242974867897 
thres:  0.00011569374054670334
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 49%|████▊     | 486/1000 [22:43<22:54,  2.67s/it]Epoch:   487
max of grad d_p:  tensor(0.4157, device='cuda:0')
min of grad d_p:  tensor(-0.0567, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0308, device='cuda:0') mean:  tensor(-1.2349e-05, device='cuda:0') min:  tensor(-0.1681, device='cuda:0') norm:  tensor(0.3737, device='cuda:0') MSE:  tensor(1.4027e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(8.9295e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0014, device='cuda:0') MSE:  tensor(5.1793e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  487  
Training Loss: 0.11245326697826385
Test Loss:  0.08699281513690948
Test Acc:  0.0
Valid Loss:  0.08439959585666656
Valid Acc:  0.0
std:  0.0015307350856745433 
thres:  0.0001146067962050438
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 49%|████▊     | 487/1000 [22:46<24:02,  2.81s/it]Epoch:   488
max of grad d_p:  tensor(0.4136, device='cuda:0')
min of grad d_p:  tensor(-0.0562, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0254, device='cuda:0') mean:  tensor(-9.1233e-06, device='cuda:0') min:  tensor(-0.1401, device='cuda:0') norm:  tensor(0.3122, device='cuda:0') MSE:  tensor(1.1720e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.7369e-05, device='cuda:0') mean:  tensor(2.6448e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.2646e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0022, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  488  
Training Loss: 0.11139510571956635
Test Loss:  0.08613403141498566
Test Acc:  0.0
Valid Loss:  0.08356067538261414
Valid Acc:  0.0
std:  0.001516112247934082 
thres:  0.00011352934092283249
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 49%|████▉     | 488/1000 [22:49<23:47,  2.79s/it]Epoch:   489
max of grad d_p:  tensor(0.4116, device='cuda:0')
min of grad d_p:  tensor(-0.0559, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0256, device='cuda:0') mean:  tensor(-1.1241e-05, device='cuda:0') min:  tensor(-0.1469, device='cuda:0') norm:  tensor(0.3227, device='cuda:0') MSE:  tensor(1.2112e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.9677e-05, device='cuda:0') mean:  tensor(2.8863e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4056e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0040, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  489  
Training Loss: 0.11035934835672379
Test Loss:  0.08528552204370499
Test Acc:  0.0
Valid Loss:  0.08272817730903625
Valid Acc:  0.0
std:  0.0014985496432866614 
thres:  0.00011246439069509506
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 49%|████▉     | 489/1000 [22:52<23:17,  2.73s/it]Epoch:   490
max of grad d_p:  tensor(0.4095, device='cuda:0')
min of grad d_p:  tensor(-0.0560, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0286, device='cuda:0') mean:  tensor(-1.0430e-05, device='cuda:0') min:  tensor(-0.1517, device='cuda:0') norm:  tensor(0.3408, device='cuda:0') MSE:  tensor(1.2794e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(9.2792e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0014, device='cuda:0') MSE:  tensor(5.1114e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  490  
Training Loss: 0.10932373255491257
Test Loss:  0.08444526791572571
Test Acc:  0.0
Valid Loss:  0.0819089412689209
Valid Acc:  0.0
std:  0.001482645228100943 
thres:  0.00011141000986099244
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 49%|████▉     | 490/1000 [22:54<22:48,  2.68s/it]Epoch:   491
max of grad d_p:  tensor(0.4075, device='cuda:0')
min of grad d_p:  tensor(-0.0557, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0295, device='cuda:0') mean:  tensor(-1.0116e-05, device='cuda:0') min:  tensor(-0.1535, device='cuda:0') norm:  tensor(0.3459, device='cuda:0') MSE:  tensor(1.2983e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0010, device='cuda:0') mean:  tensor(3.2662e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0048, device='cuda:0') MSE:  tensor(1.7881e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0017, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  491  
Training Loss: 0.10830120742321014
Test Loss:  0.08361871540546417
Test Acc:  0.0
Valid Loss:  0.08110856264829636
Valid Acc:  0.0
std:  0.0014673428134549717 
thres:  0.00011036653220653533
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 49%|████▉     | 491/1000 [22:57<22:49,  2.69s/it]Epoch:   492
max of grad d_p:  tensor(0.4055, device='cuda:0')
min of grad d_p:  tensor(-0.0552, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0318, device='cuda:0') mean:  tensor(-1.3252e-05, device='cuda:0') min:  tensor(-0.1601, device='cuda:0') norm:  tensor(0.3692, device='cuda:0') MSE:  tensor(1.3860e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.5544e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.8264e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0044, device='cuda:0')
min of d_p_list:  tensor(-0.0040, device='cuda:0')
Epoch:  492  
Training Loss: 0.10731504112482071
Test Loss:  0.0828341692686081
Test Acc:  0.0
Valid Loss:  0.08034771680831909
Valid Acc:  0.0
std:  0.0014451531054552327 
thres:  0.00010933888703584671
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 49%|████▉     | 492/1000 [23:00<23:45,  2.81s/it]Epoch:   493
max of grad d_p:  tensor(0.4035, device='cuda:0')
min of grad d_p:  tensor(-0.0550, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0323, device='cuda:0') mean:  tensor(-1.0816e-05, device='cuda:0') min:  tensor(-0.1605, device='cuda:0') norm:  tensor(0.3680, device='cuda:0') MSE:  tensor(1.3813e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.2223e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0015, device='cuda:0') MSE:  tensor(5.7613e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0036, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  493  
Training Loss: 0.10631351172924042
Test Loss:  0.0820268765091896
Test Acc:  0.0
Valid Loss:  0.07956992834806442
Valid Acc:  0.0
std:  0.0014284732034642168 
thres:  0.00010832256823778153
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 49%|████▉     | 493/1000 [23:03<24:11,  2.86s/it]Epoch:   494
max of grad d_p:  tensor(0.4015, device='cuda:0')
min of grad d_p:  tensor(-0.0547, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0294, device='cuda:0') mean:  tensor(-1.3131e-05, device='cuda:0') min:  tensor(-0.1540, device='cuda:0') norm:  tensor(0.3565, device='cuda:0') MSE:  tensor(1.3383e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.9233e-05, device='cuda:0') mean:  tensor(2.1731e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.1375e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0033, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  494  
Training Loss: 0.10531947016716003
Test Loss:  0.0812145322561264
Test Acc:  0.0
Valid Loss:  0.07878230512142181
Valid Acc:  0.0
std:  0.001413699317450539 
thres:  0.00010731459259986878
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 49%|████▉     | 494/1000 [23:06<23:54,  2.83s/it]Epoch:   495
max of grad d_p:  tensor(0.3995, device='cuda:0')
min of grad d_p:  tensor(-0.0544, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0278, device='cuda:0') mean:  tensor(-1.2311e-05, device='cuda:0') min:  tensor(-0.1394, device='cuda:0') norm:  tensor(0.3352, device='cuda:0') MSE:  tensor(1.2583e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.1838e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.6268e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0008, device='cuda:0')
Epoch:  495  
Training Loss: 0.10433363169431686
Test Loss:  0.08040843904018402
Test Acc:  0.0
Valid Loss:  0.07799887657165527
Valid Acc:  0.0
std:  0.0014044210225208462 
thres:  0.00010631657242774964
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 50%|████▉     | 495/1000 [23:08<23:10,  2.75s/it]Epoch:   496
max of grad d_p:  tensor(0.3975, device='cuda:0')
min of grad d_p:  tensor(-0.0540, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0321, device='cuda:0') mean:  tensor(-1.2698e-05, device='cuda:0') min:  tensor(-0.1436, device='cuda:0') norm:  tensor(0.3510, device='cuda:0') MSE:  tensor(1.3177e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.3628e-05, device='cuda:0') mean:  tensor(1.9705e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(9.7215e-10, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0020, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  496  
Training Loss: 0.10335834324359894
Test Loss:  0.07960493117570877
Test Acc:  0.0
Valid Loss:  0.07722088694572449
Valid Acc:  0.0
std:  0.0013991393514321679 
thres:  0.0001053279995918274
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 50%|████▉     | 496/1000 [23:12<24:25,  2.91s/it]Epoch:   497
max of grad d_p:  tensor(0.3955, device='cuda:0')
min of grad d_p:  tensor(-0.0537, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0359, device='cuda:0') mean:  tensor(-1.2575e-05, device='cuda:0') min:  tensor(-0.1537, device='cuda:0') norm:  tensor(0.3687, device='cuda:0') MSE:  tensor(1.3841e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.5646e-05, device='cuda:0') mean:  tensor(3.5653e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8250e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0059, device='cuda:0')
min of d_p_list:  tensor(-0.0046, device='cuda:0')
Epoch:  497  
Training Loss: 0.1024145781993866
Test Loss:  0.0788566917181015
Test Acc:  0.0
Valid Loss:  0.07647553831338882
Valid Acc:  0.0
std:  0.0013801983482826315 
thres:  0.00010434790700674057
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 50%|████▉     | 497/1000 [23:15<25:15,  3.01s/it]Epoch:   498
max of grad d_p:  tensor(0.3936, device='cuda:0')
min of grad d_p:  tensor(-0.0534, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0328, device='cuda:0') mean:  tensor(-1.2726e-05, device='cuda:0') min:  tensor(-0.1532, device='cuda:0') norm:  tensor(0.3631, device='cuda:0') MSE:  tensor(1.3630e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0046, device='cuda:0') mean:  tensor(1.9429e-05, device='cuda:0') min:  tensor(2.9104e-11, device='cuda:0') norm:  tensor(0.0266, device='cuda:0') MSE:  tensor(9.9994e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0009, device='cuda:0')
Epoch:  498  
Training Loss: 0.10145970433950424
Test Loss:  0.07808089256286621
Test Acc:  0.0
Valid Loss:  0.07571965456008911
Valid Acc:  0.0
std:  0.0013631552288419948 
thres:  0.00010337714552879333
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 50%|████▉     | 498/1000 [23:18<24:23,  2.92s/it]Epoch:   499
max of grad d_p:  tensor(0.3917, device='cuda:0')
min of grad d_p:  tensor(-0.0531, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0300, device='cuda:0') mean:  tensor(-1.1617e-05, device='cuda:0') min:  tensor(-0.1582, device='cuda:0') norm:  tensor(0.3508, device='cuda:0') MSE:  tensor(1.3168e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.5218e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.9427e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0007, device='cuda:0')
Epoch:  499  
Training Loss: 0.10051389038562775
Test Loss:  0.077307790517807
Test Acc:  0.0
Valid Loss:  0.07496850192546844
Valid Acc:  0.0
std:  0.0013489141185649915 
thres:  0.00010241602957248689
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 50%|████▉     | 499/1000 [23:20<24:07,  2.89s/it]Epoch:   500
max of grad d_p:  tensor(0.3897, device='cuda:0')
min of grad d_p:  tensor(-0.0528, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0312, device='cuda:0') mean:  tensor(-1.2392e-05, device='cuda:0') min:  tensor(-0.1586, device='cuda:0') norm:  tensor(0.3675, device='cuda:0') MSE:  tensor(1.3796e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0014, device='cuda:0') mean:  tensor(4.4359e-06, device='cuda:0') min:  tensor(2.9104e-11, device='cuda:0') norm:  tensor(0.0062, device='cuda:0') MSE:  tensor(2.3114e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0122, device='cuda:0')
min of d_p_list:  tensor(-0.0260, device='cuda:0')
Epoch:  500  
Training Loss: 0.09984749555587769
Test Loss:  0.07666317373514175
Test Acc:  0.0
Valid Loss:  0.07440659403800964
Valid Acc:  0.0
std:  0.0012643521742481028 
thres:  0.00010151880234479904
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 50%|█████     | 500/1000 [23:23<23:42,  2.84s/it]Epoch:   501
max of grad d_p:  tensor(0.3885, device='cuda:0')
min of grad d_p:  tensor(-0.0516, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0260, device='cuda:0') mean:  tensor(-1.3469e-05, device='cuda:0') min:  tensor(-0.1648, device='cuda:0') norm:  tensor(0.3644, device='cuda:0') MSE:  tensor(1.3677e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.9979e-05, device='cuda:0') mean:  tensor(3.0149e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4771e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  501  
Training Loss: 0.09891744703054428
Test Loss:  0.07590353488922119
Test Acc:  0.0
Valid Loss:  0.07366832345724106
Valid Acc:  0.0
std:  0.0012191602864470973 
thres:  0.00010063062310218811
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 50%|█████     | 501/1000 [23:26<23:48,  2.86s/it]Epoch:   502
max of grad d_p:  tensor(0.3865, device='cuda:0')
min of grad d_p:  tensor(-0.0513, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0325, device='cuda:0') mean:  tensor(-1.1596e-05, device='cuda:0') min:  tensor(-0.1530, device='cuda:0') norm:  tensor(0.3602, device='cuda:0') MSE:  tensor(1.3522e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(7.0331e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.3979e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  502  
Training Loss: 0.09799865633249283
Test Loss:  0.0751505196094513
Test Acc:  0.0
Valid Loss:  0.07294078171253204
Valid Acc:  0.0
std:  0.0012063531092765905 
thres:  9.974743872880935e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 50%|█████     | 502/1000 [23:29<23:49,  2.87s/it]Epoch:   503
max of grad d_p:  tensor(0.3846, device='cuda:0')
min of grad d_p:  tensor(-0.0509, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0296, device='cuda:0') mean:  tensor(-1.5942e-05, device='cuda:0') min:  tensor(-0.1339, device='cuda:0') norm:  tensor(0.3376, device='cuda:0') MSE:  tensor(1.2671e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.0265e-05, device='cuda:0') mean:  tensor(3.4772e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.6808e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  503  
Training Loss: 0.09708735346794128
Test Loss:  0.07440198212862015
Test Acc:  0.0
Valid Loss:  0.07221266627311707
Valid Acc:  0.0
std:  0.0012326515132846144 
thres:  9.887296855449676e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 50%|█████     | 503/1000 [23:32<23:22,  2.82s/it]Epoch:   504
max of grad d_p:  tensor(0.3827, device='cuda:0')
min of grad d_p:  tensor(-0.0506, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0282, device='cuda:0') mean:  tensor(-1.1361e-05, device='cuda:0') min:  tensor(-0.1549, device='cuda:0') norm:  tensor(0.3486, device='cuda:0') MSE:  tensor(1.3086e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.4333e-05, device='cuda:0') mean:  tensor(2.6663e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.3210e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0045, device='cuda:0')
min of d_p_list:  tensor(-0.0043, device='cuda:0')
Epoch:  504  
Training Loss: 0.09618429094552994
Test Loss:  0.0736754834651947
Test Acc:  0.0
Valid Loss:  0.07148902118206024
Valid Acc:  0.0
std:  0.0012949459705140227 
thres:  9.80070486664772e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 50%|█████     | 504/1000 [23:35<23:58,  2.90s/it]Epoch:   505
max of grad d_p:  tensor(0.3808, device='cuda:0')
min of grad d_p:  tensor(-0.0505, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0302, device='cuda:0') mean:  tensor(-1.1685e-05, device='cuda:0') min:  tensor(-0.1508, device='cuda:0') norm:  tensor(0.3575, device='cuda:0') MSE:  tensor(1.3418e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.7684e-05, device='cuda:0') mean:  tensor(2.3064e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.1683e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0060, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  505  
Training Loss: 0.09529698640108109
Test Loss:  0.07294433563947678
Test Acc:  0.0
Valid Loss:  0.07078784704208374
Valid Acc:  0.0
std:  0.0012806397892299783 
thres:  9.709694683551789e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 50%|█████     | 505/1000 [23:38<23:27,  2.84s/it]Epoch:   506
max of grad d_p:  tensor(0.3789, device='cuda:0')
min of grad d_p:  tensor(-0.0501, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0306, device='cuda:0') mean:  tensor(-1.2696e-05, device='cuda:0') min:  tensor(-0.1334, device='cuda:0') norm:  tensor(0.3304, device='cuda:0') MSE:  tensor(1.2404e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.6822e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8378e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0008, device='cuda:0')
Epoch:  506  
Training Loss: 0.09441058337688446
Test Loss:  0.07222311198711395
Test Acc:  0.0
Valid Loss:  0.07008571922779083
Valid Acc:  0.0
std:  0.001268081623717401 
thres:  9.619557410478592e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 51%|█████     | 506/1000 [23:40<22:52,  2.78s/it]Epoch:   507
max of grad d_p:  tensor(0.3770, device='cuda:0')
min of grad d_p:  tensor(-0.0498, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0283, device='cuda:0') mean:  tensor(-1.4099e-05, device='cuda:0') min:  tensor(-0.1425, device='cuda:0') norm:  tensor(0.3450, device='cuda:0') MSE:  tensor(1.2949e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.5216e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8001e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0059, device='cuda:0')
min of d_p_list:  tensor(-0.0059, device='cuda:0')
Epoch:  507  
Training Loss: 0.09355470538139343
Test Loss:  0.0715615451335907
Test Acc:  0.0
Valid Loss:  0.06945497542619705
Valid Acc:  0.0
std:  0.001250079765872043 
thres:  9.530678391456604e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 51%|█████     | 507/1000 [23:43<22:46,  2.77s/it]Epoch:   508
max of grad d_p:  tensor(0.3752, device='cuda:0')
min of grad d_p:  tensor(-0.0494, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0303, device='cuda:0') mean:  tensor(-1.4047e-05, device='cuda:0') min:  tensor(-0.1721, device='cuda:0') norm:  tensor(0.3856, device='cuda:0') MSE:  tensor(1.4473e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.2075e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0017, device='cuda:0') MSE:  tensor(6.2722e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0119, device='cuda:0')
min of d_p_list:  tensor(-0.0061, device='cuda:0')
Epoch:  508  
Training Loss: 0.0927027016878128
Test Loss:  0.07086247205734253
Test Acc:  0.0
Valid Loss:  0.06878630071878433
Valid Acc:  0.0
std:  0.0012312009720514283 
thres:  9.442985355854035e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 51%|█████     | 508/1000 [23:46<22:59,  2.80s/it]Epoch:   509
max of grad d_p:  tensor(0.3734, device='cuda:0')
min of grad d_p:  tensor(-0.0496, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0286, device='cuda:0') mean:  tensor(-1.4474e-05, device='cuda:0') min:  tensor(-0.1532, device='cuda:0') norm:  tensor(0.3554, device='cuda:0') MSE:  tensor(1.3343e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.9680e-05, device='cuda:0') mean:  tensor(2.7778e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.3309e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0054, device='cuda:0')
min of d_p_list:  tensor(-0.0086, device='cuda:0')
Epoch:  509  
Training Loss: 0.0918932631611824
Test Loss:  0.07020445913076401
Test Acc:  0.0
Valid Loss:  0.06811501085758209
Valid Acc:  0.0
std:  0.0012044032196731334 
thres:  9.357164800167084e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 51%|█████     | 509/1000 [23:49<23:12,  2.84s/it]Epoch:   510
max of grad d_p:  tensor(0.3717, device='cuda:0')
min of grad d_p:  tensor(-0.0495, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0274, device='cuda:0') mean:  tensor(-1.5914e-05, device='cuda:0') min:  tensor(-0.1428, device='cuda:0') norm:  tensor(0.3418, device='cuda:0') MSE:  tensor(1.2831e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.1142e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5229e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0020, device='cuda:0')
min of d_p_list:  tensor(-0.0031, device='cuda:0')
Epoch:  510  
Training Loss: 0.091038279235363
Test Loss:  0.06948871910572052
Test Acc:  0.0
Valid Loss:  0.06742431968450546
Valid Acc:  0.0
std:  0.0011888467476299789 
thres:  9.271990656852722e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 51%|█████     | 510/1000 [23:52<23:21,  2.86s/it]Epoch:   511
max of grad d_p:  tensor(0.3699, device='cuda:0')
min of grad d_p:  tensor(-0.0490, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0301, device='cuda:0') mean:  tensor(-1.5179e-05, device='cuda:0') min:  tensor(-0.1523, device='cuda:0') norm:  tensor(0.3520, device='cuda:0') MSE:  tensor(1.3213e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.1633e-05, device='cuda:0') mean:  tensor(3.8738e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8451e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0019, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  511  
Training Loss: 0.09019522368907928
Test Loss:  0.06879495084285736
Test Acc:  0.0
Valid Loss:  0.0667504146695137
Valid Acc:  0.0
std:  0.0011856278555008575 
thres:  9.187683463096619e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 51%|█████     | 511/1000 [23:55<23:30,  2.88s/it]Epoch:   512
max of grad d_p:  tensor(0.3680, device='cuda:0')
min of grad d_p:  tensor(-0.0487, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0278, device='cuda:0') mean:  tensor(-1.4977e-05, device='cuda:0') min:  tensor(-0.1469, device='cuda:0') norm:  tensor(0.3437, device='cuda:0') MSE:  tensor(1.2900e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.6517e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9365e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  512  
Training Loss: 0.08936543017625809
Test Loss:  0.06813066452741623
Test Acc:  0.0
Valid Loss:  0.06609924137592316
Valid Acc:  0.0
std:  0.0011840999780266738 
thres:  9.103897958993912e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 51%|█████     | 512/1000 [23:57<23:32,  2.89s/it]Epoch:   513
max of grad d_p:  tensor(0.3662, device='cuda:0')
min of grad d_p:  tensor(-0.0486, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0297, device='cuda:0') mean:  tensor(-1.3720e-05, device='cuda:0') min:  tensor(-0.1463, device='cuda:0') norm:  tensor(0.3491, device='cuda:0') MSE:  tensor(1.3106e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.1098e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(3.1125e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0029, device='cuda:0')
Epoch:  513  
Training Loss: 0.08854074031114578
Test Loss:  0.06746932119131088
Test Acc:  0.0
Valid Loss:  0.06546138972043991
Valid Acc:  0.0
std:  0.0011848466200139877 
thres:  9.02065873146057e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 51%|█████▏    | 513/1000 [24:00<23:33,  2.90s/it]Epoch:   514
max of grad d_p:  tensor(0.3644, device='cuda:0')
min of grad d_p:  tensor(-0.0479, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0331, device='cuda:0') mean:  tensor(-1.3127e-05, device='cuda:0') min:  tensor(-0.1460, device='cuda:0') norm:  tensor(0.3450, device='cuda:0') MSE:  tensor(1.2949e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.0223e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5466e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0022, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  514  
Training Loss: 0.0877276360988617
Test Loss:  0.06681409478187561
Test Acc:  0.0
Valid Loss:  0.06481726467609406
Valid Acc:  0.0
std:  0.0011703966437869406 
thres:  8.937346190214158e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 51%|█████▏    | 514/1000 [24:04<24:01,  2.97s/it]Epoch:   515
max of grad d_p:  tensor(0.3626, device='cuda:0')
min of grad d_p:  tensor(-0.0477, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0333, device='cuda:0') mean:  tensor(-1.5742e-05, device='cuda:0') min:  tensor(-0.1415, device='cuda:0') norm:  tensor(0.3517, device='cuda:0') MSE:  tensor(1.3200e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.3442e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0018, device='cuda:0') MSE:  tensor(6.8504e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0018, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  515  
Training Loss: 0.0869184136390686
Test Loss:  0.06615041941404343
Test Acc:  0.0
Valid Loss:  0.06417502462863922
Valid Acc:  0.0
std:  0.0011584583059960065 
thres:  8.854948878288268e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 52%|█████▏    | 515/1000 [24:06<23:54,  2.96s/it]Epoch:   516
max of grad d_p:  tensor(0.3608, device='cuda:0')
min of grad d_p:  tensor(-0.0472, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0349, device='cuda:0') mean:  tensor(-1.5320e-05, device='cuda:0') min:  tensor(-0.1813, device='cuda:0') norm:  tensor(0.4094, device='cuda:0') MSE:  tensor(1.5368e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0033, device='cuda:0') mean:  tensor(6.7089e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0107, device='cuda:0') MSE:  tensor(4.0031e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0090, device='cuda:0')
min of d_p_list:  tensor(-0.0088, device='cuda:0')
Epoch:  516  
Training Loss: 0.08618251979351044
Test Loss:  0.0655403584241867
Test Acc:  0.0
Valid Loss:  0.06360334157943726
Valid Acc:  0.0
std:  0.0011299441170366789 
thres:  8.774694800376892e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 52%|█████▏    | 516/1000 [24:09<23:55,  2.97s/it]Epoch:   517
max of grad d_p:  tensor(0.3592, device='cuda:0')
min of grad d_p:  tensor(-0.0461, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0328, device='cuda:0') mean:  tensor(-1.5504e-05, device='cuda:0') min:  tensor(-0.1409, device='cuda:0') norm:  tensor(0.3522, device='cuda:0') MSE:  tensor(1.3220e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.4934e-05, device='cuda:0') mean:  tensor(2.9519e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4476e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0006, device='cuda:0')
Epoch:  517  
Training Loss: 0.08538776636123657
Test Loss:  0.0648903027176857
Test Acc:  0.0
Valid Loss:  0.06297208368778229
Valid Acc:  0.0
std:  0.00111047378472966 
thres:  8.695141524076463e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 52%|█████▏    | 517/1000 [24:12<23:53,  2.97s/it]Epoch:   518
max of grad d_p:  tensor(0.3574, device='cuda:0')
min of grad d_p:  tensor(-0.0458, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0350, device='cuda:0') mean:  tensor(-1.8465e-05, device='cuda:0') min:  tensor(-0.1414, device='cuda:0') norm:  tensor(0.3802, device='cuda:0') MSE:  tensor(1.4272e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.6723e-05, device='cuda:0') mean:  tensor(3.8712e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8534e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0055, device='cuda:0')
min of d_p_list:  tensor(-0.0090, device='cuda:0')
Epoch:  518  
Training Loss: 0.08462314307689667
Test Loss:  0.06428524106740952
Test Acc:  0.0
Valid Loss:  0.06236814707517624
Valid Acc:  0.0
std:  0.0010946363418597126 
thres:  8.616789579391478e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 52%|█████▏    | 518/1000 [24:15<23:44,  2.96s/it]Epoch:   519
max of grad d_p:  tensor(0.3557, device='cuda:0')
min of grad d_p:  tensor(-0.0458, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0356, device='cuda:0') mean:  tensor(-1.4118e-05, device='cuda:0') min:  tensor(-0.1575, device='cuda:0') norm:  tensor(0.3772, device='cuda:0') MSE:  tensor(1.4158e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(2.4727e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0033, device='cuda:0') MSE:  tensor(1.2340e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0008, device='cuda:0')
Epoch:  519  
Training Loss: 0.08384595811367035
Test Loss:  0.06365077197551727
Test Acc:  0.0
Valid Loss:  0.0617513433098793
Valid Acc:  0.0
std:  0.001089611268344757 
thres:  8.539156019687653e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 52%|█████▏    | 519/1000 [24:18<23:38,  2.95s/it]Epoch:   520
max of grad d_p:  tensor(0.3539, device='cuda:0')
min of grad d_p:  tensor(-0.0456, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0343, device='cuda:0') mean:  tensor(-1.2892e-05, device='cuda:0') min:  tensor(-0.1582, device='cuda:0') norm:  tensor(0.3683, device='cuda:0') MSE:  tensor(1.3824e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.7772e-05, device='cuda:0') mean:  tensor(3.0633e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5551e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0029, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  520  
Training Loss: 0.083076611161232
Test Loss:  0.06302186846733093
Test Acc:  0.0
Valid Loss:  0.06113753467798233
Valid Acc:  0.0
std:  0.0010965474844688485 
thres:  8.46231997013092e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 52%|█████▏    | 520/1000 [24:21<23:26,  2.93s/it]Epoch:   521
max of grad d_p:  tensor(0.3522, device='cuda:0')
min of grad d_p:  tensor(-0.0452, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0335, device='cuda:0') mean:  tensor(-1.2946e-05, device='cuda:0') min:  tensor(-0.1487, device='cuda:0') norm:  tensor(0.3505, device='cuda:0') MSE:  tensor(1.3157e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(9.6575e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.5939e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0023, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  521  
Training Loss: 0.08231805264949799
Test Loss:  0.062396056950092316
Test Acc:  0.0
Valid Loss:  0.06053974851965904
Valid Acc:  0.0
std:  0.001086966829997672 
thres:  8.385030627250671e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 52%|█████▏    | 521/1000 [24:24<23:20,  2.92s/it]Epoch:   522
max of grad d_p:  tensor(0.3504, device='cuda:0')
min of grad d_p:  tensor(-0.0450, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-1.6145e-05, device='cuda:0') min:  tensor(-0.1470, device='cuda:0') norm:  tensor(0.3782, device='cuda:0') MSE:  tensor(1.4198e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(8.3412e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.0238e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0030, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  522  
Training Loss: 0.0815650150179863
Test Loss:  0.061783820390701294
Test Acc:  0.0
Valid Loss:  0.05995093658566475
Valid Acc:  0.0
std:  0.00108107090189884 
thres:  8.308575600385667e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 52%|█████▏    | 522/1000 [24:27<23:13,  2.91s/it]Epoch:   523
max of grad d_p:  tensor(0.3487, device='cuda:0')
min of grad d_p:  tensor(-0.0447, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0331, device='cuda:0') mean:  tensor(-1.5530e-05, device='cuda:0') min:  tensor(-0.1280, device='cuda:0') norm:  tensor(0.3423, device='cuda:0') MSE:  tensor(1.2848e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.6645e-05, device='cuda:0') mean:  tensor(2.6467e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.3440e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0032, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  523  
Training Loss: 0.08081857860088348
Test Loss:  0.06117265671491623
Test Acc:  0.0
Valid Loss:  0.05935630947351456
Valid Acc:  0.0
std:  0.0010700620232897932 
thres:  8.232484310865402e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 52%|█████▏    | 523/1000 [24:30<22:55,  2.88s/it]Epoch:   524
max of grad d_p:  tensor(0.3470, device='cuda:0')
min of grad d_p:  tensor(-0.0444, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0357, device='cuda:0') mean:  tensor(-1.7001e-05, device='cuda:0') min:  tensor(-0.1636, device='cuda:0') norm:  tensor(0.3860, device='cuda:0') MSE:  tensor(1.4489e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.9365e-05, device='cuda:0') mean:  tensor(2.9086e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5888e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0023, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  524  
Training Loss: 0.08008098602294922
Test Loss:  0.060576699674129486
Test Acc:  0.0
Valid Loss:  0.058768246322870255
Valid Acc:  0.0
std:  0.0010593643813377202 
thres:  8.157184869050979e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 52%|█████▏    | 524/1000 [24:33<22:41,  2.86s/it]Epoch:   525
max of grad d_p:  tensor(0.3452, device='cuda:0')
min of grad d_p:  tensor(-0.0444, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0347, device='cuda:0') mean:  tensor(-1.6440e-05, device='cuda:0') min:  tensor(-0.1566, device='cuda:0') norm:  tensor(0.3809, device='cuda:0') MSE:  tensor(1.4297e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.1439e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.9159e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0057, device='cuda:0')
min of d_p_list:  tensor(-0.0037, device='cuda:0')
Epoch:  525  
Training Loss: 0.07936225831508636
Test Loss:  0.05996812880039215
Test Acc:  0.0
Valid Loss:  0.058178167790174484
Valid Acc:  0.0
std:  0.0010459407806344594 
thres:  8.082897812128067e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 52%|█████▎    | 525/1000 [24:35<22:09,  2.80s/it]Epoch:   526
max of grad d_p:  tensor(0.3436, device='cuda:0')
min of grad d_p:  tensor(-0.0440, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-1.8130e-05, device='cuda:0') min:  tensor(-0.1646, device='cuda:0') norm:  tensor(0.4010, device='cuda:0') MSE:  tensor(1.5054e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.0891e-05, device='cuda:0') mean:  tensor(2.4045e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.1698e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0020, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  526  
Training Loss: 0.07863663136959076
Test Loss:  0.05936887860298157
Test Acc:  0.0
Valid Loss:  0.057603608816862106
Valid Acc:  0.0
std:  0.001034256194953653 
thres:  8.009269386529923e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 53%|█████▎    | 526/1000 [24:38<21:33,  2.73s/it]Epoch:   527
max of grad d_p:  tensor(0.3418, device='cuda:0')
min of grad d_p:  tensor(-0.0439, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0330, device='cuda:0') mean:  tensor(-1.6549e-05, device='cuda:0') min:  tensor(-0.1565, device='cuda:0') norm:  tensor(0.3782, device='cuda:0') MSE:  tensor(1.4197e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.7706e-05, device='cuda:0') mean:  tensor(2.0817e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.0404e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0020, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  527  
Training Loss: 0.07791745662689209
Test Loss:  0.05877912789583206
Test Acc:  0.0
Valid Loss:  0.057033244520425797
Valid Acc:  0.0
std:  0.0010248336847913419 
thres:  7.936318218708038e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 53%|█████▎    | 527/1000 [24:40<21:17,  2.70s/it]Epoch:   528
max of grad d_p:  tensor(0.3401, device='cuda:0')
min of grad d_p:  tensor(-0.0437, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0364, device='cuda:0') mean:  tensor(-1.6526e-05, device='cuda:0') min:  tensor(-0.1298, device='cuda:0') norm:  tensor(0.3554, device='cuda:0') MSE:  tensor(1.3339e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.6109e-05, device='cuda:0') mean:  tensor(2.4248e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.1377e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0044, device='cuda:0')
min of d_p_list:  tensor(-0.0055, device='cuda:0')
Epoch:  528  
Training Loss: 0.07720573246479034
Test Loss:  0.058193713426589966
Test Acc:  0.0
Valid Loss:  0.056464388966560364
Valid Acc:  0.0
std:  0.0010175755057681775 
thres:  7.864061295986176e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 53%|█████▎    | 528/1000 [24:43<21:24,  2.72s/it]Epoch:   529
max of grad d_p:  tensor(0.3384, device='cuda:0')
min of grad d_p:  tensor(-0.0440, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0327, device='cuda:0') mean:  tensor(-1.4614e-05, device='cuda:0') min:  tensor(-0.1432, device='cuda:0') norm:  tensor(0.3523, device='cuda:0') MSE:  tensor(1.3223e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.8218e-05, device='cuda:0') mean:  tensor(2.9773e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5905e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0031, device='cuda:0')
Epoch:  529  
Training Loss: 0.0765044316649437
Test Loss:  0.057613980025053024
Test Acc:  0.0
Valid Loss:  0.055903900414705276
Valid Acc:  0.0
std:  0.0010106975114675004 
thres:  7.792530208826065e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 53%|█████▎    | 529/1000 [24:46<21:20,  2.72s/it]Epoch:   530
max of grad d_p:  tensor(0.3368, device='cuda:0')
min of grad d_p:  tensor(-0.0441, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0286, device='cuda:0') mean:  tensor(-1.7771e-05, device='cuda:0') min:  tensor(-0.1602, device='cuda:0') norm:  tensor(0.3792, device='cuda:0') MSE:  tensor(1.4233e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.6740e-05, device='cuda:0') mean:  tensor(3.4861e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7087e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0018, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  530  
Training Loss: 0.07580731809139252
Test Loss:  0.057044997811317444
Test Acc:  0.0
Valid Loss:  0.055350422859191895
Valid Acc:  0.0
std:  0.0010001040258695113 
thres:  7.721431404352188e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 53%|█████▎    | 530/1000 [24:49<21:41,  2.77s/it]Epoch:   531
max of grad d_p:  tensor(0.3351, device='cuda:0')
min of grad d_p:  tensor(-0.0439, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0327, device='cuda:0') mean:  tensor(-1.6332e-05, device='cuda:0') min:  tensor(-0.1616, device='cuda:0') norm:  tensor(0.3746, device='cuda:0') MSE:  tensor(1.4060e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(7.9750e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.1787e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  531  
Training Loss: 0.07511763274669647
Test Loss:  0.05648272484540939
Test Acc:  0.0
Valid Loss:  0.05480184406042099
Valid Acc:  0.0
std:  0.000989692470986558 
thres:  7.651051431894302e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 53%|█████▎    | 531/1000 [24:51<21:12,  2.71s/it]Epoch:   532
max of grad d_p:  tensor(0.3334, device='cuda:0')
min of grad d_p:  tensor(-0.0435, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0300, device='cuda:0') mean:  tensor(-1.8111e-05, device='cuda:0') min:  tensor(-0.1299, device='cuda:0') norm:  tensor(0.3450, device='cuda:0') MSE:  tensor(1.2949e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.8232e-05, device='cuda:0') mean:  tensor(2.7537e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4285e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0034, device='cuda:0')
min of d_p_list:  tensor(-0.0036, device='cuda:0')
Epoch:  532  
Training Loss: 0.07444837689399719
Test Loss:  0.05594060197472572
Test Acc:  0.0
Valid Loss:  0.05426781252026558
Valid Acc:  0.0
std:  0.0009760611864495123 
thres:  7.581669837236404e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 53%|█████▎    | 532/1000 [24:54<20:49,  2.67s/it]Epoch:   533
max of grad d_p:  tensor(0.3318, device='cuda:0')
min of grad d_p:  tensor(-0.0436, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0398, device='cuda:0') mean:  tensor(-1.9124e-05, device='cuda:0') min:  tensor(-0.1553, device='cuda:0') norm:  tensor(0.3934, device='cuda:0') MSE:  tensor(1.4766e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(2.7499e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.3305e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0074, device='cuda:0')
min of d_p_list:  tensor(-0.0086, device='cuda:0')
Epoch:  533  
Training Loss: 0.07382415235042572
Test Loss:  0.05546216666698456
Test Acc:  0.0
Valid Loss:  0.05379125848412514
Valid Acc:  0.0
std:  0.0009505034796477686 
thres:  7.514038234949113e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 53%|█████▎    | 533/1000 [24:57<20:49,  2.68s/it]Epoch:   534
max of grad d_p:  tensor(0.3303, device='cuda:0')
min of grad d_p:  tensor(-0.0439, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0326, device='cuda:0') mean:  tensor(-1.6667e-05, device='cuda:0') min:  tensor(-0.1515, device='cuda:0') norm:  tensor(0.3571, device='cuda:0') MSE:  tensor(1.3405e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.7503e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2741e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  534  
Training Loss: 0.07315394282341003
Test Loss:  0.05491634085774422
Test Acc:  0.0
Valid Loss:  0.05325701832771301
Valid Acc:  0.0
std:  0.0009335352895798714 
thres:  7.447028458118439e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 53%|█████▎    | 534/1000 [25:00<21:21,  2.75s/it]Epoch:   535
max of grad d_p:  tensor(0.3287, device='cuda:0')
min of grad d_p:  tensor(-0.0436, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0398, device='cuda:0') mean:  tensor(-1.6892e-05, device='cuda:0') min:  tensor(-0.1535, device='cuda:0') norm:  tensor(0.3757, device='cuda:0') MSE:  tensor(1.4103e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.2510e-05, device='cuda:0') mean:  tensor(2.2272e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.1138e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0132, device='cuda:0')
min of d_p_list:  tensor(-0.0135, device='cuda:0')
Epoch:  535  
Training Loss: 0.07266519963741302
Test Loss:  0.054539166390895844
Test Acc:  0.0
Valid Loss:  0.052826084196567535
Valid Acc:  0.0
std:  0.0008778988615436024 
thres:  7.384186089038849e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 54%|█████▎    | 535/1000 [25:02<21:32,  2.78s/it]Epoch:   536
max of grad d_p:  tensor(0.3276, device='cuda:0')
min of grad d_p:  tensor(-0.0436, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0330, device='cuda:0') mean:  tensor(-1.9566e-05, device='cuda:0') min:  tensor(-0.1646, device='cuda:0') norm:  tensor(0.3879, device='cuda:0') MSE:  tensor(1.4562e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(6.2038e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(3.1469e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0023, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  536  
Training Loss: 0.07200847566127777
Test Loss:  0.054005082696676254
Test Acc:  0.0
Valid Loss:  0.05230580270290375
Valid Acc:  0.0
std:  0.0008548529777815299 
thres:  7.322002947330474e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 54%|█████▎    | 536/1000 [25:05<21:39,  2.80s/it]Epoch:   537
max of grad d_p:  tensor(0.3260, device='cuda:0')
min of grad d_p:  tensor(-0.0434, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0355, device='cuda:0') mean:  tensor(-1.7601e-05, device='cuda:0') min:  tensor(-0.1677, device='cuda:0') norm:  tensor(0.3913, device='cuda:0') MSE:  tensor(1.4687e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.9587e-05, device='cuda:0') mean:  tensor(2.1790e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.0810e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  537  
Training Loss: 0.07135449349880219
Test Loss:  0.05347065627574921
Test Acc:  0.0
Valid Loss:  0.05178828164935112
Valid Acc:  0.0
std:  0.0008614908312615425 
thres:  7.260125279426574e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 54%|█████▎    | 537/1000 [25:08<22:05,  2.86s/it]Epoch:   538
max of grad d_p:  tensor(0.3243, device='cuda:0')
min of grad d_p:  tensor(-0.0433, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0319, device='cuda:0') mean:  tensor(-1.5627e-05, device='cuda:0') min:  tensor(-0.1349, device='cuda:0') norm:  tensor(0.3265, device='cuda:0') MSE:  tensor(1.2255e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.0982e-05, device='cuda:0') mean:  tensor(2.4399e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.2309e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0031, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  538  
Training Loss: 0.07070537656545639
Test Loss:  0.05294410139322281
Test Acc:  0.0
Valid Loss:  0.05127398669719696
Valid Acc:  0.0
std:  0.0008791294708817848 
thres:  7.197749763727188e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 54%|█████▍    | 538/1000 [25:11<21:33,  2.80s/it]Epoch:   539
max of grad d_p:  tensor(0.3227, device='cuda:0')
min of grad d_p:  tensor(-0.0432, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0320, device='cuda:0') mean:  tensor(-1.7934e-05, device='cuda:0') min:  tensor(-0.1309, device='cuda:0') norm:  tensor(0.3348, device='cuda:0') MSE:  tensor(1.2569e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.5699e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8834e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0110, device='cuda:0')
min of d_p_list:  tensor(-0.0052, device='cuda:0')
Epoch:  539  
Training Loss: 0.0701407864689827
Test Loss:  0.0524776391685009
Test Acc:  0.0
Valid Loss:  0.05085182562470436
Valid Acc:  0.0
std:  0.0008986662928306428 
thres:  7.137486636638641e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 54%|█████▍    | 539/1000 [25:14<21:07,  2.75s/it]Epoch:   540
max of grad d_p:  tensor(0.3214, device='cuda:0')
min of grad d_p:  tensor(-0.0429, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0327, device='cuda:0') mean:  tensor(-1.7491e-05, device='cuda:0') min:  tensor(-0.1485, device='cuda:0') norm:  tensor(0.3489, device='cuda:0') MSE:  tensor(1.3097e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0025, device='cuda:0') mean:  tensor(1.2592e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0164, device='cuda:0') MSE:  tensor(6.1483e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0287, device='cuda:0')
min of d_p_list:  tensor(-0.0237, device='cuda:0')
Epoch:  540  
Training Loss: 0.07003194093704224
Test Loss:  0.05248187854886055
Test Acc:  0.0
Valid Loss:  0.05067884922027588
Valid Acc:  0.0
std:  0.000746951673295558 
thres:  7.084821462631226e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 54%|█████▍    | 540/1000 [25:16<20:44,  2.70s/it]Epoch:   541
max of grad d_p:  tensor(0.3212, device='cuda:0')
min of grad d_p:  tensor(-0.0417, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0344, device='cuda:0') mean:  tensor(-1.7454e-05, device='cuda:0') min:  tensor(-0.1560, device='cuda:0') norm:  tensor(0.3374, device='cuda:0') MSE:  tensor(1.2664e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(4.3390e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0056, device='cuda:0') MSE:  tensor(2.0934e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0022, device='cuda:0')
min of d_p_list:  tensor(-0.0027, device='cuda:0')
Epoch:  541  
Training Loss: 0.0694049820303917
Test Loss:  0.05196153372526169
Test Acc:  0.0
Valid Loss:  0.05018162727355957
Valid Acc:  0.0
std:  0.0006589025497978671 
thres:  7.032751590013505e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 54%|█████▍    | 541/1000 [25:19<20:56,  2.74s/it]Epoch:   542
max of grad d_p:  tensor(0.3196, device='cuda:0')
min of grad d_p:  tensor(-0.0414, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0339, device='cuda:0') mean:  tensor(-1.8190e-05, device='cuda:0') min:  tensor(-0.1507, device='cuda:0') norm:  tensor(0.3525, device='cuda:0') MSE:  tensor(1.3232e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.8384e-05, device='cuda:0') mean:  tensor(2.5354e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.2219e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  542  
Training Loss: 0.06877921521663666
Test Loss:  0.05144879221916199
Test Acc:  0.0
Valid Loss:  0.049686163663864136
Valid Acc:  0.0
std:  0.0006613475973932908 
thres:  6.981246024370194e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 54%|█████▍    | 542/1000 [25:22<21:45,  2.85s/it]Epoch:   543
max of grad d_p:  tensor(0.3180, device='cuda:0')
min of grad d_p:  tensor(-0.0411, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0327, device='cuda:0') mean:  tensor(-2.0726e-05, device='cuda:0') min:  tensor(-0.1545, device='cuda:0') norm:  tensor(0.3617, device='cuda:0') MSE:  tensor(1.3576e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.7411e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0021, device='cuda:0') MSE:  tensor(8.0355e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  543  
Training Loss: 0.06815808266401291
Test Loss:  0.05093514546751976
Test Acc:  0.0
Valid Loss:  0.049191221594810486
Valid Acc:  0.0
std:  0.0007521738625271918 
thres:  6.930300146341324e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 54%|█████▍    | 543/1000 [25:25<21:10,  2.78s/it]Epoch:   544
max of grad d_p:  tensor(0.3164, device='cuda:0')
min of grad d_p:  tensor(-0.0409, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0378, device='cuda:0') mean:  tensor(-1.9063e-05, device='cuda:0') min:  tensor(-0.1482, device='cuda:0') norm:  tensor(0.3541, device='cuda:0') MSE:  tensor(1.3292e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.6935e-05, device='cuda:0') mean:  tensor(5.2898e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.6322e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0006, device='cuda:0')
Epoch:  544  
Training Loss: 0.0675429105758667
Test Loss:  0.05043196305632591
Test Acc:  0.0
Valid Loss:  0.048703402280807495
Valid Acc:  0.0
std:  0.0008803490197650104 
thres:  6.878342628479004e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 54%|█████▍    | 544/1000 [25:28<21:20,  2.81s/it]Epoch:   545
max of grad d_p:  tensor(0.3149, device='cuda:0')
min of grad d_p:  tensor(-0.0407, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0386, device='cuda:0') mean:  tensor(-1.9083e-05, device='cuda:0') min:  tensor(-0.1652, device='cuda:0') norm:  tensor(0.3765, device='cuda:0') MSE:  tensor(1.4133e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.7177e-05, device='cuda:0') mean:  tensor(2.2281e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.0776e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0358, device='cuda:0')
min of d_p_list:  tensor(-0.0410, device='cuda:0')
Epoch:  545  
Training Loss: 0.06852223724126816
Test Loss:  0.05100299417972565
Test Acc:  0.0
Valid Loss:  0.0490875244140625
Valid Acc:  0.0
std:  0.0006210735564756789 
thres:  6.848148554563523e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 55%|█████▍    | 545/1000 [25:30<21:11,  2.79s/it]Epoch:   546
max of grad d_p:  tensor(0.3191, device='cuda:0')
min of grad d_p:  tensor(-0.0452, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0369, device='cuda:0') mean:  tensor(-2.3151e-05, device='cuda:0') min:  tensor(-0.1467, device='cuda:0') norm:  tensor(0.3512, device='cuda:0') MSE:  tensor(1.3183e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0020, device='cuda:0') mean:  tensor(1.1941e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0150, device='cuda:0') MSE:  tensor(5.6418e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0125, device='cuda:0')
min of d_p_list:  tensor(-0.0165, device='cuda:0')
Epoch:  546  
Training Loss: 0.0682903528213501
Test Loss:  0.050834670662879944
Test Acc:  0.0
Valid Loss:  0.048910953104496
Valid Acc:  0.0
std:  0.0004156604669612206 
thres:  6.825855970382691e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 55%|█████▍    | 546/1000 [25:33<20:56,  2.77s/it]Epoch:   547
max of grad d_p:  tensor(0.3187, device='cuda:0')
min of grad d_p:  tensor(-0.0447, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0317, device='cuda:0') mean:  tensor(-2.1676e-05, device='cuda:0') min:  tensor(-0.1414, device='cuda:0') norm:  tensor(0.3327, device='cuda:0') MSE:  tensor(1.2489e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.3226e-05, device='cuda:0') mean:  tensor(2.2189e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.1581e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0039, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  547  
Training Loss: 0.0676794946193695
Test Loss:  0.05033392459154129
Test Acc:  0.0
Valid Loss:  0.04843132942914963
Valid Acc:  0.0
std:  0.0003704659902284801 
thres:  6.803861558437348e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 55%|█████▍    | 547/1000 [25:36<20:35,  2.73s/it]Epoch:   548
max of grad d_p:  tensor(0.3171, device='cuda:0')
min of grad d_p:  tensor(-0.0444, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0304, device='cuda:0') mean:  tensor(-2.0074e-05, device='cuda:0') min:  tensor(-0.1640, device='cuda:0') norm:  tensor(0.3528, device='cuda:0') MSE:  tensor(1.3242e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.3983e-05, device='cuda:0') mean:  tensor(3.1183e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5520e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0040, device='cuda:0')
Epoch:  548  
Training Loss: 0.06707215309143066
Test Loss:  0.049850575625896454
Test Acc:  0.0
Valid Loss:  0.047960009425878525
Valid Acc:  0.0
std:  0.0005234795142898653 
thres:  6.782142966985703e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 55%|█████▍    | 548/1000 [25:38<20:45,  2.76s/it]Epoch:   549
max of grad d_p:  tensor(0.3156, device='cuda:0')
min of grad d_p:  tensor(-0.0441, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0366, device='cuda:0') mean:  tensor(-2.0855e-05, device='cuda:0') min:  tensor(-0.1594, device='cuda:0') norm:  tensor(0.3596, device='cuda:0') MSE:  tensor(1.3497e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(1.9137e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0028, device='cuda:0') MSE:  tensor(1.0447e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0007, device='cuda:0')
Epoch:  549  
Training Loss: 0.0664673000574112
Test Loss:  0.04935746639966965
Test Acc:  0.0
Valid Loss:  0.047485459595918655
Valid Acc:  0.0
std:  0.0007609021663142835 
thres:  6.760630756616593e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 55%|█████▍    | 549/1000 [25:41<21:11,  2.82s/it]Epoch:   550
max of grad d_p:  tensor(0.3140, device='cuda:0')
min of grad d_p:  tensor(-0.0438, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0267, device='cuda:0') mean:  tensor(-1.9813e-05, device='cuda:0') min:  tensor(-0.1501, device='cuda:0') norm:  tensor(0.3273, device='cuda:0') MSE:  tensor(1.2286e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.4350e-05, device='cuda:0') mean:  tensor(2.6574e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4611e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0023, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  550  
Training Loss: 0.06586876511573792
Test Loss:  0.04886246845126152
Test Acc:  0.0
Valid Loss:  0.04700688272714615
Valid Acc:  0.0
std:  0.0008563649066399366 
thres:  6.707561314105987e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 55%|█████▌    | 550/1000 [25:44<20:37,  2.75s/it]Epoch:   551
max of grad d_p:  tensor(0.3124, device='cuda:0')
min of grad d_p:  tensor(-0.0435, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-2.1311e-05, device='cuda:0') min:  tensor(-0.1503, device='cuda:0') norm:  tensor(0.3437, device='cuda:0') MSE:  tensor(1.2902e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.1832e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.4812e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  551  
Training Loss: 0.06527610123157501
Test Loss:  0.04837987571954727
Test Acc:  0.0
Valid Loss:  0.04654090851545334
Valid Acc:  0.0
std:  0.0008499779242822815 
thres:  6.647276282310485e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 55%|█████▌    | 551/1000 [25:47<20:38,  2.76s/it]Epoch:   552
max of grad d_p:  tensor(0.3109, device='cuda:0')
min of grad d_p:  tensor(-0.0433, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0329, device='cuda:0') mean:  tensor(-2.0047e-05, device='cuda:0') min:  tensor(-0.1570, device='cuda:0') norm:  tensor(0.3498, device='cuda:0') MSE:  tensor(1.3132e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.4456e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0018, device='cuda:0') MSE:  tensor(6.6490e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0024, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  552  
Training Loss: 0.06469058245420456
Test Loss:  0.04789208993315697
Test Acc:  0.0
Valid Loss:  0.046080153435468674
Valid Acc:  0.0
std:  0.0008420876927968222 
thres:  6.587498039007186e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 55%|█████▌    | 552/1000 [25:49<20:13,  2.71s/it]Epoch:   553
max of grad d_p:  tensor(0.3093, device='cuda:0')
min of grad d_p:  tensor(-0.0429, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0369, device='cuda:0') mean:  tensor(-2.1723e-05, device='cuda:0') min:  tensor(-0.1649, device='cuda:0') norm:  tensor(0.3611, device='cuda:0') MSE:  tensor(1.3556e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(1.5612e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0019, device='cuda:0') MSE:  tensor(7.3149e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0007, device='cuda:0')
Epoch:  553  
Training Loss: 0.06410972028970718
Test Loss:  0.04741861671209335
Test Acc:  0.0
Valid Loss:  0.04562089592218399
Valid Acc:  0.0
std:  0.0008334599613556436 
thres:  6.528249382972717e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 55%|█████▌    | 553/1000 [25:52<20:13,  2.71s/it]Epoch:   554
max of grad d_p:  tensor(0.3078, device='cuda:0')
min of grad d_p:  tensor(-0.0427, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0317, device='cuda:0') mean:  tensor(-1.9279e-05, device='cuda:0') min:  tensor(-0.1624, device='cuda:0') norm:  tensor(0.3440, device='cuda:0') MSE:  tensor(1.2911e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.7804e-05, device='cuda:0') mean:  tensor(3.4164e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.6514e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0006, device='cuda:0')
Epoch:  554  
Training Loss: 0.06353439390659332
Test Loss:  0.04695271700620651
Test Acc:  0.0
Valid Loss:  0.04516928642988205
Valid Acc:  0.0
std:  0.0008252245006197315 
thres:  6.46959125995636e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 55%|█████▌    | 554/1000 [25:55<20:22,  2.74s/it]Epoch:   555
max of grad d_p:  tensor(0.3062, device='cuda:0')
min of grad d_p:  tensor(-0.0424, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0344, device='cuda:0') mean:  tensor(-2.1733e-05, device='cuda:0') min:  tensor(-0.1350, device='cuda:0') norm:  tensor(0.3349, device='cuda:0') MSE:  tensor(1.2573e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.5039e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0019, device='cuda:0') MSE:  tensor(7.0888e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0020, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  555  
Training Loss: 0.06296557188034058
Test Loss:  0.0464954674243927
Test Acc:  0.0
Valid Loss:  0.04472419247031212
Valid Acc:  0.0
std:  0.0008170394322930655 
thres:  6.411527395248413e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 56%|█████▌    | 555/1000 [25:58<20:20,  2.74s/it]Epoch:   556
max of grad d_p:  tensor(0.3047, device='cuda:0')
min of grad d_p:  tensor(-0.0421, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0342, device='cuda:0') mean:  tensor(-1.9840e-05, device='cuda:0') min:  tensor(-0.1452, device='cuda:0') norm:  tensor(0.3289, device='cuda:0') MSE:  tensor(1.2345e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.5124e-05, device='cuda:0') mean:  tensor(2.1933e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.0693e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0031, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  556  
Training Loss: 0.06240226328372955
Test Loss:  0.04603537917137146
Test Acc:  0.0
Valid Loss:  0.04427778720855713
Valid Acc:  0.0
std:  0.0008090567148104044 
thres:  6.354050636291505e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 56%|█████▌    | 556/1000 [26:01<21:21,  2.89s/it]Epoch:   557
max of grad d_p:  tensor(0.3032, device='cuda:0')
min of grad d_p:  tensor(-0.0419, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0388, device='cuda:0') mean:  tensor(-2.2877e-05, device='cuda:0') min:  tensor(-0.1705, device='cuda:0') norm:  tensor(0.3741, device='cuda:0') MSE:  tensor(1.4043e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.6588e-05, device='cuda:0') mean:  tensor(2.6925e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.2262e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0018, device='cuda:0')
Epoch:  557  
Training Loss: 0.06184419244527817
Test Loss:  0.04557383432984352
Test Acc:  0.0
Valid Loss:  0.0438326895236969
Valid Acc:  0.0
std:  0.0008009097968845922 
thres:  6.297122836112976e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 56%|█████▌    | 557/1000 [26:04<21:04,  2.86s/it]Epoch:   558
max of grad d_p:  tensor(0.3017, device='cuda:0')
min of grad d_p:  tensor(-0.0416, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0360, device='cuda:0') mean:  tensor(-2.2874e-05, device='cuda:0') min:  tensor(-0.1572, device='cuda:0') norm:  tensor(0.3663, device='cuda:0') MSE:  tensor(1.3751e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.5930e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8977e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  558  
Training Loss: 0.06129314750432968
Test Loss:  0.045128606259822845
Test Acc:  0.0
Valid Loss:  0.04340170696377754
Valid Acc:  0.0
std:  0.0007925222461465298 
thres:  6.240791380405426e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 56%|█████▌    | 558/1000 [26:06<20:30,  2.78s/it]Epoch:   559
max of grad d_p:  tensor(0.3002, device='cuda:0')
min of grad d_p:  tensor(-0.0413, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0384, device='cuda:0') mean:  tensor(-2.0807e-05, device='cuda:0') min:  tensor(-0.1790, device='cuda:0') norm:  tensor(0.3840, device='cuda:0') MSE:  tensor(1.4414e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.4627e-05, device='cuda:0') mean:  tensor(2.2869e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.0687e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  559  
Training Loss: 0.060745447874069214
Test Loss:  0.044678982347249985
Test Acc:  0.0
Valid Loss:  0.04296621307730675
Valid Acc:  0.0
std:  0.0007848119654622933 
thres:  6.185012459754944e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 56%|█████▌    | 559/1000 [26:09<20:35,  2.80s/it]Epoch:   560
max of grad d_p:  tensor(0.2987, device='cuda:0')
min of grad d_p:  tensor(-0.0410, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0325, device='cuda:0') mean:  tensor(-1.8334e-05, device='cuda:0') min:  tensor(-0.1517, device='cuda:0') norm:  tensor(0.3217, device='cuda:0') MSE:  tensor(1.2078e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.8267e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8884e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0019, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  560  
Training Loss: 0.06020023673772812
Test Loss:  0.044248275458812714
Test Acc:  0.0
Valid Loss:  0.0425538569688797
Valid Acc:  0.0
std:  0.0007782211414206234 
thres:  6.129705756902694e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 56%|█████▌    | 560/1000 [26:12<20:42,  2.82s/it]Epoch:   561
max of grad d_p:  tensor(0.2972, device='cuda:0')
min of grad d_p:  tensor(-0.0406, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0366, device='cuda:0') mean:  tensor(-2.1677e-05, device='cuda:0') min:  tensor(-0.1303, device='cuda:0') norm:  tensor(0.3283, device='cuda:0') MSE:  tensor(1.2325e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.1984e-05, device='cuda:0') mean:  tensor(2.7060e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.2285e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0045, device='cuda:0')
min of d_p_list:  tensor(-0.0029, device='cuda:0')
Epoch:  561  
Training Loss: 0.05966240540146828
Test Loss:  0.04382618889212608
Test Acc:  0.0
Valid Loss:  0.04214291274547577
Valid Acc:  0.0
std:  0.0007716714999097998 
thres:  6.074908599257469e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 56%|█████▌    | 561/1000 [26:15<20:39,  2.82s/it]Epoch:   562
max of grad d_p:  tensor(0.2957, device='cuda:0')
min of grad d_p:  tensor(-0.0402, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-2.3630e-05, device='cuda:0') min:  tensor(-0.1690, device='cuda:0') norm:  tensor(0.3790, device='cuda:0') MSE:  tensor(1.4227e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(6.9547e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.2669e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0079, device='cuda:0')
min of d_p_list:  tensor(-0.0070, device='cuda:0')
Epoch:  562  
Training Loss: 0.05915910005569458
Test Loss:  0.04338735342025757
Test Acc:  0.0
Valid Loss:  0.04173726588487625
Valid Acc:  0.0
std:  0.0007568668875659704 
thres:  6.021206751465798e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 56%|█████▌    | 562/1000 [26:18<20:16,  2.78s/it]Epoch:   563
max of grad d_p:  tensor(0.2943, device='cuda:0')
min of grad d_p:  tensor(-0.0398, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0381, device='cuda:0') mean:  tensor(-2.2912e-05, device='cuda:0') min:  tensor(-0.1577, device='cuda:0') norm:  tensor(0.3644, device='cuda:0') MSE:  tensor(1.3680e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.1083e-05, device='cuda:0') mean:  tensor(2.1199e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.0275e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0035, device='cuda:0')
min of d_p_list:  tensor(-0.0073, device='cuda:0')
Epoch:  563  
Training Loss: 0.05862779915332794
Test Loss:  0.042933255434036255
Test Acc:  0.0
Valid Loss:  0.0413023978471756
Valid Acc:  0.0
std:  0.0007462698382856198 
thres:  5.967899784445763e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 56%|█████▋    | 563/1000 [26:21<20:46,  2.85s/it]Epoch:   564
max of grad d_p:  tensor(0.2928, device='cuda:0')
min of grad d_p:  tensor(-0.0392, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-2.2344e-05, device='cuda:0') min:  tensor(-0.1500, device='cuda:0') norm:  tensor(0.3476, device='cuda:0') MSE:  tensor(1.3048e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.7389e-05, device='cuda:0') mean:  tensor(2.1825e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.0418e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0024, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  564  
Training Loss: 0.058108583092689514
Test Loss:  0.042509935796260834
Test Acc:  0.0
Valid Loss:  0.04089069738984108
Valid Acc:  0.0
std:  0.0007379524387832116 
thres:  5.915162488818169e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 56%|█████▋    | 564/1000 [26:23<20:53,  2.87s/it]Epoch:   565
max of grad d_p:  tensor(0.2913, device='cuda:0')
min of grad d_p:  tensor(-0.0391, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-2.2217e-05, device='cuda:0') min:  tensor(-0.1459, device='cuda:0') norm:  tensor(0.3395, device='cuda:0') MSE:  tensor(1.2745e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.3046e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0016, device='cuda:0') MSE:  tensor(6.1768e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0075, device='cuda:0')
min of d_p_list:  tensor(-0.0053, device='cuda:0')
Epoch:  565  
Training Loss: 0.05762253701686859
Test Loss:  0.04210299253463745
Test Acc:  0.0
Valid Loss:  0.04051167890429497
Valid Acc:  0.0
std:  0.0007256010951665128 
thres:  5.863608494400978e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 56%|█████▋    | 565/1000 [26:27<21:25,  2.95s/it]Epoch:   566
max of grad d_p:  tensor(0.2900, device='cuda:0')
min of grad d_p:  tensor(-0.0382, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0348, device='cuda:0') mean:  tensor(-2.2645e-05, device='cuda:0') min:  tensor(-0.1465, device='cuda:0') norm:  tensor(0.3368, device='cuda:0') MSE:  tensor(1.2644e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.4399e-05, device='cuda:0') mean:  tensor(1.4958e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0002, device='cuda:0') MSE:  tensor(7.0384e-10, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0158, device='cuda:0')
min of d_p_list:  tensor(-0.0144, device='cuda:0')
Epoch:  566  
Training Loss: 0.05711624026298523
Test Loss:  0.04176221042871475
Test Acc:  0.0
Valid Loss:  0.04013904556632042
Valid Acc:  0.0
std:  0.0007200677103008769 
thres:  5.8126851916313175e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 57%|█████▋    | 566/1000 [26:30<21:41,  3.00s/it]Epoch:   567
max of grad d_p:  tensor(0.2885, device='cuda:0')
min of grad d_p:  tensor(-0.0379, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0336, device='cuda:0') mean:  tensor(-1.9661e-05, device='cuda:0') min:  tensor(-0.1242, device='cuda:0') norm:  tensor(0.3138, device='cuda:0') MSE:  tensor(1.1779e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.1586e-05, device='cuda:0') mean:  tensor(1.7521e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0002, device='cuda:0') MSE:  tensor(8.5219e-10, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0018, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  567  
Training Loss: 0.056611765176057816
Test Loss:  0.04135262221097946
Test Acc:  0.0
Valid Loss:  0.039744045585393906
Valid Acc:  0.0
std:  0.0007105851319199056 
thres:  5.761738494038582e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 57%|█████▋    | 567/1000 [26:33<21:33,  2.99s/it]Epoch:   568
max of grad d_p:  tensor(0.2870, device='cuda:0')
min of grad d_p:  tensor(-0.0377, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-2.0256e-05, device='cuda:0') min:  tensor(-0.1489, device='cuda:0') norm:  tensor(0.3421, device='cuda:0') MSE:  tensor(1.2843e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.5216e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.6889e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0009, device='cuda:0')
Epoch:  568  
Training Loss: 0.05611111968755722
Test Loss:  0.04094459488987923
Test Acc:  0.0
Valid Loss:  0.0393502451479435
Valid Acc:  0.0
std:  0.0007079292580484433 
thres:  5.711404904723168e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 57%|█████▋    | 568/1000 [26:36<21:16,  2.95s/it]Epoch:   569
max of grad d_p:  tensor(0.2856, device='cuda:0')
min of grad d_p:  tensor(-0.0375, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-1.9672e-05, device='cuda:0') min:  tensor(-0.1577, device='cuda:0') norm:  tensor(0.3430, device='cuda:0') MSE:  tensor(1.2874e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.5364e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7542e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  569  
Training Loss: 0.055615589022636414
Test Loss:  0.040542975068092346
Test Acc:  0.0
Valid Loss:  0.038960929960012436
Valid Acc:  0.0
std:  0.0007098027561339001 
thres:  5.661545023322105e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 57%|█████▋    | 569/1000 [26:38<20:55,  2.91s/it]Epoch:   570
max of grad d_p:  tensor(0.2842, device='cuda:0')
min of grad d_p:  tensor(-0.0372, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0357, device='cuda:0') mean:  tensor(-2.2902e-05, device='cuda:0') min:  tensor(-0.1432, device='cuda:0') norm:  tensor(0.3496, device='cuda:0') MSE:  tensor(1.3124e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.6308e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(3.0299e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0023, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  570  
Training Loss: 0.05512502044439316
Test Loss:  0.0401325523853302
Test Acc:  0.0
Valid Loss:  0.03856998682022095
Valid Acc:  0.0
std:  0.0007040936191653128 
thres:  5.6115946918725973e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 57%|█████▋    | 570/1000 [26:41<20:55,  2.92s/it]Epoch:   571
max of grad d_p:  tensor(0.2828, device='cuda:0')
min of grad d_p:  tensor(-0.0370, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0342, device='cuda:0') mean:  tensor(-2.1010e-05, device='cuda:0') min:  tensor(-0.1527, device='cuda:0') norm:  tensor(0.3378, device='cuda:0') MSE:  tensor(1.2681e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.7055e-05, device='cuda:0') mean:  tensor(3.4261e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5479e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  571  
Training Loss: 0.05464138835668564
Test Loss:  0.03973621129989624
Test Acc:  0.0
Valid Loss:  0.038188524544239044
Valid Acc:  0.0
std:  0.0006967778569157694 
thres:  5.562097653746605e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 57%|█████▋    | 571/1000 [26:44<20:20,  2.84s/it]Epoch:   572
max of grad d_p:  tensor(0.2814, device='cuda:0')
min of grad d_p:  tensor(-0.0368, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0405, device='cuda:0') mean:  tensor(-2.4463e-05, device='cuda:0') min:  tensor(-0.1514, device='cuda:0') norm:  tensor(0.3706, device='cuda:0') MSE:  tensor(1.3912e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(5.2045e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(3.1631e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0020, device='cuda:0')
min of d_p_list:  tensor(-0.0049, device='cuda:0')
Epoch:  572  
Training Loss: 0.05416272580623627
Test Loss:  0.03934387117624283
Test Acc:  0.0
Valid Loss:  0.037811752408742905
Valid Acc:  0.0
std:  0.0006888789750345333 
thres:  5.513116866350174e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 57%|█████▋    | 572/1000 [26:47<19:48,  2.78s/it]Epoch:   573
max of grad d_p:  tensor(0.2800, device='cuda:0')
min of grad d_p:  tensor(-0.0367, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0352, device='cuda:0') mean:  tensor(-2.2572e-05, device='cuda:0') min:  tensor(-0.1478, device='cuda:0') norm:  tensor(0.3443, device='cuda:0') MSE:  tensor(1.2922e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(7.4544e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.3763e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0189, device='cuda:0')
min of d_p_list:  tensor(-0.0073, device='cuda:0')
Epoch:  573  
Training Loss: 0.05370989441871643
Test Loss:  0.03897225856781006
Test Acc:  0.0
Valid Loss:  0.03743433952331543
Valid Acc:  0.0
std:  0.000675175698943898 
thres:  5.465092360973358e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 57%|█████▋    | 573/1000 [26:49<19:31,  2.74s/it]Epoch:   574
max of grad d_p:  tensor(0.2787, device='cuda:0')
min of grad d_p:  tensor(-0.0363, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0373, device='cuda:0') mean:  tensor(-2.3136e-05, device='cuda:0') min:  tensor(-0.1649, device='cuda:0') norm:  tensor(0.3713, device='cuda:0') MSE:  tensor(1.3938e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.9207e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9929e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0060, device='cuda:0')
min of d_p_list:  tensor(-0.0118, device='cuda:0')
Epoch:  574  
Training Loss: 0.05326554924249649
Test Loss:  0.038575418293476105
Test Acc:  0.0
Valid Loss:  0.03706303983926773
Valid Acc:  0.0
std:  0.0006577927495983009 
thres:  5.41809156537056e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 57%|█████▋    | 574/1000 [26:52<19:07,  2.69s/it]Epoch:   575
max of grad d_p:  tensor(0.2774, device='cuda:0')
min of grad d_p:  tensor(-0.0360, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0382, device='cuda:0') mean:  tensor(-2.2825e-05, device='cuda:0') min:  tensor(-0.1585, device='cuda:0') norm:  tensor(0.3644, device='cuda:0') MSE:  tensor(1.3678e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(9.9147e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.3329e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  575  
Training Loss: 0.05279877036809921
Test Loss:  0.03819014132022858
Test Acc:  0.0
Valid Loss:  0.036692164838314056
Valid Acc:  0.0
std:  0.0006480988131996073 
thres:  5.3715665638446804e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 57%|█████▊    | 575/1000 [26:55<19:53,  2.81s/it]Epoch:   576
max of grad d_p:  tensor(0.2760, device='cuda:0')
min of grad d_p:  tensor(-0.0358, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-2.3025e-05, device='cuda:0') min:  tensor(-0.1675, device='cuda:0') norm:  tensor(0.3722, device='cuda:0') MSE:  tensor(1.3973e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.2478e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0015, device='cuda:0') MSE:  tensor(5.6406e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0056, device='cuda:0')
min of d_p_list:  tensor(-0.0093, device='cuda:0')
Epoch:  576  
Training Loss: 0.05233902856707573
Test Loss:  0.03782439976930618
Test Acc:  0.0
Valid Loss:  0.036335013806819916
Valid Acc:  0.0
std:  0.0006446945499072924 
thres:  5.325519368052482e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 58%|█████▊    | 576/1000 [26:58<20:07,  2.85s/it]Epoch:   577
max of grad d_p:  tensor(0.2746, device='cuda:0')
min of grad d_p:  tensor(-0.0356, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0382, device='cuda:0') mean:  tensor(-2.4617e-05, device='cuda:0') min:  tensor(-0.1406, device='cuda:0') norm:  tensor(0.3491, device='cuda:0') MSE:  tensor(1.3105e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.6552e-05, device='cuda:0') mean:  tensor(4.1428e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8795e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  577  
Training Loss: 0.05188171565532684
Test Loss:  0.03744690120220184
Test Acc:  0.0
Valid Loss:  0.035971082746982574
Valid Acc:  0.0
std:  0.0006481328842442557 
thres:  5.279899165034294e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 58%|█████▊    | 577/1000 [27:01<19:39,  2.79s/it]Epoch:   578
max of grad d_p:  tensor(0.2733, device='cuda:0')
min of grad d_p:  tensor(-0.0354, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0383, device='cuda:0') mean:  tensor(-2.5246e-05, device='cuda:0') min:  tensor(-0.1540, device='cuda:0') norm:  tensor(0.3679, device='cuda:0') MSE:  tensor(1.3811e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.5054e-05, device='cuda:0') mean:  tensor(3.3172e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.6102e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0034, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  578  
Training Loss: 0.05143061280250549
Test Loss:  0.03708304464817047
Test Acc:  0.0
Valid Loss:  0.03561883047223091
Valid Acc:  0.0
std:  0.0006487022520036315 
thres:  5.234313532710076e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 58%|█████▊    | 578/1000 [27:03<19:44,  2.81s/it]Epoch:   579
max of grad d_p:  tensor(0.2719, device='cuda:0')
min of grad d_p:  tensor(-0.0352, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0389, device='cuda:0') mean:  tensor(-2.4481e-05, device='cuda:0') min:  tensor(-0.1461, device='cuda:0') norm:  tensor(0.3594, device='cuda:0') MSE:  tensor(1.3489e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.6276e-05, device='cuda:0') mean:  tensor(5.2866e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.5085e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  579  
Training Loss: 0.05098246783018112
Test Loss:  0.0367107130587101
Test Acc:  0.0
Valid Loss:  0.035264261066913605
Valid Acc:  0.0
std:  0.0006422070565758011 
thres:  5.1886519044637685e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 58%|█████▊    | 579/1000 [27:06<19:48,  2.82s/it]Epoch:   580
max of grad d_p:  tensor(0.2705, device='cuda:0')
min of grad d_p:  tensor(-0.0349, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0414, device='cuda:0') mean:  tensor(-2.1531e-05, device='cuda:0') min:  tensor(-0.1631, device='cuda:0') norm:  tensor(0.3616, device='cuda:0') MSE:  tensor(1.3574e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.8976e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.9444e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0007, device='cuda:0')
Epoch:  580  
Training Loss: 0.050537630915641785
Test Loss:  0.03634452074766159
Test Acc:  0.0
Valid Loss:  0.034909557551145554
Valid Acc:  0.0
std:  0.0006366939453576741 
thres:  5.14342911541462e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 58%|█████▊    | 580/1000 [27:09<19:32,  2.79s/it]Epoch:   581
max of grad d_p:  tensor(0.2692, device='cuda:0')
min of grad d_p:  tensor(-0.0347, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0385, device='cuda:0') mean:  tensor(-2.3419e-05, device='cuda:0') min:  tensor(-0.1802, device='cuda:0') norm:  tensor(0.3979, device='cuda:0') MSE:  tensor(1.4936e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.6734e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.3773e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0123, device='cuda:0')
min of d_p_list:  tensor(-0.0171, device='cuda:0')
Epoch:  581  
Training Loss: 0.050071969628334045
Test Loss:  0.036028824746608734
Test Acc:  0.0
Valid Loss:  0.03455117344856262
Valid Acc:  0.0
std:  0.0006381778446901154 
thres:  5.098087936639786e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 58%|█████▊    | 581/1000 [27:12<19:26,  2.78s/it]Epoch:   582
max of grad d_p:  tensor(0.2677, device='cuda:0')
min of grad d_p:  tensor(-0.0357, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0352, device='cuda:0') mean:  tensor(-2.1497e-05, device='cuda:0') min:  tensor(-0.1562, device='cuda:0') norm:  tensor(0.3559, device='cuda:0') MSE:  tensor(1.3359e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.0291e-05, device='cuda:0') mean:  tensor(2.8627e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.2283e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0043, device='cuda:0')
min of d_p_list:  tensor(-0.0079, device='cuda:0')
Epoch:  582  
Training Loss: 0.04968244209885597
Test Loss:  0.03573359549045563
Test Acc:  0.0
Valid Loss:  0.03426995500922203
Valid Acc:  0.0
std:  0.000623446435601085 
thres:  5.0541024655103686e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 58%|█████▊    | 582/1000 [27:14<19:21,  2.78s/it]Epoch:   583
max of grad d_p:  tensor(0.2666, device='cuda:0')
min of grad d_p:  tensor(-0.0356, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0381, device='cuda:0') mean:  tensor(-2.2976e-05, device='cuda:0') min:  tensor(-0.1676, device='cuda:0') norm:  tensor(0.3604, device='cuda:0') MSE:  tensor(1.3529e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.6144e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9815e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0008, device='cuda:0')
Epoch:  583  
Training Loss: 0.04925103485584259
Test Loss:  0.035384297370910645
Test Acc:  0.0
Valid Loss:  0.033932268619537354
Valid Acc:  0.0
std:  0.0006109045580780234 
thres:  5.0105109065771106e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 58%|█████▊    | 583/1000 [27:17<18:54,  2.72s/it]Epoch:   584
max of grad d_p:  tensor(0.2652, device='cuda:0')
min of grad d_p:  tensor(-0.0353, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-2.2458e-05, device='cuda:0') min:  tensor(-0.1591, device='cuda:0') norm:  tensor(0.3518, device='cuda:0') MSE:  tensor(1.3205e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.8551e-05, device='cuda:0') mean:  tensor(5.2682e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.6241e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0032, device='cuda:0')
Epoch:  584  
Training Loss: 0.048822298645973206
Test Loss:  0.035027481615543365
Test Acc:  0.0
Valid Loss:  0.03359055891633034
Valid Acc:  0.0
std:  0.0006014316064486816 
thres:  4.967307522892952e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 58%|█████▊    | 584/1000 [27:20<18:44,  2.70s/it]Epoch:   585
max of grad d_p:  tensor(0.2639, device='cuda:0')
min of grad d_p:  tensor(-0.0351, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0409, device='cuda:0') mean:  tensor(-2.4354e-05, device='cuda:0') min:  tensor(-0.1584, device='cuda:0') norm:  tensor(0.3789, device='cuda:0') MSE:  tensor(1.4223e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.7444e-05, device='cuda:0') mean:  tensor(2.5625e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.1965e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0022, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  585  
Training Loss: 0.04840153455734253
Test Loss:  0.03469400480389595
Test Acc:  0.0
Valid Loss:  0.033266618847846985
Valid Acc:  0.0
std:  0.0005942015651044213 
thres:  4.924585595726967e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 58%|█████▊    | 585/1000 [27:23<19:07,  2.77s/it]Epoch:   586
max of grad d_p:  tensor(0.2626, device='cuda:0')
min of grad d_p:  tensor(-0.0348, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0344, device='cuda:0') mean:  tensor(-2.1679e-05, device='cuda:0') min:  tensor(-0.1492, device='cuda:0') norm:  tensor(0.3269, device='cuda:0') MSE:  tensor(1.2271e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.2262e-05, device='cuda:0') mean:  tensor(2.2881e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.2400e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0039, device='cuda:0')
min of d_p_list:  tensor(-0.0031, device='cuda:0')
Epoch:  586  
Training Loss: 0.04798746481537819
Test Loss:  0.03435090184211731
Test Acc:  0.0
Valid Loss:  0.03293861448764801
Valid Acc:  0.0
std:  0.0005995714978694323 
thres:  4.88289549946785e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 59%|█████▊    | 586/1000 [27:25<18:53,  2.74s/it]Epoch:   587
max of grad d_p:  tensor(0.2613, device='cuda:0')
min of grad d_p:  tensor(-0.0347, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0379, device='cuda:0') mean:  tensor(-2.3521e-05, device='cuda:0') min:  tensor(-0.1453, device='cuda:0') norm:  tensor(0.3510, device='cuda:0') MSE:  tensor(1.3177e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.4890e-05, device='cuda:0') mean:  tensor(2.1543e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.0488e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  587  
Training Loss: 0.04757280275225639
Test Loss:  0.03401080518960953
Test Acc:  0.0
Valid Loss:  0.03261110931634903
Valid Acc:  0.0
std:  0.0005927550067080972 
thres:  4.8407027125358586e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 59%|█████▊    | 587/1000 [27:28<18:50,  2.74s/it]Epoch:   588
max of grad d_p:  tensor(0.2600, device='cuda:0')
min of grad d_p:  tensor(-0.0344, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0430, device='cuda:0') mean:  tensor(-2.2431e-05, device='cuda:0') min:  tensor(-0.1676, device='cuda:0') norm:  tensor(0.3742, device='cuda:0') MSE:  tensor(1.4046e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(1.1982e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0015, device='cuda:0') MSE:  tensor(5.6519e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0010, device='cuda:0')
Epoch:  588  
Training Loss: 0.047162458300590515
Test Loss:  0.03367620334029198
Test Acc:  0.0
Valid Loss:  0.03228802978992462
Valid Acc:  0.0
std:  0.0005866795709628307 
thres:  4.798931181430817e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 59%|█████▉    | 588/1000 [27:31<18:32,  2.70s/it]Epoch:   589
max of grad d_p:  tensor(0.2587, device='cuda:0')
min of grad d_p:  tensor(-0.0342, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0423, device='cuda:0') mean:  tensor(-2.5115e-05, device='cuda:0') min:  tensor(-0.1687, device='cuda:0') norm:  tensor(0.3770, device='cuda:0') MSE:  tensor(1.4150e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(6.6815e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.3558e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  589  
Training Loss: 0.0467565692961216
Test Loss:  0.03334135562181473
Test Acc:  0.0
Valid Loss:  0.0319654755294323
Valid Acc:  0.0
std:  0.0005819457191140064 
thres:  4.757616594433785e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 59%|█████▉    | 589/1000 [27:34<18:56,  2.76s/it]Epoch:   590
max of grad d_p:  tensor(0.2574, device='cuda:0')
min of grad d_p:  tensor(-0.0340, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0424, device='cuda:0') mean:  tensor(-2.3738e-05, device='cuda:0') min:  tensor(-0.1820, device='cuda:0') norm:  tensor(0.3919, device='cuda:0') MSE:  tensor(1.4711e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.4542e-05, device='cuda:0') mean:  tensor(3.6729e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8554e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  590  
Training Loss: 0.04635321721434593
Test Loss:  0.03301694989204407
Test Acc:  0.0
Valid Loss:  0.03165150433778763
Valid Acc:  0.0
std:  0.0005776769964793505 
thres:  4.716650247573852e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 59%|█████▉    | 590/1000 [27:36<18:36,  2.72s/it]Epoch:   591
max of grad d_p:  tensor(0.2561, device='cuda:0')
min of grad d_p:  tensor(-0.0337, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-2.4045e-05, device='cuda:0') min:  tensor(-0.1544, device='cuda:0') norm:  tensor(0.3568, device='cuda:0') MSE:  tensor(1.3392e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.3481e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.0701e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0184, device='cuda:0')
min of d_p_list:  tensor(-0.0338, device='cuda:0')
Epoch:  591  
Training Loss: 0.046347785741090775
Test Loss:  0.03307794779539108
Test Acc:  0.0
Valid Loss:  0.03169278800487518
Valid Acc:  0.0
std:  0.0004747972191286416 
thres:  4.683856666088104e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 59%|█████▉    | 591/1000 [27:39<18:15,  2.68s/it]Epoch:   592
max of grad d_p:  tensor(0.2561, device='cuda:0')
min of grad d_p:  tensor(-0.0331, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0416, device='cuda:0') mean:  tensor(-2.3511e-05, device='cuda:0') min:  tensor(-0.1697, device='cuda:0') norm:  tensor(0.3770, device='cuda:0') MSE:  tensor(1.4152e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(8.1089e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.8050e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0029, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  592  
Training Loss: 0.04595063626766205
Test Loss:  0.03276210278272629
Test Acc:  0.0
Valid Loss:  0.03138842433691025
Valid Acc:  0.0
std:  0.0004123578351473648 
thres:  4.6514133363962176e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 59%|█████▉    | 592/1000 [27:41<18:00,  2.65s/it]Epoch:   593
max of grad d_p:  tensor(0.2548, device='cuda:0')
min of grad d_p:  tensor(-0.0328, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0352, device='cuda:0') mean:  tensor(-2.5538e-05, device='cuda:0') min:  tensor(-0.1797, device='cuda:0') norm:  tensor(0.3849, device='cuda:0') MSE:  tensor(1.4450e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.5140e-05, device='cuda:0') mean:  tensor(2.7847e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.3077e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0007, device='cuda:0')
min of d_p_list:  tensor(-0.0007, device='cuda:0')
Epoch:  593  
Training Loss: 0.045556098222732544
Test Loss:  0.03244062513113022
Test Acc:  0.0
Valid Loss:  0.03107808157801628
Valid Acc:  0.0
std:  0.00040782900570377915 
thres:  4.619286134839058e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 59%|█████▉    | 593/1000 [27:44<18:02,  2.66s/it]Epoch:   594
max of grad d_p:  tensor(0.2535, device='cuda:0')
min of grad d_p:  tensor(-0.0326, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0372, device='cuda:0') mean:  tensor(-2.2130e-05, device='cuda:0') min:  tensor(-0.1497, device='cuda:0') norm:  tensor(0.3524, device='cuda:0') MSE:  tensor(1.3228e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(7.4012e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.6250e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0016, device='cuda:0')
min of d_p_list:  tensor(-0.0031, device='cuda:0')
Epoch:  594  
Training Loss: 0.04516976326704025
Test Loss:  0.03212764114141464
Test Acc:  0.0
Valid Loss:  0.03077157959342003
Valid Acc:  0.0
std:  0.00045978143686070834 
thres:  4.587550014257431e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 59%|█████▉    | 594/1000 [27:47<18:02,  2.67s/it]Epoch:   595
max of grad d_p:  tensor(0.2523, device='cuda:0')
min of grad d_p:  tensor(-0.0326, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0382, device='cuda:0') mean:  tensor(-2.0280e-05, device='cuda:0') min:  tensor(-0.1589, device='cuda:0') norm:  tensor(0.3528, device='cuda:0') MSE:  tensor(1.3245e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.1320e-05, device='cuda:0') mean:  tensor(1.8316e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0002, device='cuda:0') MSE:  tensor(9.3748e-10, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0040, device='cuda:0')
min of d_p_list:  tensor(-0.0031, device='cuda:0')
Epoch:  595  
Training Loss: 0.04478900134563446
Test Loss:  0.031827084720134735
Test Acc:  0.0
Valid Loss:  0.030477650463581085
Valid Acc:  0.0
std:  0.0005513450147978886 
thres:  4.556265696883201e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 60%|█████▉    | 595/1000 [27:49<18:04,  2.68s/it]Epoch:   596
max of grad d_p:  tensor(0.2511, device='cuda:0')
min of grad d_p:  tensor(-0.0326, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0447, device='cuda:0') mean:  tensor(-2.6111e-05, device='cuda:0') min:  tensor(-0.1873, device='cuda:0') norm:  tensor(0.4153, device='cuda:0') MSE:  tensor(1.5591e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(2.8379e-06, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0034, device='cuda:0') MSE:  tensor(1.2831e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0005, device='cuda:0')
Epoch:  596  
Training Loss: 0.04440648481249809
Test Loss:  0.03150949627161026
Test Acc:  0.0
Valid Loss:  0.03017324209213257
Valid Acc:  0.0
std:  0.0005452492335977641 
thres:  4.5174396783113484e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 60%|█████▉    | 596/1000 [27:52<17:52,  2.65s/it]Epoch:   597
max of grad d_p:  tensor(0.2498, device='cuda:0')
min of grad d_p:  tensor(-0.0324, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0379, device='cuda:0') mean:  tensor(-2.3058e-05, device='cuda:0') min:  tensor(-0.1448, device='cuda:0') norm:  tensor(0.3528, device='cuda:0') MSE:  tensor(1.3245e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.4860e-05, device='cuda:0') mean:  tensor(1.8579e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0002, device='cuda:0') MSE:  tensor(8.7710e-10, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  597  
Training Loss: 0.04402751475572586
Test Loss:  0.031197326257824898
Test Acc:  0.0
Valid Loss:  0.029874395579099655
Valid Acc:  0.0
std:  0.0005402952916938863 
thres:  4.4789772480726244e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 60%|█████▉    | 597/1000 [27:55<17:47,  2.65s/it]Epoch:   598
max of grad d_p:  tensor(0.2486, device='cuda:0')
min of grad d_p:  tensor(-0.0322, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0403, device='cuda:0') mean:  tensor(-2.4115e-05, device='cuda:0') min:  tensor(-0.1643, device='cuda:0') norm:  tensor(0.3817, device='cuda:0') MSE:  tensor(1.4329e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.4116e-05, device='cuda:0') mean:  tensor(1.9507e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(9.6394e-10, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0027, device='cuda:0')
Epoch:  598  
Training Loss: 0.04365548864006996
Test Loss:  0.030895525589585304
Test Acc:  0.0
Valid Loss:  0.029589887708425522
Valid Acc:  0.0
std:  0.0005359993175935197 
thres:  4.440965056419373e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 60%|█████▉    | 598/1000 [27:57<17:42,  2.64s/it]Epoch:   599
max of grad d_p:  tensor(0.2473, device='cuda:0')
min of grad d_p:  tensor(-0.0319, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0334, device='cuda:0') mean:  tensor(-2.3119e-05, device='cuda:0') min:  tensor(-0.1385, device='cuda:0') norm:  tensor(0.3309, device='cuda:0') MSE:  tensor(1.2420e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.3313e-05, device='cuda:0') mean:  tensor(3.1330e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5641e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0017, device='cuda:0')
min of d_p_list:  tensor(-0.0031, device='cuda:0')
Epoch:  599  
Training Loss: 0.043285615742206573
Test Loss:  0.030598588287830353
Test Acc:  0.0
Valid Loss:  0.02930700033903122
Valid Acc:  0.0
std:  0.0005314427388246553 
thres:  4.403282105922699e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 60%|█████▉    | 599/1000 [28:00<18:01,  2.70s/it]Epoch:   600
max of grad d_p:  tensor(0.2461, device='cuda:0')
min of grad d_p:  tensor(-0.0317, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0415, device='cuda:0') mean:  tensor(-2.3093e-05, device='cuda:0') min:  tensor(-0.1491, device='cuda:0') norm:  tensor(0.3650, device='cuda:0') MSE:  tensor(1.3703e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.3536e-05, device='cuda:0') mean:  tensor(4.4104e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9711e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0022, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  600  
Training Loss: 0.04291889816522598
Test Loss:  0.030299346894025803
Test Acc:  0.0
Valid Loss:  0.029017416760325432
Valid Acc:  0.0
std:  0.0005256834276255564 
thres:  4.365880042314529e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 60%|██████    | 600/1000 [28:03<17:43,  2.66s/it]Epoch:   601
max of grad d_p:  tensor(0.2449, device='cuda:0')
min of grad d_p:  tensor(-0.0316, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0426, device='cuda:0') mean:  tensor(-2.7689e-05, device='cuda:0') min:  tensor(-0.1551, device='cuda:0') norm:  tensor(0.4012, device='cuda:0') MSE:  tensor(1.5062e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.2283e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.8818e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0010, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  601  
Training Loss: 0.042554374784231186
Test Loss:  0.03000115230679512
Test Acc:  0.0
Valid Loss:  0.028731098398566246
Valid Acc:  0.0
std:  0.0005208410630601947 
thres:  4.328837841749191e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 60%|██████    | 601/1000 [28:06<18:03,  2.72s/it]Epoch:   602
max of grad d_p:  tensor(0.2437, device='cuda:0')
min of grad d_p:  tensor(-0.0314, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0386, device='cuda:0') mean:  tensor(-2.1254e-05, device='cuda:0') min:  tensor(-0.1753, device='cuda:0') norm:  tensor(0.3591, device='cuda:0') MSE:  tensor(1.3481e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.8235e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.3508e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  602  
Training Loss: 0.04219362139701843
Test Loss:  0.029706373810768127
Test Acc:  0.0
Valid Loss:  0.028445178642868996
Valid Acc:  0.0
std:  0.0005168973789843028 
thres:  4.292159974575042e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 60%|██████    | 602/1000 [28:09<18:37,  2.81s/it]Epoch:   603
max of grad d_p:  tensor(0.2425, device='cuda:0')
min of grad d_p:  tensor(-0.0312, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0389, device='cuda:0') mean:  tensor(-2.3012e-05, device='cuda:0') min:  tensor(-0.1660, device='cuda:0') norm:  tensor(0.3649, device='cuda:0') MSE:  tensor(1.3696e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.8140e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2296e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0233, device='cuda:0')
min of d_p_list:  tensor(-0.0229, device='cuda:0')
Epoch:  603  
Training Loss: 0.041890740394592285
Test Loss:  0.02948911488056183
Test Acc:  0.0
Valid Loss:  0.02823045291006565
Valid Acc:  0.0
std:  0.0004974183994758415 
thres:  4.256865009665489e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 60%|██████    | 603/1000 [28:12<18:53,  2.86s/it]Epoch:   604
max of grad d_p:  tensor(0.2416, device='cuda:0')
min of grad d_p:  tensor(-0.0329, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0373, device='cuda:0') mean:  tensor(-2.6941e-05, device='cuda:0') min:  tensor(-0.1704, device='cuda:0') norm:  tensor(0.3875, device='cuda:0') MSE:  tensor(1.4547e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(8.0645e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.7529e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  604  
Training Loss: 0.04153654724359512
Test Loss:  0.029198000207543373
Test Acc:  0.0
Valid Loss:  0.02795029804110527
Valid Acc:  0.0
std:  0.00048507190405368386 
thres:  4.2218836396932604e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 60%|██████    | 604/1000 [28:15<19:23,  2.94s/it]Epoch:   605
max of grad d_p:  tensor(0.2404, device='cuda:0')
min of grad d_p:  tensor(-0.0327, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0449, device='cuda:0') mean:  tensor(-2.8015e-05, device='cuda:0') min:  tensor(-0.1436, device='cuda:0') norm:  tensor(0.3873, device='cuda:0') MSE:  tensor(1.4540e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.6660e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.2239e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  605  
Training Loss: 0.041188836097717285
Test Loss:  0.028904901817440987
Test Acc:  0.0
Valid Loss:  0.027670275419950485
Valid Acc:  0.0
std:  0.00047930469348472375 
thres:  4.187282398343086e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 60%|██████    | 605/1000 [28:18<19:30,  2.96s/it]Epoch:   606
max of grad d_p:  tensor(0.2392, device='cuda:0')
min of grad d_p:  tensor(-0.0326, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0381, device='cuda:0') mean:  tensor(-2.2952e-05, device='cuda:0') min:  tensor(-0.1366, device='cuda:0') norm:  tensor(0.3435, device='cuda:0') MSE:  tensor(1.2895e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.4937e-05, device='cuda:0') mean:  tensor(3.6812e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7305e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0880, device='cuda:0')
min of d_p_list:  tensor(-0.0698, device='cuda:0')
Epoch:  606  
Training Loss: 0.04246672987937927
Test Loss:  0.030593857169151306
Test Acc:  0.0
Valid Loss:  0.029341507703065872
Valid Acc:  0.0
std:  0.00045504754461129577 
thres:  4.185529500246048e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 61%|██████    | 606/1000 [28:21<19:39,  2.99s/it]Epoch:   607
max of grad d_p:  tensor(0.2448, device='cuda:0')
min of grad d_p:  tensor(-0.0317, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-2.2212e-05, device='cuda:0') min:  tensor(-0.1421, device='cuda:0') norm:  tensor(0.3482, device='cuda:0') MSE:  tensor(1.3070e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.0062e-05, device='cuda:0') mean:  tensor(3.1919e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.4736e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0064, device='cuda:0')
min of d_p_list:  tensor(-0.0127, device='cuda:0')
Epoch:  607  
Training Loss: 0.04209066554903984
Test Loss:  0.030302034690976143
Test Acc:  0.0
Valid Loss:  0.029045576229691505
Valid Acc:  0.0
std:  0.00044139685157457376 
thres:  4.1834703832864765e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 61%|██████    | 607/1000 [28:24<19:41,  3.01s/it]Epoch:   608
max of grad d_p:  tensor(0.2435, device='cuda:0')
min of grad d_p:  tensor(-0.0313, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0421, device='cuda:0') mean:  tensor(-2.3386e-05, device='cuda:0') min:  tensor(-0.1765, device='cuda:0') norm:  tensor(0.3961, device='cuda:0') MSE:  tensor(1.4869e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(2.1256e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0026, device='cuda:0') MSE:  tensor(9.9207e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  608  
Training Loss: 0.04173440858721733
Test Loss:  0.030003512278199196
Test Acc:  0.0
Valid Loss:  0.028757458552718163
Valid Acc:  0.0
std:  0.00044185676777651453 
thres:  4.1803437471389774e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 61%|██████    | 608/1000 [28:27<19:59,  3.06s/it]Epoch:   609
max of grad d_p:  tensor(0.2423, device='cuda:0')
min of grad d_p:  tensor(-0.0312, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0461, device='cuda:0') mean:  tensor(-2.3702e-05, device='cuda:0') min:  tensor(-0.1662, device='cuda:0') norm:  tensor(0.3955, device='cuda:0') MSE:  tensor(1.4844e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.2381e-05, device='cuda:0') mean:  tensor(2.6280e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.3003e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0093, device='cuda:0')
min of d_p_list:  tensor(-0.0061, device='cuda:0')
Epoch:  609  
Training Loss: 0.041435785591602325
Test Loss:  0.029730599373579025
Test Acc:  0.0
Valid Loss:  0.028492821380496025
Valid Acc:  0.0
std:  0.00045565204818283063 
thres:  4.178328514099121e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 61%|██████    | 609/1000 [28:30<19:22,  2.97s/it]Epoch:   610
max of grad d_p:  tensor(0.2413, device='cuda:0')
min of grad d_p:  tensor(-0.0310, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0390, device='cuda:0') mean:  tensor(-2.2351e-05, device='cuda:0') min:  tensor(-0.1406, device='cuda:0') norm:  tensor(0.3468, device='cuda:0') MSE:  tensor(1.3020e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.6213e-05, device='cuda:0') mean:  tensor(1.9737e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(9.6485e-10, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0017, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  610  
Training Loss: 0.04108591377735138
Test Loss:  0.029437769204378128
Test Acc:  0.0
Valid Loss:  0.028208354488015175
Valid Acc:  0.0
std:  0.0004835147356670188 
thres:  4.176270067691803e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 61%|██████    | 610/1000 [28:32<18:52,  2.90s/it]Epoch:   611
max of grad d_p:  tensor(0.2401, device='cuda:0')
min of grad d_p:  tensor(-0.0308, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0422, device='cuda:0') mean:  tensor(-2.2192e-05, device='cuda:0') min:  tensor(-0.1537, device='cuda:0') norm:  tensor(0.3689, device='cuda:0') MSE:  tensor(1.3846e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(1.9437e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0025, device='cuda:0') MSE:  tensor(9.2471e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0182, device='cuda:0')
min of d_p_list:  tensor(-0.0247, device='cuda:0')
Epoch:  611  
Training Loss: 0.040533505380153656
Test Loss:  0.028897123411297798
Test Acc:  0.0
Valid Loss:  0.027726460248231888
Valid Acc:  0.0
std:  0.0005360457190993976 
thres:  4.137605577707291e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 61%|██████    | 611/1000 [28:35<18:22,  2.83s/it]Epoch:   612
max of grad d_p:  tensor(0.2380, device='cuda:0')
min of grad d_p:  tensor(-0.0301, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0394, device='cuda:0') mean:  tensor(-2.2128e-05, device='cuda:0') min:  tensor(-0.1688, device='cuda:0') norm:  tensor(0.3737, device='cuda:0') MSE:  tensor(1.4026e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.5209e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.3844e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0032, device='cuda:0')
min of d_p_list:  tensor(-0.0092, device='cuda:0')
Epoch:  612  
Training Loss: 0.04018580913543701
Test Loss:  0.028604477643966675
Test Acc:  0.0
Valid Loss:  0.027454208582639694
Valid Acc:  0.0
std:  0.0005686913776856614 
thres:  4.099508449435234e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 61%|██████    | 612/1000 [28:38<17:56,  2.77s/it]Epoch:   613
max of grad d_p:  tensor(0.2367, device='cuda:0')
min of grad d_p:  tensor(-0.0300, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0416, device='cuda:0') mean:  tensor(-2.2293e-05, device='cuda:0') min:  tensor(-0.1648, device='cuda:0') norm:  tensor(0.3893, device='cuda:0') MSE:  tensor(1.4613e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.2589e-05, device='cuda:0') mean:  tensor(1.8608e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0002, device='cuda:0') MSE:  tensor(8.7960e-10, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0055, device='cuda:0')
min of d_p_list:  tensor(-0.0065, device='cuda:0')
Epoch:  613  
Training Loss: 0.0398736298084259
Test Loss:  0.028361305594444275
Test Acc:  0.0
Valid Loss:  0.027217498049139977
Valid Acc:  0.0
std:  0.0005719458682158125 
thres:  4.062292873859406e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 61%|██████▏   | 613/1000 [28:41<18:09,  2.82s/it]Epoch:   614
max of grad d_p:  tensor(0.2357, device='cuda:0')
min of grad d_p:  tensor(-0.0299, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0457, device='cuda:0') mean:  tensor(-2.3562e-05, device='cuda:0') min:  tensor(-0.1610, device='cuda:0') norm:  tensor(0.3933, device='cuda:0') MSE:  tensor(1.4763e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.3962e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2246e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0012, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  614  
Training Loss: 0.039540164172649384
Test Loss:  0.0280880369246006
Test Acc:  0.0
Valid Loss:  0.026952968910336494
Valid Acc:  0.0
std:  0.0005345235466899302 
thres:  4.0243804454803465e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 61%|██████▏   | 614/1000 [28:44<18:21,  2.85s/it]Epoch:   615
max of grad d_p:  tensor(0.2345, device='cuda:0')
min of grad d_p:  tensor(-0.0297, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0438, device='cuda:0') mean:  tensor(-2.5210e-05, device='cuda:0') min:  tensor(-0.1512, device='cuda:0') norm:  tensor(0.3888, device='cuda:0') MSE:  tensor(1.4594e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(8.8332e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.1702e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0061, device='cuda:0')
min of d_p_list:  tensor(-0.0101, device='cuda:0')
Epoch:  615  
Training Loss: 0.03921064734458923
Test Loss:  0.02781660668551922
Test Acc:  0.0
Valid Loss:  0.026688560843467712
Valid Acc:  0.0
std:  0.00046551429072051866 
thres:  3.986875116825104e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 62%|██████▏   | 615/1000 [28:47<18:49,  2.93s/it]Epoch:   616
max of grad d_p:  tensor(0.2333, device='cuda:0')
min of grad d_p:  tensor(-0.0296, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0425, device='cuda:0') mean:  tensor(-2.2353e-05, device='cuda:0') min:  tensor(-0.1676, device='cuda:0') norm:  tensor(0.4009, device='cuda:0') MSE:  tensor(1.5048e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.3892e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.2261e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0215, device='cuda:0')
min of d_p_list:  tensor(-0.0244, device='cuda:0')
Epoch:  616  
Training Loss: 0.03905881941318512
Test Loss:  0.02774403616786003
Test Acc:  0.0
Valid Loss:  0.02664547599852085
Valid Acc:  0.0
std:  0.00041537195854131494 
thres:  3.9573813974857333e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 62%|██████▏   | 616/1000 [28:50<18:50,  2.94s/it]Epoch:   617
max of grad d_p:  tensor(0.2330, device='cuda:0')
min of grad d_p:  tensor(-0.0293, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0405, device='cuda:0') mean:  tensor(-2.1923e-05, device='cuda:0') min:  tensor(-0.1414, device='cuda:0') norm:  tensor(0.3629, device='cuda:0') MSE:  tensor(1.3622e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.6664e-05, device='cuda:0') mean:  tensor(1.5525e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0002, device='cuda:0') MSE:  tensor(7.4911e-10, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  617  
Training Loss: 0.03873299062252045
Test Loss:  0.027472253888845444
Test Acc:  0.0
Valid Loss:  0.02638302743434906
Valid Acc:  0.0
std:  0.00039318668000828933 
thres:  3.928325027227402e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 62%|██████▏   | 617/1000 [28:53<19:11,  3.01s/it]Epoch:   618
max of grad d_p:  tensor(0.2318, device='cuda:0')
min of grad d_p:  tensor(-0.0292, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0429, device='cuda:0') mean:  tensor(-2.4424e-05, device='cuda:0') min:  tensor(-0.1585, device='cuda:0') norm:  tensor(0.3821, device='cuda:0') MSE:  tensor(1.4343e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.2586e-05, device='cuda:0') mean:  tensor(2.0867e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(9.9189e-10, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0036, device='cuda:0')
min of d_p_list:  tensor(-0.0050, device='cuda:0')
Epoch:  618  
Training Loss: 0.03840803727507591
Test Loss:  0.027200836688280106
Test Acc:  0.0
Valid Loss:  0.026128286495804787
Valid Acc:  0.0
std:  0.00039008622782021657 
thres:  3.899013176560402e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 62%|██████▏   | 618/1000 [28:56<18:59,  2.98s/it]Epoch:   619
max of grad d_p:  tensor(0.2306, device='cuda:0')
min of grad d_p:  tensor(-0.0291, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0420, device='cuda:0') mean:  tensor(-2.3554e-05, device='cuda:0') min:  tensor(-0.1456, device='cuda:0') norm:  tensor(0.3670, device='cuda:0') MSE:  tensor(1.3777e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.6257e-05, device='cuda:0') mean:  tensor(4.0268e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.8510e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0055, device='cuda:0')
min of d_p_list:  tensor(-0.0029, device='cuda:0')
Epoch:  619  
Training Loss: 0.03808475658297539
Test Loss:  0.02693396806716919
Test Acc:  0.0
Valid Loss:  0.025863884016871452
Valid Acc:  0.0
std:  0.0004133673058621366 
thres:  3.8699050247669215e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 62%|██████▏   | 619/1000 [28:59<18:42,  2.95s/it]Epoch:   620
max of grad d_p:  tensor(0.2294, device='cuda:0')
min of grad d_p:  tensor(-0.0290, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-2.2590e-05, device='cuda:0') min:  tensor(-0.1431, device='cuda:0') norm:  tensor(0.3590, device='cuda:0') MSE:  tensor(1.3475e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.4809e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.7367e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0034, device='cuda:0')
min of d_p_list:  tensor(-0.0040, device='cuda:0')
Epoch:  620  
Training Loss: 0.03777556121349335
Test Loss:  0.026673773303627968
Test Acc:  0.0
Valid Loss:  0.02561524324119091
Valid Acc:  0.0
std:  0.00045465780840362894 
thres:  3.841203302145004e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 62%|██████▏   | 620/1000 [29:02<18:32,  2.93s/it]Epoch:   621
max of grad d_p:  tensor(0.2283, device='cuda:0')
min of grad d_p:  tensor(-0.0286, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0407, device='cuda:0') mean:  tensor(-2.1337e-05, device='cuda:0') min:  tensor(-0.1494, device='cuda:0') norm:  tensor(0.3590, device='cuda:0') MSE:  tensor(1.3474e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.5075e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.2369e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0023, device='cuda:0')
Epoch:  621  
Training Loss: 0.037461839616298676
Test Loss:  0.026410255581140518
Test Acc:  0.0
Valid Loss:  0.025362703949213028
Valid Acc:  0.0
std:  0.0004490065901607083 
thres:  3.809263706207276e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 62%|██████▏   | 621/1000 [29:04<18:31,  2.93s/it]Epoch:   622
max of grad d_p:  tensor(0.2272, device='cuda:0')
min of grad d_p:  tensor(-0.0285, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0493, device='cuda:0') mean:  tensor(-2.4481e-05, device='cuda:0') min:  tensor(-0.1607, device='cuda:0') norm:  tensor(0.4057, device='cuda:0') MSE:  tensor(1.5227e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0042, device='cuda:0') mean:  tensor(1.2099e-05, device='cuda:0') min:  tensor(9.0949e-13, device='cuda:0') norm:  tensor(0.0169, device='cuda:0') MSE:  tensor(6.3518e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  622  
Training Loss: 0.03715166822075844
Test Loss:  0.0261506587266922
Test Acc:  0.0
Valid Loss:  0.025110851973295212
Valid Acc:  0.0
std:  0.00044346097017036946 
thres:  3.777637258172036e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 62%|██████▏   | 622/1000 [29:07<18:13,  2.89s/it]Epoch:   623
max of grad d_p:  tensor(0.2261, device='cuda:0')
min of grad d_p:  tensor(-0.0284, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0414, device='cuda:0') mean:  tensor(-2.0647e-05, device='cuda:0') min:  tensor(-0.1606, device='cuda:0') norm:  tensor(0.3809, device='cuda:0') MSE:  tensor(1.4297e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.0566e-05, device='cuda:0') mean:  tensor(1.6910e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0002, device='cuda:0') MSE:  tensor(8.2016e-10, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0203, device='cuda:0')
min of d_p_list:  tensor(-0.0339, device='cuda:0')
Epoch:  623  
Training Loss: 0.03670504316687584
Test Loss:  0.025783803313970566
Test Acc:  0.0
Valid Loss:  0.024778837338089943
Valid Acc:  0.0
std:  0.0004799993341846437 
thres:  3.743577376008034e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 62%|██████▏   | 623/1000 [29:10<17:45,  2.83s/it]Epoch:   624
max of grad d_p:  tensor(0.2242, device='cuda:0')
min of grad d_p:  tensor(-0.0289, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0417, device='cuda:0') mean:  tensor(-2.3058e-05, device='cuda:0') min:  tensor(-0.1534, device='cuda:0') norm:  tensor(0.3872, device='cuda:0') MSE:  tensor(1.4536e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(9.7110e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0012, device='cuda:0') MSE:  tensor(4.4600e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  624  
Training Loss: 0.03640258312225342
Test Loss:  0.025534048676490784
Test Acc:  0.0
Valid Loss:  0.024535803124308586
Valid Acc:  0.0
std:  0.0004964593605477511 
thres:  3.7099339067935945e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 62%|██████▏   | 624/1000 [29:13<18:08,  2.89s/it]Epoch:   625
max of grad d_p:  tensor(0.2231, device='cuda:0')
min of grad d_p:  tensor(-0.0288, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0413, device='cuda:0') mean:  tensor(-2.1628e-05, device='cuda:0') min:  tensor(-0.1365, device='cuda:0') norm:  tensor(0.3516, device='cuda:0') MSE:  tensor(1.3199e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(2.2910e-06, device='cuda:0') min:  tensor(2.7285e-12, device='cuda:0') norm:  tensor(0.0029, device='cuda:0') MSE:  tensor(1.0896e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1012, device='cuda:0')
min of d_p_list:  tensor(-0.1900, device='cuda:0')
Epoch:  625  
Training Loss: 0.04086122661828995
Test Loss:  0.029082246124744415
Test Acc:  0.0
Valid Loss:  0.02770170569419861
Valid Acc:  0.0
std:  0.0016138534528681273 
thres:  3.771647214889527e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 62%|██████▎   | 625/1000 [29:16<17:54,  2.86s/it]Epoch:   626
max of grad d_p:  tensor(0.2383, device='cuda:0')
min of grad d_p:  tensor(-0.0347, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0395, device='cuda:0') mean:  tensor(-2.0248e-05, device='cuda:0') min:  tensor(-0.1346, device='cuda:0') norm:  tensor(0.3528, device='cuda:0') MSE:  tensor(1.3242e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.6206e-05, device='cuda:0') mean:  tensor(2.5280e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.2248e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0014, device='cuda:0')
min of d_p_list:  tensor(-0.0007, device='cuda:0')
Epoch:  626  
Training Loss: 0.040516890585422516
Test Loss:  0.028795922175049782
Test Acc:  0.0
Valid Loss:  0.02742556482553482
Valid Acc:  0.0
std:  0.0019459420980526717 
thres:  3.832748234272003e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 63%|██████▎   | 626/1000 [29:19<18:01,  2.89s/it]Epoch:   627
max of grad d_p:  tensor(0.2371, device='cuda:0')
min of grad d_p:  tensor(-0.0345, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0438, device='cuda:0') mean:  tensor(-2.6762e-05, device='cuda:0') min:  tensor(-0.1312, device='cuda:0') norm:  tensor(0.3771, device='cuda:0') MSE:  tensor(1.4156e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(2.9122e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0004, device='cuda:0') MSE:  tensor(1.5544e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  627  
Training Loss: 0.04017682000994682
Test Loss:  0.028517447412014008
Test Acc:  0.0
Valid Loss:  0.02715962380170822
Valid Acc:  0.0
std:  0.0019565610408756352 
thres:  3.8932512700557715e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 63%|██████▎   | 627/1000 [29:22<17:45,  2.86s/it]Epoch:   628
max of grad d_p:  tensor(0.2359, device='cuda:0')
min of grad d_p:  tensor(-0.0344, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0447, device='cuda:0') mean:  tensor(-2.2971e-05, device='cuda:0') min:  tensor(-0.1342, device='cuda:0') norm:  tensor(0.3713, device='cuda:0') MSE:  tensor(1.3936e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(4.2915e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2093e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0021, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  628  
Training Loss: 0.0398402139544487
Test Loss:  0.02823740802705288
Test Acc:  0.0
Valid Loss:  0.026896409690380096
Valid Acc:  0.0
std:  0.0016147505939151134 
thres:  3.955954685807228e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 63%|██████▎   | 628/1000 [29:24<17:38,  2.85s/it]Epoch:   629
max of grad d_p:  tensor(0.2347, device='cuda:0')
min of grad d_p:  tensor(-0.0342, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0425, device='cuda:0') mean:  tensor(-2.3656e-05, device='cuda:0') min:  tensor(-0.1329, device='cuda:0') norm:  tensor(0.3698, device='cuda:0') MSE:  tensor(1.3881e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.9434e-05, device='cuda:0') mean:  tensor(3.3933e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.6954e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0022, device='cuda:0')
min of d_p_list:  tensor(-0.0016, device='cuda:0')
Epoch:  629  
Training Loss: 0.039506666362285614
Test Loss:  0.02796066179871559
Test Acc:  0.0
Valid Loss:  0.026630660519003868
Valid Acc:  0.0
std:  0.0004788334090465187 
thres:  4.018036350607872e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 63%|██████▎   | 629/1000 [29:27<17:33,  2.84s/it]Epoch:   630
max of grad d_p:  tensor(0.2335, device='cuda:0')
min of grad d_p:  tensor(-0.0340, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0439, device='cuda:0') mean:  tensor(-2.3582e-05, device='cuda:0') min:  tensor(-0.1459, device='cuda:0') norm:  tensor(0.3899, device='cuda:0') MSE:  tensor(1.4634e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.1792e-05, device='cuda:0') mean:  tensor(2.0709e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.0504e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0042, device='cuda:0')
min of d_p_list:  tensor(-0.0058, device='cuda:0')
Epoch:  630  
Training Loss: 0.039184220135211945
Test Loss:  0.027704128995537758
Test Acc:  0.0
Valid Loss:  0.026386946439743042
Valid Acc:  0.0
std:  0.00047173383533307995 
thres:  3.984496220946312e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 63%|██████▎   | 630/1000 [29:30<17:15,  2.80s/it]Epoch:   631
max of grad d_p:  tensor(0.2324, device='cuda:0')
min of grad d_p:  tensor(-0.0338, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0409, device='cuda:0') mean:  tensor(-2.2392e-05, device='cuda:0') min:  tensor(-0.1316, device='cuda:0') norm:  tensor(0.3634, device='cuda:0') MSE:  tensor(1.3639e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.3151e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(2.8285e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0100, device='cuda:0')
min of d_p_list:  tensor(-0.0049, device='cuda:0')
Epoch:  631  
Training Loss: 0.038859013468027115
Test Loss:  0.027442004531621933
Test Acc:  0.0
Valid Loss:  0.02613222599029541
Valid Acc:  0.0
std:  0.0004655233459308866 
thres:  3.951338678598404e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 63%|██████▎   | 631/1000 [29:33<16:58,  2.76s/it]Epoch:   632
max of grad d_p:  tensor(0.2313, device='cuda:0')
min of grad d_p:  tensor(-0.0336, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0450, device='cuda:0') mean:  tensor(-2.2957e-05, device='cuda:0') min:  tensor(-0.1425, device='cuda:0') norm:  tensor(0.3749, device='cuda:0') MSE:  tensor(1.4073e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(1.3146e-06, device='cuda:0') min:  tensor(9.0949e-13, device='cuda:0') norm:  tensor(0.0017, device='cuda:0') MSE:  tensor(6.3563e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0028, device='cuda:0')
min of d_p_list:  tensor(-0.0032, device='cuda:0')
Epoch:  632  
Training Loss: 0.03853689134120941
Test Loss:  0.027170661836862564
Test Acc:  0.0
Valid Loss:  0.025872033089399338
Valid Acc:  0.0
std:  0.0004602361201235758 
thres:  3.918540105223656e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 63%|██████▎   | 632/1000 [29:35<16:50,  2.75s/it]Epoch:   633
max of grad d_p:  tensor(0.2301, device='cuda:0')
min of grad d_p:  tensor(-0.0334, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0478, device='cuda:0') mean:  tensor(-2.5901e-05, device='cuda:0') min:  tensor(-0.1469, device='cuda:0') norm:  tensor(0.4116, device='cuda:0') MSE:  tensor(1.5450e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.5043e-05, device='cuda:0') mean:  tensor(4.1088e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0005, device='cuda:0') MSE:  tensor(1.9143e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(3.4969, device='cuda:0')
min of d_p_list:  tensor(-5.5302, device='cuda:0')
Epoch:  633  
Training Loss: 4383.7568359375
Test Loss:  5545.54296875
Test Acc:  0.0
Valid Loss:  5270.4609375
Valid Acc:  0.0
std:  1753.487125695899 
thres:  0.8767825845457613
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 63%|██████▎   | 633/1000 [29:38<16:49,  2.75s/it]Epoch:   634
max of grad d_p:  tensor(2777.3472, device='cuda:0')
min of grad d_p:  tensor(-624.8557, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.8046, device='cuda:0') mean:  tensor(-0.0011, device='cuda:0') min:  tensor(-2.6653, device='cuda:0') norm:  tensor(7.7445, device='cuda:0') MSE:  tensor(2.9071e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.7881, device='cuda:0') mean:  tensor(0.0027, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(3.4639, device='cuda:0') MSE:  tensor(1.3003e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0220, device='cuda:0')
min of d_p_list:  tensor(-0.0521, device='cuda:0')
Epoch:  634  
Training Loss: 4340.24658203125
Test Loss:  5490.2490234375
Test Acc:  0.0
Valid Loss:  5217.77197265625
Valid Acc:  0.0
std:  2136.960947035091 
thres:  1.744823999618739
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 63%|██████▎   | 634/1000 [29:41<17:11,  2.82s/it]Epoch:   635
max of grad d_p:  tensor(2761.0874, device='cuda:0')
min of grad d_p:  tensor(-617.9052, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.9708, device='cuda:0') mean:  tensor(-0.0010, device='cuda:0') min:  tensor(-2.8201, device='cuda:0') norm:  tensor(8.2685, device='cuda:0') MSE:  tensor(3.1038e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1473, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7693, device='cuda:0') MSE:  tensor(2.8876e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0229, device='cuda:0')
min of d_p_list:  tensor(-0.0093, device='cuda:0')
Epoch:  635  
Training Loss: 4297.0048828125
Test Loss:  5435.767578125
Test Acc:  0.0
Valid Loss:  5166.16650390625
Valid Acc:  0.0
std:  2126.479758252302 
thres:  2.6042171393372118
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 64%|██████▎   | 635/1000 [29:44<16:44,  2.75s/it]Epoch:   636
max of grad d_p:  tensor(2746.2595, device='cuda:0')
min of grad d_p:  tensor(-611.5599, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.8468, device='cuda:0') mean:  tensor(-0.0008, device='cuda:0') min:  tensor(-2.3359, device='cuda:0') norm:  tensor(7.0211, device='cuda:0') MSE:  tensor(2.6355e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2587, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.9214, device='cuda:0') MSE:  tensor(3.4589e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0099, device='cuda:0')
min of d_p_list:  tensor(-0.0035, device='cuda:0')
Epoch:  636  
Training Loss: 4254.2041015625
Test Loss:  5381.7255859375
Test Acc:  0.0
Valid Loss:  5114.837890625
Valid Acc:  0.0
std:  1728.0456526900489 
thres:  3.4550501878470183
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 64%|██████▎   | 636/1000 [29:46<16:33,  2.73s/it]Epoch:   637
max of grad d_p:  tensor(2728.0498, device='cuda:0')
min of grad d_p:  tensor(-605.4065, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.8707, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-2.6887, device='cuda:0') norm:  tensor(7.5836, device='cuda:0') MSE:  tensor(2.8467e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0921, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.3244, device='cuda:0') MSE:  tensor(1.2178e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0748, device='cuda:0')
min of d_p_list:  tensor(-0.0394, device='cuda:0')
Epoch:  637  
Training Loss: 4211.8876953125
Test Loss:  5328.6435546875
Test Acc:  0.0
Valid Loss:  5064.36083984375
Valid Acc:  0.0
std:  60.781126533441736 
thres:  4.297420019531249
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 64%|██████▎   | 637/1000 [29:49<16:19,  2.70s/it]Epoch:   638
max of grad d_p:  tensor(2713.9692, device='cuda:0')
min of grad d_p:  tensor(-594.3672, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.8314, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-2.8701, device='cuda:0') norm:  tensor(7.7177, device='cuda:0') MSE:  tensor(2.8970e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1185, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.5464, device='cuda:0') MSE:  tensor(2.0509e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0098, device='cuda:0')
min of d_p_list:  tensor(-0.0025, device='cuda:0')
Epoch:  638  
Training Loss: 4169.935546875
Test Loss:  5275.564453125
Test Acc:  0.0
Valid Loss:  5013.97314453125
Valid Acc:  0.0
std:  60.209738221282905 
thres:  4.25465576171875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 64%|██████▍   | 638/1000 [29:52<16:47,  2.78s/it]Epoch:   639
max of grad d_p:  tensor(2695.0806, device='cuda:0')
min of grad d_p:  tensor(-588.4108, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.8429, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-2.7478, device='cuda:0') norm:  tensor(7.4163, device='cuda:0') MSE:  tensor(2.7839e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3451, device='cuda:0') mean:  tensor(0.0011, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.4812, device='cuda:0') MSE:  tensor(5.5599e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0115, device='cuda:0')
min of d_p_list:  tensor(-0.0151, device='cuda:0')
Epoch:  639  
Training Loss: 4128.46728515625
Test Loss:  5222.78125
Test Acc:  0.0
Valid Loss:  4963.76123046875
Valid Acc:  0.0
std:  59.58810596386019 
thres:  4.21229990234375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 64%|██████▍   | 639/1000 [29:55<16:29,  2.74s/it]Epoch:   640
max of grad d_p:  tensor(2675.5449, device='cuda:0')
min of grad d_p:  tensor(-580.6569, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.8145, device='cuda:0') mean:  tensor(-0.0012, device='cuda:0') min:  tensor(-2.7019, device='cuda:0') norm:  tensor(8.2236, device='cuda:0') MSE:  tensor(3.0869e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.0334, device='cuda:0') mean:  tensor(0.0087, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(11.1555, device='cuda:0') MSE:  tensor(4.1875e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0146, device='cuda:0')
min of d_p_list:  tensor(-0.0164, device='cuda:0')
Epoch:  640  
Training Loss: 4087.3583984375
Test Loss:  5170.9462890625
Test Acc:  0.0
Valid Loss:  4914.64404296875
Valid Acc:  0.0
std:  58.989537821186374 
thres:  4.17037060546875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 64%|██████▍   | 640/1000 [29:57<16:12,  2.70s/it]Epoch:   641
max of grad d_p:  tensor(2655.3799, device='cuda:0')
min of grad d_p:  tensor(-572.9272, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.7733, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-2.9878, device='cuda:0') norm:  tensor(7.3409, device='cuda:0') MSE:  tensor(2.7556e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4119, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.1724, device='cuda:0') MSE:  tensor(8.1548e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0333, device='cuda:0')
min of d_p_list:  tensor(-0.0290, device='cuda:0')
Epoch:  641  
Training Loss: 4046.861328125
Test Loss:  5119.25341796875
Test Acc:  0.0
Valid Loss:  4865.005859375
Valid Acc:  0.0
std:  58.355992400283206 
thres:  4.12890205078125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 64%|██████▍   | 641/1000 [30:00<16:26,  2.75s/it]Epoch:   642
max of grad d_p:  tensor(2632.2188, device='cuda:0')
min of grad d_p:  tensor(-564.9083, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.7483, device='cuda:0') mean:  tensor(-0.0008, device='cuda:0') min:  tensor(-2.5122, device='cuda:0') norm:  tensor(6.5273, device='cuda:0') MSE:  tensor(2.4502e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4788, device='cuda:0') mean:  tensor(0.0023, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.8490, device='cuda:0') MSE:  tensor(1.0694e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0393, device='cuda:0')
min of d_p_list:  tensor(-0.0299, device='cuda:0')
Epoch:  642  
Training Loss: 4006.361328125
Test Loss:  5068.244140625
Test Acc:  0.0
Valid Loss:  4816.748046875
Valid Acc:  0.0
std:  57.807444562271286 
thres:  4.08779677734375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 64%|██████▍   | 642/1000 [30:03<16:19,  2.73s/it]Epoch:   643
max of grad d_p:  tensor(2619.2568, device='cuda:0')
min of grad d_p:  tensor(-560.7582, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.8387, device='cuda:0') mean:  tensor(-0.0010, device='cuda:0') min:  tensor(-2.9260, device='cuda:0') norm:  tensor(7.6776, device='cuda:0') MSE:  tensor(2.8820e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2629, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8408, device='cuda:0') MSE:  tensor(3.1560e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0089, device='cuda:0')
min of d_p_list:  tensor(-0.0050, device='cuda:0')
Epoch:  643  
Training Loss: 3966.452392578125
Test Loss:  5017.775390625
Test Acc:  0.0
Valid Loss:  4768.7626953125
Valid Acc:  0.0
std:  57.28020019451645 
thres:  4.047100146484375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 64%|██████▍   | 643/1000 [30:05<16:20,  2.75s/it]Epoch:   644
max of grad d_p:  tensor(2601.0315, device='cuda:0')
min of grad d_p:  tensor(-554.4605, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.8546, device='cuda:0') mean:  tensor(-0.0007, device='cuda:0') min:  tensor(-2.2129, device='cuda:0') norm:  tensor(6.7817, device='cuda:0') MSE:  tensor(2.5457e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2211, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8971, device='cuda:0') MSE:  tensor(3.3675e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0514, device='cuda:0')
min of d_p_list:  tensor(-0.0555, device='cuda:0')
Epoch:  644  
Training Loss: 3927.984619140625
Test Loss:  4969.02978515625
Test Acc:  0.0
Valid Loss:  4722.7861328125
Valid Acc:  0.0
std:  56.452359376388166 
thres:  4.00700361328125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 64%|██████▍   | 644/1000 [30:08<16:45,  2.82s/it]Epoch:   645
max of grad d_p:  tensor(2552.3213, device='cuda:0')
min of grad d_p:  tensor(-543.7812, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.8193, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-2.4045, device='cuda:0') norm:  tensor(7.2000, device='cuda:0') MSE:  tensor(2.7027e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2487, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8135, device='cuda:0') MSE:  tensor(3.0536e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0196, device='cuda:0')
min of d_p_list:  tensor(-0.0157, device='cuda:0')
Epoch:  645  
Training Loss: 3888.84765625
Test Loss:  4919.4833984375
Test Acc:  0.0
Valid Loss:  4675.6201171875
Valid Acc:  0.0
std:  55.77988907751877 
thres:  3.96730146484375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 64%|██████▍   | 645/1000 [30:11<16:16,  2.75s/it]Epoch:   646
max of grad d_p:  tensor(2537.1470, device='cuda:0')
min of grad d_p:  tensor(-535.3932, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.8990, device='cuda:0') mean:  tensor(-0.0008, device='cuda:0') min:  tensor(-2.3550, device='cuda:0') norm:  tensor(7.1269, device='cuda:0') MSE:  tensor(2.6752e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4284, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.6142, device='cuda:0') MSE:  tensor(6.0591e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0168, device='cuda:0')
min of d_p_list:  tensor(-0.0104, device='cuda:0')
Epoch:  646  
Training Loss: 3850.124755859375
Test Loss:  4870.73095703125
Test Acc:  0.0
Valid Loss:  4629.3056640625
Valid Acc:  0.0
std:  55.16617376112595 
thres:  3.927954150390625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 65%|██████▍   | 646/1000 [30:14<16:19,  2.77s/it]Epoch:   647
max of grad d_p:  tensor(2519.0476, device='cuda:0')
min of grad d_p:  tensor(-530.9080, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.8386, device='cuda:0') mean:  tensor(-0.0011, device='cuda:0') min:  tensor(-2.9058, device='cuda:0') norm:  tensor(8.0664, device='cuda:0') MSE:  tensor(3.0279e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1652, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8041, device='cuda:0') MSE:  tensor(3.0183e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0127, device='cuda:0')
min of d_p_list:  tensor(-0.0039, device='cuda:0')
Epoch:  647  
Training Loss: 3811.7705078125
Test Loss:  4822.322265625
Test Acc:  0.0
Valid Loss:  4583.3515625
Valid Acc:  0.0
std:  54.76197485424901 
thres:  3.889035986328125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 65%|██████▍   | 647/1000 [30:17<16:28,  2.80s/it]Epoch:   648
max of grad d_p:  tensor(2503.7095, device='cuda:0')
min of grad d_p:  tensor(-525.3707, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.8012, device='cuda:0') mean:  tensor(-0.0008, device='cuda:0') min:  tensor(-2.3359, device='cuda:0') norm:  tensor(6.9388, device='cuda:0') MSE:  tensor(2.6046e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.6827, device='cuda:0') mean:  tensor(0.0090, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(12.1605, device='cuda:0') MSE:  tensor(4.5647e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0354, device='cuda:0')
min of d_p_list:  tensor(-0.0276, device='cuda:0')
Epoch:  648  
Training Loss: 3773.976318359375
Test Loss:  4774.5986328125
Test Acc:  0.0
Valid Loss:  4538.12744140625
Valid Acc:  0.0
std:  54.46170922174333 
thres:  3.850540771484375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 65%|██████▍   | 648/1000 [30:19<16:08,  2.75s/it]Epoch:   649
max of grad d_p:  tensor(2484.5210, device='cuda:0')
min of grad d_p:  tensor(-517.7716, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.7894, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-2.4714, device='cuda:0') norm:  tensor(7.1057, device='cuda:0') MSE:  tensor(2.6673e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2306, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.1352, device='cuda:0') MSE:  tensor(4.2613e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0092, device='cuda:0')
min of d_p_list:  tensor(-0.0085, device='cuda:0')
Epoch:  649  
Training Loss: 3736.3984375
Test Loss:  4727.00927734375
Test Acc:  0.0
Valid Loss:  4492.91015625
Valid Acc:  0.0
std:  53.88925444880055 
thres:  3.81222353515625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 65%|██████▍   | 649/1000 [30:22<16:13,  2.77s/it]Epoch:   650
max of grad d_p:  tensor(2466.6743, device='cuda:0')
min of grad d_p:  tensor(-513.1060, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.7858, device='cuda:0') mean:  tensor(-0.0010, device='cuda:0') min:  tensor(-3.1794, device='cuda:0') norm:  tensor(7.4697, device='cuda:0') MSE:  tensor(2.8039e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1188, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.6328, device='cuda:0') MSE:  tensor(2.3754e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0370, device='cuda:0')
min of d_p_list:  tensor(-0.0623, device='cuda:0')
Epoch:  650  
Training Loss: 3699.000244140625
Test Loss:  4679.45751953125
Test Acc:  0.0
Valid Loss:  4447.5908203125
Valid Acc:  0.0
std:  53.40432275262316 
thres:  3.774254052734375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 65%|██████▌   | 650/1000 [30:25<15:55,  2.73s/it]Epoch:   651
max of grad d_p:  tensor(2452.6501, device='cuda:0')
min of grad d_p:  tensor(-506.7313, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.7413, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-2.5764, device='cuda:0') norm:  tensor(7.0552, device='cuda:0') MSE:  tensor(2.6483e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.5004, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.8354, device='cuda:0') MSE:  tensor(6.8898e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1175, device='cuda:0')
min of d_p_list:  tensor(-0.1321, device='cuda:0')
Epoch:  651  
Training Loss: 3664.388671875
Test Loss:  4634.484375
Test Acc:  0.0
Valid Loss:  4404.8916015625
Valid Acc:  0.0
std:  52.296401756249345 
thres:  3.7371068359375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 65%|██████▌   | 651/1000 [30:28<15:48,  2.72s/it]Epoch:   652
max of grad d_p:  tensor(2426.0366, device='cuda:0')
min of grad d_p:  tensor(-496.3331, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.7028, device='cuda:0') mean:  tensor(-0.0008, device='cuda:0') min:  tensor(-2.1743, device='cuda:0') norm:  tensor(6.4518, device='cuda:0') MSE:  tensor(2.4218e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4184, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.1761, device='cuda:0') MSE:  tensor(4.4147e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0224, device='cuda:0')
min of d_p_list:  tensor(-0.0137, device='cuda:0')
Epoch:  652  
Training Loss: 3627.835693359375
Test Loss:  4588.7470703125
Test Acc:  0.0
Valid Loss:  4361.3349609375
Valid Acc:  0.0
std:  51.524137435080554 
thres:  3.7003198730468747
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 65%|██████▌   | 652/1000 [30:30<15:55,  2.74s/it]Epoch:   653
max of grad d_p:  tensor(2415.8621, device='cuda:0')
min of grad d_p:  tensor(-492.6447, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.7836, device='cuda:0') mean:  tensor(-0.0008, device='cuda:0') min:  tensor(-2.1130, device='cuda:0') norm:  tensor(6.7040, device='cuda:0') MSE:  tensor(2.5165e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1696, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.6294, device='cuda:0') MSE:  tensor(2.3627e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0228, device='cuda:0')
min of d_p_list:  tensor(-0.0175, device='cuda:0')
Epoch:  653  
Training Loss: 3591.667236328125
Test Loss:  4543.1337890625
Test Acc:  0.0
Valid Loss:  4318.10888671875
Valid Acc:  0.0
std:  51.00291549273099 
thres:  3.663858056640625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 65%|██████▌   | 653/1000 [30:33<15:44,  2.72s/it]Epoch:   654
max of grad d_p:  tensor(2410.3105, device='cuda:0')
min of grad d_p:  tensor(-491.6400, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.6690, device='cuda:0') mean:  tensor(-0.0006, device='cuda:0') min:  tensor(-2.1848, device='cuda:0') norm:  tensor(6.1270, device='cuda:0') MSE:  tensor(2.2999e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.7406, device='cuda:0') mean:  tensor(0.0023, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(3.1434, device='cuda:0') MSE:  tensor(1.1799e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0110, device='cuda:0')
min of d_p_list:  tensor(-0.0063, device='cuda:0')
Epoch:  654  
Training Loss: 3555.8818359375
Test Loss:  4497.9892578125
Test Acc:  0.0
Valid Loss:  4275.22998046875
Valid Acc:  0.0
std:  50.76612184905442 
thres:  3.627754736328125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 65%|██████▌   | 654/1000 [30:36<15:25,  2.68s/it]Epoch:   655
max of grad d_p:  tensor(2393.2146, device='cuda:0')
min of grad d_p:  tensor(-486.7116, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.8182, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-2.3262, device='cuda:0') norm:  tensor(7.0819, device='cuda:0') MSE:  tensor(2.6584e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.9862, device='cuda:0') mean:  tensor(0.0027, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(3.8746, device='cuda:0') MSE:  tensor(1.4544e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0160, device='cuda:0')
min of d_p_list:  tensor(-0.0052, device='cuda:0')
Epoch:  655  
Training Loss: 3520.44970703125
Test Loss:  4453.03125
Test Acc:  0.0
Valid Loss:  4232.5224609375
Valid Acc:  0.0
std:  50.888866575112765 
thres:  3.59204462890625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 66%|██████▌   | 655/1000 [30:38<15:23,  2.68s/it]Epoch:   656
max of grad d_p:  tensor(2379.4597, device='cuda:0')
min of grad d_p:  tensor(-482.0693, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.7638, device='cuda:0') mean:  tensor(-0.0010, device='cuda:0') min:  tensor(-3.2729, device='cuda:0') norm:  tensor(7.8598, device='cuda:0') MSE:  tensor(2.9504e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3278, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.0868, device='cuda:0') MSE:  tensor(4.0796e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0093, device='cuda:0')
min of d_p_list:  tensor(-0.0053, device='cuda:0')
Epoch:  656  
Training Loss: 3485.385986328125
Test Loss:  4408.77099609375
Test Acc:  0.0
Valid Loss:  4190.46728515625
Valid Acc:  0.0
std:  50.36347268297399 
thres:  3.5562440917968754
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 66%|██████▌   | 656/1000 [30:41<15:30,  2.70s/it]Epoch:   657
max of grad d_p:  tensor(2362.1577, device='cuda:0')
min of grad d_p:  tensor(-477.2172, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.8243, device='cuda:0') mean:  tensor(-0.0013, device='cuda:0') min:  tensor(-2.9873, device='cuda:0') norm:  tensor(8.4594, device='cuda:0') MSE:  tensor(3.1754e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.1201, device='cuda:0') mean:  tensor(0.0038, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(5.2023, device='cuda:0') MSE:  tensor(1.9528e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0094, device='cuda:0')
min of d_p_list:  tensor(-0.0095, device='cuda:0')
Epoch:  657  
Training Loss: 3450.66796875
Test Loss:  4364.84326171875
Test Acc:  0.0
Valid Loss:  4148.720703125
Valid Acc:  0.0
std:  49.85113181887811 
thres:  3.520810546875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 66%|██████▌   | 657/1000 [30:44<15:32,  2.72s/it]Epoch:   658
max of grad d_p:  tensor(2345.4192, device='cuda:0')
min of grad d_p:  tensor(-472.6491, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.7090, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-2.7715, device='cuda:0') norm:  tensor(6.9016, device='cuda:0') MSE:  tensor(2.5907e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1394, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.5296, device='cuda:0') MSE:  tensor(1.9881e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0135, device='cuda:0')
min of d_p_list:  tensor(-0.0101, device='cuda:0')
Epoch:  658  
Training Loss: 3416.289794921875
Test Loss:  4321.32958984375
Test Acc:  0.0
Valid Loss:  4107.34716796875
Valid Acc:  0.0
std:  49.3520910922027 
thres:  3.4857350585937503
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 66%|██████▌   | 658/1000 [30:47<15:35,  2.73s/it]Epoch:   659
max of grad d_p:  tensor(2330.9053, device='cuda:0')
min of grad d_p:  tensor(-468.7349, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.7794, device='cuda:0') mean:  tensor(-0.0008, device='cuda:0') min:  tensor(-2.5938, device='cuda:0') norm:  tensor(6.8376, device='cuda:0') MSE:  tensor(2.5666e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3120, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.3950, device='cuda:0') MSE:  tensor(5.2366e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0145, device='cuda:0')
min of d_p_list:  tensor(-0.0188, device='cuda:0')
Epoch:  659  
Training Loss: 3382.279296875
Test Loss:  4278.2744140625
Test Acc:  0.0
Valid Loss:  4066.44287109375
Valid Acc:  0.0
std:  48.85304580713292 
thres:  3.45101455078125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 66%|██████▌   | 659/1000 [30:49<15:19,  2.70s/it]Epoch:   660
max of grad d_p:  tensor(2310.7783, device='cuda:0')
min of grad d_p:  tensor(-462.6384, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.8315, device='cuda:0') mean:  tensor(-0.0008, device='cuda:0') min:  tensor(-2.4836, device='cuda:0') norm:  tensor(7.1829, device='cuda:0') MSE:  tensor(2.6963e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0629, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.2958, device='cuda:0') MSE:  tensor(1.1104e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0365, device='cuda:0')
min of d_p_list:  tensor(-0.0206, device='cuda:0')
Epoch:  660  
Training Loss: 3348.59228515625
Test Loss:  4235.65869140625
Test Acc:  0.0
Valid Loss:  4025.93408203125
Valid Acc:  0.0
std:  48.363592308183506 
thres:  3.41664306640625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 66%|██████▌   | 660/1000 [30:52<15:53,  2.80s/it]Epoch:   661
max of grad d_p:  tensor(2295.7305, device='cuda:0')
min of grad d_p:  tensor(-456.7444, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.7208, device='cuda:0') mean:  tensor(-0.0009, device='cuda:0') min:  tensor(-2.6140, device='cuda:0') norm:  tensor(6.9288, device='cuda:0') MSE:  tensor(2.6009e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.0347, device='cuda:0') mean:  tensor(0.0051, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(6.8082, device='cuda:0') MSE:  tensor(2.5556e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0139, device='cuda:0')
min of d_p_list:  tensor(-0.0108, device='cuda:0')
Epoch:  661  
Training Loss: 3315.23681640625
Test Loss:  4193.6083984375
Test Acc:  0.0
Valid Loss:  3986.046875
Valid Acc:  0.0
std:  47.88042564434342 
thres:  3.382613232421875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 66%|██████▌   | 661/1000 [30:55<16:14,  2.87s/it]Epoch:   662
max of grad d_p:  tensor(2280.2256, device='cuda:0')
min of grad d_p:  tensor(-451.4302, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.7622, device='cuda:0') mean:  tensor(-0.0007, device='cuda:0') min:  tensor(-2.4390, device='cuda:0') norm:  tensor(6.3700, device='cuda:0') MSE:  tensor(2.3911e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1619, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7211, device='cuda:0') MSE:  tensor(2.7067e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0229, device='cuda:0')
min of d_p_list:  tensor(-0.0578, device='cuda:0')
Epoch:  662  
Training Loss: 3281.99267578125
Test Loss:  4151.19677734375
Test Acc:  0.0
Valid Loss:  3945.876953125
Valid Acc:  0.0
std:  47.466734013996316 
thres:  3.3488781738281252
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 66%|██████▌   | 662/1000 [30:58<15:58,  2.84s/it]Epoch:   663
max of grad d_p:  tensor(2245.1182, device='cuda:0')
min of grad d_p:  tensor(-447.7318, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.8170, device='cuda:0') mean:  tensor(-0.0008, device='cuda:0') min:  tensor(-2.6973, device='cuda:0') norm:  tensor(7.1420, device='cuda:0') MSE:  tensor(2.6809e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4390, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.7896, device='cuda:0') MSE:  tensor(6.7177e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0253, device='cuda:0')
min of d_p_list:  tensor(-0.0080, device='cuda:0')
Epoch:  663  
Training Loss: 3249.2734375
Test Loss:  4109.76708984375
Test Acc:  0.0
Valid Loss:  3906.454345703125
Valid Acc:  0.0
std:  47.03900147960426 
thres:  3.31547490234375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 66%|██████▋   | 663/1000 [31:01<15:32,  2.77s/it]Epoch:   664
max of grad d_p:  tensor(2230.7295, device='cuda:0')
min of grad d_p:  tensor(-441.5016, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.7059, device='cuda:0') mean:  tensor(-0.0008, device='cuda:0') min:  tensor(-3.0037, device='cuda:0') norm:  tensor(7.0387, device='cuda:0') MSE:  tensor(2.6421e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.1824, device='cuda:0') mean:  tensor(0.0099, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(13.2498, device='cuda:0') MSE:  tensor(4.9736e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(7.3233, device='cuda:0')
min of d_p_list:  tensor(-6.1672, device='cuda:0')
Epoch:  664  
Training Loss: 3572.563232421875
Test Loss:  3772.4072265625
Test Acc:  0.0
Valid Loss:  3503.8359375
Valid Acc:  0.0
std:  114.41444437589307 
thres:  3.353531689453125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 66%|██████▋   | 664/1000 [31:03<15:26,  2.76s/it]Epoch:   665
max of grad d_p:  tensor(1567.4639, device='cuda:0')
min of grad d_p:  tensor(-1545.7100, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2515, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(-4.0354, device='cuda:0') norm:  tensor(11.0407, device='cuda:0') MSE:  tensor(4.1444e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3413, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.3451, device='cuda:0') MSE:  tensor(5.0491e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0462, device='cuda:0')
min of d_p_list:  tensor(-0.0450, device='cuda:0')
Epoch:  665  
Training Loss: 3537.488525390625
Test Loss:  3733.810546875
Test Acc:  0.0
Valid Loss:  3467.9697265625
Valid Acc:  0.0
std:  135.74438276968473 
thres:  3.3913109375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 66%|██████▋   | 665/1000 [31:06<15:26,  2.76s/it]Epoch:   666
max of grad d_p:  tensor(1558.6785, device='cuda:0')
min of grad d_p:  tensor(-1537.4933, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3444, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-2.7736, device='cuda:0') norm:  tensor(10.8124, device='cuda:0') MSE:  tensor(4.0587e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4360, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.8188, device='cuda:0') MSE:  tensor(6.8274e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0129, device='cuda:0')
min of d_p_list:  tensor(-0.0093, device='cuda:0')
Epoch:  666  
Training Loss: 3502.284423828125
Test Loss:  3697.2109375
Test Acc:  0.0
Valid Loss:  3433.997314453125
Valid Acc:  0.0
std:  135.39805651987464 
thres:  3.428720458984375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 67%|██████▋   | 666/1000 [31:09<15:15,  2.74s/it]Epoch:   667
max of grad d_p:  tensor(1546.1295, device='cuda:0')
min of grad d_p:  tensor(-1528.1760, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2343, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-2.9489, device='cuda:0') norm:  tensor(8.8635, device='cuda:0') MSE:  tensor(3.3271e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1453, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.0951, device='cuda:0') MSE:  tensor(4.1105e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0150, device='cuda:0')
min of d_p_list:  tensor(-0.0095, device='cuda:0')
Epoch:  667  
Training Loss: 3467.445068359375
Test Loss:  3660.373046875
Test Acc:  0.0
Valid Loss:  3400.003662109375
Valid Acc:  0.0
std:  113.80263931187953 
thres:  3.4658109375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 67%|██████▋   | 667/1000 [31:12<15:09,  2.73s/it]Epoch:   668
max of grad d_p:  tensor(1535.2505, device='cuda:0')
min of grad d_p:  tensor(-1520.5259, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.4208, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.2452, device='cuda:0') norm:  tensor(10.4197, device='cuda:0') MSE:  tensor(3.9113e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.5916, device='cuda:0') mean:  tensor(0.0027, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(3.5132, device='cuda:0') MSE:  tensor(1.3187e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0083, device='cuda:0')
min of d_p_list:  tensor(-0.0123, device='cuda:0')
Epoch:  668  
Training Loss: 3432.89453125
Test Loss:  3623.734375
Test Acc:  0.0
Valid Loss:  3366.06201171875
Valid Acc:  0.0
std:  49.410248434762025 
thres:  3.50253515625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 67%|██████▋   | 668/1000 [31:14<14:55,  2.70s/it]Epoch:   669
max of grad d_p:  tensor(1525.7583, device='cuda:0')
min of grad d_p:  tensor(-1512.2427, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3778, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.0884, device='cuda:0') norm:  tensor(9.3843, device='cuda:0') MSE:  tensor(3.5226e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1808, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.0425, device='cuda:0') MSE:  tensor(3.9132e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0199, device='cuda:0')
min of d_p_list:  tensor(-0.0201, device='cuda:0')
Epoch:  669  
Training Loss: 3398.552734375
Test Loss:  3587.351318359375
Test Acc:  0.0
Valid Loss:  3332.2939453125
Valid Acc:  0.0
std:  49.11078328122403 
thres:  3.467733056640625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 67%|██████▋   | 669/1000 [31:17<15:57,  2.89s/it]Epoch:   670
max of grad d_p:  tensor(1512.4404, device='cuda:0')
min of grad d_p:  tensor(-1502.5114, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2968, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.2484, device='cuda:0') norm:  tensor(10.1013, device='cuda:0') MSE:  tensor(3.7917e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4416, device='cuda:0') mean:  tensor(0.0011, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.5359, device='cuda:0') MSE:  tensor(5.7652e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0132, device='cuda:0')
min of d_p_list:  tensor(-0.0112, device='cuda:0')
Epoch:  670  
Training Loss: 3364.744140625
Test Loss:  3551.73388671875
Test Acc:  0.0
Valid Loss:  3299.4013671875
Valid Acc:  0.0
std:  48.64588796683054 
thres:  3.4331841796875002
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 67%|██████▋   | 670/1000 [31:21<16:13,  2.95s/it]Epoch:   671
max of grad d_p:  tensor(1497.9495, device='cuda:0')
min of grad d_p:  tensor(-1493.0730, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3546, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-2.7050, device='cuda:0') norm:  tensor(9.4261, device='cuda:0') MSE:  tensor(3.5383e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.5987, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.8605, device='cuda:0') MSE:  tensor(1.0738e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0093, device='cuda:0')
min of d_p_list:  tensor(-0.0054, device='cuda:0')
Epoch:  671  
Training Loss: 3331.211181640625
Test Loss:  3516.341552734375
Test Acc:  0.0
Valid Loss:  3266.48828125
Valid Acc:  0.0
std:  48.17167182540488 
thres:  3.3989695312499997
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 67%|██████▋   | 671/1000 [31:23<15:54,  2.90s/it]Epoch:   672
max of grad d_p:  tensor(1487.6819, device='cuda:0')
min of grad d_p:  tensor(-1485.5137, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2528, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-2.9646, device='cuda:0') norm:  tensor(9.9331, device='cuda:0') MSE:  tensor(3.7286e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(68.9166, device='cuda:0') mean:  tensor(0.2649, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(325.3298, device='cuda:0') MSE:  tensor(0.0012, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0069, device='cuda:0')
min of d_p_list:  tensor(-0.0063, device='cuda:0')
Epoch:  672  
Training Loss: 3298.020263671875
Test Loss:  3481.22607421875
Test Acc:  0.0
Valid Loss:  3233.9228515625
Valid Acc:  0.0
std:  47.67274354541705 
thres:  3.3650845703125003
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 67%|██████▋   | 672/1000 [31:26<15:31,  2.84s/it]Epoch:   673
max of grad d_p:  tensor(1477.6746, device='cuda:0')
min of grad d_p:  tensor(-1477.6229, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3096, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-2.5480, device='cuda:0') norm:  tensor(9.8185, device='cuda:0') MSE:  tensor(3.6856e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.6162, device='cuda:0') mean:  tensor(0.0031, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(3.8996, device='cuda:0') MSE:  tensor(1.4638e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0075, device='cuda:0')
min of d_p_list:  tensor(-0.0065, device='cuda:0')
Epoch:  673  
Training Loss: 3265.16357421875
Test Loss:  3446.4716796875
Test Acc:  0.0
Valid Loss:  3201.629150390625
Valid Acc:  0.0
std:  47.16509780427394 
thres:  3.33153837890625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 67%|██████▋   | 673/1000 [31:29<15:14,  2.80s/it]Epoch:   674
max of grad d_p:  tensor(1467.4923, device='cuda:0')
min of grad d_p:  tensor(-1469.0002, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3199, device='cuda:0') mean:  tensor(3.0680e-05, device='cuda:0') min:  tensor(-2.5314, device='cuda:0') norm:  tensor(9.3010, device='cuda:0') MSE:  tensor(3.4914e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.3041, device='cuda:0') mean:  tensor(0.0047, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(5.9059, device='cuda:0') MSE:  tensor(2.2169e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0073, device='cuda:0')
min of d_p_list:  tensor(-0.0061, device='cuda:0')
Epoch:  674  
Training Loss: 3232.642822265625
Test Loss:  3412.090087890625
Test Acc:  0.0
Valid Loss:  3169.71337890625
Valid Acc:  0.0
std:  46.7052882478475 
thres:  3.298356396484375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 67%|██████▋   | 674/1000 [31:32<15:42,  2.89s/it]Epoch:   675
max of grad d_p:  tensor(1457.3995, device='cuda:0')
min of grad d_p:  tensor(-1460.6958, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2687, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-3.5688, device='cuda:0') norm:  tensor(10.5341, device='cuda:0') MSE:  tensor(3.9542e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.9916, device='cuda:0') mean:  tensor(0.0039, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(5.2176, device='cuda:0') MSE:  tensor(1.9585e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2008, device='cuda:0')
min of d_p_list:  tensor(-0.1203, device='cuda:0')
Epoch:  675  
Training Loss: 3199.18359375
Test Loss:  3377.00390625
Test Acc:  0.0
Valid Loss:  3134.8779296875
Valid Acc:  0.0
std:  46.58921129483298 
thres:  3.265244287109375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 68%|██████▊   | 675/1000 [31:35<15:31,  2.87s/it]Epoch:   676
max of grad d_p:  tensor(1431.3860, device='cuda:0')
min of grad d_p:  tensor(-1446.5944, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2436, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.1829, device='cuda:0') norm:  tensor(10.1387, device='cuda:0') MSE:  tensor(3.8058e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.7725, device='cuda:0') mean:  tensor(0.0098, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(12.7531, device='cuda:0') MSE:  tensor(4.7872e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0242, device='cuda:0')
min of d_p_list:  tensor(-0.0220, device='cuda:0')
Epoch:  676  
Training Loss: 3167.29833984375
Test Loss:  3343.7041015625
Test Acc:  0.0
Valid Loss:  3103.911376953125
Valid Acc:  0.0
std:  46.30565087729795 
thres:  3.2324617187499998
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 68%|██████▊   | 676/1000 [31:38<15:31,  2.87s/it]Epoch:   677
max of grad d_p:  tensor(1421.0115, device='cuda:0')
min of grad d_p:  tensor(-1440.9834, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3736, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-3.0586, device='cuda:0') norm:  tensor(9.8020, device='cuda:0') MSE:  tensor(3.6794e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3043, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.5861, device='cuda:0') MSE:  tensor(5.9539e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0100, device='cuda:0')
min of d_p_list:  tensor(-0.0041, device='cuda:0')
Epoch:  677  
Training Loss: 3135.744873046875
Test Loss:  3310.305419921875
Test Acc:  0.0
Valid Loss:  3072.89599609375
Valid Acc:  0.0
std:  45.84895084042892 
thres:  3.200006640625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 68%|██████▊   | 677/1000 [31:41<15:37,  2.90s/it]Epoch:   678
max of grad d_p:  tensor(1410.8926, device='cuda:0')
min of grad d_p:  tensor(-1432.6825, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1842, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.1431, device='cuda:0') norm:  tensor(9.0257, device='cuda:0') MSE:  tensor(3.3880e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3708, device='cuda:0') mean:  tensor(0.0011, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.3481, device='cuda:0') MSE:  tensor(5.0604e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0116, device='cuda:0')
min of d_p_list:  tensor(-0.0084, device='cuda:0')
Epoch:  678  
Training Loss: 3104.530029296875
Test Loss:  3277.29052734375
Test Acc:  0.0
Valid Loss:  3042.357177734375
Valid Acc:  0.0
std:  45.21141809403512 
thres:  3.1678799316406248
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 68%|██████▊   | 678/1000 [31:43<15:15,  2.84s/it]Epoch:   679
max of grad d_p:  tensor(1401.8843, device='cuda:0')
min of grad d_p:  tensor(-1424.2488, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2314, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.8112, device='cuda:0') norm:  tensor(9.3160, device='cuda:0') MSE:  tensor(3.4970e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.5177, device='cuda:0') mean:  tensor(0.0020, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.6697, device='cuda:0') MSE:  tensor(1.0021e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0162, device='cuda:0')
min of d_p_list:  tensor(-0.0141, device='cuda:0')
Epoch:  679  
Training Loss: 3073.58251953125
Test Loss:  3244.7353515625
Test Acc:  0.0
Valid Loss:  3012.10595703125
Valid Acc:  0.0
std:  44.4029178716841 
thres:  3.13606787109375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 68%|██████▊   | 679/1000 [31:46<15:10,  2.83s/it]Epoch:   680
max of grad d_p:  tensor(1392.1455, device='cuda:0')
min of grad d_p:  tensor(-1417.5336, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1861, device='cuda:0') mean:  tensor(-3.5956e-05, device='cuda:0') min:  tensor(-2.6680, device='cuda:0') norm:  tensor(9.9141, device='cuda:0') MSE:  tensor(3.7215e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4459, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.0836, device='cuda:0') MSE:  tensor(7.8214e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0064, device='cuda:0')
min of d_p_list:  tensor(-0.0060, device='cuda:0')
Epoch:  680  
Training Loss: 3042.94873046875
Test Loss:  3212.22607421875
Test Acc:  0.0
Valid Loss:  2981.888671875
Valid Acc:  0.0
std:  43.963186829467446 
thres:  3.1048208984375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 68%|██████▊   | 680/1000 [31:49<14:44,  2.76s/it]Epoch:   681
max of grad d_p:  tensor(1382.4113, device='cuda:0')
min of grad d_p:  tensor(-1410.0496, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2189, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.2456, device='cuda:0') norm:  tensor(10.0662, device='cuda:0') MSE:  tensor(3.7786e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2014, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.0710, device='cuda:0') MSE:  tensor(4.0204e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0109, device='cuda:0')
min of d_p_list:  tensor(-0.0061, device='cuda:0')
Epoch:  681  
Training Loss: 3012.633544921875
Test Loss:  3180.20849609375
Test Acc:  0.0
Valid Loss:  2952.169677734375
Valid Acc:  0.0
std:  43.53078608734646 
thres:  3.073887939453125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 68%|██████▊   | 681/1000 [31:51<14:41,  2.76s/it]Epoch:   682
max of grad d_p:  tensor(1372.4637, device='cuda:0')
min of grad d_p:  tensor(-1401.9214, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3535, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(-4.2720, device='cuda:0') norm:  tensor(11.4589, device='cuda:0') MSE:  tensor(4.3014e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.2722, device='cuda:0') mean:  tensor(0.0041, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(5.3993, device='cuda:0') MSE:  tensor(2.0267e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1400, device='cuda:0')
min of d_p_list:  tensor(-0.0831, device='cuda:0')
Epoch:  682  
Training Loss: 2980.93408203125
Test Loss:  3145.162353515625
Test Acc:  0.0
Valid Loss:  2918.4521484375
Valid Acc:  0.0
std:  43.57868713010879 
thres:  3.04292578125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 68%|██████▊   | 682/1000 [31:54<14:27,  2.73s/it]Epoch:   683
max of grad d_p:  tensor(1405.5405, device='cuda:0')
min of grad d_p:  tensor(-1408.1294, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2699, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-2.9469, device='cuda:0') norm:  tensor(9.9718, device='cuda:0') MSE:  tensor(3.7431e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2269, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8689, device='cuda:0') MSE:  tensor(3.2616e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0099, device='cuda:0')
min of d_p_list:  tensor(-0.0074, device='cuda:0')
Epoch:  683  
Training Loss: 2951.2275390625
Test Loss:  3113.70361328125
Test Acc:  0.0
Valid Loss:  2889.2333984375
Valid Acc:  0.0
std:  43.37894281875464 
thres:  3.012265283203125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 68%|██████▊   | 683/1000 [31:57<14:16,  2.70s/it]Epoch:   684
max of grad d_p:  tensor(1393.5798, device='cuda:0')
min of grad d_p:  tensor(-1398.6970, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1389, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-3.6595, device='cuda:0') norm:  tensor(10.1610, device='cuda:0') MSE:  tensor(3.8142e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1586, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7901, device='cuda:0') MSE:  tensor(2.9657e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0116, device='cuda:0')
min of d_p_list:  tensor(-0.0164, device='cuda:0')
Epoch:  684  
Training Loss: 2921.798828125
Test Loss:  3082.34619140625
Test Acc:  0.0
Valid Loss:  2860.113037109375
Valid Acc:  0.0
std:  42.954351650247624 
thres:  2.981908544921875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 68%|██████▊   | 684/1000 [31:59<14:06,  2.68s/it]Epoch:   685
max of grad d_p:  tensor(1383.3608, device='cuda:0')
min of grad d_p:  tensor(-1389.9670, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1241, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(-4.5094, device='cuda:0') norm:  tensor(10.7903, device='cuda:0') MSE:  tensor(4.0504e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4002, device='cuda:0') mean:  tensor(0.0020, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.4618, device='cuda:0') MSE:  tensor(9.2411e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0167, device='cuda:0')
min of d_p_list:  tensor(-0.0117, device='cuda:0')
Epoch:  685  
Training Loss: 2892.6787109375
Test Loss:  3051.3203125
Test Acc:  0.0
Valid Loss:  2831.340087890625
Valid Acc:  0.0
std:  42.297103673333 
thres:  2.9518545410156247
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 68%|██████▊   | 685/1000 [32:02<14:08,  2.69s/it]Epoch:   686
max of grad d_p:  tensor(1373.0054, device='cuda:0')
min of grad d_p:  tensor(-1380.6050, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2186, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.1600, device='cuda:0') norm:  tensor(9.4692, device='cuda:0') MSE:  tensor(3.5545e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.6261, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.3631, device='cuda:0') MSE:  tensor(8.8704e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0087, device='cuda:0')
min of d_p_list:  tensor(-0.0075, device='cuda:0')
Epoch:  686  
Training Loss: 2863.83984375
Test Loss:  3021.15869140625
Test Acc:  0.0
Valid Loss:  2803.365234375
Valid Acc:  0.0
std:  41.400027567628534 
thres:  2.9220958007812503
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 69%|██████▊   | 686/1000 [32:05<14:28,  2.76s/it]Epoch:   687
max of grad d_p:  tensor(1364.7861, device='cuda:0')
min of grad d_p:  tensor(-1372.6440, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2145, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-2.5782, device='cuda:0') norm:  tensor(9.6718, device='cuda:0') MSE:  tensor(3.6305e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2935, device='cuda:0') mean:  tensor(0.0011, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.4671, device='cuda:0') MSE:  tensor(5.5073e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0116, device='cuda:0')
min of d_p_list:  tensor(-0.0132, device='cuda:0')
Epoch:  687  
Training Loss: 2835.31201171875
Test Loss:  2991.2998046875
Test Acc:  0.0
Valid Loss:  2775.677734375
Valid Acc:  0.0
std:  40.98325668897646 
thres:  2.89297138671875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 69%|██████▊   | 687/1000 [32:08<15:02,  2.88s/it]Epoch:   688
max of grad d_p:  tensor(1356.9519, device='cuda:0')
min of grad d_p:  tensor(-1367.3619, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1484, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-3.5817, device='cuda:0') norm:  tensor(9.7007, device='cuda:0') MSE:  tensor(3.6414e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1641, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.6502, device='cuda:0') MSE:  tensor(2.4406e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0084, device='cuda:0')
min of d_p_list:  tensor(-0.0043, device='cuda:0')
Epoch:  688  
Training Loss: 2807.061767578125
Test Loss:  2961.3603515625
Test Acc:  0.0
Valid Loss:  2747.8994140625
Valid Acc:  0.0
std:  40.566158520680005 
thres:  2.8641382324218747
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 69%|██████▉   | 688/1000 [32:11<15:22,  2.96s/it]Epoch:   689
max of grad d_p:  tensor(1348.1301, device='cuda:0')
min of grad d_p:  tensor(-1360.1528, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1957, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.0077, device='cuda:0') norm:  tensor(10.2004, device='cuda:0') MSE:  tensor(3.8290e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.7362, device='cuda:0') mean:  tensor(0.0035, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(4.1653, device='cuda:0') MSE:  tensor(1.5635e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0993, device='cuda:0')
min of d_p_list:  tensor(-0.0832, device='cuda:0')
Epoch:  689  
Training Loss: 2778.688720703125
Test Loss:  2932.003662109375
Test Acc:  0.0
Valid Loss:  2721.62451171875
Valid Acc:  0.0
std:  40.27118143908403 
thres:  2.8355162109375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 69%|██████▉   | 689/1000 [32:14<14:50,  2.86s/it]Epoch:   690
max of grad d_p:  tensor(1351.3751, device='cuda:0')
min of grad d_p:  tensor(-1353.7089, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2754, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.6949, device='cuda:0') norm:  tensor(10.1148, device='cuda:0') MSE:  tensor(3.7968e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4356, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.4051, device='cuda:0') MSE:  tensor(9.0281e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0254, device='cuda:0')
min of d_p_list:  tensor(-0.0202, device='cuda:0')
Epoch:  690  
Training Loss: 2751.023193359375
Test Loss:  2902.90283203125
Test Acc:  0.0
Valid Loss:  2694.49853515625
Valid Acc:  0.0
std:  39.91766965553018 
thres:  2.807185107421875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 69%|██████▉   | 690/1000 [32:17<14:34,  2.82s/it]Epoch:   691
max of grad d_p:  tensor(1344.6741, device='cuda:0')
min of grad d_p:  tensor(-1348.9485, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2954, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.2354, device='cuda:0') norm:  tensor(9.8114, device='cuda:0') MSE:  tensor(3.6829e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3218, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.2936, device='cuda:0') MSE:  tensor(4.8558e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0125, device='cuda:0')
min of d_p_list:  tensor(-0.0056, device='cuda:0')
Epoch:  691  
Training Loss: 2723.6142578125
Test Loss:  2873.972900390625
Test Acc:  0.0
Valid Loss:  2667.647705078125
Valid Acc:  0.0
std:  39.519075189990325 
thres:  2.779139990234375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 69%|██████▉   | 691/1000 [32:19<14:23,  2.79s/it]Epoch:   692
max of grad d_p:  tensor(1335.2656, device='cuda:0')
min of grad d_p:  tensor(-1339.9270, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2461, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-3.5428, device='cuda:0') norm:  tensor(10.2832, device='cuda:0') MSE:  tensor(3.8600e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.7427, device='cuda:0') mean:  tensor(0.0020, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.9380, device='cuda:0') MSE:  tensor(1.1028e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0079, device='cuda:0')
min of d_p_list:  tensor(-0.0051, device='cuda:0')
Epoch:  692  
Training Loss: 2696.482421875
Test Loss:  2845.25732421875
Test Acc:  0.0
Valid Loss:  2641.0205078125
Valid Acc:  0.0
std:  39.06669457624342 
thres:  2.751374072265625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 69%|██████▉   | 692/1000 [32:22<14:18,  2.79s/it]Epoch:   693
max of grad d_p:  tensor(1326.1377, device='cuda:0')
min of grad d_p:  tensor(-1332.2549, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1895, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-2.9869, device='cuda:0') norm:  tensor(9.7711, device='cuda:0') MSE:  tensor(3.6678e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.2914, device='cuda:0') mean:  tensor(0.0035, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(4.7229, device='cuda:0') MSE:  tensor(1.7728e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0103, device='cuda:0')
min of d_p_list:  tensor(-0.0072, device='cuda:0')
Epoch:  693  
Training Loss: 2669.637451171875
Test Loss:  2816.6474609375
Test Acc:  0.0
Valid Loss:  2614.561279296875
Valid Acc:  0.0
std:  38.558268623546454 
thres:  2.723889208984375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 69%|██████▉   | 693/1000 [32:25<14:36,  2.85s/it]Epoch:   694
max of grad d_p:  tensor(1317.0001, device='cuda:0')
min of grad d_p:  tensor(-1324.2180, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2984, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.1824, device='cuda:0') norm:  tensor(10.3553, device='cuda:0') MSE:  tensor(3.8871e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.6257, device='cuda:0') mean:  tensor(0.0023, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.8342, device='cuda:0') MSE:  tensor(1.0639e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0118, device='cuda:0')
min of d_p_list:  tensor(-0.0130, device='cuda:0')
Epoch:  694  
Training Loss: 2643.07861328125
Test Loss:  2788.27978515625
Test Acc:  0.0
Valid Loss:  2588.261962890625
Valid Acc:  0.0
std:  38.16555002227492 
thres:  2.6967671875000003
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 69%|██████▉   | 694/1000 [32:28<14:39,  2.87s/it]Epoch:   695
max of grad d_p:  tensor(1309.2898, device='cuda:0')
min of grad d_p:  tensor(-1317.2369, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0871, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-3.5947, device='cuda:0') norm:  tensor(9.4053, device='cuda:0') MSE:  tensor(3.5305e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2929, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.5616, device='cuda:0') MSE:  tensor(5.8619e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0092, device='cuda:0')
min of d_p_list:  tensor(-0.0045, device='cuda:0')
Epoch:  695  
Training Loss: 2616.76806640625
Test Loss:  2760.37646484375
Test Acc:  0.0
Valid Loss:  2562.3056640625
Valid Acc:  0.0
std:  37.773809508266034 
thres:  2.669916162109375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 70%|██████▉   | 695/1000 [32:31<14:55,  2.94s/it]Epoch:   696
max of grad d_p:  tensor(1300.4146, device='cuda:0')
min of grad d_p:  tensor(-1310.5681, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1898, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.4244, device='cuda:0') norm:  tensor(9.8199, device='cuda:0') MSE:  tensor(3.6861e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4033, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.4901, device='cuda:0') MSE:  tensor(5.5935e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0216, device='cuda:0')
min of d_p_list:  tensor(-0.0198, device='cuda:0')
Epoch:  696  
Training Loss: 2590.78662109375
Test Loss:  2732.80322265625
Test Acc:  0.0
Valid Loss:  2536.4462890625
Valid Acc:  0.0
std:  37.372893887890754 
thres:  2.643350634765625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 70%|██████▉   | 696/1000 [32:34<14:53,  2.94s/it]Epoch:   697
max of grad d_p:  tensor(1286.6431, device='cuda:0')
min of grad d_p:  tensor(-1300.6178, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3139, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.4828, device='cuda:0') norm:  tensor(10.0468, device='cuda:0') MSE:  tensor(3.7713e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1914, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7370, device='cuda:0') MSE:  tensor(2.7665e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0198, device='cuda:0')
min of d_p_list:  tensor(-0.0252, device='cuda:0')
Epoch:  697  
Training Loss: 2564.968505859375
Test Loss:  2705.81005859375
Test Acc:  0.0
Valid Loss:  2511.39599609375
Valid Acc:  0.0
std:  37.00068998563346 
thres:  2.6170478515625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 70%|██████▉   | 697/1000 [32:37<14:59,  2.97s/it]Epoch:   698
max of grad d_p:  tensor(1279.8220, device='cuda:0')
min of grad d_p:  tensor(-1292.0702, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1937, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.1628, device='cuda:0') norm:  tensor(9.5154, device='cuda:0') MSE:  tensor(3.5718e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2839, device='cuda:0') mean:  tensor(0.0011, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.4311, device='cuda:0') MSE:  tensor(5.3718e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0091, device='cuda:0')
min of d_p_list:  tensor(-0.0040, device='cuda:0')
Epoch:  698  
Training Loss: 2539.4150390625
Test Loss:  2678.813720703125
Test Acc:  0.0
Valid Loss:  2486.401123046875
Valid Acc:  0.0
std:  36.64660301728875 
thres:  2.5910033691406253
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 70%|██████▉   | 698/1000 [32:40<14:27,  2.87s/it]Epoch:   699
max of grad d_p:  tensor(1271.7662, device='cuda:0')
min of grad d_p:  tensor(-1284.8567, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2727, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.3912, device='cuda:0') norm:  tensor(10.2672, device='cuda:0') MSE:  tensor(3.8540e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.0380, device='cuda:0') mean:  tensor(0.0083, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(11.2854, device='cuda:0') MSE:  tensor(4.2363e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0096, device='cuda:0')
min of d_p_list:  tensor(-0.0049, device='cuda:0')
Epoch:  699  
Training Loss: 2514.123291015625
Test Loss:  2652.126953125
Test Acc:  0.0
Valid Loss:  2461.56005859375
Valid Acc:  0.0
std:  36.297900478148726 
thres:  2.5652123046875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 70%|██████▉   | 699/1000 [32:43<14:13,  2.84s/it]Epoch:   700
max of grad d_p:  tensor(1263.0043, device='cuda:0')
min of grad d_p:  tensor(-1277.3473, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1866, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.3033, device='cuda:0') norm:  tensor(9.7389, device='cuda:0') MSE:  tensor(3.6557e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(41.7486, device='cuda:0') mean:  tensor(0.1245, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(166.2067, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0120, device='cuda:0')
min of d_p_list:  tensor(-0.0124, device='cuda:0')
Epoch:  700  
Training Loss: 2489.076171875
Test Loss:  2625.6884765625
Test Acc:  0.0
Valid Loss:  2437.017578125
Valid Acc:  0.0
std:  35.95930495172031 
thres:  2.53967392578125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 70%|███████   | 700/1000 [32:45<14:07,  2.82s/it]Epoch:   701
max of grad d_p:  tensor(1254.9180, device='cuda:0')
min of grad d_p:  tensor(-1270.1166, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2377, device='cuda:0') mean:  tensor(2.7899e-05, device='cuda:0') min:  tensor(-2.3875, device='cuda:0') norm:  tensor(9.2317, device='cuda:0') MSE:  tensor(3.4653e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.5336, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.8173, device='cuda:0') MSE:  tensor(1.0575e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0157, device='cuda:0')
min of d_p_list:  tensor(-0.0296, device='cuda:0')
Epoch:  701  
Training Loss: 2464.286865234375
Test Loss:  2599.701904296875
Test Acc:  0.0
Valid Loss:  2413.005859375
Valid Acc:  0.0
std:  35.596689993165164 
thres:  2.5143739746093754
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 70%|███████   | 701/1000 [32:48<14:07,  2.84s/it]Epoch:   702
max of grad d_p:  tensor(1246.0476, device='cuda:0')
min of grad d_p:  tensor(-1261.9128, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2784, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.3124, device='cuda:0') norm:  tensor(9.1417, device='cuda:0') MSE:  tensor(3.4316e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4812, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.7980, device='cuda:0') MSE:  tensor(6.7493e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0100, device='cuda:0')
min of d_p_list:  tensor(-0.0069, device='cuda:0')
Epoch:  702  
Training Loss: 2439.73876953125
Test Loss:  2574.029296875
Test Acc:  0.0
Valid Loss:  2389.1767578125
Valid Acc:  0.0
std:  35.241258674547176 
thres:  2.48932802734375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 70%|███████   | 702/1000 [32:51<14:16,  2.87s/it]Epoch:   703
max of grad d_p:  tensor(1237.7179, device='cuda:0')
min of grad d_p:  tensor(-1255.4297, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3724, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-3.6475, device='cuda:0') norm:  tensor(9.7960, device='cuda:0') MSE:  tensor(3.6771e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3594, device='cuda:0') mean:  tensor(0.0011, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.3935, device='cuda:0') MSE:  tensor(5.2308e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0268, device='cuda:0')
min of d_p_list:  tensor(-0.0234, device='cuda:0')
Epoch:  703  
Training Loss: 2415.5302734375
Test Loss:  2549.25927734375
Test Acc:  0.0
Valid Loss:  2366.078125
Valid Acc:  0.0
std:  34.864435382586464 
thres:  2.46455107421875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 70%|███████   | 703/1000 [32:54<14:23,  2.91s/it]Epoch:   704
max of grad d_p:  tensor(1228.6210, device='cuda:0')
min of grad d_p:  tensor(-1244.5129, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.9832, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-3.9503, device='cuda:0') norm:  tensor(9.1396, device='cuda:0') MSE:  tensor(3.4308e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.9889, device='cuda:0') mean:  tensor(0.0037, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(4.6779, device='cuda:0') MSE:  tensor(1.7560e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0090, device='cuda:0')
min of d_p_list:  tensor(-0.0068, device='cuda:0')
Epoch:  704  
Training Loss: 2391.4638671875
Test Loss:  2523.82568359375
Test Acc:  0.0
Valid Loss:  2342.4912109375
Valid Acc:  0.0
std:  34.50481872271071 
thres:  2.440019189453125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 70%|███████   | 704/1000 [32:57<14:24,  2.92s/it]Epoch:   705
max of grad d_p:  tensor(1220.6490, device='cuda:0')
min of grad d_p:  tensor(-1237.0388, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1004, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-2.5132, device='cuda:0') norm:  tensor(8.4434, device='cuda:0') MSE:  tensor(3.1694e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.6116, device='cuda:0') mean:  tensor(0.0031, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(4.0442, device='cuda:0') MSE:  tensor(1.5181e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0081, device='cuda:0')
min of d_p_list:  tensor(-0.0072, device='cuda:0')
Epoch:  705  
Training Loss: 2367.63427734375
Test Loss:  2498.661865234375
Test Acc:  0.0
Valid Loss:  2319.146240234375
Valid Acc:  0.0
std:  34.16511028142476 
thres:  2.4157308105468753
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 70%|███████   | 705/1000 [33:00<14:27,  2.94s/it]Epoch:   706
max of grad d_p:  tensor(1213.2549, device='cuda:0')
min of grad d_p:  tensor(-1230.8867, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1412, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.8862, device='cuda:0') norm:  tensor(9.4587, device='cuda:0') MSE:  tensor(3.5506e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3101, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.6780, device='cuda:0') MSE:  tensor(6.2988e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0094, device='cuda:0')
min of d_p_list:  tensor(-0.0068, device='cuda:0')
Epoch:  706  
Training Loss: 2344.04345703125
Test Loss:  2473.646484375
Test Acc:  0.0
Valid Loss:  2295.939453125
Valid Acc:  0.0
std:  33.8406990669744 
thres:  2.39168212890625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 71%|███████   | 706/1000 [33:03<14:28,  2.95s/it]Epoch:   707
max of grad d_p:  tensor(1205.4561, device='cuda:0')
min of grad d_p:  tensor(-1224.2561, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1395, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-2.4879, device='cuda:0') norm:  tensor(8.7113, device='cuda:0') MSE:  tensor(3.2700e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2226, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.1629, device='cuda:0') MSE:  tensor(4.3653e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0101, device='cuda:0')
min of d_p_list:  tensor(-0.0062, device='cuda:0')
Epoch:  707  
Training Loss: 2320.701416015625
Test Loss:  2449.263916015625
Test Acc:  0.0
Valid Loss:  2273.30029296875
Valid Acc:  0.0
std:  33.52851668239372 
thres:  2.367874658203125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 71%|███████   | 707/1000 [33:06<14:27,  2.96s/it]Epoch:   708
max of grad d_p:  tensor(1197.1938, device='cuda:0')
min of grad d_p:  tensor(-1217.8098, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1700, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.0728, device='cuda:0') norm:  tensor(9.5457, device='cuda:0') MSE:  tensor(3.5832e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3026, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.4641, device='cuda:0') MSE:  tensor(5.4958e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0073, device='cuda:0')
min of d_p_list:  tensor(-0.0043, device='cuda:0')
Epoch:  708  
Training Loss: 2297.57763671875
Test Loss:  2424.83642578125
Test Acc:  0.0
Valid Loss:  2250.67138671875
Valid Acc:  0.0
std:  33.19293846297606 
thres:  2.3442841308593754
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 71%|███████   | 708/1000 [33:09<14:27,  2.97s/it]Epoch:   709
max of grad d_p:  tensor(1188.9219, device='cuda:0')
min of grad d_p:  tensor(-1211.0652, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0029, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.2399, device='cuda:0') norm:  tensor(8.5675, device='cuda:0') MSE:  tensor(3.2160e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.5318, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.2998, device='cuda:0') MSE:  tensor(8.6327e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0859, device='cuda:0')
min of d_p_list:  tensor(-0.0606, device='cuda:0')
Epoch:  709  
Training Loss: 2274.666748046875
Test Loss:  2400.227294921875
Test Acc:  0.0
Valid Loss:  2228.2138671875
Valid Acc:  0.0
std:  32.86698915567253 
thres:  2.3209247070312498
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 71%|███████   | 709/1000 [33:12<14:25,  2.97s/it]Epoch:   710
max of grad d_p:  tensor(1179.4812, device='cuda:0')
min of grad d_p:  tensor(-1201.0291, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2064, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-3.9598, device='cuda:0') norm:  tensor(9.7268, device='cuda:0') MSE:  tensor(3.6512e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.9813, device='cuda:0') mean:  tensor(0.0040, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(5.0089, device='cuda:0') MSE:  tensor(1.8802e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0075, device='cuda:0')
min of d_p_list:  tensor(-0.0058, device='cuda:0')
Epoch:  710  
Training Loss: 2252.00830078125
Test Loss:  2376.16748046875
Test Acc:  0.0
Valid Loss:  2205.86767578125
Valid Acc:  0.0
std:  32.542306867294386 
thres:  2.2977995117187504
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 71%|███████   | 710/1000 [33:15<14:28,  3.00s/it]Epoch:   711
max of grad d_p:  tensor(1171.8179, device='cuda:0')
min of grad d_p:  tensor(-1194.6682, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1568, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-3.5377, device='cuda:0') norm:  tensor(9.7241, device='cuda:0') MSE:  tensor(3.6502e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3370, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.3571, device='cuda:0') MSE:  tensor(5.0940e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0089, device='cuda:0')
min of d_p_list:  tensor(-0.0038, device='cuda:0')
Epoch:  711  
Training Loss: 2229.568603515625
Test Loss:  2352.374267578125
Test Acc:  0.0
Valid Loss:  2183.80322265625
Valid Acc:  0.0
std:  32.221311642758415 
thres:  2.274904541015625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 71%|███████   | 711/1000 [33:18<14:22,  2.98s/it]Epoch:   712
max of grad d_p:  tensor(1163.9561, device='cuda:0')
min of grad d_p:  tensor(-1188.4684, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1914, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-3.8694, device='cuda:0') norm:  tensor(9.4115, device='cuda:0') MSE:  tensor(3.5328e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1074, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.6786, device='cuda:0') MSE:  tensor(2.5474e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0906, device='cuda:0')
min of d_p_list:  tensor(-0.0600, device='cuda:0')
Epoch:  712  
Training Loss: 2208.115234375
Test Loss:  2331.392578125
Test Acc:  0.0
Valid Loss:  2164.361328125
Valid Acc:  0.0
std:  31.684042300140444 
thres:  2.2523873046875003
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 71%|███████   | 712/1000 [33:21<14:14,  2.97s/it]Epoch:   713
max of grad d_p:  tensor(1148.3036, device='cuda:0')
min of grad d_p:  tensor(-1181.3394, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0653, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.8939, device='cuda:0') norm:  tensor(8.7825, device='cuda:0') MSE:  tensor(3.2967e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3337, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.8162, device='cuda:0') MSE:  tensor(6.8174e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0090, device='cuda:0')
min of d_p_list:  tensor(-0.0053, device='cuda:0')
Epoch:  713  
Training Loss: 2186.114990234375
Test Loss:  2308.140869140625
Test Acc:  0.0
Valid Loss:  2142.79296875
Valid Acc:  0.0
std:  31.255277711146817 
thres:  2.230094775390625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 71%|███████▏  | 713/1000 [33:24<14:06,  2.95s/it]Epoch:   714
max of grad d_p:  tensor(1140.0916, device='cuda:0')
min of grad d_p:  tensor(-1174.4775, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2247, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.6995, device='cuda:0') norm:  tensor(9.1834, device='cuda:0') MSE:  tensor(3.4472e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2862, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.4545, device='cuda:0') MSE:  tensor(9.2136e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0088, device='cuda:0')
min of d_p_list:  tensor(-0.0054, device='cuda:0')
Epoch:  714  
Training Loss: 2164.338623046875
Test Loss:  2285.06396484375
Test Acc:  0.0
Valid Loss:  2121.3828125
Valid Acc:  0.0
std:  30.94257169462936 
thres:  2.208029150390625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 71%|███████▏  | 714/1000 [33:27<14:30,  3.05s/it]Epoch:   715
max of grad d_p:  tensor(1132.3154, device='cuda:0')
min of grad d_p:  tensor(-1167.9062, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1212, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.8213, device='cuda:0') norm:  tensor(8.0239, device='cuda:0') MSE:  tensor(3.0120e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3871, device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.9683, device='cuda:0') MSE:  tensor(7.3883e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0538, device='cuda:0')
min of d_p_list:  tensor(-0.0331, device='cuda:0')
Epoch:  715  
Training Loss: 2142.51171875
Test Loss:  2262.13671875
Test Acc:  0.0
Valid Loss:  2099.68115234375
Valid Acc:  0.0
std:  30.81454721323647 
thres:  2.186129833984375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 72%|███████▏  | 715/1000 [33:30<14:09,  2.98s/it]Epoch:   716
max of grad d_p:  tensor(1120.6317, device='cuda:0')
min of grad d_p:  tensor(-1163.1757, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0680, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-3.4966, device='cuda:0') norm:  tensor(9.1019, device='cuda:0') MSE:  tensor(3.4166e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.0587, device='cuda:0') mean:  tensor(0.0076, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(9.8545, device='cuda:0') MSE:  tensor(3.6991e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0172, device='cuda:0')
min of d_p_list:  tensor(-0.0194, device='cuda:0')
Epoch:  716  
Training Loss: 2121.185302734375
Test Loss:  2239.6728515625
Test Acc:  0.0
Valid Loss:  2079.045654296875
Valid Acc:  0.0
std:  30.754378754997767 
thres:  2.1644531738281247
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 72%|███████▏  | 716/1000 [33:33<13:53,  2.93s/it]Epoch:   717
max of grad d_p:  tensor(1111.0845, device='cuda:0')
min of grad d_p:  tensor(-1155.8424, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1679, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.4797, device='cuda:0') norm:  tensor(8.6172, device='cuda:0') MSE:  tensor(3.2347e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(13.6829, device='cuda:0') mean:  tensor(0.0512, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(65.7491, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0085, device='cuda:0')
min of d_p_list:  tensor(-0.0071, device='cuda:0')
Epoch:  717  
Training Loss: 2100.052734375
Test Loss:  2217.310546875
Test Acc:  0.0
Valid Loss:  2058.263427734375
Valid Acc:  0.0
std:  30.445687222777316 
thres:  2.142840673828125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 72%|███████▏  | 717/1000 [33:35<13:30,  2.86s/it]Epoch:   718
max of grad d_p:  tensor(1103.6558, device='cuda:0')
min of grad d_p:  tensor(-1149.7307, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1528, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.0225, device='cuda:0') norm:  tensor(8.3680, device='cuda:0') MSE:  tensor(3.1411e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3111, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.1566, device='cuda:0') MSE:  tensor(4.3416e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0058, device='cuda:0')
min of d_p_list:  tensor(-0.0055, device='cuda:0')
Epoch:  718  
Training Loss: 2079.134765625
Test Loss:  2195.103271484375
Test Acc:  0.0
Valid Loss:  2037.6212158203125
Valid Acc:  0.0
std:  30.104889770262293 
thres:  2.12144462890625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 72%|███████▏  | 718/1000 [33:38<13:18,  2.83s/it]Epoch:   719
max of grad d_p:  tensor(1096.3824, device='cuda:0')
min of grad d_p:  tensor(-1143.6681, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2079, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.8130, device='cuda:0') norm:  tensor(9.5775, device='cuda:0') MSE:  tensor(3.5952e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3608, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.6160, device='cuda:0') MSE:  tensor(6.0661e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0081, device='cuda:0')
min of d_p_list:  tensor(-0.0067, device='cuda:0')
Epoch:  719  
Training Loss: 2058.42236328125
Test Loss:  2173.27001953125
Test Acc:  0.0
Valid Loss:  2017.3118896484375
Valid Acc:  0.0
std:  29.731405466349653 
thres:  2.100261376953125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 72%|███████▏  | 719/1000 [33:41<13:05,  2.79s/it]Epoch:   720
max of grad d_p:  tensor(1088.2332, device='cuda:0')
min of grad d_p:  tensor(-1137.3374, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0773, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-2.5377, device='cuda:0') norm:  tensor(8.2812, device='cuda:0') MSE:  tensor(3.1086e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.8478, device='cuda:0') mean:  tensor(0.0272, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(33.6151, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0909, device='cuda:0')
min of d_p_list:  tensor(-0.0694, device='cuda:0')
Epoch:  720  
Training Loss: 2037.6463623046875
Test Loss:  2150.00390625
Test Acc:  0.0
Valid Loss:  1995.430419921875
Valid Acc:  0.0
std:  29.516037796469977 
thres:  2.0792883056640625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 72%|███████▏  | 720/1000 [33:44<13:32,  2.90s/it]Epoch:   721
max of grad d_p:  tensor(1079.8477, device='cuda:0')
min of grad d_p:  tensor(-1115.2009, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1230, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.2125, device='cuda:0') norm:  tensor(8.7044, device='cuda:0') MSE:  tensor(3.2674e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.5580, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.1492, device='cuda:0') MSE:  tensor(8.0674e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0113, device='cuda:0')
min of d_p_list:  tensor(-0.0149, device='cuda:0')
Epoch:  721  
Training Loss: 2017.31982421875
Test Loss:  2128.081298828125
Test Acc:  0.0
Valid Loss:  1975.19921875
Valid Acc:  0.0
std:  29.268102909773756 
thres:  2.058515209960938
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 72%|███████▏  | 721/1000 [33:47<13:02,  2.81s/it]Epoch:   722
max of grad d_p:  tensor(1073.3984, device='cuda:0')
min of grad d_p:  tensor(-1109.1562, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1228, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.6666, device='cuda:0') norm:  tensor(8.9237, device='cuda:0') MSE:  tensor(3.3497e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.5984, device='cuda:0') mean:  tensor(0.0067, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(8.5613, device='cuda:0') MSE:  tensor(3.2137e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0088, device='cuda:0')
min of d_p_list:  tensor(-0.0088, device='cuda:0')
Epoch:  722  
Training Loss: 1997.2142333984375
Test Loss:  2106.78466796875
Test Acc:  0.0
Valid Loss:  1955.4674072265625
Valid Acc:  0.0
std:  28.98413902855002 
thres:  2.037947509765625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 72%|███████▏  | 722/1000 [33:50<13:11,  2.85s/it]Epoch:   723
max of grad d_p:  tensor(1067.0928, device='cuda:0')
min of grad d_p:  tensor(-1103.5251, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1944, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.0608, device='cuda:0') norm:  tensor(9.2762, device='cuda:0') MSE:  tensor(3.4820e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4424, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.2545, device='cuda:0') MSE:  tensor(8.4629e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0077, device='cuda:0')
min of d_p_list:  tensor(-0.0068, device='cuda:0')
Epoch:  723  
Training Loss: 1977.31640625
Test Loss:  2085.740234375
Test Acc:  0.0
Valid Loss:  1935.935302734375
Valid Acc:  0.0
std:  28.659192533164873 
thres:  2.017583837890625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 72%|███████▏  | 723/1000 [33:52<12:54,  2.80s/it]Epoch:   724
max of grad d_p:  tensor(1059.9884, device='cuda:0')
min of grad d_p:  tensor(-1098.2998, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2172, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-2.7006, device='cuda:0') norm:  tensor(9.2630, device='cuda:0') MSE:  tensor(3.4771e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2826, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.3175, device='cuda:0') MSE:  tensor(4.9455e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0077, device='cuda:0')
min of d_p_list:  tensor(-0.0056, device='cuda:0')
Epoch:  724  
Training Loss: 1957.6220703125
Test Loss:  2064.948974609375
Test Acc:  0.0
Valid Loss:  1916.6416015625
Valid Acc:  0.0
std:  28.292172718829 
thres:  1.997423779296875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 72%|███████▏  | 724/1000 [33:55<12:42,  2.76s/it]Epoch:   725
max of grad d_p:  tensor(1053.5305, device='cuda:0')
min of grad d_p:  tensor(-1093.1443, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2047, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-4.0552, device='cuda:0') norm:  tensor(9.6144, device='cuda:0') MSE:  tensor(3.6090e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.3433, device='cuda:0') mean:  tensor(0.0050, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(6.6942, device='cuda:0') MSE:  tensor(2.5128e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0192, device='cuda:0')
min of d_p_list:  tensor(-0.0220, device='cuda:0')
Epoch:  725  
Training Loss: 1938.131591796875
Test Loss:  2044.9044189453125
Test Acc:  0.0
Valid Loss:  1898.260986328125
Valid Acc:  0.0
std:  27.997516284951175 
thres:  1.9775208251953125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 72%|███████▎  | 725/1000 [33:58<12:49,  2.80s/it]Epoch:   726
max of grad d_p:  tensor(1049.1650, device='cuda:0')
min of grad d_p:  tensor(-1086.6626, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0640, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.2817, device='cuda:0') norm:  tensor(8.5434, device='cuda:0') MSE:  tensor(3.2070e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4021, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.1158, device='cuda:0') MSE:  tensor(7.9423e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0072, device='cuda:0')
min of d_p_list:  tensor(-0.0058, device='cuda:0')
Epoch:  726  
Training Loss: 1918.82421875
Test Loss:  2024.4951171875
Test Acc:  0.0
Valid Loss:  1879.3270263671875
Valid Acc:  0.0
std:  27.714108379046664 
thres:  1.9578217041015626
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 73%|███████▎  | 726/1000 [34:01<12:51,  2.82s/it]Epoch:   727
max of grad d_p:  tensor(1042.3516, device='cuda:0')
min of grad d_p:  tensor(-1081.4370, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1290, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.1366, device='cuda:0') norm:  tensor(9.1834, device='cuda:0') MSE:  tensor(3.4472e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1316, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7319, device='cuda:0') MSE:  tensor(2.7473e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0074, device='cuda:0')
min of d_p_list:  tensor(-0.0042, device='cuda:0')
Epoch:  727  
Training Loss: 1899.708984375
Test Loss:  2004.2772216796875
Test Acc:  0.0
Valid Loss:  1860.58349609375
Valid Acc:  0.0
std:  27.438006955375098 
thres:  1.9383206542968752
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 73%|███████▎  | 727/1000 [34:03<12:38,  2.78s/it]Epoch:   728
max of grad d_p:  tensor(1035.0894, device='cuda:0')
min of grad d_p:  tensor(-1074.9674, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2702, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.3651, device='cuda:0') norm:  tensor(9.2458, device='cuda:0') MSE:  tensor(3.4706e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.6516, device='cuda:0') mean:  tensor(0.0079, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(9.9422, device='cuda:0') MSE:  tensor(3.7320e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0112, device='cuda:0')
min of d_p_list:  tensor(-0.0120, device='cuda:0')
Epoch:  728  
Training Loss: 1880.7694091796875
Test Loss:  1984.059814453125
Test Acc:  0.0
Valid Loss:  1841.7830810546875
Valid Acc:  0.0
std:  27.17143258610418 
thres:  1.9190112548828124
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 73%|███████▎  | 728/1000 [34:06<12:33,  2.77s/it]Epoch:   729
max of grad d_p:  tensor(1028.6404, device='cuda:0')
min of grad d_p:  tensor(-1070.7777, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1427, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.0459, device='cuda:0') norm:  tensor(8.5375, device='cuda:0') MSE:  tensor(3.2047e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2490, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.1473, device='cuda:0') MSE:  tensor(4.3065e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2071, device='cuda:0')
min of d_p_list:  tensor(-0.2111, device='cuda:0')
Epoch:  729  
Training Loss: 1866.674072265625
Test Loss:  1972.9583740234375
Test Acc:  0.0
Valid Loss:  1830.9888916015625
Valid Acc:  0.0
std:  25.63400745228332 
thres:  1.9008216552734376
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 73%|███████▎  | 729/1000 [34:09<12:27,  2.76s/it]Epoch:   730
max of grad d_p:  tensor(1016.4207, device='cuda:0')
min of grad d_p:  tensor(-1086.0374, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2775, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.4247, device='cuda:0') norm:  tensor(9.4242, device='cuda:0') MSE:  tensor(3.5376e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2675, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.1313, device='cuda:0') MSE:  tensor(4.2467e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0137, device='cuda:0')
min of d_p_list:  tensor(-0.0105, device='cuda:0')
Epoch:  730  
Training Loss: 1848.0771484375
Test Loss:  1953.1781005859375
Test Acc:  0.0
Valid Loss:  1812.64990234375
Valid Acc:  0.0
std:  24.71235632046661 
thres:  1.8828107666015625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 73%|███████▎  | 730/1000 [34:12<12:23,  2.75s/it]Epoch:   731
max of grad d_p:  tensor(1009.0853, device='cuda:0')
min of grad d_p:  tensor(-1079.1676, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3903, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-4.2175, device='cuda:0') norm:  tensor(10.0566, device='cuda:0') MSE:  tensor(3.7750e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.6981, device='cuda:0') mean:  tensor(0.0030, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(3.9990, device='cuda:0') MSE:  tensor(1.5011e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0088, device='cuda:0')
min of d_p_list:  tensor(-0.0037, device='cuda:0')
Epoch:  731  
Training Loss: 1829.663330078125
Test Loss:  1933.6285400390625
Test Acc:  0.0
Valid Loss:  1794.545166015625
Valid Acc:  0.0
std:  24.45915466307801 
thres:  1.8649785888671875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 73%|███████▎  | 731/1000 [34:14<12:25,  2.77s/it]Epoch:   732
max of grad d_p:  tensor(1002.3099, device='cuda:0')
min of grad d_p:  tensor(-1073.0206, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.4244, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-4.2477, device='cuda:0') norm:  tensor(10.3727, device='cuda:0') MSE:  tensor(3.8937e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.2543, device='cuda:0') mean:  tensor(0.0120, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(16.0175, device='cuda:0') MSE:  tensor(6.0125e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0255, device='cuda:0')
min of d_p_list:  tensor(-0.0316, device='cuda:0')
Epoch:  732  
Training Loss: 1811.439208984375
Test Loss:  1914.4256591796875
Test Acc:  0.0
Valid Loss:  1776.4554443359375
Valid Acc:  0.0
std:  24.87249650021727 
thres:  1.8473246337890625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 73%|███████▎  | 732/1000 [34:17<12:12,  2.73s/it]Epoch:   733
max of grad d_p:  tensor(1000.4903, device='cuda:0')
min of grad d_p:  tensor(-1072.3314, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1653, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.9408, device='cuda:0') norm:  tensor(8.5556, device='cuda:0') MSE:  tensor(3.2116e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2905, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.3075, device='cuda:0') MSE:  tensor(4.9081e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0093, device='cuda:0')
min of d_p_list:  tensor(-0.0058, device='cuda:0')
Epoch:  733  
Training Loss: 1793.38916015625
Test Loss:  1895.2672119140625
Test Acc:  0.0
Valid Loss:  1758.6785888671875
Valid Acc:  0.0
std:  25.909944584863428 
thres:  1.829848583984375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 73%|███████▎  | 733/1000 [34:20<12:28,  2.80s/it]Epoch:   734
max of grad d_p:  tensor(994.1508, device='cuda:0')
min of grad d_p:  tensor(-1066.6108, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1771, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-4.1085, device='cuda:0') norm:  tensor(9.6467, device='cuda:0') MSE:  tensor(3.6211e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.2016, device='cuda:0') mean:  tensor(0.0035, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(4.5932, device='cuda:0') MSE:  tensor(1.7242e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0077, device='cuda:0')
min of d_p_list:  tensor(-0.0072, device='cuda:0')
Epoch:  734  
Training Loss: 1775.515625
Test Loss:  1876.293701171875
Test Acc:  0.0
Valid Loss:  1741.1015625
Valid Acc:  0.0
std:  25.653878791414044 
thres:  1.81161689453125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 73%|███████▎  | 734/1000 [34:23<12:33,  2.83s/it]Epoch:   735
max of grad d_p:  tensor(987.6022, device='cuda:0')
min of grad d_p:  tensor(-1060.6121, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1606, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.4552, device='cuda:0') norm:  tensor(8.4739, device='cuda:0') MSE:  tensor(3.1809e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3631, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8738, device='cuda:0') MSE:  tensor(3.2802e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0079, device='cuda:0')
min of d_p_list:  tensor(-0.0047, device='cuda:0')
Epoch:  735  
Training Loss: 1757.8267822265625
Test Loss:  1857.615966796875
Test Acc:  0.0
Valid Loss:  1723.78955078125
Valid Acc:  0.0
std:  25.399243421109322 
thres:  1.7935668212890625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 74%|███████▎  | 735/1000 [34:26<13:06,  2.97s/it]Epoch:   736
max of grad d_p:  tensor(980.6418, device='cuda:0')
min of grad d_p:  tensor(-1054.5569, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2914, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.2400, device='cuda:0') norm:  tensor(9.1997, device='cuda:0') MSE:  tensor(3.4533e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4655, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.8254, device='cuda:0') MSE:  tensor(6.8521e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0091, device='cuda:0')
min of d_p_list:  tensor(-0.0075, device='cuda:0')
Epoch:  736  
Training Loss: 1740.3193359375
Test Loss:  1839.0416259765625
Test Acc:  0.0
Valid Loss:  1706.612060546875
Valid Acc:  0.0
std:  25.14547563093534 
thres:  1.7756980224609376
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 74%|███████▎  | 736/1000 [34:29<12:43,  2.89s/it]Epoch:   737
max of grad d_p:  tensor(974.5983, device='cuda:0')
min of grad d_p:  tensor(-1049.1519, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1768, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.3638, device='cuda:0') norm:  tensor(9.0403, device='cuda:0') MSE:  tensor(3.3935e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1457, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.6352, device='cuda:0') MSE:  tensor(2.3844e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0216, device='cuda:0')
min of d_p_list:  tensor(-0.0163, device='cuda:0')
Epoch:  737  
Training Loss: 1723.036376953125
Test Loss:  1820.543701171875
Test Acc:  0.0
Valid Loss:  1689.351806640625
Valid Acc:  0.0
std:  24.876812797414757 
thres:  1.7580174560546875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 74%|███████▎  | 737/1000 [34:32<12:29,  2.85s/it]Epoch:   738
max of grad d_p:  tensor(965.7720, device='cuda:0')
min of grad d_p:  tensor(-1041.8922, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1953, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.0492, device='cuda:0') norm:  tensor(8.3885, device='cuda:0') MSE:  tensor(3.1488e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1446, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.5389, device='cuda:0') MSE:  tensor(2.0230e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0148, device='cuda:0')
min of d_p_list:  tensor(-0.0259, device='cuda:0')
Epoch:  738  
Training Loss: 1705.7474365234375
Test Loss:  1802.2012939453125
Test Acc:  0.0
Valid Loss:  1672.356201171875
Valid Acc:  0.0
std:  24.653852523574482 
thres:  1.7404891113281251
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 74%|███████▍  | 738/1000 [34:34<12:17,  2.81s/it]Epoch:   739
max of grad d_p:  tensor(958.4302, device='cuda:0')
min of grad d_p:  tensor(-1031.6875, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1923, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.0862, device='cuda:0') norm:  tensor(8.6831, device='cuda:0') MSE:  tensor(3.2594e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.7343, device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.6061, device='cuda:0') MSE:  tensor(9.7826e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0270, device='cuda:0')
min of d_p_list:  tensor(-0.0201, device='cuda:0')
Epoch:  739  
Training Loss: 1688.8182373046875
Test Loss:  1784.408447265625
Test Acc:  0.0
Valid Loss:  1655.8358154296875
Valid Acc:  0.0
std:  24.40818459850071 
thres:  1.7231496337890626
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 74%|███████▍  | 739/1000 [34:37<12:08,  2.79s/it]Epoch:   740
max of grad d_p:  tensor(953.2482, device='cuda:0')
min of grad d_p:  tensor(-1026.6829, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2401, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-2.6788, device='cuda:0') norm:  tensor(8.6607, device='cuda:0') MSE:  tensor(3.2510e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1974, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.1327, device='cuda:0') MSE:  tensor(4.2519e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0089, device='cuda:0')
min of d_p_list:  tensor(-0.0055, device='cuda:0')
Epoch:  740  
Training Loss: 1671.98779296875
Test Loss:  1766.576416015625
Test Acc:  0.0
Valid Loss:  1639.331298828125
Valid Acc:  0.0
std:  24.166755239288758 
thres:  1.7059818359374999
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 74%|███████▍  | 740/1000 [34:40<11:49,  2.73s/it]Epoch:   741
max of grad d_p:  tensor(947.5257, device='cuda:0')
min of grad d_p:  tensor(-1020.8005, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2835, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.2292, device='cuda:0') norm:  tensor(9.1037, device='cuda:0') MSE:  tensor(3.4173e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2122, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.0874, device='cuda:0') MSE:  tensor(4.0819e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0087, device='cuda:0')
min of d_p_list:  tensor(-0.0046, device='cuda:0')
Epoch:  741  
Training Loss: 1655.328369140625
Test Loss:  1748.9246826171875
Test Acc:  0.0
Valid Loss:  1622.98779296875
Valid Acc:  0.0
std:  23.92562308010836 
thres:  1.688983642578125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 74%|███████▍  | 741/1000 [34:42<11:44,  2.72s/it]Epoch:   742
max of grad d_p:  tensor(941.3308, device='cuda:0')
min of grad d_p:  tensor(-1015.1180, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.9903, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.4263, device='cuda:0') norm:  tensor(8.2240, device='cuda:0') MSE:  tensor(3.0871e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4473, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.1800, device='cuda:0') MSE:  tensor(8.1833e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0188, device='cuda:0')
min of d_p_list:  tensor(-0.0193, device='cuda:0')
Epoch:  742  
Training Loss: 1638.7886962890625
Test Loss:  1731.30712890625
Test Acc:  0.0
Valid Loss:  1606.5030517578125
Valid Acc:  0.0
std:  23.675247723940977 
thres:  1.6721341064453126
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 74%|███████▍  | 742/1000 [34:45<11:40,  2.72s/it]Epoch:   743
max of grad d_p:  tensor(935.3470, device='cuda:0')
min of grad d_p:  tensor(-1012.0901, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1839, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.2689, device='cuda:0') norm:  tensor(9.0870, device='cuda:0') MSE:  tensor(3.4110e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.8493, device='cuda:0') mean:  tensor(0.0031, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(4.2481, device='cuda:0') MSE:  tensor(1.5946e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0087, device='cuda:0')
min of d_p_list:  tensor(-0.0064, device='cuda:0')
Epoch:  743  
Training Loss: 1622.460693359375
Test Loss:  1714.02490234375
Test Acc:  0.0
Valid Loss:  1590.4306640625
Valid Acc:  0.0
std:  23.46419598128077 
thres:  1.6554767578125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 74%|███████▍  | 743/1000 [34:48<11:25,  2.67s/it]Epoch:   744
max of grad d_p:  tensor(929.1453, device='cuda:0')
min of grad d_p:  tensor(-1006.7815, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1402, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.6190, device='cuda:0') norm:  tensor(7.9800, device='cuda:0') MSE:  tensor(2.9955e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3967, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.4269, device='cuda:0') MSE:  tensor(5.3561e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0079, device='cuda:0')
min of d_p_list:  tensor(-0.0055, device='cuda:0')
Epoch:  744  
Training Loss: 1606.3017578125
Test Loss:  1696.911865234375
Test Acc:  0.0
Valid Loss:  1574.57861328125
Valid Acc:  0.0
std:  23.227462013551474 
thres:  1.6389734619140626
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 74%|███████▍  | 744/1000 [34:50<11:26,  2.68s/it]Epoch:   745
max of grad d_p:  tensor(922.7707, device='cuda:0')
min of grad d_p:  tensor(-1000.8441, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2085, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.3245, device='cuda:0') norm:  tensor(8.6694, device='cuda:0') MSE:  tensor(3.2542e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.4725, device='cuda:0') mean:  tensor(0.0077, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(9.7098, device='cuda:0') MSE:  tensor(3.6448e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0130, device='cuda:0')
min of d_p_list:  tensor(-0.0080, device='cuda:0')
Epoch:  745  
Training Loss: 1590.3057861328125
Test Loss:  1680.076416015625
Test Acc:  0.0
Valid Loss:  1558.982177734375
Valid Acc:  0.0
std:  22.986002352588496 
thres:  1.6226370605468752
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 74%|███████▍  | 745/1000 [34:53<11:33,  2.72s/it]Epoch:   746
max of grad d_p:  tensor(915.7158, device='cuda:0')
min of grad d_p:  tensor(-995.0913, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2042, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.0863, device='cuda:0') norm:  tensor(8.7563, device='cuda:0') MSE:  tensor(3.2869e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.3962, device='cuda:0') mean:  tensor(0.0040, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(5.3117, device='cuda:0') MSE:  tensor(1.9939e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0074, device='cuda:0')
min of d_p_list:  tensor(-0.0032, device='cuda:0')
Epoch:  746  
Training Loss: 1574.46435546875
Test Loss:  1663.312744140625
Test Acc:  0.0
Valid Loss:  1543.4278564453125
Valid Acc:  0.0
std:  22.74146713083041 
thres:  1.6064642578125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 75%|███████▍  | 746/1000 [34:56<11:31,  2.72s/it]Epoch:   747
max of grad d_p:  tensor(909.2815, device='cuda:0')
min of grad d_p:  tensor(-989.5420, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2693, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-3.8502, device='cuda:0') norm:  tensor(9.3747, device='cuda:0') MSE:  tensor(3.5190e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2070, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.9365, device='cuda:0') MSE:  tensor(3.5155e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0082, device='cuda:0')
min of d_p_list:  tensor(-0.0064, device='cuda:0')
Epoch:  747  
Training Loss: 1558.772705078125
Test Loss:  1646.7705078125
Test Acc:  0.0
Valid Loss:  1528.057373046875
Valid Acc:  0.0
std:  22.516548340320867 
thres:  1.5904610595703126
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 75%|███████▍  | 747/1000 [34:59<11:27,  2.72s/it]Epoch:   748
max of grad d_p:  tensor(903.3802, device='cuda:0')
min of grad d_p:  tensor(-984.4608, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0469, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.4844, device='cuda:0') norm:  tensor(7.6635, device='cuda:0') MSE:  tensor(2.8767e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2939, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.0547, device='cuda:0') MSE:  tensor(3.9591e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0072, device='cuda:0')
min of d_p_list:  tensor(-0.0056, device='cuda:0')
Epoch:  748  
Training Loss: 1543.24072265625
Test Loss:  1630.28466796875
Test Acc:  0.0
Valid Loss:  1512.78955078125
Valid Acc:  0.0
std:  22.296177474234 
thres:  1.5746170654296876
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 75%|███████▍  | 748/1000 [35:01<11:25,  2.72s/it]Epoch:   749
max of grad d_p:  tensor(897.5761, device='cuda:0')
min of grad d_p:  tensor(-979.1417, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1740, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.9747, device='cuda:0') norm:  tensor(8.5125, device='cuda:0') MSE:  tensor(3.1954e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2010, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.9057, device='cuda:0') MSE:  tensor(3.3997e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0100, device='cuda:0')
min of d_p_list:  tensor(-0.0048, device='cuda:0')
Epoch:  749  
Training Loss: 1527.862548828125
Test Loss:  1614.002197265625
Test Acc:  0.0
Valid Loss:  1497.686279296875
Valid Acc:  0.0
std:  22.077684841695397 
thres:  1.5589292236328125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 75%|███████▍  | 749/1000 [35:05<12:03,  2.88s/it]Epoch:   750
max of grad d_p:  tensor(891.9767, device='cuda:0')
min of grad d_p:  tensor(-973.7075, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0557, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.5673, device='cuda:0') norm:  tensor(8.6724, device='cuda:0') MSE:  tensor(3.2554e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1694, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8734, device='cuda:0') MSE:  tensor(3.2784e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0140, device='cuda:0')
min of d_p_list:  tensor(-0.0107, device='cuda:0')
Epoch:  750  
Training Loss: 1512.649169921875
Test Loss:  1598.05712890625
Test Acc:  0.0
Valid Loss:  1482.903076171875
Valid Acc:  0.0
std:  21.855733932999915 
thres:  1.543397900390625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 75%|███████▌  | 750/1000 [35:07<11:44,  2.82s/it]Epoch:   751
max of grad d_p:  tensor(886.1763, device='cuda:0')
min of grad d_p:  tensor(-969.1755, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0796, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-2.9324, device='cuda:0') norm:  tensor(8.4011, device='cuda:0') MSE:  tensor(3.1535e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.1267, device='cuda:0') mean:  tensor(0.0147, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(19.7803, device='cuda:0') MSE:  tensor(7.4250e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0082, device='cuda:0')
min of d_p_list:  tensor(-0.0041, device='cuda:0')
Epoch:  751  
Training Loss: 1497.57958984375
Test Loss:  1582.1419677734375
Test Acc:  0.0
Valid Loss:  1468.13671875
Valid Acc:  0.0
std:  21.634717663777828 
thres:  1.528020947265625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 75%|███████▌  | 751/1000 [35:10<11:58,  2.89s/it]Epoch:   752
max of grad d_p:  tensor(880.4598, device='cuda:0')
min of grad d_p:  tensor(-964.2621, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1248, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.8849, device='cuda:0') norm:  tensor(8.2606, device='cuda:0') MSE:  tensor(3.1008e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.4047, device='cuda:0') mean:  tensor(0.0052, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(6.5432, device='cuda:0') MSE:  tensor(2.4562e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0069, device='cuda:0')
min of d_p_list:  tensor(-0.0056, device='cuda:0')
Epoch:  752  
Training Loss: 1482.653076171875
Test Loss:  1566.285888671875
Test Acc:  0.0
Valid Loss:  1453.434814453125
Valid Acc:  0.0
std:  21.41979729134859 
thres:  1.512797021484375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 75%|███████▌  | 752/1000 [35:13<11:34,  2.80s/it]Epoch:   753
max of grad d_p:  tensor(875.2555, device='cuda:0')
min of grad d_p:  tensor(-959.6712, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1478, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-3.0444, device='cuda:0') norm:  tensor(8.5848, device='cuda:0') MSE:  tensor(3.2225e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.8964, device='cuda:0') mean:  tensor(0.0035, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(4.5823, device='cuda:0') MSE:  tensor(1.7201e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0164, device='cuda:0')
min of d_p_list:  tensor(-0.0141, device='cuda:0')
Epoch:  753  
Training Loss: 1467.873779296875
Test Loss:  1550.631591796875
Test Acc:  0.0
Valid Loss:  1438.9371337890625
Valid Acc:  0.0
std:  21.20981894000809 
thres:  1.4977236328125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 75%|███████▌  | 753/1000 [35:16<11:41,  2.84s/it]Epoch:   754
max of grad d_p:  tensor(870.9918, device='cuda:0')
min of grad d_p:  tensor(-954.2418, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0564, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-2.7681, device='cuda:0') norm:  tensor(7.5523, device='cuda:0') MSE:  tensor(2.8349e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1265, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.6925, device='cuda:0') MSE:  tensor(2.5996e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0133, device='cuda:0')
min of d_p_list:  tensor(-0.0172, device='cuda:0')
Epoch:  754  
Training Loss: 1453.2696533203125
Test Loss:  1535.010986328125
Test Acc:  0.0
Valid Loss:  1424.40087890625
Valid Acc:  0.0
std:  20.996495514188425 
thres:  1.4828050537109376
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 75%|███████▌  | 754/1000 [35:19<11:35,  2.83s/it]Epoch:   755
max of grad d_p:  tensor(867.0215, device='cuda:0')
min of grad d_p:  tensor(-950.7676, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1164, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.4274, device='cuda:0') norm:  tensor(8.7290, device='cuda:0') MSE:  tensor(3.2766e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4224, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.8029, device='cuda:0') MSE:  tensor(6.7678e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1624, device='cuda:0')
min of d_p_list:  tensor(-0.1218, device='cuda:0')
Epoch:  755  
Training Loss: 1436.9114990234375
Test Loss:  1519.6571044921875
Test Acc:  0.0
Valid Loss:  1409.751220703125
Valid Acc:  0.0
std:  21.319344503081133 
thres:  1.46765751953125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 76%|███████▌  | 755/1000 [35:21<11:18,  2.77s/it]Epoch:   756
max of grad d_p:  tensor(868.7195, device='cuda:0')
min of grad d_p:  tensor(-977.2830, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1799, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.9752, device='cuda:0') norm:  tensor(8.7769, device='cuda:0') MSE:  tensor(3.2946e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1869, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.0862, device='cuda:0') MSE:  tensor(4.0773e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0117, device='cuda:0')
min of d_p_list:  tensor(-0.0076, device='cuda:0')
Epoch:  756  
Training Loss: 1422.6201171875
Test Loss:  1504.5513916015625
Test Acc:  0.0
Valid Loss:  1395.74853515625
Valid Acc:  0.0
std:  21.3627014214555 
thres:  1.452665625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 76%|███████▌  | 756/1000 [35:24<11:04,  2.73s/it]Epoch:   757
max of grad d_p:  tensor(862.5865, device='cuda:0')
min of grad d_p:  tensor(-972.0347, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1597, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.3158, device='cuda:0') norm:  tensor(8.3479, device='cuda:0') MSE:  tensor(3.1336e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.7059, device='cuda:0') mean:  tensor(0.0035, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(4.3000, device='cuda:0') MSE:  tensor(1.6141e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0109, device='cuda:0')
min of d_p_list:  tensor(-0.0057, device='cuda:0')
Epoch:  757  
Training Loss: 1408.4462890625
Test Loss:  1489.5146484375
Test Acc:  0.0
Valid Loss:  1381.777099609375
Valid Acc:  0.0
std:  21.149931690007676 
thres:  1.437824267578125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 76%|███████▌  | 757/1000 [35:27<11:09,  2.75s/it]Epoch:   758
max of grad d_p:  tensor(856.7877, device='cuda:0')
min of grad d_p:  tensor(-966.6563, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0035, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.2573, device='cuda:0') norm:  tensor(7.6322, device='cuda:0') MSE:  tensor(2.8649e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1653, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.6377, device='cuda:0') MSE:  tensor(2.3936e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0100, device='cuda:0')
min of d_p_list:  tensor(-0.0053, device='cuda:0')
Epoch:  758  
Training Loss: 1394.412109375
Test Loss:  1474.56591796875
Test Acc:  0.0
Valid Loss:  1367.850341796875
Valid Acc:  0.0
std:  20.682925268132223 
thres:  1.4231319335937502
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 76%|███████▌  | 758/1000 [35:30<11:35,  2.87s/it]Epoch:   759
max of grad d_p:  tensor(851.5765, device='cuda:0')
min of grad d_p:  tensor(-961.6331, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2303, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.4094, device='cuda:0') norm:  tensor(9.0663, device='cuda:0') MSE:  tensor(3.4033e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.6127, device='cuda:0') mean:  tensor(0.0065, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(8.3991, device='cuda:0') MSE:  tensor(3.1528e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0243, device='cuda:0')
min of d_p_list:  tensor(-0.0349, device='cuda:0')
Epoch:  759  
Training Loss: 1380.577392578125
Test Loss:  1460.0206298828125
Test Acc:  0.0
Valid Loss:  1354.256591796875
Valid Acc:  0.0
std:  19.923307178314314 
thres:  1.4085934814453127
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 76%|███████▌  | 759/1000 [35:33<11:29,  2.86s/it]Epoch:   760
max of grad d_p:  tensor(845.7361, device='cuda:0')
min of grad d_p:  tensor(-958.6823, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1753, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-4.3235, device='cuda:0') norm:  tensor(9.2899, device='cuda:0') MSE:  tensor(3.4872e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2309, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.6741, device='cuda:0') MSE:  tensor(2.5304e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0105, device='cuda:0')
min of d_p_list:  tensor(-0.0132, device='cuda:0')
Epoch:  760  
Training Loss: 1366.8265380859375
Test Loss:  1445.4600830078125
Test Acc:  0.0
Valid Loss:  1340.751953125
Valid Acc:  0.0
std:  19.722464007904367 
thres:  1.3945764892578125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 76%|███████▌  | 760/1000 [35:35<11:08,  2.79s/it]Epoch:   761
max of grad d_p:  tensor(839.0591, device='cuda:0')
min of grad d_p:  tensor(-952.6271, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3149, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.9055, device='cuda:0') norm:  tensor(9.2037, device='cuda:0') MSE:  tensor(3.4548e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1386, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.6371, device='cuda:0') MSE:  tensor(2.3915e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0111, device='cuda:0')
min of d_p_list:  tensor(-0.0116, device='cuda:0')
Epoch:  761  
Training Loss: 1353.220947265625
Test Loss:  1431.0692138671875
Test Acc:  0.0
Valid Loss:  1327.429931640625
Valid Acc:  0.0
std:  19.521602196311626 
thres:  1.3806966552734374
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 76%|███████▌  | 761/1000 [35:38<11:16,  2.83s/it]Epoch:   762
max of grad d_p:  tensor(833.3875, device='cuda:0')
min of grad d_p:  tensor(-946.2607, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2175, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.5477, device='cuda:0') norm:  tensor(8.7901, device='cuda:0') MSE:  tensor(3.2996e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4111, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.3502, device='cuda:0') MSE:  tensor(5.0685e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0077, device='cuda:0')
min of d_p_list:  tensor(-0.0062, device='cuda:0')
Epoch:  762  
Training Loss: 1339.742919921875
Test Loss:  1416.72802734375
Test Acc:  0.0
Valid Loss:  1314.135986328125
Valid Acc:  0.0
std:  19.331841294193055 
thres:  1.3669559814453125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 76%|███████▌  | 762/1000 [35:41<11:31,  2.90s/it]Epoch:   763
max of grad d_p:  tensor(827.6040, device='cuda:0')
min of grad d_p:  tensor(-941.2200, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1087, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.8331, device='cuda:0') norm:  tensor(8.2561, device='cuda:0') MSE:  tensor(3.0991e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.6049, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.1790, device='cuda:0') MSE:  tensor(8.1793e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0521, device='cuda:0')
min of d_p_list:  tensor(-0.0574, device='cuda:0')
Epoch:  763  
Training Loss: 1326.244140625
Test Loss:  1402.5361328125
Test Acc:  0.0
Valid Loss:  1300.6500244140625
Valid Acc:  0.0
std:  19.19813047411774 
thres:  1.3533223876953124
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 76%|███████▋  | 763/1000 [35:44<11:24,  2.89s/it]Epoch:   764
max of grad d_p:  tensor(827.2357, device='cuda:0')
min of grad d_p:  tensor(-938.6767, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1843, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.4688, device='cuda:0') norm:  tensor(8.4524, device='cuda:0') MSE:  tensor(3.1728e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1812, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8528, device='cuda:0') MSE:  tensor(3.2012e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0100, device='cuda:0')
min of d_p_list:  tensor(-0.0070, device='cuda:0')
Epoch:  764  
Training Loss: 1313.0325927734375
Test Loss:  1388.4774169921875
Test Acc:  0.0
Valid Loss:  1287.6002197265625
Valid Acc:  0.0
std:  19.030572014838597 
thres:  1.339813427734375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 76%|███████▋  | 764/1000 [35:47<11:22,  2.89s/it]Epoch:   765
max of grad d_p:  tensor(821.3176, device='cuda:0')
min of grad d_p:  tensor(-933.6359, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1522, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.2096, device='cuda:0') norm:  tensor(8.6176, device='cuda:0') MSE:  tensor(3.2348e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2265, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.0333, device='cuda:0') MSE:  tensor(3.8786e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0089, device='cuda:0')
min of d_p_list:  tensor(-0.0089, device='cuda:0')
Epoch:  765  
Training Loss: 1299.9422607421875
Test Loss:  1374.670654296875
Test Acc:  0.0
Valid Loss:  1274.8519287109375
Valid Acc:  0.0
std:  18.847354569561556 
thres:  1.326436572265625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 76%|███████▋  | 765/1000 [35:50<11:02,  2.82s/it]Epoch:   766
max of grad d_p:  tensor(816.7151, device='cuda:0')
min of grad d_p:  tensor(-927.8248, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1173, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-2.6605, device='cuda:0') norm:  tensor(8.0601, device='cuda:0') MSE:  tensor(3.0256e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.6386, device='cuda:0') mean:  tensor(0.0033, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(4.1089, device='cuda:0') MSE:  tensor(1.5424e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0074, device='cuda:0')
min of d_p_list:  tensor(-0.0036, device='cuda:0')
Epoch:  766  
Training Loss: 1286.9912109375
Test Loss:  1360.9256591796875
Test Acc:  0.0
Valid Loss:  1262.1021728515625
Valid Acc:  0.0
std:  18.64066556054792 
thres:  1.313190625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 77%|███████▋  | 766/1000 [35:53<11:08,  2.86s/it]Epoch:   767
max of grad d_p:  tensor(811.3490, device='cuda:0')
min of grad d_p:  tensor(-922.7651, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1295, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.9033, device='cuda:0') norm:  tensor(9.1066, device='cuda:0') MSE:  tensor(3.4184e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1702, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.9722, device='cuda:0') MSE:  tensor(3.6494e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0067, device='cuda:0')
min of d_p_list:  tensor(-0.0031, device='cuda:0')
Epoch:  767  
Training Loss: 1274.17431640625
Test Loss:  1347.337646484375
Test Acc:  0.0
Valid Loss:  1249.485595703125
Valid Acc:  0.0
std:  18.41071253356394 
thres:  1.300076904296875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 77%|███████▋  | 767/1000 [35:55<10:53,  2.80s/it]Epoch:   768
max of grad d_p:  tensor(806.2825, device='cuda:0')
min of grad d_p:  tensor(-917.5063, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1588, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-4.0665, device='cuda:0') norm:  tensor(8.7005, device='cuda:0') MSE:  tensor(3.2659e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2580, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8179, device='cuda:0') MSE:  tensor(3.0703e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0163, device='cuda:0')
min of d_p_list:  tensor(-0.0221, device='cuda:0')
Epoch:  768  
Training Loss: 1261.434326171875
Test Loss:  1333.8980712890625
Test Acc:  0.0
Valid Loss:  1237.049072265625
Valid Acc:  0.0
std:  18.238606619874925 
thres:  1.28711494140625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 77%|███████▋  | 768/1000 [35:58<10:38,  2.75s/it]Epoch:   769
max of grad d_p:  tensor(799.9799, device='cuda:0')
min of grad d_p:  tensor(-914.1618, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0995, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.6438, device='cuda:0') norm:  tensor(8.2379, device='cuda:0') MSE:  tensor(3.0923e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3435, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.8038, device='cuda:0') MSE:  tensor(6.7709e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0121, device='cuda:0')
min of d_p_list:  tensor(-0.0061, device='cuda:0')
Epoch:  769  
Training Loss: 1248.86962890625
Test Loss:  1320.661865234375
Test Acc:  0.0
Valid Loss:  1224.75830078125
Valid Acc:  0.0
std:  18.060099371597634 
thres:  1.2742823486328125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 77%|███████▋  | 769/1000 [36:01<10:53,  2.83s/it]Epoch:   770
max of grad d_p:  tensor(794.1615, device='cuda:0')
min of grad d_p:  tensor(-908.0373, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1937, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.5176, device='cuda:0') norm:  tensor(8.7107, device='cuda:0') MSE:  tensor(3.2698e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3100, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.7182, device='cuda:0') MSE:  tensor(6.4497e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0131, device='cuda:0')
min of d_p_list:  tensor(-0.0190, device='cuda:0')
Epoch:  770  
Training Loss: 1236.395263671875
Test Loss:  1307.4949951171875
Test Acc:  0.0
Valid Loss:  1212.5576171875
Valid Acc:  0.0
std:  17.889616522471865 
thres:  1.26157294921875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 77%|███████▋  | 770/1000 [36:04<10:57,  2.86s/it]Epoch:   771
max of grad d_p:  tensor(791.3629, device='cuda:0')
min of grad d_p:  tensor(-904.1338, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2481, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.5628, device='cuda:0') norm:  tensor(9.1102, device='cuda:0') MSE:  tensor(3.4197e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.9895, device='cuda:0') mean:  tensor(0.0041, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(5.5531, device='cuda:0') MSE:  tensor(2.0845e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0060, device='cuda:0')
min of d_p_list:  tensor(-0.0033, device='cuda:0')
Epoch:  771  
Training Loss: 1224.0780029296875
Test Loss:  1294.36474609375
Test Acc:  0.0
Valid Loss:  1200.386962890625
Valid Acc:  0.0
std:  17.710790590233092 
thres:  1.2489903076171875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 77%|███████▋  | 771/1000 [36:07<10:59,  2.88s/it]Epoch:   772
max of grad d_p:  tensor(786.2424, device='cuda:0')
min of grad d_p:  tensor(-898.7424, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2050, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-4.4838, device='cuda:0') norm:  tensor(9.5400, device='cuda:0') MSE:  tensor(3.5811e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1910, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8449, device='cuda:0') MSE:  tensor(3.1717e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0107, device='cuda:0')
min of d_p_list:  tensor(-0.0061, device='cuda:0')
Epoch:  772  
Training Loss: 1211.88232421875
Test Loss:  1281.5126953125
Test Acc:  0.0
Valid Loss:  1188.496337890625
Valid Acc:  0.0
std:  17.521816068713132 
thres:  1.2365319091796876
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 77%|███████▋  | 772/1000 [36:10<11:24,  3.00s/it]Epoch:   773
max of grad d_p:  tensor(781.1959, device='cuda:0')
min of grad d_p:  tensor(-893.1370, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0802, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-3.0338, device='cuda:0') norm:  tensor(8.1680, device='cuda:0') MSE:  tensor(3.0660e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2417, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.9088, device='cuda:0') MSE:  tensor(3.4114e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0071, device='cuda:0')
min of d_p_list:  tensor(-0.0052, device='cuda:0')
Epoch:  773  
Training Loss: 1199.812744140625
Test Loss:  1268.659423828125
Test Acc:  0.0
Valid Loss:  1176.5628662109375
Valid Acc:  0.0
std:  17.34239329755484 
thres:  1.2242075927734375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 77%|███████▋  | 773/1000 [36:13<11:24,  3.02s/it]Epoch:   774
max of grad d_p:  tensor(776.5728, device='cuda:0')
min of grad d_p:  tensor(-888.5277, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2951, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.1436, device='cuda:0') norm:  tensor(8.1783, device='cuda:0') MSE:  tensor(3.0699e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1787, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8204, device='cuda:0') MSE:  tensor(3.0797e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0103, device='cuda:0')
min of d_p_list:  tensor(-0.0074, device='cuda:0')
Epoch:  774  
Training Loss: 1187.8538818359375
Test Loss:  1256.011474609375
Test Acc:  0.0
Valid Loss:  1164.832763671875
Valid Acc:  0.0
std:  17.16149772622928 
thres:  1.212004443359375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 77%|███████▋  | 774/1000 [36:16<11:31,  3.06s/it]Epoch:   775
max of grad d_p:  tensor(771.7545, device='cuda:0')
min of grad d_p:  tensor(-883.3005, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1127, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.5931, device='cuda:0') norm:  tensor(8.3154, device='cuda:0') MSE:  tensor(3.1214e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1982, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7853, device='cuda:0') MSE:  tensor(2.9477e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0333, device='cuda:0')
min of d_p_list:  tensor(-0.0464, device='cuda:0')
Epoch:  775  
Training Loss: 1176.1431884765625
Test Loss:  1243.3902587890625
Test Acc:  0.0
Valid Loss:  1153.00830078125
Valid Acc:  0.0
std:  16.956650578589663 
thres:  1.1999540283203125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 78%|███████▊  | 775/1000 [36:19<11:21,  3.03s/it]Epoch:   776
max of grad d_p:  tensor(764.8463, device='cuda:0')
min of grad d_p:  tensor(-878.4230, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1714, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-4.3922, device='cuda:0') norm:  tensor(9.3616, device='cuda:0') MSE:  tensor(3.5141e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.6651, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(3.0242, device='cuda:0') MSE:  tensor(1.1352e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0141, device='cuda:0')
min of d_p_list:  tensor(-0.0049, device='cuda:0')
Epoch:  776  
Training Loss: 1164.4228515625
Test Loss:  1230.97802734375
Test Acc:  0.0
Valid Loss:  1141.545166015625
Valid Acc:  0.0
std:  16.7713502624843 
thres:  1.188022998046875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 78%|███████▊  | 776/1000 [36:22<10:51,  2.91s/it]Epoch:   777
max of grad d_p:  tensor(759.9338, device='cuda:0')
min of grad d_p:  tensor(-872.4315, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2391, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.0054, device='cuda:0') norm:  tensor(8.3161, device='cuda:0') MSE:  tensor(3.1216e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0829, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.4738, device='cuda:0') MSE:  tensor(1.7784e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0128, device='cuda:0')
min of d_p_list:  tensor(-0.0076, device='cuda:0')
Epoch:  777  
Training Loss: 1152.8153076171875
Test Loss:  1218.7578125
Test Acc:  0.0
Valid Loss:  1130.234130859375
Valid Acc:  0.0
std:  16.606760539669366 
thres:  1.1762095947265625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 78%|███████▊  | 777/1000 [36:25<11:00,  2.96s/it]Epoch:   778
max of grad d_p:  tensor(755.3300, device='cuda:0')
min of grad d_p:  tensor(-866.8365, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1326, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.1103, device='cuda:0') norm:  tensor(7.6120, device='cuda:0') MSE:  tensor(2.8573e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2892, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.1963, device='cuda:0') MSE:  tensor(4.4904e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0067, device='cuda:0')
min of d_p_list:  tensor(-0.0029, device='cuda:0')
Epoch:  778  
Training Loss: 1141.32958984375
Test Loss:  1206.578125
Test Acc:  0.0
Valid Loss:  1118.9542236328125
Valid Acc:  0.0
std:  16.458266550093573 
thres:  1.1645129638671874
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 78%|███████▊  | 778/1000 [36:28<10:51,  2.93s/it]Epoch:   779
max of grad d_p:  tensor(750.4283, device='cuda:0')
min of grad d_p:  tensor(-862.0483, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1168, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.4528, device='cuda:0') norm:  tensor(8.3587, device='cuda:0') MSE:  tensor(3.1377e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.4619, device='cuda:0') mean:  tensor(0.0042, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(5.6737, device='cuda:0') MSE:  tensor(2.1298e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0287, device='cuda:0')
min of d_p_list:  tensor(-0.0486, device='cuda:0')
Epoch:  779  
Training Loss: 1130.1533203125
Test Loss:  1194.949462890625
Test Acc:  0.0
Valid Loss:  1108.17041015625
Valid Acc:  0.0
std:  16.274448578842282 
thres:  1.1529728515625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 78%|███████▊  | 779/1000 [36:31<11:00,  2.99s/it]Epoch:   780
max of grad d_p:  tensor(744.8398, device='cuda:0')
min of grad d_p:  tensor(-856.2787, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0743, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.2935, device='cuda:0') norm:  tensor(8.0073, device='cuda:0') MSE:  tensor(3.0057e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2132, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7719, device='cuda:0') MSE:  tensor(2.8975e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0071, device='cuda:0')
min of d_p_list:  tensor(-0.0052, device='cuda:0')
Epoch:  780  
Training Loss: 1118.89013671875
Test Loss:  1183.0245361328125
Test Acc:  0.0
Valid Loss:  1097.12255859375
Valid Acc:  0.0
std:  16.083985414191133 
thres:  1.1415222412109374
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 78%|███████▊  | 780/1000 [36:34<10:30,  2.86s/it]Epoch:   781
max of grad d_p:  tensor(740.2433, device='cuda:0')
min of grad d_p:  tensor(-851.5386, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1721, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-2.9195, device='cuda:0') norm:  tensor(8.2172, device='cuda:0') MSE:  tensor(3.0845e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4172, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.7138, device='cuda:0') MSE:  tensor(6.4333e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0082, device='cuda:0')
min of d_p_list:  tensor(-0.0044, device='cuda:0')
Epoch:  781  
Training Loss: 1107.741455078125
Test Loss:  1171.20751953125
Test Acc:  0.0
Valid Loss:  1086.1739501953125
Valid Acc:  0.0
std:  15.922439196382618 
thres:  1.1301859619140626
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 78%|███████▊  | 781/1000 [36:36<10:15,  2.81s/it]Epoch:   782
max of grad d_p:  tensor(735.3282, device='cuda:0')
min of grad d_p:  tensor(-846.8052, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1173, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-4.2224, device='cuda:0') norm:  tensor(8.7944, device='cuda:0') MSE:  tensor(3.3012e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2246, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.0225, device='cuda:0') MSE:  tensor(3.8383e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1264, device='cuda:0')
min of d_p_list:  tensor(-0.1166, device='cuda:0')
Epoch:  782  
Training Loss: 1097.244140625
Test Loss:  1159.217041015625
Test Acc:  0.0
Valid Loss:  1074.6195068359375
Valid Acc:  0.0
std:  15.640113378916276 
thres:  1.119071728515625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 78%|███████▊  | 782/1000 [36:39<10:34,  2.91s/it]Epoch:   783
max of grad d_p:  tensor(726.2867, device='cuda:0')
min of grad d_p:  tensor(-853.5206, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2630, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.7594, device='cuda:0') norm:  tensor(9.0957, device='cuda:0') MSE:  tensor(3.4143e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2592, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.7085, device='cuda:0') MSE:  tensor(6.4133e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0076, device='cuda:0')
min of d_p_list:  tensor(-0.0045, device='cuda:0')
Epoch:  783  
Training Loss: 1086.306396484375
Test Loss:  1147.696044921875
Test Acc:  0.0
Valid Loss:  1063.9300537109375
Valid Acc:  0.0
std:  15.464216522347067 
thres:  1.10806708984375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 78%|███████▊  | 783/1000 [36:42<10:19,  2.85s/it]Epoch:   784
max of grad d_p:  tensor(721.6549, device='cuda:0')
min of grad d_p:  tensor(-849.0042, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1329, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.1315, device='cuda:0') norm:  tensor(7.6093, device='cuda:0') MSE:  tensor(2.8563e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2176, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.1295, device='cuda:0') MSE:  tensor(4.2399e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0082, device='cuda:0')
min of d_p_list:  tensor(-0.0080, device='cuda:0')
Epoch:  784  
Training Loss: 1075.478271484375
Test Loss:  1136.4071044921875
Test Acc:  0.0
Valid Loss:  1053.4559326171875
Valid Acc:  0.0
std:  15.310566783239514 
thres:  1.097132080078125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 78%|███████▊  | 784/1000 [36:45<10:03,  2.79s/it]Epoch:   785
max of grad d_p:  tensor(717.0734, device='cuda:0')
min of grad d_p:  tensor(-844.8478, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2656, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.6898, device='cuda:0') norm:  tensor(8.4452, device='cuda:0') MSE:  tensor(3.1701e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1152, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.4991, device='cuda:0') MSE:  tensor(1.8736e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0067, device='cuda:0')
min of d_p_list:  tensor(-0.0051, device='cuda:0')
Epoch:  785  
Training Loss: 1064.760498046875
Test Loss:  1125.045166015625
Test Acc:  0.0
Valid Loss:  1042.93359375
Valid Acc:  0.0
std:  15.235288077354749 
thres:  1.08630615234375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 78%|███████▊  | 785/1000 [36:48<10:13,  2.85s/it]Epoch:   786
max of grad d_p:  tensor(712.3052, device='cuda:0')
min of grad d_p:  tensor(-840.1467, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0829, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.8938, device='cuda:0') norm:  tensor(7.8069, device='cuda:0') MSE:  tensor(2.9305e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2480, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.0429, device='cuda:0') MSE:  tensor(3.9149e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0121, device='cuda:0')
min of d_p_list:  tensor(-0.0112, device='cuda:0')
Epoch:  786  
Training Loss: 1054.16162109375
Test Loss:  1113.72509765625
Test Acc:  0.0
Valid Loss:  1032.4970703125
Valid Acc:  0.0
std:  15.23291815778726 
thres:  1.075590185546875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 79%|███████▊  | 786/1000 [36:51<10:26,  2.93s/it]Epoch:   787
max of grad d_p:  tensor(707.0588, device='cuda:0')
min of grad d_p:  tensor(-833.9458, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1577, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.9377, device='cuda:0') norm:  tensor(7.6632, device='cuda:0') MSE:  tensor(2.8765e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0766, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.4086, device='cuda:0') MSE:  tensor(1.5337e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0137, device='cuda:0')
min of d_p_list:  tensor(-0.0155, device='cuda:0')
Epoch:  787  
Training Loss: 1043.66064453125
Test Loss:  1103.015625
Test Acc:  0.0
Valid Loss:  1022.552978515625
Valid Acc:  0.0
std:  15.076953181770271 
thres:  1.064873486328125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 79%|███████▊  | 787/1000 [36:54<10:24,  2.93s/it]Epoch:   788
max of grad d_p:  tensor(702.6104, device='cuda:0')
min of grad d_p:  tensor(-829.8367, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3131, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.6689, device='cuda:0') norm:  tensor(8.5429, device='cuda:0') MSE:  tensor(3.2068e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2272, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8119, device='cuda:0') MSE:  tensor(3.0478e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0102, device='cuda:0')
min of d_p_list:  tensor(-0.0083, device='cuda:0')
Epoch:  788  
Training Loss: 1033.24755859375
Test Loss:  1092.018310546875
Test Acc:  0.0
Valid Loss:  1012.3209228515625
Valid Acc:  0.0
std:  14.92885928569068 
thres:  1.05426171875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 79%|███████▉  | 788/1000 [36:57<10:27,  2.96s/it]Epoch:   789
max of grad d_p:  tensor(698.6161, device='cuda:0')
min of grad d_p:  tensor(-826.6589, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0760, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.2532, device='cuda:0') norm:  tensor(7.9902, device='cuda:0') MSE:  tensor(2.9993e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2726, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8252, device='cuda:0') MSE:  tensor(3.0977e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0353, device='cuda:0')
min of d_p_list:  tensor(-0.0306, device='cuda:0')
Epoch:  789  
Training Loss: 1023.093017578125
Test Loss:  1081.02685546875
Test Acc:  0.0
Valid Loss:  1001.7999877929688
Valid Acc:  0.0
std:  14.743520985886883 
thres:  1.04378466796875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 79%|███████▉  | 789/1000 [37:00<10:38,  3.03s/it]Epoch:   790
max of grad d_p:  tensor(693.0978, device='cuda:0')
min of grad d_p:  tensor(-825.2319, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0592, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.1552, device='cuda:0') norm:  tensor(7.6225, device='cuda:0') MSE:  tensor(2.8613e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1792, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8458, device='cuda:0') MSE:  tensor(3.1748e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0106, device='cuda:0')
min of d_p_list:  tensor(-0.0093, device='cuda:0')
Epoch:  790  
Training Loss: 1012.8984985351562
Test Loss:  1070.1568603515625
Test Acc:  0.0
Valid Loss:  991.6922607421875
Valid Acc:  0.0
std:  14.580080050877765 
thres:  1.0334122680664064
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 79%|███████▉  | 790/1000 [37:03<10:37,  3.04s/it]Epoch:   791
max of grad d_p:  tensor(688.7792, device='cuda:0')
min of grad d_p:  tensor(-820.8222, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1686, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.7661, device='cuda:0') norm:  tensor(8.5555, device='cuda:0') MSE:  tensor(3.2115e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.7646, device='cuda:0') mean:  tensor(0.0023, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(3.2153, device='cuda:0') MSE:  tensor(1.2069e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0080, device='cuda:0')
min of d_p_list:  tensor(-0.0055, device='cuda:0')
Epoch:  791  
Training Loss: 1002.8042602539062
Test Loss:  1059.463134765625
Test Acc:  0.0
Valid Loss:  981.792236328125
Valid Acc:  0.0
std:  14.433935431197947 
thres:  1.0231407958984375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 79%|███████▉  | 791/1000 [37:06<10:31,  3.02s/it]Epoch:   792
max of grad d_p:  tensor(684.6156, device='cuda:0')
min of grad d_p:  tensor(-816.3952, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1865, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-4.1185, device='cuda:0') norm:  tensor(8.5899, device='cuda:0') MSE:  tensor(3.2244e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2510, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.2699, device='cuda:0') MSE:  tensor(4.7670e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0149, device='cuda:0')
min of d_p_list:  tensor(-0.0092, device='cuda:0')
Epoch:  792  
Training Loss: 992.828369140625
Test Loss:  1049.096923828125
Test Acc:  0.0
Valid Loss:  972.246826171875
Valid Acc:  0.0
std:  14.301660350578178 
thres:  1.0129743408203125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 79%|███████▉  | 792/1000 [37:09<10:23,  3.00s/it]Epoch:   793
max of grad d_p:  tensor(679.6722, device='cuda:0')
min of grad d_p:  tensor(-810.6295, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2205, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.8359, device='cuda:0') norm:  tensor(8.7379, device='cuda:0') MSE:  tensor(3.2800e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2406, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.2048, device='cuda:0') MSE:  tensor(4.5225e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0099, device='cuda:0')
min of d_p_list:  tensor(-0.0136, device='cuda:0')
Epoch:  793  
Training Loss: 982.9284057617188
Test Loss:  1038.657470703125
Test Acc:  0.0
Valid Loss:  962.5947265625
Valid Acc:  0.0
std:  14.198865237939593 
thres:  1.0029105102539062
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 79%|███████▉  | 793/1000 [37:12<10:00,  2.90s/it]Epoch:   794
max of grad d_p:  tensor(675.5891, device='cuda:0')
min of grad d_p:  tensor(-805.6032, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1026, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.7963, device='cuda:0') norm:  tensor(7.7205, device='cuda:0') MSE:  tensor(2.8981e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.5035, device='cuda:0') mean:  tensor(0.0063, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(8.1308, device='cuda:0') MSE:  tensor(3.0521e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0068, device='cuda:0')
min of d_p_list:  tensor(-0.0041, device='cuda:0')
Epoch:  794  
Training Loss: 973.1355590820312
Test Loss:  1028.30322265625
Test Acc:  0.0
Valid Loss:  952.9833984375
Valid Acc:  0.0
std:  14.057762650887643 
thres:  0.9929190185546874
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 79%|███████▉  | 794/1000 [37:15<10:05,  2.94s/it]Epoch:   795
max of grad d_p:  tensor(671.1639, device='cuda:0')
min of grad d_p:  tensor(-801.2904, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1484, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.0805, device='cuda:0') norm:  tensor(7.8574, device='cuda:0') MSE:  tensor(2.9495e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1677, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.9223, device='cuda:0') MSE:  tensor(3.4620e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1744, device='cuda:0')
min of d_p_list:  tensor(-0.2633, device='cuda:0')
Epoch:  795  
Training Loss: 967.8802490234375
Test Loss:  1023.3814697265625
Test Acc:  0.0
Valid Loss:  947.8112182617188
Valid Acc:  0.0
std:  12.73212672944066 
thres:  0.9839153686523437
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 80%|███████▉  | 795/1000 [37:18<10:13,  2.99s/it]Epoch:   796
max of grad d_p:  tensor(678.1231, device='cuda:0')
min of grad d_p:  tensor(-803.1158, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2223, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.0065, device='cuda:0') norm:  tensor(7.5302, device='cuda:0') MSE:  tensor(2.8266e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2583, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.0578, device='cuda:0') MSE:  tensor(3.9706e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0083, device='cuda:0')
min of d_p_list:  tensor(-0.0043, device='cuda:0')
Epoch:  796  
Training Loss: 958.2374267578125
Test Loss:  1013.1893310546875
Test Acc:  0.0
Valid Loss:  938.3442993164062
Valid Acc:  0.0
std:  11.965460289536065 
thres:  0.975002001953125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 80%|███████▉  | 796/1000 [37:21<10:22,  3.05s/it]Epoch:   797
max of grad d_p:  tensor(673.3956, device='cuda:0')
min of grad d_p:  tensor(-798.5699, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3066, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.2069, device='cuda:0') norm:  tensor(8.0690, device='cuda:0') MSE:  tensor(3.0289e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2276, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.1149, device='cuda:0') MSE:  tensor(4.1852e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0082, device='cuda:0')
min of d_p_list:  tensor(-0.0063, device='cuda:0')
Epoch:  797  
Training Loss: 948.6994018554688
Test Loss:  1003.1112060546875
Test Acc:  0.0
Valid Loss:  928.9849243164062
Valid Acc:  0.0
std:  11.835839250049776 
thres:  0.9661762084960938
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 80%|███████▉  | 797/1000 [37:24<10:12,  3.02s/it]Epoch:   798
max of grad d_p:  tensor(668.9218, device='cuda:0')
min of grad d_p:  tensor(-794.7537, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.4422, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-3.5207, device='cuda:0') norm:  tensor(8.6508, device='cuda:0') MSE:  tensor(3.2473e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.8753, device='cuda:0') mean:  tensor(0.0065, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(8.4738, device='cuda:0') MSE:  tensor(3.1808e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0059, device='cuda:0')
min of d_p_list:  tensor(-0.0106, device='cuda:0')
Epoch:  798  
Training Loss: 939.2424926757812
Test Loss:  993.1724243164062
Test Acc:  0.0
Valid Loss:  919.786376953125
Valid Acc:  0.0
std:  12.357447859470136 
thres:  0.9574390258789063
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 80%|███████▉  | 798/1000 [37:27<10:05,  3.00s/it]Epoch:   799
max of grad d_p:  tensor(664.5200, device='cuda:0')
min of grad d_p:  tensor(-790.1542, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1272, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.4741, device='cuda:0') norm:  tensor(7.2161, device='cuda:0') MSE:  tensor(2.7087e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1288, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.6191, device='cuda:0') MSE:  tensor(2.3239e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0079, device='cuda:0')
min of d_p_list:  tensor(-0.0052, device='cuda:0')
Epoch:  799  
Training Loss: 929.8831787109375
Test Loss:  983.2467041015625
Test Acc:  0.0
Valid Loss:  910.59326171875
Valid Acc:  0.0
std:  13.433707343783443 
thres:  0.9487885498046875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 80%|███████▉  | 799/1000 [37:30<10:01,  2.99s/it]Epoch:   800
max of grad d_p:  tensor(660.1902, device='cuda:0')
min of grad d_p:  tensor(-785.7336, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3394, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.0782, device='cuda:0') norm:  tensor(8.3858, device='cuda:0') MSE:  tensor(3.1478e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.7335, device='cuda:0') mean:  tensor(0.0026, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(3.6003, device='cuda:0') MSE:  tensor(1.3515e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0081, device='cuda:0')
min of d_p_list:  tensor(-0.0075, device='cuda:0')
Epoch:  800  
Training Loss: 920.61962890625
Test Loss:  973.3759765625
Test Acc:  0.0
Valid Loss:  901.4581298828125
Valid Acc:  0.0
std:  13.301160458720089 
thres:  0.93933642578125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 80%|████████  | 800/1000 [37:33<09:52,  2.96s/it]Epoch:   801
max of grad d_p:  tensor(655.6888, device='cuda:0')
min of grad d_p:  tensor(-781.3632, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2579, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.3099, device='cuda:0') norm:  tensor(8.1475, device='cuda:0') MSE:  tensor(3.0583e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.2059, device='cuda:0') mean:  tensor(0.0044, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(5.7693, device='cuda:0') MSE:  tensor(2.1656e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0072, device='cuda:0')
min of d_p_list:  tensor(-0.0050, device='cuda:0')
Epoch:  801  
Training Loss: 911.45068359375
Test Loss:  963.662841796875
Test Acc:  0.0
Valid Loss:  892.4620971679688
Valid Acc:  0.0
std:  13.169443875842328 
thres:  0.9299790771484375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 80%|████████  | 801/1000 [37:36<09:38,  2.91s/it]Epoch:   802
max of grad d_p:  tensor(651.2649, device='cuda:0')
min of grad d_p:  tensor(-776.9157, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1473, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.7720, device='cuda:0') norm:  tensor(8.3017, device='cuda:0') MSE:  tensor(3.1163e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.6920, device='cuda:0') mean:  tensor(0.0081, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(11.2602, device='cuda:0') MSE:  tensor(4.2268e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0061, device='cuda:0')
min of d_p_list:  tensor(-0.0060, device='cuda:0')
Epoch:  802  
Training Loss: 902.3711547851562
Test Loss:  954.0616455078125
Test Acc:  0.0
Valid Loss:  883.5894775390625
Valid Acc:  0.0
std:  13.035772203851227 
thres:  0.920713427734375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 80%|████████  | 802/1000 [37:39<09:35,  2.90s/it]Epoch:   803
max of grad d_p:  tensor(647.2518, device='cuda:0')
min of grad d_p:  tensor(-772.4444, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0502, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.1841, device='cuda:0') norm:  tensor(7.1950, device='cuda:0') MSE:  tensor(2.7008e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.5000, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.1256, device='cuda:0') MSE:  tensor(7.9791e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0077, device='cuda:0')
min of d_p_list:  tensor(-0.0092, device='cuda:0')
Epoch:  803  
Training Loss: 893.3773193359375
Test Loss:  944.4595336914062
Test Acc:  0.0
Valid Loss:  874.696533203125
Valid Acc:  0.0
std:  12.906359164559102 
thres:  0.9115403930664063
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 80%|████████  | 803/1000 [37:41<09:35,  2.92s/it]Epoch:   804
max of grad d_p:  tensor(643.0154, device='cuda:0')
min of grad d_p:  tensor(-767.7871, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.5786, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.9047, device='cuda:0') norm:  tensor(8.9208, device='cuda:0') MSE:  tensor(3.3486e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2002, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8335, device='cuda:0') MSE:  tensor(3.1289e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0064, device='cuda:0')
min of d_p_list:  tensor(-0.0070, device='cuda:0')
Epoch:  804  
Training Loss: 884.4725952148438
Test Loss:  934.9722900390625
Test Acc:  0.0
Valid Loss:  865.9072875976562
Valid Acc:  0.0
std:  12.780095547871957 
thres:  0.9024582763671876
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 80%|████████  | 804/1000 [37:44<09:32,  2.92s/it]Epoch:   805
max of grad d_p:  tensor(638.9261, device='cuda:0')
min of grad d_p:  tensor(-763.3054, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2679, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.9384, device='cuda:0') norm:  tensor(8.5490, device='cuda:0') MSE:  tensor(3.2091e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3683, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.5518, device='cuda:0') MSE:  tensor(5.8251e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0070, device='cuda:0')
min of d_p_list:  tensor(-0.0043, device='cuda:0')
Epoch:  805  
Training Loss: 875.6609497070312
Test Loss:  925.619873046875
Test Acc:  0.0
Valid Loss:  857.2559814453125
Valid Acc:  0.0
std:  12.654324431426904 
thres:  0.8934665405273439
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 80%|████████  | 805/1000 [37:48<09:47,  3.01s/it]Epoch:   806
max of grad d_p:  tensor(634.5151, device='cuda:0')
min of grad d_p:  tensor(-759.3061, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.5613, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-3.9753, device='cuda:0') norm:  tensor(9.1857, device='cuda:0') MSE:  tensor(3.4481e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3568, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.9032, device='cuda:0') MSE:  tensor(3.3905e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0070, device='cuda:0')
min of d_p_list:  tensor(-0.0063, device='cuda:0')
Epoch:  806  
Training Loss: 866.93359375
Test Loss:  916.3577880859375
Test Acc:  0.0
Valid Loss:  848.7010498046875
Valid Acc:  0.0
std:  12.528952384809555 
thres:  0.8845631225585937
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 81%|████████  | 806/1000 [37:51<09:37,  2.98s/it]Epoch:   807
max of grad d_p:  tensor(630.9127, device='cuda:0')
min of grad d_p:  tensor(-755.6556, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2726, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.6221, device='cuda:0') norm:  tensor(8.1798, device='cuda:0') MSE:  tensor(3.0705e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.6096, device='cuda:0') mean:  tensor(0.0058, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(7.8756, device='cuda:0') MSE:  tensor(2.9563e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0190, device='cuda:0')
min of d_p_list:  tensor(-0.0090, device='cuda:0')
Epoch:  807  
Training Loss: 858.2991943359375
Test Loss:  907.3464965820312
Test Acc:  0.0
Valid Loss:  840.3773193359375
Valid Acc:  0.0
std:  12.402206365314003 
thres:  0.87574873046875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 81%|████████  | 807/1000 [37:53<09:28,  2.95s/it]Epoch:   808
max of grad d_p:  tensor(626.0298, device='cuda:0')
min of grad d_p:  tensor(-750.4976, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2603, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.2694, device='cuda:0') norm:  tensor(8.0008, device='cuda:0') MSE:  tensor(3.0033e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2440, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.2670, device='cuda:0') MSE:  tensor(4.7561e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0213, device='cuda:0')
min of d_p_list:  tensor(-0.0397, device='cuda:0')
Epoch:  808  
Training Loss: 849.6944580078125
Test Loss:  898.409912109375
Test Acc:  0.0
Valid Loss:  832.0770263671875
Valid Acc:  0.0
std:  12.292217919457622 
thres:  0.8670121582031249
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 81%|████████  | 808/1000 [37:56<09:16,  2.90s/it]Epoch:   809
max of grad d_p:  tensor(620.5051, device='cuda:0')
min of grad d_p:  tensor(-743.3477, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2679, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-2.5248, device='cuda:0') norm:  tensor(7.4178, device='cuda:0') MSE:  tensor(2.7844e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2572, device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.8621, device='cuda:0') MSE:  tensor(6.9898e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0102, device='cuda:0')
min of d_p_list:  tensor(-0.0048, device='cuda:0')
Epoch:  809  
Training Loss: 841.228759765625
Test Loss:  889.406494140625
Test Acc:  0.0
Valid Loss:  823.7486572265625
Valid Acc:  0.0
std:  12.177060567904169 
thres:  0.8583633911132813
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 81%|████████  | 809/1000 [37:59<09:13,  2.90s/it]Epoch:   810
max of grad d_p:  tensor(616.3173, device='cuda:0')
min of grad d_p:  tensor(-738.8778, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1563, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.4924, device='cuda:0') norm:  tensor(7.8615, device='cuda:0') MSE:  tensor(2.9510e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2738, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.3039, device='cuda:0') MSE:  tensor(4.8946e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0074, device='cuda:0')
min of d_p_list:  tensor(-0.0046, device='cuda:0')
Epoch:  810  
Training Loss: 832.8448486328125
Test Loss:  880.5552978515625
Test Acc:  0.0
Valid Loss:  815.5521240234375
Valid Acc:  0.0
std:  12.05612537389823 
thres:  0.8498001708984375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 81%|████████  | 810/1000 [38:02<09:05,  2.87s/it]Epoch:   811
max of grad d_p:  tensor(612.6105, device='cuda:0')
min of grad d_p:  tensor(-735.1728, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2120, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-2.9489, device='cuda:0') norm:  tensor(7.9298, device='cuda:0') MSE:  tensor(2.9767e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4173, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.5648, device='cuda:0') MSE:  tensor(5.8738e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0122, device='cuda:0')
min of d_p_list:  tensor(-0.0099, device='cuda:0')
Epoch:  811  
Training Loss: 824.5599365234375
Test Loss:  871.805908203125
Test Acc:  0.0
Valid Loss:  807.5126342773438
Valid Acc:  0.0
std:  11.926111541482484 
thres:  0.841325439453125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 81%|████████  | 811/1000 [38:05<08:55,  2.83s/it]Epoch:   812
max of grad d_p:  tensor(608.5111, device='cuda:0')
min of grad d_p:  tensor(-731.2024, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2051, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-2.8879, device='cuda:0') norm:  tensor(7.7596, device='cuda:0') MSE:  tensor(2.9128e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1574, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8091, device='cuda:0') MSE:  tensor(3.0370e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0076, device='cuda:0')
min of d_p_list:  tensor(-0.0097, device='cuda:0')
Epoch:  812  
Training Loss: 816.3265380859375
Test Loss:  863.2605590820312
Test Acc:  0.0
Valid Loss:  799.54931640625
Valid Acc:  0.0
std:  11.795394208824423 
thres:  0.832930908203125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 81%|████████  | 812/1000 [38:07<08:48,  2.81s/it]Epoch:   813
max of grad d_p:  tensor(605.1803, device='cuda:0')
min of grad d_p:  tensor(-727.6726, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2971, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.4944, device='cuda:0') norm:  tensor(7.8201, device='cuda:0') MSE:  tensor(2.9355e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2952, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.9970, device='cuda:0') MSE:  tensor(3.7423e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0109, device='cuda:0')
min of d_p_list:  tensor(-0.0098, device='cuda:0')
Epoch:  813  
Training Loss: 808.1934204101562
Test Loss:  854.6576538085938
Test Acc:  0.0
Valid Loss:  791.5682373046875
Valid Acc:  0.0
std:  11.680035090910197 
thres:  0.8246307006835938
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 81%|████████▏ | 813/1000 [38:10<08:49,  2.83s/it]Epoch:   814
max of grad d_p:  tensor(601.2620, device='cuda:0')
min of grad d_p:  tensor(-723.4129, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3126, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-2.9908, device='cuda:0') norm:  tensor(7.7769, device='cuda:0') MSE:  tensor(2.9192e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3725, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.6590, device='cuda:0') MSE:  tensor(6.2275e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0361, device='cuda:0')
min of d_p_list:  tensor(-0.0187, device='cuda:0')
Epoch:  814  
Training Loss: 800.0924682617188
Test Loss:  845.8629760742188
Test Acc:  0.0
Valid Loss:  783.3995361328125
Valid Acc:  0.0
std:  11.578484253000955 
thres:  0.8164034423828125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 81%|████████▏ | 814/1000 [38:13<08:46,  2.83s/it]Epoch:   815
max of grad d_p:  tensor(595.7714, device='cuda:0')
min of grad d_p:  tensor(-720.8527, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2320, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.7169, device='cuda:0') norm:  tensor(7.9663, device='cuda:0') MSE:  tensor(2.9903e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0991, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.4423, device='cuda:0') MSE:  tensor(1.6604e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0185, device='cuda:0')
min of d_p_list:  tensor(-0.0137, device='cuda:0')
Epoch:  815  
Training Loss: 792.114990234375
Test Loss:  837.3963623046875
Test Acc:  0.0
Valid Loss:  775.6126708984375
Valid Acc:  0.0
std:  11.472848671912312 
thres:  0.808257470703125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 82%|████████▏ | 815/1000 [38:16<08:45,  2.84s/it]Epoch:   816
max of grad d_p:  tensor(590.2424, device='cuda:0')
min of grad d_p:  tensor(-717.0673, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2281, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.5651, device='cuda:0') norm:  tensor(7.0781, device='cuda:0') MSE:  tensor(2.6569e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0721, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.3744, device='cuda:0') MSE:  tensor(1.4054e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0065, device='cuda:0')
min of d_p_list:  tensor(-0.0032, device='cuda:0')
Epoch:  816  
Training Loss: 784.220703125
Test Loss:  829.0503540039062
Test Acc:  0.0
Valid Loss:  767.88330078125
Valid Acc:  0.0
std:  11.354966638353643 
thres:  0.8001896240234375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 82%|████████▏ | 816/1000 [38:19<08:31,  2.78s/it]Epoch:   817
max of grad d_p:  tensor(586.4409, device='cuda:0')
min of grad d_p:  tensor(-713.0199, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2113, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.1156, device='cuda:0') norm:  tensor(7.7239, device='cuda:0') MSE:  tensor(2.8993e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1956, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8410, device='cuda:0') MSE:  tensor(3.1570e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0088, device='cuda:0')
min of d_p_list:  tensor(-0.0068, device='cuda:0')
Epoch:  817  
Training Loss: 776.4047241210938
Test Loss:  820.7816772460938
Test Acc:  0.0
Valid Loss:  760.2171630859375
Valid Acc:  0.0
std:  11.236080799334829 
thres:  0.7922052612304687
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 82%|████████▏ | 817/1000 [38:21<08:27,  2.77s/it]Epoch:   818
max of grad d_p:  tensor(582.5518, device='cuda:0')
min of grad d_p:  tensor(-708.9924, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2483, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.1221, device='cuda:0') norm:  tensor(7.4624, device='cuda:0') MSE:  tensor(2.8012e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1036, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.6987, device='cuda:0') MSE:  tensor(2.6227e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0169, device='cuda:0')
min of d_p_list:  tensor(-0.0138, device='cuda:0')
Epoch:  818  
Training Loss: 768.67236328125
Test Loss:  812.728759765625
Test Acc:  0.0
Valid Loss:  752.8128662109375
Valid Acc:  0.0
std:  11.108922713404466 
thres:  0.7843010498046875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 82%|████████▏ | 818/1000 [38:24<08:14,  2.71s/it]Epoch:   819
max of grad d_p:  tensor(578.8055, device='cuda:0')
min of grad d_p:  tensor(-705.8617, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1669, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.9703, device='cuda:0') norm:  tensor(8.1298, device='cuda:0') MSE:  tensor(3.0517e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.6528, device='cuda:0') mean:  tensor(0.0023, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.8717, device='cuda:0') MSE:  tensor(1.0779e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0119, device='cuda:0')
min of d_p_list:  tensor(-0.0088, device='cuda:0')
Epoch:  819  
Training Loss: 761.0125732421875
Test Loss:  804.6834716796875
Test Acc:  0.0
Valid Loss:  745.3948974609375
Valid Acc:  0.0
std:  10.996157729238845 
thres:  0.7764850708007813
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 82%|████████▏ | 819/1000 [38:27<08:17,  2.75s/it]Epoch:   820
max of grad d_p:  tensor(575.2999, device='cuda:0')
min of grad d_p:  tensor(-701.4697, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3023, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.7153, device='cuda:0') norm:  tensor(8.1609, device='cuda:0') MSE:  tensor(3.0634e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.7521, device='cuda:0') mean:  tensor(0.0072, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(9.0139, device='cuda:0') MSE:  tensor(3.3836e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0150, device='cuda:0')
min of d_p_list:  tensor(-0.0121, device='cuda:0')
Epoch:  820  
Training Loss: 753.4161376953125
Test Loss:  796.4899291992188
Test Acc:  0.0
Valid Loss:  737.740966796875
Valid Acc:  0.0
std:  10.88979779047743 
thres:  0.7687453002929687
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 82%|████████▏ | 820/1000 [38:29<08:11,  2.73s/it]Epoch:   821
max of grad d_p:  tensor(572.2552, device='cuda:0')
min of grad d_p:  tensor(-697.0094, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2837, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.3572, device='cuda:0') norm:  tensor(7.8194, device='cuda:0') MSE:  tensor(2.9352e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2112, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.1573, device='cuda:0') MSE:  tensor(4.3442e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0651, device='cuda:0')
min of d_p_list:  tensor(-0.1167, device='cuda:0')
Epoch:  821  
Training Loss: 745.5787963867188
Test Loss:  787.6441650390625
Test Acc:  0.0
Valid Loss:  729.245849609375
Valid Acc:  0.0
std:  10.876561025784632 
thres:  0.7610169189453124
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 82%|████████▏ | 821/1000 [38:32<08:10,  2.74s/it]Epoch:   822
max of grad d_p:  tensor(573.6477, device='cuda:0')
min of grad d_p:  tensor(-691.4750, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2539, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.7253, device='cuda:0') norm:  tensor(8.1316, device='cuda:0') MSE:  tensor(3.0524e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.3027, device='cuda:0') mean:  tensor(0.0043, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(6.2287, device='cuda:0') MSE:  tensor(2.3381e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0078, device='cuda:0')
min of d_p_list:  tensor(-0.0065, device='cuda:0')
Epoch:  822  
Training Loss: 738.1464233398438
Test Loss:  779.8201293945312
Test Acc:  0.0
Valid Loss:  721.986328125
Valid Acc:  0.0
std:  10.816962643148331 
thres:  0.7533652587890626
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 82%|████████▏ | 822/1000 [38:35<08:07,  2.74s/it]Epoch:   823
max of grad d_p:  tensor(570.1456, device='cuda:0')
min of grad d_p:  tensor(-687.8459, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2385, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.9353, device='cuda:0') norm:  tensor(8.1609, device='cuda:0') MSE:  tensor(3.0634e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.5580, device='cuda:0') mean:  tensor(0.0154, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(20.7491, device='cuda:0') MSE:  tensor(7.7887e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0141, device='cuda:0')
min of d_p_list:  tensor(-0.0186, device='cuda:0')
Epoch:  823  
Training Loss: 730.7835693359375
Test Loss:  772.0811767578125
Test Acc:  0.0
Valid Loss:  714.842529296875
Valid Acc:  0.0
std:  10.710242886255127 
thres:  0.7457875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 82%|████████▏ | 823/1000 [38:38<07:57,  2.70s/it]Epoch:   824
max of grad d_p:  tensor(565.2506, device='cuda:0')
min of grad d_p:  tensor(-683.3553, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2647, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-3.1417, device='cuda:0') norm:  tensor(7.5019, device='cuda:0') MSE:  tensor(2.8160e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0603, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.2962, device='cuda:0') MSE:  tensor(1.1119e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0058, device='cuda:0')
min of d_p_list:  tensor(-0.0039, device='cuda:0')
Epoch:  824  
Training Loss: 723.501708984375
Test Loss:  764.38818359375
Test Acc:  0.0
Valid Loss:  707.7278442382812
Valid Acc:  0.0
std:  10.554498111245497 
thres:  0.7382853271484375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 82%|████████▏ | 824/1000 [38:41<08:21,  2.85s/it]Epoch:   825
max of grad d_p:  tensor(561.5433, device='cuda:0')
min of grad d_p:  tensor(-679.3982, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3928, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.2501, device='cuda:0') norm:  tensor(8.2850, device='cuda:0') MSE:  tensor(3.1100e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1424, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.5707, device='cuda:0') MSE:  tensor(2.1421e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0057, device='cuda:0')
min of d_p_list:  tensor(-0.0027, device='cuda:0')
Epoch:  825  
Training Loss: 716.2933349609375
Test Loss:  756.7621459960938
Test Acc:  0.0
Valid Loss:  700.6727905273438
Valid Acc:  0.0
std:  10.354447816276803 
thres:  0.7308607666015625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 82%|████████▎ | 825/1000 [38:43<08:09,  2.80s/it]Epoch:   826
max of grad d_p:  tensor(557.9999, device='cuda:0')
min of grad d_p:  tensor(-675.6313, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1371, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.2507, device='cuda:0') norm:  tensor(7.7534, device='cuda:0') MSE:  tensor(2.9104e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(72.9793, device='cuda:0') mean:  tensor(0.2495, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(314.5385, device='cuda:0') MSE:  tensor(0.0012, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0061, device='cuda:0')
min of d_p_list:  tensor(-0.0102, device='cuda:0')
Epoch:  826  
Training Loss: 709.15576171875
Test Loss:  749.1744384765625
Test Acc:  0.0
Valid Loss:  693.6088256835938
Valid Acc:  0.0
std:  10.24921746497121 
thres:  0.7235761596679688
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 83%|████████▎ | 826/1000 [38:47<08:32,  2.95s/it]Epoch:   827
max of grad d_p:  tensor(554.2584, device='cuda:0')
min of grad d_p:  tensor(-672.0105, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1774, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.8431, device='cuda:0') norm:  tensor(8.2180, device='cuda:0') MSE:  tensor(3.0848e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3401, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.2262, device='cuda:0') MSE:  tensor(8.3566e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0060, device='cuda:0')
min of d_p_list:  tensor(-0.0037, device='cuda:0')
Epoch:  827  
Training Loss: 702.0879516601562
Test Loss:  741.7279663085938
Test Acc:  0.0
Valid Loss:  686.7137451171875
Valid Acc:  0.0
std:  10.145344914446687 
thres:  0.7163644653320312
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 83%|████████▎ | 827/1000 [38:49<08:17,  2.88s/it]Epoch:   828
max of grad d_p:  tensor(550.7902, device='cuda:0')
min of grad d_p:  tensor(-668.5478, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1958, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.6657, device='cuda:0') norm:  tensor(7.9387, device='cuda:0') MSE:  tensor(2.9800e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1143, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.5419, device='cuda:0') MSE:  tensor(2.0341e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0153, device='cuda:0')
min of d_p_list:  tensor(-0.0120, device='cuda:0')
Epoch:  828  
Training Loss: 695.0884399414062
Test Loss:  734.2938842773438
Test Acc:  0.0
Valid Loss:  679.8262329101562
Valid Acc:  0.0
std:  10.045599641773855 
thres:  0.709225439453125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 83%|████████▎ | 828/1000 [38:52<08:00,  2.80s/it]Epoch:   829
max of grad d_p:  tensor(546.8022, device='cuda:0')
min of grad d_p:  tensor(-665.1813, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.4868, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-4.4761, device='cuda:0') norm:  tensor(9.3052, device='cuda:0') MSE:  tensor(3.4929e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1780, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7899, device='cuda:0') MSE:  tensor(2.9650e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0210, device='cuda:0')
min of d_p_list:  tensor(-0.0274, device='cuda:0')
Epoch:  829  
Training Loss: 688.18212890625
Test Loss:  726.93994140625
Test Acc:  0.0
Valid Loss:  672.9266967773438
Valid Acc:  0.0
std:  9.940672617869895 
thres:  0.7021615234375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 83%|████████▎ | 829/1000 [38:55<07:45,  2.72s/it]Epoch:   830
max of grad d_p:  tensor(543.5006, device='cuda:0')
min of grad d_p:  tensor(-661.7485, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.4057, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.2992, device='cuda:0') norm:  tensor(8.0158, device='cuda:0') MSE:  tensor(3.0089e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1742, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7903, device='cuda:0') MSE:  tensor(2.9667e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0147, device='cuda:0')
min of d_p_list:  tensor(-0.0160, device='cuda:0')
Epoch:  830  
Training Loss: 681.29541015625
Test Loss:  719.7291870117188
Test Acc:  0.0
Valid Loss:  666.208251953125
Valid Acc:  0.0
std:  9.846831966510104 
thres:  0.6951619384765625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 83%|████████▎ | 830/1000 [38:57<07:48,  2.75s/it]Epoch:   831
max of grad d_p:  tensor(539.6934, device='cuda:0')
min of grad d_p:  tensor(-659.5925, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0770, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.8917, device='cuda:0') norm:  tensor(7.7924, device='cuda:0') MSE:  tensor(2.9251e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1566, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.6497, device='cuda:0') MSE:  tensor(2.4390e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0098, device='cuda:0')
min of d_p_list:  tensor(-0.0099, device='cuda:0')
Epoch:  831  
Training Loss: 674.497802734375
Test Loss:  712.5657958984375
Test Acc:  0.0
Valid Loss:  659.65380859375
Valid Acc:  0.0
std:  9.754435829189365 
thres:  0.6882303466796875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 83%|████████▎ | 831/1000 [39:00<07:45,  2.75s/it]Epoch:   832
max of grad d_p:  tensor(536.7812, device='cuda:0')
min of grad d_p:  tensor(-656.4580, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.4319, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-4.1371, device='cuda:0') norm:  tensor(8.2779, device='cuda:0') MSE:  tensor(3.1073e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0764, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.4249, device='cuda:0') MSE:  tensor(1.5948e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0085, device='cuda:0')
min of d_p_list:  tensor(-0.0071, device='cuda:0')
Epoch:  832  
Training Loss: 667.7718505859375
Test Loss:  705.4896240234375
Test Acc:  0.0
Valid Loss:  653.0791015625
Valid Acc:  0.0
std:  9.661707714114916 
thres:  0.6813671264648438
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 83%|████████▎ | 832/1000 [39:03<07:37,  2.72s/it]Epoch:   833
max of grad d_p:  tensor(533.0444, device='cuda:0')
min of grad d_p:  tensor(-653.2277, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2399, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.0755, device='cuda:0') norm:  tensor(7.7270, device='cuda:0') MSE:  tensor(2.9005e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1293, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.4965, device='cuda:0') MSE:  tensor(1.8637e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2336, device='cuda:0')
min of d_p_list:  tensor(-0.1790, device='cuda:0')
Epoch:  833  
Training Loss: 660.463134765625
Test Loss:  699.1810302734375
Test Acc:  0.0
Valid Loss:  646.491943359375
Valid Acc:  0.0
std:  9.753594757838284 
thres:  0.6744420654296875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 83%|████████▎ | 833/1000 [39:05<07:30,  2.70s/it]Epoch:   834
max of grad d_p:  tensor(530.0177, device='cuda:0')
min of grad d_p:  tensor(-637.6105, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2820, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-4.4821, device='cuda:0') norm:  tensor(8.6219, device='cuda:0') MSE:  tensor(3.2365e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1901, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7295, device='cuda:0') MSE:  tensor(2.7383e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0070, device='cuda:0')
min of d_p_list:  tensor(-0.0073, device='cuda:0')
Epoch:  834  
Training Loss: 653.8765258789062
Test Loss:  692.1295166015625
Test Acc:  0.0
Valid Loss:  639.968017578125
Valid Acc:  0.0
std:  9.741049700740614 
thres:  0.6675809448242187
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 83%|████████▎ | 834/1000 [39:08<07:28,  2.70s/it]Epoch:   835
max of grad d_p:  tensor(526.6969, device='cuda:0')
min of grad d_p:  tensor(-634.4388, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0554, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.4461, device='cuda:0') norm:  tensor(7.1859, device='cuda:0') MSE:  tensor(2.6974e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.8053, device='cuda:0') mean:  tensor(0.0132, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(16.8365, device='cuda:0') MSE:  tensor(6.3200e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0086, device='cuda:0')
min of d_p_list:  tensor(-0.0108, device='cuda:0')
Epoch:  835  
Training Loss: 647.3584594726562
Test Loss:  685.09619140625
Test Acc:  0.0
Valid Loss:  633.47607421875
Valid Acc:  0.0
std:  9.643228468433506 
thres:  0.6607935546875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 84%|████████▎ | 835/1000 [39:11<07:28,  2.72s/it]Epoch:   836
max of grad d_p:  tensor(522.7749, device='cuda:0')
min of grad d_p:  tensor(-630.8014, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1727, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.1550, device='cuda:0') norm:  tensor(6.9878, device='cuda:0') MSE:  tensor(2.6230e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0915, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.4418, device='cuda:0') MSE:  tensor(1.6583e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0049, device='cuda:0')
min of d_p_list:  tensor(-0.0039, device='cuda:0')
Epoch:  836  
Training Loss: 640.9083251953125
Test Loss:  678.2625122070312
Test Acc:  0.0
Valid Loss:  627.1668701171875
Valid Acc:  0.0
std:  9.45435998499403 
thres:  0.6540756591796875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 84%|████████▎ | 836/1000 [39:14<07:28,  2.73s/it]Epoch:   837
max of grad d_p:  tensor(519.5002, device='cuda:0')
min of grad d_p:  tensor(-627.1941, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2883, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-4.8298, device='cuda:0') norm:  tensor(8.9049, device='cuda:0') MSE:  tensor(3.3427e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1189, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.4580, device='cuda:0') MSE:  tensor(1.7193e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1369, device='cuda:0')
min of d_p_list:  tensor(-0.0986, device='cuda:0')
Epoch:  837  
Training Loss: 634.8623046875
Test Loss:  672.427978515625
Test Acc:  0.0
Valid Loss:  621.8509521484375
Valid Acc:  0.0
std:  9.076169932155677 
thres:  0.64749375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 84%|████████▎ | 837/1000 [39:16<07:26,  2.74s/it]Epoch:   838
max of grad d_p:  tensor(519.7407, device='cuda:0')
min of grad d_p:  tensor(-621.3917, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.0725, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.7853, device='cuda:0') norm:  tensor(7.7786, device='cuda:0') MSE:  tensor(2.9199e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1841, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.8710, device='cuda:0') MSE:  tensor(3.2693e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0756, device='cuda:0')
min of d_p_list:  tensor(-0.0706, device='cuda:0')
Epoch:  838  
Training Loss: 628.56298828125
Test Loss:  666.0885620117188
Test Acc:  0.0
Valid Loss:  615.8319091796875
Valid Acc:  0.0
std:  8.9278130815467 
thres:  0.641113720703125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 84%|████████▍ | 838/1000 [39:19<07:14,  2.68s/it]Epoch:   839
max of grad d_p:  tensor(520.8640, device='cuda:0')
min of grad d_p:  tensor(-617.0018, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3478, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.9061, device='cuda:0') norm:  tensor(8.2192, device='cuda:0') MSE:  tensor(3.0853e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.7396, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.3479, device='cuda:0') MSE:  tensor(8.8135e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1046, device='cuda:0')
min of d_p_list:  tensor(-0.1139, device='cuda:0')
Epoch:  839  
Training Loss: 622.4940185546875
Test Loss:  660.867431640625
Test Acc:  0.0
Valid Loss:  610.3212280273438
Valid Acc:  0.0
std:  8.779077298279503 
thres:  0.6348372192382813
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 84%|████████▍ | 839/1000 [39:22<07:07,  2.65s/it]Epoch:   840
max of grad d_p:  tensor(518.1564, device='cuda:0')
min of grad d_p:  tensor(-615.8822, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.5155, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.9034, device='cuda:0') norm:  tensor(8.4931, device='cuda:0') MSE:  tensor(3.1881e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3264, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.6863, device='cuda:0') MSE:  tensor(2.5763e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0121, device='cuda:0')
min of d_p_list:  tensor(-0.0226, device='cuda:0')
Epoch:  840  
Training Loss: 616.2803955078125
Test Loss:  654.3084716796875
Test Acc:  0.0
Valid Loss:  604.3270263671875
Valid Acc:  0.0
std:  8.71511364288505 
thres:  0.6286216064453125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 84%|████████▍ | 840/1000 [39:24<07:09,  2.69s/it]Epoch:   841
max of grad d_p:  tensor(515.3862, device='cuda:0')
min of grad d_p:  tensor(-612.9590, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1343, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-2.9780, device='cuda:0') norm:  tensor(7.1970, device='cuda:0') MSE:  tensor(2.7016e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4490, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.5939, device='cuda:0') MSE:  tensor(5.9832e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0050, device='cuda:0')
min of d_p_list:  tensor(-0.0096, device='cuda:0')
Epoch:  841  
Training Loss: 610.139892578125
Test Loss:  647.7691650390625
Test Acc:  0.0
Valid Loss:  598.2645263671875
Valid Acc:  0.0
std:  8.729685329097643 
thres:  0.622467919921875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 84%|████████▍ | 841/1000 [39:27<07:05,  2.68s/it]Epoch:   842
max of grad d_p:  tensor(512.3320, device='cuda:0')
min of grad d_p:  tensor(-609.9194, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2269, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.9592, device='cuda:0') norm:  tensor(7.1077, device='cuda:0') MSE:  tensor(2.6681e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2086, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7731, device='cuda:0') MSE:  tensor(2.9019e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0077, device='cuda:0')
min of d_p_list:  tensor(-0.0070, device='cuda:0')
Epoch:  842  
Training Loss: 604.056884765625
Test Loss:  641.3515625
Test Acc:  0.0
Valid Loss:  592.3274536132812
Valid Acc:  0.0
std:  8.67856776454524 
thres:  0.6163068359375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 84%|████████▍ | 842/1000 [39:30<07:20,  2.79s/it]Epoch:   843
max of grad d_p:  tensor(508.6299, device='cuda:0')
min of grad d_p:  tensor(-605.7434, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3534, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.0944, device='cuda:0') norm:  tensor(7.3773, device='cuda:0') MSE:  tensor(2.7693e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1083, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.5528, device='cuda:0') MSE:  tensor(2.0750e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0109, device='cuda:0')
min of d_p_list:  tensor(-0.0099, device='cuda:0')
Epoch:  843  
Training Loss: 598.03173828125
Test Loss:  634.9505615234375
Test Acc:  0.0
Valid Loss:  586.4020385742188
Valid Acc:  0.0
std:  8.647799384569284 
thres:  0.6102005859375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 84%|████████▍ | 843/1000 [39:33<07:16,  2.78s/it]Epoch:   844
max of grad d_p:  tensor(506.1821, device='cuda:0')
min of grad d_p:  tensor(-603.0877, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.5484, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-4.3214, device='cuda:0') norm:  tensor(8.5976, device='cuda:0') MSE:  tensor(3.2273e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2161, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.1217, device='cuda:0') MSE:  tensor(4.2105e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0065, device='cuda:0')
min of d_p_list:  tensor(-0.0094, device='cuda:0')
Epoch:  844  
Training Loss: 592.0595703125
Test Loss:  628.60693359375
Test Acc:  0.0
Valid Loss:  580.5552368164062
Valid Acc:  0.0
std:  8.563165365805698 
thres:  0.6041136962890625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 84%|████████▍ | 844/1000 [39:36<07:12,  2.77s/it]Epoch:   845
max of grad d_p:  tensor(503.7749, device='cuda:0')
min of grad d_p:  tensor(-600.3632, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1714, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.2155, device='cuda:0') norm:  tensor(7.1523, device='cuda:0') MSE:  tensor(2.6848e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2924, device='cuda:0') mean:  tensor(0.0011, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.4471, device='cuda:0') MSE:  tensor(5.4321e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0234, device='cuda:0')
min of d_p_list:  tensor(-0.0399, device='cuda:0')
Epoch:  845  
Training Loss: 586.1644287109375
Test Loss:  622.439697265625
Test Acc:  0.0
Valid Loss:  574.921875
Valid Acc:  0.0
std:  8.478117136489365 
thres:  0.5980905029296876
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 84%|████████▍ | 845/1000 [39:38<07:01,  2.72s/it]Epoch:   846
max of grad d_p:  tensor(501.2756, device='cuda:0')
min of grad d_p:  tensor(-597.3484, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.4890, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.3881, device='cuda:0') norm:  tensor(7.7768, device='cuda:0') MSE:  tensor(2.9192e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1482, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.5400, device='cuda:0') MSE:  tensor(2.0270e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0039, device='cuda:0')
min of d_p_list:  tensor(-0.0046, device='cuda:0')
Epoch:  846  
Training Loss: 580.3223266601562
Test Loss:  616.2440185546875
Test Acc:  0.0
Valid Loss:  569.1809692382812
Valid Acc:  0.0
std:  8.391605334987478 
thres:  0.5921269897460938
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 85%|████████▍ | 846/1000 [39:41<07:01,  2.74s/it]Epoch:   847
max of grad d_p:  tensor(498.3220, device='cuda:0')
min of grad d_p:  tensor(-594.2389, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2663, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.5802, device='cuda:0') norm:  tensor(7.6432, device='cuda:0') MSE:  tensor(2.8691e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1407, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.4952, device='cuda:0') MSE:  tensor(1.8589e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0151, device='cuda:0')
min of d_p_list:  tensor(-0.0102, device='cuda:0')
Epoch:  847  
Training Loss: 574.5462036132812
Test Loss:  610.1458740234375
Test Acc:  0.0
Valid Loss:  563.5330810546875
Valid Acc:  0.0
std:  8.302780087977135 
thres:  0.586224853515625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 85%|████████▍ | 847/1000 [39:44<06:55,  2.71s/it]Epoch:   848
max of grad d_p:  tensor(495.6611, device='cuda:0')
min of grad d_p:  tensor(-591.7222, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1665, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-2.8929, device='cuda:0') norm:  tensor(6.8643, device='cuda:0') MSE:  tensor(2.5767e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4897, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.1548, device='cuda:0') MSE:  tensor(8.0887e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0413, device='cuda:0')
min of d_p_list:  tensor(-0.0408, device='cuda:0')
Epoch:  848  
Training Loss: 568.8756103515625
Test Loss:  604.2667846679688
Test Acc:  0.0
Valid Loss:  558.15380859375
Valid Acc:  0.0
std:  8.200713838113227 
thres:  0.5803936279296875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 85%|████████▍ | 848/1000 [39:46<06:45,  2.67s/it]Epoch:   849
max of grad d_p:  tensor(492.4342, device='cuda:0')
min of grad d_p:  tensor(-588.8892, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.6617, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-3.9302, device='cuda:0') norm:  tensor(8.6831, device='cuda:0') MSE:  tensor(3.2594e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3617, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.2258, device='cuda:0') MSE:  tensor(8.3552e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0098, device='cuda:0')
min of d_p_list:  tensor(-0.0166, device='cuda:0')
Epoch:  849  
Training Loss: 563.2001953125
Test Loss:  598.35888671875
Test Acc:  0.0
Valid Loss:  552.6348876953125
Valid Acc:  0.0
std:  8.114255920016943 
thres:  0.5746217529296875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 85%|████████▍ | 849/1000 [39:49<06:36,  2.63s/it]Epoch:   850
max of grad d_p:  tensor(489.5623, device='cuda:0')
min of grad d_p:  tensor(-586.2621, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.5343, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.7061, device='cuda:0') norm:  tensor(7.9813, device='cuda:0') MSE:  tensor(2.9960e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0554, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.2801, device='cuda:0') MSE:  tensor(1.0512e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0091, device='cuda:0')
min of d_p_list:  tensor(-0.0080, device='cuda:0')
Epoch:  850  
Training Loss: 557.5912475585938
Test Loss:  592.3858642578125
Test Acc:  0.0
Valid Loss:  547.11865234375
Valid Acc:  0.0
std:  8.033992263482924 
thres:  0.5689071166992187
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 85%|████████▌ | 850/1000 [39:51<06:32,  2.61s/it]Epoch:   851
max of grad d_p:  tensor(487.0914, device='cuda:0')
min of grad d_p:  tensor(-583.9268, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3797, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.7495, device='cuda:0') norm:  tensor(7.2553, device='cuda:0') MSE:  tensor(2.7234e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1706, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7453, device='cuda:0') MSE:  tensor(2.7978e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0310, device='cuda:0')
min of d_p_list:  tensor(-0.0326, device='cuda:0')
Epoch:  851  
Training Loss: 552.0345458984375
Test Loss:  586.1761474609375
Test Acc:  0.0
Valid Loss:  541.3751220703125
Valid Acc:  0.0
std:  7.96319128665127 
thres:  0.563249560546875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 85%|████████▌ | 851/1000 [39:55<07:01,  2.83s/it]Epoch:   852
max of grad d_p:  tensor(482.7711, device='cuda:0')
min of grad d_p:  tensor(-581.4219, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3454, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.7686, device='cuda:0') norm:  tensor(7.7051, device='cuda:0') MSE:  tensor(2.8923e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1713, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.6776, device='cuda:0') MSE:  tensor(2.5436e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0658, device='cuda:0')
min of d_p_list:  tensor(-0.0798, device='cuda:0')
Epoch:  852  
Training Loss: 545.9744873046875
Test Loss:  580.3328857421875
Test Acc:  0.0
Valid Loss:  535.5498657226562
Valid Acc:  0.0
std:  8.05738783636979 
thres:  0.5575352172851563
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 85%|████████▌ | 852/1000 [39:58<07:20,  2.98s/it]Epoch:   853
max of grad d_p:  tensor(482.2227, device='cuda:0')
min of grad d_p:  tensor(-580.0215, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.4993, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-4.7361, device='cuda:0') norm:  tensor(8.6555, device='cuda:0') MSE:  tensor(3.2491e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1955, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7573, device='cuda:0') MSE:  tensor(2.8426e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0279, device='cuda:0')
min of d_p_list:  tensor(-0.0342, device='cuda:0')
Epoch:  853  
Training Loss: 540.5216064453125
Test Loss:  574.6464233398438
Test Acc:  0.0
Valid Loss:  530.1629028320312
Valid Acc:  0.0
std:  8.058238332716712 
thres:  0.5518644165039063
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 85%|████████▌ | 853/1000 [40:01<07:10,  2.93s/it]Epoch:   854
max of grad d_p:  tensor(481.6979, device='cuda:0')
min of grad d_p:  tensor(-581.7271, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3580, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-2.8286, device='cuda:0') norm:  tensor(7.1758, device='cuda:0') MSE:  tensor(2.6936e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1465, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.5465, device='cuda:0') MSE:  tensor(2.0514e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0125, device='cuda:0')
min of d_p_list:  tensor(-0.0090, device='cuda:0')
Epoch:  854  
Training Loss: 535.137939453125
Test Loss:  568.9569091796875
Test Acc:  0.0
Valid Loss:  524.9268798828125
Valid Acc:  0.0
std:  7.98064079737797 
thres:  0.5462519653320312
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 85%|████████▌ | 854/1000 [40:04<07:04,  2.90s/it]Epoch:   855
max of grad d_p:  tensor(478.5824, device='cuda:0')
min of grad d_p:  tensor(-578.9636, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3058, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.7352, device='cuda:0') norm:  tensor(7.2851, device='cuda:0') MSE:  tensor(2.7346e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1924, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.5526, device='cuda:0') MSE:  tensor(2.0744e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0106, device='cuda:0')
min of d_p_list:  tensor(-0.0172, device='cuda:0')
Epoch:  855  
Training Loss: 529.8145141601562
Test Loss:  563.31396484375
Test Acc:  0.0
Valid Loss:  519.6932373046875
Valid Acc:  0.0
std:  7.81990068530838 
thres:  0.5406966186523438
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 86%|████████▌ | 855/1000 [40:07<07:06,  2.94s/it]Epoch:   856
max of grad d_p:  tensor(474.9983, device='cuda:0')
min of grad d_p:  tensor(-575.3246, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2218, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-4.2695, device='cuda:0') norm:  tensor(8.1094, device='cuda:0') MSE:  tensor(3.0441e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1568, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7082, device='cuda:0') MSE:  tensor(2.6585e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0056, device='cuda:0')
min of d_p_list:  tensor(-0.0047, device='cuda:0')
Epoch:  856  
Training Loss: 524.533935546875
Test Loss:  557.70068359375
Test Acc:  0.0
Valid Loss:  514.5140991210938
Valid Acc:  0.0
std:  7.578670736070132 
thres:  0.5351964965820313
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 86%|████████▌ | 856/1000 [40:10<07:14,  3.02s/it]Epoch:   857
max of grad d_p:  tensor(472.2223, device='cuda:0')
min of grad d_p:  tensor(-572.3623, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.4467, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.9794, device='cuda:0') norm:  tensor(7.6412, device='cuda:0') MSE:  tensor(2.8683e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1135, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7715, device='cuda:0') MSE:  tensor(2.8961e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0103, device='cuda:0')
min of d_p_list:  tensor(-0.0120, device='cuda:0')
Epoch:  857  
Training Loss: 519.314697265625
Test Loss:  552.162841796875
Test Acc:  0.0
Valid Loss:  509.36419677734375
Valid Acc:  0.0
std:  7.497984197801268 
thres:  0.5298645385742188
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 86%|████████▌ | 857/1000 [40:13<07:04,  2.97s/it]Epoch:   858
max of grad d_p:  tensor(469.4361, device='cuda:0')
min of grad d_p:  tensor(-569.8566, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2241, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.2950, device='cuda:0') norm:  tensor(7.4331, device='cuda:0') MSE:  tensor(2.7902e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.9440, device='cuda:0') mean:  tensor(0.0228, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(29.7972, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0052, device='cuda:0')
min of d_p_list:  tensor(-0.0042, device='cuda:0')
Epoch:  858  
Training Loss: 514.1390380859375
Test Loss:  546.694580078125
Test Acc:  0.0
Valid Loss:  504.29583740234375
Valid Acc:  0.0
std:  7.424407350123022 
thres:  0.5245880249023437
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 86%|████████▌ | 858/1000 [40:16<07:13,  3.05s/it]Epoch:   859
max of grad d_p:  tensor(466.7634, device='cuda:0')
min of grad d_p:  tensor(-567.2265, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.5427, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-4.0386, device='cuda:0') norm:  tensor(8.4661, device='cuda:0') MSE:  tensor(3.1780e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0677, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.3065, device='cuda:0') MSE:  tensor(1.1504e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0099, device='cuda:0')
min of d_p_list:  tensor(-0.0051, device='cuda:0')
Epoch:  859  
Training Loss: 509.01336669921875
Test Loss:  541.232177734375
Test Acc:  0.0
Valid Loss:  499.2708740234375
Valid Acc:  0.0
std:  7.353635064420297 
thres:  0.5193631103515625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 86%|████████▌ | 859/1000 [40:19<07:00,  2.98s/it]Epoch:   860
max of grad d_p:  tensor(463.9690, device='cuda:0')
min of grad d_p:  tensor(-564.3422, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1829, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.2828, device='cuda:0') norm:  tensor(7.0087, device='cuda:0') MSE:  tensor(2.6309e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1464, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.5703, device='cuda:0') MSE:  tensor(2.1406e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0077, device='cuda:0')
min of d_p_list:  tensor(-0.0074, device='cuda:0')
Epoch:  860  
Training Loss: 503.9392395019531
Test Loss:  535.8125610351562
Test Acc:  0.0
Valid Loss:  494.2662048339844
Valid Acc:  0.0
std:  7.282001455520462 
thres:  0.5141880554199219
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 86%|████████▌ | 860/1000 [40:21<06:45,  2.90s/it]Epoch:   861
max of grad d_p:  tensor(461.3226, device='cuda:0')
min of grad d_p:  tensor(-561.4933, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3471, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.6949, device='cuda:0') norm:  tensor(7.3666, device='cuda:0') MSE:  tensor(2.7652e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4514, device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.1247, device='cuda:0') MSE:  tensor(7.9755e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0062, device='cuda:0')
min of d_p_list:  tensor(-0.0062, device='cuda:0')
Epoch:  861  
Training Loss: 498.9190673828125
Test Loss:  530.4552001953125
Test Acc:  0.0
Valid Loss:  489.30902099609375
Valid Acc:  0.0
std:  7.211354822148967 
thres:  0.5090650817871094
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 86%|████████▌ | 861/1000 [40:25<06:50,  2.96s/it]Epoch:   862
max of grad d_p:  tensor(458.0087, device='cuda:0')
min of grad d_p:  tensor(-558.3450, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.5143, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-3.0925, device='cuda:0') norm:  tensor(7.4477, device='cuda:0') MSE:  tensor(2.7957e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1765, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.7939, device='cuda:0') MSE:  tensor(2.9801e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0053, device='cuda:0')
min of d_p_list:  tensor(-0.0063, device='cuda:0')
Epoch:  862  
Training Loss: 493.94775390625
Test Loss:  525.17578125
Test Acc:  0.0
Valid Loss:  484.43359375
Valid Acc:  0.0
std:  7.138638715820951 
thres:  0.5039916931152344
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 86%|████████▌ | 862/1000 [40:28<06:55,  3.01s/it]Epoch:   863
max of grad d_p:  tensor(455.1373, device='cuda:0')
min of grad d_p:  tensor(-555.3715, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.2632, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-3.5742, device='cuda:0') norm:  tensor(7.8743, device='cuda:0') MSE:  tensor(2.9558e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1087, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.5024, device='cuda:0') MSE:  tensor(1.8858e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0171, device='cuda:0')
min of d_p_list:  tensor(-0.0195, device='cuda:0')
Epoch:  863  
Training Loss: 489.0385437011719
Test Loss:  520.0042114257812
Test Acc:  0.0
Valid Loss:  479.6119079589844
Valid Acc:  0.0
std:  7.062887757114401 
thres:  0.49897159423828125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 86%|████████▋ | 863/1000 [40:31<06:54,  3.02s/it]Epoch:   864
max of grad d_p:  tensor(452.3449, device='cuda:0')
min of grad d_p:  tensor(-551.4960, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3795, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-2.8774, device='cuda:0') norm:  tensor(7.2151, device='cuda:0') MSE:  tensor(2.7084e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.4461, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.0125, device='cuda:0') MSE:  tensor(7.5542e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0050, device='cuda:0')
min of d_p_list:  tensor(-0.0037, device='cuda:0')
Epoch:  864  
Training Loss: 484.1667175292969
Test Loss:  514.7828979492188
Test Acc:  0.0
Valid Loss:  474.79461669921875
Valid Acc:  0.0
std:  6.989962840592672 
thres:  0.49400226440429684
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 86%|████████▋ | 864/1000 [40:34<07:01,  3.10s/it]Epoch:   865
max of grad d_p:  tensor(449.4561, device='cuda:0')
min of grad d_p:  tensor(-548.4259, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.5096, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-4.3251, device='cuda:0') norm:  tensor(8.5052, device='cuda:0') MSE:  tensor(3.1926e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.6065, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.4153, device='cuda:0') MSE:  tensor(9.0663e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0049, device='cuda:0')
min of d_p_list:  tensor(-0.0042, device='cuda:0')
Epoch:  865  
Training Loss: 479.3423767089844
Test Loss:  509.673583984375
Test Acc:  0.0
Valid Loss:  470.06268310546875
Valid Acc:  0.0
std:  6.920485587888182 
thres:  0.48908289184570314
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 86%|████████▋ | 865/1000 [40:37<06:49,  3.03s/it]Epoch:   866
max of grad d_p:  tensor(446.5530, device='cuda:0')
min of grad d_p:  tensor(-545.5099, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3521, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.1031, device='cuda:0') norm:  tensor(7.3405, device='cuda:0') MSE:  tensor(2.7554e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.8582, device='cuda:0') mean:  tensor(0.0026, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(3.4181, device='cuda:0') MSE:  tensor(1.2831e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0078, device='cuda:0')
min of d_p_list:  tensor(-0.0093, device='cuda:0')
Epoch:  866  
Training Loss: 474.55914306640625
Test Loss:  504.617431640625
Test Acc:  0.0
Valid Loss:  465.386962890625
Valid Acc:  0.0
std:  6.8552658697957245 
thres:  0.48421090698242186
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 87%|████████▋ | 866/1000 [40:40<06:32,  2.93s/it]Epoch:   867
max of grad d_p:  tensor(444.1781, device='cuda:0')
min of grad d_p:  tensor(-543.0291, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1426, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.1761, device='cuda:0') norm:  tensor(6.9128, device='cuda:0') MSE:  tensor(2.5949e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.4036, device='cuda:0') mean:  tensor(0.0050, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(6.9754, device='cuda:0') MSE:  tensor(2.6184e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0076, device='cuda:0')
min of d_p_list:  tensor(-0.0042, device='cuda:0')
Epoch:  867  
Training Loss: 469.83001708984375
Test Loss:  499.5838623046875
Test Acc:  0.0
Valid Loss:  460.7335510253906
Valid Acc:  0.0
std:  6.791820241779631 
thres:  0.47938735961914064
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 87%|████████▋ | 867/1000 [40:42<06:25,  2.90s/it]Epoch:   868
max of grad d_p:  tensor(441.3491, device='cuda:0')
min of grad d_p:  tensor(-540.0969, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.5057, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.3465, device='cuda:0') norm:  tensor(7.7010, device='cuda:0') MSE:  tensor(2.8908e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.3690, device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(2.0359, device='cuda:0') MSE:  tensor(7.6424e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0049, device='cuda:0')
min of d_p_list:  tensor(-0.0025, device='cuda:0')
Epoch:  868  
Training Loss: 465.148193359375
Test Loss:  494.5890808105469
Test Acc:  0.0
Valid Loss:  456.1284484863281
Valid Acc:  0.0
std:  6.7246240739609116 
thres:  0.47460928955078124
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 87%|████████▋ | 868/1000 [40:45<06:30,  2.96s/it]Epoch:   869
max of grad d_p:  tensor(438.7477, device='cuda:0')
min of grad d_p:  tensor(-537.4768, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.4837, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-3.9018, device='cuda:0') norm:  tensor(7.9308, device='cuda:0') MSE:  tensor(2.9770e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1011, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.3516, device='cuda:0') MSE:  tensor(1.3196e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0083, device='cuda:0')
min of d_p_list:  tensor(-0.0067, device='cuda:0')
Epoch:  869  
Training Loss: 460.5101013183594
Test Loss:  489.615966796875
Test Acc:  0.0
Valid Loss:  451.55078125
Valid Acc:  0.0
std:  6.6576035601243975 
thres:  0.46987796630859374
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 87%|████████▋ | 869/1000 [40:48<06:20,  2.91s/it]Epoch:   870
max of grad d_p:  tensor(436.3564, device='cuda:0')
min of grad d_p:  tensor(-534.7407, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.1484, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-3.8477, device='cuda:0') norm:  tensor(7.6977, device='cuda:0') MSE:  tensor(2.8895e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.1865, device='cuda:0') mean:  tensor(0.0045, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(5.8618, device='cuda:0') MSE:  tensor(2.2004e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.3849, device='cuda:0')
min of d_p_list:  tensor(-0.4912, device='cuda:0')
Epoch:  870  
Training Loss: 454.64935302734375
Test Loss:  482.4912109375
Test Acc:  0.0
Valid Loss:  444.1377258300781
Valid Acc:  0.0
std:  6.957081864594292 
thres:  0.4649393615722656
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 87%|████████▋ | 870/1000 [40:51<06:26,  2.97s/it]Epoch:   871
max of grad d_p:  tensor(418.4843, device='cuda:0')
min of grad d_p:  tensor(-523.8642, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.6736, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-5.2310, device='cuda:0') norm:  tensor(9.2125, device='cuda:0') MSE:  tensor(3.4581e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1560, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.6679, device='cuda:0') MSE:  tensor(2.5071e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0151, device='cuda:0')
min of d_p_list:  tensor(-0.0198, device='cuda:0')
Epoch:  871  
Training Loss: 450.13494873046875
Test Loss:  477.6495666503906
Test Acc:  0.0
Valid Loss:  439.63348388671875
Valid Acc:  0.0
std:  7.061545583748015 
thres:  0.46005452270507813
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 87%|████████▋ | 871/1000 [40:55<06:37,  3.08s/it]Epoch:   872
max of grad d_p:  tensor(415.8181, device='cuda:0')
min of grad d_p:  tensor(-520.5332, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3899, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-3.0512, device='cuda:0') norm:  tensor(6.7060, device='cuda:0') MSE:  tensor(2.5172e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.2624, device='cuda:0') mean:  tensor(0.0011, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1.4387, device='cuda:0') MSE:  tensor(5.4006e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0054, device='cuda:0')
min of d_p_list:  tensor(-0.0055, device='cuda:0')
Epoch:  872  
Training Loss: 445.64581298828125
Test Loss:  472.89007568359375
Test Acc:  0.0
Valid Loss:  435.2424621582031
Valid Acc:  0.0
std:  6.991460645500071 
thres:  0.45521768188476563
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 87%|████████▋ | 872/1000 [40:57<06:17,  2.95s/it]Epoch:   873
max of grad d_p:  tensor(413.4713, device='cuda:0')
min of grad d_p:  tensor(-517.6516, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.3539, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-3.2491, device='cuda:0') norm:  tensor(7.0181, device='cuda:0') MSE:  tensor(2.6344e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0935, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.5636, device='cuda:0') MSE:  tensor(2.1155e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0050, device='cuda:0')
min of d_p_list:  tensor(-0.0051, device='cuda:0')
Epoch:  873  
Training Loss: 441.205078125
Test Loss:  468.15740966796875
Test Acc:  0.0
Valid Loss:  430.87701416015625
Valid Acc:  0.0
std:  6.745162152882888 
thres:  0.45042905883789064
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 87%|████████▋ | 873/1000 [41:00<06:04,  2.87s/it]Epoch:   874
max of grad d_p:  tensor(411.0520, device='cuda:0')
min of grad d_p:  tensor(-514.8928, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.5276, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-4.2855, device='cuda:0') norm:  tensor(8.1337, device='cuda:0') MSE:  tensor(3.0532e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1321, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.6139, device='cuda:0') MSE:  tensor(2.3043e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0077, device='cuda:0')
min of d_p_list:  tensor(-0.0036, device='cuda:0')
Epoch:  874  
Training Loss: 436.8103942871094
Test Loss:  463.4397277832031
Test Acc:  0.0
Valid Loss:  426.5244140625
Valid Acc:  0.0
std:  6.3085885318935295 
thres:  0.44568911743164064
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 87%|████████▋ | 874/1000 [41:03<05:55,  2.82s/it]Epoch:   875
max of grad d_p:  tensor(408.5476, device='cuda:0')
min of grad d_p:  tensor(-511.8940, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(1.5201, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-4.1761, device='cuda:0') norm:  tensor(8.0199, device='cuda:0') MSE:  tensor(3.0105e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.1062, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.4234, device='cuda:0') MSE:  tensor(1.5895e-06, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(5.5957, device='cuda:0')
min of d_p_list:  tensor(-4.8842, device='cuda:0')
Epoch:  875  
Training Loss: 22762.43359375
Test Loss:  21303.43359375
Test Acc:  0.0
Valid Loss:  18823.71484375
Valid Acc:  0.0
std:  8927.594918910509 
thres:  4.907245965576172
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 88%|████████▊ | 875/1000 [41:06<06:12,  2.98s/it]Epoch:   876
max of grad d_p:  tensor(7245.3433, device='cuda:0')
min of grad d_p:  tensor(-32023.3535, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.6469, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-9.3301, device='cuda:0') norm:  tensor(27.8301, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.4086, device='cuda:0') mean:  tensor(0.0199, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(25.6220, device='cuda:0') MSE:  tensor(9.6178e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0467, device='cuda:0')
min of d_p_list:  tensor(-0.0585, device='cuda:0')
Epoch:  876  
Training Loss: 22529.61328125
Test Loss:  21078.39453125
Test Acc:  0.0
Valid Loss:  18631.8984375
Valid Acc:  0.0
std:  10878.336947213811 
thres:  9.323141632080079
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 88%|████████▊ | 876/1000 [41:09<06:21,  3.08s/it]Epoch:   877
max of grad d_p:  tensor(7171.0723, device='cuda:0')
min of grad d_p:  tensor(-31802.8027, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.9667, device='cuda:0') mean:  tensor(0.0023, device='cuda:0') min:  tensor(-6.0400, device='cuda:0') norm:  tensor(24.8112, device='cuda:0') MSE:  tensor(9.3135e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(10.1689, device='cuda:0') mean:  tensor(0.0313, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(41.9088, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0096, device='cuda:0')
min of d_p_list:  tensor(-0.0087, device='cuda:0')
Epoch:  877  
Training Loss: 22304.84375
Test Loss:  20870.63671875
Test Acc:  0.0
Valid Loss:  18448.03515625
Valid Acc:  0.0
std:  10824.424461892728 
thres:  13.694981219482424
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 88%|████████▊ | 877/1000 [41:13<06:18,  3.08s/it]Epoch:   878
max of grad d_p:  tensor(7117.2896, device='cuda:0')
min of grad d_p:  tensor(-31628.3008, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.2504, device='cuda:0') mean:  tensor(0.0024, device='cuda:0') min:  tensor(-9.5664, device='cuda:0') norm:  tensor(26.5236, device='cuda:0') MSE:  tensor(9.9563e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.2095, device='cuda:0') mean:  tensor(0.0151, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(19.2151, device='cuda:0') MSE:  tensor(7.2128e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0071, device='cuda:0')
min of d_p_list:  tensor(-0.0072, device='cuda:0')
Epoch:  878  
Training Loss: 22082.4453125
Test Loss:  20664.0234375
Test Acc:  0.0
Valid Loss:  18264.9921875
Valid Acc:  0.0
std:  8796.125747011192 
thres:  18.023229266357422
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 88%|████████▊ | 878/1000 [41:16<06:23,  3.14s/it]Epoch:   879
max of grad d_p:  tensor(7072.5098, device='cuda:0')
min of grad d_p:  tensor(-31457.7578, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.2744, device='cuda:0') mean:  tensor(0.0026, device='cuda:0') min:  tensor(-11.4395, device='cuda:0') norm:  tensor(29.2667, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(12.7681, device='cuda:0') mean:  tensor(0.0292, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(41.2832, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0101, device='cuda:0')
min of d_p_list:  tensor(-0.0076, device='cuda:0')
Epoch:  879  
Training Loss: 21862.390625
Test Loss:  20460.6796875
Test Acc:  0.0
Valid Loss:  18085.126953125
Valid Acc:  0.0
std:  317.828361039884 
thres:  22.308345312500002
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 88%|████████▊ | 879/1000 [41:19<06:16,  3.11s/it]Epoch:   880
max of grad d_p:  tensor(7021.7231, device='cuda:0')
min of grad d_p:  tensor(-31287.5664, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.2071, device='cuda:0') mean:  tensor(0.0024, device='cuda:0') min:  tensor(-8.1582, device='cuda:0') norm:  tensor(26.5477, device='cuda:0') MSE:  tensor(9.9653e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.9487, device='cuda:0') mean:  tensor(0.0171, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(22.6152, device='cuda:0') MSE:  tensor(8.4891e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0081, device='cuda:0')
min of d_p_list:  tensor(-0.0053, device='cuda:0')
Epoch:  880  
Training Loss: 21644.53515625
Test Loss:  20256.775390625
Test Acc:  0.0
Valid Loss:  17905.083984375
Valid Acc:  0.0
std:  312.91618956697533 
thres:  22.084765625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 88%|████████▊ | 880/1000 [41:22<06:10,  3.09s/it]Epoch:   881
max of grad d_p:  tensor(6972.2695, device='cuda:0')
min of grad d_p:  tensor(-31119.7559, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.8919, device='cuda:0') mean:  tensor(0.0026, device='cuda:0') min:  tensor(-5.9474, device='cuda:0') norm:  tensor(26.5933, device='cuda:0') MSE:  tensor(9.9824e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(18.2966, device='cuda:0') mean:  tensor(0.0834, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(104.6613, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0368, device='cuda:0')
min of d_p_list:  tensor(-0.0620, device='cuda:0')
Epoch:  881  
Training Loss: 21430.12890625
Test Loss:  20051.08984375
Test Acc:  0.0
Valid Loss:  17720.828125
Valid Acc:  0.0
std:  309.34425049009604 
thres:  21.864868750000003
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 88%|████████▊ | 881/1000 [41:25<05:54,  2.98s/it]Epoch:   882
max of grad d_p:  tensor(6895.9702, device='cuda:0')
min of grad d_p:  tensor(-31023.7695, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.2380, device='cuda:0') mean:  tensor(0.0024, device='cuda:0') min:  tensor(-9.7285, device='cuda:0') norm:  tensor(26.8045, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(24.2927, device='cuda:0') mean:  tensor(0.0747, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(104.6086, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0083, device='cuda:0')
min of d_p_list:  tensor(-0.0068, device='cuda:0')
Epoch:  882  
Training Loss: 21216.65625
Test Loss:  19850.1171875
Test Acc:  0.0
Valid Loss:  17542.0234375
Valid Acc:  0.0
std:  306.0197261799953 
thres:  21.64723125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 88%|████████▊ | 882/1000 [41:27<05:39,  2.88s/it]Epoch:   883
max of grad d_p:  tensor(6844.4380, device='cuda:0')
min of grad d_p:  tensor(-30869.5430, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.9642, device='cuda:0') mean:  tensor(0.0026, device='cuda:0') min:  tensor(-7.4291, device='cuda:0') norm:  tensor(27.5414, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(10.6091, device='cuda:0') mean:  tensor(0.0438, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(60.4315, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0213, device='cuda:0')
min of d_p_list:  tensor(-0.0224, device='cuda:0')
Epoch:  883  
Training Loss: 21005.16015625
Test Loss:  19656.908203125
Test Acc:  0.0
Valid Loss:  17371.765625
Valid Acc:  0.0
std:  302.97713171546343 
thres:  21.43177421875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 88%|████████▊ | 883/1000 [41:30<05:43,  2.93s/it]Epoch:   884
max of grad d_p:  tensor(6794.0801, device='cuda:0')
min of grad d_p:  tensor(-30687.8145, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.1449, device='cuda:0') mean:  tensor(0.0023, device='cuda:0') min:  tensor(-6.2910, device='cuda:0') norm:  tensor(25.8509, device='cuda:0') MSE:  tensor(9.7038e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.8884, device='cuda:0') mean:  tensor(0.0194, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(25.3379, device='cuda:0') MSE:  tensor(9.5112e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0148, device='cuda:0')
min of d_p_list:  tensor(-0.0168, device='cuda:0')
Epoch:  884  
Training Loss: 20795.4609375
Test Loss:  19460.294921875
Test Acc:  0.0
Valid Loss:  17196.712890625
Valid Acc:  0.0
std:  300.2572306081415 
thres:  21.21838828125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 88%|████████▊ | 884/1000 [41:33<05:40,  2.93s/it]Epoch:   885
max of grad d_p:  tensor(6760.9971, device='cuda:0')
min of grad d_p:  tensor(-30540.6602, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.7356, device='cuda:0') mean:  tensor(0.0027, device='cuda:0') min:  tensor(-7.8125, device='cuda:0') norm:  tensor(27.9328, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(22.3999, device='cuda:0') mean:  tensor(0.0456, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(71.3530, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0143, device='cuda:0')
min of d_p_list:  tensor(-0.0103, device='cuda:0')
Epoch:  885  
Training Loss: 20589.39453125
Test Loss:  19267.1796875
Test Acc:  0.0
Valid Loss:  17027.75
Valid Acc:  0.0
std:  297.36834176625877 
thres:  21.00736015625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 88%|████████▊ | 885/1000 [41:36<05:36,  2.93s/it]Epoch:   886
max of grad d_p:  tensor(6716.0928, device='cuda:0')
min of grad d_p:  tensor(-30360.4746, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.8074, device='cuda:0') mean:  tensor(0.0024, device='cuda:0') min:  tensor(-6.0529, device='cuda:0') norm:  tensor(26.5989, device='cuda:0') MSE:  tensor(9.9845e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(10.8564, device='cuda:0') mean:  tensor(0.0342, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(44.1543, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0215, device='cuda:0')
min of d_p_list:  tensor(-0.0129, device='cuda:0')
Epoch:  886  
Training Loss: 20384.107421875
Test Loss:  19074.6015625
Test Acc:  0.0
Valid Loss:  16856.990234375
Valid Acc:  0.0
std:  294.28490250048793 
thres:  20.798155859375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 89%|████████▊ | 886/1000 [41:39<05:31,  2.91s/it]Epoch:   887
max of grad d_p:  tensor(6671.9819, device='cuda:0')
min of grad d_p:  tensor(-30190.8926, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.7659, device='cuda:0') mean:  tensor(0.0026, device='cuda:0') min:  tensor(-6.4902, device='cuda:0') norm:  tensor(24.3685, device='cuda:0') MSE:  tensor(9.1473e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.1038, device='cuda:0') mean:  tensor(0.0215, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(32.9616, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1054, device='cuda:0')
min of d_p_list:  tensor(-0.0832, device='cuda:0')
Epoch:  887  
Training Loss: 20183.283203125
Test Loss:  18883.23828125
Test Acc:  0.0
Valid Loss:  16679.298828125
Valid Acc:  0.0
std:  290.64475045929083 
thres:  20.59148125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 89%|████████▊ | 887/1000 [41:42<05:27,  2.90s/it]Epoch:   888
max of grad d_p:  tensor(6634.4746, device='cuda:0')
min of grad d_p:  tensor(-30013.2500, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.2673, device='cuda:0') mean:  tensor(0.0024, device='cuda:0') min:  tensor(-6.6484, device='cuda:0') norm:  tensor(25.9709, device='cuda:0') MSE:  tensor(9.7488e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(10.6978, device='cuda:0') mean:  tensor(0.0257, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(35.9189, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0354, device='cuda:0')
min of d_p_list:  tensor(-0.0283, device='cuda:0')
Epoch:  888  
Training Loss: 19982.99609375
Test Loss:  18691.2578125
Test Acc:  0.0
Valid Loss:  16509.34375
Valid Acc:  0.0
std:  287.23924822865246 
thres:  20.387048437500003
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 89%|████████▉ | 888/1000 [41:45<05:23,  2.88s/it]Epoch:   889
max of grad d_p:  tensor(6587.2803, device='cuda:0')
min of grad d_p:  tensor(-29804.5000, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.6042, device='cuda:0') mean:  tensor(0.0025, device='cuda:0') min:  tensor(-7.0798, device='cuda:0') norm:  tensor(26.4958, device='cuda:0') MSE:  tensor(9.9458e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.8923, device='cuda:0') mean:  tensor(0.0230, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(27.9466, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0205, device='cuda:0')
min of d_p_list:  tensor(-0.0238, device='cuda:0')
Epoch:  889  
Training Loss: 19783.49609375
Test Loss:  18506.77734375
Test Acc:  0.0
Valid Loss:  16346.748046875
Valid Acc:  0.0
std:  284.6724507596346 
thres:  20.184655468749998
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 89%|████████▉ | 889/1000 [41:48<05:16,  2.85s/it]Epoch:   890
max of grad d_p:  tensor(6533.0400, device='cuda:0')
min of grad d_p:  tensor(-29616.9062, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.6317, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-8.1055, device='cuda:0') norm:  tensor(27.1144, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.9250, device='cuda:0') mean:  tensor(0.0144, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(18.6254, device='cuda:0') MSE:  tensor(6.9915e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0096, device='cuda:0')
min of d_p_list:  tensor(-0.0075, device='cuda:0')
Epoch:  890  
Training Loss: 19586.66015625
Test Loss:  18321.4375
Test Acc:  0.0
Valid Loss:  16184.2021484375
Valid Acc:  0.0
std:  282.09270136065146 
thres:  19.98410859375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 89%|████████▉ | 890/1000 [41:50<05:10,  2.82s/it]Epoch:   891
max of grad d_p:  tensor(6480.8320, device='cuda:0')
min of grad d_p:  tensor(-29449.7012, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.5571, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-5.6543, device='cuda:0') norm:  tensor(23.7161, device='cuda:0') MSE:  tensor(8.9024e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.3027, device='cuda:0') mean:  tensor(0.0138, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(17.0257, device='cuda:0') MSE:  tensor(6.3910e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0128, device='cuda:0')
min of d_p_list:  tensor(-0.0094, device='cuda:0')
Epoch:  891  
Training Loss: 19391.341796875
Test Loss:  18135.935546875
Test Acc:  0.0
Valid Loss:  16021.4560546875
Valid Acc:  0.0
std:  280.0493372763073 
thres:  19.78555546875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 89%|████████▉ | 891/1000 [41:53<05:02,  2.77s/it]Epoch:   892
max of grad d_p:  tensor(6439.6323, device='cuda:0')
min of grad d_p:  tensor(-29291.8145, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.9551, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-6.2480, device='cuda:0') norm:  tensor(24.8920, device='cuda:0') MSE:  tensor(9.3438e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(32.7539, device='cuda:0') mean:  tensor(0.0865, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(120.8412, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0117, device='cuda:0')
min of d_p_list:  tensor(-0.0109, device='cuda:0')
Epoch:  892  
Training Loss: 19198.240234375
Test Loss:  17954.97265625
Test Acc:  0.0
Valid Loss:  15860.7607421875
Valid Acc:  0.0
std:  277.42676883301027 
thres:  19.588546875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 89%|████████▉ | 892/1000 [41:56<04:54,  2.73s/it]Epoch:   893
max of grad d_p:  tensor(6394.1113, device='cuda:0')
min of grad d_p:  tensor(-29143.5957, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.7953, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-5.8457, device='cuda:0') norm:  tensor(22.3629, device='cuda:0') MSE:  tensor(8.3945e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.3408, device='cuda:0') mean:  tensor(0.0291, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(37.0206, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0095, device='cuda:0')
min of d_p_list:  tensor(-0.0050, device='cuda:0')
Epoch:  893  
Training Loss: 19006.84765625
Test Loss:  17776.533203125
Test Acc:  0.0
Valid Loss:  15702.1923828125
Valid Acc:  0.0
std:  274.6046980081584 
thres:  19.393317187500003
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 89%|████████▉ | 893/1000 [41:58<04:50,  2.72s/it]Epoch:   894
max of grad d_p:  tensor(6352.6172, device='cuda:0')
min of grad d_p:  tensor(-28987.5723, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.9105, device='cuda:0') mean:  tensor(0.0027, device='cuda:0') min:  tensor(-7.8867, device='cuda:0') norm:  tensor(26.8721, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.5374, device='cuda:0') mean:  tensor(0.0056, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(7.6533, device='cuda:0') MSE:  tensor(2.8729e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0098, device='cuda:0')
min of d_p_list:  tensor(-0.0104, device='cuda:0')
Epoch:  894  
Training Loss: 18817.34375
Test Loss:  17598.931640625
Test Acc:  0.0
Valid Loss:  15545.501953125
Valid Acc:  0.0
std:  271.9759005489846 
thres:  19.20008671875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 89%|████████▉ | 894/1000 [42:01<04:57,  2.80s/it]Epoch:   895
max of grad d_p:  tensor(6309.3711, device='cuda:0')
min of grad d_p:  tensor(-28855.3086, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.1832, device='cuda:0') mean:  tensor(0.0026, device='cuda:0') min:  tensor(-6.6276, device='cuda:0') norm:  tensor(26.5494, device='cuda:0') MSE:  tensor(9.9659e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(12.2195, device='cuda:0') mean:  tensor(0.0327, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(46.4494, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0239, device='cuda:0')
min of d_p_list:  tensor(-0.0429, device='cuda:0')
Epoch:  895  
Training Loss: 18630.30078125
Test Loss:  17425.73046875
Test Acc:  0.0
Valid Loss:  15393.24609375
Valid Acc:  0.0
std:  269.1270308085998 
thres:  19.00881484375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 90%|████████▉ | 895/1000 [42:04<04:58,  2.84s/it]Epoch:   896
max of grad d_p:  tensor(6283.5225, device='cuda:0')
min of grad d_p:  tensor(-28718.1641, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.2309, device='cuda:0') mean:  tensor(0.0025, device='cuda:0') min:  tensor(-6.4600, device='cuda:0') norm:  tensor(25.6312, device='cuda:0') MSE:  tensor(9.6213e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.6211, device='cuda:0') mean:  tensor(0.0166, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(24.0944, device='cuda:0') MSE:  tensor(9.0444e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0237, device='cuda:0')
min of d_p_list:  tensor(-0.0299, device='cuda:0')
Epoch:  896  
Training Loss: 18448.80078125
Test Loss:  17260.603515625
Test Acc:  0.0
Valid Loss:  15251.1474609375
Valid Acc:  0.0
std:  265.23912255277946 
thres:  18.820306640625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 90%|████████▉ | 896/1000 [42:07<04:58,  2.87s/it]Epoch:   897
max of grad d_p:  tensor(6242.0039, device='cuda:0')
min of grad d_p:  tensor(-28568.3301, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.8639, device='cuda:0') mean:  tensor(0.0023, device='cuda:0') min:  tensor(-7.1484, device='cuda:0') norm:  tensor(23.1771, device='cuda:0') MSE:  tensor(8.7001e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(14.2085, device='cuda:0') mean:  tensor(0.0397, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(52.4304, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0070, device='cuda:0')
min of d_p_list:  tensor(-0.0090, device='cuda:0')
Epoch:  897  
Training Loss: 18264.947265625
Test Loss:  17087.6171875
Test Acc:  0.0
Valid Loss:  15098.67578125
Valid Acc:  0.0
std:  261.97024322422754 
thres:  18.633648046875003
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 90%|████████▉ | 897/1000 [42:10<04:54,  2.86s/it]Epoch:   898
max of grad d_p:  tensor(6198.1270, device='cuda:0')
min of grad d_p:  tensor(-28411.4961, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.7101, device='cuda:0') mean:  tensor(0.0026, device='cuda:0') min:  tensor(-5.9078, device='cuda:0') norm:  tensor(25.1813, device='cuda:0') MSE:  tensor(9.4524e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.7727, device='cuda:0') mean:  tensor(0.0320, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(40.1704, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0061, device='cuda:0')
min of d_p_list:  tensor(-0.0094, device='cuda:0')
Epoch:  898  
Training Loss: 18083.0625
Test Loss:  16918.873046875
Test Acc:  0.0
Valid Loss:  14949.689453125
Valid Acc:  0.0
std:  259.35795136576303 
thres:  18.448891015624998
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 90%|████████▉ | 898/1000 [42:13<04:51,  2.85s/it]Epoch:   899
max of grad d_p:  tensor(6159.6953, device='cuda:0')
min of grad d_p:  tensor(-28245.7695, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.0007, device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(-6.1518, device='cuda:0') norm:  tensor(21.5607, device='cuda:0') MSE:  tensor(8.0933e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.1555, device='cuda:0') mean:  tensor(0.0185, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(24.1621, device='cuda:0') MSE:  tensor(9.0698e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0379, device='cuda:0')
min of d_p_list:  tensor(-0.0287, device='cuda:0')
Epoch:  899  
Training Loss: 17905.90625
Test Loss:  16755.107421875
Test Acc:  0.0
Valid Loss:  14815.5146484375
Valid Acc:  0.0
std:  256.61804676772033 
thres:  18.266603515625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 90%|████████▉ | 899/1000 [42:15<04:41,  2.79s/it]Epoch:   900
max of grad d_p:  tensor(6108.4888, device='cuda:0')
min of grad d_p:  tensor(-28103.7891, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.5432, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-6.6953, device='cuda:0') norm:  tensor(24.8035, device='cuda:0') MSE:  tensor(9.3106e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(23.5508, device='cuda:0') mean:  tensor(0.0783, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(102.5263, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0154, device='cuda:0')
min of d_p_list:  tensor(-0.0108, device='cuda:0')
Epoch:  900  
Training Loss: 17727.4453125
Test Loss:  16588.341796875
Test Acc:  0.0
Valid Loss:  14667.03125
Valid Acc:  0.0
std:  254.81380540226618 
thres:  18.086032421875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 90%|█████████ | 900/1000 [42:18<04:35,  2.75s/it]Epoch:   901
max of grad d_p:  tensor(6076.6226, device='cuda:0')
min of grad d_p:  tensor(-27959.4609, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.9783, device='cuda:0') mean:  tensor(0.0023, device='cuda:0') min:  tensor(-6.0911, device='cuda:0') norm:  tensor(24.8999, device='cuda:0') MSE:  tensor(9.3468e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(34.0876, device='cuda:0') mean:  tensor(0.0950, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(120.9736, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0072, device='cuda:0')
min of d_p_list:  tensor(-0.0120, device='cuda:0')
Epoch:  901  
Training Loss: 17550.79296875
Test Loss:  16421.697265625
Test Acc:  0.0
Valid Loss:  14519.001953125
Valid Acc:  0.0
std:  252.28839072523047 
thres:  17.906430859375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 90%|█████████ | 901/1000 [42:21<04:30,  2.74s/it]Epoch:   902
max of grad d_p:  tensor(6036.5444, device='cuda:0')
min of grad d_p:  tensor(-27804.5488, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.5029, device='cuda:0') mean:  tensor(0.0023, device='cuda:0') min:  tensor(-7.3555, device='cuda:0') norm:  tensor(24.3321, device='cuda:0') MSE:  tensor(9.1336e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.0800, device='cuda:0') mean:  tensor(0.0129, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(15.9366, device='cuda:0') MSE:  tensor(5.9822e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0097, device='cuda:0')
min of d_p_list:  tensor(-0.0134, device='cuda:0')
Epoch:  902  
Training Loss: 17376.296875
Test Loss:  16258.984375
Test Acc:  0.0
Valid Loss:  14375.494140625
Valid Acc:  0.0
std:  250.12608219093727 
thres:  17.72870078125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 90%|█████████ | 902/1000 [42:23<04:22,  2.68s/it]Epoch:   903
max of grad d_p:  tensor(5995.4961, device='cuda:0')
min of grad d_p:  tensor(-27638.6875, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(3.9680, device='cuda:0') mean:  tensor(0.0021, device='cuda:0') min:  tensor(-6.2080, device='cuda:0') norm:  tensor(22.0692, device='cuda:0') MSE:  tensor(8.2842e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(34.6995, device='cuda:0') mean:  tensor(0.1044, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(134.8159, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0097, device='cuda:0')
min of d_p_list:  tensor(-0.0095, device='cuda:0')
Epoch:  903  
Training Loss: 17203.26953125
Test Loss:  16097.482421875
Test Acc:  0.0
Valid Loss:  14232.4296875
Valid Acc:  0.0
std:  248.40045175065936 
thres:  17.5527421875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 90%|█████████ | 903/1000 [42:26<04:19,  2.67s/it]Epoch:   904
max of grad d_p:  tensor(5953.9175, device='cuda:0')
min of grad d_p:  tensor(-27491.7422, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(4.1361, device='cuda:0') mean:  tensor(0.0022, device='cuda:0') min:  tensor(-6.2973, device='cuda:0') norm:  tensor(25.1899, device='cuda:0') MSE:  tensor(9.4556e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.7134, device='cuda:0') mean:  tensor(0.0096, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(11.8309, device='cuda:0') MSE:  tensor(4.4410e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(7.3680, device='cuda:0')
min of d_p_list:  tensor(-7.6535, device='cuda:0')
Epoch:  904  
Training Loss: 101480.953125
Test Loss:  85861.703125
Test Acc:  0.0
Valid Loss:  73939.828125
Valid Acc:  0.0
std:  33607.054879012874 
thres:  34.2677515625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 90%|█████████ | 904/1000 [42:29<04:21,  2.72s/it]Epoch:   905
max of grad d_p:  tensor(55886.1641, device='cuda:0')
min of grad d_p:  tensor(-15480.4854, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.0469, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-11.3057, device='cuda:0') norm:  tensor(39.2832, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(78.9746, device='cuda:0') mean:  tensor(0.1690, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(249.4444, device='cuda:0') MSE:  tensor(0.0009, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0326, device='cuda:0')
min of d_p_list:  tensor(-0.0292, device='cuda:0')
Epoch:  905  
Training Loss: 100469.09375
Test Loss:  85007.0
Test Acc:  0.0
Valid Loss:  73201.21875
Valid Acc:  0.0
std:  40956.00221593075 
thres:  50.81608125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 90%|█████████ | 905/1000 [42:31<04:15,  2.69s/it]Epoch:   906
max of grad d_p:  tensor(55506.7891, device='cuda:0')
min of grad d_p:  tensor(-15386.5176, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.7031, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-12.1680, device='cuda:0') norm:  tensor(41.0440, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.6302, device='cuda:0') mean:  tensor(0.0177, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(26.1763, device='cuda:0') MSE:  tensor(9.8259e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0113, device='cuda:0')
min of d_p_list:  tensor(-0.0066, device='cuda:0')
Epoch:  906  
Training Loss: 99467.9375
Test Loss:  84158.7578125
Test Acc:  0.0
Valid Loss:  72471.65625
Valid Acc:  0.0
std:  40756.12981150658 
thres:  67.19951015625001
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 91%|█████████ | 906/1000 [42:35<04:27,  2.85s/it]Epoch:   907
max of grad d_p:  tensor(55159.6719, device='cuda:0')
min of grad d_p:  tensor(-15308.5703, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.9961, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(-14.1260, device='cuda:0') norm:  tensor(42.2254, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(97.7324, device='cuda:0') mean:  tensor(0.2407, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(375.5437, device='cuda:0') MSE:  tensor(0.0014, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0127, device='cuda:0')
min of d_p_list:  tensor(-0.0097, device='cuda:0')
Epoch:  907  
Training Loss: 98477.3359375
Test Loss:  83323.3125
Test Acc:  0.0
Valid Loss:  71752.5625
Valid Acc:  0.0
std:  33123.35937851639 
thres:  83.41971796875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 91%|█████████ | 907/1000 [42:38<04:31,  2.92s/it]Epoch:   908
max of grad d_p:  tensor(54788.3203, device='cuda:0')
min of grad d_p:  tensor(-15225.9346, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.5078, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(-12.6182, device='cuda:0') norm:  tensor(39.0827, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(15.1187, device='cuda:0') mean:  tensor(0.0455, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(69.6619, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0093, device='cuda:0')
min of d_p_list:  tensor(-0.0046, device='cuda:0')
Epoch:  908  
Training Loss: 97496.3828125
Test Loss:  82494.703125
Test Acc:  0.0
Valid Loss:  71038.828125
Valid Acc:  0.0
std:  1408.7103293289247 
thres:  99.478340625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 91%|█████████ | 908/1000 [42:41<04:27,  2.91s/it]Epoch:   909
max of grad d_p:  tensor(54414.5547, device='cuda:0')
min of grad d_p:  tensor(-15133.3281, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.2227, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-10.7246, device='cuda:0') norm:  tensor(36.4949, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(11.1362, device='cuda:0') mean:  tensor(0.0252, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(36.3640, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0108, device='cuda:0')
min of d_p_list:  tensor(-0.0073, device='cuda:0')
Epoch:  909  
Training Loss: 96524.0859375
Test Loss:  81669.078125
Test Acc:  0.0
Valid Loss:  70326.5859375
Valid Acc:  0.0
std:  1394.6599177108862 
thres:  98.48696718750001
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 91%|█████████ | 909/1000 [42:43<04:17,  2.83s/it]Epoch:   910
max of grad d_p:  tensor(54115.7227, device='cuda:0')
min of grad d_p:  tensor(-15042.9766, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.5195, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-11.8936, device='cuda:0') norm:  tensor(36.1549, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(83.7402, device='cuda:0') mean:  tensor(0.2508, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(377.9367, device='cuda:0') MSE:  tensor(0.0014, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0122, device='cuda:0')
min of d_p_list:  tensor(-0.0076, device='cuda:0')
Epoch:  910  
Training Loss: 95562.328125
Test Loss:  80854.703125
Test Acc:  0.0
Valid Loss:  69624.671875
Valid Acc:  0.0
std:  1380.9271948037785 
thres:  97.5056140625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 91%|█████████ | 910/1000 [42:46<04:13,  2.81s/it]Epoch:   911
max of grad d_p:  tensor(53756.0039, device='cuda:0')
min of grad d_p:  tensor(-14961.0605, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.0352, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-14.3828, device='cuda:0') norm:  tensor(40.5701, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(17.0379, device='cuda:0') mean:  tensor(0.0385, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(60.9456, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0288, device='cuda:0')
min of d_p_list:  tensor(-0.0284, device='cuda:0')
Epoch:  911  
Training Loss: 94608.421875
Test Loss:  80052.96875
Test Acc:  0.0
Valid Loss:  68932.3046875
Valid Acc:  0.0
std:  1367.8326259282278 
thres:  96.5337109375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 91%|█████████ | 911/1000 [42:49<04:09,  2.80s/it]Epoch:   912
max of grad d_p:  tensor(53278.4023, device='cuda:0')
min of grad d_p:  tensor(-14817.4004, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.3438, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-6.8828, device='cuda:0') norm:  tensor(31.9661, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(59.2552, device='cuda:0') mean:  tensor(0.1278, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(178.5186, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0138, device='cuda:0')
min of d_p_list:  tensor(-0.0126, device='cuda:0')
Epoch:  912  
Training Loss: 93665.421875
Test Loss:  79239.2265625
Test Acc:  0.0
Valid Loss:  68231.90625
Valid Acc:  0.0
std:  1354.4985108314909 
thres:  95.57132812500001
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 91%|█████████ | 912/1000 [42:51<04:02,  2.76s/it]Epoch:   913
max of grad d_p:  tensor(52980.2109, device='cuda:0')
min of grad d_p:  tensor(-14754.2266, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.6289, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-9.7080, device='cuda:0') norm:  tensor(33.7288, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(73.3000, device='cuda:0') mean:  tensor(0.1191, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(183.2374, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0231, device='cuda:0')
min of d_p_list:  tensor(-0.0391, device='cuda:0')
Epoch:  913  
Training Loss: 92732.1015625
Test Loss:  78461.59375
Test Acc:  0.0
Valid Loss:  67564.203125
Valid Acc:  0.0
std:  1340.8227203283188 
thres:  94.61847187500001
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 91%|█████████▏| 913/1000 [42:54<04:00,  2.76s/it]Epoch:   914
max of grad d_p:  tensor(52746.7695, device='cuda:0')
min of grad d_p:  tensor(-14647.9814, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.6172, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-11.1172, device='cuda:0') norm:  tensor(39.0221, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(52.4148, device='cuda:0') mean:  tensor(0.1320, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(185.4082, device='cuda:0') MSE:  tensor(0.0007, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0104, device='cuda:0')
min of d_p_list:  tensor(-0.0087, device='cuda:0')
Epoch:  914  
Training Loss: 91807.84375
Test Loss:  77684.25
Test Acc:  0.0
Valid Loss:  66893.9296875
Valid Acc:  0.0
std:  1327.305937932583 
thres:  93.6752234375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 91%|█████████▏| 914/1000 [42:57<04:03,  2.83s/it]Epoch:   915
max of grad d_p:  tensor(52406.8594, device='cuda:0')
min of grad d_p:  tensor(-14558.4902, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.5000, device='cuda:0') mean:  tensor(0.0011, device='cuda:0') min:  tensor(-12.4053, device='cuda:0') norm:  tensor(37.9153, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(11.7329, device='cuda:0') mean:  tensor(0.0291, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(43.4901, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1017, device='cuda:0')
min of d_p_list:  tensor(-0.1098, device='cuda:0')
Epoch:  915  
Training Loss: 90679.1640625
Test Loss:  76567.5
Test Acc:  0.0
Valid Loss:  66004.9375
Valid Acc:  0.0
std:  1375.12578981256 
thres:  92.698590625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 92%|█████████▏| 915/1000 [43:00<04:05,  2.89s/it]Epoch:   916
max of grad d_p:  tensor(51499.8867, device='cuda:0')
min of grad d_p:  tensor(-14459.8926, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.8984, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(-12.2461, device='cuda:0') norm:  tensor(34.2062, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(239.6047, device='cuda:0') mean:  tensor(0.5769, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(867.7070, device='cuda:0') MSE:  tensor(0.0033, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0145, device='cuda:0')
min of d_p_list:  tensor(-0.0144, device='cuda:0')
Epoch:  916  
Training Loss: 89775.390625
Test Loss:  75804.796875
Test Acc:  0.0
Valid Loss:  65347.296875
Valid Acc:  0.0
std:  1391.4639278735335 
thres:  91.731984375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 92%|█████████▏| 916/1000 [43:03<03:56,  2.81s/it]Epoch:   917
max of grad d_p:  tensor(51171.6016, device='cuda:0')
min of grad d_p:  tensor(-14353.7539, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.2188, device='cuda:0') mean:  tensor(0.0017, device='cuda:0') min:  tensor(-12.4883, device='cuda:0') norm:  tensor(34.6977, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(66.4648, device='cuda:0') mean:  tensor(0.3571, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(485.8607, device='cuda:0') MSE:  tensor(0.0018, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0105, device='cuda:0')
min of d_p_list:  tensor(-0.0070, device='cuda:0')
Epoch:  917  
Training Loss: 88880.671875
Test Loss:  75047.3671875
Test Acc:  0.0
Valid Loss:  64694.390625
Valid Acc:  0.0
std:  1377.9619157738875 
thres:  90.775034375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 92%|█████████▏| 917/1000 [43:05<03:46,  2.73s/it]Epoch:   918
max of grad d_p:  tensor(50850.3672, device='cuda:0')
min of grad d_p:  tensor(-14275.0586, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.1406, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-6.7500, device='cuda:0') norm:  tensor(29.0217, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.4761, device='cuda:0') mean:  tensor(0.0177, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(25.8963, device='cuda:0') MSE:  tensor(9.7208e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0114, device='cuda:0')
min of d_p_list:  tensor(-0.0078, device='cuda:0')
Epoch:  918  
Training Loss: 87995.125
Test Loss:  74298.765625
Test Acc:  0.0
Valid Loss:  64045.5703125
Valid Acc:  0.0
std:  1334.4579403417015 
thres:  89.82763906250001
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 92%|█████████▏| 918/1000 [43:08<03:40,  2.69s/it]Epoch:   919
max of grad d_p:  tensor(50559.9375, device='cuda:0')
min of grad d_p:  tensor(-14193.1250, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.2539, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-11.5010, device='cuda:0') norm:  tensor(34.8716, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.5088, device='cuda:0') mean:  tensor(0.0159, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(24.2492, device='cuda:0') MSE:  tensor(9.1025e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0110, device='cuda:0')
min of d_p_list:  tensor(-0.0062, device='cuda:0')
Epoch:  919  
Training Loss: 87118.328125
Test Loss:  73556.109375
Test Acc:  0.0
Valid Loss:  63404.6953125
Valid Acc:  0.0
std:  1258.946683933947 
thres:  88.88973593749999
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 92%|█████████▏| 919/1000 [43:11<03:37,  2.69s/it]Epoch:   920
max of grad d_p:  tensor(50231.8828, device='cuda:0')
min of grad d_p:  tensor(-14120.4844, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.0508, device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(-13.0518, device='cuda:0') norm:  tensor(35.8457, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(10598.6865, device='cuda:0') mean:  tensor(54.6482, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(74219.5781, device='cuda:0') MSE:  tensor(0.2786, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0144, device='cuda:0')
min of d_p_list:  tensor(-0.0108, device='cuda:0')
Epoch:  920  
Training Loss: 86250.09375
Test Loss:  72819.1015625
Test Acc:  0.0
Valid Loss:  62771.5234375
Valid Acc:  0.0
std:  1246.3594073794611 
thres:  88.003921875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 92%|█████████▏| 920/1000 [43:14<03:47,  2.84s/it]Epoch:   921
max of grad d_p:  tensor(49908.5703, device='cuda:0')
min of grad d_p:  tensor(-14042.4238, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.5039, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-11.6514, device='cuda:0') norm:  tensor(32.7741, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(16.9370, device='cuda:0') mean:  tensor(0.0453, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(63.7618, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0102, device='cuda:0')
min of d_p_list:  tensor(-0.0058, device='cuda:0')
Epoch:  921  
Training Loss: 85390.78125
Test Loss:  72092.8984375
Test Acc:  0.0
Valid Loss:  62145.640625
Valid Acc:  0.0
std:  1233.896379875365 
thres:  87.127
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 92%|█████████▏| 921/1000 [43:17<03:46,  2.87s/it]Epoch:   922
max of grad d_p:  tensor(49573.1289, device='cuda:0')
min of grad d_p:  tensor(-13952.8975, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.7852, device='cuda:0') mean:  tensor(0.0018, device='cuda:0') min:  tensor(-14.7021, device='cuda:0') norm:  tensor(35.9463, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(17.2197, device='cuda:0') mean:  tensor(0.0611, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(88.8371, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0287, device='cuda:0')
min of d_p_list:  tensor(-0.0175, device='cuda:0')
Epoch:  922  
Training Loss: 84540.90625
Test Loss:  71401.359375
Test Acc:  0.0
Valid Loss:  61547.0859375
Valid Acc:  0.0
std:  1221.3356691740707 
thres:  86.259046875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 92%|█████████▏| 922/1000 [43:20<03:51,  2.96s/it]Epoch:   923
max of grad d_p:  tensor(49190.4844, device='cuda:0')
min of grad d_p:  tensor(-13867.2891, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.6680, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(-12.0557, device='cuda:0') norm:  tensor(33.0736, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(30.7537, device='cuda:0') mean:  tensor(0.0801, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(117.5086, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0218, device='cuda:0')
min of d_p_list:  tensor(-0.0068, device='cuda:0')
Epoch:  923  
Training Loss: 83698.828125
Test Loss:  70680.078125
Test Acc:  0.0
Valid Loss:  60926.30859375
Valid Acc:  0.0
std:  1208.9188151489302 
thres:  85.3997875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 92%|█████████▏| 923/1000 [43:23<03:43,  2.90s/it]Epoch:   924
max of grad d_p:  tensor(48851.8320, device='cuda:0')
min of grad d_p:  tensor(-13781.2783, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.9531, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(-12.2461, device='cuda:0') norm:  tensor(31.4195, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(26.9258, device='cuda:0') mean:  tensor(0.0449, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(75.2522, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0104, device='cuda:0')
min of d_p_list:  tensor(-0.0054, device='cuda:0')
Epoch:  924  
Training Loss: 82864.765625
Test Loss:  69974.3984375
Test Acc:  0.0
Valid Loss:  60319.2421875
Valid Acc:  0.0
std:  1196.8139994817361 
thres:  84.549075
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 92%|█████████▏| 924/1000 [43:26<03:44,  2.95s/it]Epoch:   925
max of grad d_p:  tensor(48535.1641, device='cuda:0')
min of grad d_p:  tensor(-13699.7207, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.7578, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(-10.2148, device='cuda:0') norm:  tensor(31.2887, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(21.4958, device='cuda:0') mean:  tensor(0.0994, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(137.9795, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0115, device='cuda:0')
min of d_p_list:  tensor(-0.0068, device='cuda:0')
Epoch:  925  
Training Loss: 82039.046875
Test Loss:  69278.15625
Test Acc:  0.0
Valid Loss:  59719.265625
Valid Acc:  0.0
std:  1185.0748491574145 
thres:  83.706865625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 92%|█████████▎| 925/1000 [43:28<03:34,  2.86s/it]Epoch:   926
max of grad d_p:  tensor(48222.4023, device='cuda:0')
min of grad d_p:  tensor(-13620.6514, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.0195, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-8.0371, device='cuda:0') norm:  tensor(30.3143, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(25.4199, device='cuda:0') mean:  tensor(0.0867, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(123.9895, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0112, device='cuda:0')
min of d_p_list:  tensor(-0.0059, device='cuda:0')
Epoch:  926  
Training Loss: 81221.53125
Test Loss:  68585.5625
Test Acc:  0.0
Valid Loss:  59123.3203125
Valid Acc:  0.0
std:  1173.609645620284 
thres:  82.87301562500001
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 93%|█████████▎| 926/1000 [43:31<03:25,  2.78s/it]Epoch:   927
max of grad d_p:  tensor(47905.2812, device='cuda:0')
min of grad d_p:  tensor(-13540.8877, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.1289, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(-13.3184, device='cuda:0') norm:  tensor(33.9138, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(14.6006, device='cuda:0') mean:  tensor(0.0544, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(77.0742, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0108, device='cuda:0')
min of d_p_list:  tensor(-0.0064, device='cuda:0')
Epoch:  927  
Training Loss: 80412.296875
Test Loss:  67902.2734375
Test Acc:  0.0
Valid Loss:  58533.40234375
Valid Acc:  0.0
std:  1161.9804264131078 
thres:  82.04729375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 93%|█████████▎| 927/1000 [43:34<03:24,  2.80s/it]Epoch:   928
max of grad d_p:  tensor(47586.4062, device='cuda:0')
min of grad d_p:  tensor(-13463.3574, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.6016, device='cuda:0') mean:  tensor(0.0013, device='cuda:0') min:  tensor(-9.7812, device='cuda:0') norm:  tensor(31.0708, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(25.6479, device='cuda:0') mean:  tensor(0.0769, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(114.6532, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0237, device='cuda:0')
min of d_p_list:  tensor(-0.0353, device='cuda:0')
Epoch:  928  
Training Loss: 79608.625
Test Loss:  67227.78125
Test Acc:  0.0
Valid Loss:  57951.640625
Valid Acc:  0.0
std:  1151.049930846087 
thres:  81.229253125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 93%|█████████▎| 928/1000 [43:37<03:26,  2.86s/it]Epoch:   929
max of grad d_p:  tensor(47375.5039, device='cuda:0')
min of grad d_p:  tensor(-13321.7188, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.7539, device='cuda:0') mean:  tensor(0.0015, device='cuda:0') min:  tensor(-9.8799, device='cuda:0') norm:  tensor(31.4740, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(11.3804, device='cuda:0') mean:  tensor(0.0315, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(46.5226, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0118, device='cuda:0')
min of d_p_list:  tensor(-0.0132, device='cuda:0')
Epoch:  929  
Training Loss: 78816.28125
Test Loss:  66562.78125
Test Acc:  0.0
Valid Loss:  57376.54296875
Valid Acc:  0.0
std:  1139.6549215850248 
thres:  80.41955625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 93%|█████████▎| 929/1000 [43:40<03:28,  2.93s/it]Epoch:   930
max of grad d_p:  tensor(47080.9219, device='cuda:0')
min of grad d_p:  tensor(-13235.9570, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.6875, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(-9.8193, device='cuda:0') norm:  tensor(29.1235, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(20.2532, device='cuda:0') mean:  tensor(0.0435, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(70.5925, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0157, device='cuda:0')
min of d_p_list:  tensor(-0.0073, device='cuda:0')
Epoch:  930  
Training Loss: 78031.578125
Test Loss:  65898.59375
Test Acc:  0.0
Valid Loss:  56805.9296875
Valid Acc:  0.0
std:  1127.988934877923 
thres:  79.61806250000001
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 93%|█████████▎| 930/1000 [43:43<03:18,  2.83s/it]Epoch:   931
max of grad d_p:  tensor(46766.7969, device='cuda:0')
min of grad d_p:  tensor(-13148.2812, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.4297, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(-12.8818, device='cuda:0') norm:  tensor(35.0324, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(20.9199, device='cuda:0') mean:  tensor(0.0683, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(94.5561, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0128, device='cuda:0')
min of d_p_list:  tensor(-0.0076, device='cuda:0')
Epoch:  931  
Training Loss: 77254.3125
Test Loss:  65241.62890625
Test Acc:  0.0
Valid Loss:  56236.1484375
Valid Acc:  0.0
std:  1116.2645111476295 
thres:  78.82461875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 93%|█████████▎| 931/1000 [43:45<03:13,  2.80s/it]Epoch:   932
max of grad d_p:  tensor(46457.4180, device='cuda:0')
min of grad d_p:  tensor(-13083.1152, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.0625, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-11.2666, device='cuda:0') norm:  tensor(31.7426, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(32.4507, device='cuda:0') mean:  tensor(0.0884, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(128.4640, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0107, device='cuda:0')
min of d_p_list:  tensor(-0.0052, device='cuda:0')
Epoch:  932  
Training Loss: 76484.5546875
Test Loss:  64591.046875
Test Acc:  0.0
Valid Loss:  55675.1171875
Valid Acc:  0.0
std:  1104.5341591770996 
thres:  78.0390703125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 93%|█████████▎| 932/1000 [43:49<03:18,  2.92s/it]Epoch:   933
max of grad d_p:  tensor(46166.7578, device='cuda:0')
min of grad d_p:  tensor(-13000.9121, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.6992, device='cuda:0') mean:  tensor(0.0014, device='cuda:0') min:  tensor(-10.3154, device='cuda:0') norm:  tensor(32.8863, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(25.8286, device='cuda:0') mean:  tensor(0.0654, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(95.7548, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0095, device='cuda:0')
min of d_p_list:  tensor(-0.0065, device='cuda:0')
Epoch:  933  
Training Loss: 75722.453125
Test Loss:  63950.578125
Test Acc:  0.0
Valid Loss:  55122.0625
Valid Acc:  0.0
std:  1093.8670350553853 
thres:  77.2618359375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 93%|█████████▎| 933/1000 [43:52<03:20,  2.99s/it]Epoch:   934
max of grad d_p:  tensor(45868.1094, device='cuda:0')
min of grad d_p:  tensor(-12893.4023, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.6055, device='cuda:0') mean:  tensor(0.0019, device='cuda:0') min:  tensor(-10.9551, device='cuda:0') norm:  tensor(31.9797, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(10.1912, device='cuda:0') mean:  tensor(0.0333, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(48.0777, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0107, device='cuda:0')
min of d_p_list:  tensor(-0.0063, device='cuda:0')
Epoch:  934  
Training Loss: 74967.828125
Test Loss:  63313.03125
Test Acc:  0.0
Valid Loss:  54572.79296875
Valid Acc:  0.0
std:  1083.2154702641258 
thres:  76.4921453125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 93%|█████████▎| 934/1000 [43:55<03:19,  3.03s/it]Epoch:   935
max of grad d_p:  tensor(45570.1211, device='cuda:0')
min of grad d_p:  tensor(-12828.5488, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.7070, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(-7.5586, device='cuda:0') norm:  tensor(30.2357, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.6245, device='cuda:0') mean:  tensor(0.0182, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(25.1216, device='cuda:0') MSE:  tensor(9.4300e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0186, device='cuda:0')
min of d_p_list:  tensor(-0.0280, device='cuda:0')
Epoch:  935  
Training Loss: 74221.625
Test Loss:  62679.046875
Test Acc:  0.0
Valid Loss:  54016.4375
Valid Acc:  0.0
std:  1072.2909416228078 
thres:  75.7301546875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 94%|█████████▎| 935/1000 [43:58<03:14,  2.99s/it]Epoch:   936
max of grad d_p:  tensor(45257.5469, device='cuda:0')
min of grad d_p:  tensor(-12719.6836, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.4375, device='cuda:0') mean:  tensor(0.0016, device='cuda:0') min:  tensor(-10.6514, device='cuda:0') norm:  tensor(31.0037, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.5303, device='cuda:0') mean:  tensor(0.0211, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(29.4396, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2606, device='cuda:0')
min of d_p_list:  tensor(-0.3860, device='cuda:0')
Epoch:  936  
Training Loss: 73741.703125
Test Loss:  62442.3671875
Test Acc:  0.0
Valid Loss:  53891.734375
Valid Acc:  0.0
std:  991.1848437267358 
thres:  75.0276328125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 94%|█████████▎| 936/1000 [44:00<03:03,  2.87s/it]Epoch:   937
max of grad d_p:  tensor(45197.6016, device='cuda:0')
min of grad d_p:  tensor(-11793.7012, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.6094, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(-14.2676, device='cuda:0') norm:  tensor(35.0942, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(22.0524, device='cuda:0') mean:  tensor(0.0887, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(121.1985, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0885, device='cuda:0')
min of d_p_list:  tensor(-0.1145, device='cuda:0')
Epoch:  937  
Training Loss: 73116.328125
Test Loss:  61921.31640625
Test Acc:  0.0
Valid Loss:  53447.1875
Valid Acc:  0.0
std:  913.6422927500469 
thres:  74.3539875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 94%|█████████▎| 937/1000 [44:03<02:55,  2.79s/it]Epoch:   938
max of grad d_p:  tensor(44805.3359, device='cuda:0')
min of grad d_p:  tensor(-11938.1426, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.7305, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-12.4580, device='cuda:0') norm:  tensor(33.7892, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(10.6357, device='cuda:0') mean:  tensor(0.0425, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(55.9575, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0091, device='cuda:0')
min of d_p_list:  tensor(-0.0055, device='cuda:0')
Epoch:  938  
Training Loss: 72387.9765625
Test Loss:  61301.0859375
Test Acc:  0.0
Valid Loss:  52914.9296875
Valid Acc:  0.0
std:  887.9713110116157 
thres:  73.68709218750001
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 94%|█████████▍| 938/1000 [44:06<02:50,  2.74s/it]Epoch:   939
max of grad d_p:  tensor(44513.8398, device='cuda:0')
min of grad d_p:  tensor(-11829.1133, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.1758, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-11.1738, device='cuda:0') norm:  tensor(32.9923, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.7251, device='cuda:0') mean:  tensor(0.0233, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(31.0497, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0150, device='cuda:0')
min of d_p_list:  tensor(-0.0238, device='cuda:0')
Epoch:  939  
Training Loss: 71666.359375
Test Loss:  60689.28125
Test Acc:  0.0
Valid Loss:  52382.8203125
Valid Acc:  0.0
std:  917.1262314821533 
thres:  73.02679843749999
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 94%|█████████▍| 939/1000 [44:08<02:43,  2.68s/it]Epoch:   940
max of grad d_p:  tensor(44256.7070, device='cuda:0')
min of grad d_p:  tensor(-11709.9395, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.6719, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(-14.2041, device='cuda:0') norm:  tensor(36.4822, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(12.2739, device='cuda:0') mean:  tensor(0.0315, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(43.0982, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0088, device='cuda:0')
min of d_p_list:  tensor(-0.0047, device='cuda:0')
Epoch:  940  
Training Loss: 70952.234375
Test Loss:  60082.92578125
Test Acc:  0.0
Valid Loss:  51859.9453125
Valid Acc:  0.0
std:  994.3867603258443 
thres:  72.37292031250001
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 94%|█████████▍| 940/1000 [44:11<02:39,  2.65s/it]Epoch:   941
max of grad d_p:  tensor(43976.2500, device='cuda:0')
min of grad d_p:  tensor(-11592.9375, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.7734, device='cuda:0') mean:  tensor(-0.0001, device='cuda:0') min:  tensor(-7.3584, device='cuda:0') norm:  tensor(28.3610, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(39.7832, device='cuda:0') mean:  tensor(0.1508, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(213.4356, device='cuda:0') MSE:  tensor(0.0008, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0107, device='cuda:0')
min of d_p_list:  tensor(-0.0091, device='cuda:0')
Epoch:  941  
Training Loss: 70245.3828125
Test Loss:  59483.0703125
Test Acc:  0.0
Valid Loss:  51343.25
Valid Acc:  0.0
std:  1015.0885110321623 
thres:  71.67365625000001
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 94%|█████████▍| 941/1000 [44:14<02:39,  2.71s/it]Epoch:   942
max of grad d_p:  tensor(43718.3867, device='cuda:0')
min of grad d_p:  tensor(-11492.4678, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.1641, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-9.0850, device='cuda:0') norm:  tensor(33.3058, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(11.5469, device='cuda:0') mean:  tensor(0.0508, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(72.3743, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0105, device='cuda:0')
min of d_p_list:  tensor(-0.0121, device='cuda:0')
Epoch:  942  
Training Loss: 69545.453125
Test Loss:  58888.6484375
Test Acc:  0.0
Valid Loss:  50831.4765625
Valid Acc:  0.0
std:  1004.9617082621817 
thres:  70.95948125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 94%|█████████▍| 942/1000 [44:16<02:40,  2.77s/it]Epoch:   943
max of grad d_p:  tensor(43451.2969, device='cuda:0')
min of grad d_p:  tensor(-11392.4727, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.5117, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-11.8760, device='cuda:0') norm:  tensor(33.4302, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(34.1282, device='cuda:0') mean:  tensor(0.1108, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(159.1570, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0111, device='cuda:0')
min of d_p_list:  tensor(-0.0053, device='cuda:0')
Epoch:  943  
Training Loss: 68852.421875
Test Loss:  58299.81640625
Test Acc:  0.0
Valid Loss:  50321.78125
Valid Acc:  0.0
std:  994.8679447692025 
thres:  70.2523703125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 94%|█████████▍| 943/1000 [44:20<02:43,  2.87s/it]Epoch:   944
max of grad d_p:  tensor(43175.4766, device='cuda:0')
min of grad d_p:  tensor(-11293.2109, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.6289, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(-11.6182, device='cuda:0') norm:  tensor(33.7868, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.3892, device='cuda:0') mean:  tensor(0.0203, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(29.0561, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0092, device='cuda:0')
min of d_p_list:  tensor(-0.0061, device='cuda:0')
Epoch:  944  
Training Loss: 68166.28125
Test Loss:  57721.1328125
Test Acc:  0.0
Valid Loss:  49823.4453125
Valid Acc:  0.0
std:  984.9978953518917 
thres:  69.5523546875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 94%|█████████▍| 944/1000 [44:23<02:42,  2.89s/it]Epoch:   945
max of grad d_p:  tensor(42905.7422, device='cuda:0')
min of grad d_p:  tensor(-11192.9268, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.2969, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-10.9854, device='cuda:0') norm:  tensor(33.7487, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(10.3687, device='cuda:0') mean:  tensor(0.0294, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(46.3380, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0254, device='cuda:0')
min of d_p_list:  tensor(-0.0245, device='cuda:0')
Epoch:  945  
Training Loss: 67489.3828125
Test Loss:  57152.1953125
Test Acc:  0.0
Valid Loss:  49340.16015625
Valid Acc:  0.0
std:  974.579488602388 
thres:  68.859784375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 94%|█████████▍| 945/1000 [44:26<02:41,  2.93s/it]Epoch:   946
max of grad d_p:  tensor(42569.8125, device='cuda:0')
min of grad d_p:  tensor(-11084.3438, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.2383, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-6.8252, device='cuda:0') norm:  tensor(28.0935, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(16.6260, device='cuda:0') mean:  tensor(0.0397, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(59.3709, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0109, device='cuda:0')
min of d_p_list:  tensor(-0.0059, device='cuda:0')
Epoch:  946  
Training Loss: 66816.8671875
Test Loss:  56582.5
Test Acc:  0.0
Valid Loss:  48845.91796875
Valid Acc:  0.0
std:  964.5423396439476 
thres:  68.17408125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 95%|█████████▍| 946/1000 [44:28<02:35,  2.87s/it]Epoch:   947
max of grad d_p:  tensor(42295.7500, device='cuda:0')
min of grad d_p:  tensor(-10963.5518, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.4414, device='cuda:0') mean:  tensor(0.0011, device='cuda:0') min:  tensor(-15.0713, device='cuda:0') norm:  tensor(37.7640, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.9551, device='cuda:0') mean:  tensor(0.0167, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(25.5282, device='cuda:0') MSE:  tensor(9.5826e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0093, device='cuda:0')
min of d_p_list:  tensor(-0.0051, device='cuda:0')
Epoch:  947  
Training Loss: 66151.234375
Test Loss:  56017.734375
Test Acc:  0.0
Valid Loss:  48357.85546875
Valid Acc:  0.0
std:  954.862723161297 
thres:  67.4952375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 95%|█████████▍| 947/1000 [44:31<02:32,  2.88s/it]Epoch:   948
max of grad d_p:  tensor(42022.8906, device='cuda:0')
min of grad d_p:  tensor(-10859.2041, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.8281, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-12.2539, device='cuda:0') norm:  tensor(34.4659, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(12.3041, device='cuda:0') mean:  tensor(0.0347, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(49.9374, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0155, device='cuda:0')
min of d_p_list:  tensor(-0.0160, device='cuda:0')
Epoch:  948  
Training Loss: 65491.92578125
Test Loss:  55463.0546875
Test Acc:  0.0
Valid Loss:  47877.75390625
Valid Acc:  0.0
std:  945.6781393191001 
thres:  66.82313828125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 95%|█████████▍| 948/1000 [44:34<02:25,  2.80s/it]Epoch:   949
max of grad d_p:  tensor(41740.6445, device='cuda:0')
min of grad d_p:  tensor(-10756.0576, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.6055, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(-13.2871, device='cuda:0') norm:  tensor(32.6244, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(86.5232, device='cuda:0') mean:  tensor(0.2532, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(349.2540, device='cuda:0') MSE:  tensor(0.0013, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1844, device='cuda:0')
min of d_p_list:  tensor(-0.1061, device='cuda:0')
Epoch:  949  
Training Loss: 64844.5859375
Test Loss:  54903.046875
Test Acc:  0.0
Valid Loss:  47383.6328125
Valid Acc:  0.0
std:  935.4613950954188 
thres:  66.15879921875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 95%|█████████▍| 949/1000 [44:36<02:18,  2.72s/it]Epoch:   950
max of grad d_p:  tensor(41849.2773, device='cuda:0')
min of grad d_p:  tensor(-10859.1113, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.0938, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-8.2305, device='cuda:0') norm:  tensor(28.0366, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.6580, device='cuda:0') mean:  tensor(0.0213, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(32.6351, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0087, device='cuda:0')
min of d_p_list:  tensor(-0.0072, device='cuda:0')
Epoch:  950  
Training Loss: 64198.44921875
Test Loss:  54354.85546875
Test Acc:  0.0
Valid Loss:  46912.8515625
Valid Acc:  0.0
std:  925.409179489615 
thres:  65.5006125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 95%|█████████▌| 950/1000 [44:39<02:17,  2.74s/it]Epoch:   951
max of grad d_p:  tensor(41572.9453, device='cuda:0')
min of grad d_p:  tensor(-10749.1787, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.8398, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-9.4248, device='cuda:0') norm:  tensor(28.7238, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(11.9492, device='cuda:0') mean:  tensor(0.0269, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(41.5908, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0084, device='cuda:0')
min of d_p_list:  tensor(-0.0068, device='cuda:0')
Epoch:  951  
Training Loss: 63558.4453125
Test Loss:  53815.5234375
Test Acc:  0.0
Valid Loss:  46447.46875
Valid Acc:  0.0
std:  916.289812904023 
thres:  64.848928125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 95%|█████████▌| 951/1000 [44:42<02:14,  2.74s/it]Epoch:   952
max of grad d_p:  tensor(41316.0547, device='cuda:0')
min of grad d_p:  tensor(-10642.8125, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.9141, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-13.3789, device='cuda:0') norm:  tensor(34.0361, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.8618, device='cuda:0') mean:  tensor(0.0149, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(23.5323, device='cuda:0') MSE:  tensor(8.8334e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0081, device='cuda:0')
min of d_p_list:  tensor(-0.0043, device='cuda:0')
Epoch:  952  
Training Loss: 62925.2421875
Test Loss:  53278.21484375
Test Acc:  0.0
Valid Loss:  45985.53515625
Valid Acc:  0.0
std:  907.8651887524305 
thres:  64.2037296875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 95%|█████████▌| 952/1000 [44:45<02:17,  2.87s/it]Epoch:   953
max of grad d_p:  tensor(41043.7148, device='cuda:0')
min of grad d_p:  tensor(-10532.1543, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.9258, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-12.4111, device='cuda:0') norm:  tensor(32.4268, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(142.5806, device='cuda:0') mean:  tensor(0.8059, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1103.4111, device='cuda:0') MSE:  tensor(0.0041, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0788, device='cuda:0')
min of d_p_list:  tensor(-0.0503, device='cuda:0')
Epoch:  953  
Training Loss: 62302.1328125
Test Loss:  52720.6015625
Test Acc:  0.0
Valid Loss:  45506.421875
Valid Acc:  0.0
std:  899.1953811160342 
thres:  63.56577109375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 95%|█████████▌| 953/1000 [44:48<02:13,  2.84s/it]Epoch:   954
max of grad d_p:  tensor(40887.6562, device='cuda:0')
min of grad d_p:  tensor(-10522.8594, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.7500, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-12.1143, device='cuda:0') norm:  tensor(35.1838, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(31.5024, device='cuda:0') mean:  tensor(0.0822, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(120.0142, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0085, device='cuda:0')
min of d_p_list:  tensor(-0.0149, device='cuda:0')
Epoch:  954  
Training Loss: 61682.21875
Test Loss:  52201.76171875
Test Acc:  0.0
Valid Loss:  45056.9921875
Valid Acc:  0.0
std:  889.387480060013 
thres:  62.93329765625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 95%|█████████▌| 954/1000 [44:51<02:13,  2.90s/it]Epoch:   955
max of grad d_p:  tensor(40606.3555, device='cuda:0')
min of grad d_p:  tensor(-10363.5479, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.3359, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-8.9434, device='cuda:0') norm:  tensor(31.4896, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.8965, device='cuda:0') mean:  tensor(0.0229, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(34.1412, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0096, device='cuda:0')
min of d_p_list:  tensor(-0.0054, device='cuda:0')
Epoch:  955  
Training Loss: 61067.578125
Test Loss:  51683.078125
Test Acc:  0.0
Valid Loss:  44609.86328125
Valid Acc:  0.0
std:  880.327277834007 
thres:  62.3071234375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 96%|█████████▌| 955/1000 [44:54<02:10,  2.91s/it]Epoch:   956
max of grad d_p:  tensor(40352.0312, device='cuda:0')
min of grad d_p:  tensor(-10267.0410, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.2305, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-11.5635, device='cuda:0') norm:  tensor(34.5721, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(14.0006, device='cuda:0') mean:  tensor(0.0478, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(67.3811, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0109, device='cuda:0')
min of d_p_list:  tensor(-0.0098, device='cuda:0')
Epoch:  956  
Training Loss: 60458.8125
Test Loss:  51168.5546875
Test Acc:  0.0
Valid Loss:  44164.98828125
Valid Acc:  0.0
std:  872.2135922876282 
thres:  61.687196875000005
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 96%|█████████▌| 956/1000 [44:57<02:10,  2.97s/it]Epoch:   957
max of grad d_p:  tensor(40122.5859, device='cuda:0')
min of grad d_p:  tensor(-10171.1914, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.8438, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-11.6465, device='cuda:0') norm:  tensor(34.4745, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(11.8079, device='cuda:0') mean:  tensor(0.0278, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(39.3713, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0080, device='cuda:0')
min of d_p_list:  tensor(-0.0056, device='cuda:0')
Epoch:  957  
Training Loss: 59856.4921875
Test Loss:  50662.8046875
Test Acc:  0.0
Valid Loss:  43731.04296875
Valid Acc:  0.0
std:  864.7613424971881 
thres:  61.073446875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 96%|█████████▌| 957/1000 [45:00<02:05,  2.91s/it]Epoch:   958
max of grad d_p:  tensor(39857.9297, device='cuda:0')
min of grad d_p:  tensor(-10075.5195, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.9141, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-7.4248, device='cuda:0') norm:  tensor(30.1580, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(25.5234, device='cuda:0') mean:  tensor(0.0463, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(76.4028, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0103, device='cuda:0')
min of d_p_list:  tensor(-0.0056, device='cuda:0')
Epoch:  958  
Training Loss: 59259.9765625
Test Loss:  50155.2109375
Test Acc:  0.0
Valid Loss:  43293.90234375
Valid Acc:  0.0
std:  856.4021729086722 
thres:  60.465015625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 96%|█████████▌| 958/1000 [45:02<01:59,  2.85s/it]Epoch:   959
max of grad d_p:  tensor(39604.9844, device='cuda:0')
min of grad d_p:  tensor(-9990.7764, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.6562, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-11.3887, device='cuda:0') norm:  tensor(34.0511, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(265.0276, device='cuda:0') mean:  tensor(0.9381, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(1319.2014, device='cuda:0') MSE:  tensor(0.0050, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0101, device='cuda:0')
min of d_p_list:  tensor(-0.0054, device='cuda:0')
Epoch:  959  
Training Loss: 58669.59375
Test Loss:  49650.671875
Test Acc:  0.0
Valid Loss:  42857.9140625
Valid Acc:  0.0
std:  847.8086803527345 
thres:  59.862490625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 96%|█████████▌| 959/1000 [45:05<01:55,  2.82s/it]Epoch:   960
max of grad d_p:  tensor(39372.7461, device='cuda:0')
min of grad d_p:  tensor(-9909.7383, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.9570, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-11.8389, device='cuda:0') norm:  tensor(33.1478, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(36.5259, device='cuda:0') mean:  tensor(0.1104, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(157.6847, device='cuda:0') MSE:  tensor(0.0006, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0089, device='cuda:0')
min of d_p_list:  tensor(-0.0042, device='cuda:0')
Epoch:  960  
Training Loss: 58084.97265625
Test Loss:  49154.9609375
Test Acc:  0.0
Valid Loss:  42429.7109375
Valid Acc:  0.0
std:  839.2907675575398 
thres:  59.26596953125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 96%|█████████▌| 960/1000 [45:08<01:52,  2.81s/it]Epoch:   961
max of grad d_p:  tensor(39122.7266, device='cuda:0')
min of grad d_p:  tensor(-9804.3379, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.8086, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-5.4375, device='cuda:0') norm:  tensor(29.9746, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.2888, device='cuda:0') mean:  tensor(0.0258, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(35.7277, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0231, device='cuda:0')
min of d_p_list:  tensor(-0.0360, device='cuda:0')
Epoch:  961  
Training Loss: 57507.31640625
Test Loss:  48658.2265625
Test Acc:  0.0
Valid Loss:  42003.7578125
Valid Acc:  0.0
std:  830.6341661921056 
thres:  58.6756703125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 96%|█████████▌| 961/1000 [45:11<01:52,  2.88s/it]Epoch:   962
max of grad d_p:  tensor(38867.5781, device='cuda:0')
min of grad d_p:  tensor(-9625.3496, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.3516, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-13.7734, device='cuda:0') norm:  tensor(33.8326, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(9.6318, device='cuda:0') mean:  tensor(0.0364, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(51.5792, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0112, device='cuda:0')
min of d_p_list:  tensor(-0.0071, device='cuda:0')
Epoch:  962  
Training Loss: 56934.09765625
Test Loss:  48175.3046875
Test Acc:  0.0
Valid Loss:  41586.3203125
Valid Acc:  0.0
std:  822.2435949876964 
thres:  58.091191406250005
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 96%|█████████▌| 962/1000 [45:14<01:49,  2.87s/it]Epoch:   963
max of grad d_p:  tensor(38641.1484, device='cuda:0')
min of grad d_p:  tensor(-9558.7080, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.8516, device='cuda:0') mean:  tensor(4.6102e-06, device='cuda:0') min:  tensor(-9.2051, device='cuda:0') norm:  tensor(29.1114, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.1094, device='cuda:0') mean:  tensor(0.0148, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(21.3589, device='cuda:0') MSE:  tensor(8.0176e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0264, device='cuda:0')
min of d_p_list:  tensor(-0.0254, device='cuda:0')
Epoch:  963  
Training Loss: 56368.1484375
Test Loss:  47702.9375
Test Acc:  0.0
Valid Loss:  41175.109375
Valid Acc:  0.0
std:  813.720713423436 
thres:  57.51282578125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 96%|█████████▋| 963/1000 [45:17<01:48,  2.93s/it]Epoch:   964
max of grad d_p:  tensor(38368.5312, device='cuda:0')
min of grad d_p:  tensor(-9342.3330, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(5.0508, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-4.4404, device='cuda:0') norm:  tensor(27.1924, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(17.0381, device='cuda:0') mean:  tensor(0.0507, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(80.0342, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0086, device='cuda:0')
min of d_p_list:  tensor(-0.0048, device='cuda:0')
Epoch:  964  
Training Loss: 55806.4453125
Test Loss:  47227.93359375
Test Acc:  0.0
Valid Loss:  40765.0546875
Valid Acc:  0.0
std:  805.5812029641033 
thres:  56.94019609375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 96%|█████████▋| 964/1000 [45:20<01:48,  3.00s/it]Epoch:   965
max of grad d_p:  tensor(38131.4297, device='cuda:0')
min of grad d_p:  tensor(-9260.2861, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.0430, device='cuda:0') mean:  tensor(0.0001, device='cuda:0') min:  tensor(-11.0898, device='cuda:0') norm:  tensor(33.5360, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.7766, device='cuda:0') mean:  tensor(0.0220, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(30.7254, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0531, device='cuda:0')
min of d_p_list:  tensor(-0.0702, device='cuda:0')
Epoch:  965  
Training Loss: 55239.28125
Test Loss:  46724.87109375
Test Acc:  0.0
Valid Loss:  40337.109375
Valid Acc:  0.0
std:  800.9758279204447 
thres:  56.371057812500005
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 96%|█████████▋| 965/1000 [45:23<01:45,  3.00s/it]Epoch:   966
max of grad d_p:  tensor(37908.1094, device='cuda:0')
min of grad d_p:  tensor(-9293.8984, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.7148, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(-11.3477, device='cuda:0') norm:  tensor(31.4531, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(19.7144, device='cuda:0') mean:  tensor(0.0491, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(68.9319, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0130, device='cuda:0')
min of d_p_list:  tensor(-0.0158, device='cuda:0')
Epoch:  966  
Training Loss: 54688.39453125
Test Loss:  46253.1640625
Test Acc:  0.0
Valid Loss:  39927.1484375
Valid Acc:  0.0
std:  794.8357570328344 
thres:  55.8072734375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 97%|█████████▋| 966/1000 [45:26<01:38,  2.89s/it]Epoch:   967
max of grad d_p:  tensor(37643.0508, device='cuda:0')
min of grad d_p:  tensor(-9185.3887, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.5430, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(-11.5898, device='cuda:0') norm:  tensor(32.8442, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(6.9795, device='cuda:0') mean:  tensor(0.0211, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(32.9421, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0072, device='cuda:0')
min of d_p_list:  tensor(-0.0046, device='cuda:0')
Epoch:  967  
Training Loss: 54143.5859375
Test Loss:  45792.484375
Test Acc:  0.0
Valid Loss:  39530.5625
Valid Acc:  0.0
std:  787.343832196364 
thres:  55.24917109375001
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 97%|█████████▋| 967/1000 [45:28<01:34,  2.85s/it]Epoch:   968
max of grad d_p:  tensor(37403.3047, device='cuda:0')
min of grad d_p:  tensor(-9099.7871, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.6406, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-8.6074, device='cuda:0') norm:  tensor(30.2506, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(15.0962, device='cuda:0') mean:  tensor(0.0519, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(71.6344, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0112, device='cuda:0')
min of d_p_list:  tensor(-0.0067, device='cuda:0')
Epoch:  968  
Training Loss: 53603.8125
Test Loss:  45332.484375
Test Acc:  0.0
Valid Loss:  39134.515625
Valid Acc:  0.0
std:  777.9891415204524 
thres:  54.69630390625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 97%|█████████▋| 968/1000 [45:31<01:30,  2.83s/it]Epoch:   969
max of grad d_p:  tensor(37192.0859, device='cuda:0')
min of grad d_p:  tensor(-9016.1582, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.0469, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-11.0996, device='cuda:0') norm:  tensor(30.0214, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(119.1938, device='cuda:0') mean:  tensor(0.3146, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(480.9644, device='cuda:0') MSE:  tensor(0.0018, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0087, device='cuda:0')
min of d_p_list:  tensor(-0.0053, device='cuda:0')
Epoch:  969  
Training Loss: 53069.65625
Test Loss:  44879.21875
Test Acc:  0.0
Valid Loss:  38744.99609375
Valid Acc:  0.0
std:  767.0594895844281 
thres:  54.14894609375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 97%|█████████▋| 969/1000 [45:34<01:28,  2.85s/it]Epoch:   970
max of grad d_p:  tensor(36963.4961, device='cuda:0')
min of grad d_p:  tensor(-8942.0117, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.7188, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-12.7500, device='cuda:0') norm:  tensor(30.9828, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(12.7899, device='cuda:0') mean:  tensor(0.0332, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(47.5397, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0129, device='cuda:0')
min of d_p_list:  tensor(-0.0139, device='cuda:0')
Epoch:  970  
Training Loss: 52540.7265625
Test Loss:  44430.3046875
Test Acc:  0.0
Valid Loss:  38353.32421875
Valid Acc:  0.0
std:  759.3419691102594 
thres:  53.60923515625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 97%|█████████▋| 970/1000 [45:37<01:24,  2.82s/it]Epoch:   971
max of grad d_p:  tensor(36782.3672, device='cuda:0')
min of grad d_p:  tensor(-8891.7119, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.1562, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-7.5215, device='cuda:0') norm:  tensor(30.2904, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(36.1365, device='cuda:0') mean:  tensor(0.0785, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(121.9252, device='cuda:0') MSE:  tensor(0.0005, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0073, device='cuda:0')
min of d_p_list:  tensor(-0.0057, device='cuda:0')
Epoch:  971  
Training Loss: 52017.09765625
Test Loss:  43985.0546875
Test Acc:  0.0
Valid Loss:  37969.21875
Valid Acc:  0.0
std:  751.8181420583221 
thres:  53.074975781250004
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 97%|█████████▋| 971/1000 [45:40<01:24,  2.92s/it]Epoch:   972
max of grad d_p:  tensor(36572.0078, device='cuda:0')
min of grad d_p:  tensor(-8825.1748, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.2891, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-9.9111, device='cuda:0') norm:  tensor(30.5960, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.2454, device='cuda:0') mean:  tensor(0.0211, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(29.0506, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0084, device='cuda:0')
min of d_p_list:  tensor(-0.0052, device='cuda:0')
Epoch:  972  
Training Loss: 51498.77734375
Test Loss:  43548.1796875
Test Acc:  0.0
Valid Loss:  37591.17578125
Valid Acc:  0.0
std:  744.2612367256753 
thres:  52.5460140625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 97%|█████████▋| 972/1000 [45:43<01:20,  2.86s/it]Epoch:   973
max of grad d_p:  tensor(36339.0430, device='cuda:0')
min of grad d_p:  tensor(-8734.4951, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.6680, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-9.0244, device='cuda:0') norm:  tensor(31.9303, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(16.7356, device='cuda:0') mean:  tensor(0.0551, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(75.7725, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0299, device='cuda:0')
min of d_p_list:  tensor(-0.0399, device='cuda:0')
Epoch:  973  
Training Loss: 50990.06640625
Test Loss:  43126.20703125
Test Acc:  0.0
Valid Loss:  37222.453125
Valid Acc:  0.0
std:  735.5713138174854 
thres:  52.023264843750006
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 97%|█████████▋| 973/1000 [45:45<01:16,  2.83s/it]Epoch:   974
max of grad d_p:  tensor(36122.4492, device='cuda:0')
min of grad d_p:  tensor(-8726.3887, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.2930, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-9.9980, device='cuda:0') norm:  tensor(29.2492, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.5708, device='cuda:0') mean:  tensor(0.0137, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(19.3722, device='cuda:0') MSE:  tensor(7.2718e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0112, device='cuda:0')
min of d_p_list:  tensor(-0.0216, device='cuda:0')
Epoch:  974  
Training Loss: 50482.04296875
Test Loss:  42703.46875
Test Acc:  0.0
Valid Loss:  36851.76171875
Valid Acc:  0.0
std:  727.5448003800581 
thres:  51.505742187500005
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 97%|█████████▋| 974/1000 [45:48<01:14,  2.85s/it]Epoch:   975
max of grad d_p:  tensor(35918.6406, device='cuda:0')
min of grad d_p:  tensor(-8600.5762, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.6602, device='cuda:0') mean:  tensor(0.0009, device='cuda:0') min:  tensor(-12.1855, device='cuda:0') norm:  tensor(30.6085, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(32.7285, device='cuda:0') mean:  tensor(0.0657, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(97.3041, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0089, device='cuda:0')
min of d_p_list:  tensor(-0.0051, device='cuda:0')
Epoch:  975  
Training Loss: 49978.921875
Test Loss:  42277.89453125
Test Acc:  0.0
Valid Loss:  36484.875
Valid Acc:  0.0
std:  720.2813535819673 
thres:  50.99338125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 98%|█████████▊| 975/1000 [45:51<01:11,  2.88s/it]Epoch:   976
max of grad d_p:  tensor(35701.9219, device='cuda:0')
min of grad d_p:  tensor(-8527.0303, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.7422, device='cuda:0') mean:  tensor(0.0012, device='cuda:0') min:  tensor(-14.3926, device='cuda:0') norm:  tensor(36.4773, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(3.7351, device='cuda:0') mean:  tensor(0.0197, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(25.4587, device='cuda:0') MSE:  tensor(9.5565e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0079, device='cuda:0')
min of d_p_list:  tensor(-0.0119, device='cuda:0')
Epoch:  976  
Training Loss: 49480.8203125
Test Loss:  41859.63671875
Test Acc:  0.0
Valid Loss:  36121.2265625
Valid Acc:  0.0
std:  713.7689959547007 
thres:  50.486125781249996
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 98%|█████████▊| 976/1000 [45:54<01:09,  2.89s/it]Epoch:   977
max of grad d_p:  tensor(35477.4297, device='cuda:0')
min of grad d_p:  tensor(-8403.9971, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.8906, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-9.5410, device='cuda:0') norm:  tensor(30.3801, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.6653, device='cuda:0') mean:  tensor(0.0169, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(24.6283, device='cuda:0') MSE:  tensor(9.2448e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0068, device='cuda:0')
min of d_p_list:  tensor(-0.0043, device='cuda:0')
Epoch:  977  
Training Loss: 48987.7734375
Test Loss:  41438.828125
Test Acc:  0.0
Valid Loss:  35761.60546875
Valid Acc:  0.0
std:  707.9405813311995 
thres:  49.983925000000006
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 98%|█████████▊| 977/1000 [45:57<01:06,  2.91s/it]Epoch:   978
max of grad d_p:  tensor(35258.5820, device='cuda:0')
min of grad d_p:  tensor(-8334.5596, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.7188, device='cuda:0') mean:  tensor(0.0010, device='cuda:0') min:  tensor(-13.2422, device='cuda:0') norm:  tensor(33.3706, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(17.6719, device='cuda:0') mean:  tensor(0.0294, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(45.5053, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0084, device='cuda:0')
min of d_p_list:  tensor(-0.0050, device='cuda:0')
Epoch:  978  
Training Loss: 48499.625
Test Loss:  41025.03125
Test Acc:  0.0
Valid Loss:  35404.59375
Valid Acc:  0.0
std:  700.8945162453706 
thres:  49.48583671875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 98%|█████████▊| 978/1000 [46:00<01:04,  2.93s/it]Epoch:   979
max of grad d_p:  tensor(35040.9023, device='cuda:0')
min of grad d_p:  tensor(-8256.3008, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.4844, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-7.9365, device='cuda:0') norm:  tensor(30.0709, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(54.8085, device='cuda:0') mean:  tensor(0.1756, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(248.0400, device='cuda:0') MSE:  tensor(0.0009, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0087, device='cuda:0')
min of d_p_list:  tensor(-0.0051, device='cuda:0')
Epoch:  979  
Training Loss: 48016.33203125
Test Loss:  40619.1640625
Test Acc:  0.0
Valid Loss:  35054.125
Valid Acc:  0.0
std:  693.8784710737384 
thres:  48.99269453125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 98%|█████████▊| 979/1000 [46:03<01:01,  2.93s/it]Epoch:   980
max of grad d_p:  tensor(34815.7969, device='cuda:0')
min of grad d_p:  tensor(-8159.5078, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.4648, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-10.3223, device='cuda:0') norm:  tensor(31.9243, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(18.5507, device='cuda:0') mean:  tensor(0.0601, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(84.3370, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0084, device='cuda:0')
min of d_p_list:  tensor(-0.0083, device='cuda:0')
Epoch:  980  
Training Loss: 47537.9609375
Test Loss:  40216.88671875
Test Acc:  0.0
Valid Loss:  34707.62109375
Valid Acc:  0.0
std:  686.9183442946589 
thres:  48.50450234375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 98%|█████████▊| 980/1000 [46:06<00:58,  2.92s/it]Epoch:   981
max of grad d_p:  tensor(34598.4766, device='cuda:0')
min of grad d_p:  tensor(-8080.0854, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.1992, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-9.9097, device='cuda:0') norm:  tensor(30.4584, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(96.2668, device='cuda:0') mean:  tensor(0.2405, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(344.2665, device='cuda:0') MSE:  tensor(0.0013, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0091, device='cuda:0')
min of d_p_list:  tensor(-0.0041, device='cuda:0')
Epoch:  981  
Training Loss: 47064.0390625
Test Loss:  39815.515625
Test Acc:  0.0
Valid Loss:  34361.30859375
Valid Acc:  0.0
std:  680.1257861745365 
thres:  48.021146093750005
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 98%|█████████▊| 981/1000 [46:09<00:55,  2.92s/it]Epoch:   982
max of grad d_p:  tensor(34388.7969, device='cuda:0')
min of grad d_p:  tensor(-7995.2744, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.1680, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-11.0747, device='cuda:0') norm:  tensor(31.1306, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(128.9349, device='cuda:0') mean:  tensor(0.3116, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(510.2791, device='cuda:0') MSE:  tensor(0.0019, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0199, device='cuda:0')
min of d_p_list:  tensor(-0.0260, device='cuda:0')
Epoch:  982  
Training Loss: 46598.47265625
Test Loss:  39437.453125
Test Acc:  0.0
Valid Loss:  34031.8125
Valid Acc:  0.0
std:  672.4187785188884 
thres:  47.543285937499995
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 98%|█████████▊| 982/1000 [46:12<00:52,  2.91s/it]Epoch:   983
max of grad d_p:  tensor(34130.7891, device='cuda:0')
min of grad d_p:  tensor(-7874.9546, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.9336, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-9.9517, device='cuda:0') norm:  tensor(32.4524, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.1931, device='cuda:0') mean:  tensor(0.0168, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(24.2808, device='cuda:0') MSE:  tensor(9.1144e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0076, device='cuda:0')
min of d_p_list:  tensor(-0.0069, device='cuda:0')
Epoch:  983  
Training Loss: 46134.30078125
Test Loss:  39042.23828125
Test Acc:  0.0
Valid Loss:  33690.6328125
Valid Acc:  0.0
std:  665.1974300360109 
thres:  47.07022109375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 98%|█████████▊| 983/1000 [46:15<00:49,  2.93s/it]Epoch:   984
max of grad d_p:  tensor(33909.3984, device='cuda:0')
min of grad d_p:  tensor(-7803.9810, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.3438, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-10.5874, device='cuda:0') norm:  tensor(28.9783, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.3203, device='cuda:0') mean:  tensor(0.0256, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(36.0708, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0090, device='cuda:0')
min of d_p_list:  tensor(-0.0045, device='cuda:0')
Epoch:  984  
Training Loss: 45674.72265625
Test Loss:  38652.0703125
Test Acc:  0.0
Valid Loss:  33356.58203125
Valid Acc:  0.0
std:  658.498472985747 
thres:  46.60189921875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 98%|█████████▊| 984/1000 [46:18<00:46,  2.91s/it]Epoch:   985
max of grad d_p:  tensor(33696.6562, device='cuda:0')
min of grad d_p:  tensor(-7742.8101, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(10.0586, device='cuda:0') mean:  tensor(0.0008, device='cuda:0') min:  tensor(-11.7354, device='cuda:0') norm:  tensor(31.0095, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.4043, device='cuda:0') mean:  tensor(0.0278, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(36.5494, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0091, device='cuda:0')
min of d_p_list:  tensor(-0.0059, device='cuda:0')
Epoch:  985  
Training Loss: 45219.6796875
Test Loss:  38267.1640625
Test Acc:  0.0
Valid Loss:  33023.109375
Valid Acc:  0.0
std:  652.3089597824417 
thres:  46.13824296875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 98%|█████████▊| 985/1000 [46:20<00:42,  2.86s/it]Epoch:   986
max of grad d_p:  tensor(33477.5391, device='cuda:0')
min of grad d_p:  tensor(-7646.6362, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.9336, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-12.7710, device='cuda:0') norm:  tensor(31.9998, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(17.1262, device='cuda:0') mean:  tensor(0.0890, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(117.1223, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0087, device='cuda:0')
min of d_p_list:  tensor(-0.0054, device='cuda:0')
Epoch:  986  
Training Loss: 44768.98046875
Test Loss:  37884.46875
Test Acc:  0.0
Valid Loss:  32693.205078125
Valid Acc:  0.0
std:  646.8164333126674 
thres:  45.67923125
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 99%|█████████▊| 986/1000 [46:23<00:39,  2.81s/it]Epoch:   987
max of grad d_p:  tensor(33282.3086, device='cuda:0')
min of grad d_p:  tensor(-7595.0850, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.6758, device='cuda:0') mean:  tensor(0.0004, device='cuda:0') min:  tensor(-8.0464, device='cuda:0') norm:  tensor(27.2338, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(14.8881, device='cuda:0') mean:  tensor(0.0478, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(68.0727, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0407, device='cuda:0')
min of d_p_list:  tensor(-0.0472, device='cuda:0')
Epoch:  987  
Training Loss: 44319.703125
Test Loss:  37505.66015625
Test Acc:  0.0
Valid Loss:  32360.56640625
Valid Acc:  0.0
std:  641.3441098829038 
thres:  45.22347734375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 99%|█████████▊| 987/1000 [46:26<00:36,  2.77s/it]Epoch:   988
max of grad d_p:  tensor(33090.9453, device='cuda:0')
min of grad d_p:  tensor(-7382.8799, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.7852, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-9.7183, device='cuda:0') norm:  tensor(28.9679, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(220.1456, device='cuda:0') mean:  tensor(0.6353, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(893.6819, device='cuda:0') MSE:  tensor(0.0034, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0092, device='cuda:0')
min of d_p_list:  tensor(-0.0034, device='cuda:0')
Epoch:  988  
Training Loss: 43878.0546875
Test Loss:  37132.19921875
Test Acc:  0.0
Valid Loss:  32039.541015625
Valid Acc:  0.0
std:  635.4596507956321 
thres:  44.772228125000005
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 99%|█████████▉| 988/1000 [46:28<00:32,  2.73s/it]Epoch:   989
max of grad d_p:  tensor(32885.9727, device='cuda:0')
min of grad d_p:  tensor(-7303.2524, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.2383, device='cuda:0') mean:  tensor(0.0007, device='cuda:0') min:  tensor(-11.0947, device='cuda:0') norm:  tensor(30.3656, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(11.4624, device='cuda:0') mean:  tensor(0.0460, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(59.6106, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0085, device='cuda:0')
min of d_p_list:  tensor(-0.0041, device='cuda:0')
Epoch:  989  
Training Loss: 43440.7890625
Test Loss:  36761.3515625
Test Acc:  0.0
Valid Loss:  31720.185546875
Valid Acc:  0.0
std:  629.1560342084143 
thres:  44.32544140625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 99%|█████████▉| 989/1000 [46:31<00:29,  2.71s/it]Epoch:   990
max of grad d_p:  tensor(32686.6367, device='cuda:0')
min of grad d_p:  tensor(-7232.2632, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.8828, device='cuda:0') mean:  tensor(0.0002, device='cuda:0') min:  tensor(-10.2319, device='cuda:0') norm:  tensor(27.2105, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.6031, device='cuda:0') mean:  tensor(0.0205, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(28.4681, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0101, device='cuda:0')
min of d_p_list:  tensor(-0.0051, device='cuda:0')
Epoch:  990  
Training Loss: 43008.0625
Test Loss:  36395.4296875
Test Acc:  0.0
Valid Loss:  31404.384765625
Valid Acc:  0.0
std:  622.3763393758967 
thres:  43.88311796875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 99%|█████████▉| 990/1000 [46:34<00:26,  2.69s/it]Epoch:   991
max of grad d_p:  tensor(32480.0352, device='cuda:0')
min of grad d_p:  tensor(-7140.5820, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.9141, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-7.4268, device='cuda:0') norm:  tensor(27.3668, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(52.6354, device='cuda:0') mean:  tensor(0.2003, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(268.3204, device='cuda:0') MSE:  tensor(0.0010, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0226, device='cuda:0')
min of d_p_list:  tensor(-0.0268, device='cuda:0')
Epoch:  991  
Training Loss: 42579.3984375
Test Loss:  36027.5546875
Test Acc:  0.0
Valid Loss:  31086.40234375
Valid Acc:  0.0
std:  615.278781044268 
thres:  43.4452015625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 99%|█████████▉| 991/1000 [46:36<00:24,  2.70s/it]Epoch:   992
max of grad d_p:  tensor(32281.2129, device='cuda:0')
min of grad d_p:  tensor(-7078.2754, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.1406, device='cuda:0') mean:  tensor(-0.0001, device='cuda:0') min:  tensor(-7.3979, device='cuda:0') norm:  tensor(26.2381, device='cuda:0') MSE:  tensor(9.8491e-05, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.9490, device='cuda:0') mean:  tensor(0.0273, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(38.6034, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0085, device='cuda:0')
min of d_p_list:  tensor(-0.0042, device='cuda:0')
Epoch:  992  
Training Loss: 42155.01953125
Test Loss:  35667.46875
Test Acc:  0.0
Valid Loss:  30775.3828125
Valid Acc:  0.0
std:  609.1774077806814 
thres:  43.01226484375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 99%|█████████▉| 992/1000 [46:39<00:21,  2.69s/it]Epoch:   993
max of grad d_p:  tensor(32087.1523, device='cuda:0')
min of grad d_p:  tensor(-7003.0986, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.9375, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-11.9990, device='cuda:0') norm:  tensor(31.8226, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(10.9296, device='cuda:0') mean:  tensor(0.0273, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(41.4738, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0086, device='cuda:0')
min of d_p_list:  tensor(-0.0071, device='cuda:0')
Epoch:  993  
Training Loss: 41735.13671875
Test Loss:  35311.9375
Test Acc:  0.0
Valid Loss:  30470.46875
Valid Acc:  0.0
std:  603.0804723615239 
thres:  42.583681250000005
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 99%|█████████▉| 993/1000 [46:42<00:19,  2.72s/it]Epoch:   994
max of grad d_p:  tensor(31880.7578, device='cuda:0')
min of grad d_p:  tensor(-6925.4600, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(6.8594, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-8.7808, device='cuda:0') norm:  tensor(27.0188, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(34.5210, device='cuda:0') mean:  tensor(0.0486, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(75.4402, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0170, device='cuda:0')
min of d_p_list:  tensor(-0.0103, device='cuda:0')
Epoch:  994  
Training Loss: 41319.0703125
Test Loss:  34958.67578125
Test Acc:  0.0
Valid Loss:  30170.69140625
Valid Acc:  0.0
std:  597.1263201190809 
thres:  42.1593375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 99%|█████████▉| 994/1000 [46:44<00:16,  2.70s/it]Epoch:   995
max of grad d_p:  tensor(31665.2070, device='cuda:0')
min of grad d_p:  tensor(-6890.0898, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.0117, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-11.2061, device='cuda:0') norm:  tensor(28.7568, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(28.3547, device='cuda:0') mean:  tensor(0.0859, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(115.4817, device='cuda:0') MSE:  tensor(0.0004, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0081, device='cuda:0')
min of d_p_list:  tensor(-0.0041, device='cuda:0')
Epoch:  995  
Training Loss: 40907.3828125
Test Loss:  34608.625
Test Acc:  0.0
Valid Loss:  29868.787109375
Valid Acc:  0.0
std:  591.1488128936704 
thres:  41.7392015625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
100%|█████████▉| 995/1000 [46:47<00:13,  2.76s/it]Epoch:   996
max of grad d_p:  tensor(31467.4121, device='cuda:0')
min of grad d_p:  tensor(-6806.4302, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.3164, device='cuda:0') mean:  tensor(0.0003, device='cuda:0') min:  tensor(-10.8818, device='cuda:0') norm:  tensor(29.7528, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(4.0474, device='cuda:0') mean:  tensor(0.0207, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(26.1704, device='cuda:0') MSE:  tensor(9.8237e-05, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0075, device='cuda:0')
min of d_p_list:  tensor(-0.0046, device='cuda:0')
Epoch:  996  
Training Loss: 40499.6484375
Test Loss:  34262.765625
Test Acc:  0.0
Valid Loss:  29570.125
Valid Acc:  0.0
std:  585.2817686149943 
thres:  41.323251562500005
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
100%|█████████▉| 996/1000 [46:50<00:11,  2.75s/it]Epoch:   997
max of grad d_p:  tensor(31277.7773, device='cuda:0')
min of grad d_p:  tensor(-6738.2705, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(9.4004, device='cuda:0') mean:  tensor(0.0006, device='cuda:0') min:  tensor(-10.9849, device='cuda:0') norm:  tensor(32.0387, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(124.1057, device='cuda:0') mean:  tensor(0.3071, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(443.2562, device='cuda:0') MSE:  tensor(0.0017, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0087, device='cuda:0')
min of d_p_list:  tensor(-0.0044, device='cuda:0')
Epoch:  997  
Training Loss: 40096.0390625
Test Loss:  33920.96875
Test Acc:  0.0
Valid Loss:  29275.63671875
Valid Acc:  0.0
std:  579.5008534151495 
thres:  40.91145546875
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
100%|█████████▉| 997/1000 [46:53<00:08,  2.74s/it]Epoch:   998
max of grad d_p:  tensor(31089.1016, device='cuda:0')
min of grad d_p:  tensor(-6672.0059, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.1523, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-7.9189, device='cuda:0') norm:  tensor(28.7208, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(18.9221, device='cuda:0') mean:  tensor(0.0528, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(75.7964, device='cuda:0') MSE:  tensor(0.0003, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0104, device='cuda:0')
min of d_p_list:  tensor(-0.0044, device='cuda:0')
Epoch:  998  
Training Loss: 39696.30859375
Test Loss:  33579.90625
Test Acc:  0.0
Valid Loss:  28982.171875
Valid Acc:  0.0
std:  573.7374481602074 
thres:  40.50368984375
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
100%|█████████▉| 998/1000 [46:56<00:05,  2.72s/it]Epoch:   999
max of grad d_p:  tensor(30912.3008, device='cuda:0')
min of grad d_p:  tensor(-6622.9878, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(8.6836, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-10.9707, device='cuda:0') norm:  tensor(29.6657, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.9504, device='cuda:0') mean:  tensor(0.0301, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(42.1908, device='cuda:0') MSE:  tensor(0.0002, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0078, device='cuda:0')
min of d_p_list:  tensor(-0.0050, device='cuda:0')
Epoch:  999  
Training Loss: 39300.703125
Test Loss:  33246.82421875
Test Acc:  0.0
Valid Loss:  28694.74609375
Valid Acc:  0.0
std:  568.0570064811318 
thres:  40.10001640625
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
100%|█████████▉| 999/1000 [46:58<00:02,  2.73s/it]Epoch:   1000
max of grad d_p:  tensor(30727.2695, device='cuda:0')
min of grad d_p:  tensor(-6560.4102, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(7.6152, device='cuda:0') mean:  tensor(0.0005, device='cuda:0') min:  tensor(-10.7017, device='cuda:0') norm:  tensor(28.8375, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.9149, device='cuda:0') mean:  tensor(0.0269, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(37.0908, device='cuda:0') MSE:  tensor(0.0001, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2614, device='cuda:0')
min of d_p_list:  tensor(-0.1976, device='cuda:0')
Epoch:  1000  
Training Loss: 38513.4296875
Test Loss:  32514.5078125
Test Acc:  0.0
Valid Loss:  28046.4375
Valid Acc:  0.0
std:  683.0312441308848 
thres:  39.621225781250004
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
100%|██████████| 1000/1000 [47:01<00:00,  2.76s/it]100%|██████████| 1000/1000 [47:01<00:00,  2.82s/it]
