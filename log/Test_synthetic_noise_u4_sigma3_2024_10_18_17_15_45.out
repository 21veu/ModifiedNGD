/nishome/yui/ModifiedNGD/utils/readData.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)
/nishome/yui/anaconda3/envs/ng/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /opt/conda/conda-bld/pytorch_1716905971214/work/torch/csrc/autograd/engine.cpp:1203.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Train info: 
 train data shape: torch.Size([512, 2]), 
 train lable shape: torch.Size([512, 1]), 
 positive / negative: -0.02499326691031456 / 1.0249933004379272
Test info: 
 test data shape: torch.Size([128, 2]), 
 test lable shape: torch.Size([128, 1]), , 
 positive / negative: -0.006046447902917862 / 1.0060464143753052
Valid info: 
 valid data shape: torch.Size([128, 2]), valid lable shape: torch.Size([128, 1]), 
 positive / negative: 0.050523675978183746 / 0.9494763016700745
torch.Size([512, 2]) torch.Size([512])
seed is  2190
---------------------------------------- MNGD ----------------------------------------
OUTPUT CHECK:  torch.Size([512]) tensor(-0.0934, device='cuda:0', grad_fn=<MaxBackward1>) tensor(-0.1214, device='cuda:0', grad_fn=<MinBackward1>) 
TARGET:  torch.Size([512]) tensor(0.5000, device='cuda:0') tensor(-0.5000, device='cuda:0')
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch:   1
Test train Loss:  0.06703334301710129
Test train Acc:  0.0
Test Loss:  0.07140271365642548
Test Acc:  0.0
Valid Loss:  0.08514202386140823
Valid Acc:  0.0
max of grad d_p:  tensor(0.0067, device='cuda:0')
min of grad d_p:  tensor(-0.0852, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0023, device='cuda:0') mean:  tensor(-3.1503e-06, device='cuda:0') min:  tensor(-0.0022, device='cuda:0') norm:  tensor(0.0614, device='cuda:0') MSE:  tensor(2.3039e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(5.8077e-05, device='cuda:0') mean:  tensor(6.1226e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.3268e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0204, device='cuda:0')
min of d_p_list:  tensor(-0.0074, device='cuda:0')
Epoch:  1  
Training Loss: 0.06257871827983763
Test Loss:  0.06626077741384506
Test Acc:  0.0
Valid Loss:  0.07920993119478226
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
  0%|          | 1/1000 [00:03<1:05:25,  3.93s/it]Epoch:   2
max of grad d_p:  tensor(0.0059, device='cuda:0')
min of grad d_p:  tensor(-0.0850, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0028, device='cuda:0') mean:  tensor(-5.3926e-06, device='cuda:0') min:  tensor(-0.0033, device='cuda:0') norm:  tensor(0.0635, device='cuda:0') MSE:  tensor(2.3853e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(1.3366e-05, device='cuda:0') mean:  tensor(2.9553e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.1437e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0033, device='cuda:0')
min of d_p_list:  tensor(-0.0041, device='cuda:0')
Epoch:  2  
Training Loss: 0.061651621013879776
Test Loss:  0.06548731029033661
Test Acc:  0.0
Valid Loss:  0.0781988799571991
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
  0%|          | 2/1000 [00:07<1:01:34,  3.70s/it]Epoch:   3
max of grad d_p:  tensor(0.0058, device='cuda:0')
min of grad d_p:  tensor(-0.0845, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0028, device='cuda:0') mean:  tensor(-5.3936e-06, device='cuda:0') min:  tensor(-0.0039, device='cuda:0') norm:  tensor(0.0599, device='cuda:0') MSE:  tensor(2.2469e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(2.6718e-05, device='cuda:0') mean:  tensor(3.2833e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0003, device='cuda:0') MSE:  tensor(1.2861e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0528, device='cuda:0')
min of d_p_list:  tensor(-0.0409, device='cuda:0')
Epoch:  3  
Training Loss: 0.058730997145175934
Test Loss:  0.06329488009214401
Test Acc:  0.0
Valid Loss:  0.07485443353652954
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  2
  0%|          | 3/1000 [00:11<1:03:41,  3.83s/it]Epoch:   4
max of grad d_p:  tensor(0.0151, device='cuda:0')
min of grad d_p:  tensor(-0.0820, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0140, device='cuda:0') mean:  tensor(-7.1145e-06, device='cuda:0') min:  tensor(-0.0068, device='cuda:0') norm:  tensor(0.0934, device='cuda:0') MSE:  tensor(3.5070e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.2502e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.1934e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0482, device='cuda:0')
min of d_p_list:  tensor(-0.0120, device='cuda:0')
Epoch:  4  
Training Loss: 0.05425383523106575
Test Loss:  0.05806794762611389
Test Acc:  0.0
Valid Loss:  0.06880711764097214
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  2
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
  0%|          | 4/1000 [00:15<1:02:19,  3.75s/it]Epoch:   5
max of grad d_p:  tensor(0.0161, device='cuda:0')
min of grad d_p:  tensor(-0.0806, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0113, device='cuda:0') mean:  tensor(-9.7837e-06, device='cuda:0') min:  tensor(-0.0109, device='cuda:0') norm:  tensor(0.0921, device='cuda:0') MSE:  tensor(3.4575e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(8.4397e-07, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.6325e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0120, device='cuda:0')
min of d_p_list:  tensor(-0.0078, device='cuda:0')
Epoch:  5  
Training Loss: 0.05364259332418442
Test Loss:  0.05755239725112915
Test Acc:  0.0
Valid Loss:  0.06807833164930344
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
  0%|          | 5/1000 [00:19<1:03:28,  3.83s/it]Epoch:   6
max of grad d_p:  tensor(0.0162, device='cuda:0')
min of grad d_p:  tensor(-0.0800, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0126, device='cuda:0') mean:  tensor(-9.0609e-06, device='cuda:0') min:  tensor(-0.0125, device='cuda:0') norm:  tensor(0.0935, device='cuda:0') MSE:  tensor(3.5110e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(2.0178e-06, device='cuda:0') min:  tensor(3.6380e-12, device='cuda:0') norm:  tensor(0.0022, device='cuda:0') MSE:  tensor(8.2401e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0539, device='cuda:0')
min of d_p_list:  tensor(-0.1009, device='cuda:0')
Epoch:  6  
Training Loss: 0.05302530527114868
Test Loss:  0.05641299486160278
Test Acc:  0.0
Valid Loss:  0.06670533120632172
Valid Acc:  0.0
std:  0.0033619686208053046 
thres:  5.6260870397090916e-05
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
  1%|          | 6/1000 [00:22<1:03:33,  3.84s/it]Epoch:   7
max of grad d_p:  tensor(0.0145, device='cuda:0')
min of grad d_p:  tensor(-0.0762, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0143, device='cuda:0') mean:  tensor(-1.0781e-05, device='cuda:0') min:  tensor(-0.0177, device='cuda:0') norm:  tensor(0.1032, device='cuda:0') MSE:  tensor(3.8752e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0002, device='cuda:0') mean:  tensor(8.4416e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0010, device='cuda:0') MSE:  tensor(3.7088e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0455, device='cuda:0')
min of d_p_list:  tensor(-0.0179, device='cuda:0')
Epoch:  7  
Training Loss: 0.0490516722202301
Test Loss:  0.05209283158183098
Test Acc:  0.0
Valid Loss:  0.06149212270975113
Valid Acc:  0.0
std:  0.0030878720587719476 
thres:  5.3740880638360984e-05
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  1%|          | 7/1000 [00:26<1:03:39,  3.85s/it]Epoch:   8
max of grad d_p:  tensor(0.0161, device='cuda:0')
min of grad d_p:  tensor(-0.0743, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0111, device='cuda:0') mean:  tensor(-1.1091e-05, device='cuda:0') min:  tensor(-0.0221, device='cuda:0') norm:  tensor(0.0969, device='cuda:0') MSE:  tensor(3.6366e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(2.7660e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0030, device='cuda:0') MSE:  tensor(1.1406e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1121, device='cuda:0')
min of d_p_list:  tensor(-0.0977, device='cuda:0')
Epoch:  8  
Training Loss: 0.045290157198905945
Test Loss:  0.04795835539698601
Test Acc:  0.0
Valid Loss:  0.055639319121837616
Valid Acc:  0.0
std:  0.0034075503653809933 
thres:  5.1052712649106975e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
  1%|          | 8/1000 [00:30<1:03:13,  3.82s/it]Epoch:   9
max of grad d_p:  tensor(0.0117, device='cuda:0')
min of grad d_p:  tensor(-0.0458, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0130, device='cuda:0') mean:  tensor(-1.3543e-05, device='cuda:0') min:  tensor(-0.0253, device='cuda:0') norm:  tensor(0.1063, device='cuda:0') MSE:  tensor(3.9884e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0019, device='cuda:0') mean:  tensor(9.9908e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0114, device='cuda:0') MSE:  tensor(4.2893e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0097, device='cuda:0')
min of d_p_list:  tensor(-0.0069, device='cuda:0')
Epoch:  9  
Training Loss: 0.04482879862189293
Test Loss:  0.04734998196363449
Test Acc:  0.0
Valid Loss:  0.05491647124290466
Valid Acc:  0.0
std:  0.0037089258412542187 
thres:  4.9167705327272417e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
  1%|          | 9/1000 [00:34<1:02:32,  3.79s/it]Epoch:   10
max of grad d_p:  tensor(0.0119, device='cuda:0')
min of grad d_p:  tensor(-0.0451, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0179, device='cuda:0') mean:  tensor(-1.4206e-05, device='cuda:0') min:  tensor(-0.0258, device='cuda:0') norm:  tensor(0.1116, device='cuda:0') MSE:  tensor(4.1878e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(8.7489e-05, device='cuda:0') mean:  tensor(5.8410e-07, device='cuda:0') min:  tensor(4.5475e-13, device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.4508e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0105, device='cuda:0')
min of d_p_list:  tensor(-0.0083, device='cuda:0')
Epoch:  10  
Training Loss: 0.044377632439136505
Test Loss:  0.046797238290309906
Test Acc:  0.0
Valid Loss:  0.054307207465171814
Valid Acc:  0.0
std:  0.0033025120780421258 
thres:  4.731471315026283e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  1%|          | 10/1000 [00:38<1:03:15,  3.83s/it]Epoch:   11
max of grad d_p:  tensor(0.0127, device='cuda:0')
min of grad d_p:  tensor(-0.0448, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0116, device='cuda:0') mean:  tensor(-1.2875e-05, device='cuda:0') min:  tensor(-0.0237, device='cuda:0') norm:  tensor(0.1043, device='cuda:0') MSE:  tensor(3.9169e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(2.0904e-06, device='cuda:0') min:  tensor(7.2760e-12, device='cuda:0') norm:  tensor(0.0024, device='cuda:0') MSE:  tensor(9.0733e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0202, device='cuda:0')
min of d_p_list:  tensor(-0.0181, device='cuda:0')
Epoch:  11  
Training Loss: 0.04114675521850586
Test Loss:  0.04299551993608475
Test Acc:  0.0
Valid Loss:  0.05000773444771767
Valid Acc:  0.0
std:  0.002519753263089172 
thres:  4.493900313973427e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
  1%|          | 11/1000 [00:41<1:02:06,  3.77s/it]Epoch:   12
max of grad d_p:  tensor(0.0131, device='cuda:0')
min of grad d_p:  tensor(-0.0451, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0179, device='cuda:0') mean:  tensor(-1.4022e-05, device='cuda:0') min:  tensor(-0.0246, device='cuda:0') norm:  tensor(0.1070, device='cuda:0') MSE:  tensor(4.0182e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(5.9742e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.5721e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0043, device='cuda:0')
min of d_p_list:  tensor(-0.0051, device='cuda:0')
Epoch:  12  
Training Loss: 0.04078592732548714
Test Loss:  0.042563870549201965
Test Acc:  0.0
Valid Loss:  0.04950282722711563
Valid Acc:  0.0
std:  0.0019191282684837296 
thres:  4.328585416078568e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
  1%|          | 12/1000 [00:45<1:01:15,  3.72s/it]Epoch:   13
max of grad d_p:  tensor(0.0136, device='cuda:0')
min of grad d_p:  tensor(-0.0448, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0162, device='cuda:0') mean:  tensor(-1.5620e-05, device='cuda:0') min:  tensor(-0.0275, device='cuda:0') norm:  tensor(0.1171, device='cuda:0') MSE:  tensor(4.3949e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(7.0162e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(3.0165e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0476, device='cuda:0')
min of d_p_list:  tensor(-0.0293, device='cuda:0')
Epoch:  13  
Training Loss: 0.04036738723516464
Test Loss:  0.04220263287425041
Test Acc:  0.0
Valid Loss:  0.04888801649212837
Valid Acc:  0.0
std:  0.001900986704772541 
thres:  4.230130016803742e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
  1%|▏         | 13/1000 [00:49<1:01:21,  3.73s/it]Epoch:   14
max of grad d_p:  tensor(0.0114, device='cuda:0')
min of grad d_p:  tensor(-0.0433, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0179, device='cuda:0') mean:  tensor(-1.6636e-05, device='cuda:0') min:  tensor(-0.0291, device='cuda:0') norm:  tensor(0.1293, device='cuda:0') MSE:  tensor(4.8553e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(7.2471e-07, device='cuda:0') min:  tensor(2.2737e-13, device='cuda:0') norm:  tensor(0.0009, device='cuda:0') MSE:  tensor(3.2422e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0086, device='cuda:0')
min of d_p_list:  tensor(-0.0058, device='cuda:0')
Epoch:  14  
Training Loss: 0.03989732265472412
Test Loss:  0.041610877960920334
Test Acc:  0.0
Valid Loss:  0.04821073263883591
Valid Acc:  0.0
std:  0.0015871811910384438 
thres:  4.131500497460365e-05
Preserved_eigens number check:  4
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
  1%|▏         | 14/1000 [00:52<1:01:05,  3.72s/it]Epoch:   15
max of grad d_p:  tensor(0.0119, device='cuda:0')
min of grad d_p:  tensor(-0.0427, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0144, device='cuda:0') mean:  tensor(-1.6043e-05, device='cuda:0') min:  tensor(-0.0415, device='cuda:0') norm:  tensor(0.1336, device='cuda:0') MSE:  tensor(5.0132e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(1.6085e-06, device='cuda:0') min:  tensor(4.5475e-13, device='cuda:0') norm:  tensor(0.0020, device='cuda:0') MSE:  tensor(7.4899e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0483, device='cuda:0')
min of d_p_list:  tensor(-0.0346, device='cuda:0')
Epoch:  15  
Training Loss: 0.03704997897148132
Test Loss:  0.03830878064036369
Test Acc:  0.0
Valid Loss:  0.04439608380198479
Valid Acc:  0.0
std:  0.0014606559771775127 
thres:  3.984947428107262e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  2%|▏         | 15/1000 [00:56<1:01:48,  3.76s/it]Epoch:   16
max of grad d_p:  tensor(0.0103, device='cuda:0')
min of grad d_p:  tensor(-0.0424, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0166, device='cuda:0') mean:  tensor(-1.7318e-05, device='cuda:0') min:  tensor(-0.0312, device='cuda:0') norm:  tensor(0.1286, device='cuda:0') MSE:  tensor(4.8276e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(7.9239e-05, device='cuda:0') mean:  tensor(7.1208e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0008, device='cuda:0') MSE:  tensor(3.0860e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  16  
Training Loss: 0.03677276521921158
Test Loss:  0.03793073445558548
Test Acc:  0.0
Valid Loss:  0.0439867228269577
Valid Acc:  0.0
std:  0.0017102293727010334 
thres:  3.897467628121376e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
  2%|▏         | 16/1000 [01:00<1:01:11,  3.73s/it]Epoch:   17
max of grad d_p:  tensor(0.0102, device='cuda:0')
min of grad d_p:  tensor(-0.0422, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0162, device='cuda:0') mean:  tensor(-1.5476e-05, device='cuda:0') min:  tensor(-0.0285, device='cuda:0') norm:  tensor(0.1195, device='cuda:0') MSE:  tensor(4.4869e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(2.3830e-06, device='cuda:0') min:  tensor(2.9843e-12, device='cuda:0') norm:  tensor(0.0026, device='cuda:0') MSE:  tensor(9.9145e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0316, device='cuda:0')
min of d_p_list:  tensor(-0.0408, device='cuda:0')
Epoch:  17  
Training Loss: 0.0364907830953598
Test Loss:  0.0377361886203289
Test Acc:  0.0
Valid Loss:  0.043626535683870316
Valid Acc:  0.0
std:  0.0016627606417087188 
thres:  3.811564743518829e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
  2%|▏         | 17/1000 [01:04<1:02:19,  3.80s/it]Epoch:   18
max of grad d_p:  tensor(0.0124, device='cuda:0')
min of grad d_p:  tensor(-0.0403, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0184, device='cuda:0') mean:  tensor(-1.7046e-05, device='cuda:0') min:  tensor(-0.0306, device='cuda:0') norm:  tensor(0.1358, device='cuda:0') MSE:  tensor(5.0985e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(6.5456e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0007, device='cuda:0') MSE:  tensor(2.7994e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0046, device='cuda:0')
min of d_p_list:  tensor(-0.0050, device='cuda:0')
Epoch:  18  
Training Loss: 0.036214157938957214
Test Loss:  0.037416793406009674
Test Acc:  0.0
Valid Loss:  0.04325208067893982
Valid Acc:  0.0
std:  0.0013356146314100052 
thres:  3.728500157594681e-05
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
  2%|▏         | 18/1000 [01:08<1:02:40,  3.83s/it]Epoch:   19
max of grad d_p:  tensor(0.0120, device='cuda:0')
min of grad d_p:  tensor(-0.0401, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0241, device='cuda:0') mean:  tensor(-1.8123e-05, device='cuda:0') min:  tensor(-0.0294, device='cuda:0') norm:  tensor(0.1411, device='cuda:0') MSE:  tensor(5.2975e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(8.8151e-07, device='cuda:0') min:  tensor(1.8190e-12, device='cuda:0') norm:  tensor(0.0011, device='cuda:0') MSE:  tensor(4.0083e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2060, device='cuda:0')
min of d_p_list:  tensor(-0.5133, device='cuda:0')
Epoch:  19  
Training Loss: 0.055140748620033264
Test Loss:  0.049331218004226685
Test Acc:  0.0
Valid Loss:  0.04957877844572067
Valid Acc:  0.0
std:  0.007408784060424331 
thres:  4.0333686769008634e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  2%|▏         | 19/1000 [01:12<1:02:54,  3.85s/it]Epoch:   20
max of grad d_p:  tensor(0.2305, device='cuda:0')
min of grad d_p:  tensor(-0.0581, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0433, device='cuda:0') mean:  tensor(-2.4665e-05, device='cuda:0') min:  tensor(-0.1019, device='cuda:0') norm:  tensor(0.3073, device='cuda:0') MSE:  tensor(1.1536e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2305, device='cuda:0')
min of d_p_list:  tensor(-0.0581, device='cuda:0')
Epoch:  20  
Training Loss: 0.043296150863170624
Test Loss:  0.037688449025154114
Test Acc:  0.0
Valid Loss:  0.038626834750175476
Valid Acc:  0.0
std:  0.007275176014634142 
thres:  4.15829211473465e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
  2%|▏         | 20/1000 [01:16<1:03:21,  3.88s/it]Epoch:   21
max of grad d_p:  tensor(0.1707, device='cuda:0')
min of grad d_p:  tensor(-0.0387, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0290, device='cuda:0') mean:  tensor(-2.4375e-05, device='cuda:0') min:  tensor(-0.0908, device='cuda:0') norm:  tensor(0.2802, device='cuda:0') MSE:  tensor(1.0518e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1707, device='cuda:0')
min of d_p_list:  tensor(-0.0387, device='cuda:0')
Epoch:  21  
Training Loss: 0.037293463945388794
Test Loss:  0.032071273773908615
Test Acc:  0.0
Valid Loss:  0.033452294766902924
Valid Acc:  0.0
std:  0.0072090019811525425 
thres:  4.168706089258194e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
  2%|▏         | 21/1000 [01:19<1:01:22,  3.76s/it]Epoch:   22
max of grad d_p:  tensor(0.1312, device='cuda:0')
min of grad d_p:  tensor(-0.0268, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0220, device='cuda:0') mean:  tensor(-2.6283e-05, device='cuda:0') min:  tensor(-0.0916, device='cuda:0') norm:  tensor(0.2841, device='cuda:0') MSE:  tensor(1.0665e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1312, device='cuda:0')
min of d_p_list:  tensor(-0.0268, device='cuda:0')
Epoch:  22  
Training Loss: 0.03388501703739166
Test Loss:  0.02904512919485569
Test Acc:  0.0
Valid Loss:  0.030702263116836548
Valid Acc:  0.0
std:  0.007646713409615182 
thres:  4.116590768098831e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
  2%|▏         | 22/1000 [01:23<1:00:27,  3.71s/it]Epoch:   23
max of grad d_p:  tensor(0.1039, device='cuda:0')
min of grad d_p:  tensor(-0.0189, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0185, device='cuda:0') mean:  tensor(-2.3353e-05, device='cuda:0') min:  tensor(-0.0744, device='cuda:0') norm:  tensor(0.2404, device='cuda:0') MSE:  tensor(9.0255e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0001, device='cuda:0') mean:  tensor(3.8365e-07, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0006, device='cuda:0') MSE:  tensor(2.2504e-09, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1392, device='cuda:0')
min of d_p_list:  tensor(-0.1201, device='cuda:0')
Epoch:  23  
Training Loss: 0.04646293818950653
Test Loss:  0.03923000395298004
Test Acc:  0.0
Valid Loss:  0.03922954201698303
Valid Acc:  0.0
std:  0.007414746620345176 
thres:  4.321566373109818e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
  2%|▏         | 23/1000 [01:27<1:01:45,  3.79s/it]Epoch:   24
max of grad d_p:  tensor(0.2159, device='cuda:0')
min of grad d_p:  tensor(-0.0679, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0315, device='cuda:0') mean:  tensor(-3.1300e-05, device='cuda:0') min:  tensor(-0.1087, device='cuda:0') norm:  tensor(0.3326, device='cuda:0') MSE:  tensor(1.2486e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.2159, device='cuda:0')
min of d_p_list:  tensor(-0.0679, device='cuda:0')
Epoch:  24  
Training Loss: 0.034796424210071564
Test Loss:  0.02795468643307686
Test Acc:  0.0
Valid Loss:  0.028813228011131287
Valid Acc:  0.0
std:  0.004915078322553095 
thres:  3.914679884910584e-05
Preserved_eigens number check:  4
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
  2%|▏         | 24/1000 [01:31<1:02:22,  3.83s/it]Epoch:   25
max of grad d_p:  tensor(0.1464, device='cuda:0')
min of grad d_p:  tensor(-0.0405, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0302, device='cuda:0') mean:  tensor(-2.4351e-05, device='cuda:0') min:  tensor(-0.0860, device='cuda:0') norm:  tensor(0.2700, device='cuda:0') MSE:  tensor(1.0135e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1464, device='cuda:0')
min of d_p_list:  tensor(-0.0405, device='cuda:0')
Epoch:  25  
Training Loss: 0.0301517304033041
Test Loss:  0.023847654461860657
Test Acc:  0.0
Valid Loss:  0.02519535832107067
Valid Acc:  0.0
std:  0.005475928249110643 
thres:  3.651791475713253e-05
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
  2%|▎         | 25/1000 [01:34<1:00:43,  3.74s/it]Epoch:   26
max of grad d_p:  tensor(0.1065, device='cuda:0')
min of grad d_p:  tensor(-0.0258, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0264, device='cuda:0') mean:  tensor(-2.3671e-05, device='cuda:0') min:  tensor(-0.0834, device='cuda:0') norm:  tensor(0.2691, device='cuda:0') MSE:  tensor(1.0102e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.1065, device='cuda:0')
min of d_p_list:  tensor(-0.0258, device='cuda:0')
Epoch:  26  
Training Loss: 0.027895323932170868
Test Loss:  0.022042108699679375
Test Acc:  0.0
Valid Loss:  0.0236649252474308
Valid Acc:  0.0
std:  0.006418902395218956 
thres:  3.463828675448895e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  3%|▎         | 26/1000 [01:38<1:00:19,  3.72s/it]Epoch:   27
max of grad d_p:  tensor(0.0815, device='cuda:0')
min of grad d_p:  tensor(-0.0170, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0276, device='cuda:0') mean:  tensor(-2.4780e-05, device='cuda:0') min:  tensor(-0.0851, device='cuda:0') norm:  tensor(0.2814, device='cuda:0') MSE:  tensor(1.0561e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0815, device='cuda:0')
min of d_p_list:  tensor(-0.0170, device='cuda:0')
Epoch:  27  
Training Loss: 0.026596810668706894
Test Loss:  0.02108280546963215
Test Acc:  0.0
Valid Loss:  0.02284966967999935
Valid Acc:  0.0
std:  0.007203969346877311 
thres:  3.318064548075199e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(196.8237, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
  3%|▎         | 27/1000 [01:41<1:00:06,  3.71s/it]Epoch:   28
max of grad d_p:  tensor(0.0652, device='cuda:0')
min of grad d_p:  tensor(-0.0132, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0236, device='cuda:0') mean:  tensor(-2.4113e-05, device='cuda:0') min:  tensor(-0.0778, device='cuda:0') norm:  tensor(0.2632, device='cuda:0') MSE:  tensor(9.8786e-07, device='cuda:0')

 check NTK dimension reduction res:  torch.Size([266401, 1]) max:  tensor(0.0043, device='cuda:0') mean:  tensor(9.8716e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0149, device='cuda:0') MSE:  tensor(5.6008e-08, device='cuda:0')
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0411, device='cuda:0')
min of d_p_list:  tensor(-0.0432, device='cuda:0')
Epoch:  28  
Training Loss: 0.025692345574498177
Test Loss:  0.02017032727599144
Test Acc:  0.0
Valid Loss:  0.02182251401245594
Valid Acc:  0.0
std:  0.0032513905985894274 
thres:  2.902652695775032e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
  3%|▎         | 28/1000 [01:45<1:01:17,  3.78s/it]Epoch:   29
max of grad d_p:  tensor(0.0661, device='cuda:0')
min of grad d_p:  tensor(-0.0153, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0273, device='cuda:0') mean:  tensor(-2.9002e-05, device='cuda:0') min:  tensor(-0.0804, device='cuda:0') norm:  tensor(0.2929, device='cuda:0') MSE:  tensor(1.0996e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0661, device='cuda:0')
min of d_p_list:  tensor(-0.0153, device='cuda:0')
Epoch:  29  
Training Loss: 0.024874141439795494
Test Loss:  0.019561737775802612
Test Acc:  0.0
Valid Loss:  0.02127804048359394
Valid Acc:  0.0
std:  0.0018502949081533918 
thres:  2.7042070403695108e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(596.2970, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  3%|▎         | 29/1000 [01:49<59:13,  3.66s/it]  Epoch:   30
max of grad d_p:  tensor(0.0557, device='cuda:0')
min of grad d_p:  tensor(-0.0175, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0275, device='cuda:0') mean:  tensor(-2.4508e-05, device='cuda:0') min:  tensor(-0.0719, device='cuda:0') norm:  tensor(0.2673, device='cuda:0') MSE:  tensor(1.0033e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0557, device='cuda:0')
min of d_p_list:  tensor(-0.0175, device='cuda:0')
Epoch:  30  
Training Loss: 0.024239830672740936
Test Loss:  0.0190727598965168
Test Acc:  0.0
Valid Loss:  0.020807117223739624
Valid Acc:  0.0
std:  0.0012892173398938737 
thres:  2.5859690457582474e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  3%|▎         | 30/1000 [01:53<1:01:02,  3.78s/it]Epoch:   31
max of grad d_p:  tensor(0.0484, device='cuda:0')
min of grad d_p:  tensor(-0.0188, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0299, device='cuda:0') mean:  tensor(-2.6547e-05, device='cuda:0') min:  tensor(-0.0838, device='cuda:0') norm:  tensor(0.3010, device='cuda:0') MSE:  tensor(1.1300e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0484, device='cuda:0')
min of d_p_list:  tensor(-0.0188, device='cuda:0')
Epoch:  31  
Training Loss: 0.023706486448645592
Test Loss:  0.018634334206581116
Test Acc:  0.0
Valid Loss:  0.020357228815555573
Valid Acc:  0.0
std:  0.00102894302232679 
thres:  2.502192296087742e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
  3%|▎         | 31/1000 [01:56<1:00:20,  3.74s/it]Epoch:   32
max of grad d_p:  tensor(0.0432, device='cuda:0')
min of grad d_p:  tensor(-0.0196, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0342, device='cuda:0') mean:  tensor(-2.4989e-05, device='cuda:0') min:  tensor(-0.0803, device='cuda:0') norm:  tensor(0.2915, device='cuda:0') MSE:  tensor(1.0943e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0432, device='cuda:0')
min of d_p_list:  tensor(-0.0196, device='cuda:0')
Epoch:  32  
Training Loss: 0.023233361542224884
Test Loss:  0.01821720227599144
Test Acc:  0.0
Valid Loss:  0.019910134375095367
Valid Acc:  0.0
std:  0.0008659955388693887 
thres:  2.4349233135581017e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
  3%|▎         | 32/1000 [02:00<1:01:23,  3.81s/it]Epoch:   33
max of grad d_p:  tensor(0.0394, device='cuda:0')
min of grad d_p:  tensor(-0.0199, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0302, device='cuda:0') mean:  tensor(-2.4348e-05, device='cuda:0') min:  tensor(-0.0778, device='cuda:0') norm:  tensor(0.2805, device='cuda:0') MSE:  tensor(1.0531e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0394, device='cuda:0')
min of d_p_list:  tensor(-0.0199, device='cuda:0')
Epoch:  33  
Training Loss: 0.022799573838710785
Test Loss:  0.017809664830565453
Test Acc:  0.0
Valid Loss:  0.01946147531270981
Valid Acc:  0.0
std:  0.0007312466911291529 
thres:  2.377067878842354e-05
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
  3%|▎         | 33/1000 [02:04<1:00:35,  3.76s/it]Epoch:   34
max of grad d_p:  tensor(0.0366, device='cuda:0')
min of grad d_p:  tensor(-0.0201, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0308, device='cuda:0') mean:  tensor(-2.5184e-05, device='cuda:0') min:  tensor(-0.0821, device='cuda:0') norm:  tensor(0.2957, device='cuda:0') MSE:  tensor(1.1100e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0366, device='cuda:0')
min of d_p_list:  tensor(-0.0201, device='cuda:0')
Epoch:  34  
Training Loss: 0.022393949329853058
Test Loss:  0.01740773394703865
Test Acc:  0.0
Valid Loss:  0.01901211217045784
Valid Acc:  0.0
std:  0.0006513205378483734 
thres:  2.327464036643505e-05
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
  3%|▎         | 34/1000 [02:08<1:01:09,  3.80s/it]Epoch:   35
max of grad d_p:  tensor(0.0345, device='cuda:0')
min of grad d_p:  tensor(-0.0201, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0325, device='cuda:0') mean:  tensor(-2.7960e-05, device='cuda:0') min:  tensor(-0.0841, device='cuda:0') norm:  tensor(0.3024, device='cuda:0') MSE:  tensor(1.1351e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0345, device='cuda:0')
min of d_p_list:  tensor(-0.0201, device='cuda:0')
Epoch:  35  
Training Loss: 0.022010184824466705
Test Loss:  0.017010673880577087
Test Acc:  0.0
Valid Loss:  0.01856447570025921
Valid Acc:  0.0
std:  0.0005990131189878538 
thres:  2.2828711196780205e-05
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
  4%|▎         | 35/1000 [02:12<1:02:29,  3.89s/it]Epoch:   36
max of grad d_p:  tensor(0.0329, device='cuda:0')
min of grad d_p:  tensor(-0.0200, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0276, device='cuda:0') mean:  tensor(-2.5450e-05, device='cuda:0') min:  tensor(-0.0815, device='cuda:0') norm:  tensor(0.2901, device='cuda:0') MSE:  tensor(1.0891e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0329, device='cuda:0')
min of d_p_list:  tensor(-0.0200, device='cuda:0')
Epoch:  36  
Training Loss: 0.02164449542760849
Test Loss:  0.016618991270661354
Test Acc:  0.0
Valid Loss:  0.018121104687452316
Valid Acc:  0.0
std:  0.0005613554639616274 
thres:  2.2416312992572785e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
  4%|▎         | 36/1000 [02:16<1:01:01,  3.80s/it]Epoch:   37
max of grad d_p:  tensor(0.0317, device='cuda:0')
min of grad d_p:  tensor(-0.0198, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0244, device='cuda:0') mean:  tensor(-2.7945e-05, device='cuda:0') min:  tensor(-0.0774, device='cuda:0') norm:  tensor(0.2820, device='cuda:0') MSE:  tensor(1.0587e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0317, device='cuda:0')
min of d_p_list:  tensor(-0.0198, device='cuda:0')
Epoch:  37  
Training Loss: 0.021294455975294113
Test Loss:  0.0162335317581892
Test Acc:  0.0
Valid Loss:  0.01768413558602333
Valid Acc:  0.0
std:  0.000531925494751218 
thres:  2.2028531879186632e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
  4%|▎         | 37/1000 [02:19<59:50,  3.73s/it]  Epoch:   38
max of grad d_p:  tensor(0.0307, device='cuda:0')
min of grad d_p:  tensor(-0.0196, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0259, device='cuda:0') mean:  tensor(-2.6678e-05, device='cuda:0') min:  tensor(-0.0785, device='cuda:0') norm:  tensor(0.2802, device='cuda:0') MSE:  tensor(1.0519e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0307, device='cuda:0')
min of d_p_list:  tensor(-0.0196, device='cuda:0')
Epoch:  38  
Training Loss: 0.02095837891101837
Test Loss:  0.015855107456445694
Test Acc:  0.0
Valid Loss:  0.017255160957574844
Valid Acc:  0.0
std:  0.0005074338537015583 
thres:  2.1660292893648147e-05
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  4%|▍         | 38/1000 [02:23<58:53,  3.67s/it]Epoch:   39
max of grad d_p:  tensor(0.0298, device='cuda:0')
min of grad d_p:  tensor(-0.0194, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0314, device='cuda:0') mean:  tensor(-2.8964e-05, device='cuda:0') min:  tensor(-0.0887, device='cuda:0') norm:  tensor(0.3105, device='cuda:0') MSE:  tensor(1.1657e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0298, device='cuda:0')
min of d_p_list:  tensor(-0.0194, device='cuda:0')
Epoch:  39  
Training Loss: 0.020635036751627922
Test Loss:  0.015484388917684555
Test Acc:  0.0
Valid Loss:  0.016835298389196396
Valid Acc:  0.0
std:  0.0004861253497215837 
thres:  2.130851037800312e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
  4%|▍         | 39/1000 [02:27<1:00:23,  3.77s/it]Epoch:   40
max of grad d_p:  tensor(0.0291, device='cuda:0')
min of grad d_p:  tensor(-0.0191, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0271, device='cuda:0') mean:  tensor(-2.5473e-05, device='cuda:0') min:  tensor(-0.0831, device='cuda:0') norm:  tensor(0.2877, device='cuda:0') MSE:  tensor(1.0800e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0291, device='cuda:0')
min of d_p_list:  tensor(-0.0191, device='cuda:0')
Epoch:  40  
Training Loss: 0.020323460921645164
Test Loss:  0.01512184552848339
Test Acc:  0.0
Valid Loss:  0.01642526313662529
Valid Acc:  0.0
std:  0.00046702401993706504 
thres:  2.0971165597438814e-05
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  4%|▍         | 40/1000 [02:31<1:00:56,  3.81s/it]Epoch:   41
max of grad d_p:  tensor(0.0285, device='cuda:0')
min of grad d_p:  tensor(-0.0189, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0292, device='cuda:0') mean:  tensor(-2.7341e-05, device='cuda:0') min:  tensor(-0.0819, device='cuda:0') norm:  tensor(0.2881, device='cuda:0') MSE:  tensor(1.0815e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0285, device='cuda:0')
min of d_p_list:  tensor(-0.0189, device='cuda:0')
Epoch:  41  
Training Loss: 0.02002287656068802
Test Loss:  0.014767803251743317
Test Acc:  0.0
Valid Loss:  0.016025478020310402
Valid Acc:  0.0
std:  0.0004495568180120983 
thres:  2.064684182405472e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(200.2786, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
  4%|▍         | 41/1000 [02:34<59:38,  3.73s/it]  Epoch:   42
max of grad d_p:  tensor(0.0280, device='cuda:0')
min of grad d_p:  tensor(-0.0186, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0284, device='cuda:0') mean:  tensor(-2.5725e-05, device='cuda:0') min:  tensor(-0.0836, device='cuda:0') norm:  tensor(0.2918, device='cuda:0') MSE:  tensor(1.0952e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0280, device='cuda:0')
min of d_p_list:  tensor(-0.0186, device='cuda:0')
Epoch:  42  
Training Loss: 0.019732628017663956
Test Loss:  0.014422433450818062
Test Acc:  0.0
Valid Loss:  0.015636131167411804
Valid Acc:  0.0
std:  0.0004333654679756431 
thres:  2.033447623252869e-05
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
  4%|▍         | 42/1000 [02:38<59:34,  3.73s/it]Epoch:   43
max of grad d_p:  tensor(0.0275, device='cuda:0')
min of grad d_p:  tensor(-0.0183, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0319, device='cuda:0') mean:  tensor(-2.7120e-05, device='cuda:0') min:  tensor(-0.0876, device='cuda:0') norm:  tensor(0.3022, device='cuda:0') MSE:  tensor(1.1345e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0275, device='cuda:0')
min of d_p_list:  tensor(-0.0183, device='cuda:0')
Epoch:  43  
Training Loss: 0.019452150911092758
Test Loss:  0.014085810631513596
Test Acc:  0.0
Valid Loss:  0.015257260762155056
Valid Acc:  0.0
std:  0.00041821693108652814 
thres:  2.0033230632543567e-05
Preserved_eigens number check:  11
max of Lambda2 tensor(200.8216, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
  4%|▍         | 43/1000 [02:42<1:00:15,  3.78s/it]Epoch:   44
max of grad d_p:  tensor(0.0271, device='cuda:0')
min of grad d_p:  tensor(-0.0181, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0282, device='cuda:0') mean:  tensor(-3.0366e-05, device='cuda:0') min:  tensor(-0.0858, device='cuda:0') norm:  tensor(0.3021, device='cuda:0') MSE:  tensor(1.1341e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0271, device='cuda:0')
min of d_p_list:  tensor(-0.0181, device='cuda:0')
Epoch:  44  
Training Loss: 0.019180962815880775
Test Loss:  0.013757919892668724
Test Acc:  0.0
Valid Loss:  0.014888795092701912
Valid Acc:  0.0
std:  0.00040394322162034337 
thres:  1.9742415845394135e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(555.0645, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
  4%|▍         | 44/1000 [02:46<1:00:21,  3.79s/it]Epoch:   45
max of grad d_p:  tensor(0.0266, device='cuda:0')
min of grad d_p:  tensor(-0.0178, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0321, device='cuda:0') mean:  tensor(-2.8549e-05, device='cuda:0') min:  tensor(-0.0904, device='cuda:0') norm:  tensor(0.3095, device='cuda:0') MSE:  tensor(1.1619e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0266, device='cuda:0')
min of d_p_list:  tensor(-0.0178, device='cuda:0')
Epoch:  45  
Training Loss: 0.01891862042248249
Test Loss:  0.013438697904348373
Test Acc:  0.0
Valid Loss:  0.01453059259802103
Valid Acc:  0.0
std:  0.00039042560982143376 
thres:  1.94614477455616e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
  4%|▍         | 45/1000 [02:50<1:00:48,  3.82s/it]Epoch:   46
max of grad d_p:  tensor(0.0262, device='cuda:0')
min of grad d_p:  tensor(-0.0176, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0232, device='cuda:0') mean:  tensor(-2.7497e-05, device='cuda:0') min:  tensor(-0.0753, device='cuda:0') norm:  tensor(0.2671, device='cuda:0') MSE:  tensor(1.0027e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0262, device='cuda:0')
min of d_p_list:  tensor(-0.0176, device='cuda:0')
Epoch:  46  
Training Loss: 0.01866474188864231
Test Loss:  0.013128029182553291
Test Acc:  0.0
Valid Loss:  0.014182453975081444
Valid Acc:  0.0
std:  0.00037756926107269245 
thres:  1.9189820811152457e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
  5%|▍         | 46/1000 [02:53<1:01:19,  3.86s/it]Epoch:   47
max of grad d_p:  tensor(0.0258, device='cuda:0')
min of grad d_p:  tensor(-0.0173, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0300, device='cuda:0') mean:  tensor(-2.8394e-05, device='cuda:0') min:  tensor(-0.0851, device='cuda:0') norm:  tensor(0.2961, device='cuda:0') MSE:  tensor(1.1113e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0258, device='cuda:0')
min of d_p_list:  tensor(-0.0173, device='cuda:0')
Epoch:  47  
Training Loss: 0.018418962135910988
Test Loss:  0.012825767509639263
Test Acc:  0.0
Valid Loss:  0.01384415477514267
Valid Acc:  0.0
std:  0.0003653033146613246 
thres:  1.8927087634801868e-05
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
  5%|▍         | 47/1000 [02:57<1:01:49,  3.89s/it]Epoch:   48
max of grad d_p:  tensor(0.0254, device='cuda:0')
min of grad d_p:  tensor(-0.0171, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0307, device='cuda:0') mean:  tensor(-2.9088e-05, device='cuda:0') min:  tensor(-0.0923, device='cuda:0') norm:  tensor(0.3138, device='cuda:0') MSE:  tensor(1.1779e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0254, device='cuda:0')
min of d_p_list:  tensor(-0.0171, device='cuda:0')
Epoch:  48  
Training Loss: 0.01818096451461315
Test Loss:  0.01253175176680088
Test Acc:  0.0
Valid Loss:  0.013515450991690159
Valid Acc:  0.0
std:  0.00035356975378688873 
thres:  1.8672850355505944e-05
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
  5%|▍         | 48/1000 [03:01<1:02:18,  3.93s/it]Epoch:   49
max of grad d_p:  tensor(0.0250, device='cuda:0')
min of grad d_p:  tensor(-0.0169, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0282, device='cuda:0') mean:  tensor(-2.9356e-05, device='cuda:0') min:  tensor(-0.0833, device='cuda:0') norm:  tensor(0.2931, device='cuda:0') MSE:  tensor(1.1003e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0250, device='cuda:0')
min of d_p_list:  tensor(-0.0169, device='cuda:0')
Epoch:  49  
Training Loss: 0.01795044168829918
Test Loss:  0.01224579755216837
Test Acc:  0.0
Valid Loss:  0.013196088373661041
Valid Acc:  0.0
std:  0.0003423207311709173 
thres:  1.8426746129989623e-05
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
  5%|▍         | 49/1000 [03:05<1:01:51,  3.90s/it]Epoch:   50
max of grad d_p:  tensor(0.0247, device='cuda:0')
min of grad d_p:  tensor(-0.0166, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0320, device='cuda:0') mean:  tensor(-2.8535e-05, device='cuda:0') min:  tensor(-0.0921, device='cuda:0') norm:  tensor(0.3139, device='cuda:0') MSE:  tensor(1.1781e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0247, device='cuda:0')
min of d_p_list:  tensor(-0.0166, device='cuda:0')
Epoch:  50  
Training Loss: 0.017727119848132133
Test Loss:  0.011967719532549381
Test Acc:  0.0
Valid Loss:  0.012885808013379574
Valid Acc:  0.0
std:  0.00033151751261792785 
thres:  1.818844601511955e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  5%|▌         | 50/1000 [03:09<1:01:16,  3.87s/it]Epoch:   51
max of grad d_p:  tensor(0.0243, device='cuda:0')
min of grad d_p:  tensor(-0.0164, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0330, device='cuda:0') mean:  tensor(-2.8327e-05, device='cuda:0') min:  tensor(-0.0875, device='cuda:0') norm:  tensor(0.3021, device='cuda:0') MSE:  tensor(1.1338e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0243, device='cuda:0')
min of d_p_list:  tensor(-0.0164, device='cuda:0')
Epoch:  51  
Training Loss: 0.017510732635855675
Test Loss:  0.011697311885654926
Test Acc:  0.0
Valid Loss:  0.012584344483911991
Valid Acc:  0.0
std:  0.00032112598775462344 
thres:  1.7957644164562228e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(554.8574, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  5%|▌         | 51/1000 [03:13<1:01:26,  3.88s/it]Epoch:   52
max of grad d_p:  tensor(0.0239, device='cuda:0')
min of grad d_p:  tensor(-0.0162, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0272, device='cuda:0') mean:  tensor(-2.7664e-05, device='cuda:0') min:  tensor(-0.0949, device='cuda:0') norm:  tensor(0.3036, device='cuda:0') MSE:  tensor(1.1396e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0239, device='cuda:0')
min of d_p_list:  tensor(-0.0162, device='cuda:0')
Epoch:  52  
Training Loss: 0.017301036044955254
Test Loss:  0.011434381827712059
Test Acc:  0.0
Valid Loss:  0.012291442602872849
Valid Acc:  0.0
std:  0.0003111198171552126 
thres:  1.773405894637108e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(203.7720, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
  5%|▌         | 52/1000 [03:17<1:01:27,  3.89s/it]Epoch:   53
max of grad d_p:  tensor(0.0236, device='cuda:0')
min of grad d_p:  tensor(-0.0159, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0355, device='cuda:0') mean:  tensor(-2.8529e-05, device='cuda:0') min:  tensor(-0.0995, device='cuda:0') norm:  tensor(0.3254, device='cuda:0') MSE:  tensor(1.2214e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0236, device='cuda:0')
min of d_p_list:  tensor(-0.0159, device='cuda:0')
Epoch:  53  
Training Loss: 0.017097797244787216
Test Loss:  0.01117872353643179
Test Acc:  0.0
Valid Loss:  0.012006850913167
Valid Acc:  0.0
std:  0.00030147364801111625 
thres:  1.751742549240589e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(204.1320, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
  5%|▌         | 53/1000 [03:21<1:01:20,  3.89s/it]Epoch:   54
max of grad d_p:  tensor(0.0232, device='cuda:0')
min of grad d_p:  tensor(-0.0157, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0249, device='cuda:0') mean:  tensor(-2.9662e-05, device='cuda:0') min:  tensor(-0.0792, device='cuda:0') norm:  tensor(0.2820, device='cuda:0') MSE:  tensor(1.0586e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0232, device='cuda:0')
min of d_p_list:  tensor(-0.0157, device='cuda:0')
Epoch:  54  
Training Loss: 0.016900788992643356
Test Loss:  0.010930132120847702
Test Acc:  0.0
Valid Loss:  0.011730309575796127
Valid Acc:  0.0
std:  0.00029216953737843445 
thres:  1.7307494953274728e-05
Preserved_eigens number check:  11
max of Lambda2 tensor(555.6534, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
  5%|▌         | 54/1000 [03:25<1:01:14,  3.88s/it]Epoch:   55
max of grad d_p:  tensor(0.0229, device='cuda:0')
min of grad d_p:  tensor(-0.0155, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0274, device='cuda:0') mean:  tensor(-2.9371e-05, device='cuda:0') min:  tensor(-0.0808, device='cuda:0') norm:  tensor(0.2824, device='cuda:0') MSE:  tensor(1.0602e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0229, device='cuda:0')
min of d_p_list:  tensor(-0.0155, device='cuda:0')
Epoch:  55  
Training Loss: 0.016709808260202408
Test Loss:  0.010688412934541702
Test Acc:  0.0
Valid Loss:  0.011461581103503704
Valid Acc:  0.0
std:  0.0002831871996274044 
thres:  1.7104032635688783e-05
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
  6%|▌         | 55/1000 [03:29<1:00:49,  3.86s/it]Epoch:   56
max of grad d_p:  tensor(0.0226, device='cuda:0')
min of grad d_p:  tensor(-0.0153, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0283, device='cuda:0') mean:  tensor(-2.8910e-05, device='cuda:0') min:  tensor(-0.0898, device='cuda:0') norm:  tensor(0.3058, device='cuda:0') MSE:  tensor(1.1477e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0226, device='cuda:0')
min of d_p_list:  tensor(-0.0153, device='cuda:0')
Epoch:  56  
Training Loss: 0.016524653881788254
Test Loss:  0.010453369468450546
Test Acc:  0.0
Valid Loss:  0.011200430803000927
Valid Acc:  0.0
std:  0.0002745103053275061 
thres:  1.6906816884875295e-05
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
  6%|▌         | 56/1000 [03:32<1:00:29,  3.85s/it]Epoch:   57
max of grad d_p:  tensor(0.0222, device='cuda:0')
min of grad d_p:  tensor(-0.0151, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0357, device='cuda:0') mean:  tensor(-3.0504e-05, device='cuda:0') min:  tensor(-0.0966, device='cuda:0') norm:  tensor(0.3257, device='cuda:0') MSE:  tensor(1.2227e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0222, device='cuda:0')
min of d_p_list:  tensor(-0.0151, device='cuda:0')
Epoch:  57  
Training Loss: 0.016345135867595673
Test Loss:  0.01022480707615614
Test Acc:  0.0
Valid Loss:  0.010946620255708694
Valid Acc:  0.0
std:  0.00026612302712764854 
thres:  1.671563684940338e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  6%|▌         | 57/1000 [03:36<1:00:50,  3.87s/it]Epoch:   58
max of grad d_p:  tensor(0.0219, device='cuda:0')
min of grad d_p:  tensor(-0.0149, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0288, device='cuda:0') mean:  tensor(-2.9975e-05, device='cuda:0') min:  tensor(-0.0862, device='cuda:0') norm:  tensor(0.2955, device='cuda:0') MSE:  tensor(1.1092e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0219, device='cuda:0')
min of d_p_list:  tensor(-0.0149, device='cuda:0')
Epoch:  58  
Training Loss: 0.016171064227819443
Test Loss:  0.010002534836530685
Test Acc:  0.0
Valid Loss:  0.010699931532144547
Valid Acc:  0.0
std:  0.00025801290016941097 
thres:  1.6530290246009826e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(205.9676, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
  6%|▌         | 58/1000 [03:40<1:00:34,  3.86s/it]Epoch:   59
max of grad d_p:  tensor(0.0216, device='cuda:0')
min of grad d_p:  tensor(-0.0147, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0315, device='cuda:0') mean:  tensor(-3.0970e-05, device='cuda:0') min:  tensor(-0.0939, device='cuda:0') norm:  tensor(0.3135, device='cuda:0') MSE:  tensor(1.1768e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0216, device='cuda:0')
min of d_p_list:  tensor(-0.0147, device='cuda:0')
Epoch:  59  
Training Loss: 0.016002263873815536
Test Loss:  0.009786361828446388
Test Acc:  0.0
Valid Loss:  0.010460138320922852
Valid Acc:  0.0
std:  0.00025017047544100376 
thres:  1.6350585222244262e-05
Preserved_eigens number check:  4
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
  6%|▌         | 59/1000 [03:44<1:00:32,  3.86s/it]Epoch:   60
max of grad d_p:  tensor(0.0212, device='cuda:0')
min of grad d_p:  tensor(-0.0145, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0311, device='cuda:0') mean:  tensor(-2.9580e-05, device='cuda:0') min:  tensor(-0.0871, device='cuda:0') norm:  tensor(0.2941, device='cuda:0') MSE:  tensor(1.1041e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0212, device='cuda:0')
min of d_p_list:  tensor(-0.0145, device='cuda:0')
Epoch:  60  
Training Loss: 0.015838567167520523
Test Loss:  0.00957611296325922
Test Acc:  0.0
Valid Loss:  0.010227035731077194
Valid Acc:  0.0
std:  0.00024258418042386352 
thres:  1.6176337003707888e-05
Preserved_eigens number check:  4
max of Lambda2 tensor(558.1558, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  6%|▌         | 60/1000 [03:48<1:01:12,  3.91s/it]Epoch:   61
max of grad d_p:  tensor(0.0209, device='cuda:0')
min of grad d_p:  tensor(-0.0143, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0331, device='cuda:0') mean:  tensor(-2.5738e-05, device='cuda:0') min:  tensor(-0.0872, device='cuda:0') norm:  tensor(0.2853, device='cuda:0') MSE:  tensor(1.0710e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0209, device='cuda:0')
min of d_p_list:  tensor(-0.0143, device='cuda:0')
Epoch:  61  
Training Loss: 0.01567981019616127
Test Loss:  0.00937160849571228
Test Acc:  0.0
Valid Loss:  0.010000413283705711
Valid Acc:  0.0
std:  0.0002352434804144891 
thres:  1.600736826658249e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
  6%|▌         | 61/1000 [03:52<1:01:14,  3.91s/it]Epoch:   62
max of grad d_p:  tensor(0.0206, device='cuda:0')
min of grad d_p:  tensor(-0.0141, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0311, device='cuda:0') mean:  tensor(-3.2427e-05, device='cuda:0') min:  tensor(-0.0957, device='cuda:0') norm:  tensor(0.3210, device='cuda:0') MSE:  tensor(1.2051e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0206, device='cuda:0')
min of d_p_list:  tensor(-0.0141, device='cuda:0')
Epoch:  62  
Training Loss: 0.01552584022283554
Test Loss:  0.009172677993774414
Test Acc:  0.0
Valid Loss:  0.009780079126358032
Valid Acc:  0.0
std:  0.00022813623530846137 
thres:  1.5843509137630463e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(559.1768, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
  6%|▌         | 62/1000 [03:55<59:48,  3.83s/it]  Epoch:   63
max of grad d_p:  tensor(0.0203, device='cuda:0')
min of grad d_p:  tensor(-0.0139, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0276, device='cuda:0') mean:  tensor(-3.1461e-05, device='cuda:0') min:  tensor(-0.0904, device='cuda:0') norm:  tensor(0.3056, device='cuda:0') MSE:  tensor(1.1471e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0203, device='cuda:0')
min of d_p_list:  tensor(-0.0139, device='cuda:0')
Epoch:  63  
Training Loss: 0.01537649892270565
Test Loss:  0.008979151025414467
Test Acc:  0.0
Valid Loss:  0.009565837681293488
Valid Acc:  0.0
std:  0.00022125555731817537 
thres:  1.5684596076607704e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(559.7124, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
  6%|▋         | 63/1000 [04:00<1:01:02,  3.91s/it]Epoch:   64
max of grad d_p:  tensor(0.0200, device='cuda:0')
min of grad d_p:  tensor(-0.0137, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0295, device='cuda:0') mean:  tensor(-2.9321e-05, device='cuda:0') min:  tensor(-0.0893, device='cuda:0') norm:  tensor(0.3024, device='cuda:0') MSE:  tensor(1.1353e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0200, device='cuda:0')
min of d_p_list:  tensor(-0.0137, device='cuda:0')
Epoch:  64  
Training Loss: 0.015231646597385406
Test Loss:  0.008790872059762478
Test Acc:  0.0
Valid Loss:  0.009357508271932602
Valid Acc:  0.0
std:  0.00021459278283261898 
thres:  1.553047262132168e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
  6%|▋         | 64/1000 [04:03<59:17,  3.80s/it]  Epoch:   65
max of grad d_p:  tensor(0.0197, device='cuda:0')
min of grad d_p:  tensor(-0.0135, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0269, device='cuda:0') mean:  tensor(-3.0776e-05, device='cuda:0') min:  tensor(-0.0869, device='cuda:0') norm:  tensor(0.2939, device='cuda:0') MSE:  tensor(1.1032e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0197, device='cuda:0')
min of d_p_list:  tensor(-0.0135, device='cuda:0')
Epoch:  65  
Training Loss: 0.01509113609790802
Test Loss:  0.008607677184045315
Test Acc:  0.0
Valid Loss:  0.009154902771115303
Valid Acc:  0.0
std:  0.00020814129953593898 
thres:  1.5380986407399177e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(560.8245, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
  6%|▋         | 65/1000 [04:07<59:51,  3.84s/it]Epoch:   66
max of grad d_p:  tensor(0.0194, device='cuda:0')
min of grad d_p:  tensor(-0.0133, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0317, device='cuda:0') mean:  tensor(-3.1430e-05, device='cuda:0') min:  tensor(-0.1027, device='cuda:0') norm:  tensor(0.3235, device='cuda:0') MSE:  tensor(1.2145e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0194, device='cuda:0')
min of d_p_list:  tensor(-0.0133, device='cuda:0')
Epoch:  66  
Training Loss: 0.014954835176467896
Test Loss:  0.00842941552400589
Test Acc:  0.0
Valid Loss:  0.00895785354077816
Valid Acc:  0.0
std:  0.00020189376509480465 
thres:  1.5235991403460502e-05
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
  7%|▋         | 66/1000 [04:11<1:00:04,  3.86s/it]Epoch:   67
max of grad d_p:  tensor(0.0191, device='cuda:0')
min of grad d_p:  tensor(-0.0131, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-3.3346e-05, device='cuda:0') min:  tensor(-0.1019, device='cuda:0') norm:  tensor(0.3377, device='cuda:0') MSE:  tensor(1.2678e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0191, device='cuda:0')
min of d_p_list:  tensor(-0.0131, device='cuda:0')
Epoch:  67  
Training Loss: 0.014822611585259438
Test Loss:  0.008255942724645138
Test Acc:  0.0
Valid Loss:  0.00876619666814804
Valid Acc:  0.0
std:  0.00019584171903973597 
thres:  1.5095345675945283e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
  7%|▋         | 67/1000 [04:15<1:00:45,  3.91s/it]Epoch:   68
max of grad d_p:  tensor(0.0188, device='cuda:0')
min of grad d_p:  tensor(-0.0129, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0339, device='cuda:0') mean:  tensor(-3.1015e-05, device='cuda:0') min:  tensor(-0.0978, device='cuda:0') norm:  tensor(0.3213, device='cuda:0') MSE:  tensor(1.2059e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0188, device='cuda:0')
min of d_p_list:  tensor(-0.0129, device='cuda:0')
Epoch:  68  
Training Loss: 0.014694338664412498
Test Loss:  0.008087114430963993
Test Acc:  0.0
Valid Loss:  0.008579766377806664
Valid Acc:  0.0
std:  0.00018997939157594743 
thres:  1.495891362428665e-05
Preserved_eigens number check:  12
max of Lambda2 tensor(562.5696, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
  7%|▋         | 68/1000 [04:19<59:39,  3.84s/it]  Epoch:   69
max of grad d_p:  tensor(0.0185, device='cuda:0')
min of grad d_p:  tensor(-0.0127, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0315, device='cuda:0') mean:  tensor(-2.9510e-05, device='cuda:0') min:  tensor(-0.0901, device='cuda:0') norm:  tensor(0.2991, device='cuda:0') MSE:  tensor(1.1229e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0185, device='cuda:0')
min of d_p_list:  tensor(-0.0127, device='cuda:0')
Epoch:  69  
Training Loss: 0.01456989161670208
Test Loss:  0.007922793738543987
Test Acc:  0.0
Valid Loss:  0.008398406207561493
Valid Acc:  0.0
std:  0.0001842996272355657 
thres:  1.4826562628149987e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(563.1626, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
  7%|▋         | 69/1000 [04:23<1:00:36,  3.91s/it]Epoch:   70
max of grad d_p:  tensor(0.0182, device='cuda:0')
min of grad d_p:  tensor(-0.0125, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0330, device='cuda:0') mean:  tensor(-2.8580e-05, device='cuda:0') min:  tensor(-0.0921, device='cuda:0') norm:  tensor(0.3001, device='cuda:0') MSE:  tensor(1.1266e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0182, device='cuda:0')
min of d_p_list:  tensor(-0.0125, device='cuda:0')
Epoch:  70  
Training Loss: 0.01444915123283863
Test Loss:  0.007762847933918238
Test Acc:  0.0
Valid Loss:  0.00822196714580059
Valid Acc:  0.0
std:  0.00017879770133380856 
thres:  1.4698165655136109e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
  7%|▋         | 70/1000 [04:27<1:00:45,  3.92s/it]Epoch:   71
max of grad d_p:  tensor(0.0179, device='cuda:0')
min of grad d_p:  tensor(-0.0123, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0305, device='cuda:0') mean:  tensor(-2.8243e-05, device='cuda:0') min:  tensor(-0.0887, device='cuda:0') norm:  tensor(0.2929, device='cuda:0') MSE:  tensor(1.0993e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0179, device='cuda:0')
min of d_p_list:  tensor(-0.0123, device='cuda:0')
Epoch:  71  
Training Loss: 0.014332005754113197
Test Loss:  0.007607140112668276
Test Acc:  0.0
Valid Loss:  0.008050300180912018
Valid Acc:  0.0
std:  0.0001734667818791546 
thres:  1.457359977066517e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(210.7731, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
  7%|▋         | 71/1000 [04:31<1:00:09,  3.88s/it]Epoch:   72
max of grad d_p:  tensor(0.0177, device='cuda:0')
min of grad d_p:  tensor(-0.0122, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0314, device='cuda:0') mean:  tensor(-2.8928e-05, device='cuda:0') min:  tensor(-0.0938, device='cuda:0') norm:  tensor(0.2976, device='cuda:0') MSE:  tensor(1.1171e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0177, device='cuda:0')
min of d_p_list:  tensor(-0.0122, device='cuda:0')
Epoch:  72  
Training Loss: 0.014218339696526527
Test Loss:  0.007455555722117424
Test Acc:  0.0
Valid Loss:  0.007883267477154732
Valid Acc:  0.0
std:  0.0001683018451737507 
thres:  1.4452745392918587e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(211.1313, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
  7%|▋         | 72/1000 [04:34<59:21,  3.84s/it]  Epoch:   73
max of grad d_p:  tensor(0.0174, device='cuda:0')
min of grad d_p:  tensor(-0.0120, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0327, device='cuda:0') mean:  tensor(-2.9316e-05, device='cuda:0') min:  tensor(-0.1000, device='cuda:0') norm:  tensor(0.3168, device='cuda:0') MSE:  tensor(1.1890e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0174, device='cuda:0')
min of d_p_list:  tensor(-0.0120, device='cuda:0')
Epoch:  73  
Training Loss: 0.014108046889305115
Test Loss:  0.007307966239750385
Test Acc:  0.0
Valid Loss:  0.007720729801803827
Valid Acc:  0.0
std:  0.00016329708870336184 
thres:  1.4335487037897111e-05
Preserved_eigens number check:  5
max of Lambda2 tensor(565.5972, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
  7%|▋         | 73/1000 [04:38<57:06,  3.70s/it]Epoch:   74
max of grad d_p:  tensor(0.0171, device='cuda:0')
min of grad d_p:  tensor(-0.0118, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0348, device='cuda:0') mean:  tensor(-3.0741e-05, device='cuda:0') min:  tensor(-0.1003, device='cuda:0') norm:  tensor(0.3196, device='cuda:0') MSE:  tensor(1.1998e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0171, device='cuda:0')
min of d_p_list:  tensor(-0.0118, device='cuda:0')
Epoch:  74  
Training Loss: 0.014001023024320602
Test Loss:  0.007164259906858206
Test Acc:  0.0
Valid Loss:  0.007562557235360146
Valid Acc:  0.0
std:  0.0001584475122103988 
thres:  1.4221713319420816e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
  7%|▋         | 74/1000 [04:42<58:29,  3.79s/it]Epoch:   75
max of grad d_p:  tensor(0.0169, device='cuda:0')
min of grad d_p:  tensor(-0.0116, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0332, device='cuda:0') mean:  tensor(-2.7705e-05, device='cuda:0') min:  tensor(-0.0987, device='cuda:0') norm:  tensor(0.3100, device='cuda:0') MSE:  tensor(1.1635e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0169, device='cuda:0')
min of d_p_list:  tensor(-0.0116, device='cuda:0')
Epoch:  75  
Training Loss: 0.013897165656089783
Test Loss:  0.007024320773780346
Test Acc:  0.0
Valid Loss:  0.007408622652292252
Valid Acc:  0.0
std:  0.00015374890995018692 
thres:  1.4111316204071046e-05
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
  8%|▊         | 75/1000 [04:46<59:15,  3.84s/it]Epoch:   76
max of grad d_p:  tensor(0.0166, device='cuda:0')
min of grad d_p:  tensor(-0.0115, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0324, device='cuda:0') mean:  tensor(-3.0553e-05, device='cuda:0') min:  tensor(-0.0995, device='cuda:0') norm:  tensor(0.3095, device='cuda:0') MSE:  tensor(1.1619e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0166, device='cuda:0')
min of d_p_list:  tensor(-0.0115, device='cuda:0')
Epoch:  76  
Training Loss: 0.013796377927064896
Test Loss:  0.0068880366161465645
Test Acc:  0.0
Valid Loss:  0.007258797995746136
Valid Acc:  0.0
std:  0.0001491954714851967 
thres:  1.4004190638661383e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(567.4455, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
  8%|▊         | 76/1000 [04:49<58:46,  3.82s/it]Epoch:   77
max of grad d_p:  tensor(0.0163, device='cuda:0')
min of grad d_p:  tensor(-0.0113, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0330, device='cuda:0') mean:  tensor(-3.1974e-05, device='cuda:0') min:  tensor(-0.1005, device='cuda:0') norm:  tensor(0.3217, device='cuda:0') MSE:  tensor(1.2074e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0163, device='cuda:0')
min of d_p_list:  tensor(-0.0113, device='cuda:0')
Epoch:  77  
Training Loss: 0.013698565773665905
Test Loss:  0.006755308713763952
Test Acc:  0.0
Valid Loss:  0.007112969644367695
Valid Acc:  0.0
std:  0.00014478273135995433 
thres:  1.390023585408926e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
  8%|▊         | 77/1000 [04:53<59:58,  3.90s/it]Epoch:   78
max of grad d_p:  tensor(0.0161, device='cuda:0')
min of grad d_p:  tensor(-0.0111, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0351, device='cuda:0') mean:  tensor(-2.8984e-05, device='cuda:0') min:  tensor(-0.0924, device='cuda:0') norm:  tensor(0.3027, device='cuda:0') MSE:  tensor(1.1363e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0161, device='cuda:0')
min of d_p_list:  tensor(-0.0111, device='cuda:0')
Epoch:  78  
Training Loss: 0.013603633269667625
Test Loss:  0.006626030430197716
Test Acc:  0.0
Valid Loss:  0.006971021182835102
Valid Acc:  0.0
std:  0.0001405071124841675 
thres:  1.3799353130161763e-05
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
  8%|▊         | 78/1000 [04:57<59:37,  3.88s/it]Epoch:   79
max of grad d_p:  tensor(0.0158, device='cuda:0')
min of grad d_p:  tensor(-0.0109, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0327, device='cuda:0') mean:  tensor(-3.0840e-05, device='cuda:0') min:  tensor(-0.0975, device='cuda:0') norm:  tensor(0.3149, device='cuda:0') MSE:  tensor(1.1821e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0158, device='cuda:0')
min of d_p_list:  tensor(-0.0109, device='cuda:0')
Epoch:  79  
Training Loss: 0.013511495664715767
Test Loss:  0.0065001025795936584
Test Acc:  0.0
Valid Loss:  0.006832837127149105
Valid Acc:  0.0
std:  0.00013636349242800337 
thres:  1.3701447658240795e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(569.2943, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
  8%|▊         | 79/1000 [05:01<59:05,  3.85s/it]Epoch:   80
max of grad d_p:  tensor(0.0156, device='cuda:0')
min of grad d_p:  tensor(-0.0108, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0332, device='cuda:0') mean:  tensor(-3.0397e-05, device='cuda:0') min:  tensor(-0.0938, device='cuda:0') norm:  tensor(0.3067, device='cuda:0') MSE:  tensor(1.1513e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0156, device='cuda:0')
min of d_p_list:  tensor(-0.0108, device='cuda:0')
Epoch:  80  
Training Loss: 0.013422061689198017
Test Loss:  0.006377427838742733
Test Acc:  0.0
Valid Loss:  0.006698311772197485
Valid Acc:  0.0
std:  0.00013234896258037545 
thres:  1.3606426864862442e-05
Preserved_eigens number check:  5
max of Lambda2 tensor(569.9094, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
  8%|▊         | 80/1000 [05:05<59:49,  3.90s/it]Epoch:   81
max of grad d_p:  tensor(0.0153, device='cuda:0')
min of grad d_p:  tensor(-0.0106, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0324, device='cuda:0') mean:  tensor(-2.9283e-05, device='cuda:0') min:  tensor(-0.0903, device='cuda:0') norm:  tensor(0.2939, device='cuda:0') MSE:  tensor(1.1034e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0153, device='cuda:0')
min of d_p_list:  tensor(-0.0106, device='cuda:0')
Epoch:  81  
Training Loss: 0.013335252180695534
Test Loss:  0.006257915869355202
Test Acc:  0.0
Valid Loss:  0.006567338015884161
Valid Acc:  0.0
std:  0.00012845867194452072 
thres:  1.351420171558857e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
  8%|▊         | 81/1000 [05:09<59:56,  3.91s/it]Epoch:   82
max of grad d_p:  tensor(0.0151, device='cuda:0')
min of grad d_p:  tensor(-0.0105, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0316, device='cuda:0') mean:  tensor(-3.0639e-05, device='cuda:0') min:  tensor(-0.0914, device='cuda:0') norm:  tensor(0.2997, device='cuda:0') MSE:  tensor(1.1251e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0151, device='cuda:0')
min of d_p_list:  tensor(-0.0105, device='cuda:0')
Epoch:  82  
Training Loss: 0.013250982388854027
Test Loss:  0.006141476333141327
Test Acc:  0.0
Valid Loss:  0.006439819931983948
Valid Acc:  0.0
std:  0.00012468863843403 
thres:  1.3424685038626194e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(571.1246, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
  8%|▊         | 82/1000 [05:13<59:48,  3.91s/it]Epoch:   83
max of grad d_p:  tensor(0.0149, device='cuda:0')
min of grad d_p:  tensor(-0.0103, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0325, device='cuda:0') mean:  tensor(-2.7639e-05, device='cuda:0') min:  tensor(-0.0885, device='cuda:0') norm:  tensor(0.2847, device='cuda:0') MSE:  tensor(1.0687e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0149, device='cuda:0')
min of d_p_list:  tensor(-0.0103, device='cuda:0')
Epoch:  83  
Training Loss: 0.013169175945222378
Test Loss:  0.00602802075445652
Test Acc:  0.0
Valid Loss:  0.006315654143691063
Valid Acc:  0.0
std:  0.00012103559545771586 
thres:  1.3337793573737146e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  8%|▊         | 83/1000 [05:17<59:23,  3.89s/it]Epoch:   84
max of grad d_p:  tensor(0.0146, device='cuda:0')
min of grad d_p:  tensor(-0.0101, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-2.7749e-05, device='cuda:0') min:  tensor(-0.0908, device='cuda:0') norm:  tensor(0.2906, device='cuda:0') MSE:  tensor(1.0909e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0146, device='cuda:0')
min of d_p_list:  tensor(-0.0101, device='cuda:0')
Epoch:  84  
Training Loss: 0.013089755550026894
Test Loss:  0.0059174662455916405
Test Acc:  0.0
Valid Loss:  0.006194746121764183
Valid Acc:  0.0
std:  0.00011749517161756373 
thres:  1.3253445550799372e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
  8%|▊         | 84/1000 [05:20<57:59,  3.80s/it]Epoch:   85
max of grad d_p:  tensor(0.0144, device='cuda:0')
min of grad d_p:  tensor(-0.0100, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0336, device='cuda:0') mean:  tensor(-3.2772e-05, device='cuda:0') min:  tensor(-0.0989, device='cuda:0') norm:  tensor(0.3228, device='cuda:0') MSE:  tensor(1.2117e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0144, device='cuda:0')
min of d_p_list:  tensor(-0.0100, device='cuda:0')
Epoch:  85  
Training Loss: 0.01301264762878418
Test Loss:  0.005809730384498835
Test Acc:  0.0
Valid Loss:  0.00607700552791357
Valid Acc:  0.0
std:  0.00011406475293679158 
thres:  1.3171562738716604e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
  8%|▊         | 85/1000 [05:24<58:00,  3.80s/it]Epoch:   86
max of grad d_p:  tensor(0.0142, device='cuda:0')
min of grad d_p:  tensor(-0.0098, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0328, device='cuda:0') mean:  tensor(-3.0510e-05, device='cuda:0') min:  tensor(-0.0925, device='cuda:0') norm:  tensor(0.3054, device='cuda:0') MSE:  tensor(1.1464e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0142, device='cuda:0')
min of d_p_list:  tensor(-0.0098, device='cuda:0')
Epoch:  86  
Training Loss: 0.01293778046965599
Test Loss:  0.005704733543097973
Test Acc:  0.0
Valid Loss:  0.005962340161204338
Valid Acc:  0.0
std:  0.00011074023930719166 
thres:  1.3092068396508695e-05
Preserved_eigens number check:  13
max of Lambda2 tensor(573.5279, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
  9%|▊         | 86/1000 [05:28<57:26,  3.77s/it]Epoch:   87
max of grad d_p:  tensor(0.0139, device='cuda:0')
min of grad d_p:  tensor(-0.0097, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0345, device='cuda:0') mean:  tensor(-2.9565e-05, device='cuda:0') min:  tensor(-0.0941, device='cuda:0') norm:  tensor(0.3014, device='cuda:0') MSE:  tensor(1.1312e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0139, device='cuda:0')
min of d_p_list:  tensor(-0.0097, device='cuda:0')
Epoch:  87  
Training Loss: 0.012865083292126656
Test Loss:  0.0056023988872766495
Test Acc:  0.0
Valid Loss:  0.005850666202604771
Valid Acc:  0.0
std:  0.00010751926440062947 
thres:  1.3014888577163219e-05
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
  9%|▊         | 87/1000 [05:32<57:49,  3.80s/it]Epoch:   88
max of grad d_p:  tensor(0.0137, device='cuda:0')
min of grad d_p:  tensor(-0.0095, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0379, device='cuda:0') mean:  tensor(-3.3439e-05, device='cuda:0') min:  tensor(-0.1046, device='cuda:0') norm:  tensor(0.3418, device='cuda:0') MSE:  tensor(1.2831e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0137, device='cuda:0')
min of d_p_list:  tensor(-0.0095, device='cuda:0')
Epoch:  88  
Training Loss: 0.012794491834938526
Test Loss:  0.005502653773874044
Test Acc:  0.0
Valid Loss:  0.005741897039115429
Valid Acc:  0.0
std:  0.00010439775536577188 
thres:  1.293995175510645e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(574.7055, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
  9%|▉         | 88/1000 [05:36<58:02,  3.82s/it]Epoch:   89
max of grad d_p:  tensor(0.0135, device='cuda:0')
min of grad d_p:  tensor(-0.0094, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0360, device='cuda:0') mean:  tensor(-3.5275e-05, device='cuda:0') min:  tensor(-0.1041, device='cuda:0') norm:  tensor(0.3394, device='cuda:0') MSE:  tensor(1.2739e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0135, device='cuda:0')
min of d_p_list:  tensor(-0.0094, device='cuda:0')
Epoch:  89  
Training Loss: 0.012725938111543655
Test Loss:  0.005405423231422901
Test Acc:  0.0
Valid Loss:  0.005635952576994896
Valid Acc:  0.0
std:  0.00010137306701152208 
thres:  1.28671882674098e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
  9%|▉         | 89/1000 [05:39<58:27,  3.85s/it]Epoch:   90
max of grad d_p:  tensor(0.0133, device='cuda:0')
min of grad d_p:  tensor(-0.0092, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0345, device='cuda:0') mean:  tensor(-2.8662e-05, device='cuda:0') min:  tensor(-0.1001, device='cuda:0') norm:  tensor(0.3044, device='cuda:0') MSE:  tensor(1.1426e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0133, device='cuda:0')
min of d_p_list:  tensor(-0.0092, device='cuda:0')
Epoch:  90  
Training Loss: 0.012659359723329544
Test Loss:  0.005310637876391411
Test Acc:  0.0
Valid Loss:  0.005532752722501755
Valid Acc:  0.0
std:  9.844216847630447e-05 
thres:  1.2796530686318873e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
  9%|▉         | 90/1000 [05:43<56:10,  3.70s/it]Epoch:   91
max of grad d_p:  tensor(0.0131, device='cuda:0')
min of grad d_p:  tensor(-0.0091, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-3.1618e-05, device='cuda:0') min:  tensor(-0.1090, device='cuda:0') norm:  tensor(0.3370, device='cuda:0') MSE:  tensor(1.2651e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0131, device='cuda:0')
min of d_p_list:  tensor(-0.0091, device='cuda:0')
Epoch:  91  
Training Loss: 0.012594694271683693
Test Loss:  0.005218232050538063
Test Acc:  0.0
Valid Loss:  0.005432222969830036
Valid Acc:  0.0
std:  9.560241817419771e-05 
thres:  1.2727913446724415e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
  9%|▉         | 91/1000 [05:47<57:27,  3.79s/it]Epoch:   92
max of grad d_p:  tensor(0.0129, device='cuda:0')
min of grad d_p:  tensor(-0.0089, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0359, device='cuda:0') mean:  tensor(-3.4270e-05, device='cuda:0') min:  tensor(-0.1008, device='cuda:0') norm:  tensor(0.3314, device='cuda:0') MSE:  tensor(1.2441e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0129, device='cuda:0')
min of d_p_list:  tensor(-0.0089, device='cuda:0')
Epoch:  92  
Training Loss: 0.012531884014606476
Test Loss:  0.005128137301653624
Test Acc:  0.0
Valid Loss:  0.005334286019206047
Valid Acc:  0.0
std:  9.285120555446108e-05 
thres:  1.266127359122038e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
  9%|▉         | 92/1000 [05:51<57:28,  3.80s/it]Epoch:   93
max of grad d_p:  tensor(0.0126, device='cuda:0')
min of grad d_p:  tensor(-0.0088, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-3.1879e-05, device='cuda:0') min:  tensor(-0.0966, device='cuda:0') norm:  tensor(0.3168, device='cuda:0') MSE:  tensor(1.1892e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0126, device='cuda:0')
min of d_p_list:  tensor(-0.0088, device='cuda:0')
Epoch:  93  
Training Loss: 0.012470869347453117
Test Loss:  0.005040289834141731
Test Acc:  0.0
Valid Loss:  0.005238870158791542
Valid Acc:  0.0
std:  9.018548061475334e-05 
thres:  1.2596549093723297e-05
Preserved_eigens number check:  12
max of Lambda2 tensor(217.9233, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
  9%|▉         | 93/1000 [05:54<57:04,  3.78s/it]Epoch:   94
max of grad d_p:  tensor(0.0124, device='cuda:0')
min of grad d_p:  tensor(-0.0087, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0336, device='cuda:0') mean:  tensor(-2.9955e-05, device='cuda:0') min:  tensor(-0.0999, device='cuda:0') norm:  tensor(0.3051, device='cuda:0') MSE:  tensor(1.1453e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0124, device='cuda:0')
min of d_p_list:  tensor(-0.0087, device='cuda:0')
Epoch:  94  
Training Loss: 0.01241159625351429
Test Loss:  0.004954629577696323
Test Acc:  0.0
Valid Loss:  0.005145906470716
Valid Acc:  0.0
std:  8.760248740254021e-05 
thres:  1.2533680722117424e-05
Preserved_eigens number check:  5
max of Lambda2 tensor(578.1193, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
  9%|▉         | 94/1000 [05:58<58:06,  3.85s/it]Epoch:   95
max of grad d_p:  tensor(0.0122, device='cuda:0')
min of grad d_p:  tensor(-0.0085, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0337, device='cuda:0') mean:  tensor(-2.8324e-05, device='cuda:0') min:  tensor(-0.0967, device='cuda:0') norm:  tensor(0.2988, device='cuda:0') MSE:  tensor(1.1215e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0122, device='cuda:0')
min of d_p_list:  tensor(-0.0085, device='cuda:0')
Epoch:  95  
Training Loss: 0.012354010716080666
Test Loss:  0.004871094599366188
Test Acc:  0.0
Valid Loss:  0.005055326968431473
Valid Acc:  0.0
std:  8.509932487811954e-05 
thres:  1.2472610920667648e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(29.2321, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 10%|▉         | 95/1000 [06:02<59:04,  3.92s/it]Epoch:   96
max of grad d_p:  tensor(0.0120, device='cuda:0')
min of grad d_p:  tensor(-0.0084, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0373, device='cuda:0') mean:  tensor(-3.2799e-05, device='cuda:0') min:  tensor(-0.1011, device='cuda:0') norm:  tensor(0.3280, device='cuda:0') MSE:  tensor(1.2312e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0120, device='cuda:0')
min of d_p_list:  tensor(-0.0084, device='cuda:0')
Epoch:  96  
Training Loss: 0.012298059649765491
Test Loss:  0.004789629485458136
Test Acc:  0.0
Valid Loss:  0.004967065528035164
Valid Acc:  0.0
std:  8.267388616449477e-05 
thres:  1.2413283996284007e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 10%|▉         | 96/1000 [06:06<59:13,  3.93s/it]Epoch:   97
max of grad d_p:  tensor(0.0119, device='cuda:0')
min of grad d_p:  tensor(-0.0083, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0330, device='cuda:0') mean:  tensor(-3.0653e-05, device='cuda:0') min:  tensor(-0.0950, device='cuda:0') norm:  tensor(0.3027, device='cuda:0') MSE:  tensor(1.1362e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0119, device='cuda:0')
min of d_p_list:  tensor(-0.0083, device='cuda:0')
Epoch:  97  
Training Loss: 0.012243692763149738
Test Loss:  0.0047101727686822414
Test Acc:  0.0
Valid Loss:  0.004881056025624275
Valid Acc:  0.0
std:  8.032339608653461e-05 
thres:  1.2355645745992661e-05
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 10%|▉         | 97/1000 [06:10<58:41,  3.90s/it]Epoch:   98
max of grad d_p:  tensor(0.0117, device='cuda:0')
min of grad d_p:  tensor(-0.0081, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0367, device='cuda:0') mean:  tensor(-3.3621e-05, device='cuda:0') min:  tensor(-0.1026, device='cuda:0') norm:  tensor(0.3331, device='cuda:0') MSE:  tensor(1.2505e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0117, device='cuda:0')
min of d_p_list:  tensor(-0.0081, device='cuda:0')
Epoch:  98  
Training Loss: 0.012190859764814377
Test Loss:  0.0046326713636517525
Test Acc:  0.0
Valid Loss:  0.004797237925231457
Valid Acc:  0.0
std:  7.804627829671157e-05 
thres:  1.2299643829464912e-05
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 10%|▉         | 98/1000 [06:14<56:52,  3.78s/it]Epoch:   99
max of grad d_p:  tensor(0.0115, device='cuda:0')
min of grad d_p:  tensor(-0.0080, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0325, device='cuda:0') mean:  tensor(-3.0603e-05, device='cuda:0') min:  tensor(-0.0938, device='cuda:0') norm:  tensor(0.3009, device='cuda:0') MSE:  tensor(1.1294e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0115, device='cuda:0')
min of d_p_list:  tensor(-0.0080, device='cuda:0')
Epoch:  99  
Training Loss: 0.012139512225985527
Test Loss:  0.004557074047625065
Test Acc:  0.0
Valid Loss:  0.004715551622211933
Valid Acc:  0.0
std:  7.584055558199944e-05 
thres:  1.224522702395916e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 10%|▉         | 99/1000 [06:18<57:06,  3.80s/it]Epoch:   100
max of grad d_p:  tensor(0.0113, device='cuda:0')
min of grad d_p:  tensor(-0.0079, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0358, device='cuda:0') mean:  tensor(-3.2318e-05, device='cuda:0') min:  tensor(-0.1036, device='cuda:0') norm:  tensor(0.3262, device='cuda:0') MSE:  tensor(1.2246e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0113, device='cuda:0')
min of d_p_list:  tensor(-0.0079, device='cuda:0')
Epoch:  100  
Training Loss: 0.012089606374502182
Test Loss:  0.004483327269554138
Test Acc:  0.0
Valid Loss:  0.004635936580598354
Valid Acc:  0.0
std:  7.370334192103702e-05 
thres:  1.2192346155643464e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 10%|█         | 100/1000 [06:22<57:40,  3.85s/it]Epoch:   101
max of grad d_p:  tensor(0.0111, device='cuda:0')
min of grad d_p:  tensor(-0.0077, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0323, device='cuda:0') mean:  tensor(-3.4015e-05, device='cuda:0') min:  tensor(-0.1123, device='cuda:0') norm:  tensor(0.3346, device='cuda:0') MSE:  tensor(1.2559e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0111, device='cuda:0')
min of d_p_list:  tensor(-0.0077, device='cuda:0')
Epoch:  101  
Training Loss: 0.012041095644235611
Test Loss:  0.004411379806697369
Test Acc:  0.0
Valid Loss:  0.004558335058391094
Valid Acc:  0.0
std:  7.163265649925748e-05 
thres:  1.2140953354537488e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 10%|█         | 101/1000 [06:25<57:45,  3.85s/it]Epoch:   102
max of grad d_p:  tensor(0.0109, device='cuda:0')
min of grad d_p:  tensor(-0.0076, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0321, device='cuda:0') mean:  tensor(-3.2956e-05, device='cuda:0') min:  tensor(-0.1071, device='cuda:0') norm:  tensor(0.3273, device='cuda:0') MSE:  tensor(1.2288e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0109, device='cuda:0')
min of d_p_list:  tensor(-0.0076, device='cuda:0')
Epoch:  102  
Training Loss: 0.01199393905699253
Test Loss:  0.004341184161603451
Test Acc:  0.0
Valid Loss:  0.004482695367187262
Valid Acc:  0.0
std:  6.962560195573566e-05 
thres:  1.2091002613306046e-05
Preserved_eigens number check:  12
max of Lambda2 tensor(220.3318, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 10%|█         | 102/1000 [06:29<56:45,  3.79s/it]Epoch:   103
max of grad d_p:  tensor(0.0108, device='cuda:0')
min of grad d_p:  tensor(-0.0075, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0368, device='cuda:0') mean:  tensor(-3.4056e-05, device='cuda:0') min:  tensor(-0.1112, device='cuda:0') norm:  tensor(0.3436, device='cuda:0') MSE:  tensor(1.2898e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0108, device='cuda:0')
min of d_p_list:  tensor(-0.0075, device='cuda:0')
Epoch:  103  
Training Loss: 0.01194809004664421
Test Loss:  0.004272692836821079
Test Acc:  0.0
Valid Loss:  0.004408961161971092
Valid Acc:  0.0
std:  6.768123230102103e-05 
thres:  1.2042448669672013e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 10%|█         | 103/1000 [06:33<57:16,  3.83s/it]Epoch:   104
max of grad d_p:  tensor(0.0106, device='cuda:0')
min of grad d_p:  tensor(-0.0074, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0341, device='cuda:0') mean:  tensor(-3.2384e-05, device='cuda:0') min:  tensor(-0.0969, device='cuda:0') norm:  tensor(0.3122, device='cuda:0') MSE:  tensor(1.1719e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0106, device='cuda:0')
min of d_p_list:  tensor(-0.0074, device='cuda:0')
Epoch:  104  
Training Loss: 0.011903513222932816
Test Loss:  0.004205859266221523
Test Acc:  0.0
Valid Loss:  0.004337081220000982
Valid Acc:  0.0
std:  6.579721048333655e-05 
thres:  1.199524886906147e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 10%|█         | 104/1000 [06:37<58:04,  3.89s/it]Epoch:   105
max of grad d_p:  tensor(0.0104, device='cuda:0')
min of grad d_p:  tensor(-0.0073, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0349, device='cuda:0') mean:  tensor(-3.1670e-05, device='cuda:0') min:  tensor(-0.1016, device='cuda:0') norm:  tensor(0.3174, device='cuda:0') MSE:  tensor(1.1913e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0104, device='cuda:0')
min of d_p_list:  tensor(-0.0073, device='cuda:0')
Epoch:  105  
Training Loss: 0.011860164813697338
Test Loss:  0.004140638746321201
Test Acc:  0.0
Valid Loss:  0.004267004318535328
Valid Acc:  0.0
std:  6.397193408465271e-05 
thres:  1.19493605569005e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 10%|█         | 105/1000 [06:41<57:13,  3.84s/it]Epoch:   106
max of grad d_p:  tensor(0.0102, device='cuda:0')
min of grad d_p:  tensor(-0.0072, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0402, device='cuda:0') mean:  tensor(-3.3977e-05, device='cuda:0') min:  tensor(-0.1061, device='cuda:0') norm:  tensor(0.3429, device='cuda:0') MSE:  tensor(1.2871e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0102, device='cuda:0')
min of d_p_list:  tensor(-0.0072, device='cuda:0')
Epoch:  106  
Training Loss: 0.011818008497357368
Test Loss:  0.004076987970620394
Test Acc:  0.0
Valid Loss:  0.0041986801661551
Valid Acc:  0.0
std:  6.220370411807216e-05 
thres:  1.1904743127524853e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 11%|█         | 106/1000 [06:45<58:01,  3.89s/it]Epoch:   107
max of grad d_p:  tensor(0.0101, device='cuda:0')
min of grad d_p:  tensor(-0.0070, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0344, device='cuda:0') mean:  tensor(-3.1326e-05, device='cuda:0') min:  tensor(-0.1125, device='cuda:0') norm:  tensor(0.3340, device='cuda:0') MSE:  tensor(1.2538e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0101, device='cuda:0')
min of d_p_list:  tensor(-0.0070, device='cuda:0')
Epoch:  107  
Training Loss: 0.011777007952332497
Test Loss:  0.004014864098280668
Test Acc:  0.0
Valid Loss:  0.004132063128054142
Valid Acc:  0.0
std:  6.048974184778392e-05 
thres:  1.1861356906592846e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 11%|█         | 107/1000 [06:49<57:34,  3.87s/it]Epoch:   108
max of grad d_p:  tensor(0.0099, device='cuda:0')
min of grad d_p:  tensor(-0.0069, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0297, device='cuda:0') mean:  tensor(-3.2829e-05, device='cuda:0') min:  tensor(-0.0968, device='cuda:0') norm:  tensor(0.3154, device='cuda:0') MSE:  tensor(1.1839e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0099, device='cuda:0')
min of d_p_list:  tensor(-0.0069, device='cuda:0')
Epoch:  108  
Training Loss: 0.011737124994397163
Test Loss:  0.003954227082431316
Test Acc:  0.0
Valid Loss:  0.004067105706781149
Valid Acc:  0.0
std:  5.882979536725232e-05 
thres:  1.1819163896143437e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(585.2707, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
 11%|█         | 108/1000 [06:53<58:18,  3.92s/it]Epoch:   109
max of grad d_p:  tensor(0.0098, device='cuda:0')
min of grad d_p:  tensor(-0.0068, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0315, device='cuda:0') mean:  tensor(-3.0290e-05, device='cuda:0') min:  tensor(-0.0899, device='cuda:0') norm:  tensor(0.2905, device='cuda:0') MSE:  tensor(1.0905e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0098, device='cuda:0')
min of d_p_list:  tensor(-0.0068, device='cuda:0')
Epoch:  109  
Training Loss: 0.011698327027261257
Test Loss:  0.003895035944879055
Test Acc:  0.0
Valid Loss:  0.00400376133620739
Valid Acc:  0.0
std:  5.7220956104137266e-05 
thres:  1.1778126657009125e-05
Preserved_eigens number check:  4
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 11%|█         | 109/1000 [06:57<58:14,  3.92s/it]Epoch:   110
max of grad d_p:  tensor(0.0096, device='cuda:0')
min of grad d_p:  tensor(-0.0067, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0380, device='cuda:0') mean:  tensor(-3.4075e-05, device='cuda:0') min:  tensor(-0.1064, device='cuda:0') norm:  tensor(0.3347, device='cuda:0') MSE:  tensor(1.2562e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0096, device='cuda:0')
min of d_p_list:  tensor(-0.0067, device='cuda:0')
Epoch:  110  
Training Loss: 0.011660579591989517
Test Loss:  0.0038372529670596123
Test Acc:  0.0
Valid Loss:  0.003941989503800869
Valid Acc:  0.0
std:  5.5662177974725374e-05 
thres:  1.173820961266756e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 11%|█         | 110/1000 [07:00<58:05,  3.92s/it]Epoch:   111
max of grad d_p:  tensor(0.0094, device='cuda:0')
min of grad d_p:  tensor(-0.0066, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-3.1720e-05, device='cuda:0') min:  tensor(-0.0969, device='cuda:0') norm:  tensor(0.3124, device='cuda:0') MSE:  tensor(1.1726e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0094, device='cuda:0')
min of d_p_list:  tensor(-0.0066, device='cuda:0')
Epoch:  111  
Training Loss: 0.011623850092291832
Test Loss:  0.0037808408960700035
Test Acc:  0.0
Valid Loss:  0.003881744109094143
Valid Acc:  0.0
std:  5.415188073513394e-05 
thres:  1.1699377931654453e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(586.6501, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 11%|█         | 111/1000 [07:04<57:55,  3.91s/it]Epoch:   112
max of grad d_p:  tensor(0.0093, device='cuda:0')
min of grad d_p:  tensor(-0.0065, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-3.1208e-05, device='cuda:0') min:  tensor(-0.0966, device='cuda:0') norm:  tensor(0.3110, device='cuda:0') MSE:  tensor(1.1672e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0093, device='cuda:0')
min of d_p_list:  tensor(-0.0065, device='cuda:0')
Epoch:  112  
Training Loss: 0.011588106863200665
Test Loss:  0.003725761780515313
Test Acc:  0.0
Valid Loss:  0.0038229867350310087
Valid Acc:  0.0
std:  5.2688209696471336e-05 
thres:  1.1661597713828086e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
 11%|█         | 112/1000 [07:08<57:34,  3.89s/it]Epoch:   113
max of grad d_p:  tensor(0.0091, device='cuda:0')
min of grad d_p:  tensor(-0.0064, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0353, device='cuda:0') mean:  tensor(-3.1620e-05, device='cuda:0') min:  tensor(-0.0962, device='cuda:0') norm:  tensor(0.3086, device='cuda:0') MSE:  tensor(1.1583e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0091, device='cuda:0')
min of d_p_list:  tensor(-0.0064, device='cuda:0')
Epoch:  113  
Training Loss: 0.011553319171071053
Test Loss:  0.0036719809286296368
Test Acc:  0.0
Valid Loss:  0.0037656729109585285
Valid Acc:  0.0
std:  5.127025215230696e-05 
thres:  1.1624836549162864e-05
Preserved_eigens number check:  4
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 11%|█▏        | 113/1000 [07:12<57:11,  3.87s/it]Epoch:   114
max of grad d_p:  tensor(0.0090, device='cuda:0')
min of grad d_p:  tensor(-0.0063, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0336, device='cuda:0') mean:  tensor(-3.2732e-05, device='cuda:0') min:  tensor(-0.0977, device='cuda:0') norm:  tensor(0.3188, device='cuda:0') MSE:  tensor(1.1966e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0090, device='cuda:0')
min of d_p_list:  tensor(-0.0063, device='cuda:0')
Epoch:  114  
Training Loss: 0.011519457213580608
Test Loss:  0.0036194634158164263
Test Acc:  0.0
Valid Loss:  0.0037097674794495106
Valid Acc:  0.0
std:  4.9896424172886714e-05 
thres:  1.1589062586426734e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 11%|█▏        | 114/1000 [07:16<55:42,  3.77s/it]Epoch:   115
max of grad d_p:  tensor(0.0089, device='cuda:0')
min of grad d_p:  tensor(-0.0062, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0331, device='cuda:0') mean:  tensor(-3.1772e-05, device='cuda:0') min:  tensor(-0.0954, device='cuda:0') norm:  tensor(0.3021, device='cuda:0') MSE:  tensor(1.1339e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0089, device='cuda:0')
min of d_p_list:  tensor(-0.0062, device='cuda:0')
Epoch:  115  
Training Loss: 0.011486493051052094
Test Loss:  0.0035681745503097773
Test Acc:  0.0
Valid Loss:  0.0036552296951413155
Valid Acc:  0.0
std:  4.856514898853805e-05 
thres:  1.155424527823925e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 12%|█▏        | 115/1000 [07:19<56:07,  3.80s/it]Epoch:   116
max of grad d_p:  tensor(0.0087, device='cuda:0')
min of grad d_p:  tensor(-0.0061, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0294, device='cuda:0') mean:  tensor(-3.5270e-05, device='cuda:0') min:  tensor(-0.0995, device='cuda:0') norm:  tensor(0.3259, device='cuda:0') MSE:  tensor(1.2232e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0087, device='cuda:0')
min of d_p_list:  tensor(-0.0061, device='cuda:0')
Epoch:  116  
Training Loss: 0.011454399675130844
Test Loss:  0.0035180849954485893
Test Acc:  0.0
Valid Loss:  0.0036020264960825443
Valid Acc:  0.0
std:  4.72747163438868e-05 
thres:  1.1520355194807052e-05
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 12%|█▏        | 116/1000 [07:23<55:44,  3.78s/it]Epoch:   117
max of grad d_p:  tensor(0.0086, device='cuda:0')
min of grad d_p:  tensor(-0.0060, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0351, device='cuda:0') mean:  tensor(-2.9462e-05, device='cuda:0') min:  tensor(-0.0975, device='cuda:0') norm:  tensor(0.3043, device='cuda:0') MSE:  tensor(1.1423e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0086, device='cuda:0')
min of d_p_list:  tensor(-0.0060, device='cuda:0')
Epoch:  117  
Training Loss: 0.011423146352171898
Test Loss:  0.003469160757958889
Test Acc:  0.0
Valid Loss:  0.003550116904079914
Valid Acc:  0.0
std:  4.6024711848198997e-05 
thres:  1.14873630926013e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(589.2383, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 12%|█▏        | 117/1000 [07:27<55:20,  3.76s/it]Epoch:   118
max of grad d_p:  tensor(0.0084, device='cuda:0')
min of grad d_p:  tensor(-0.0059, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-3.0674e-05, device='cuda:0') min:  tensor(-0.1107, device='cuda:0') norm:  tensor(0.3269, device='cuda:0') MSE:  tensor(1.2272e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0084, device='cuda:0')
min of d_p_list:  tensor(-0.0059, device='cuda:0')
Epoch:  118  
Training Loss: 0.011392712593078613
Test Loss:  0.003421371104195714
Test Acc:  0.0
Valid Loss:  0.0034994708839803934
Valid Acc:  0.0
std:  4.481291933683005e-05 
thres:  1.1455241777002812e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 12%|█▏        | 118/1000 [07:31<55:32,  3.78s/it]Epoch:   119
max of grad d_p:  tensor(0.0083, device='cuda:0')
min of grad d_p:  tensor(-0.0058, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0339, device='cuda:0') mean:  tensor(-3.2795e-05, device='cuda:0') min:  tensor(-0.1000, device='cuda:0') norm:  tensor(0.3170, device='cuda:0') MSE:  tensor(1.1899e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0083, device='cuda:0')
min of d_p_list:  tensor(-0.0058, device='cuda:0')
Epoch:  119  
Training Loss: 0.011363068595528603
Test Loss:  0.003374685999006033
Test Acc:  0.0
Valid Loss:  0.0034500500187277794
Valid Acc:  0.0
std:  4.3638931733953633e-05 
thres:  1.1423964053392411e-05
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 12%|█▏        | 119/1000 [07:34<55:28,  3.78s/it]Epoch:   120
max of grad d_p:  tensor(0.0082, device='cuda:0')
min of grad d_p:  tensor(-0.0057, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0295, device='cuda:0') mean:  tensor(-3.2860e-05, device='cuda:0') min:  tensor(-0.1080, device='cuda:0') norm:  tensor(0.3252, device='cuda:0') MSE:  tensor(1.2207e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0082, device='cuda:0')
min of d_p_list:  tensor(-0.0057, device='cuda:0')
Epoch:  120  
Training Loss: 0.01133419293910265
Test Loss:  0.003329078434035182
Test Acc:  0.0
Valid Loss:  0.0034018256701529026
Valid Acc:  0.0
std:  4.2501045650527926e-05 
thres:  1.1393504031002522e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 12%|█▏        | 120/1000 [07:38<56:00,  3.82s/it]Epoch:   121
max of grad d_p:  tensor(0.0080, device='cuda:0')
min of grad d_p:  tensor(-0.0056, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0354, device='cuda:0') mean:  tensor(-3.2977e-05, device='cuda:0') min:  tensor(-0.1016, device='cuda:0') norm:  tensor(0.3201, device='cuda:0') MSE:  tensor(1.2014e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0080, device='cuda:0')
min of d_p_list:  tensor(-0.0056, device='cuda:0')
Epoch:  121  
Training Loss: 0.01130605861544609
Test Loss:  0.003284517675638199
Test Acc:  0.0
Valid Loss:  0.0033547631464898586
Valid Acc:  0.0
std:  4.1398313099197027e-05 
thres:  1.1363835819065571e-05
Preserved_eigens number check:  12
max of Lambda2 tensor(590.8467, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 12%|█▏        | 121/1000 [07:42<55:38,  3.80s/it]Epoch:   122
max of grad d_p:  tensor(0.0079, device='cuda:0')
min of grad d_p:  tensor(-0.0055, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0353, device='cuda:0') mean:  tensor(-3.2840e-05, device='cuda:0') min:  tensor(-0.1029, device='cuda:0') norm:  tensor(0.3271, device='cuda:0') MSE:  tensor(1.2277e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0079, device='cuda:0')
min of d_p_list:  tensor(-0.0055, device='cuda:0')
Epoch:  122  
Training Loss: 0.011278646998107433
Test Loss:  0.0032409774139523506
Test Acc:  0.0
Valid Loss:  0.003308831714093685
Valid Acc:  0.0
std:  4.0329852097837235e-05 
thres:  1.133493594825268e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 12%|█▏        | 122/1000 [07:46<54:43,  3.74s/it]Epoch:   123
max of grad d_p:  tensor(0.0078, device='cuda:0')
min of grad d_p:  tensor(-0.0054, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0375, device='cuda:0') mean:  tensor(-3.4914e-05, device='cuda:0') min:  tensor(-0.1032, device='cuda:0') norm:  tensor(0.3294, device='cuda:0') MSE:  tensor(1.2367e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0078, device='cuda:0')
min of d_p_list:  tensor(-0.0054, device='cuda:0')
Epoch:  123  
Training Loss: 0.011251932941377163
Test Loss:  0.0031984313391149044
Test Acc:  0.0
Valid Loss:  0.0032640015706419945
Valid Acc:  0.0
std:  3.929392127941751e-05 
thres:  1.1306780017912387e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 12%|█▏        | 123/1000 [07:50<55:52,  3.82s/it]Epoch:   124
max of grad d_p:  tensor(0.0077, device='cuda:0')
min of grad d_p:  tensor(-0.0054, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0395, device='cuda:0') mean:  tensor(-2.9988e-05, device='cuda:0') min:  tensor(-0.0958, device='cuda:0') norm:  tensor(0.3057, device='cuda:0') MSE:  tensor(1.1474e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0077, device='cuda:0')
min of d_p_list:  tensor(-0.0054, device='cuda:0')
Epoch:  124  
Training Loss: 0.011225895956158638
Test Loss:  0.003156851977109909
Test Acc:  0.0
Valid Loss:  0.0032202426809817553
Valid Acc:  0.0
std:  3.829000424379349e-05 
thres:  1.1279345490038395e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 12%|█▏        | 124/1000 [07:53<54:51,  3.76s/it]Epoch:   125
max of grad d_p:  tensor(0.0075, device='cuda:0')
min of grad d_p:  tensor(-0.0053, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0348, device='cuda:0') mean:  tensor(-3.2197e-05, device='cuda:0') min:  tensor(-0.0964, device='cuda:0') norm:  tensor(0.3124, device='cuda:0') MSE:  tensor(1.1728e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0075, device='cuda:0')
min of d_p_list:  tensor(-0.0053, device='cuda:0')
Epoch:  125  
Training Loss: 0.011200515553355217
Test Loss:  0.003116215579211712
Test Acc:  0.0
Valid Loss:  0.0031775273382663727
Valid Acc:  0.0
std:  3.731651023746153e-05 
thres:  1.125261001288891e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 12%|█▎        | 125/1000 [07:57<55:32,  3.81s/it]Epoch:   126
max of grad d_p:  tensor(0.0074, device='cuda:0')
min of grad d_p:  tensor(-0.0052, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0321, device='cuda:0') mean:  tensor(-3.2968e-05, device='cuda:0') min:  tensor(-0.0999, device='cuda:0') norm:  tensor(0.3180, device='cuda:0') MSE:  tensor(1.1937e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0074, device='cuda:0')
min of d_p_list:  tensor(-0.0052, device='cuda:0')
Epoch:  126  
Training Loss: 0.011175769381225109
Test Loss:  0.0030764981638640165
Test Acc:  0.0
Valid Loss:  0.0031358273699879646
Valid Acc:  0.0
std:  3.637384315661718e-05 
thres:  1.1226552166044711e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 13%|█▎        | 126/1000 [08:01<54:33,  3.75s/it]Epoch:   127
max of grad d_p:  tensor(0.0073, device='cuda:0')
min of grad d_p:  tensor(-0.0051, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-3.2274e-05, device='cuda:0') min:  tensor(-0.0961, device='cuda:0') norm:  tensor(0.3093, device='cuda:0') MSE:  tensor(1.1609e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0073, device='cuda:0')
min of d_p_list:  tensor(-0.0051, device='cuda:0')
Epoch:  127  
Training Loss: 0.011151639744639397
Test Loss:  0.0030376731883734465
Test Acc:  0.0
Valid Loss:  0.0030951150692999363
Valid Acc:  0.0
std:  3.546015565779862e-05 
thres:  1.1201150715351105e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(225.5085, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 13%|█▎        | 127/1000 [08:05<55:30,  3.81s/it]Epoch:   128
max of grad d_p:  tensor(0.0072, device='cuda:0')
min of grad d_p:  tensor(-0.0050, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0322, device='cuda:0') mean:  tensor(-3.2362e-05, device='cuda:0') min:  tensor(-0.1012, device='cuda:0') norm:  tensor(0.3108, device='cuda:0') MSE:  tensor(1.1668e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0072, device='cuda:0')
min of d_p_list:  tensor(-0.0050, device='cuda:0')
Epoch:  128  
Training Loss: 0.011128108017146587
Test Loss:  0.00299972016364336
Test Acc:  0.0
Valid Loss:  0.0030553657561540604
Valid Acc:  0.0
std:  3.4574534284844744e-05 
thres:  1.117638573050499e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 13%|█▎        | 128/1000 [08:08<53:47,  3.70s/it]Epoch:   129
max of grad d_p:  tensor(0.0071, device='cuda:0')
min of grad d_p:  tensor(-0.0050, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-3.2245e-05, device='cuda:0') min:  tensor(-0.0977, device='cuda:0') norm:  tensor(0.3147, device='cuda:0') MSE:  tensor(1.1812e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0071, device='cuda:0')
min of d_p_list:  tensor(-0.0050, device='cuda:0')
Epoch:  129  
Training Loss: 0.011105156503617764
Test Loss:  0.002962615340948105
Test Acc:  0.0
Valid Loss:  0.003016553120687604
Valid Acc:  0.0
std:  3.371566206905111e-05 
thres:  1.1152237839996815e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 13%|█▎        | 129/1000 [08:12<53:25,  3.68s/it]Epoch:   130
max of grad d_p:  tensor(0.0070, device='cuda:0')
min of grad d_p:  tensor(-0.0049, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0360, device='cuda:0') mean:  tensor(-3.3584e-05, device='cuda:0') min:  tensor(-0.1030, device='cuda:0') norm:  tensor(0.3298, device='cuda:0') MSE:  tensor(1.2379e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0070, device='cuda:0')
min of d_p_list:  tensor(-0.0049, device='cuda:0')
Epoch:  130  
Training Loss: 0.011082766577601433
Test Loss:  0.002926337532699108
Test Acc:  0.0
Valid Loss:  0.002978652250021696
Valid Acc:  0.0
std:  3.288246881622839e-05 
thres:  1.1128688044846059e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 13%|█▎        | 130/1000 [08:16<54:16,  3.74s/it]Epoch:   131
max of grad d_p:  tensor(0.0068, device='cuda:0')
min of grad d_p:  tensor(-0.0048, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0342, device='cuda:0') mean:  tensor(-3.2727e-05, device='cuda:0') min:  tensor(-0.1109, device='cuda:0') norm:  tensor(0.3372, device='cuda:0') MSE:  tensor(1.2656e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0068, device='cuda:0')
min of d_p_list:  tensor(-0.0048, device='cuda:0')
Epoch:  131  
Training Loss: 0.011060919612646103
Test Loss:  0.0028908655513077974
Test Acc:  0.0
Valid Loss:  0.0029416391626000404
Valid Acc:  0.0
std:  3.207521808600351e-05 
thres:  1.1105718091130257e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(226.1555, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 13%|█▎        | 131/1000 [08:20<54:53,  3.79s/it]Epoch:   132
max of grad d_p:  tensor(0.0067, device='cuda:0')
min of grad d_p:  tensor(-0.0047, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0344, device='cuda:0') mean:  tensor(-3.5042e-05, device='cuda:0') min:  tensor(-0.1043, device='cuda:0') norm:  tensor(0.3347, device='cuda:0') MSE:  tensor(1.2562e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0067, device='cuda:0')
min of d_p_list:  tensor(-0.0047, device='cuda:0')
Epoch:  132  
Training Loss: 0.01103960070759058
Test Loss:  0.0028561772778630257
Test Acc:  0.0
Valid Loss:  0.0029054898768663406
Valid Acc:  0.0
std:  3.129299939883489e-05 
thres:  1.1083310283720494e-05
Preserved_eigens number check:  12
max of Lambda2 tensor(226.3098, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 13%|█▎        | 132/1000 [08:24<55:44,  3.85s/it]Epoch:   133
max of grad d_p:  tensor(0.0066, device='cuda:0')
min of grad d_p:  tensor(-0.0046, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-3.3888e-05, device='cuda:0') min:  tensor(-0.1043, device='cuda:0') norm:  tensor(0.3321, device='cuda:0') MSE:  tensor(1.2468e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0066, device='cuda:0')
min of d_p_list:  tensor(-0.0046, device='cuda:0')
Epoch:  133  
Training Loss: 0.01101879496127367
Test Loss:  0.0028222547844052315
Test Acc:  0.0
Valid Loss:  0.0028701836708933115
Valid Acc:  0.0
std:  3.053450549894161e-05 
thres:  1.106144767254591e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(595.1356, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 13%|█▎        | 133/1000 [08:28<56:30,  3.91s/it]Epoch:   134
max of grad d_p:  tensor(0.0065, device='cuda:0')
min of grad d_p:  tensor(-0.0046, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0307, device='cuda:0') mean:  tensor(-3.1679e-05, device='cuda:0') min:  tensor(-0.1004, device='cuda:0') norm:  tensor(0.3094, device='cuda:0') MSE:  tensor(1.1613e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0065, device='cuda:0')
min of d_p_list:  tensor(-0.0046, device='cuda:0')
Epoch:  134  
Training Loss: 0.010998483747243881
Test Loss:  0.0027890759520232677
Test Acc:  0.0
Valid Loss:  0.002835694933310151
Valid Acc:  0.0
std:  2.979919030985827e-05 
thres:  1.1040113121271134e-05
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 13%|█▎        | 134/1000 [08:32<56:18,  3.90s/it]Epoch:   135
max of grad d_p:  tensor(0.0064, device='cuda:0')
min of grad d_p:  tensor(-0.0045, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0414, device='cuda:0') mean:  tensor(-3.1557e-05, device='cuda:0') min:  tensor(-0.1134, device='cuda:0') norm:  tensor(0.3346, device='cuda:0') MSE:  tensor(1.2561e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0064, device='cuda:0')
min of d_p_list:  tensor(-0.0045, device='cuda:0')
Epoch:  135  
Training Loss: 0.010978654026985168
Test Loss:  0.0027566226199269295
Test Acc:  0.0
Valid Loss:  0.00280200457200408
Valid Acc:  0.0
std:  2.9086000103078074e-05 
thres:  1.101929061114788e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(595.7828, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 14%|█▎        | 135/1000 [08:36<56:38,  3.93s/it]Epoch:   136
max of grad d_p:  tensor(0.0063, device='cuda:0')
min of grad d_p:  tensor(-0.0044, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0362, device='cuda:0') mean:  tensor(-3.0404e-05, device='cuda:0') min:  tensor(-0.1073, device='cuda:0') norm:  tensor(0.3137, device='cuda:0') MSE:  tensor(1.1775e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0063, device='cuda:0')
min of d_p_list:  tensor(-0.0044, device='cuda:0')
Epoch:  136  
Training Loss: 0.010959292761981487
Test Loss:  0.0027248782571405172
Test Acc:  0.0
Valid Loss:  0.0027690911665558815
Valid Acc:  0.0
std:  2.839416064487187e-05 
thres:  1.0998965241014958e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 14%|█▎        | 136/1000 [08:40<57:01,  3.96s/it]Epoch:   137
max of grad d_p:  tensor(0.0062, device='cuda:0')
min of grad d_p:  tensor(-0.0044, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0391, device='cuda:0') mean:  tensor(-3.4115e-05, device='cuda:0') min:  tensor(-0.1058, device='cuda:0') norm:  tensor(0.3341, device='cuda:0') MSE:  tensor(1.2542e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0062, device='cuda:0')
min of d_p_list:  tensor(-0.0044, device='cuda:0')
Epoch:  137  
Training Loss: 0.010940381325781345
Test Loss:  0.0026938216760754585
Test Acc:  0.0
Valid Loss:  0.0027369349263608456
Valid Acc:  0.0
std:  2.7723919739434832e-05 
thres:  1.0979121364653112e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(227.0478, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 14%|█▎        | 137/1000 [08:44<56:55,  3.96s/it]Epoch:   138
max of grad d_p:  tensor(0.0061, device='cuda:0')
min of grad d_p:  tensor(-0.0043, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0367, device='cuda:0') mean:  tensor(-3.2770e-05, device='cuda:0') min:  tensor(-0.1148, device='cuda:0') norm:  tensor(0.3398, device='cuda:0') MSE:  tensor(1.2755e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0061, device='cuda:0')
min of d_p_list:  tensor(-0.0043, device='cuda:0')
Epoch:  138  
Training Loss: 0.010921910405158997
Test Loss:  0.002663438906893134
Test Acc:  0.0
Valid Loss:  0.0027055153623223305
Valid Acc:  0.0
std:  2.707343643984602e-05 
thres:  1.0959744453430175e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(596.7052, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 14%|█▍        | 138/1000 [08:48<56:58,  3.97s/it]Epoch:   139
max of grad d_p:  tensor(0.0060, device='cuda:0')
min of grad d_p:  tensor(-0.0042, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0324, device='cuda:0') mean:  tensor(-3.1231e-05, device='cuda:0') min:  tensor(-0.1018, device='cuda:0') norm:  tensor(0.3083, device='cuda:0') MSE:  tensor(1.1572e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0060, device='cuda:0')
min of d_p_list:  tensor(-0.0042, device='cuda:0')
Epoch:  139  
Training Loss: 0.010903865098953247
Test Loss:  0.0026337108574807644
Test Acc:  0.0
Valid Loss:  0.0026748129166662693
Valid Acc:  0.0
std:  2.6442717159990283e-05 
thres:  1.094082072377205e-05
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 14%|█▍        | 139/1000 [08:52<57:01,  3.97s/it]Epoch:   140
max of grad d_p:  tensor(0.0059, device='cuda:0')
min of grad d_p:  tensor(-0.0042, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0384, device='cuda:0') mean:  tensor(-3.0568e-05, device='cuda:0') min:  tensor(-0.1113, device='cuda:0') norm:  tensor(0.3246, device='cuda:0') MSE:  tensor(1.2184e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0059, device='cuda:0')
min of d_p_list:  tensor(-0.0042, device='cuda:0')
Epoch:  140  
Training Loss: 0.010886233299970627
Test Loss:  0.00260462099686265
Test Acc:  0.0
Valid Loss:  0.002644810825586319
Valid Acc:  0.0
std:  2.5830974828283835e-05 
thres:  1.092233657836914e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 14%|█▍        | 140/1000 [08:56<56:57,  3.97s/it]Epoch:   141
max of grad d_p:  tensor(0.0058, device='cuda:0')
min of grad d_p:  tensor(-0.0041, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0346, device='cuda:0') mean:  tensor(-3.3492e-05, device='cuda:0') min:  tensor(-0.1001, device='cuda:0') norm:  tensor(0.3236, device='cuda:0') MSE:  tensor(1.2147e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0058, device='cuda:0')
min of d_p_list:  tensor(-0.0041, device='cuda:0')
Epoch:  141  
Training Loss: 0.010869001038372517
Test Loss:  0.0025761532597243786
Test Acc:  0.0
Valid Loss:  0.002615488599985838
Valid Acc:  0.0
std:  2.52372643207754e-05 
thres:  1.0904278233647347e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 14%|█▍        | 141/1000 [09:00<57:16,  4.00s/it]Epoch:   142
max of grad d_p:  tensor(0.0058, device='cuda:0')
min of grad d_p:  tensor(-0.0040, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0374, device='cuda:0') mean:  tensor(-3.6177e-05, device='cuda:0') min:  tensor(-0.1083, device='cuda:0') norm:  tensor(0.3456, device='cuda:0') MSE:  tensor(1.2973e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0058, device='cuda:0')
min of d_p_list:  tensor(-0.0040, device='cuda:0')
Epoch:  142  
Training Loss: 0.010852156206965446
Test Loss:  0.002548293210566044
Test Acc:  0.0
Valid Loss:  0.0025868299417197704
Valid Acc:  0.0
std:  2.4662261201115382e-05 
thres:  1.0886633209884167e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(597.8723, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 14%|█▍        | 142/1000 [09:04<56:43,  3.97s/it]Epoch:   143
max of grad d_p:  tensor(0.0057, device='cuda:0')
min of grad d_p:  tensor(-0.0040, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0359, device='cuda:0') mean:  tensor(-3.3024e-05, device='cuda:0') min:  tensor(-0.1080, device='cuda:0') norm:  tensor(0.3215, device='cuda:0') MSE:  tensor(1.2068e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0057, device='cuda:0')
min of d_p_list:  tensor(-0.0040, device='cuda:0')
Epoch:  143  
Training Loss: 0.01083568949252367
Test Loss:  0.0025210222229361534
Test Acc:  0.0
Valid Loss:  0.002558815758675337
Valid Acc:  0.0
std:  2.410439094718705e-05 
thres:  1.0869389027357102e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 14%|█▍        | 143/1000 [09:07<56:13,  3.94s/it]Epoch:   144
max of grad d_p:  tensor(0.0056, device='cuda:0')
min of grad d_p:  tensor(-0.0039, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0398, device='cuda:0') mean:  tensor(-3.1284e-05, device='cuda:0') min:  tensor(-0.1236, device='cuda:0') norm:  tensor(0.3428, device='cuda:0') MSE:  tensor(1.2866e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0056, device='cuda:0')
min of d_p_list:  tensor(-0.0039, device='cuda:0')
Epoch:  144  
Training Loss: 0.010819585993885994
Test Loss:  0.002494330983608961
Test Acc:  0.0
Valid Loss:  0.0025314325466752052
Valid Acc:  0.0
std:  2.3563774887349607e-05 
thres:  1.0852533206343652e-05
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 14%|█▍        | 144/1000 [09:11<55:54,  3.92s/it]Epoch:   145
max of grad d_p:  tensor(0.0055, device='cuda:0')
min of grad d_p:  tensor(-0.0039, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0393, device='cuda:0') mean:  tensor(-3.2498e-05, device='cuda:0') min:  tensor(-0.1041, device='cuda:0') norm:  tensor(0.3256, device='cuda:0') MSE:  tensor(1.2224e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0055, device='cuda:0')
min of d_p_list:  tensor(-0.0039, device='cuda:0')
Epoch:  145  
Training Loss: 0.01080384012311697
Test Loss:  0.002468200633302331
Test Acc:  0.0
Valid Loss:  0.0025046607479453087
Valid Acc:  0.0
std:  2.3038447690564384e-05 
thres:  1.083605457097292e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(598.7091, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 14%|█▍        | 145/1000 [09:15<55:32,  3.90s/it]Epoch:   146
max of grad d_p:  tensor(0.0054, device='cuda:0')
min of grad d_p:  tensor(-0.0038, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0311, device='cuda:0') mean:  tensor(-3.0689e-05, device='cuda:0') min:  tensor(-0.0935, device='cuda:0') norm:  tensor(0.2974, device='cuda:0') MSE:  tensor(1.1163e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0054, device='cuda:0')
min of d_p_list:  tensor(-0.0038, device='cuda:0')
Epoch:  146  
Training Loss: 0.01078843791037798
Test Loss:  0.0024426179006695747
Test Acc:  0.0
Valid Loss:  0.0024784873239696026
Valid Acc:  0.0
std:  2.2528397606587674e-05 
thres:  1.0819941945374011e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(598.9756, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 15%|█▍        | 146/1000 [09:19<55:47,  3.92s/it]Epoch:   147
max of grad d_p:  tensor(0.0053, device='cuda:0')
min of grad d_p:  tensor(-0.0037, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-3.1401e-05, device='cuda:0') min:  tensor(-0.1046, device='cuda:0') norm:  tensor(0.3207, device='cuda:0') MSE:  tensor(1.2038e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0053, device='cuda:0')
min of d_p_list:  tensor(-0.0037, device='cuda:0')
Epoch:  147  
Training Loss: 0.010773368179798126
Test Loss:  0.0024175718426704407
Test Acc:  0.0
Valid Loss:  0.0024528950452804565
Valid Acc:  0.0
std:  2.2034018419957077e-05 
thres:  1.0804184339940548e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 15%|█▍        | 147/1000 [09:23<54:28,  3.83s/it]Epoch:   148
max of grad d_p:  tensor(0.0052, device='cuda:0')
min of grad d_p:  tensor(-0.0037, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0344, device='cuda:0') mean:  tensor(-3.2272e-05, device='cuda:0') min:  tensor(-0.1075, device='cuda:0') norm:  tensor(0.3208, device='cuda:0') MSE:  tensor(1.2042e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0052, device='cuda:0')
min of d_p_list:  tensor(-0.0037, device='cuda:0')
Epoch:  148  
Training Loss: 0.010758623480796814
Test Loss:  0.002393044764176011
Test Acc:  0.0
Valid Loss:  0.0024278697092086077
Valid Acc:  0.0
std:  2.155399291355365e-05 
thres:  1.0788771137595178e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(599.4948, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  131
 15%|█▍        | 148/1000 [09:27<55:16,  3.89s/it]Epoch:   149
max of grad d_p:  tensor(0.0052, device='cuda:0')
min of grad d_p:  tensor(-0.0036, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0393, device='cuda:0') mean:  tensor(-3.5363e-05, device='cuda:0') min:  tensor(-0.1127, device='cuda:0') norm:  tensor(0.3452, device='cuda:0') MSE:  tensor(1.2957e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0052, device='cuda:0')
min of d_p_list:  tensor(-0.0036, device='cuda:0')
Epoch:  149  
Training Loss: 0.010744191706180573
Test Loss:  0.0023690282832831144
Test Acc:  0.0
Valid Loss:  0.0024033968802541494
Valid Acc:  0.0
std:  2.1089256344839237e-05 
thres:  1.0773692280054093e-05
Preserved_eigens number check:  131
max of Lambda2 tensor(228.5768, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 15%|█▍        | 149/1000 [09:31<55:10,  3.89s/it]Epoch:   150
max of grad d_p:  tensor(0.0051, device='cuda:0')
min of grad d_p:  tensor(-0.0036, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0369, device='cuda:0') mean:  tensor(-3.3901e-05, device='cuda:0') min:  tensor(-0.1101, device='cuda:0') norm:  tensor(0.3340, device='cuda:0') MSE:  tensor(1.2539e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0051, device='cuda:0')
min of d_p_list:  tensor(-0.0036, device='cuda:0')
Epoch:  150  
Training Loss: 0.010730065405368805
Test Loss:  0.002345506800338626
Test Acc:  0.0
Valid Loss:  0.002379461657255888
Valid Acc:  0.0
std:  2.0638089173125018e-05 
thres:  1.075893733650446e-05
Preserved_eigens number check:  13
max of Lambda2 tensor(228.6922, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  3
 15%|█▌        | 150/1000 [09:34<54:53,  3.88s/it]Epoch:   151
max of grad d_p:  tensor(0.0050, device='cuda:0')
min of grad d_p:  tensor(-0.0035, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0367, device='cuda:0') mean:  tensor(-3.7110e-05, device='cuda:0') min:  tensor(-0.1104, device='cuda:0') norm:  tensor(0.3535, device='cuda:0') MSE:  tensor(1.3271e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0050, device='cuda:0')
min of d_p_list:  tensor(-0.0035, device='cuda:0')
Epoch:  151  
Training Loss: 0.01071623619645834
Test Loss:  0.0023224689066410065
Test Acc:  0.0
Valid Loss:  0.002356051467359066
Valid Acc:  0.0
std:  2.019970112340243e-05 
thres:  1.0744496993720532e-05
Preserved_eigens number check:  3
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 15%|█▌        | 151/1000 [09:38<54:53,  3.88s/it]Epoch:   152
max of grad d_p:  tensor(0.0049, device='cuda:0')
min of grad d_p:  tensor(-0.0035, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-3.3288e-05, device='cuda:0') min:  tensor(-0.1006, device='cuda:0') norm:  tensor(0.3243, device='cuda:0') MSE:  tensor(1.2174e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0049, device='cuda:0')
min of d_p_list:  tensor(-0.0035, device='cuda:0')
Epoch:  152  
Training Loss: 0.010702693834900856
Test Loss:  0.0022999029606580734
Test Acc:  0.0
Valid Loss:  0.0023331516422331333
Valid Acc:  0.0
std:  1.9774355735741046e-05 
thres:  1.0730362124741078e-05
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 15%|█▌        | 152/1000 [09:42<54:52,  3.88s/it]Epoch:   153
max of grad d_p:  tensor(0.0049, device='cuda:0')
min of grad d_p:  tensor(-0.0034, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0349, device='cuda:0') mean:  tensor(-3.4658e-05, device='cuda:0') min:  tensor(-0.1194, device='cuda:0') norm:  tensor(0.3505, device='cuda:0') MSE:  tensor(1.3156e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0049, device='cuda:0')
min of d_p_list:  tensor(-0.0034, device='cuda:0')
Epoch:  153  
Training Loss: 0.010689429938793182
Test Loss:  0.002277798019349575
Test Acc:  0.0
Valid Loss:  0.00231075007468462
Valid Acc:  0.0
std:  1.9361384626004664e-05 
thres:  1.0716523416340352e-05
Preserved_eigens number check:  14
max of Lambda2 tensor(600.7358, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 15%|█▌        | 153/1000 [09:46<54:54,  3.89s/it]Epoch:   154
max of grad d_p:  tensor(0.0048, device='cuda:0')
min of grad d_p:  tensor(-0.0034, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0343, device='cuda:0') mean:  tensor(-3.4174e-05, device='cuda:0') min:  tensor(-0.1017, device='cuda:0') norm:  tensor(0.3243, device='cuda:0') MSE:  tensor(1.2175e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0048, device='cuda:0')
min of d_p_list:  tensor(-0.0034, device='cuda:0')
Epoch:  154  
Training Loss: 0.010676437988877296
Test Loss:  0.0022561419755220413
Test Acc:  0.0
Valid Loss:  0.0022888346575200558
Valid Acc:  0.0
std:  1.8960538303072075e-05 
thres:  1.0702972672879696e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 15%|█▌        | 154/1000 [09:50<54:24,  3.86s/it]Epoch:   155
max of grad d_p:  tensor(0.0047, device='cuda:0')
min of grad d_p:  tensor(-0.0033, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0394, device='cuda:0') mean:  tensor(-3.3684e-05, device='cuda:0') min:  tensor(-0.1283, device='cuda:0') norm:  tensor(0.3509, device='cuda:0') MSE:  tensor(1.3172e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0047, device='cuda:0')
min of d_p_list:  tensor(-0.0033, device='cuda:0')
Epoch:  155  
Training Loss: 0.010663708671927452
Test Loss:  0.002234923653304577
Test Acc:  0.0
Valid Loss:  0.002267391886562109
Valid Acc:  0.0
std:  1.8571550641566485e-05 
thres:  1.0689701326191425e-05
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 16%|█▌        | 155/1000 [09:54<53:42,  3.81s/it]Epoch:   156
max of grad d_p:  tensor(0.0046, device='cuda:0')
min of grad d_p:  tensor(-0.0033, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0286, device='cuda:0') mean:  tensor(-3.8970e-05, device='cuda:0') min:  tensor(-0.1070, device='cuda:0') norm:  tensor(0.3572, device='cuda:0') MSE:  tensor(1.3408e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0046, device='cuda:0')
min of d_p_list:  tensor(-0.0033, device='cuda:0')
Epoch:  156  
Training Loss: 0.010651235468685627
Test Loss:  0.0022141332738101482
Test Acc:  0.0
Valid Loss:  0.0022464103531092405
Valid Acc:  0.0
std:  1.819349552746414e-05 
thres:  1.0676701180636883e-05
Preserved_eigens number check:  5
max of Lambda2 tensor(229.3356, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 16%|█▌        | 156/1000 [09:57<52:44,  3.75s/it]Epoch:   157
max of grad d_p:  tensor(0.0046, device='cuda:0')
min of grad d_p:  tensor(-0.0032, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0388, device='cuda:0') mean:  tensor(-3.3910e-05, device='cuda:0') min:  tensor(-0.1041, device='cuda:0') norm:  tensor(0.3293, device='cuda:0') MSE:  tensor(1.2361e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0046, device='cuda:0')
min of d_p_list:  tensor(-0.0032, device='cuda:0')
Epoch:  157  
Training Loss: 0.0106390081346035
Test Loss:  0.0021937598939985037
Test Acc:  0.0
Valid Loss:  0.0022258779499679804
Valid Acc:  0.0
std:  1.7826891802300296e-05 
thres:  1.0663964040577411e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(601.6501, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 16%|█▌        | 157/1000 [10:01<53:55,  3.84s/it]Epoch:   158
max of grad d_p:  tensor(0.0045, device='cuda:0')
min of grad d_p:  tensor(-0.0032, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0302, device='cuda:0') mean:  tensor(-3.2614e-05, device='cuda:0') min:  tensor(-0.1133, device='cuda:0') norm:  tensor(0.3203, device='cuda:0') MSE:  tensor(1.2022e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0045, device='cuda:0')
min of d_p_list:  tensor(-0.0032, device='cuda:0')
Epoch:  158  
Training Loss: 0.010627022944390774
Test Loss:  0.0021737939678132534
Test Acc:  0.0
Valid Loss:  0.0022057844325900078
Valid Acc:  0.0
std:  1.7471098317624982e-05 
thres:  1.065148264169693e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 16%|█▌        | 158/1000 [10:05<53:24,  3.81s/it]Epoch:   159
max of grad d_p:  tensor(0.0044, device='cuda:0')
min of grad d_p:  tensor(-0.0031, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0379, device='cuda:0') mean:  tensor(-3.1521e-05, device='cuda:0') min:  tensor(-0.1060, device='cuda:0') norm:  tensor(0.3199, device='cuda:0') MSE:  tensor(1.2007e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0044, device='cuda:0')
min of d_p_list:  tensor(-0.0031, device='cuda:0')
Epoch:  159  
Training Loss: 0.010615268722176552
Test Loss:  0.0021542245522141457
Test Acc:  0.0
Valid Loss:  0.0021861172281205654
Valid Acc:  0.0
std:  1.7126232268161164e-05 
thres:  1.0639248788356782e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 16%|█▌        | 159/1000 [10:09<53:49,  3.84s/it]Epoch:   160
max of grad d_p:  tensor(0.0044, device='cuda:0')
min of grad d_p:  tensor(-0.0031, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0401, device='cuda:0') mean:  tensor(-3.3735e-05, device='cuda:0') min:  tensor(-0.1074, device='cuda:0') norm:  tensor(0.3351, device='cuda:0') MSE:  tensor(1.2577e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0044, device='cuda:0')
min of d_p_list:  tensor(-0.0031, device='cuda:0')
Epoch:  160  
Training Loss: 0.01060374453663826
Test Loss:  0.0021350430324673653
Test Acc:  0.0
Valid Loss:  0.002166867023333907
Valid Acc:  0.0
std:  1.6790864421584964e-05 
thres:  1.0627255961298941e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 16%|█▌        | 160/1000 [10:13<53:46,  3.84s/it]Epoch:   161
max of grad d_p:  tensor(0.0043, device='cuda:0')
min of grad d_p:  tensor(-0.0030, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0364, device='cuda:0') mean:  tensor(-3.4758e-05, device='cuda:0') min:  tensor(-0.1052, device='cuda:0') norm:  tensor(0.3305, device='cuda:0') MSE:  tensor(1.2405e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0043, device='cuda:0')
min of d_p_list:  tensor(-0.0030, device='cuda:0')
Epoch:  161  
Training Loss: 0.010592440143227577
Test Loss:  0.002116240095347166
Test Acc:  0.0
Valid Loss:  0.002148022875189781
Valid Acc:  0.0
std:  1.646458013097812e-05 
thres:  1.0615496896207333e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 16%|█▌        | 161/1000 [10:16<52:26,  3.75s/it]Epoch:   162
max of grad d_p:  tensor(0.0042, device='cuda:0')
min of grad d_p:  tensor(-0.0030, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0362, device='cuda:0') mean:  tensor(-2.9080e-05, device='cuda:0') min:  tensor(-0.0985, device='cuda:0') norm:  tensor(0.2979, device='cuda:0') MSE:  tensor(1.1183e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0042, device='cuda:0')
min of d_p_list:  tensor(-0.0030, device='cuda:0')
Epoch:  162  
Training Loss: 0.010581348091363907
Test Loss:  0.002097806427627802
Test Acc:  0.0
Valid Loss:  0.002129573840647936
Valid Acc:  0.0
std:  1.6148302811636797e-05 
thres:  1.0603964887559413e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 16%|█▌        | 162/1000 [10:20<52:44,  3.78s/it]Epoch:   163
max of grad d_p:  tensor(0.0042, device='cuda:0')
min of grad d_p:  tensor(-0.0030, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0390, device='cuda:0') mean:  tensor(-3.3836e-05, device='cuda:0') min:  tensor(-0.1069, device='cuda:0') norm:  tensor(0.3344, device='cuda:0') MSE:  tensor(1.2553e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0042, device='cuda:0')
min of d_p_list:  tensor(-0.0030, device='cuda:0')
Epoch:  163  
Training Loss: 0.010570465587079525
Test Loss:  0.0020797327160835266
Test Acc:  0.0
Valid Loss:  0.0021115108393132687
Valid Acc:  0.0
std:  1.584058479399543e-05 
thres:  1.0592653416097164e-05
Preserved_eigens number check:  11
max of Lambda2 tensor(602.9271, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 16%|█▋        | 163/1000 [10:24<53:41,  3.85s/it]Epoch:   164
max of grad d_p:  tensor(0.0041, device='cuda:0')
min of grad d_p:  tensor(-0.0029, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0392, device='cuda:0') mean:  tensor(-3.5487e-05, device='cuda:0') min:  tensor(-0.1116, device='cuda:0') norm:  tensor(0.3463, device='cuda:0') MSE:  tensor(1.3000e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0041, device='cuda:0')
min of d_p_list:  tensor(-0.0029, device='cuda:0')
Epoch:  164  
Training Loss: 0.01055978611111641
Test Loss:  0.0020620108116418123
Test Acc:  0.0
Valid Loss:  0.0020938245579600334
Valid Acc:  0.0
std:  1.5541970754715435e-05 
thres:  1.0581556893885135e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 16%|█▋        | 164/1000 [10:28<52:20,  3.76s/it]Epoch:   165
max of grad d_p:  tensor(0.0041, device='cuda:0')
min of grad d_p:  tensor(-0.0029, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0315, device='cuda:0') mean:  tensor(-3.2537e-05, device='cuda:0') min:  tensor(-0.1004, device='cuda:0') norm:  tensor(0.3097, device='cuda:0') MSE:  tensor(1.1626e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0041, device='cuda:0')
min of d_p_list:  tensor(-0.0029, device='cuda:0')
Epoch:  165  
Training Loss: 0.010549301281571388
Test Loss:  0.002044632099568844
Test Acc:  0.0
Valid Loss:  0.002076504286378622
Valid Acc:  0.0
std:  1.5251778290031415e-05 
thres:  1.057066824287176e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(230.1887, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 16%|█▋        | 165/1000 [10:32<52:57,  3.81s/it]Epoch:   166
max of grad d_p:  tensor(0.0040, device='cuda:0')
min of grad d_p:  tensor(-0.0028, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0360, device='cuda:0') mean:  tensor(-3.5761e-05, device='cuda:0') min:  tensor(-0.1225, device='cuda:0') norm:  tensor(0.3522, device='cuda:0') MSE:  tensor(1.3219e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0040, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  166  
Training Loss: 0.010539006441831589
Test Loss:  0.002027588663622737
Test Acc:  0.0
Valid Loss:  0.0020595425739884377
Valid Acc:  0.0
std:  1.4970007455376456e-05 
thres:  1.0559981502592564e-05
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 17%|█▋        | 166/1000 [10:35<52:02,  3.74s/it]Epoch:   167
max of grad d_p:  tensor(0.0039, device='cuda:0')
min of grad d_p:  tensor(-0.0028, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0367, device='cuda:0') mean:  tensor(-3.0530e-05, device='cuda:0') min:  tensor(-0.1171, device='cuda:0') norm:  tensor(0.3314, device='cuda:0') MSE:  tensor(1.2441e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0039, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  167  
Training Loss: 0.010528897866606712
Test Loss:  0.002010872820392251
Test Acc:  0.0
Valid Loss:  0.0020429291762411594
Valid Acc:  0.0
std:  1.4696677930956421e-05 
thres:  1.0549491457641124e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 17%|█▋        | 167/1000 [10:39<51:38,  3.72s/it]Epoch:   168
max of grad d_p:  tensor(0.0039, device='cuda:0')
min of grad d_p:  tensor(-0.0028, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0355, device='cuda:0') mean:  tensor(-3.5478e-05, device='cuda:0') min:  tensor(-0.1097, device='cuda:0') norm:  tensor(0.3380, device='cuda:0') MSE:  tensor(1.2686e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0039, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  168  
Training Loss: 0.010518969967961311
Test Loss:  0.001994477352127433
Test Acc:  0.0
Valid Loss:  0.002026657108217478
Valid Acc:  0.0
std:  1.4430864006939206e-05 
thres:  1.0539192333817482e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(603.8909, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 17%|█▋        | 168/1000 [10:43<51:41,  3.73s/it]Epoch:   169
max of grad d_p:  tensor(0.0038, device='cuda:0')
min of grad d_p:  tensor(-0.0027, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0379, device='cuda:0') mean:  tensor(-3.3550e-05, device='cuda:0') min:  tensor(-0.1025, device='cuda:0') norm:  tensor(0.3239, device='cuda:0') MSE:  tensor(1.2158e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0038, device='cuda:0')
min of d_p_list:  tensor(-0.0027, device='cuda:0')
Epoch:  169  
Training Loss: 0.010509216226637363
Test Loss:  0.001978392945602536
Test Acc:  0.0
Valid Loss:  0.002010716823861003
Valid Acc:  0.0
std:  1.4172154916773951e-05 
thres:  1.0529078356921673e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 17%|█▋        | 169/1000 [10:46<51:22,  3.71s/it]Epoch:   170
max of grad d_p:  tensor(0.0038, device='cuda:0')
min of grad d_p:  tensor(-0.0027, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0375, device='cuda:0') mean:  tensor(-2.9908e-05, device='cuda:0') min:  tensor(-0.1221, device='cuda:0') norm:  tensor(0.3303, device='cuda:0') MSE:  tensor(1.2399e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0038, device='cuda:0')
min of d_p_list:  tensor(-0.0027, device='cuda:0')
Epoch:  170  
Training Loss: 0.01049963291734457
Test Loss:  0.0019626147113740444
Test Acc:  0.0
Valid Loss:  0.0019951006397604942
Valid Acc:  0.0
std:  1.3920688376889728e-05 
thres:  1.051914468407631e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 17%|█▋        | 170/1000 [10:50<52:02,  3.76s/it]Epoch:   171
max of grad d_p:  tensor(0.0037, device='cuda:0')
min of grad d_p:  tensor(-0.0026, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0364, device='cuda:0') mean:  tensor(-3.0147e-05, device='cuda:0') min:  tensor(-0.0982, device='cuda:0') norm:  tensor(0.3035, device='cuda:0') MSE:  tensor(1.1394e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0037, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  171  
Training Loss: 0.010490215383470058
Test Loss:  0.0019471326377242804
Test Acc:  0.0
Valid Loss:  0.001979799009859562
Valid Acc:  0.0
std:  1.3676471486915962e-05 
thres:  1.0509386472404005e-05
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 17%|█▋        | 171/1000 [10:54<53:05,  3.84s/it]Epoch:   172
max of grad d_p:  tensor(0.0037, device='cuda:0')
min of grad d_p:  tensor(-0.0026, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0399, device='cuda:0') mean:  tensor(-3.3092e-05, device='cuda:0') min:  tensor(-0.1247, device='cuda:0') norm:  tensor(0.3432, device='cuda:0') MSE:  tensor(1.2882e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0037, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  172  
Training Loss: 0.010480956174433231
Test Loss:  0.0019319425337016582
Test Acc:  0.0
Valid Loss:  0.0019648075103759766
Valid Acc:  0.0
std:  1.343975841259151e-05 
thres:  1.0499798133969308e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 17%|█▋        | 172/1000 [10:58<52:48,  3.83s/it]Epoch:   173
max of grad d_p:  tensor(0.0036, device='cuda:0')
min of grad d_p:  tensor(-0.0026, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0372, device='cuda:0') mean:  tensor(-3.0668e-05, device='cuda:0') min:  tensor(-0.1102, device='cuda:0') norm:  tensor(0.3158, device='cuda:0') MSE:  tensor(1.1855e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0036, device='cuda:0')
min of d_p_list:  tensor(-0.0026, device='cuda:0')
Epoch:  173  
Training Loss: 0.010471856221556664
Test Loss:  0.0019170353189110756
Test Acc:  0.0
Valid Loss:  0.0019501151982694864
Valid Acc:  0.0
std:  1.3208979987468299e-05 
thres:  1.0490375384688379e-05
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 17%|█▋        | 173/1000 [11:02<53:07,  3.85s/it]Epoch:   174
max of grad d_p:  tensor(0.0036, device='cuda:0')
min of grad d_p:  tensor(-0.0025, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0361, device='cuda:0') mean:  tensor(-3.1001e-05, device='cuda:0') min:  tensor(-0.1152, device='cuda:0') norm:  tensor(0.3263, device='cuda:0') MSE:  tensor(1.2248e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0036, device='cuda:0')
min of d_p_list:  tensor(-0.0025, device='cuda:0')
Epoch:  174  
Training Loss: 0.010462906211614609
Test Loss:  0.0019024061039090157
Test Acc:  0.0
Valid Loss:  0.0019357166020199656
Valid Acc:  0.0
std:  1.29849174604625e-05 
thres:  1.0481113381683828e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(230.9236, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 17%|█▋        | 174/1000 [11:06<53:57,  3.92s/it]Epoch:   175
max of grad d_p:  tensor(0.0035, device='cuda:0')
min of grad d_p:  tensor(-0.0025, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0375, device='cuda:0') mean:  tensor(-3.6684e-05, device='cuda:0') min:  tensor(-0.1202, device='cuda:0') norm:  tensor(0.3561, device='cuda:0') MSE:  tensor(1.3366e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0035, device='cuda:0')
min of d_p_list:  tensor(-0.0025, device='cuda:0')
Epoch:  175  
Training Loss: 0.010454105213284492
Test Loss:  0.0018880475545302033
Test Acc:  0.0
Valid Loss:  0.0019216046202927828
Valid Acc:  0.0
std:  1.2766785022674584e-05 
thres:  1.0472007840871812e-05
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 18%|█▊        | 175/1000 [11:10<54:06,  3.93s/it]Epoch:   176
max of grad d_p:  tensor(0.0035, device='cuda:0')
min of grad d_p:  tensor(-0.0025, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0397, device='cuda:0') mean:  tensor(-3.5550e-05, device='cuda:0') min:  tensor(-0.1103, device='cuda:0') norm:  tensor(0.3451, device='cuda:0') MSE:  tensor(1.2953e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0035, device='cuda:0')
min of d_p_list:  tensor(-0.0025, device='cuda:0')
Epoch:  176  
Training Loss: 0.010445447638630867
Test Loss:  0.0018739535007625818
Test Acc:  0.0
Valid Loss:  0.0019077714532613754
Valid Acc:  0.0
std:  1.2554310328260915e-05 
thres:  1.0463054291903973e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(231.0739, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 18%|█▊        | 176/1000 [11:14<53:23,  3.89s/it]Epoch:   177
max of grad d_p:  tensor(0.0034, device='cuda:0')
min of grad d_p:  tensor(-0.0024, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0401, device='cuda:0') mean:  tensor(-3.4517e-05, device='cuda:0') min:  tensor(-0.1085, device='cuda:0') norm:  tensor(0.3374, device='cuda:0') MSE:  tensor(1.2665e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0034, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  177  
Training Loss: 0.010436927899718285
Test Loss:  0.0018601176561787724
Test Acc:  0.0
Valid Loss:  0.0018942103488370776
Valid Acc:  0.0
std:  1.2348819496335921e-05 
thres:  1.0454248636960984e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 18%|█▊        | 177/1000 [11:18<53:16,  3.88s/it]Epoch:   178
max of grad d_p:  tensor(0.0034, device='cuda:0')
min of grad d_p:  tensor(-0.0024, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0344, device='cuda:0') mean:  tensor(-3.3622e-05, device='cuda:0') min:  tensor(-0.0993, device='cuda:0') norm:  tensor(0.3160, device='cuda:0') MSE:  tensor(1.1862e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0034, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  178  
Training Loss: 0.010428545996546745
Test Loss:  0.0018465350149199367
Test Acc:  0.0
Valid Loss:  0.0018809153698384762
Valid Acc:  0.0
std:  1.2148335570382184e-05 
thres:  1.0445586591959e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 18%|█▊        | 178/1000 [11:22<53:40,  3.92s/it]Epoch:   179
max of grad d_p:  tensor(0.0033, device='cuda:0')
min of grad d_p:  tensor(-0.0024, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0365, device='cuda:0') mean:  tensor(-3.4640e-05, device='cuda:0') min:  tensor(-0.1252, device='cuda:0') norm:  tensor(0.3521, device='cuda:0') MSE:  tensor(1.3215e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0033, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  179  
Training Loss: 0.010420296341180801
Test Loss:  0.0018331989413127303
Test Acc:  0.0
Valid Loss:  0.0018678797641769052
Valid Acc:  0.0
std:  1.1953389756760124e-05 
thres:  1.043706461787224e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 18%|█▊        | 179/1000 [11:25<52:38,  3.85s/it]Epoch:   180
max of grad d_p:  tensor(0.0033, device='cuda:0')
min of grad d_p:  tensor(-0.0024, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0312, device='cuda:0') mean:  tensor(-3.1518e-05, device='cuda:0') min:  tensor(-0.0969, device='cuda:0') norm:  tensor(0.3005, device='cuda:0') MSE:  tensor(1.1280e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0033, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  180  
Training Loss: 0.01041217427700758
Test Loss:  0.0018201033817604184
Test Acc:  0.0
Valid Loss:  0.0018550967797636986
Valid Acc:  0.0
std:  1.1763707972643022e-05 
thres:  1.0428678430616855e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(605.9102, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 18%|█▊        | 180/1000 [11:29<52:21,  3.83s/it]Epoch:   181
max of grad d_p:  tensor(0.0032, device='cuda:0')
min of grad d_p:  tensor(-0.0023, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0397, device='cuda:0') mean:  tensor(-3.1991e-05, device='cuda:0') min:  tensor(-0.1032, device='cuda:0') norm:  tensor(0.3216, device='cuda:0') MSE:  tensor(1.2072e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0032, device='cuda:0')
min of d_p_list:  tensor(-0.0023, device='cuda:0')
Epoch:  181  
Training Loss: 0.010404177010059357
Test Loss:  0.0018072433304041624
Test Acc:  0.0
Valid Loss:  0.0018425609450787306
Valid Acc:  0.0
std:  1.1579157497062212e-05 
thres:  1.0420424304902554e-05
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 18%|█▊        | 181/1000 [11:33<51:22,  3.76s/it]Epoch:   182
max of grad d_p:  tensor(0.0032, device='cuda:0')
min of grad d_p:  tensor(-0.0023, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0390, device='cuda:0') mean:  tensor(-3.3713e-05, device='cuda:0') min:  tensor(-0.1065, device='cuda:0') norm:  tensor(0.3346, device='cuda:0') MSE:  tensor(1.2561e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0032, device='cuda:0')
min of d_p_list:  tensor(-0.0023, device='cuda:0')
Epoch:  182  
Training Loss: 0.010396301746368408
Test Loss:  0.001794614945538342
Test Acc:  0.0
Valid Loss:  0.0018302671378478408
Valid Acc:  0.0
std:  1.1400147042023357e-05 
thres:  1.041229907423258e-05
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 18%|█▊        | 182/1000 [11:37<52:17,  3.84s/it]Epoch:   183
max of grad d_p:  tensor(0.0031, device='cuda:0')
min of grad d_p:  tensor(-0.0023, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0400, device='cuda:0') mean:  tensor(-3.5693e-05, device='cuda:0') min:  tensor(-0.1107, device='cuda:0') norm:  tensor(0.3511, device='cuda:0') MSE:  tensor(1.3181e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0031, device='cuda:0')
min of d_p_list:  tensor(-0.0023, device='cuda:0')
Epoch:  183  
Training Loss: 0.010388544760644436
Test Loss:  0.0017822099616751075
Test Acc:  0.0
Valid Loss:  0.0018182073254138231
Valid Acc:  0.0
std:  1.1225880077014505e-05 
thres:  1.0404298827052117e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(231.5624, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 18%|█▊        | 183/1000 [11:41<52:24,  3.85s/it]Epoch:   184
max of grad d_p:  tensor(0.0031, device='cuda:0')
min of grad d_p:  tensor(-0.0022, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0352, device='cuda:0') mean:  tensor(-3.1018e-05, device='cuda:0') min:  tensor(-0.0934, device='cuda:0') norm:  tensor(0.2996, device='cuda:0') MSE:  tensor(1.1248e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0031, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  184  
Training Loss: 0.010380902327597141
Test Loss:  0.0017700251191854477
Test Acc:  0.0
Valid Loss:  0.0018063782481476665
Valid Acc:  0.0
std:  1.1056219830672792e-05 
thres:  1.0396420024335384e-05
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 18%|█▊        | 184/1000 [11:44<52:23,  3.85s/it]Epoch:   185
max of grad d_p:  tensor(0.0030, device='cuda:0')
min of grad d_p:  tensor(-0.0022, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0384, device='cuda:0') mean:  tensor(-3.4516e-05, device='cuda:0') min:  tensor(-0.1095, device='cuda:0') norm:  tensor(0.3331, device='cuda:0') MSE:  tensor(1.2503e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0030, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  185  
Training Loss: 0.010373372584581375
Test Loss:  0.001758055528625846
Test Acc:  0.0
Valid Loss:  0.001794772339053452
Valid Acc:  0.0
std:  1.0891039616570703e-05 
thres:  1.0388659685850144e-05
Preserved_eigens number check:  5
max of Lambda2 tensor(231.6909, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 18%|█▊        | 185/1000 [11:48<52:47,  3.89s/it]Epoch:   186
max of grad d_p:  tensor(0.0030, device='cuda:0')
min of grad d_p:  tensor(-0.0022, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0346, device='cuda:0') mean:  tensor(-3.5261e-05, device='cuda:0') min:  tensor(-0.1155, device='cuda:0') norm:  tensor(0.3433, device='cuda:0') MSE:  tensor(1.2886e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0030, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  186  
Training Loss: 0.010365951806306839
Test Loss:  0.0017462954856455326
Test Acc:  0.0
Valid Loss:  0.0017833864549174905
Valid Acc:  0.0
std:  1.0730339435485277e-05 
thres:  1.038101464509964e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(606.7739, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 19%|█▊        | 186/1000 [11:52<53:14,  3.92s/it]Epoch:   187
max of grad d_p:  tensor(0.0030, device='cuda:0')
min of grad d_p:  tensor(-0.0022, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0372, device='cuda:0') mean:  tensor(-3.5126e-05, device='cuda:0') min:  tensor(-0.1110, device='cuda:0') norm:  tensor(0.3393, device='cuda:0') MSE:  tensor(1.2737e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0030, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  187  
Training Loss: 0.010358637198805809
Test Loss:  0.0017347419634461403
Test Acc:  0.0
Valid Loss:  0.0017722139600664377
Valid Acc:  0.0
std:  1.0573853893602848e-05 
thres:  1.037348173558712e-05
Preserved_eigens number check:  6
max of Lambda2 tensor(606.9118, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 19%|█▊        | 187/1000 [11:56<52:10,  3.85s/it]Epoch:   188
max of grad d_p:  tensor(0.0029, device='cuda:0')
min of grad d_p:  tensor(-0.0021, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0383, device='cuda:0') mean:  tensor(-3.4677e-05, device='cuda:0') min:  tensor(-0.1282, device='cuda:0') norm:  tensor(0.3487, device='cuda:0') MSE:  tensor(1.3090e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0029, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  188  
Training Loss: 0.010351425036787987
Test Loss:  0.001723388908430934
Test Acc:  0.0
Valid Loss:  0.001761250663548708
Valid Acc:  0.0
std:  1.042171184613024e-05 
thres:  1.0366057790815831e-05
Preserved_eigens number check:  9
max of Lambda2 tensor(231.8787, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 19%|█▉        | 188/1000 [12:00<51:36,  3.81s/it]Epoch:   189
max of grad d_p:  tensor(0.0029, device='cuda:0')
min of grad d_p:  tensor(-0.0021, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-3.3752e-05, device='cuda:0') min:  tensor(-0.1041, device='cuda:0') norm:  tensor(0.3239, device='cuda:0') MSE:  tensor(1.2158e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0029, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  189  
Training Loss: 0.010344315320253372
Test Loss:  0.0017122304998338223
Test Acc:  0.0
Valid Loss:  0.0017504894640296698
Valid Acc:  0.0
std:  1.027339594926539e-05 
thres:  1.0358740389347077e-05
Preserved_eigens number check:  7
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 19%|█▉        | 189/1000 [12:04<52:00,  3.85s/it]Epoch:   190
max of grad d_p:  tensor(0.0028, device='cuda:0')
min of grad d_p:  tensor(-0.0021, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-3.4772e-05, device='cuda:0') min:  tensor(-0.1159, device='cuda:0') norm:  tensor(0.3345, device='cuda:0') MSE:  tensor(1.2558e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0028, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  190  
Training Loss: 0.010340802371501923
Test Loss:  0.0017067405860871077
Test Acc:  0.0
Valid Loss:  0.001745202112942934
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 19%|█▉        | 190/1000 [12:08<51:41,  3.83s/it]Epoch:   191
max of grad d_p:  tensor(0.0028, device='cuda:0')
min of grad d_p:  tensor(-0.0021, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0339, device='cuda:0') mean:  tensor(-3.2819e-05, device='cuda:0') min:  tensor(-0.1157, device='cuda:0') norm:  tensor(0.3302, device='cuda:0') MSE:  tensor(1.2393e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0028, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  191  
Training Loss: 0.010337314568459988
Test Loss:  0.0017012989846989512
Test Acc:  0.0
Valid Loss:  0.0017399638891220093
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 19%|█▉        | 191/1000 [12:11<51:06,  3.79s/it]Epoch:   192
max of grad d_p:  tensor(0.0028, device='cuda:0')
min of grad d_p:  tensor(-0.0021, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0337, device='cuda:0') mean:  tensor(-3.1928e-05, device='cuda:0') min:  tensor(-0.0994, device='cuda:0') norm:  tensor(0.3040, device='cuda:0') MSE:  tensor(1.1412e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0028, device='cuda:0')
min of d_p_list:  tensor(-0.0021, device='cuda:0')
Epoch:  192  
Training Loss: 0.010333850048482418
Test Loss:  0.0016959027852863073
Test Acc:  0.0
Valid Loss:  0.001734772464260459
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 19%|█▉        | 192/1000 [12:15<50:42,  3.77s/it]Epoch:   193
max of grad d_p:  tensor(0.0028, device='cuda:0')
min of grad d_p:  tensor(-0.0020, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0400, device='cuda:0') mean:  tensor(-3.1892e-05, device='cuda:0') min:  tensor(-0.1079, device='cuda:0') norm:  tensor(0.3236, device='cuda:0') MSE:  tensor(1.2147e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0028, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  193  
Training Loss: 0.01033040788024664
Test Loss:  0.001690552686341107
Test Acc:  0.0
Valid Loss:  0.0017296290025115013
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 19%|█▉        | 193/1000 [12:19<51:44,  3.85s/it]Epoch:   194
max of grad d_p:  tensor(0.0028, device='cuda:0')
min of grad d_p:  tensor(-0.0020, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0362, device='cuda:0') mean:  tensor(-3.4087e-05, device='cuda:0') min:  tensor(-0.1142, device='cuda:0') norm:  tensor(0.3341, device='cuda:0') MSE:  tensor(1.2543e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0028, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  194  
Training Loss: 0.010326988995075226
Test Loss:  0.001685247989371419
Test Acc:  0.0
Valid Loss:  0.00172453373670578
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.4928, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 19%|█▉        | 194/1000 [12:23<51:43,  3.85s/it]Epoch:   195
max of grad d_p:  tensor(0.0028, device='cuda:0')
min of grad d_p:  tensor(-0.0020, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0349, device='cuda:0') mean:  tensor(-3.2589e-05, device='cuda:0') min:  tensor(-0.1058, device='cuda:0') norm:  tensor(0.3160, device='cuda:0') MSE:  tensor(1.1861e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0028, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  195  
Training Loss: 0.010323594324290752
Test Loss:  0.0016799882287159562
Test Acc:  0.0
Valid Loss:  0.0017194830579683185
Valid Acc:  0.0
std:  4.8510096745665346e-06 
thres:  1.0330431163311005e-05
Preserved_eigens number check:  11
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 20%|█▉        | 195/1000 [12:27<52:19,  3.90s/it]Epoch:   196
max of grad d_p:  tensor(0.0027, device='cuda:0')
min of grad d_p:  tensor(-0.0020, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0342, device='cuda:0') mean:  tensor(-3.2186e-05, device='cuda:0') min:  tensor(-0.1114, device='cuda:0') norm:  tensor(0.3201, device='cuda:0') MSE:  tensor(1.2017e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  196  
Training Loss: 0.010321905836462975
Test Loss:  0.0016773793613538146
Test Acc:  0.0
Valid Loss:  0.001716979662887752
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 20%|█▉        | 196/1000 [12:31<52:36,  3.93s/it]Epoch:   197
max of grad d_p:  tensor(0.0027, device='cuda:0')
min of grad d_p:  tensor(-0.0020, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-3.5476e-05, device='cuda:0') min:  tensor(-0.1171, device='cuda:0') norm:  tensor(0.3469, device='cuda:0') MSE:  tensor(1.3022e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  197  
Training Loss: 0.010320223867893219
Test Loss:  0.001674781902693212
Test Acc:  0.0
Valid Loss:  0.0017144880257546902
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 20%|█▉        | 197/1000 [12:35<52:33,  3.93s/it]Epoch:   198
max of grad d_p:  tensor(0.0027, device='cuda:0')
min of grad d_p:  tensor(-0.0020, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0402, device='cuda:0') mean:  tensor(-3.4732e-05, device='cuda:0') min:  tensor(-0.1220, device='cuda:0') norm:  tensor(0.3533, device='cuda:0') MSE:  tensor(1.3263e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  198  
Training Loss: 0.010318545624613762
Test Loss:  0.001672194804996252
Test Acc:  0.0
Valid Loss:  0.0017120075644925237
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.6372, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 20%|█▉        | 198/1000 [12:39<52:44,  3.95s/it]Epoch:   199
max of grad d_p:  tensor(0.0027, device='cuda:0')
min of grad d_p:  tensor(-0.0020, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0391, device='cuda:0') mean:  tensor(-3.4146e-05, device='cuda:0') min:  tensor(-0.1282, device='cuda:0') norm:  tensor(0.3551, device='cuda:0') MSE:  tensor(1.3328e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  199  
Training Loss: 0.010316875763237476
Test Loss:  0.0016696187667548656
Test Acc:  0.0
Valid Loss:  0.0017095383955165744
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 20%|█▉        | 199/1000 [12:43<52:15,  3.92s/it]Epoch:   200
max of grad d_p:  tensor(0.0027, device='cuda:0')
min of grad d_p:  tensor(-0.0020, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0374, device='cuda:0') mean:  tensor(-3.4217e-05, device='cuda:0') min:  tensor(-0.1205, device='cuda:0') norm:  tensor(0.3391, device='cuda:0') MSE:  tensor(1.2730e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  200  
Training Loss: 0.01031520962715149
Test Loss:  0.0016670532058924437
Test Acc:  0.0
Valid Loss:  0.0017070797039195895
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  10
max of Lambda2 tensor(232.1898, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 20%|██        | 200/1000 [12:47<52:33,  3.94s/it]Epoch:   201
max of grad d_p:  tensor(0.0027, device='cuda:0')
min of grad d_p:  tensor(-0.0020, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0323, device='cuda:0') mean:  tensor(-3.6353e-05, device='cuda:0') min:  tensor(-0.1083, device='cuda:0') norm:  tensor(0.3409, device='cuda:0') MSE:  tensor(1.2797e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  201  
Training Loss: 0.010313550010323524
Test Loss:  0.0016644990537315607
Test Acc:  0.0
Valid Loss:  0.0017046311404556036
Valid Acc:  0.0
std:  2.359438395092489e-06 
thres:  1.0316880978643895e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 20%|██        | 201/1000 [12:51<52:29,  3.94s/it]Epoch:   202
max of grad d_p:  tensor(0.0027, device='cuda:0')
min of grad d_p:  tensor(-0.0020, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0375, device='cuda:0') mean:  tensor(-3.4290e-05, device='cuda:0') min:  tensor(-0.1115, device='cuda:0') norm:  tensor(0.3320, device='cuda:0') MSE:  tensor(1.2463e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  202  
Training Loss: 0.010312721133232117
Test Loss:  0.0016632266342639923
Test Acc:  0.0
Valid Loss:  0.0017034141346812248
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.7490, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 20%|██        | 202/1000 [12:55<52:22,  3.94s/it]Epoch:   203
max of grad d_p:  tensor(0.0027, device='cuda:0')
min of grad d_p:  tensor(-0.0020, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0400, device='cuda:0') mean:  tensor(-3.3270e-05, device='cuda:0') min:  tensor(-0.1332, device='cuda:0') norm:  tensor(0.3583, device='cuda:0') MSE:  tensor(1.3451e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  203  
Training Loss: 0.010311895050108433
Test Loss:  0.0016619573580101132
Test Acc:  0.0
Valid Loss:  0.0017021987587213516
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2190, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 20%|██        | 203/1000 [12:58<51:45,  3.90s/it]Epoch:   204
max of grad d_p:  tensor(0.0027, device='cuda:0')
min of grad d_p:  tensor(-0.0020, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0344, device='cuda:0') mean:  tensor(-3.4485e-05, device='cuda:0') min:  tensor(-0.1106, device='cuda:0') norm:  tensor(0.3348, device='cuda:0') MSE:  tensor(1.2567e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  204  
Training Loss: 0.010311068966984749
Test Loss:  0.0016606899444013834
Test Acc:  0.0
Valid Loss:  0.0017009847797453403
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 20%|██        | 204/1000 [13:02<52:10,  3.93s/it]Epoch:   205
max of grad d_p:  tensor(0.0027, device='cuda:0')
min of grad d_p:  tensor(-0.0020, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0385, device='cuda:0') mean:  tensor(-3.3181e-05, device='cuda:0') min:  tensor(-0.1135, device='cuda:0') norm:  tensor(0.3264, device='cuda:0') MSE:  tensor(1.2251e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  205  
Training Loss: 0.010310246609151363
Test Loss:  0.0016594259068369865
Test Acc:  0.0
Valid Loss:  0.001699774875305593
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2334, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 20%|██        | 205/1000 [13:06<52:48,  3.99s/it]Epoch:   206
max of grad d_p:  tensor(0.0027, device='cuda:0')
min of grad d_p:  tensor(-0.0020, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0333, device='cuda:0') mean:  tensor(-3.4380e-05, device='cuda:0') min:  tensor(-0.1060, device='cuda:0') norm:  tensor(0.3314, device='cuda:0') MSE:  tensor(1.2441e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  206  
Training Loss: 0.010309423319995403
Test Loss:  0.001658164313994348
Test Acc:  0.0
Valid Loss:  0.0016985676484182477
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 21%|██        | 206/1000 [13:10<51:53,  3.92s/it]Epoch:   207
max of grad d_p:  tensor(0.0027, device='cuda:0')
min of grad d_p:  tensor(-0.0020, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0310, device='cuda:0') mean:  tensor(-3.2748e-05, device='cuda:0') min:  tensor(-0.1058, device='cuda:0') norm:  tensor(0.3141, device='cuda:0') MSE:  tensor(1.1790e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  207  
Training Loss: 0.010308601893484592
Test Loss:  0.001656905049458146
Test Acc:  0.0
Valid Loss:  0.0016973624005913734
Valid Acc:  0.0
std:  1.1641755101930643e-06 
thres:  1.0310247167944907e-05
Preserved_eigens number check:  6
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 21%|██        | 207/1000 [13:14<50:53,  3.85s/it]Epoch:   208
max of grad d_p:  tensor(0.0027, device='cuda:0')
min of grad d_p:  tensor(-0.0020, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0370, device='cuda:0') mean:  tensor(-3.5076e-05, device='cuda:0') min:  tensor(-0.1066, device='cuda:0') norm:  tensor(0.3418, device='cuda:0') MSE:  tensor(1.2829e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0020, device='cuda:0')
Epoch:  208  
Training Loss: 0.010308191180229187
Test Loss:  0.0016562766395509243
Test Acc:  0.0
Valid Loss:  0.0016967611154541373
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 21%|██        | 208/1000 [13:18<51:16,  3.88s/it]Epoch:   209
max of grad d_p:  tensor(0.0027, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0378, device='cuda:0') mean:  tensor(-3.5860e-05, device='cuda:0') min:  tensor(-0.1204, device='cuda:0') norm:  tensor(0.3561, device='cuda:0') MSE:  tensor(1.3367e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  209  
Training Loss: 0.010307781398296356
Test Loss:  0.0016556488117203116
Test Acc:  0.0
Valid Loss:  0.0016961605288088322
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 21%|██        | 209/1000 [13:22<50:33,  3.83s/it]Epoch:   210
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0322, device='cuda:0') mean:  tensor(-3.3273e-05, device='cuda:0') min:  tensor(-0.0976, device='cuda:0') norm:  tensor(0.3137, device='cuda:0') MSE:  tensor(1.1774e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  210  
Training Loss: 0.0103073725476861
Test Loss:  0.00165502168238163
Test Acc:  0.0
Valid Loss:  0.0016955607570707798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  5
max of Lambda2 tensor(607.8283, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 21%|██        | 210/1000 [13:26<50:56,  3.87s/it]Epoch:   211
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-3.3466e-05, device='cuda:0') min:  tensor(-0.1275, device='cuda:0') norm:  tensor(0.3433, device='cuda:0') MSE:  tensor(1.2887e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  211  
Training Loss: 0.010306963697075844
Test Loss:  0.001654394785873592
Test Acc:  0.0
Valid Loss:  0.0016949608689174056
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.8431, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 21%|██        | 211/1000 [13:30<51:24,  3.91s/it]Epoch:   212
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0351, device='cuda:0') mean:  tensor(-3.2521e-05, device='cuda:0') min:  tensor(-0.1162, device='cuda:0') norm:  tensor(0.3335, device='cuda:0') MSE:  tensor(1.2519e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  212  
Training Loss: 0.010306554846465588
Test Loss:  0.0016537694027647376
Test Acc:  0.0
Valid Loss:  0.0016943622613325715
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 21%|██        | 212/1000 [13:33<51:15,  3.90s/it]Epoch:   213
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0372, device='cuda:0') mean:  tensor(-3.5868e-05, device='cuda:0') min:  tensor(-0.1365, device='cuda:0') norm:  tensor(0.3740, device='cuda:0') MSE:  tensor(1.4040e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  213  
Training Loss: 0.010306145995855331
Test Loss:  0.0016531447181478143
Test Acc:  0.0
Valid Loss:  0.0016937649343162775
Valid Acc:  0.0
std:  5.782020780088275e-07 
thres:  1.0306963697075844e-05
Preserved_eigens number check:  9
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2689, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 21%|██▏       | 213/1000 [13:37<50:07,  3.82s/it]Epoch:   214
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0392, device='cuda:0') mean:  tensor(-3.4559e-05, device='cuda:0') min:  tensor(-0.1167, device='cuda:0') norm:  tensor(0.3473, device='cuda:0') MSE:  tensor(1.3038e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  214  
Training Loss: 0.01030594203621149
Test Loss:  0.001652832143008709
Test Acc:  0.0
Valid Loss:  0.0016934662126004696
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 21%|██▏       | 214/1000 [13:41<48:52,  3.73s/it]Epoch:   215
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0421, device='cuda:0') mean:  tensor(-3.4367e-05, device='cuda:0') min:  tensor(-0.1363, device='cuda:0') norm:  tensor(0.3687, device='cuda:0') MSE:  tensor(1.3839e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  215  
Training Loss: 0.010305739007890224
Test Loss:  0.0016525211976841092
Test Acc:  0.0
Valid Loss:  0.0016931690042838454
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  15
max of Lambda2 tensor(232.2708, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 22%|██▏       | 215/1000 [13:44<49:07,  3.76s/it]Epoch:   216
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0422, device='cuda:0') mean:  tensor(-3.6290e-05, device='cuda:0') min:  tensor(-0.1107, device='cuda:0') norm:  tensor(0.3492, device='cuda:0') MSE:  tensor(1.3109e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  216  
Training Loss: 0.010305535048246384
Test Loss:  0.0016522090882062912
Test Acc:  0.0
Valid Loss:  0.0016928707482293248
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 22%|██▏       | 216/1000 [13:48<49:02,  3.75s/it]Epoch:   217
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0354, device='cuda:0') mean:  tensor(-3.2590e-05, device='cuda:0') min:  tensor(-0.1014, device='cuda:0') norm:  tensor(0.3066, device='cuda:0') MSE:  tensor(1.1509e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  217  
Training Loss: 0.010305331088602543
Test Loss:  0.001651897793635726
Test Acc:  0.0
Valid Loss:  0.0016925729578360915
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 22%|██▏       | 217/1000 [13:52<49:54,  3.82s/it]Epoch:   218
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0345, device='cuda:0') mean:  tensor(-3.3518e-05, device='cuda:0') min:  tensor(-0.1081, device='cuda:0') norm:  tensor(0.3230, device='cuda:0') MSE:  tensor(1.2125e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  218  
Training Loss: 0.010305127128958702
Test Loss:  0.0016515864990651608
Test Acc:  0.0
Valid Loss:  0.00169227528385818
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 22%|██▏       | 218/1000 [13:56<50:27,  3.87s/it]Epoch:   219
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0398, device='cuda:0') mean:  tensor(-3.5206e-05, device='cuda:0') min:  tensor(-0.1289, device='cuda:0') norm:  tensor(0.3623, device='cuda:0') MSE:  tensor(1.3598e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  219  
Training Loss: 0.010304924100637436
Test Loss:  0.0016512747388333082
Test Acc:  0.0
Valid Loss:  0.0016919774934649467
Valid Acc:  0.0
std:  2.881791970852618e-07 
thres:  1.0305331274867058e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2778, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 22%|██▏       | 219/1000 [14:00<50:06,  3.85s/it]Epoch:   220
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0326, device='cuda:0') mean:  tensor(-3.3645e-05, device='cuda:0') min:  tensor(-0.1116, device='cuda:0') norm:  tensor(0.3294, device='cuda:0') MSE:  tensor(1.2365e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  220  
Training Loss: 0.010304823517799377
Test Loss:  0.0016511200228706002
Test Acc:  0.0
Valid Loss:  0.0016918291803449392
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.8903, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 22%|██▏       | 220/1000 [14:04<49:55,  3.84s/it]Epoch:   221
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0315, device='cuda:0') mean:  tensor(-3.2271e-05, device='cuda:0') min:  tensor(-0.1049, device='cuda:0') norm:  tensor(0.3066, device='cuda:0') MSE:  tensor(1.1508e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  221  
Training Loss: 0.010304722003638744
Test Loss:  0.0016509643755853176
Test Acc:  0.0
Valid Loss:  0.0016916807508096099
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  11
max of Lambda2 tensor(607.8920, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 22%|██▏       | 221/1000 [14:08<49:35,  3.82s/it]Epoch:   222
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-3.1236e-05, device='cuda:0') min:  tensor(-0.1113, device='cuda:0') norm:  tensor(0.3151, device='cuda:0') MSE:  tensor(1.1829e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  222  
Training Loss: 0.010304619558155537
Test Loss:  0.0016508095432072878
Test Acc:  0.0
Valid Loss:  0.0016915330197662115
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  17
max of Lambda2 tensor(607.8969, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 22%|██▏       | 222/1000 [14:11<49:46,  3.84s/it]Epoch:   223
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0394, device='cuda:0') mean:  tensor(-3.5453e-05, device='cuda:0') min:  tensor(-0.1185, device='cuda:0') norm:  tensor(0.3506, device='cuda:0') MSE:  tensor(1.3159e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  223  
Training Loss: 0.010304518043994904
Test Loss:  0.0016506544779986143
Test Acc:  0.0
Valid Loss:  0.001691384706646204
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.8870, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 22%|██▏       | 223/1000 [14:15<48:51,  3.77s/it]Epoch:   224
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0396, device='cuda:0') mean:  tensor(-3.3910e-05, device='cuda:0') min:  tensor(-0.1025, device='cuda:0') norm:  tensor(0.3316, device='cuda:0') MSE:  tensor(1.2446e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  224  
Training Loss: 0.01030441652983427
Test Loss:  0.0016504998784512281
Test Acc:  0.0
Valid Loss:  0.0016912368591874838
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.8901, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 22%|██▏       | 224/1000 [14:19<48:37,  3.76s/it]Epoch:   225
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0396, device='cuda:0') mean:  tensor(-3.3364e-05, device='cuda:0') min:  tensor(-0.1206, device='cuda:0') norm:  tensor(0.3392, device='cuda:0') MSE:  tensor(1.2733e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  225  
Training Loss: 0.010304315015673637
Test Loss:  0.0016503441147506237
Test Acc:  0.0
Valid Loss:  0.0016910879639908671
Valid Acc:  0.0
std:  1.438263617683181e-07 
thres:  1.0304518230259419e-05
Preserved_eigens number check:  6
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 22%|██▎       | 225/1000 [14:22<47:18,  3.66s/it]Epoch:   226
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0328, device='cuda:0') mean:  tensor(-3.1857e-05, device='cuda:0') min:  tensor(-0.1214, device='cuda:0') norm:  tensor(0.3328, device='cuda:0') MSE:  tensor(1.2491e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  226  
Training Loss: 0.010304264724254608
Test Loss:  0.0016502670478075743
Test Acc:  0.0
Valid Loss:  0.001691014040261507
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 23%|██▎       | 226/1000 [14:26<47:19,  3.67s/it]Epoch:   227
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0361, device='cuda:0') mean:  tensor(-3.5868e-05, device='cuda:0') min:  tensor(-0.1245, device='cuda:0') norm:  tensor(0.3531, device='cuda:0') MSE:  tensor(1.3253e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  227  
Training Loss: 0.010304214432835579
Test Loss:  0.0016501895152032375
Test Acc:  0.0
Valid Loss:  0.001690940116532147
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 23%|██▎       | 227/1000 [14:30<47:51,  3.72s/it]Epoch:   228
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0402, device='cuda:0') mean:  tensor(-3.7386e-05, device='cuda:0') min:  tensor(-0.1307, device='cuda:0') norm:  tensor(0.3699, device='cuda:0') MSE:  tensor(1.3886e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  228  
Training Loss: 0.01030416414141655
Test Loss:  0.0016501122154295444
Test Acc:  0.0
Valid Loss:  0.0016908665420487523
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2858, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 23%|██▎       | 228/1000 [14:33<48:11,  3.75s/it]Epoch:   229
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0396, device='cuda:0') mean:  tensor(-3.1707e-05, device='cuda:0') min:  tensor(-0.1150, device='cuda:0') norm:  tensor(0.3283, device='cuda:0') MSE:  tensor(1.2322e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  229  
Training Loss: 0.01030411384999752
Test Loss:  0.001650035148486495
Test Acc:  0.0
Valid Loss:  0.0016907925019040704
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 23%|██▎       | 229/1000 [14:37<48:31,  3.78s/it]Epoch:   230
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0335, device='cuda:0') mean:  tensor(-3.1099e-05, device='cuda:0') min:  tensor(-0.0978, device='cuda:0') norm:  tensor(0.3035, device='cuda:0') MSE:  tensor(1.1392e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  230  
Training Loss: 0.010304063558578491
Test Loss:  0.0016499576158821583
Test Acc:  0.0
Valid Loss:  0.0016907185781747103
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.8884, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 23%|██▎       | 230/1000 [14:41<47:53,  3.73s/it]Epoch:   231
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0356, device='cuda:0') mean:  tensor(-3.3174e-05, device='cuda:0') min:  tensor(-0.1135, device='cuda:0') norm:  tensor(0.3257, device='cuda:0') MSE:  tensor(1.2225e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  231  
Training Loss: 0.010304013267159462
Test Loss:  0.0016498803161084652
Test Acc:  0.0
Valid Loss:  0.0016906450036913157
Valid Acc:  0.0
std:  7.112280686213368e-08 
thres:  1.0304113849997521e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 23%|██▎       | 231/1000 [14:45<47:10,  3.68s/it]Epoch:   232
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0383, device='cuda:0') mean:  tensor(-3.3539e-05, device='cuda:0') min:  tensor(-0.1037, device='cuda:0') norm:  tensor(0.3277, device='cuda:0') MSE:  tensor(1.2303e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  232  
Training Loss: 0.010303987190127373
Test Loss:  0.0016498422482982278
Test Acc:  0.0
Valid Loss:  0.0016906078672036529
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  13
max of Lambda2 tensor(607.9030, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 23%|██▎       | 232/1000 [14:48<46:58,  3.67s/it]Epoch:   233
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0353, device='cuda:0') mean:  tensor(-3.3934e-05, device='cuda:0') min:  tensor(-0.1170, device='cuda:0') norm:  tensor(0.3312, device='cuda:0') MSE:  tensor(1.2432e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  233  
Training Loss: 0.010303962044417858
Test Loss:  0.0016498040640726686
Test Acc:  0.0
Valid Loss:  0.001690572127699852
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 23%|██▎       | 233/1000 [14:52<48:09,  3.77s/it]Epoch:   234
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0409, device='cuda:0') mean:  tensor(-3.5017e-05, device='cuda:0') min:  tensor(-0.1102, device='cuda:0') norm:  tensor(0.3433, device='cuda:0') MSE:  tensor(1.2888e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  234  
Training Loss: 0.010303936898708344
Test Loss:  0.0016497655306011438
Test Acc:  0.0
Valid Loss:  0.0016905353404581547
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  69
 23%|██▎       | 234/1000 [14:56<47:28,  3.72s/it]Epoch:   235
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0397, device='cuda:0') mean:  tensor(-3.4150e-05, device='cuda:0') min:  tensor(-0.1302, device='cuda:0') norm:  tensor(0.3576, device='cuda:0') MSE:  tensor(1.3423e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  235  
Training Loss: 0.010303912684321404
Test Loss:  0.0016497272299602628
Test Acc:  0.0
Valid Loss:  0.001690498786047101
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  69
max of Lambda2 tensor(607.9080, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 24%|██▎       | 235/1000 [15:00<47:59,  3.76s/it]Epoch:   236
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0385, device='cuda:0') mean:  tensor(-3.2662e-05, device='cuda:0') min:  tensor(-0.1130, device='cuda:0') norm:  tensor(0.3285, device='cuda:0') MSE:  tensor(1.2331e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  236  
Training Loss: 0.010303886607289314
Test Loss:  0.0016496889293193817
Test Acc:  0.0
Valid Loss:  0.001690462464466691
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 24%|██▎       | 236/1000 [15:03<46:20,  3.64s/it]Epoch:   237
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0401, device='cuda:0') mean:  tensor(-3.2320e-05, device='cuda:0') min:  tensor(-0.1096, device='cuda:0') norm:  tensor(0.3286, device='cuda:0') MSE:  tensor(1.2335e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  237  
Training Loss: 0.0103038614615798
Test Loss:  0.0016496506286785007
Test Acc:  0.0
Valid Loss:  0.0016904252115637064
Valid Acc:  0.0
std:  3.556335462052435e-08 
thres:  1.0303911939263344e-05
Preserved_eigens number check:  30
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 24%|██▎       | 237/1000 [15:07<47:12,  3.71s/it]Epoch:   238
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-3.2109e-05, device='cuda:0') min:  tensor(-0.1009, device='cuda:0') norm:  tensor(0.3145, device='cuda:0') MSE:  tensor(1.1806e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  238  
Training Loss: 0.01030384935438633
Test Loss:  0.001649630954489112
Test Acc:  0.0
Valid Loss:  0.001690407283604145
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(607.9103, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 24%|██▍       | 238/1000 [15:11<47:42,  3.76s/it]Epoch:   239
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0359, device='cuda:0') mean:  tensor(-3.5680e-05, device='cuda:0') min:  tensor(-0.1065, device='cuda:0') norm:  tensor(0.3335, device='cuda:0') MSE:  tensor(1.2518e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  239  
Training Loss: 0.010303836315870285
Test Loss:  0.001649612095206976
Test Acc:  0.0
Valid Loss:  0.0016903893556445837
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.8965, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 24%|██▍       | 239/1000 [15:15<48:28,  3.82s/it]Epoch:   240
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0387, device='cuda:0') mean:  tensor(-3.2542e-05, device='cuda:0') min:  tensor(-0.1068, device='cuda:0') norm:  tensor(0.3244, device='cuda:0') MSE:  tensor(1.2178e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  240  
Training Loss: 0.010303824208676815
Test Loss:  0.0016495931195095181
Test Acc:  0.0
Valid Loss:  0.0016903708456084132
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.8939, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 24%|██▍       | 240/1000 [15:19<48:53,  3.86s/it]Epoch:   241
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0352, device='cuda:0') mean:  tensor(-3.6150e-05, device='cuda:0') min:  tensor(-0.1074, device='cuda:0') norm:  tensor(0.3380, device='cuda:0') MSE:  tensor(1.2689e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  241  
Training Loss: 0.010303810238838196
Test Loss:  0.0016495733289048076
Test Acc:  0.0
Valid Loss:  0.0016903525684028864
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2875, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 24%|██▍       | 241/1000 [15:23<49:10,  3.89s/it]Epoch:   242
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0366, device='cuda:0') mean:  tensor(-3.4261e-05, device='cuda:0') min:  tensor(-0.1170, device='cuda:0') norm:  tensor(0.3420, device='cuda:0') MSE:  tensor(1.2839e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  242  
Training Loss: 0.0103037990629673
Test Loss:  0.001649554818868637
Test Acc:  0.0
Valid Loss:  0.0016903345240280032
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 24%|██▍       | 242/1000 [15:27<49:33,  3.92s/it]Epoch:   243
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0397, device='cuda:0') mean:  tensor(-3.1014e-05, device='cuda:0') min:  tensor(-0.1091, device='cuda:0') norm:  tensor(0.3216, device='cuda:0') MSE:  tensor(1.2072e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  243  
Training Loss: 0.010303786024451256
Test Loss:  0.0016495352610945702
Test Acc:  0.0
Valid Loss:  0.00169031647965312
Valid Acc:  0.0
std:  1.778801737176377e-08 
thres:  1.030381117016077e-05
Preserved_eigens number check:  5
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 24%|██▍       | 243/1000 [15:31<49:26,  3.92s/it]Epoch:   244
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-3.4781e-05, device='cuda:0') min:  tensor(-0.1116, device='cuda:0') norm:  tensor(0.3381, device='cuda:0') MSE:  tensor(1.2691e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  244  
Training Loss: 0.010303780436515808
Test Loss:  0.0016495261806994677
Test Acc:  0.0
Valid Loss:  0.001690307748503983
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9097, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 24%|██▍       | 244/1000 [15:35<49:49,  3.95s/it]Epoch:   245
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0365, device='cuda:0') mean:  tensor(-3.5858e-05, device='cuda:0') min:  tensor(-0.1159, device='cuda:0') norm:  tensor(0.3435, device='cuda:0') MSE:  tensor(1.2896e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  245  
Training Loss: 0.010303772985935211
Test Loss:  0.001649516518227756
Test Acc:  0.0
Valid Loss:  0.001690298318862915
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 24%|██▍       | 245/1000 [15:39<49:45,  3.95s/it]Epoch:   246
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0391, device='cuda:0') mean:  tensor(-3.5420e-05, device='cuda:0') min:  tensor(-0.1127, device='cuda:0') norm:  tensor(0.3399, device='cuda:0') MSE:  tensor(1.2759e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  246  
Training Loss: 0.010303767397999763
Test Loss:  0.001649507787078619
Test Acc:  0.0
Valid Loss:  0.001690289587713778
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 25%|██▍       | 246/1000 [15:42<48:27,  3.86s/it]Epoch:   247
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0368, device='cuda:0') mean:  tensor(-3.2996e-05, device='cuda:0') min:  tensor(-0.1069, device='cuda:0') norm:  tensor(0.3254, device='cuda:0') MSE:  tensor(1.2215e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  247  
Training Loss: 0.010303761810064316
Test Loss:  0.0016494982410222292
Test Acc:  0.0
Valid Loss:  0.0016902803909033537
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 25%|██▍       | 247/1000 [15:46<48:15,  3.85s/it]Epoch:   248
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0361, device='cuda:0') mean:  tensor(-3.2552e-05, device='cuda:0') min:  tensor(-0.1087, device='cuda:0') norm:  tensor(0.3177, device='cuda:0') MSE:  tensor(1.1925e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  248  
Training Loss: 0.010303755290806293
Test Loss:  0.0016494886949658394
Test Acc:  0.0
Valid Loss:  0.001690271426923573
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  11
max of Lambda2 tensor(607.9077, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 25%|██▍       | 248/1000 [15:50<48:36,  3.88s/it]Epoch:   249
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0402, device='cuda:0') mean:  tensor(-3.4363e-05, device='cuda:0') min:  tensor(-0.1129, device='cuda:0') norm:  tensor(0.3451, device='cuda:0') MSE:  tensor(1.2954e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  249  
Training Loss: 0.010303748771548271
Test Loss:  0.0016494796145707369
Test Acc:  0.0
Valid Loss:  0.0016902623465284705
Valid Acc:  0.0
std:  8.568167686462403e-09 
thres:  1.0303761251270772e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 25%|██▍       | 249/1000 [15:54<48:40,  3.89s/it]Epoch:   250
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0423, device='cuda:0') mean:  tensor(-3.4687e-05, device='cuda:0') min:  tensor(-0.1224, device='cuda:0') norm:  tensor(0.3512, device='cuda:0') MSE:  tensor(1.3182e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  250  
Training Loss: 0.010303746908903122
Test Loss:  0.0016494744922965765
Test Acc:  0.0
Valid Loss:  0.0016902572242543101
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 25%|██▌       | 250/1000 [15:58<47:56,  3.84s/it]Epoch:   251
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0305, device='cuda:0') mean:  tensor(-3.4516e-05, device='cuda:0') min:  tensor(-0.0997, device='cuda:0') norm:  tensor(0.3213, device='cuda:0') MSE:  tensor(1.2059e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  251  
Training Loss: 0.010303744114935398
Test Loss:  0.0016494698356837034
Test Acc:  0.0
Valid Loss:  0.0016902523348107934
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 25%|██▌       | 251/1000 [16:02<48:33,  3.89s/it]Epoch:   252
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0423, device='cuda:0') mean:  tensor(-3.2482e-05, device='cuda:0') min:  tensor(-0.1153, device='cuda:0') norm:  tensor(0.3349, device='cuda:0') MSE:  tensor(1.2573e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  252  
Training Loss: 0.010303739458322525
Test Loss:  0.0016494651790708303
Test Acc:  0.0
Valid Loss:  0.0016902480274438858
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 25%|██▌       | 252/1000 [16:05<48:05,  3.86s/it]Epoch:   253
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0326, device='cuda:0') mean:  tensor(-3.5493e-05, device='cuda:0') min:  tensor(-0.1166, device='cuda:0') norm:  tensor(0.3366, device='cuda:0') MSE:  tensor(1.2635e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  253  
Training Loss: 0.010303735733032227
Test Loss:  0.0016494595911353827
Test Acc:  0.0
Valid Loss:  0.0016902427887544036
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  13
max of Lambda2 tensor(607.9001, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 25%|██▌       | 253/1000 [16:09<47:35,  3.82s/it]Epoch:   254
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0394, device='cuda:0') mean:  tensor(-3.3960e-05, device='cuda:0') min:  tensor(-0.1165, device='cuda:0') norm:  tensor(0.3402, device='cuda:0') MSE:  tensor(1.2770e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  254  
Training Loss: 0.010303733870387077
Test Loss:  0.001649454701691866
Test Acc:  0.0
Valid Loss:  0.0016902382485568523
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 25%|██▌       | 254/1000 [16:13<47:44,  3.84s/it]Epoch:   255
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0410, device='cuda:0') mean:  tensor(-3.3724e-05, device='cuda:0') min:  tensor(-0.1114, device='cuda:0') norm:  tensor(0.3396, device='cuda:0') MSE:  tensor(1.2749e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  255  
Training Loss: 0.010303731076419353
Test Loss:  0.0016494501614943147
Test Acc:  0.0
Valid Loss:  0.0016902333591133356
Valid Acc:  0.0
std:  4.539660217968352e-09 
thres:  1.0303736850619316e-05
Preserved_eigens number check:  13
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2890, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 26%|██▌       | 255/1000 [16:17<46:58,  3.78s/it]Epoch:   256
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0401, device='cuda:0') mean:  tensor(-3.2425e-05, device='cuda:0') min:  tensor(-0.1362, device='cuda:0') norm:  tensor(0.3638, device='cuda:0') MSE:  tensor(1.3657e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  256  
Training Loss: 0.010303730145096779
Test Loss:  0.0016494479496032
Test Acc:  0.0
Valid Loss:  0.00169023172929883
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
 26%|██▌       | 256/1000 [16:20<46:41,  3.77s/it]Epoch:   257
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0397, device='cuda:0') mean:  tensor(-3.5326e-05, device='cuda:0') min:  tensor(-0.1080, device='cuda:0') norm:  tensor(0.3382, device='cuda:0') MSE:  tensor(1.2696e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  257  
Training Loss: 0.01030372828245163
Test Loss:  0.001649445970542729
Test Acc:  0.0
Valid Loss:  0.0016902300994843245
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  4
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 26%|██▌       | 257/1000 [16:24<46:30,  3.76s/it]Epoch:   258
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0395, device='cuda:0') mean:  tensor(-3.4632e-05, device='cuda:0') min:  tensor(-0.1038, device='cuda:0') norm:  tensor(0.3369, device='cuda:0') MSE:  tensor(1.2645e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  258  
Training Loss: 0.01030372641980648
Test Loss:  0.0016494437586516142
Test Acc:  0.0
Valid Loss:  0.001690227771177888
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.9111, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 26%|██▌       | 258/1000 [16:28<47:35,  3.85s/it]Epoch:   259
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0384, device='cuda:0') mean:  tensor(-3.1355e-05, device='cuda:0') min:  tensor(-0.1049, device='cuda:0') norm:  tensor(0.3193, device='cuda:0') MSE:  tensor(1.1987e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  259  
Training Loss: 0.010303725488483906
Test Loss:  0.0016494409646838903
Test Acc:  0.0
Valid Loss:  0.0016902257921174169
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 26%|██▌       | 259/1000 [16:32<48:00,  3.89s/it]Epoch:   260
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0412, device='cuda:0') mean:  tensor(-3.4607e-05, device='cuda:0') min:  tensor(-0.1060, device='cuda:0') norm:  tensor(0.3361, device='cuda:0') MSE:  tensor(1.2617e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  260  
Training Loss: 0.010303722694516182
Test Loss:  0.0016494389856234193
Test Acc:  0.0
Valid Loss:  0.0016902235802263021
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 26%|██▌       | 260/1000 [16:36<48:36,  3.94s/it]Epoch:   261
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-3.3731e-05, device='cuda:0') min:  tensor(-0.1026, device='cuda:0') norm:  tensor(0.3178, device='cuda:0') MSE:  tensor(1.1929e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  261  
Training Loss: 0.010303721763193607
Test Loss:  0.0016494367737323046
Test Acc:  0.0
Valid Loss:  0.0016902212519198656
Valid Acc:  0.0
std:  2.3998503995547306e-09 
thres:  1.0303724929690361e-05
Preserved_eigens number check:  12
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 26%|██▌       | 261/1000 [16:40<48:36,  3.95s/it]Epoch:   262
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0314, device='cuda:0') mean:  tensor(-3.1516e-05, device='cuda:0') min:  tensor(-0.0990, device='cuda:0') norm:  tensor(0.2955, device='cuda:0') MSE:  tensor(1.1094e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  262  
Training Loss: 0.010303721763193607
Test Loss:  0.0016494360752403736
Test Acc:  0.0
Valid Loss:  0.0016902207862585783
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2885, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 26%|██▌       | 262/1000 [16:44<47:53,  3.89s/it]Epoch:   263
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0349, device='cuda:0') mean:  tensor(-3.6474e-05, device='cuda:0') min:  tensor(-0.1311, device='cuda:0') norm:  tensor(0.3630, device='cuda:0') MSE:  tensor(1.3627e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  263  
Training Loss: 0.010303720831871033
Test Loss:  0.0016494357259944081
Test Acc:  0.0
Valid Loss:  0.001690220320597291
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 26%|██▋       | 263/1000 [16:48<48:09,  3.92s/it]Epoch:   264
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0342, device='cuda:0') mean:  tensor(-3.3952e-05, device='cuda:0') min:  tensor(-0.1210, device='cuda:0') norm:  tensor(0.3329, device='cuda:0') MSE:  tensor(1.2496e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  264  
Training Loss: 0.010303719900548458
Test Loss:  0.001649435143917799
Test Acc:  0.0
Valid Loss:  0.0016902200877666473
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 26%|██▋       | 264/1000 [16:52<47:54,  3.91s/it]Epoch:   265
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0354, device='cuda:0') mean:  tensor(-3.1950e-05, device='cuda:0') min:  tensor(-0.1114, device='cuda:0') norm:  tensor(0.3193, device='cuda:0') MSE:  tensor(1.1984e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  265  
Training Loss: 0.010303719900548458
Test Loss:  0.0016494349110871553
Test Acc:  0.0
Valid Loss:  0.00169021962210536
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 26%|██▋       | 265/1000 [16:56<47:39,  3.89s/it]Epoch:   266
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0443, device='cuda:0') mean:  tensor(-3.5964e-05, device='cuda:0') min:  tensor(-0.1257, device='cuda:0') norm:  tensor(0.3601, device='cuda:0') MSE:  tensor(1.3518e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  266  
Training Loss: 0.010303718969225883
Test Loss:  0.001649434445425868
Test Acc:  0.0
Valid Loss:  0.0016902192728593946
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  3
 27%|██▋       | 266/1000 [17:00<47:43,  3.90s/it]Epoch:   267
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0332, device='cuda:0') mean:  tensor(-3.2663e-05, device='cuda:0') min:  tensor(-0.1041, device='cuda:0') norm:  tensor(0.3117, device='cuda:0') MSE:  tensor(1.1700e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  267  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494336305186152
Test Acc:  0.0
Valid Loss:  0.00169021834153682
Valid Acc:  0.0
std:  6.969379981558661e-10 
thres:  1.0303719714283944e-05
Preserved_eigens number check:  3
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2887, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 27%|██▋       | 267/1000 [17:03<47:47,  3.91s/it]Epoch:   268
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0318, device='cuda:0') mean:  tensor(-3.3506e-05, device='cuda:0') min:  tensor(-0.1007, device='cuda:0') norm:  tensor(0.3206, device='cuda:0') MSE:  tensor(1.2035e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  268  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494335141032934
Test Acc:  0.0
Valid Loss:  0.0016902179922908545
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  5
max of Lambda2 tensor(232.2884, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
 27%|██▋       | 268/1000 [17:07<47:19,  3.88s/it]Epoch:   269
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0337, device='cuda:0') mean:  tensor(-3.2812e-05, device='cuda:0') min:  tensor(-0.1089, device='cuda:0') norm:  tensor(0.3181, device='cuda:0') MSE:  tensor(1.1942e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  269  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494330484420061
Test Acc:  0.0
Valid Loss:  0.0016902179922908545
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  4
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 27%|██▋       | 269/1000 [17:11<46:19,  3.80s/it]Epoch:   270
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0319, device='cuda:0') mean:  tensor(-3.4254e-05, device='cuda:0') min:  tensor(-0.1185, device='cuda:0') norm:  tensor(0.3288, device='cuda:0') MSE:  tensor(1.2344e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  270  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494328156113625
Test Acc:  0.0
Valid Loss:  0.0016902177594602108
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 27%|██▋       | 270/1000 [17:15<47:01,  3.87s/it]Epoch:   271
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0353, device='cuda:0') mean:  tensor(-3.7504e-05, device='cuda:0') min:  tensor(-0.1231, device='cuda:0') norm:  tensor(0.3635, device='cuda:0') MSE:  tensor(1.3647e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  271  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494326991960406
Test Acc:  0.0
Valid Loss:  0.001690217643044889
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 27%|██▋       | 271/1000 [17:19<47:11,  3.88s/it]Epoch:   272
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0425, device='cuda:0') mean:  tensor(-3.4934e-05, device='cuda:0') min:  tensor(-0.1295, device='cuda:0') norm:  tensor(0.3499, device='cuda:0') MSE:  tensor(1.3134e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  272  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494325827807188
Test Acc:  0.0
Valid Loss:  0.0016902177594602108
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 27%|██▋       | 272/1000 [17:23<46:48,  3.86s/it]Epoch:   273
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0390, device='cuda:0') mean:  tensor(-3.3223e-05, device='cuda:0') min:  tensor(-0.1102, device='cuda:0') norm:  tensor(0.3276, device='cuda:0') MSE:  tensor(1.2296e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  273  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494325827807188
Test Acc:  0.0
Valid Loss:  0.0016902175266295671
Valid Acc:  0.0
std:  0.0 
thres:  1.0303718969225883e-05
Preserved_eigens number check:  6
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.8968, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 27%|██▋       | 273/1000 [17:26<45:41,  3.77s/it]Epoch:   274
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-3.4900e-05, device='cuda:0') min:  tensor(-0.1038, device='cuda:0') norm:  tensor(0.3304, device='cuda:0') MSE:  tensor(1.2404e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  274  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494323499500751
Test Acc:  0.0
Valid Loss:  0.0016902174102142453
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 27%|██▋       | 274/1000 [17:30<45:32,  3.76s/it]Epoch:   275
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0428, device='cuda:0') mean:  tensor(-3.4345e-05, device='cuda:0') min:  tensor(-0.1103, device='cuda:0') norm:  tensor(0.3430, device='cuda:0') MSE:  tensor(1.2875e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  275  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494323499500751
Test Acc:  0.0
Valid Loss:  0.0016902172937989235
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  11
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 28%|██▊       | 275/1000 [17:34<45:54,  3.80s/it]Epoch:   276
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0346, device='cuda:0') mean:  tensor(-3.3587e-05, device='cuda:0') min:  tensor(-0.1119, device='cuda:0') norm:  tensor(0.3239, device='cuda:0') MSE:  tensor(1.2159e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  276  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902172937989235
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 28%|██▊       | 276/1000 [17:38<46:22,  3.84s/it]Epoch:   277
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-3.4575e-05, device='cuda:0') min:  tensor(-0.1181, device='cuda:0') norm:  tensor(0.3469, device='cuda:0') MSE:  tensor(1.3021e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  277  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902174102142453
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 28%|██▊       | 277/1000 [17:42<46:30,  3.86s/it]Epoch:   278
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0397, device='cuda:0') mean:  tensor(-3.3493e-05, device='cuda:0') min:  tensor(-0.1188, device='cuda:0') norm:  tensor(0.3425, device='cuda:0') MSE:  tensor(1.2857e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  278  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902171773836017
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  13
max of Lambda2 tensor(607.9139, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 28%|██▊       | 278/1000 [17:46<47:13,  3.92s/it]Epoch:   279
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0341, device='cuda:0') mean:  tensor(-3.1625e-05, device='cuda:0') min:  tensor(-0.0977, device='cuda:0') norm:  tensor(0.3078, device='cuda:0') MSE:  tensor(1.1553e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  279  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.030371878296137e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2891, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 28%|██▊       | 279/1000 [17:50<47:19,  3.94s/it]Epoch:   280
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0431, device='cuda:0') mean:  tensor(-3.7012e-05, device='cuda:0') min:  tensor(-0.1327, device='cuda:0') norm:  tensor(0.3794, device='cuda:0') MSE:  tensor(1.4240e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  280  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494323499500751
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  6
max of Lambda2 tensor(232.2889, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 28%|██▊       | 280/1000 [17:53<46:26,  3.87s/it]Epoch:   281
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0387, device='cuda:0') mean:  tensor(-3.1352e-05, device='cuda:0') min:  tensor(-0.1034, device='cuda:0') norm:  tensor(0.3089, device='cuda:0') MSE:  tensor(1.1595e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  281  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  7
max of Lambda2 tensor(232.2896, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 28%|██▊       | 281/1000 [17:57<46:10,  3.85s/it]Epoch:   282
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-3.1939e-05, device='cuda:0') min:  tensor(-0.1211, device='cuda:0') norm:  tensor(0.3334, device='cuda:0') MSE:  tensor(1.2516e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  282  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 28%|██▊       | 282/1000 [18:01<46:47,  3.91s/it]Epoch:   283
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0324, device='cuda:0') mean:  tensor(-3.1787e-05, device='cuda:0') min:  tensor(-0.1065, device='cuda:0') norm:  tensor(0.3106, device='cuda:0') MSE:  tensor(1.1659e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  283  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 28%|██▊       | 283/1000 [18:05<47:03,  3.94s/it]Epoch:   284
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0354, device='cuda:0') mean:  tensor(-3.2727e-05, device='cuda:0') min:  tensor(-0.1197, device='cuda:0') norm:  tensor(0.3357, device='cuda:0') MSE:  tensor(1.2602e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  284  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 28%|██▊       | 284/1000 [18:09<46:53,  3.93s/it]Epoch:   285
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0401, device='cuda:0') mean:  tensor(-3.3098e-05, device='cuda:0') min:  tensor(-0.1077, device='cuda:0') norm:  tensor(0.3276, device='cuda:0') MSE:  tensor(1.2299e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  285  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 28%|██▊       | 285/1000 [18:13<47:11,  3.96s/it]Epoch:   286
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0389, device='cuda:0') mean:  tensor(-3.3794e-05, device='cuda:0') min:  tensor(-0.1096, device='cuda:0') norm:  tensor(0.3308, device='cuda:0') MSE:  tensor(1.2419e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  286  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2880, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 29%|██▊       | 286/1000 [18:17<47:11,  3.97s/it]Epoch:   287
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0384, device='cuda:0') mean:  tensor(-3.6580e-05, device='cuda:0') min:  tensor(-0.1099, device='cuda:0') norm:  tensor(0.3515, device='cuda:0') MSE:  tensor(1.3193e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  287  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  5
max of Lambda2 tensor(607.9128, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 29%|██▊       | 287/1000 [18:21<46:24,  3.91s/it]Epoch:   288
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0393, device='cuda:0') mean:  tensor(-3.5258e-05, device='cuda:0') min:  tensor(-0.1113, device='cuda:0') norm:  tensor(0.3422, device='cuda:0') MSE:  tensor(1.2844e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  288  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 29%|██▉       | 288/1000 [18:25<46:37,  3.93s/it]Epoch:   289
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0370, device='cuda:0') mean:  tensor(-3.1947e-05, device='cuda:0') min:  tensor(-0.1157, device='cuda:0') norm:  tensor(0.3309, device='cuda:0') MSE:  tensor(1.2421e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  289  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 29%|██▉       | 289/1000 [18:29<46:19,  3.91s/it]Epoch:   290
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0393, device='cuda:0') mean:  tensor(-3.2215e-05, device='cuda:0') min:  tensor(-0.1026, device='cuda:0') norm:  tensor(0.3222, device='cuda:0') MSE:  tensor(1.2093e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  290  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 29%|██▉       | 290/1000 [18:33<46:20,  3.92s/it]Epoch:   291
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0398, device='cuda:0') mean:  tensor(-3.0830e-05, device='cuda:0') min:  tensor(-0.1003, device='cuda:0') norm:  tensor(0.3069, device='cuda:0') MSE:  tensor(1.1520e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  291  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  6
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 29%|██▉       | 291/1000 [18:37<46:10,  3.91s/it]Epoch:   292
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0364, device='cuda:0') mean:  tensor(-3.2317e-05, device='cuda:0') min:  tensor(-0.1136, device='cuda:0') norm:  tensor(0.3238, device='cuda:0') MSE:  tensor(1.2155e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  292  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 29%|██▉       | 292/1000 [18:41<46:13,  3.92s/it]Epoch:   293
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0406, device='cuda:0') mean:  tensor(-3.4303e-05, device='cuda:0') min:  tensor(-0.1063, device='cuda:0') norm:  tensor(0.3355, device='cuda:0') MSE:  tensor(1.2594e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  293  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.9098, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 29%|██▉       | 293/1000 [18:44<45:09,  3.83s/it]Epoch:   294
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-3.2223e-05, device='cuda:0') min:  tensor(-0.1166, device='cuda:0') norm:  tensor(0.3273, device='cuda:0') MSE:  tensor(1.2285e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  294  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  13
max of Lambda2 tensor(232.2895, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 29%|██▉       | 294/1000 [18:48<45:21,  3.85s/it]Epoch:   295
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0379, device='cuda:0') mean:  tensor(-3.3741e-05, device='cuda:0') min:  tensor(-0.1229, device='cuda:0') norm:  tensor(0.3450, device='cuda:0') MSE:  tensor(1.2952e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  295  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  6
max of Lambda2 tensor(607.9153, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 30%|██▉       | 295/1000 [18:52<45:33,  3.88s/it]Epoch:   296
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0412, device='cuda:0') mean:  tensor(-3.4371e-05, device='cuda:0') min:  tensor(-0.1092, device='cuda:0') norm:  tensor(0.3431, device='cuda:0') MSE:  tensor(1.2880e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  296  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 30%|██▉       | 296/1000 [18:56<45:01,  3.84s/it]Epoch:   297
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0392, device='cuda:0') mean:  tensor(-3.3110e-05, device='cuda:0') min:  tensor(-0.1134, device='cuda:0') norm:  tensor(0.3354, device='cuda:0') MSE:  tensor(1.2591e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  297  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  0.0 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  11
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 30%|██▉       | 297/1000 [19:00<45:36,  3.89s/it]Epoch:   298
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0356, device='cuda:0') mean:  tensor(-3.3874e-05, device='cuda:0') min:  tensor(-0.1088, device='cuda:0') norm:  tensor(0.3240, device='cuda:0') MSE:  tensor(1.2162e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  298  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  10
max of Lambda2 tensor(232.2874, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 30%|██▉       | 298/1000 [19:04<45:38,  3.90s/it]Epoch:   299
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0375, device='cuda:0') mean:  tensor(-3.3993e-05, device='cuda:0') min:  tensor(-0.1050, device='cuda:0') norm:  tensor(0.3352, device='cuda:0') MSE:  tensor(1.2583e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  299  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 30%|██▉       | 299/1000 [19:08<46:04,  3.94s/it]Epoch:   300
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0349, device='cuda:0') mean:  tensor(-3.4116e-05, device='cuda:0') min:  tensor(-0.1193, device='cuda:0') norm:  tensor(0.3377, device='cuda:0') MSE:  tensor(1.2677e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  300  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  11
max of Lambda2 tensor(232.2900, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 30%|███       | 300/1000 [19:12<45:51,  3.93s/it]Epoch:   301
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0357, device='cuda:0') mean:  tensor(-3.5595e-05, device='cuda:0') min:  tensor(-0.1067, device='cuda:0') norm:  tensor(0.3350, device='cuda:0') MSE:  tensor(1.2574e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  301  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  13
max of Lambda2 tensor(232.2883, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 30%|███       | 301/1000 [19:16<45:35,  3.91s/it]Epoch:   302
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0403, device='cuda:0') mean:  tensor(-3.4221e-05, device='cuda:0') min:  tensor(-0.1116, device='cuda:0') norm:  tensor(0.3410, device='cuda:0') MSE:  tensor(1.2799e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  302  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9131, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 30%|███       | 302/1000 [19:19<44:58,  3.87s/it]Epoch:   303
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0386, device='cuda:0') mean:  tensor(-3.4398e-05, device='cuda:0') min:  tensor(-0.1130, device='cuda:0') norm:  tensor(0.3372, device='cuda:0') MSE:  tensor(1.2659e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  303  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  6.96937998155866e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 30%|███       | 303/1000 [19:23<45:08,  3.89s/it]Epoch:   304
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0351, device='cuda:0') mean:  tensor(-3.3639e-05, device='cuda:0') min:  tensor(-0.1068, device='cuda:0') norm:  tensor(0.3266, device='cuda:0') MSE:  tensor(1.2260e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  304  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.9006, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 30%|███       | 304/1000 [19:27<44:27,  3.83s/it]Epoch:   305
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0423, device='cuda:0') mean:  tensor(-3.2292e-05, device='cuda:0') min:  tensor(-0.1133, device='cuda:0') norm:  tensor(0.3359, device='cuda:0') MSE:  tensor(1.2607e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  305  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2885, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 30%|███       | 305/1000 [19:31<44:23,  3.83s/it]Epoch:   306
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0360, device='cuda:0') mean:  tensor(-3.2257e-05, device='cuda:0') min:  tensor(-0.1136, device='cuda:0') norm:  tensor(0.3268, device='cuda:0') MSE:  tensor(1.2268e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  306  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9150, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 31%|███       | 306/1000 [19:35<44:19,  3.83s/it]Epoch:   307
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0379, device='cuda:0') mean:  tensor(-3.3399e-05, device='cuda:0') min:  tensor(-0.1006, device='cuda:0') norm:  tensor(0.3223, device='cuda:0') MSE:  tensor(1.2098e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  307  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  15
max of Lambda2 tensor(232.2876, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 31%|███       | 307/1000 [19:38<43:57,  3.81s/it]Epoch:   308
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0413, device='cuda:0') mean:  tensor(-3.1570e-05, device='cuda:0') min:  tensor(-0.1108, device='cuda:0') norm:  tensor(0.3273, device='cuda:0') MSE:  tensor(1.2287e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  308  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(232.2886, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 31%|███       | 308/1000 [19:42<44:03,  3.82s/it]Epoch:   309
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0388, device='cuda:0') mean:  tensor(-3.4950e-05, device='cuda:0') min:  tensor(-0.1201, device='cuda:0') norm:  tensor(0.3529, device='cuda:0') MSE:  tensor(1.3247e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  309  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  7.450580596923828e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  5
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 31%|███       | 309/1000 [19:46<44:20,  3.85s/it]Epoch:   310
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-2.9997e-05, device='cuda:0') min:  tensor(-0.1035, device='cuda:0') norm:  tensor(0.3024, device='cuda:0') MSE:  tensor(1.1351e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  310  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9037, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 31%|███       | 310/1000 [19:50<43:12,  3.76s/it]Epoch:   311
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0384, device='cuda:0') mean:  tensor(-3.2939e-05, device='cuda:0') min:  tensor(-0.1043, device='cuda:0') norm:  tensor(0.3246, device='cuda:0') MSE:  tensor(1.2183e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  311  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 31%|███       | 311/1000 [19:53<43:14,  3.77s/it]Epoch:   312
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0362, device='cuda:0') mean:  tensor(-3.3925e-05, device='cuda:0') min:  tensor(-0.1174, device='cuda:0') norm:  tensor(0.3400, device='cuda:0') MSE:  tensor(1.2763e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  312  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 31%|███       | 312/1000 [19:57<44:03,  3.84s/it]Epoch:   313
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0380, device='cuda:0') mean:  tensor(-3.1549e-05, device='cuda:0') min:  tensor(-0.1168, device='cuda:0') norm:  tensor(0.3291, device='cuda:0') MSE:  tensor(1.2353e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  313  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  11
max of Lambda2 tensor(607.8912, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 31%|███▏      | 313/1000 [20:01<44:24,  3.88s/it]Epoch:   314
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0382, device='cuda:0') mean:  tensor(-3.5183e-05, device='cuda:0') min:  tensor(-0.1225, device='cuda:0') norm:  tensor(0.3456, device='cuda:0') MSE:  tensor(1.2972e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  314  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 31%|███▏      | 314/1000 [20:05<44:49,  3.92s/it]Epoch:   315
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0349, device='cuda:0') mean:  tensor(-3.4973e-05, device='cuda:0') min:  tensor(-0.1031, device='cuda:0') norm:  tensor(0.3292, device='cuda:0') MSE:  tensor(1.2358e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  315  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 32%|███▏      | 315/1000 [20:09<43:10,  3.78s/it]Epoch:   316
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0392, device='cuda:0') mean:  tensor(-3.0353e-05, device='cuda:0') min:  tensor(-0.1240, device='cuda:0') norm:  tensor(0.3330, device='cuda:0') MSE:  tensor(1.2500e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  316  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 32%|███▏      | 316/1000 [20:13<43:13,  3.79s/it]Epoch:   317
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0367, device='cuda:0') mean:  tensor(-2.9435e-05, device='cuda:0') min:  tensor(-0.1057, device='cuda:0') norm:  tensor(0.3125, device='cuda:0') MSE:  tensor(1.1732e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  317  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  11
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 32%|███▏      | 317/1000 [20:17<44:07,  3.88s/it]Epoch:   318
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0372, device='cuda:0') mean:  tensor(-3.4197e-05, device='cuda:0') min:  tensor(-0.1178, device='cuda:0') norm:  tensor(0.3339, device='cuda:0') MSE:  tensor(1.2532e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  318  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.9089, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 32%|███▏      | 318/1000 [20:20<42:57,  3.78s/it]Epoch:   319
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0409, device='cuda:0') mean:  tensor(-3.4936e-05, device='cuda:0') min:  tensor(-0.1127, device='cuda:0') norm:  tensor(0.3445, device='cuda:0') MSE:  tensor(1.2932e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  319  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 32%|███▏      | 319/1000 [20:24<43:11,  3.81s/it]Epoch:   320
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0391, device='cuda:0') mean:  tensor(-3.2755e-05, device='cuda:0') min:  tensor(-0.1036, device='cuda:0') norm:  tensor(0.3238, device='cuda:0') MSE:  tensor(1.2156e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  320  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  14
max of Lambda2 tensor(607.9130, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 32%|███▏      | 320/1000 [20:28<43:13,  3.81s/it]Epoch:   321
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-3.2045e-05, device='cuda:0') min:  tensor(-0.1141, device='cuda:0') norm:  tensor(0.3193, device='cuda:0') MSE:  tensor(1.1988e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  321  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  5.890201144234053e-10 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 32%|███▏      | 321/1000 [20:32<43:50,  3.87s/it]Epoch:   322
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0353, device='cuda:0') mean:  tensor(-3.3872e-05, device='cuda:0') min:  tensor(-0.1042, device='cuda:0') norm:  tensor(0.3266, device='cuda:0') MSE:  tensor(1.2261e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  322  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 32%|███▏      | 322/1000 [20:36<44:12,  3.91s/it]Epoch:   323
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0412, device='cuda:0') mean:  tensor(-3.6081e-05, device='cuda:0') min:  tensor(-0.1381, device='cuda:0') norm:  tensor(0.3804, device='cuda:0') MSE:  tensor(1.4279e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  323  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 32%|███▏      | 323/1000 [20:40<43:24,  3.85s/it]Epoch:   324
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0379, device='cuda:0') mean:  tensor(-3.1353e-05, device='cuda:0') min:  tensor(-0.1090, device='cuda:0') norm:  tensor(0.3128, device='cuda:0') MSE:  tensor(1.1742e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  324  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(232.2881, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 32%|███▏      | 324/1000 [20:44<43:54,  3.90s/it]Epoch:   325
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0408, device='cuda:0') mean:  tensor(-3.4991e-05, device='cuda:0') min:  tensor(-0.1219, device='cuda:0') norm:  tensor(0.3527, device='cuda:0') MSE:  tensor(1.3238e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  325  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 32%|███▎      | 325/1000 [20:48<43:44,  3.89s/it]Epoch:   326
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0337, device='cuda:0') mean:  tensor(-3.3039e-05, device='cuda:0') min:  tensor(-0.1151, device='cuda:0') norm:  tensor(0.3231, device='cuda:0') MSE:  tensor(1.2129e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  326  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9067, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 33%|███▎      | 326/1000 [20:52<43:51,  3.90s/it]Epoch:   327
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0374, device='cuda:0') mean:  tensor(-3.3020e-05, device='cuda:0') min:  tensor(-0.1101, device='cuda:0') norm:  tensor(0.3245, device='cuda:0') MSE:  tensor(1.2181e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  327  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9017, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 33%|███▎      | 327/1000 [20:56<44:25,  3.96s/it]Epoch:   328
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0329, device='cuda:0') mean:  tensor(-3.4822e-05, device='cuda:0') min:  tensor(-0.1193, device='cuda:0') norm:  tensor(0.3386, device='cuda:0') MSE:  tensor(1.2709e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  328  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 33%|███▎      | 328/1000 [21:00<44:45,  4.00s/it]Epoch:   329
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0367, device='cuda:0') mean:  tensor(-3.4033e-05, device='cuda:0') min:  tensor(-0.1095, device='cuda:0') norm:  tensor(0.3318, device='cuda:0') MSE:  tensor(1.2455e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  329  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 33%|███▎      | 329/1000 [21:03<43:43,  3.91s/it]Epoch:   330
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0372, device='cuda:0') mean:  tensor(-3.3001e-05, device='cuda:0') min:  tensor(-0.1164, device='cuda:0') norm:  tensor(0.3262, device='cuda:0') MSE:  tensor(1.2245e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  330  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.9123, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 33%|███▎      | 330/1000 [21:07<43:23,  3.89s/it]Epoch:   331
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0374, device='cuda:0') mean:  tensor(-3.1592e-05, device='cuda:0') min:  tensor(-0.1210, device='cuda:0') norm:  tensor(0.3314, device='cuda:0') MSE:  tensor(1.2438e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  331  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 33%|███▎      | 331/1000 [21:11<43:48,  3.93s/it]Epoch:   332
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0396, device='cuda:0') mean:  tensor(-3.2965e-05, device='cuda:0') min:  tensor(-0.1144, device='cuda:0') norm:  tensor(0.3325, device='cuda:0') MSE:  tensor(1.2481e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  332  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 33%|███▎      | 332/1000 [21:15<44:22,  3.99s/it]Epoch:   333
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0313, device='cuda:0') mean:  tensor(-3.2405e-05, device='cuda:0') min:  tensor(-0.1045, device='cuda:0') norm:  tensor(0.3038, device='cuda:0') MSE:  tensor(1.1404e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  333  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  5
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 33%|███▎      | 333/1000 [21:19<44:06,  3.97s/it]Epoch:   334
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0361, device='cuda:0') mean:  tensor(-3.2551e-05, device='cuda:0') min:  tensor(-0.1059, device='cuda:0') norm:  tensor(0.3228, device='cuda:0') MSE:  tensor(1.2118e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  334  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 33%|███▎      | 334/1000 [21:23<43:55,  3.96s/it]Epoch:   335
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0366, device='cuda:0') mean:  tensor(-3.1168e-05, device='cuda:0') min:  tensor(-0.1139, device='cuda:0') norm:  tensor(0.3213, device='cuda:0') MSE:  tensor(1.2059e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  335  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(232.2881, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 34%|███▎      | 335/1000 [21:27<43:47,  3.95s/it]Epoch:   336
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-3.5457e-05, device='cuda:0') min:  tensor(-0.1069, device='cuda:0') norm:  tensor(0.3398, device='cuda:0') MSE:  tensor(1.2755e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  336  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  5
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 34%|███▎      | 336/1000 [21:31<43:55,  3.97s/it]Epoch:   337
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0312, device='cuda:0') mean:  tensor(-3.5358e-05, device='cuda:0') min:  tensor(-0.0992, device='cuda:0') norm:  tensor(0.3258, device='cuda:0') MSE:  tensor(1.2230e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  337  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 34%|███▎      | 337/1000 [21:35<43:52,  3.97s/it]Epoch:   338
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0378, device='cuda:0') mean:  tensor(-3.3871e-05, device='cuda:0') min:  tensor(-0.1097, device='cuda:0') norm:  tensor(0.3283, device='cuda:0') MSE:  tensor(1.2322e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  338  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  18
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 34%|███▍      | 338/1000 [21:39<43:21,  3.93s/it]Epoch:   339
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0342, device='cuda:0') mean:  tensor(-3.1848e-05, device='cuda:0') min:  tensor(-0.1025, device='cuda:0') norm:  tensor(0.3049, device='cuda:0') MSE:  tensor(1.1444e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  339  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  5.890201144234053e-10 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 34%|███▍      | 339/1000 [21:43<42:53,  3.89s/it]Epoch:   340
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0378, device='cuda:0') mean:  tensor(-3.2188e-05, device='cuda:0') min:  tensor(-0.1017, device='cuda:0') norm:  tensor(0.3188, device='cuda:0') MSE:  tensor(1.1966e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  340  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  14
max of Lambda2 tensor(232.2875, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 34%|███▍      | 340/1000 [21:47<43:04,  3.92s/it]Epoch:   341
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0319, device='cuda:0') mean:  tensor(-3.2113e-05, device='cuda:0') min:  tensor(-0.1156, device='cuda:0') norm:  tensor(0.3152, device='cuda:0') MSE:  tensor(1.1831e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  341  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  5
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 34%|███▍      | 341/1000 [21:51<42:57,  3.91s/it]Epoch:   342
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0357, device='cuda:0') mean:  tensor(-3.1460e-05, device='cuda:0') min:  tensor(-0.1044, device='cuda:0') norm:  tensor(0.3142, device='cuda:0') MSE:  tensor(1.1795e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  342  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 34%|███▍      | 342/1000 [21:55<42:52,  3.91s/it]Epoch:   343
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0347, device='cuda:0') mean:  tensor(-3.1607e-05, device='cuda:0') min:  tensor(-0.1114, device='cuda:0') norm:  tensor(0.3089, device='cuda:0') MSE:  tensor(1.1595e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  343  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9108, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 34%|███▍      | 343/1000 [21:59<42:43,  3.90s/it]Epoch:   344
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0327, device='cuda:0') mean:  tensor(-3.0362e-05, device='cuda:0') min:  tensor(-0.0980, device='cuda:0') norm:  tensor(0.2988, device='cuda:0') MSE:  tensor(1.1215e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  344  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 34%|███▍      | 344/1000 [22:03<42:51,  3.92s/it]Epoch:   345
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-3.3449e-05, device='cuda:0') min:  tensor(-0.1010, device='cuda:0') norm:  tensor(0.3137, device='cuda:0') MSE:  tensor(1.1775e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  345  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 34%|███▍      | 345/1000 [22:06<43:01,  3.94s/it]Epoch:   346
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-2.7465e-05, device='cuda:0') min:  tensor(-0.0906, device='cuda:0') norm:  tensor(0.2832, device='cuda:0') MSE:  tensor(1.0632e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  346  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 35%|███▍      | 346/1000 [22:10<42:46,  3.92s/it]Epoch:   347
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0349, device='cuda:0') mean:  tensor(-3.1034e-05, device='cuda:0') min:  tensor(-0.1167, device='cuda:0') norm:  tensor(0.3223, device='cuda:0') MSE:  tensor(1.2098e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  347  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9113, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 35%|███▍      | 347/1000 [22:14<42:57,  3.95s/it]Epoch:   348
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0416, device='cuda:0') mean:  tensor(-3.4283e-05, device='cuda:0') min:  tensor(-0.1192, device='cuda:0') norm:  tensor(0.3453, device='cuda:0') MSE:  tensor(1.2961e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  348  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 35%|███▍      | 348/1000 [22:18<41:11,  3.79s/it]Epoch:   349
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0356, device='cuda:0') mean:  tensor(-3.2301e-05, device='cuda:0') min:  tensor(-0.1167, device='cuda:0') norm:  tensor(0.3237, device='cuda:0') MSE:  tensor(1.2152e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  349  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 35%|███▍      | 349/1000 [22:22<41:28,  3.82s/it]Epoch:   350
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0396, device='cuda:0') mean:  tensor(-3.4003e-05, device='cuda:0') min:  tensor(-0.1092, device='cuda:0') norm:  tensor(0.3374, device='cuda:0') MSE:  tensor(1.2664e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  350  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 35%|███▌      | 350/1000 [22:26<42:10,  3.89s/it]Epoch:   351
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0351, device='cuda:0') mean:  tensor(-3.4458e-05, device='cuda:0') min:  tensor(-0.1131, device='cuda:0') norm:  tensor(0.3390, device='cuda:0') MSE:  tensor(1.2724e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  351  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  7
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2894, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 35%|███▌      | 351/1000 [22:30<42:04,  3.89s/it]Epoch:   352
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0346, device='cuda:0') mean:  tensor(-3.6943e-05, device='cuda:0') min:  tensor(-0.1203, device='cuda:0') norm:  tensor(0.3554, device='cuda:0') MSE:  tensor(1.3339e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  352  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 35%|███▌      | 352/1000 [22:34<42:10,  3.91s/it]Epoch:   353
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0398, device='cuda:0') mean:  tensor(-3.1399e-05, device='cuda:0') min:  tensor(-0.1070, device='cuda:0') norm:  tensor(0.3236, device='cuda:0') MSE:  tensor(1.2148e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  353  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 35%|███▌      | 353/1000 [22:37<42:08,  3.91s/it]Epoch:   354
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0433, device='cuda:0') mean:  tensor(-3.6837e-05, device='cuda:0') min:  tensor(-0.1116, device='cuda:0') norm:  tensor(0.3571, device='cuda:0') MSE:  tensor(1.3406e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  354  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2885, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 35%|███▌      | 354/1000 [22:41<42:17,  3.93s/it]Epoch:   355
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0380, device='cuda:0') mean:  tensor(-3.6158e-05, device='cuda:0') min:  tensor(-0.1241, device='cuda:0') norm:  tensor(0.3550, device='cuda:0') MSE:  tensor(1.3325e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  355  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 36%|███▌      | 355/1000 [22:45<42:14,  3.93s/it]Epoch:   356
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0350, device='cuda:0') mean:  tensor(-3.2398e-05, device='cuda:0') min:  tensor(-0.1104, device='cuda:0') norm:  tensor(0.3180, device='cuda:0') MSE:  tensor(1.1938e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  356  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 36%|███▌      | 356/1000 [22:49<42:35,  3.97s/it]Epoch:   357
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0335, device='cuda:0') mean:  tensor(-3.5690e-05, device='cuda:0') min:  tensor(-0.1081, device='cuda:0') norm:  tensor(0.3399, device='cuda:0') MSE:  tensor(1.2760e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  357  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  6
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 36%|███▌      | 357/1000 [22:53<42:29,  3.96s/it]Epoch:   358
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0386, device='cuda:0') mean:  tensor(-3.3417e-05, device='cuda:0') min:  tensor(-0.1193, device='cuda:0') norm:  tensor(0.3357, device='cuda:0') MSE:  tensor(1.2601e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  358  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 36%|███▌      | 358/1000 [22:57<41:31,  3.88s/it]Epoch:   359
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0313, device='cuda:0') mean:  tensor(-3.1278e-05, device='cuda:0') min:  tensor(-0.0999, device='cuda:0') norm:  tensor(0.3044, device='cuda:0') MSE:  tensor(1.1426e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  359  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 36%|███▌      | 359/1000 [23:01<41:08,  3.85s/it]Epoch:   360
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0380, device='cuda:0') mean:  tensor(-3.4768e-05, device='cuda:0') min:  tensor(-0.1092, device='cuda:0') norm:  tensor(0.3393, device='cuda:0') MSE:  tensor(1.2737e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  360  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 36%|███▌      | 360/1000 [23:05<41:47,  3.92s/it]Epoch:   361
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0400, device='cuda:0') mean:  tensor(-3.4508e-05, device='cuda:0') min:  tensor(-0.1194, device='cuda:0') norm:  tensor(0.3479, device='cuda:0') MSE:  tensor(1.3061e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  361  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  5
max of Lambda2 tensor(232.2887, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 36%|███▌      | 361/1000 [23:09<41:43,  3.92s/it]Epoch:   362
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0416, device='cuda:0') mean:  tensor(-3.3106e-05, device='cuda:0') min:  tensor(-0.1014, device='cuda:0') norm:  tensor(0.3278, device='cuda:0') MSE:  tensor(1.2305e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  362  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 36%|███▌      | 362/1000 [23:13<41:48,  3.93s/it]Epoch:   363
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0326, device='cuda:0') mean:  tensor(-3.0637e-05, device='cuda:0') min:  tensor(-0.0928, device='cuda:0') norm:  tensor(0.2961, device='cuda:0') MSE:  tensor(1.1113e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  363  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  8.33000234328132e-10 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 36%|███▋      | 363/1000 [23:17<41:35,  3.92s/it]Epoch:   364
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0359, device='cuda:0') mean:  tensor(-3.5552e-05, device='cuda:0') min:  tensor(-0.1107, device='cuda:0') norm:  tensor(0.3466, device='cuda:0') MSE:  tensor(1.3010e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  364  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 36%|███▋      | 364/1000 [23:21<41:08,  3.88s/it]Epoch:   365
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0321, device='cuda:0') mean:  tensor(-3.2305e-05, device='cuda:0') min:  tensor(-0.1095, device='cuda:0') norm:  tensor(0.3182, device='cuda:0') MSE:  tensor(1.1945e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  365  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  5
max of Lambda2 tensor(232.2882, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 36%|███▋      | 365/1000 [23:25<42:00,  3.97s/it]Epoch:   366
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0413, device='cuda:0') mean:  tensor(-3.6514e-05, device='cuda:0') min:  tensor(-0.1210, device='cuda:0') norm:  tensor(0.3575, device='cuda:0') MSE:  tensor(1.3420e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  366  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 37%|███▋      | 366/1000 [23:29<42:04,  3.98s/it]Epoch:   367
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0351, device='cuda:0') mean:  tensor(-3.3743e-05, device='cuda:0') min:  tensor(-0.1038, device='cuda:0') norm:  tensor(0.3218, device='cuda:0') MSE:  tensor(1.2078e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  367  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2886, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
 37%|███▋      | 367/1000 [23:33<41:39,  3.95s/it]Epoch:   368
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0364, device='cuda:0') mean:  tensor(-3.0534e-05, device='cuda:0') min:  tensor(-0.1201, device='cuda:0') norm:  tensor(0.3218, device='cuda:0') MSE:  tensor(1.2079e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  368  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  4
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 37%|███▋      | 368/1000 [23:37<41:37,  3.95s/it]Epoch:   369
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0339, device='cuda:0') mean:  tensor(-3.2256e-05, device='cuda:0') min:  tensor(-0.0995, device='cuda:0') norm:  tensor(0.3068, device='cuda:0') MSE:  tensor(1.1516e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  369  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 37%|███▋      | 369/1000 [23:40<41:10,  3.92s/it]Epoch:   370
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0386, device='cuda:0') mean:  tensor(-3.5150e-05, device='cuda:0') min:  tensor(-0.1130, device='cuda:0') norm:  tensor(0.3429, device='cuda:0') MSE:  tensor(1.2873e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  370  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 37%|███▋      | 370/1000 [23:44<41:11,  3.92s/it]Epoch:   371
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0400, device='cuda:0') mean:  tensor(-3.3448e-05, device='cuda:0') min:  tensor(-0.1174, device='cuda:0') norm:  tensor(0.3374, device='cuda:0') MSE:  tensor(1.2664e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  371  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 37%|███▋      | 371/1000 [23:48<41:08,  3.93s/it]Epoch:   372
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-3.3307e-05, device='cuda:0') min:  tensor(-0.1045, device='cuda:0') norm:  tensor(0.3230, device='cuda:0') MSE:  tensor(1.2126e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  372  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9130, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 37%|███▋      | 372/1000 [23:52<40:58,  3.91s/it]Epoch:   373
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0406, device='cuda:0') mean:  tensor(-3.2915e-05, device='cuda:0') min:  tensor(-0.1161, device='cuda:0') norm:  tensor(0.3316, device='cuda:0') MSE:  tensor(1.2446e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  373  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 37%|███▋      | 373/1000 [23:56<40:58,  3.92s/it]Epoch:   374
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-3.3017e-05, device='cuda:0') min:  tensor(-0.1277, device='cuda:0') norm:  tensor(0.3403, device='cuda:0') MSE:  tensor(1.2773e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  374  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 37%|███▋      | 374/1000 [24:00<40:47,  3.91s/it]Epoch:   375
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0388, device='cuda:0') mean:  tensor(-3.6881e-05, device='cuda:0') min:  tensor(-0.1227, device='cuda:0') norm:  tensor(0.3621, device='cuda:0') MSE:  tensor(1.3592e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  375  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  9
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 38%|███▊      | 375/1000 [24:04<40:23,  3.88s/it]Epoch:   376
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0400, device='cuda:0') mean:  tensor(-3.1911e-05, device='cuda:0') min:  tensor(-0.1154, device='cuda:0') norm:  tensor(0.3314, device='cuda:0') MSE:  tensor(1.2440e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  376  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 38%|███▊      | 376/1000 [24:08<40:08,  3.86s/it]Epoch:   377
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0330, device='cuda:0') mean:  tensor(-3.4669e-05, device='cuda:0') min:  tensor(-0.1100, device='cuda:0') norm:  tensor(0.3316, device='cuda:0') MSE:  tensor(1.2446e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  377  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 38%|███▊      | 377/1000 [24:12<40:47,  3.93s/it]Epoch:   378
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0398, device='cuda:0') mean:  tensor(-3.6275e-05, device='cuda:0') min:  tensor(-0.1151, device='cuda:0') norm:  tensor(0.3546, device='cuda:0') MSE:  tensor(1.3309e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  378  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  28
 38%|███▊      | 378/1000 [24:15<40:11,  3.88s/it]Epoch:   379
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0415, device='cuda:0') mean:  tensor(-3.4948e-05, device='cuda:0') min:  tensor(-0.1213, device='cuda:0') norm:  tensor(0.3552, device='cuda:0') MSE:  tensor(1.3335e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  379  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  28
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 38%|███▊      | 379/1000 [24:19<39:18,  3.80s/it]Epoch:   380
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0374, device='cuda:0') mean:  tensor(-3.4521e-05, device='cuda:0') min:  tensor(-0.1228, device='cuda:0') norm:  tensor(0.3466, device='cuda:0') MSE:  tensor(1.3011e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  380  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  12
max of Lambda2 tensor(607.9020, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 38%|███▊      | 380/1000 [24:23<40:07,  3.88s/it]Epoch:   381
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0395, device='cuda:0') mean:  tensor(-3.4824e-05, device='cuda:0') min:  tensor(-0.1115, device='cuda:0') norm:  tensor(0.3485, device='cuda:0') MSE:  tensor(1.3083e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  381  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.030371766537428e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2884, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 38%|███▊      | 381/1000 [24:27<39:36,  3.84s/it]Epoch:   382
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0369, device='cuda:0') mean:  tensor(-3.4049e-05, device='cuda:0') min:  tensor(-0.1257, device='cuda:0') norm:  tensor(0.3422, device='cuda:0') MSE:  tensor(1.2845e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  382  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 38%|███▊      | 382/1000 [24:31<39:47,  3.86s/it]Epoch:   383
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-3.3535e-05, device='cuda:0') min:  tensor(-0.1217, device='cuda:0') norm:  tensor(0.3406, device='cuda:0') MSE:  tensor(1.2785e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  383  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 38%|███▊      | 383/1000 [24:35<39:45,  3.87s/it]Epoch:   384
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0396, device='cuda:0') mean:  tensor(-3.5540e-05, device='cuda:0') min:  tensor(-0.1227, device='cuda:0') norm:  tensor(0.3548, device='cuda:0') MSE:  tensor(1.3318e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  384  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 38%|███▊      | 384/1000 [24:38<39:18,  3.83s/it]Epoch:   385
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0411, device='cuda:0') mean:  tensor(-3.5062e-05, device='cuda:0') min:  tensor(-0.1108, device='cuda:0') norm:  tensor(0.3474, device='cuda:0') MSE:  tensor(1.3042e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  385  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 38%|███▊      | 385/1000 [24:42<39:46,  3.88s/it]Epoch:   386
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0335, device='cuda:0') mean:  tensor(-3.1732e-05, device='cuda:0') min:  tensor(-0.1060, device='cuda:0') norm:  tensor(0.3139, device='cuda:0') MSE:  tensor(1.1782e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  386  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 39%|███▊      | 386/1000 [24:46<38:21,  3.75s/it]Epoch:   387
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0390, device='cuda:0') mean:  tensor(-3.4159e-05, device='cuda:0') min:  tensor(-0.1092, device='cuda:0') norm:  tensor(0.3350, device='cuda:0') MSE:  tensor(1.2573e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  387  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  14
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 39%|███▊      | 387/1000 [24:50<39:07,  3.83s/it]Epoch:   388
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0406, device='cuda:0') mean:  tensor(-3.2921e-05, device='cuda:0') min:  tensor(-0.1099, device='cuda:0') norm:  tensor(0.3316, device='cuda:0') MSE:  tensor(1.2447e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  388  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(232.2885, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 39%|███▉      | 388/1000 [24:54<39:47,  3.90s/it]Epoch:   389
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0403, device='cuda:0') mean:  tensor(-3.6996e-05, device='cuda:0') min:  tensor(-0.1167, device='cuda:0') norm:  tensor(0.3591, device='cuda:0') MSE:  tensor(1.3478e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  389  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2887, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 39%|███▉      | 389/1000 [24:58<39:34,  3.89s/it]Epoch:   390
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-3.2710e-05, device='cuda:0') min:  tensor(-0.1156, device='cuda:0') norm:  tensor(0.3260, device='cuda:0') MSE:  tensor(1.2237e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  390  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 39%|███▉      | 390/1000 [25:02<39:49,  3.92s/it]Epoch:   391
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0387, device='cuda:0') mean:  tensor(-3.2415e-05, device='cuda:0') min:  tensor(-0.1072, device='cuda:0') norm:  tensor(0.3245, device='cuda:0') MSE:  tensor(1.2179e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  391  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  5
max of Lambda2 tensor(232.2895, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 39%|███▉      | 391/1000 [25:06<40:08,  3.95s/it]Epoch:   392
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0403, device='cuda:0') mean:  tensor(-2.9755e-05, device='cuda:0') min:  tensor(-0.1169, device='cuda:0') norm:  tensor(0.3234, device='cuda:0') MSE:  tensor(1.2139e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  392  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 39%|███▉      | 392/1000 [25:10<40:02,  3.95s/it]Epoch:   393
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0347, device='cuda:0') mean:  tensor(-3.6598e-05, device='cuda:0') min:  tensor(-0.1195, device='cuda:0') norm:  tensor(0.3497, device='cuda:0') MSE:  tensor(1.3127e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  393  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  6.969379981558661e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  5
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 39%|███▉      | 393/1000 [25:14<39:52,  3.94s/it]Epoch:   394
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0357, device='cuda:0') mean:  tensor(-3.0843e-05, device='cuda:0') min:  tensor(-0.1017, device='cuda:0') norm:  tensor(0.3061, device='cuda:0') MSE:  tensor(1.1488e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  394  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 39%|███▉      | 394/1000 [25:18<40:01,  3.96s/it]Epoch:   395
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0402, device='cuda:0') mean:  tensor(-3.3899e-05, device='cuda:0') min:  tensor(-0.1126, device='cuda:0') norm:  tensor(0.3389, device='cuda:0') MSE:  tensor(1.2720e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  395  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 40%|███▉      | 395/1000 [25:22<40:19,  4.00s/it]Epoch:   396
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0306, device='cuda:0') mean:  tensor(-3.2326e-05, device='cuda:0') min:  tensor(-0.0997, device='cuda:0') norm:  tensor(0.3129, device='cuda:0') MSE:  tensor(1.1745e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  396  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2885, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 40%|███▉      | 396/1000 [25:26<40:24,  4.01s/it]Epoch:   397
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0358, device='cuda:0') mean:  tensor(-3.2303e-05, device='cuda:0') min:  tensor(-0.0987, device='cuda:0') norm:  tensor(0.3149, device='cuda:0') MSE:  tensor(1.1819e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  397  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  6
max of Lambda2 tensor(232.2883, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 40%|███▉      | 397/1000 [25:30<39:50,  3.96s/it]Epoch:   398
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0330, device='cuda:0') mean:  tensor(-3.2934e-05, device='cuda:0') min:  tensor(-0.0998, device='cuda:0') norm:  tensor(0.3141, device='cuda:0') MSE:  tensor(1.1789e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  398  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 40%|███▉      | 398/1000 [25:33<38:22,  3.82s/it]Epoch:   399
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0395, device='cuda:0') mean:  tensor(-3.4289e-05, device='cuda:0') min:  tensor(-0.1257, device='cuda:0') norm:  tensor(0.3481, device='cuda:0') MSE:  tensor(1.3067e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  399  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  5.890201144234053e-10 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  7
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 40%|███▉      | 399/1000 [25:37<38:57,  3.89s/it]Epoch:   400
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0374, device='cuda:0') mean:  tensor(-3.1505e-05, device='cuda:0') min:  tensor(-0.0960, device='cuda:0') norm:  tensor(0.3096, device='cuda:0') MSE:  tensor(1.1622e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  400  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 40%|████      | 400/1000 [25:41<39:17,  3.93s/it]Epoch:   401
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0406, device='cuda:0') mean:  tensor(-3.5021e-05, device='cuda:0') min:  tensor(-0.1259, device='cuda:0') norm:  tensor(0.3511, device='cuda:0') MSE:  tensor(1.3178e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  401  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 40%|████      | 401/1000 [25:45<39:17,  3.94s/it]Epoch:   402
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0320, device='cuda:0') mean:  tensor(-3.3918e-05, device='cuda:0') min:  tensor(-0.1118, device='cuda:0') norm:  tensor(0.3300, device='cuda:0') MSE:  tensor(1.2388e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  402  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
 40%|████      | 402/1000 [25:49<38:58,  3.91s/it]Epoch:   403
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0318, device='cuda:0') mean:  tensor(-3.0610e-05, device='cuda:0') min:  tensor(-0.0951, device='cuda:0') norm:  tensor(0.2969, device='cuda:0') MSE:  tensor(1.1143e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  403  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  4
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 40%|████      | 403/1000 [25:53<38:02,  3.82s/it]Epoch:   404
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0433, device='cuda:0') mean:  tensor(-3.4116e-05, device='cuda:0') min:  tensor(-0.1338, device='cuda:0') norm:  tensor(0.3647, device='cuda:0') MSE:  tensor(1.3688e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  404  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 40%|████      | 404/1000 [25:56<37:45,  3.80s/it]Epoch:   405
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0385, device='cuda:0') mean:  tensor(-3.0438e-05, device='cuda:0') min:  tensor(-0.1079, device='cuda:0') norm:  tensor(0.3115, device='cuda:0') MSE:  tensor(1.1695e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  405  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  9
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 40%|████      | 405/1000 [26:00<38:08,  3.85s/it]Epoch:   406
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0396, device='cuda:0') mean:  tensor(-3.5788e-05, device='cuda:0') min:  tensor(-0.1328, device='cuda:0') norm:  tensor(0.3619, device='cuda:0') MSE:  tensor(1.3585e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  406  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  6
max of Lambda2 tensor(607.9010, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 41%|████      | 406/1000 [26:04<38:26,  3.88s/it]Epoch:   407
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0350, device='cuda:0') mean:  tensor(-3.5484e-05, device='cuda:0') min:  tensor(-0.1241, device='cuda:0') norm:  tensor(0.3506, device='cuda:0') MSE:  tensor(1.3159e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  407  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  7
max of Lambda2 tensor(232.2892, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 41%|████      | 407/1000 [26:08<38:37,  3.91s/it]Epoch:   408
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0346, device='cuda:0') mean:  tensor(-3.2034e-05, device='cuda:0') min:  tensor(-0.1190, device='cuda:0') norm:  tensor(0.3267, device='cuda:0') MSE:  tensor(1.2264e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  408  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 41%|████      | 408/1000 [26:12<38:48,  3.93s/it]Epoch:   409
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0408, device='cuda:0') mean:  tensor(-3.4026e-05, device='cuda:0') min:  tensor(-0.1188, device='cuda:0') norm:  tensor(0.3489, device='cuda:0') MSE:  tensor(1.3096e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  409  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  5
max of Lambda2 tensor(232.2902, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 41%|████      | 409/1000 [26:16<38:55,  3.95s/it]Epoch:   410
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0334, device='cuda:0') mean:  tensor(-3.2990e-05, device='cuda:0') min:  tensor(-0.1123, device='cuda:0') norm:  tensor(0.3170, device='cuda:0') MSE:  tensor(1.1899e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  410  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 41%|████      | 410/1000 [26:20<39:01,  3.97s/it]Epoch:   411
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0359, device='cuda:0') mean:  tensor(-3.2217e-05, device='cuda:0') min:  tensor(-0.1099, device='cuda:0') norm:  tensor(0.3175, device='cuda:0') MSE:  tensor(1.1917e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  411  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  5.890201144234053e-10 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  5
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 41%|████      | 411/1000 [26:24<39:16,  4.00s/it]Epoch:   412
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0405, device='cuda:0') mean:  tensor(-3.4289e-05, device='cuda:0') min:  tensor(-0.1059, device='cuda:0') norm:  tensor(0.3410, device='cuda:0') MSE:  tensor(1.2799e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  412  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.9029, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 41%|████      | 412/1000 [26:28<39:11,  4.00s/it]Epoch:   413
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0406, device='cuda:0') mean:  tensor(-3.1966e-05, device='cuda:0') min:  tensor(-0.1102, device='cuda:0') norm:  tensor(0.3290, device='cuda:0') MSE:  tensor(1.2349e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  413  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9006, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 41%|████▏     | 413/1000 [26:32<39:00,  3.99s/it]Epoch:   414
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0337, device='cuda:0') mean:  tensor(-3.1290e-05, device='cuda:0') min:  tensor(-0.1081, device='cuda:0') norm:  tensor(0.3119, device='cuda:0') MSE:  tensor(1.1709e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  414  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2890, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
 41%|████▏     | 414/1000 [26:36<39:10,  4.01s/it]Epoch:   415
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0354, device='cuda:0') mean:  tensor(-3.3862e-05, device='cuda:0') min:  tensor(-0.1161, device='cuda:0') norm:  tensor(0.3414, device='cuda:0') MSE:  tensor(1.2815e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  415  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  4
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 42%|████▏     | 415/1000 [26:40<38:28,  3.95s/it]Epoch:   416
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0369, device='cuda:0') mean:  tensor(-3.4574e-05, device='cuda:0') min:  tensor(-0.1172, device='cuda:0') norm:  tensor(0.3398, device='cuda:0') MSE:  tensor(1.2757e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  416  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2896, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 42%|████▏     | 416/1000 [26:44<38:06,  3.91s/it]Epoch:   417
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0360, device='cuda:0') mean:  tensor(-3.3417e-05, device='cuda:0') min:  tensor(-0.1010, device='cuda:0') norm:  tensor(0.3208, device='cuda:0') MSE:  tensor(1.2041e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  417  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  5.890201144234053e-10 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2878, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 42%|████▏     | 417/1000 [26:48<38:00,  3.91s/it]Epoch:   418
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0349, device='cuda:0') mean:  tensor(-3.7030e-05, device='cuda:0') min:  tensor(-0.1082, device='cuda:0') norm:  tensor(0.3484, device='cuda:0') MSE:  tensor(1.3078e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  418  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 42%|████▏     | 418/1000 [26:52<38:26,  3.96s/it]Epoch:   419
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0367, device='cuda:0') mean:  tensor(-3.4402e-05, device='cuda:0') min:  tensor(-0.1094, device='cuda:0') norm:  tensor(0.3309, device='cuda:0') MSE:  tensor(1.2422e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  419  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  12
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 42%|████▏     | 419/1000 [26:56<38:29,  3.98s/it]Epoch:   420
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0433, device='cuda:0') mean:  tensor(-3.4668e-05, device='cuda:0') min:  tensor(-0.1106, device='cuda:0') norm:  tensor(0.3426, device='cuda:0') MSE:  tensor(1.2859e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  420  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2894, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 42%|████▏     | 420/1000 [27:00<38:38,  4.00s/it]Epoch:   421
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0347, device='cuda:0') mean:  tensor(-3.3369e-05, device='cuda:0') min:  tensor(-0.1011, device='cuda:0') norm:  tensor(0.3202, device='cuda:0') MSE:  tensor(1.2021e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  421  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  10
max of Lambda2 tensor(232.2877, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 42%|████▏     | 421/1000 [27:04<38:35,  4.00s/it]Epoch:   422
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0399, device='cuda:0') mean:  tensor(-3.0515e-05, device='cuda:0') min:  tensor(-0.1202, device='cuda:0') norm:  tensor(0.3288, device='cuda:0') MSE:  tensor(1.2344e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  422  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2886, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 42%|████▏     | 422/1000 [27:08<38:06,  3.96s/it]Epoch:   423
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0375, device='cuda:0') mean:  tensor(-3.2818e-05, device='cuda:0') min:  tensor(-0.1247, device='cuda:0') norm:  tensor(0.3401, device='cuda:0') MSE:  tensor(1.2767e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  423  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.030371878296137e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 42%|████▏     | 423/1000 [27:12<38:14,  3.98s/it]Epoch:   424
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0416, device='cuda:0') mean:  tensor(-3.6855e-05, device='cuda:0') min:  tensor(-0.1201, device='cuda:0') norm:  tensor(0.3566, device='cuda:0') MSE:  tensor(1.3386e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  424  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.9106, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 42%|████▏     | 424/1000 [27:16<38:16,  3.99s/it]Epoch:   425
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0441, device='cuda:0') mean:  tensor(-3.4291e-05, device='cuda:0') min:  tensor(-0.1233, device='cuda:0') norm:  tensor(0.3634, device='cuda:0') MSE:  tensor(1.3640e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  425  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 42%|████▎     | 425/1000 [27:19<36:41,  3.83s/it]Epoch:   426
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0402, device='cuda:0') mean:  tensor(-3.3392e-05, device='cuda:0') min:  tensor(-0.1143, device='cuda:0') norm:  tensor(0.3389, device='cuda:0') MSE:  tensor(1.2722e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  426  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  6
max of Lambda2 tensor(232.2886, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 43%|████▎     | 426/1000 [27:23<37:20,  3.90s/it]Epoch:   427
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0340, device='cuda:0') mean:  tensor(-3.2447e-05, device='cuda:0') min:  tensor(-0.1116, device='cuda:0') norm:  tensor(0.3182, device='cuda:0') MSE:  tensor(1.1945e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  427  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 43%|████▎     | 427/1000 [27:27<37:21,  3.91s/it]Epoch:   428
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-3.5103e-05, device='cuda:0') min:  tensor(-0.1080, device='cuda:0') norm:  tensor(0.3357, device='cuda:0') MSE:  tensor(1.2602e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  428  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 43%|████▎     | 428/1000 [27:31<35:23,  3.71s/it]Epoch:   429
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0456, device='cuda:0') mean:  tensor(-3.1547e-05, device='cuda:0') min:  tensor(-0.1245, device='cuda:0') norm:  tensor(0.3529, device='cuda:0') MSE:  tensor(1.3248e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  429  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  7
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 43%|████▎     | 429/1000 [27:35<36:12,  3.81s/it]Epoch:   430
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0370, device='cuda:0') mean:  tensor(-3.3131e-05, device='cuda:0') min:  tensor(-0.1062, device='cuda:0') norm:  tensor(0.3271, device='cuda:0') MSE:  tensor(1.2279e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  430  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  5
max of Lambda2 tensor(607.9103, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 43%|████▎     | 430/1000 [27:39<37:12,  3.92s/it]Epoch:   431
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0379, device='cuda:0') mean:  tensor(-3.1616e-05, device='cuda:0') min:  tensor(-0.1058, device='cuda:0') norm:  tensor(0.3236, device='cuda:0') MSE:  tensor(1.2148e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  431  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  12
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 43%|████▎     | 431/1000 [27:43<37:18,  3.93s/it]Epoch:   432
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0349, device='cuda:0') mean:  tensor(-3.4162e-05, device='cuda:0') min:  tensor(-0.1171, device='cuda:0') norm:  tensor(0.3353, device='cuda:0') MSE:  tensor(1.2585e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  432  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  5
max of Lambda2 tensor(232.2896, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 43%|████▎     | 432/1000 [27:47<37:16,  3.94s/it]Epoch:   433
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0362, device='cuda:0') mean:  tensor(-3.3518e-05, device='cuda:0') min:  tensor(-0.0999, device='cuda:0') norm:  tensor(0.3220, device='cuda:0') MSE:  tensor(1.2086e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  433  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 43%|████▎     | 433/1000 [27:50<36:16,  3.84s/it]Epoch:   434
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0425, device='cuda:0') mean:  tensor(-3.6533e-05, device='cuda:0') min:  tensor(-0.1229, device='cuda:0') norm:  tensor(0.3634, device='cuda:0') MSE:  tensor(1.3642e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  434  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 43%|████▎     | 434/1000 [27:54<36:05,  3.83s/it]Epoch:   435
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0406, device='cuda:0') mean:  tensor(-3.4612e-05, device='cuda:0') min:  tensor(-0.1211, device='cuda:0') norm:  tensor(0.3482, device='cuda:0') MSE:  tensor(1.3069e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  435  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  7.450580596923828e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  7
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9090, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 44%|████▎     | 435/1000 [27:58<36:42,  3.90s/it]Epoch:   436
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0310, device='cuda:0') mean:  tensor(-3.2837e-05, device='cuda:0') min:  tensor(-0.0994, device='cuda:0') norm:  tensor(0.3119, device='cuda:0') MSE:  tensor(1.1707e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  436  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 44%|████▎     | 436/1000 [28:02<36:32,  3.89s/it]Epoch:   437
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0315, device='cuda:0') mean:  tensor(-3.3109e-05, device='cuda:0') min:  tensor(-0.0982, device='cuda:0') norm:  tensor(0.3125, device='cuda:0') MSE:  tensor(1.1730e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  437  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 44%|████▎     | 437/1000 [28:06<36:31,  3.89s/it]Epoch:   438
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0380, device='cuda:0') mean:  tensor(-3.0828e-05, device='cuda:0') min:  tensor(-0.1151, device='cuda:0') norm:  tensor(0.3183, device='cuda:0') MSE:  tensor(1.1949e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  438  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(232.2890, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 44%|████▍     | 438/1000 [28:10<36:40,  3.92s/it]Epoch:   439
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0361, device='cuda:0') mean:  tensor(-3.5748e-05, device='cuda:0') min:  tensor(-0.1203, device='cuda:0') norm:  tensor(0.3496, device='cuda:0') MSE:  tensor(1.3124e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  439  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 44%|████▍     | 439/1000 [28:14<36:31,  3.91s/it]Epoch:   440
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0392, device='cuda:0') mean:  tensor(-3.5731e-05, device='cuda:0') min:  tensor(-0.1177, device='cuda:0') norm:  tensor(0.3518, device='cuda:0') MSE:  tensor(1.3206e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  440  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 44%|████▍     | 440/1000 [28:17<35:10,  3.77s/it]Epoch:   441
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0344, device='cuda:0') mean:  tensor(-3.2786e-05, device='cuda:0') min:  tensor(-0.1094, device='cuda:0') norm:  tensor(0.3155, device='cuda:0') MSE:  tensor(1.1842e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  441  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  6
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 44%|████▍     | 441/1000 [28:21<35:04,  3.76s/it]Epoch:   442
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0328, device='cuda:0') mean:  tensor(-3.4514e-05, device='cuda:0') min:  tensor(-0.1126, device='cuda:0') norm:  tensor(0.3300, device='cuda:0') MSE:  tensor(1.2386e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  442  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 44%|████▍     | 442/1000 [28:25<34:42,  3.73s/it]Epoch:   443
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0356, device='cuda:0') mean:  tensor(-3.3557e-05, device='cuda:0') min:  tensor(-0.1141, device='cuda:0') norm:  tensor(0.3298, device='cuda:0') MSE:  tensor(1.2378e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  443  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(232.2882, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 44%|████▍     | 443/1000 [28:28<34:44,  3.74s/it]Epoch:   444
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0359, device='cuda:0') mean:  tensor(-3.4362e-05, device='cuda:0') min:  tensor(-0.1100, device='cuda:0') norm:  tensor(0.3345, device='cuda:0') MSE:  tensor(1.2556e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  444  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 44%|████▍     | 444/1000 [28:32<35:17,  3.81s/it]Epoch:   445
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0423, device='cuda:0') mean:  tensor(-3.4169e-05, device='cuda:0') min:  tensor(-0.1142, device='cuda:0') norm:  tensor(0.3400, device='cuda:0') MSE:  tensor(1.2761e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  445  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 44%|████▍     | 445/1000 [28:36<35:11,  3.80s/it]Epoch:   446
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0340, device='cuda:0') mean:  tensor(-3.2892e-05, device='cuda:0') min:  tensor(-0.1085, device='cuda:0') norm:  tensor(0.3216, device='cuda:0') MSE:  tensor(1.2074e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  446  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 45%|████▍     | 446/1000 [28:40<35:51,  3.88s/it]Epoch:   447
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0413, device='cuda:0') mean:  tensor(-3.5601e-05, device='cuda:0') min:  tensor(-0.1220, device='cuda:0') norm:  tensor(0.3621, device='cuda:0') MSE:  tensor(1.3591e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  447  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 45%|████▍     | 447/1000 [28:44<36:09,  3.92s/it]Epoch:   448
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0378, device='cuda:0') mean:  tensor(-3.3342e-05, device='cuda:0') min:  tensor(-0.1085, device='cuda:0') norm:  tensor(0.3273, device='cuda:0') MSE:  tensor(1.2285e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  448  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  12
max of Lambda2 tensor(607.9113, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 45%|████▍     | 448/1000 [28:48<35:45,  3.89s/it]Epoch:   449
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0445, device='cuda:0') mean:  tensor(-3.7218e-05, device='cuda:0') min:  tensor(-0.1308, device='cuda:0') norm:  tensor(0.3760, device='cuda:0') MSE:  tensor(1.4115e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  449  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 45%|████▍     | 449/1000 [28:52<35:55,  3.91s/it]Epoch:   450
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0387, device='cuda:0') mean:  tensor(-3.7565e-05, device='cuda:0') min:  tensor(-0.1212, device='cuda:0') norm:  tensor(0.3590, device='cuda:0') MSE:  tensor(1.3476e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  450  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9081, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 45%|████▌     | 450/1000 [28:56<35:58,  3.93s/it]Epoch:   451
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0394, device='cuda:0') mean:  tensor(-3.5025e-05, device='cuda:0') min:  tensor(-0.1207, device='cuda:0') norm:  tensor(0.3485, device='cuda:0') MSE:  tensor(1.3082e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  451  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2894, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 45%|████▌     | 451/1000 [29:00<35:58,  3.93s/it]Epoch:   452
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0346, device='cuda:0') mean:  tensor(-3.3439e-05, device='cuda:0') min:  tensor(-0.1087, device='cuda:0') norm:  tensor(0.3283, device='cuda:0') MSE:  tensor(1.2323e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  452  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 45%|████▌     | 452/1000 [29:04<35:27,  3.88s/it]Epoch:   453
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0368, device='cuda:0') mean:  tensor(-3.3609e-05, device='cuda:0') min:  tensor(-0.1229, device='cuda:0') norm:  tensor(0.3521, device='cuda:0') MSE:  tensor(1.3218e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  453  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  5.890201144234053e-10 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  6
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 45%|████▌     | 453/1000 [29:08<35:39,  3.91s/it]Epoch:   454
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0326, device='cuda:0') mean:  tensor(-3.3489e-05, device='cuda:0') min:  tensor(-0.1025, device='cuda:0') norm:  tensor(0.3163, device='cuda:0') MSE:  tensor(1.1875e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  454  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 45%|████▌     | 454/1000 [29:12<35:49,  3.94s/it]Epoch:   455
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0341, device='cuda:0') mean:  tensor(-3.1844e-05, device='cuda:0') min:  tensor(-0.0955, device='cuda:0') norm:  tensor(0.3056, device='cuda:0') MSE:  tensor(1.1470e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  455  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 46%|████▌     | 455/1000 [29:16<36:05,  3.97s/it]Epoch:   456
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0308, device='cuda:0') mean:  tensor(-3.4901e-05, device='cuda:0') min:  tensor(-0.1174, device='cuda:0') norm:  tensor(0.3385, device='cuda:0') MSE:  tensor(1.2705e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  456  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 46%|████▌     | 456/1000 [29:20<35:36,  3.93s/it]Epoch:   457
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0401, device='cuda:0') mean:  tensor(-3.4834e-05, device='cuda:0') min:  tensor(-0.1185, device='cuda:0') norm:  tensor(0.3410, device='cuda:0') MSE:  tensor(1.2801e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  457  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9146, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 46%|████▌     | 457/1000 [29:23<34:41,  3.83s/it]Epoch:   458
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0382, device='cuda:0') mean:  tensor(-3.6916e-05, device='cuda:0') min:  tensor(-0.1200, device='cuda:0') norm:  tensor(0.3643, device='cuda:0') MSE:  tensor(1.3675e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  458  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(232.2895, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 46%|████▌     | 458/1000 [29:27<34:56,  3.87s/it]Epoch:   459
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0325, device='cuda:0') mean:  tensor(-3.3394e-05, device='cuda:0') min:  tensor(-0.1047, device='cuda:0') norm:  tensor(0.3249, device='cuda:0') MSE:  tensor(1.2197e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  459  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.030371878296137e-05
Preserved_eigens number check:  7
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 46%|████▌     | 459/1000 [29:31<34:42,  3.85s/it]Epoch:   460
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0379, device='cuda:0') mean:  tensor(-3.1641e-05, device='cuda:0') min:  tensor(-0.1189, device='cuda:0') norm:  tensor(0.3289, device='cuda:0') MSE:  tensor(1.2346e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  460  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 46%|████▌     | 460/1000 [29:35<35:01,  3.89s/it]Epoch:   461
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0438, device='cuda:0') mean:  tensor(-3.4918e-05, device='cuda:0') min:  tensor(-0.1158, device='cuda:0') norm:  tensor(0.3487, device='cuda:0') MSE:  tensor(1.3089e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  461  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 46%|████▌     | 461/1000 [29:39<34:58,  3.89s/it]Epoch:   462
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0342, device='cuda:0') mean:  tensor(-3.1621e-05, device='cuda:0') min:  tensor(-0.1086, device='cuda:0') norm:  tensor(0.3125, device='cuda:0') MSE:  tensor(1.1731e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  462  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 46%|████▌     | 462/1000 [29:43<34:43,  3.87s/it]Epoch:   463
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0347, device='cuda:0') mean:  tensor(-3.4582e-05, device='cuda:0') min:  tensor(-0.1200, device='cuda:0') norm:  tensor(0.3364, device='cuda:0') MSE:  tensor(1.2628e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  463  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9006, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 46%|████▋     | 463/1000 [29:47<34:31,  3.86s/it]Epoch:   464
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0390, device='cuda:0') mean:  tensor(-3.5188e-05, device='cuda:0') min:  tensor(-0.1138, device='cuda:0') norm:  tensor(0.3464, device='cuda:0') MSE:  tensor(1.3004e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  464  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2873, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 46%|████▋     | 464/1000 [29:50<34:33,  3.87s/it]Epoch:   465
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0387, device='cuda:0') mean:  tensor(-3.6987e-05, device='cuda:0') min:  tensor(-0.1333, device='cuda:0') norm:  tensor(0.3747, device='cuda:0') MSE:  tensor(1.4064e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  465  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9036, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 46%|████▋     | 465/1000 [29:54<34:14,  3.84s/it]Epoch:   466
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0411, device='cuda:0') mean:  tensor(-3.6465e-05, device='cuda:0') min:  tensor(-0.1214, device='cuda:0') norm:  tensor(0.3556, device='cuda:0') MSE:  tensor(1.3350e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  466  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 47%|████▋     | 466/1000 [29:58<34:22,  3.86s/it]Epoch:   467
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0369, device='cuda:0') mean:  tensor(-3.2381e-05, device='cuda:0') min:  tensor(-0.1120, device='cuda:0') norm:  tensor(0.3213, device='cuda:0') MSE:  tensor(1.2062e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  467  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 47%|████▋     | 467/1000 [30:02<33:38,  3.79s/it]Epoch:   468
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0355, device='cuda:0') mean:  tensor(-3.1244e-05, device='cuda:0') min:  tensor(-0.0994, device='cuda:0') norm:  tensor(0.3053, device='cuda:0') MSE:  tensor(1.1461e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  468  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.8963, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 47%|████▋     | 468/1000 [30:06<33:44,  3.80s/it]Epoch:   469
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0387, device='cuda:0') mean:  tensor(-3.4495e-05, device='cuda:0') min:  tensor(-0.1301, device='cuda:0') norm:  tensor(0.3501, device='cuda:0') MSE:  tensor(1.3142e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  469  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 47%|████▋     | 469/1000 [30:10<34:19,  3.88s/it]Epoch:   470
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0359, device='cuda:0') mean:  tensor(-3.2824e-05, device='cuda:0') min:  tensor(-0.1004, device='cuda:0') norm:  tensor(0.3200, device='cuda:0') MSE:  tensor(1.2013e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  470  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 47%|████▋     | 470/1000 [30:14<34:28,  3.90s/it]Epoch:   471
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0407, device='cuda:0') mean:  tensor(-3.5652e-05, device='cuda:0') min:  tensor(-0.1167, device='cuda:0') norm:  tensor(0.3458, device='cuda:0') MSE:  tensor(1.2982e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  471  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  11
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2888, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 47%|████▋     | 471/1000 [30:18<34:38,  3.93s/it]Epoch:   472
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0347, device='cuda:0') mean:  tensor(-3.4806e-05, device='cuda:0') min:  tensor(-0.1103, device='cuda:0') norm:  tensor(0.3339, device='cuda:0') MSE:  tensor(1.2535e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  472  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 47%|████▋     | 472/1000 [30:21<34:29,  3.92s/it]Epoch:   473
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-3.4909e-05, device='cuda:0') min:  tensor(-0.1185, device='cuda:0') norm:  tensor(0.3429, device='cuda:0') MSE:  tensor(1.2870e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  473  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 47%|████▋     | 473/1000 [30:25<33:52,  3.86s/it]Epoch:   474
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0345, device='cuda:0') mean:  tensor(-3.3099e-05, device='cuda:0') min:  tensor(-0.1036, device='cuda:0') norm:  tensor(0.3202, device='cuda:0') MSE:  tensor(1.2018e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  474  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 47%|████▋     | 474/1000 [30:29<33:45,  3.85s/it]Epoch:   475
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0451, device='cuda:0') mean:  tensor(-3.5468e-05, device='cuda:0') min:  tensor(-0.1269, device='cuda:0') norm:  tensor(0.3667, device='cuda:0') MSE:  tensor(1.3766e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  475  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 48%|████▊     | 475/1000 [30:33<33:18,  3.81s/it]Epoch:   476
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0308, device='cuda:0') mean:  tensor(-3.3727e-05, device='cuda:0') min:  tensor(-0.1011, device='cuda:0') norm:  tensor(0.3125, device='cuda:0') MSE:  tensor(1.1732e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  476  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  15
max of Lambda2 tensor(607.9010, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 48%|████▊     | 476/1000 [30:37<33:54,  3.88s/it]Epoch:   477
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0382, device='cuda:0') mean:  tensor(-3.4424e-05, device='cuda:0') min:  tensor(-0.1194, device='cuda:0') norm:  tensor(0.3444, device='cuda:0') MSE:  tensor(1.2928e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  477  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  6.96937998155866e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 48%|████▊     | 477/1000 [30:41<34:05,  3.91s/it]Epoch:   478
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0373, device='cuda:0') mean:  tensor(-3.2957e-05, device='cuda:0') min:  tensor(-0.1058, device='cuda:0') norm:  tensor(0.3239, device='cuda:0') MSE:  tensor(1.2159e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  478  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 48%|████▊     | 478/1000 [30:44<33:30,  3.85s/it]Epoch:   479
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0410, device='cuda:0') mean:  tensor(-3.6410e-05, device='cuda:0') min:  tensor(-0.1306, device='cuda:0') norm:  tensor(0.3711, device='cuda:0') MSE:  tensor(1.3930e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  479  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 48%|████▊     | 479/1000 [30:48<33:52,  3.90s/it]Epoch:   480
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0353, device='cuda:0') mean:  tensor(-3.1158e-05, device='cuda:0') min:  tensor(-0.1034, device='cuda:0') norm:  tensor(0.3135, device='cuda:0') MSE:  tensor(1.1769e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  480  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 48%|████▊     | 480/1000 [30:52<33:08,  3.82s/it]Epoch:   481
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-3.2309e-05, device='cuda:0') min:  tensor(-0.1082, device='cuda:0') norm:  tensor(0.3197, device='cuda:0') MSE:  tensor(1.2002e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  481  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 48%|████▊     | 481/1000 [30:56<33:30,  3.87s/it]Epoch:   482
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0361, device='cuda:0') mean:  tensor(-3.3912e-05, device='cuda:0') min:  tensor(-0.1136, device='cuda:0') norm:  tensor(0.3290, device='cuda:0') MSE:  tensor(1.2350e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  482  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 48%|████▊     | 482/1000 [31:00<33:43,  3.91s/it]Epoch:   483
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0401, device='cuda:0') mean:  tensor(-3.7039e-05, device='cuda:0') min:  tensor(-0.1248, device='cuda:0') norm:  tensor(0.3679, device='cuda:0') MSE:  tensor(1.3809e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  483  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  6
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 48%|████▊     | 483/1000 [31:04<34:00,  3.95s/it]Epoch:   484
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0368, device='cuda:0') mean:  tensor(-3.3792e-05, device='cuda:0') min:  tensor(-0.1039, device='cuda:0') norm:  tensor(0.3277, device='cuda:0') MSE:  tensor(1.2300e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  484  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 48%|████▊     | 484/1000 [31:08<34:08,  3.97s/it]Epoch:   485
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0358, device='cuda:0') mean:  tensor(-3.2347e-05, device='cuda:0') min:  tensor(-0.1249, device='cuda:0') norm:  tensor(0.3341, device='cuda:0') MSE:  tensor(1.2543e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  485  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9141, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 48%|████▊     | 485/1000 [31:12<33:52,  3.95s/it]Epoch:   486
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0369, device='cuda:0') mean:  tensor(-3.2144e-05, device='cuda:0') min:  tensor(-0.1076, device='cuda:0') norm:  tensor(0.3204, device='cuda:0') MSE:  tensor(1.2026e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  486  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 49%|████▊     | 486/1000 [31:16<33:33,  3.92s/it]Epoch:   487
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0412, device='cuda:0') mean:  tensor(-3.3065e-05, device='cuda:0') min:  tensor(-0.1179, device='cuda:0') norm:  tensor(0.3374, device='cuda:0') MSE:  tensor(1.2666e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  487  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 49%|████▊     | 487/1000 [31:20<33:20,  3.90s/it]Epoch:   488
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0331, device='cuda:0') mean:  tensor(-2.8341e-05, device='cuda:0') min:  tensor(-0.1022, device='cuda:0') norm:  tensor(0.2889, device='cuda:0') MSE:  tensor(1.0844e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  488  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 49%|████▉     | 488/1000 [31:24<33:31,  3.93s/it]Epoch:   489
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0334, device='cuda:0') mean:  tensor(-3.2588e-05, device='cuda:0') min:  tensor(-0.1072, device='cuda:0') norm:  tensor(0.3112, device='cuda:0') MSE:  tensor(1.1681e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  489  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  5.890201144234053e-10 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  11
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 49%|████▉     | 489/1000 [31:27<32:29,  3.82s/it]Epoch:   490
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0332, device='cuda:0') mean:  tensor(-3.2839e-05, device='cuda:0') min:  tensor(-0.1099, device='cuda:0') norm:  tensor(0.3213, device='cuda:0') MSE:  tensor(1.2061e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  490  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 49%|████▉     | 490/1000 [31:31<31:54,  3.75s/it]Epoch:   491
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0373, device='cuda:0') mean:  tensor(-3.1260e-05, device='cuda:0') min:  tensor(-0.1055, device='cuda:0') norm:  tensor(0.3140, device='cuda:0') MSE:  tensor(1.1787e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  491  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 49%|████▉     | 491/1000 [31:35<31:40,  3.73s/it]Epoch:   492
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0390, device='cuda:0') mean:  tensor(-3.4024e-05, device='cuda:0') min:  tensor(-0.1178, device='cuda:0') norm:  tensor(0.3409, device='cuda:0') MSE:  tensor(1.2795e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  492  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.9151, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 49%|████▉     | 492/1000 [31:39<32:01,  3.78s/it]Epoch:   493
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0358, device='cuda:0') mean:  tensor(-3.4254e-05, device='cuda:0') min:  tensor(-0.1173, device='cuda:0') norm:  tensor(0.3404, device='cuda:0') MSE:  tensor(1.2778e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  493  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 49%|████▉     | 493/1000 [31:42<31:41,  3.75s/it]Epoch:   494
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0360, device='cuda:0') mean:  tensor(-3.6168e-05, device='cuda:0') min:  tensor(-0.1176, device='cuda:0') norm:  tensor(0.3405, device='cuda:0') MSE:  tensor(1.2781e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  494  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(232.2891, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 49%|████▉     | 494/1000 [31:46<31:21,  3.72s/it]Epoch:   495
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0345, device='cuda:0') mean:  tensor(-3.2213e-05, device='cuda:0') min:  tensor(-0.1022, device='cuda:0') norm:  tensor(0.3125, device='cuda:0') MSE:  tensor(1.1729e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  495  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 50%|████▉     | 495/1000 [31:49<31:10,  3.70s/it]Epoch:   496
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0359, device='cuda:0') mean:  tensor(-3.5013e-05, device='cuda:0') min:  tensor(-0.1053, device='cuda:0') norm:  tensor(0.3321, device='cuda:0') MSE:  tensor(1.2468e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  496  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 50%|████▉     | 496/1000 [31:53<31:21,  3.73s/it]Epoch:   497
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-3.3954e-05, device='cuda:0') min:  tensor(-0.1124, device='cuda:0') norm:  tensor(0.3397, device='cuda:0') MSE:  tensor(1.2752e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  497  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 50%|████▉     | 497/1000 [31:57<31:32,  3.76s/it]Epoch:   498
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0391, device='cuda:0') mean:  tensor(-3.3160e-05, device='cuda:0') min:  tensor(-0.1095, device='cuda:0') norm:  tensor(0.3331, device='cuda:0') MSE:  tensor(1.2506e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  498  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 50%|████▉     | 498/1000 [32:01<32:21,  3.87s/it]Epoch:   499
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0365, device='cuda:0') mean:  tensor(-3.1410e-05, device='cuda:0') min:  tensor(-0.1150, device='cuda:0') norm:  tensor(0.3240, device='cuda:0') MSE:  tensor(1.2162e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  499  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  11
max of Lambda2 tensor(232.2882, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 50%|████▉     | 499/1000 [32:05<32:44,  3.92s/it]Epoch:   500
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0357, device='cuda:0') mean:  tensor(-3.5686e-05, device='cuda:0') min:  tensor(-0.1185, device='cuda:0') norm:  tensor(0.3474, device='cuda:0') MSE:  tensor(1.3040e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  500  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 50%|█████     | 500/1000 [32:09<32:42,  3.92s/it]Epoch:   501
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0362, device='cuda:0') mean:  tensor(-3.2147e-05, device='cuda:0') min:  tensor(-0.1220, device='cuda:0') norm:  tensor(0.3350, device='cuda:0') MSE:  tensor(1.2573e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  501  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  12
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 50%|█████     | 501/1000 [32:13<32:32,  3.91s/it]Epoch:   502
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0348, device='cuda:0') mean:  tensor(-3.4911e-05, device='cuda:0') min:  tensor(-0.1151, device='cuda:0') norm:  tensor(0.3407, device='cuda:0') MSE:  tensor(1.2789e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  502  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(607.9116, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 50%|█████     | 502/1000 [32:17<32:01,  3.86s/it]Epoch:   503
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-3.3912e-05, device='cuda:0') min:  tensor(-0.0995, device='cuda:0') norm:  tensor(0.3188, device='cuda:0') MSE:  tensor(1.1968e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  503  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 50%|█████     | 503/1000 [32:21<32:01,  3.87s/it]Epoch:   504
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0355, device='cuda:0') mean:  tensor(-3.2997e-05, device='cuda:0') min:  tensor(-0.1138, device='cuda:0') norm:  tensor(0.3285, device='cuda:0') MSE:  tensor(1.2331e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  504  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  12
max of Lambda2 tensor(232.2891, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 50%|█████     | 504/1000 [32:25<32:32,  3.94s/it]Epoch:   505
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0308, device='cuda:0') mean:  tensor(-3.5266e-05, device='cuda:0') min:  tensor(-0.1148, device='cuda:0') norm:  tensor(0.3398, device='cuda:0') MSE:  tensor(1.2756e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  505  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  6
max of Lambda2 tensor(232.2891, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 50%|█████     | 505/1000 [32:29<32:38,  3.96s/it]Epoch:   506
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0332, device='cuda:0') mean:  tensor(-3.3172e-05, device='cuda:0') min:  tensor(-0.1007, device='cuda:0') norm:  tensor(0.3134, device='cuda:0') MSE:  tensor(1.1765e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  506  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 51%|█████     | 506/1000 [32:33<32:18,  3.93s/it]Epoch:   507
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0355, device='cuda:0') mean:  tensor(-3.4082e-05, device='cuda:0') min:  tensor(-0.1081, device='cuda:0') norm:  tensor(0.3286, device='cuda:0') MSE:  tensor(1.2335e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  507  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  5
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9105, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 51%|█████     | 507/1000 [32:37<32:45,  3.99s/it]Epoch:   508
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-3.5634e-05, device='cuda:0') min:  tensor(-0.1322, device='cuda:0') norm:  tensor(0.3593, device='cuda:0') MSE:  tensor(1.3486e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  508  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 51%|█████     | 508/1000 [32:41<32:16,  3.94s/it]Epoch:   509
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0383, device='cuda:0') mean:  tensor(-3.3196e-05, device='cuda:0') min:  tensor(-0.1126, device='cuda:0') norm:  tensor(0.3317, device='cuda:0') MSE:  tensor(1.2453e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  509  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2886, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 51%|█████     | 509/1000 [32:45<32:21,  3.95s/it]Epoch:   510
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0355, device='cuda:0') mean:  tensor(-3.3922e-05, device='cuda:0') min:  tensor(-0.1076, device='cuda:0') norm:  tensor(0.3246, device='cuda:0') MSE:  tensor(1.2184e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  510  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2876, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 51%|█████     | 510/1000 [32:48<31:38,  3.87s/it]Epoch:   511
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0422, device='cuda:0') mean:  tensor(-3.2002e-05, device='cuda:0') min:  tensor(-0.1106, device='cuda:0') norm:  tensor(0.3229, device='cuda:0') MSE:  tensor(1.2121e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  511  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 51%|█████     | 511/1000 [32:52<31:54,  3.91s/it]Epoch:   512
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0373, device='cuda:0') mean:  tensor(-3.1011e-05, device='cuda:0') min:  tensor(-0.1104, device='cuda:0') norm:  tensor(0.3136, device='cuda:0') MSE:  tensor(1.1771e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  512  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9017, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 51%|█████     | 512/1000 [32:56<31:21,  3.86s/it]Epoch:   513
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0318, device='cuda:0') mean:  tensor(-3.5438e-05, device='cuda:0') min:  tensor(-0.1150, device='cuda:0') norm:  tensor(0.3366, device='cuda:0') MSE:  tensor(1.2634e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  513  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  5.890201144234053e-10 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 51%|█████▏    | 513/1000 [33:00<31:38,  3.90s/it]Epoch:   514
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0364, device='cuda:0') mean:  tensor(-3.2767e-05, device='cuda:0') min:  tensor(-0.1067, device='cuda:0') norm:  tensor(0.3214, device='cuda:0') MSE:  tensor(1.2063e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  514  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 51%|█████▏    | 514/1000 [33:04<31:43,  3.92s/it]Epoch:   515
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-3.5431e-05, device='cuda:0') min:  tensor(-0.1066, device='cuda:0') norm:  tensor(0.3351, device='cuda:0') MSE:  tensor(1.2579e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  515  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 52%|█████▏    | 515/1000 [33:08<31:15,  3.87s/it]Epoch:   516
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0435, device='cuda:0') mean:  tensor(-3.4197e-05, device='cuda:0') min:  tensor(-0.1339, device='cuda:0') norm:  tensor(0.3663, device='cuda:0') MSE:  tensor(1.3749e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  516  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  12
max of Lambda2 tensor(607.9006, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 52%|█████▏    | 516/1000 [33:12<31:30,  3.91s/it]Epoch:   517
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0348, device='cuda:0') mean:  tensor(-3.5515e-05, device='cuda:0') min:  tensor(-0.1108, device='cuda:0') norm:  tensor(0.3356, device='cuda:0') MSE:  tensor(1.2596e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  517  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  11
max of Lambda2 tensor(232.2874, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 52%|█████▏    | 517/1000 [33:16<31:44,  3.94s/it]Epoch:   518
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0401, device='cuda:0') mean:  tensor(-3.7457e-05, device='cuda:0') min:  tensor(-0.1102, device='cuda:0') norm:  tensor(0.3560, device='cuda:0') MSE:  tensor(1.3362e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  518  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 52%|█████▏    | 518/1000 [33:19<30:33,  3.80s/it]Epoch:   519
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0387, device='cuda:0') mean:  tensor(-3.3103e-05, device='cuda:0') min:  tensor(-0.1177, device='cuda:0') norm:  tensor(0.3438, device='cuda:0') MSE:  tensor(1.2905e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  519  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.030371766537428e-05
Preserved_eigens number check:  7
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 52%|█████▏    | 519/1000 [33:23<30:05,  3.75s/it]Epoch:   520
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0339, device='cuda:0') mean:  tensor(-3.3857e-05, device='cuda:0') min:  tensor(-0.1241, device='cuda:0') norm:  tensor(0.3427, device='cuda:0') MSE:  tensor(1.2864e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  520  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 52%|█████▏    | 520/1000 [33:26<29:39,  3.71s/it]Epoch:   521
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0347, device='cuda:0') mean:  tensor(-3.2580e-05, device='cuda:0') min:  tensor(-0.1106, device='cuda:0') norm:  tensor(0.3237, device='cuda:0') MSE:  tensor(1.2152e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  521  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2883, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 52%|█████▏    | 521/1000 [33:30<29:18,  3.67s/it]Epoch:   522
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0403, device='cuda:0') mean:  tensor(-3.6762e-05, device='cuda:0') min:  tensor(-0.1104, device='cuda:0') norm:  tensor(0.3564, device='cuda:0') MSE:  tensor(1.3377e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  522  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 52%|█████▏    | 522/1000 [33:34<29:56,  3.76s/it]Epoch:   523
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-3.3436e-05, device='cuda:0') min:  tensor(-0.1026, device='cuda:0') norm:  tensor(0.3264, device='cuda:0') MSE:  tensor(1.2253e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  523  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 52%|█████▏    | 523/1000 [33:38<30:07,  3.79s/it]Epoch:   524
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0426, device='cuda:0') mean:  tensor(-3.4052e-05, device='cuda:0') min:  tensor(-0.1215, device='cuda:0') norm:  tensor(0.3509, device='cuda:0') MSE:  tensor(1.3174e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  524  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  5
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 52%|█████▏    | 524/1000 [33:42<30:02,  3.79s/it]Epoch:   525
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0441, device='cuda:0') mean:  tensor(-3.0835e-05, device='cuda:0') min:  tensor(-0.1133, device='cuda:0') norm:  tensor(0.3304, device='cuda:0') MSE:  tensor(1.2402e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  525  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  5.890201144234053e-10 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  9
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2890, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 52%|█████▎    | 525/1000 [33:46<30:19,  3.83s/it]Epoch:   526
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0431, device='cuda:0') mean:  tensor(-3.6869e-05, device='cuda:0') min:  tensor(-0.1243, device='cuda:0') norm:  tensor(0.3663, device='cuda:0') MSE:  tensor(1.3750e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  526  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 53%|█████▎    | 526/1000 [33:49<30:15,  3.83s/it]Epoch:   527
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0389, device='cuda:0') mean:  tensor(-3.5584e-05, device='cuda:0') min:  tensor(-0.1180, device='cuda:0') norm:  tensor(0.3492, device='cuda:0') MSE:  tensor(1.3110e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  527  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  7
max of Lambda2 tensor(232.2894, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 53%|█████▎    | 527/1000 [33:53<30:21,  3.85s/it]Epoch:   528
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0337, device='cuda:0') mean:  tensor(-3.6344e-05, device='cuda:0') min:  tensor(-0.1070, device='cuda:0') norm:  tensor(0.3402, device='cuda:0') MSE:  tensor(1.2770e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  528  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(120.5649, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  17
 53%|█████▎    | 528/1000 [33:57<30:38,  3.90s/it]Epoch:   529
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0368, device='cuda:0') mean:  tensor(-3.3577e-05, device='cuda:0') min:  tensor(-0.1078, device='cuda:0') norm:  tensor(0.3273, device='cuda:0') MSE:  tensor(1.2288e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  529  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  17
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 53%|█████▎    | 529/1000 [34:01<30:44,  3.92s/it]Epoch:   530
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0396, device='cuda:0') mean:  tensor(-3.3931e-05, device='cuda:0') min:  tensor(-0.1224, device='cuda:0') norm:  tensor(0.3409, device='cuda:0') MSE:  tensor(1.2796e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  530  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9108, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 53%|█████▎    | 530/1000 [34:05<30:16,  3.87s/it]Epoch:   531
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0353, device='cuda:0') mean:  tensor(-3.3998e-05, device='cuda:0') min:  tensor(-0.1253, device='cuda:0') norm:  tensor(0.3439, device='cuda:0') MSE:  tensor(1.2909e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  531  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 53%|█████▎    | 531/1000 [34:09<30:21,  3.88s/it]Epoch:   532
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0355, device='cuda:0') mean:  tensor(-3.2862e-05, device='cuda:0') min:  tensor(-0.1013, device='cuda:0') norm:  tensor(0.3191, device='cuda:0') MSE:  tensor(1.1979e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  532  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  21
 53%|█████▎    | 532/1000 [34:13<29:39,  3.80s/it]Epoch:   533
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0454, device='cuda:0') mean:  tensor(-3.3713e-05, device='cuda:0') min:  tensor(-0.1152, device='cuda:0') norm:  tensor(0.3461, device='cuda:0') MSE:  tensor(1.2993e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  533  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  21
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 53%|█████▎    | 533/1000 [34:16<29:13,  3.75s/it]Epoch:   534
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0387, device='cuda:0') mean:  tensor(-3.0844e-05, device='cuda:0') min:  tensor(-0.1155, device='cuda:0') norm:  tensor(0.3181, device='cuda:0') MSE:  tensor(1.1942e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  534  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 53%|█████▎    | 534/1000 [34:20<29:22,  3.78s/it]Epoch:   535
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0398, device='cuda:0') mean:  tensor(-3.4482e-05, device='cuda:0') min:  tensor(-0.1140, device='cuda:0') norm:  tensor(0.3437, device='cuda:0') MSE:  tensor(1.2901e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  535  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 54%|█████▎    | 535/1000 [34:24<29:45,  3.84s/it]Epoch:   536
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0435, device='cuda:0') mean:  tensor(-3.6350e-05, device='cuda:0') min:  tensor(-0.1257, device='cuda:0') norm:  tensor(0.3609, device='cuda:0') MSE:  tensor(1.3549e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  536  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  16
max of Lambda2 tensor(232.2889, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 54%|█████▎    | 536/1000 [34:28<30:05,  3.89s/it]Epoch:   537
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0422, device='cuda:0') mean:  tensor(-3.3369e-05, device='cuda:0') min:  tensor(-0.1272, device='cuda:0') norm:  tensor(0.3549, device='cuda:0') MSE:  tensor(1.3322e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  537  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  9
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 54%|█████▎    | 537/1000 [34:32<30:25,  3.94s/it]Epoch:   538
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0325, device='cuda:0') mean:  tensor(-3.3935e-05, device='cuda:0') min:  tensor(-0.1038, device='cuda:0') norm:  tensor(0.3153, device='cuda:0') MSE:  tensor(1.1837e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  538  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9100, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
 54%|█████▍    | 538/1000 [34:36<30:06,  3.91s/it]Epoch:   539
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0375, device='cuda:0') mean:  tensor(-3.1745e-05, device='cuda:0') min:  tensor(-0.0999, device='cuda:0') norm:  tensor(0.3140, device='cuda:0') MSE:  tensor(1.1786e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  539  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  4
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 54%|█████▍    | 539/1000 [34:40<30:05,  3.92s/it]Epoch:   540
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0383, device='cuda:0') mean:  tensor(-3.1595e-05, device='cuda:0') min:  tensor(-0.1111, device='cuda:0') norm:  tensor(0.3207, device='cuda:0') MSE:  tensor(1.2037e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  540  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 54%|█████▍    | 540/1000 [34:44<30:15,  3.95s/it]Epoch:   541
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0344, device='cuda:0') mean:  tensor(-3.2115e-05, device='cuda:0') min:  tensor(-0.1128, device='cuda:0') norm:  tensor(0.3163, device='cuda:0') MSE:  tensor(1.1872e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  541  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 54%|█████▍    | 541/1000 [34:48<30:19,  3.96s/it]Epoch:   542
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0366, device='cuda:0') mean:  tensor(-3.4152e-05, device='cuda:0') min:  tensor(-0.1118, device='cuda:0') norm:  tensor(0.3357, device='cuda:0') MSE:  tensor(1.2600e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  542  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 54%|█████▍    | 542/1000 [34:52<30:08,  3.95s/it]Epoch:   543
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0410, device='cuda:0') mean:  tensor(-3.5089e-05, device='cuda:0') min:  tensor(-0.1112, device='cuda:0') norm:  tensor(0.3407, device='cuda:0') MSE:  tensor(1.2788e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  543  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 54%|█████▍    | 543/1000 [34:56<30:01,  3.94s/it]Epoch:   544
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0386, device='cuda:0') mean:  tensor(-3.3237e-05, device='cuda:0') min:  tensor(-0.1079, device='cuda:0') norm:  tensor(0.3317, device='cuda:0') MSE:  tensor(1.2453e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  544  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 54%|█████▍    | 544/1000 [35:00<29:40,  3.90s/it]Epoch:   545
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0398, device='cuda:0') mean:  tensor(-3.2938e-05, device='cuda:0') min:  tensor(-0.1194, device='cuda:0') norm:  tensor(0.3400, device='cuda:0') MSE:  tensor(1.2761e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  545  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 55%|█████▍    | 545/1000 [35:03<28:40,  3.78s/it]Epoch:   546
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0390, device='cuda:0') mean:  tensor(-3.4106e-05, device='cuda:0') min:  tensor(-0.1065, device='cuda:0') norm:  tensor(0.3315, device='cuda:0') MSE:  tensor(1.2443e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  546  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 55%|█████▍    | 546/1000 [35:07<28:32,  3.77s/it]Epoch:   547
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0364, device='cuda:0') mean:  tensor(-3.4594e-05, device='cuda:0') min:  tensor(-0.1057, device='cuda:0') norm:  tensor(0.3268, device='cuda:0') MSE:  tensor(1.2267e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  547  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 55%|█████▍    | 547/1000 [35:11<29:02,  3.85s/it]Epoch:   548
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0315, device='cuda:0') mean:  tensor(-3.6109e-05, device='cuda:0') min:  tensor(-0.1276, device='cuda:0') norm:  tensor(0.3561, device='cuda:0') MSE:  tensor(1.3365e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  548  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 55%|█████▍    | 548/1000 [35:15<29:00,  3.85s/it]Epoch:   549
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0382, device='cuda:0') mean:  tensor(-3.4368e-05, device='cuda:0') min:  tensor(-0.1177, device='cuda:0') norm:  tensor(0.3457, device='cuda:0') MSE:  tensor(1.2978e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  549  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  7
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9044, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 55%|█████▍    | 549/1000 [35:19<29:11,  3.88s/it]Epoch:   550
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0314, device='cuda:0') mean:  tensor(-3.3942e-05, device='cuda:0') min:  tensor(-0.1144, device='cuda:0') norm:  tensor(0.3267, device='cuda:0') MSE:  tensor(1.2263e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  550  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 55%|█████▌    | 550/1000 [35:23<29:21,  3.91s/it]Epoch:   551
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0382, device='cuda:0') mean:  tensor(-3.3972e-05, device='cuda:0') min:  tensor(-0.1117, device='cuda:0') norm:  tensor(0.3349, device='cuda:0') MSE:  tensor(1.2570e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  551  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 55%|█████▌    | 551/1000 [35:27<29:33,  3.95s/it]Epoch:   552
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0358, device='cuda:0') mean:  tensor(-3.1491e-05, device='cuda:0') min:  tensor(-0.1174, device='cuda:0') norm:  tensor(0.3277, device='cuda:0') MSE:  tensor(1.2302e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  552  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 55%|█████▌    | 552/1000 [35:31<29:25,  3.94s/it]Epoch:   553
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0404, device='cuda:0') mean:  tensor(-3.2548e-05, device='cuda:0') min:  tensor(-0.1193, device='cuda:0') norm:  tensor(0.3352, device='cuda:0') MSE:  tensor(1.2584e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  553  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 55%|█████▌    | 553/1000 [35:34<28:56,  3.89s/it]Epoch:   554
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0360, device='cuda:0') mean:  tensor(-3.1400e-05, device='cuda:0') min:  tensor(-0.1167, device='cuda:0') norm:  tensor(0.3246, device='cuda:0') MSE:  tensor(1.2185e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  554  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  6
max of Lambda2 tensor(232.2885, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 55%|█████▌    | 554/1000 [35:38<28:39,  3.85s/it]Epoch:   555
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0369, device='cuda:0') mean:  tensor(-3.3537e-05, device='cuda:0') min:  tensor(-0.1003, device='cuda:0') norm:  tensor(0.3227, device='cuda:0') MSE:  tensor(1.2114e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  555  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  6
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9003, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 56%|█████▌    | 555/1000 [35:42<28:45,  3.88s/it]Epoch:   556
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0328, device='cuda:0') mean:  tensor(-3.3259e-05, device='cuda:0') min:  tensor(-0.1096, device='cuda:0') norm:  tensor(0.3204, device='cuda:0') MSE:  tensor(1.2028e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  556  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 56%|█████▌    | 556/1000 [35:46<28:38,  3.87s/it]Epoch:   557
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0427, device='cuda:0') mean:  tensor(-3.4987e-05, device='cuda:0') min:  tensor(-0.1188, device='cuda:0') norm:  tensor(0.3503, device='cuda:0') MSE:  tensor(1.3150e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  557  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  16
max of Lambda2 tensor(232.2893, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 56%|█████▌    | 557/1000 [35:50<27:58,  3.79s/it]Epoch:   558
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0406, device='cuda:0') mean:  tensor(-3.4984e-05, device='cuda:0') min:  tensor(-0.1145, device='cuda:0') norm:  tensor(0.3461, device='cuda:0') MSE:  tensor(1.2993e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  558  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2892, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
 56%|█████▌    | 558/1000 [35:53<27:53,  3.79s/it]Epoch:   559
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0370, device='cuda:0') mean:  tensor(-3.6298e-05, device='cuda:0') min:  tensor(-0.1358, device='cuda:0') norm:  tensor(0.3701, device='cuda:0') MSE:  tensor(1.3893e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  559  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  4
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 56%|█████▌    | 559/1000 [35:57<28:02,  3.81s/it]Epoch:   560
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0332, device='cuda:0') mean:  tensor(-2.8595e-05, device='cuda:0') min:  tensor(-0.1109, device='cuda:0') norm:  tensor(0.3013, device='cuda:0') MSE:  tensor(1.1310e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  560  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 56%|█████▌    | 560/1000 [36:01<28:27,  3.88s/it]Epoch:   561
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0341, device='cuda:0') mean:  tensor(-3.3625e-05, device='cuda:0') min:  tensor(-0.1005, device='cuda:0') norm:  tensor(0.3209, device='cuda:0') MSE:  tensor(1.2047e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  561  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  0.0 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  9
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 56%|█████▌    | 561/1000 [36:05<28:26,  3.89s/it]Epoch:   562
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0401, device='cuda:0') mean:  tensor(-3.6484e-05, device='cuda:0') min:  tensor(-0.1253, device='cuda:0') norm:  tensor(0.3594, device='cuda:0') MSE:  tensor(1.3491e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  562  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2886, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 56%|█████▌    | 562/1000 [36:09<28:33,  3.91s/it]Epoch:   563
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0360, device='cuda:0') mean:  tensor(-3.6234e-05, device='cuda:0') min:  tensor(-0.1197, device='cuda:0') norm:  tensor(0.3513, device='cuda:0') MSE:  tensor(1.3187e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  563  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 56%|█████▋    | 563/1000 [36:13<27:58,  3.84s/it]Epoch:   564
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0372, device='cuda:0') mean:  tensor(-3.3886e-05, device='cuda:0') min:  tensor(-0.1103, device='cuda:0') norm:  tensor(0.3299, device='cuda:0') MSE:  tensor(1.2382e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  564  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 56%|█████▋    | 564/1000 [36:17<27:59,  3.85s/it]Epoch:   565
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0355, device='cuda:0') mean:  tensor(-3.3702e-05, device='cuda:0') min:  tensor(-0.1076, device='cuda:0') norm:  tensor(0.3245, device='cuda:0') MSE:  tensor(1.2180e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  565  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 56%|█████▋    | 565/1000 [36:21<28:23,  3.92s/it]Epoch:   566
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0354, device='cuda:0') mean:  tensor(-3.4402e-05, device='cuda:0') min:  tensor(-0.1107, device='cuda:0') norm:  tensor(0.3279, device='cuda:0') MSE:  tensor(1.2309e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  566  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  5
max of Lambda2 tensor(232.2895, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 57%|█████▋    | 566/1000 [36:25<28:28,  3.94s/it]Epoch:   567
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0288, device='cuda:0') mean:  tensor(-3.2384e-05, device='cuda:0') min:  tensor(-0.0954, device='cuda:0') norm:  tensor(0.3046, device='cuda:0') MSE:  tensor(1.1433e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  567  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 57%|█████▋    | 567/1000 [36:29<28:24,  3.94s/it]Epoch:   568
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-3.1452e-05, device='cuda:0') min:  tensor(-0.1084, device='cuda:0') norm:  tensor(0.3200, device='cuda:0') MSE:  tensor(1.2012e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  568  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 57%|█████▋    | 568/1000 [36:32<28:03,  3.90s/it]Epoch:   569
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0339, device='cuda:0') mean:  tensor(-3.1620e-05, device='cuda:0') min:  tensor(-0.1162, device='cuda:0') norm:  tensor(0.3240, device='cuda:0') MSE:  tensor(1.2161e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  569  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 57%|█████▋    | 569/1000 [36:36<27:50,  3.88s/it]Epoch:   570
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0390, device='cuda:0') mean:  tensor(-3.2512e-05, device='cuda:0') min:  tensor(-0.1040, device='cuda:0') norm:  tensor(0.3218, device='cuda:0') MSE:  tensor(1.2078e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  570  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 57%|█████▋    | 570/1000 [36:40<27:59,  3.91s/it]Epoch:   571
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0333, device='cuda:0') mean:  tensor(-3.2803e-05, device='cuda:0') min:  tensor(-0.1116, device='cuda:0') norm:  tensor(0.3180, device='cuda:0') MSE:  tensor(1.1935e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  571  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 57%|█████▋    | 571/1000 [36:44<27:50,  3.90s/it]Epoch:   572
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0345, device='cuda:0') mean:  tensor(-3.8690e-05, device='cuda:0') min:  tensor(-0.1165, device='cuda:0') norm:  tensor(0.3624, device='cuda:0') MSE:  tensor(1.3604e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  572  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 57%|█████▋    | 572/1000 [36:48<27:48,  3.90s/it]Epoch:   573
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0341, device='cuda:0') mean:  tensor(-3.4529e-05, device='cuda:0') min:  tensor(-0.1115, device='cuda:0') norm:  tensor(0.3285, device='cuda:0') MSE:  tensor(1.2332e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  573  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  6.969379981558661e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  7
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 57%|█████▋    | 573/1000 [36:52<27:50,  3.91s/it]Epoch:   574
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0379, device='cuda:0') mean:  tensor(-3.4409e-05, device='cuda:0') min:  tensor(-0.1235, device='cuda:0') norm:  tensor(0.3486, device='cuda:0') MSE:  tensor(1.3085e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  574  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  13
max of Lambda2 tensor(232.2880, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 57%|█████▋    | 574/1000 [36:56<27:57,  3.94s/it]Epoch:   575
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-3.6166e-05, device='cuda:0') min:  tensor(-0.1210, device='cuda:0') norm:  tensor(0.3502, device='cuda:0') MSE:  tensor(1.3145e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  575  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 57%|█████▊    | 575/1000 [37:00<28:12,  3.98s/it]Epoch:   576
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-3.4869e-05, device='cuda:0') min:  tensor(-0.1222, device='cuda:0') norm:  tensor(0.3475, device='cuda:0') MSE:  tensor(1.3043e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  576  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 58%|█████▊    | 576/1000 [37:04<27:12,  3.85s/it]Epoch:   577
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0382, device='cuda:0') mean:  tensor(-3.2414e-05, device='cuda:0') min:  tensor(-0.1013, device='cuda:0') norm:  tensor(0.3212, device='cuda:0') MSE:  tensor(1.2059e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  577  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 58%|█████▊    | 577/1000 [37:07<27:03,  3.84s/it]Epoch:   578
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0394, device='cuda:0') mean:  tensor(-3.4722e-05, device='cuda:0') min:  tensor(-0.1138, device='cuda:0') norm:  tensor(0.3379, device='cuda:0') MSE:  tensor(1.2683e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  578  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 58%|█████▊    | 578/1000 [37:11<27:09,  3.86s/it]Epoch:   579
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0370, device='cuda:0') mean:  tensor(-3.5885e-05, device='cuda:0') min:  tensor(-0.1069, device='cuda:0') norm:  tensor(0.3397, device='cuda:0') MSE:  tensor(1.2752e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  579  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  0.0 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  12
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 58%|█████▊    | 579/1000 [37:15<27:31,  3.92s/it]Epoch:   580
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0345, device='cuda:0') mean:  tensor(-3.3646e-05, device='cuda:0') min:  tensor(-0.1193, device='cuda:0') norm:  tensor(0.3379, device='cuda:0') MSE:  tensor(1.2683e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  580  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  15
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 58%|█████▊    | 580/1000 [37:19<27:22,  3.91s/it]Epoch:   581
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0405, device='cuda:0') mean:  tensor(-3.4229e-05, device='cuda:0') min:  tensor(-0.1326, device='cuda:0') norm:  tensor(0.3638, device='cuda:0') MSE:  tensor(1.3655e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  581  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 58%|█████▊    | 581/1000 [37:23<27:02,  3.87s/it]Epoch:   582
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0373, device='cuda:0') mean:  tensor(-3.1524e-05, device='cuda:0') min:  tensor(-0.1106, device='cuda:0') norm:  tensor(0.3230, device='cuda:0') MSE:  tensor(1.2125e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  582  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9017, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 58%|█████▊    | 582/1000 [37:27<26:56,  3.87s/it]Epoch:   583
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0374, device='cuda:0') mean:  tensor(-3.4386e-05, device='cuda:0') min:  tensor(-0.1158, device='cuda:0') norm:  tensor(0.3340, device='cuda:0') MSE:  tensor(1.2537e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  583  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 58%|█████▊    | 583/1000 [37:31<26:49,  3.86s/it]Epoch:   584
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0348, device='cuda:0') mean:  tensor(-3.3422e-05, device='cuda:0') min:  tensor(-0.1151, device='cuda:0') norm:  tensor(0.3307, device='cuda:0') MSE:  tensor(1.2415e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  584  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9092, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 58%|█████▊    | 584/1000 [37:35<27:07,  3.91s/it]Epoch:   585
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0387, device='cuda:0') mean:  tensor(-3.5790e-05, device='cuda:0') min:  tensor(-0.1128, device='cuda:0') norm:  tensor(0.3490, device='cuda:0') MSE:  tensor(1.3101e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  585  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  6.96937998155866e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  6
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2893, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 58%|█████▊    | 585/1000 [37:39<26:44,  3.87s/it]Epoch:   586
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-2.9890e-05, device='cuda:0') min:  tensor(-0.1022, device='cuda:0') norm:  tensor(0.2968, device='cuda:0') MSE:  tensor(1.1139e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  586  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 59%|█████▊    | 586/1000 [37:42<26:22,  3.82s/it]Epoch:   587
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0343, device='cuda:0') mean:  tensor(-3.3638e-05, device='cuda:0') min:  tensor(-0.1090, device='cuda:0') norm:  tensor(0.3247, device='cuda:0') MSE:  tensor(1.2189e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  587  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 59%|█████▊    | 587/1000 [37:46<26:31,  3.85s/it]Epoch:   588
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0404, device='cuda:0') mean:  tensor(-3.2739e-05, device='cuda:0') min:  tensor(-0.1147, device='cuda:0') norm:  tensor(0.3344, device='cuda:0') MSE:  tensor(1.2553e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  588  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 59%|█████▉    | 588/1000 [37:50<26:19,  3.83s/it]Epoch:   589
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0398, device='cuda:0') mean:  tensor(-3.5334e-05, device='cuda:0') min:  tensor(-0.1187, device='cuda:0') norm:  tensor(0.3483, device='cuda:0') MSE:  tensor(1.3074e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  589  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 59%|█████▉    | 589/1000 [37:54<26:08,  3.82s/it]Epoch:   590
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0391, device='cuda:0') mean:  tensor(-3.4932e-05, device='cuda:0') min:  tensor(-0.1299, device='cuda:0') norm:  tensor(0.3565, device='cuda:0') MSE:  tensor(1.3382e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  590  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 59%|█████▉    | 590/1000 [37:58<26:14,  3.84s/it]Epoch:   591
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0379, device='cuda:0') mean:  tensor(-3.3495e-05, device='cuda:0') min:  tensor(-0.1091, device='cuda:0') norm:  tensor(0.3299, device='cuda:0') MSE:  tensor(1.2384e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  591  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 59%|█████▉    | 591/1000 [38:02<26:18,  3.86s/it]Epoch:   592
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0395, device='cuda:0') mean:  tensor(-3.4295e-05, device='cuda:0') min:  tensor(-0.1191, device='cuda:0') norm:  tensor(0.3453, device='cuda:0') MSE:  tensor(1.2961e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  592  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  5
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  222
 59%|█████▉    | 592/1000 [38:06<26:45,  3.93s/it]Epoch:   593
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0434, device='cuda:0') mean:  tensor(-3.4190e-05, device='cuda:0') min:  tensor(-0.1250, device='cuda:0') norm:  tensor(0.3490, device='cuda:0') MSE:  tensor(1.3100e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  593  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  222
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 59%|█████▉    | 593/1000 [38:09<26:06,  3.85s/it]Epoch:   594
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0320, device='cuda:0') mean:  tensor(-3.4936e-05, device='cuda:0') min:  tensor(-0.1101, device='cuda:0') norm:  tensor(0.3336, device='cuda:0') MSE:  tensor(1.2522e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  594  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 59%|█████▉    | 594/1000 [38:13<26:21,  3.90s/it]Epoch:   595
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0351, device='cuda:0') mean:  tensor(-3.1930e-05, device='cuda:0') min:  tensor(-0.1094, device='cuda:0') norm:  tensor(0.3202, device='cuda:0') MSE:  tensor(1.2021e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  595  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 60%|█████▉    | 595/1000 [38:17<26:43,  3.96s/it]Epoch:   596
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0464, device='cuda:0') mean:  tensor(-3.7038e-05, device='cuda:0') min:  tensor(-0.1287, device='cuda:0') norm:  tensor(0.3754, device='cuda:0') MSE:  tensor(1.4092e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  596  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 60%|█████▉    | 596/1000 [38:21<26:23,  3.92s/it]Epoch:   597
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0368, device='cuda:0') mean:  tensor(-3.2656e-05, device='cuda:0') min:  tensor(-0.1039, device='cuda:0') norm:  tensor(0.3229, device='cuda:0') MSE:  tensor(1.2119e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  597  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  9
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 60%|█████▉    | 597/1000 [38:25<26:34,  3.96s/it]Epoch:   598
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0379, device='cuda:0') mean:  tensor(-3.4294e-05, device='cuda:0') min:  tensor(-0.1148, device='cuda:0') norm:  tensor(0.3420, device='cuda:0') MSE:  tensor(1.2839e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  598  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 60%|█████▉    | 598/1000 [38:29<26:35,  3.97s/it]Epoch:   599
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0300, device='cuda:0') mean:  tensor(-3.3993e-05, device='cuda:0') min:  tensor(-0.1018, device='cuda:0') norm:  tensor(0.3131, device='cuda:0') MSE:  tensor(1.1752e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  599  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 60%|█████▉    | 599/1000 [38:33<26:22,  3.95s/it]Epoch:   600
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0350, device='cuda:0') mean:  tensor(-3.4126e-05, device='cuda:0') min:  tensor(-0.1071, device='cuda:0') norm:  tensor(0.3321, device='cuda:0') MSE:  tensor(1.2465e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  600  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9011, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 60%|██████    | 600/1000 [38:37<26:24,  3.96s/it]Epoch:   601
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0403, device='cuda:0') mean:  tensor(-3.9348e-05, device='cuda:0') min:  tensor(-0.1163, device='cuda:0') norm:  tensor(0.3741, device='cuda:0') MSE:  tensor(1.4043e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  601  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 60%|██████    | 601/1000 [38:41<26:25,  3.97s/it]Epoch:   602
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0352, device='cuda:0') mean:  tensor(-3.3156e-05, device='cuda:0') min:  tensor(-0.1230, device='cuda:0') norm:  tensor(0.3339, device='cuda:0') MSE:  tensor(1.2534e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  602  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  12
max of Lambda2 tensor(232.2886, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 60%|██████    | 602/1000 [38:45<26:29,  3.99s/it]Epoch:   603
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0364, device='cuda:0') mean:  tensor(-3.4756e-05, device='cuda:0') min:  tensor(-0.1148, device='cuda:0') norm:  tensor(0.3384, device='cuda:0') MSE:  tensor(1.2702e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  603  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.0303717851638795e-05
Preserved_eigens number check:  5
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 60%|██████    | 603/1000 [38:49<26:08,  3.95s/it]Epoch:   604
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0420, device='cuda:0') mean:  tensor(-3.5385e-05, device='cuda:0') min:  tensor(-0.1257, device='cuda:0') norm:  tensor(0.3567, device='cuda:0') MSE:  tensor(1.3391e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  604  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  16
max of Lambda2 tensor(232.2887, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 60%|██████    | 604/1000 [38:53<25:42,  3.90s/it]Epoch:   605
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0467, device='cuda:0') mean:  tensor(-3.3488e-05, device='cuda:0') min:  tensor(-0.1073, device='cuda:0') norm:  tensor(0.3436, device='cuda:0') MSE:  tensor(1.2899e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  605  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 60%|██████    | 605/1000 [38:57<25:42,  3.90s/it]Epoch:   606
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0310, device='cuda:0') mean:  tensor(-3.4500e-05, device='cuda:0') min:  tensor(-0.1030, device='cuda:0') norm:  tensor(0.3225, device='cuda:0') MSE:  tensor(1.2107e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  606  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 61%|██████    | 606/1000 [39:01<25:54,  3.94s/it]Epoch:   607
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0335, device='cuda:0') mean:  tensor(-3.3439e-05, device='cuda:0') min:  tensor(-0.1021, device='cuda:0') norm:  tensor(0.3230, device='cuda:0') MSE:  tensor(1.2123e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  607  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
 61%|██████    | 607/1000 [39:05<25:51,  3.95s/it]Epoch:   608
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0412, device='cuda:0') mean:  tensor(-3.7139e-05, device='cuda:0') min:  tensor(-0.1271, device='cuda:0') norm:  tensor(0.3635, device='cuda:0') MSE:  tensor(1.3643e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  608  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  4
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 61%|██████    | 608/1000 [39:09<25:39,  3.93s/it]Epoch:   609
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0417, device='cuda:0') mean:  tensor(-3.4776e-05, device='cuda:0') min:  tensor(-0.1153, device='cuda:0') norm:  tensor(0.3505, device='cuda:0') MSE:  tensor(1.3159e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  609  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  9
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 61%|██████    | 609/1000 [39:12<25:00,  3.84s/it]Epoch:   610
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0348, device='cuda:0') mean:  tensor(-3.3152e-05, device='cuda:0') min:  tensor(-0.0999, device='cuda:0') norm:  tensor(0.3176, device='cuda:0') MSE:  tensor(1.1921e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  610  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.9042, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 61%|██████    | 610/1000 [39:16<25:03,  3.85s/it]Epoch:   611
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0373, device='cuda:0') mean:  tensor(-3.4551e-05, device='cuda:0') min:  tensor(-0.1076, device='cuda:0') norm:  tensor(0.3344, device='cuda:0') MSE:  tensor(1.2553e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  611  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2876, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 61%|██████    | 611/1000 [39:20<24:57,  3.85s/it]Epoch:   612
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-3.4505e-05, device='cuda:0') min:  tensor(-0.1228, device='cuda:0') norm:  tensor(0.3435, device='cuda:0') MSE:  tensor(1.2894e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  612  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 61%|██████    | 612/1000 [39:24<25:06,  3.88s/it]Epoch:   613
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0405, device='cuda:0') mean:  tensor(-3.1413e-05, device='cuda:0') min:  tensor(-0.1223, device='cuda:0') norm:  tensor(0.3373, device='cuda:0') MSE:  tensor(1.2661e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  613  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 61%|██████▏   | 613/1000 [39:28<24:57,  3.87s/it]Epoch:   614
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0430, device='cuda:0') mean:  tensor(-3.4052e-05, device='cuda:0') min:  tensor(-0.1169, device='cuda:0') norm:  tensor(0.3442, device='cuda:0') MSE:  tensor(1.2921e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  614  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 61%|██████▏   | 614/1000 [39:32<25:00,  3.89s/it]Epoch:   615
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0402, device='cuda:0') mean:  tensor(-3.6448e-05, device='cuda:0') min:  tensor(-0.1109, device='cuda:0') norm:  tensor(0.3505, device='cuda:0') MSE:  tensor(1.3157e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  615  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  0.0 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  9
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 62%|██████▏   | 615/1000 [39:35<24:41,  3.85s/it]Epoch:   616
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0402, device='cuda:0') mean:  tensor(-3.3819e-05, device='cuda:0') min:  tensor(-0.1285, device='cuda:0') norm:  tensor(0.3536, device='cuda:0') MSE:  tensor(1.3272e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  616  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 62%|██████▏   | 616/1000 [39:39<24:30,  3.83s/it]Epoch:   617
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0327, device='cuda:0') mean:  tensor(-3.3663e-05, device='cuda:0') min:  tensor(-0.1068, device='cuda:0') norm:  tensor(0.3275, device='cuda:0') MSE:  tensor(1.2295e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  617  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 62%|██████▏   | 617/1000 [39:43<24:51,  3.90s/it]Epoch:   618
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0410, device='cuda:0') mean:  tensor(-3.4036e-05, device='cuda:0') min:  tensor(-0.1146, device='cuda:0') norm:  tensor(0.3388, device='cuda:0') MSE:  tensor(1.2718e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  618  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 62%|██████▏   | 618/1000 [39:47<24:27,  3.84s/it]Epoch:   619
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-3.5715e-05, device='cuda:0') min:  tensor(-0.1078, device='cuda:0') norm:  tensor(0.3358, device='cuda:0') MSE:  tensor(1.2603e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  619  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9006, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 62%|██████▏   | 619/1000 [39:51<23:46,  3.74s/it]Epoch:   620
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0339, device='cuda:0') mean:  tensor(-3.2747e-05, device='cuda:0') min:  tensor(-0.1061, device='cuda:0') norm:  tensor(0.3208, device='cuda:0') MSE:  tensor(1.2041e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  620  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9111, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 62%|██████▏   | 620/1000 [39:54<23:08,  3.65s/it]Epoch:   621
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0375, device='cuda:0') mean:  tensor(-3.0529e-05, device='cuda:0') min:  tensor(-0.1088, device='cuda:0') norm:  tensor(0.3144, device='cuda:0') MSE:  tensor(1.1802e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  621  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  13
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2895, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 62%|██████▏   | 621/1000 [39:58<23:32,  3.73s/it]Epoch:   622
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0444, device='cuda:0') mean:  tensor(-3.3899e-05, device='cuda:0') min:  tensor(-0.1121, device='cuda:0') norm:  tensor(0.3494, device='cuda:0') MSE:  tensor(1.3116e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  622  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  10
max of Lambda2 tensor(232.2874, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 62%|██████▏   | 622/1000 [40:02<23:48,  3.78s/it]Epoch:   623
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0318, device='cuda:0') mean:  tensor(-3.5540e-05, device='cuda:0') min:  tensor(-0.1189, device='cuda:0') norm:  tensor(0.3465, device='cuda:0') MSE:  tensor(1.3006e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  623  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 62%|██████▏   | 623/1000 [40:06<24:10,  3.85s/it]Epoch:   624
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0360, device='cuda:0') mean:  tensor(-3.4813e-05, device='cuda:0') min:  tensor(-0.1181, device='cuda:0') norm:  tensor(0.3441, device='cuda:0') MSE:  tensor(1.2916e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  624  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 62%|██████▏   | 624/1000 [40:10<24:10,  3.86s/it]Epoch:   625
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0345, device='cuda:0') mean:  tensor(-3.2683e-05, device='cuda:0') min:  tensor(-0.1021, device='cuda:0') norm:  tensor(0.3160, device='cuda:0') MSE:  tensor(1.1860e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  625  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2887, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 62%|██████▎   | 625/1000 [40:14<24:06,  3.86s/it]Epoch:   626
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0307, device='cuda:0') mean:  tensor(-3.2233e-05, device='cuda:0') min:  tensor(-0.1081, device='cuda:0') norm:  tensor(0.3090, device='cuda:0') MSE:  tensor(1.1598e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  626  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9131, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 63%|██████▎   | 626/1000 [40:18<24:17,  3.90s/it]Epoch:   627
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0375, device='cuda:0') mean:  tensor(-3.5307e-05, device='cuda:0') min:  tensor(-0.1043, device='cuda:0') norm:  tensor(0.3344, device='cuda:0') MSE:  tensor(1.2553e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  627  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2892, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 63%|██████▎   | 627/1000 [40:21<23:53,  3.84s/it]Epoch:   628
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0396, device='cuda:0') mean:  tensor(-2.9628e-05, device='cuda:0') min:  tensor(-0.1033, device='cuda:0') norm:  tensor(0.3094, device='cuda:0') MSE:  tensor(1.1614e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  628  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 63%|██████▎   | 628/1000 [40:25<23:58,  3.87s/it]Epoch:   629
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0358, device='cuda:0') mean:  tensor(-3.3819e-05, device='cuda:0') min:  tensor(-0.1053, device='cuda:0') norm:  tensor(0.3233, device='cuda:0') MSE:  tensor(1.2137e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  629  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  15
max of Lambda2 tensor(607.9107, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 63%|██████▎   | 629/1000 [40:29<24:02,  3.89s/it]Epoch:   630
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0370, device='cuda:0') mean:  tensor(-3.3320e-05, device='cuda:0') min:  tensor(-0.1172, device='cuda:0') norm:  tensor(0.3311, device='cuda:0') MSE:  tensor(1.2427e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  630  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 63%|██████▎   | 630/1000 [40:33<23:49,  3.86s/it]Epoch:   631
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0352, device='cuda:0') mean:  tensor(-3.2147e-05, device='cuda:0') min:  tensor(-0.1041, device='cuda:0') norm:  tensor(0.3183, device='cuda:0') MSE:  tensor(1.1947e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  631  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 63%|██████▎   | 631/1000 [40:37<23:52,  3.88s/it]Epoch:   632
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0365, device='cuda:0') mean:  tensor(-3.2303e-05, device='cuda:0') min:  tensor(-0.1108, device='cuda:0') norm:  tensor(0.3199, device='cuda:0') MSE:  tensor(1.2008e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  632  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9014, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 63%|██████▎   | 632/1000 [40:41<23:30,  3.83s/it]Epoch:   633
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0397, device='cuda:0') mean:  tensor(-3.5223e-05, device='cuda:0') min:  tensor(-0.1173, device='cuda:0') norm:  tensor(0.3512, device='cuda:0') MSE:  tensor(1.3182e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  633  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.7252902984619143e-10 
thres:  1.030371878296137e-05
Preserved_eigens number check:  7
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 63%|██████▎   | 633/1000 [40:45<23:47,  3.89s/it]Epoch:   634
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0417, device='cuda:0') mean:  tensor(-3.1451e-05, device='cuda:0') min:  tensor(-0.1085, device='cuda:0') norm:  tensor(0.3297, device='cuda:0') MSE:  tensor(1.2377e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  634  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 63%|██████▎   | 634/1000 [40:48<23:40,  3.88s/it]Epoch:   635
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0414, device='cuda:0') mean:  tensor(-3.6337e-05, device='cuda:0') min:  tensor(-0.1300, device='cuda:0') norm:  tensor(0.3647, device='cuda:0') MSE:  tensor(1.3691e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  635  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 64%|██████▎   | 635/1000 [40:52<23:43,  3.90s/it]Epoch:   636
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0346, device='cuda:0') mean:  tensor(-2.9972e-05, device='cuda:0') min:  tensor(-0.1017, device='cuda:0') norm:  tensor(0.3002, device='cuda:0') MSE:  tensor(1.1270e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  636  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.9044, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 64%|██████▎   | 636/1000 [40:56<23:48,  3.92s/it]Epoch:   637
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0382, device='cuda:0') mean:  tensor(-3.1622e-05, device='cuda:0') min:  tensor(-0.1080, device='cuda:0') norm:  tensor(0.3186, device='cuda:0') MSE:  tensor(1.1960e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  637  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 64%|██████▎   | 637/1000 [41:00<23:21,  3.86s/it]Epoch:   638
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0391, device='cuda:0') mean:  tensor(-3.3764e-05, device='cuda:0') min:  tensor(-0.1110, device='cuda:0') norm:  tensor(0.3332, device='cuda:0') MSE:  tensor(1.2508e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  638  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 64%|██████▍   | 638/1000 [41:04<23:10,  3.84s/it]Epoch:   639
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0362, device='cuda:0') mean:  tensor(-3.4514e-05, device='cuda:0') min:  tensor(-0.1116, device='cuda:0') norm:  tensor(0.3364, device='cuda:0') MSE:  tensor(1.2628e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  639  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  15
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2880, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 64%|██████▍   | 639/1000 [41:08<23:23,  3.89s/it]Epoch:   640
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0448, device='cuda:0') mean:  tensor(-3.6259e-05, device='cuda:0') min:  tensor(-0.1295, device='cuda:0') norm:  tensor(0.3677, device='cuda:0') MSE:  tensor(1.3804e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  640  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 64%|██████▍   | 640/1000 [41:12<23:21,  3.89s/it]Epoch:   641
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0352, device='cuda:0') mean:  tensor(-3.4190e-05, device='cuda:0') min:  tensor(-0.1106, device='cuda:0') norm:  tensor(0.3283, device='cuda:0') MSE:  tensor(1.2323e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  641  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9108, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 64%|██████▍   | 641/1000 [41:16<23:23,  3.91s/it]Epoch:   642
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0305, device='cuda:0') mean:  tensor(-3.0481e-05, device='cuda:0') min:  tensor(-0.0987, device='cuda:0') norm:  tensor(0.2919, device='cuda:0') MSE:  tensor(1.0958e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  642  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 64%|██████▍   | 642/1000 [41:20<23:23,  3.92s/it]Epoch:   643
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0361, device='cuda:0') mean:  tensor(-3.4964e-05, device='cuda:0') min:  tensor(-0.1102, device='cuda:0') norm:  tensor(0.3392, device='cuda:0') MSE:  tensor(1.2733e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  643  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 64%|██████▍   | 643/1000 [41:23<23:04,  3.88s/it]Epoch:   644
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0367, device='cuda:0') mean:  tensor(-3.0762e-05, device='cuda:0') min:  tensor(-0.1096, device='cuda:0') norm:  tensor(0.3178, device='cuda:0') MSE:  tensor(1.1929e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  644  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  11
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 64%|██████▍   | 644/1000 [41:27<22:41,  3.82s/it]Epoch:   645
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-3.3445e-05, device='cuda:0') min:  tensor(-0.1191, device='cuda:0') norm:  tensor(0.3357, device='cuda:0') MSE:  tensor(1.2603e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  645  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 64%|██████▍   | 645/1000 [41:31<22:42,  3.84s/it]Epoch:   646
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-3.1795e-05, device='cuda:0') min:  tensor(-0.1050, device='cuda:0') norm:  tensor(0.3156, device='cuda:0') MSE:  tensor(1.1845e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  646  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 65%|██████▍   | 646/1000 [41:35<22:41,  3.85s/it]Epoch:   647
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0379, device='cuda:0') mean:  tensor(-3.3877e-05, device='cuda:0') min:  tensor(-0.1130, device='cuda:0') norm:  tensor(0.3355, device='cuda:0') MSE:  tensor(1.2594e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  647  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  13
max of Lambda2 tensor(607.9138, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 65%|██████▍   | 647/1000 [41:39<22:37,  3.84s/it]Epoch:   648
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-3.4793e-05, device='cuda:0') min:  tensor(-0.1271, device='cuda:0') norm:  tensor(0.3485, device='cuda:0') MSE:  tensor(1.3083e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  648  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 65%|██████▍   | 648/1000 [41:43<22:29,  3.83s/it]Epoch:   649
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0334, device='cuda:0') mean:  tensor(-3.1949e-05, device='cuda:0') min:  tensor(-0.1082, device='cuda:0') norm:  tensor(0.3155, device='cuda:0') MSE:  tensor(1.1843e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  649  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2893, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 65%|██████▍   | 649/1000 [41:46<21:54,  3.75s/it]Epoch:   650
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0322, device='cuda:0') mean:  tensor(-3.2794e-05, device='cuda:0') min:  tensor(-0.0964, device='cuda:0') norm:  tensor(0.3097, device='cuda:0') MSE:  tensor(1.1626e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  650  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 65%|██████▌   | 650/1000 [41:50<22:19,  3.83s/it]Epoch:   651
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0360, device='cuda:0') mean:  tensor(-3.1360e-05, device='cuda:0') min:  tensor(-0.1066, device='cuda:0') norm:  tensor(0.3102, device='cuda:0') MSE:  tensor(1.1645e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  651  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 65%|██████▌   | 651/1000 [41:54<22:09,  3.81s/it]Epoch:   652
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0425, device='cuda:0') mean:  tensor(-3.1646e-05, device='cuda:0') min:  tensor(-0.1198, device='cuda:0') norm:  tensor(0.3327, device='cuda:0') MSE:  tensor(1.2489e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  652  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2892, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
 65%|██████▌   | 652/1000 [41:58<22:16,  3.84s/it]Epoch:   653
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0379, device='cuda:0') mean:  tensor(-3.3184e-05, device='cuda:0') min:  tensor(-0.1222, device='cuda:0') norm:  tensor(0.3379, device='cuda:0') MSE:  tensor(1.2685e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  653  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  4
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 65%|██████▌   | 653/1000 [42:02<22:24,  3.87s/it]Epoch:   654
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0385, device='cuda:0') mean:  tensor(-3.2017e-05, device='cuda:0') min:  tensor(-0.1253, device='cuda:0') norm:  tensor(0.3393, device='cuda:0') MSE:  tensor(1.2736e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  654  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 65%|██████▌   | 654/1000 [42:05<22:10,  3.85s/it]Epoch:   655
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0328, device='cuda:0') mean:  tensor(-3.1982e-05, device='cuda:0') min:  tensor(-0.1087, device='cuda:0') norm:  tensor(0.3143, device='cuda:0') MSE:  tensor(1.1797e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  655  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2901, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 66%|██████▌   | 655/1000 [42:09<21:43,  3.78s/it]Epoch:   656
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-3.4667e-05, device='cuda:0') min:  tensor(-0.1012, device='cuda:0') norm:  tensor(0.3216, device='cuda:0') MSE:  tensor(1.2074e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  656  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 66%|██████▌   | 656/1000 [42:13<22:11,  3.87s/it]Epoch:   657
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0416, device='cuda:0') mean:  tensor(-3.4031e-05, device='cuda:0') min:  tensor(-0.1068, device='cuda:0') norm:  tensor(0.3362, device='cuda:0') MSE:  tensor(1.2620e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  657  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  5.890201144234053e-10 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9005, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 66%|██████▌   | 657/1000 [42:17<22:21,  3.91s/it]Epoch:   658
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-3.3993e-05, device='cuda:0') min:  tensor(-0.1100, device='cuda:0') norm:  tensor(0.3321, device='cuda:0') MSE:  tensor(1.2468e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  658  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 66%|██████▌   | 658/1000 [42:21<22:03,  3.87s/it]Epoch:   659
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0352, device='cuda:0') mean:  tensor(-3.3047e-05, device='cuda:0') min:  tensor(-0.1072, device='cuda:0') norm:  tensor(0.3239, device='cuda:0') MSE:  tensor(1.2157e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  659  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 66%|██████▌   | 659/1000 [42:25<21:36,  3.80s/it]Epoch:   660
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0389, device='cuda:0') mean:  tensor(-3.4272e-05, device='cuda:0') min:  tensor(-0.1185, device='cuda:0') norm:  tensor(0.3423, device='cuda:0') MSE:  tensor(1.2849e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  660  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  6
max of Lambda2 tensor(607.9055, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 66%|██████▌   | 660/1000 [42:29<21:44,  3.84s/it]Epoch:   661
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0420, device='cuda:0') mean:  tensor(-3.5305e-05, device='cuda:0') min:  tensor(-0.1255, device='cuda:0') norm:  tensor(0.3531, device='cuda:0') MSE:  tensor(1.3256e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  661  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.8967, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 66%|██████▌   | 661/1000 [42:33<22:03,  3.90s/it]Epoch:   662
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0348, device='cuda:0') mean:  tensor(-3.0879e-05, device='cuda:0') min:  tensor(-0.1026, device='cuda:0') norm:  tensor(0.3094, device='cuda:0') MSE:  tensor(1.1613e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  662  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 66%|██████▌   | 662/1000 [42:36<21:52,  3.88s/it]Epoch:   663
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0349, device='cuda:0') mean:  tensor(-3.3330e-05, device='cuda:0') min:  tensor(-0.1037, device='cuda:0') norm:  tensor(0.3171, device='cuda:0') MSE:  tensor(1.1903e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  663  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  3.7252902984619143e-10 
thres:  1.030371878296137e-05
Preserved_eigens number check:  6
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2876, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 66%|██████▋   | 663/1000 [42:40<21:38,  3.85s/it]Epoch:   664
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0331, device='cuda:0') mean:  tensor(-3.2986e-05, device='cuda:0') min:  tensor(-0.0975, device='cuda:0') norm:  tensor(0.3151, device='cuda:0') MSE:  tensor(1.1828e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  664  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  6
max of Lambda2 tensor(232.2897, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  30
 66%|██████▋   | 664/1000 [42:44<21:38,  3.87s/it]Epoch:   665
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0352, device='cuda:0') mean:  tensor(-3.3294e-05, device='cuda:0') min:  tensor(-0.1225, device='cuda:0') norm:  tensor(0.3444, device='cuda:0') MSE:  tensor(1.2927e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  665  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  30
max of Lambda2 tensor(607.9119, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 66%|██████▋   | 665/1000 [42:48<21:59,  3.94s/it]Epoch:   666
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0391, device='cuda:0') mean:  tensor(-3.6251e-05, device='cuda:0') min:  tensor(-0.1130, device='cuda:0') norm:  tensor(0.3495, device='cuda:0') MSE:  tensor(1.3120e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  666  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  11
max of Lambda2 tensor(607.9006, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 67%|██████▋   | 666/1000 [42:52<21:43,  3.90s/it]Epoch:   667
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-2.9754e-05, device='cuda:0') min:  tensor(-0.1132, device='cuda:0') norm:  tensor(0.3102, device='cuda:0') MSE:  tensor(1.1644e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  667  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 67%|██████▋   | 667/1000 [42:56<21:02,  3.79s/it]Epoch:   668
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0374, device='cuda:0') mean:  tensor(-3.5819e-05, device='cuda:0') min:  tensor(-0.1189, device='cuda:0') norm:  tensor(0.3491, device='cuda:0') MSE:  tensor(1.3106e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  668  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 67%|██████▋   | 668/1000 [42:59<21:02,  3.80s/it]Epoch:   669
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0374, device='cuda:0') mean:  tensor(-3.1291e-05, device='cuda:0') min:  tensor(-0.1096, device='cuda:0') norm:  tensor(0.3184, device='cuda:0') MSE:  tensor(1.1951e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  669  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  11
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2584, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 67%|██████▋   | 669/1000 [43:03<21:23,  3.88s/it]Epoch:   670
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0368, device='cuda:0') mean:  tensor(-3.4565e-05, device='cuda:0') min:  tensor(-0.1134, device='cuda:0') norm:  tensor(0.3333, device='cuda:0') MSE:  tensor(1.2511e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  670  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 67%|██████▋   | 670/1000 [43:08<21:43,  3.95s/it]Epoch:   671
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0412, device='cuda:0') mean:  tensor(-3.2330e-05, device='cuda:0') min:  tensor(-0.1103, device='cuda:0') norm:  tensor(0.3248, device='cuda:0') MSE:  tensor(1.2194e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  671  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 67%|██████▋   | 671/1000 [43:12<21:46,  3.97s/it]Epoch:   672
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0396, device='cuda:0') mean:  tensor(-3.3049e-05, device='cuda:0') min:  tensor(-0.1105, device='cuda:0') norm:  tensor(0.3284, device='cuda:0') MSE:  tensor(1.2327e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  672  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9006, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 67%|██████▋   | 672/1000 [43:15<21:04,  3.86s/it]Epoch:   673
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-3.2583e-05, device='cuda:0') min:  tensor(-0.1001, device='cuda:0') norm:  tensor(0.3188, device='cuda:0') MSE:  tensor(1.1967e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  673  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 67%|██████▋   | 673/1000 [43:19<21:19,  3.91s/it]Epoch:   674
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0370, device='cuda:0') mean:  tensor(-3.3663e-05, device='cuda:0') min:  tensor(-0.1017, device='cuda:0') norm:  tensor(0.3236, device='cuda:0') MSE:  tensor(1.2146e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  674  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  6
max of Lambda2 tensor(607.9149, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 67%|██████▋   | 674/1000 [43:23<21:25,  3.94s/it]Epoch:   675
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0404, device='cuda:0') mean:  tensor(-3.4455e-05, device='cuda:0') min:  tensor(-0.1224, device='cuda:0') norm:  tensor(0.3504, device='cuda:0') MSE:  tensor(1.3152e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  675  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  9
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 68%|██████▊   | 675/1000 [43:27<21:33,  3.98s/it]Epoch:   676
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0323, device='cuda:0') mean:  tensor(-3.3220e-05, device='cuda:0') min:  tensor(-0.1129, device='cuda:0') norm:  tensor(0.3273, device='cuda:0') MSE:  tensor(1.2287e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  676  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 68%|██████▊   | 676/1000 [43:31<21:19,  3.95s/it]Epoch:   677
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0375, device='cuda:0') mean:  tensor(-3.3896e-05, device='cuda:0') min:  tensor(-0.1071, device='cuda:0') norm:  tensor(0.3318, device='cuda:0') MSE:  tensor(1.2457e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  677  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(232.2901, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 68%|██████▊   | 677/1000 [43:35<20:43,  3.85s/it]Epoch:   678
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0334, device='cuda:0') mean:  tensor(-3.0838e-05, device='cuda:0') min:  tensor(-0.1070, device='cuda:0') norm:  tensor(0.3128, device='cuda:0') MSE:  tensor(1.1741e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  678  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  19
 68%|██████▊   | 678/1000 [43:38<20:24,  3.80s/it]Epoch:   679
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0292, device='cuda:0') mean:  tensor(-3.1818e-05, device='cuda:0') min:  tensor(-0.0972, device='cuda:0') norm:  tensor(0.3044, device='cuda:0') MSE:  tensor(1.1426e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  679  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  19
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 68%|██████▊   | 679/1000 [43:42<20:37,  3.85s/it]Epoch:   680
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0346, device='cuda:0') mean:  tensor(-3.5610e-05, device='cuda:0') min:  tensor(-0.1110, device='cuda:0') norm:  tensor(0.3380, device='cuda:0') MSE:  tensor(1.2686e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  680  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(232.2885, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 68%|██████▊   | 680/1000 [43:46<20:40,  3.88s/it]Epoch:   681
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0339, device='cuda:0') mean:  tensor(-3.3385e-05, device='cuda:0') min:  tensor(-0.1123, device='cuda:0') norm:  tensor(0.3223, device='cuda:0') MSE:  tensor(1.2098e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  681  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.7252902984619143e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 68%|██████▊   | 681/1000 [43:50<20:50,  3.92s/it]Epoch:   682
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0312, device='cuda:0') mean:  tensor(-3.3253e-05, device='cuda:0') min:  tensor(-0.1212, device='cuda:0') norm:  tensor(0.3425, device='cuda:0') MSE:  tensor(1.2858e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  682  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 68%|██████▊   | 682/1000 [43:54<20:24,  3.85s/it]Epoch:   683
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0397, device='cuda:0') mean:  tensor(-3.4727e-05, device='cuda:0') min:  tensor(-0.1116, device='cuda:0') norm:  tensor(0.3425, device='cuda:0') MSE:  tensor(1.2855e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  683  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  14
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 68%|██████▊   | 683/1000 [43:58<20:26,  3.87s/it]Epoch:   684
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0372, device='cuda:0') mean:  tensor(-3.4297e-05, device='cuda:0') min:  tensor(-0.1221, device='cuda:0') norm:  tensor(0.3398, device='cuda:0') MSE:  tensor(1.2755e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  684  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  3
 68%|██████▊   | 684/1000 [44:02<20:38,  3.92s/it]Epoch:   685
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0329, device='cuda:0') mean:  tensor(-3.2775e-05, device='cuda:0') min:  tensor(-0.1301, device='cuda:0') norm:  tensor(0.3502, device='cuda:0') MSE:  tensor(1.3147e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  685  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  3
max of Lambda2 tensor(232.2897, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  3
 68%|██████▊   | 685/1000 [44:06<20:42,  3.95s/it]Epoch:   686
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0311, device='cuda:0') mean:  tensor(-3.1852e-05, device='cuda:0') min:  tensor(-0.1082, device='cuda:0') norm:  tensor(0.3147, device='cuda:0') MSE:  tensor(1.1811e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  686  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  3
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 69%|██████▊   | 686/1000 [44:10<20:09,  3.85s/it]Epoch:   687
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-3.5567e-05, device='cuda:0') min:  tensor(-0.1072, device='cuda:0') norm:  tensor(0.3381, device='cuda:0') MSE:  tensor(1.2692e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  687  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  5.890201144234053e-10 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 69%|██████▊   | 687/1000 [44:14<20:12,  3.87s/it]Epoch:   688
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0357, device='cuda:0') mean:  tensor(-3.2653e-05, device='cuda:0') min:  tensor(-0.1222, device='cuda:0') norm:  tensor(0.3343, device='cuda:0') MSE:  tensor(1.2547e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  688  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2891, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 69%|██████▉   | 688/1000 [44:17<20:07,  3.87s/it]Epoch:   689
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0401, device='cuda:0') mean:  tensor(-3.4558e-05, device='cuda:0') min:  tensor(-0.1087, device='cuda:0') norm:  tensor(0.3377, device='cuda:0') MSE:  tensor(1.2675e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  689  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
 69%|██████▉   | 689/1000 [44:21<19:42,  3.80s/it]Epoch:   690
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0392, device='cuda:0') mean:  tensor(-3.6092e-05, device='cuda:0') min:  tensor(-0.1241, device='cuda:0') norm:  tensor(0.3546, device='cuda:0') MSE:  tensor(1.3310e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  690  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  4
max of Lambda2 tensor(607.9119, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 69%|██████▉   | 690/1000 [44:25<19:54,  3.85s/it]Epoch:   691
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0405, device='cuda:0') mean:  tensor(-3.3938e-05, device='cuda:0') min:  tensor(-0.1170, device='cuda:0') norm:  tensor(0.3395, device='cuda:0') MSE:  tensor(1.2743e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  691  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(232.2887, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 69%|██████▉   | 691/1000 [44:29<19:18,  3.75s/it]Epoch:   692
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0332, device='cuda:0') mean:  tensor(-3.4782e-05, device='cuda:0') min:  tensor(-0.1149, device='cuda:0') norm:  tensor(0.3383, device='cuda:0') MSE:  tensor(1.2698e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  692  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 69%|██████▉   | 692/1000 [44:32<19:26,  3.79s/it]Epoch:   693
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0384, device='cuda:0') mean:  tensor(-3.5932e-05, device='cuda:0') min:  tensor(-0.1087, device='cuda:0') norm:  tensor(0.3448, device='cuda:0') MSE:  tensor(1.2942e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  693  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  13
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2884, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 69%|██████▉   | 693/1000 [44:36<19:42,  3.85s/it]Epoch:   694
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0344, device='cuda:0') mean:  tensor(-3.8271e-05, device='cuda:0') min:  tensor(-0.1107, device='cuda:0') norm:  tensor(0.3514, device='cuda:0') MSE:  tensor(1.3192e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  694  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  6
max of Lambda2 tensor(232.2883, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 69%|██████▉   | 694/1000 [44:40<19:50,  3.89s/it]Epoch:   695
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0313, device='cuda:0') mean:  tensor(-3.1923e-05, device='cuda:0') min:  tensor(-0.1123, device='cuda:0') norm:  tensor(0.3141, device='cuda:0') MSE:  tensor(1.1792e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  695  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9075, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 70%|██████▉   | 695/1000 [44:44<19:33,  3.85s/it]Epoch:   696
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0361, device='cuda:0') mean:  tensor(-3.4167e-05, device='cuda:0') min:  tensor(-0.1154, device='cuda:0') norm:  tensor(0.3370, device='cuda:0') MSE:  tensor(1.2651e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  696  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(232.2877, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 70%|██████▉   | 696/1000 [44:48<19:40,  3.88s/it]Epoch:   697
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0422, device='cuda:0') mean:  tensor(-3.5990e-05, device='cuda:0') min:  tensor(-0.1252, device='cuda:0') norm:  tensor(0.3650, device='cuda:0') MSE:  tensor(1.3700e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  697  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 70%|██████▉   | 697/1000 [44:52<19:23,  3.84s/it]Epoch:   698
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0407, device='cuda:0') mean:  tensor(-3.4467e-05, device='cuda:0') min:  tensor(-0.1195, device='cuda:0') norm:  tensor(0.3471, device='cuda:0') MSE:  tensor(1.3029e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  698  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 70%|██████▉   | 698/1000 [44:56<19:21,  3.85s/it]Epoch:   699
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0435, device='cuda:0') mean:  tensor(-3.7753e-05, device='cuda:0') min:  tensor(-0.1283, device='cuda:0') norm:  tensor(0.3757, device='cuda:0') MSE:  tensor(1.4102e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  699  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  0.0 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 70%|██████▉   | 699/1000 [44:59<18:50,  3.76s/it]Epoch:   700
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0404, device='cuda:0') mean:  tensor(-3.4435e-05, device='cuda:0') min:  tensor(-0.1135, device='cuda:0') norm:  tensor(0.3423, device='cuda:0') MSE:  tensor(1.2848e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  700  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  14
max of Lambda2 tensor(232.2891, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 70%|███████   | 700/1000 [45:03<19:06,  3.82s/it]Epoch:   701
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0344, device='cuda:0') mean:  tensor(-3.5065e-05, device='cuda:0') min:  tensor(-0.1034, device='cuda:0') norm:  tensor(0.3344, device='cuda:0') MSE:  tensor(1.2552e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  701  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 70%|███████   | 701/1000 [45:07<18:58,  3.81s/it]Epoch:   702
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0375, device='cuda:0') mean:  tensor(-3.3656e-05, device='cuda:0') min:  tensor(-0.1140, device='cuda:0') norm:  tensor(0.3385, device='cuda:0') MSE:  tensor(1.2707e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  702  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 70%|███████   | 702/1000 [45:11<18:58,  3.82s/it]Epoch:   703
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0413, device='cuda:0') mean:  tensor(-3.1422e-05, device='cuda:0') min:  tensor(-0.1187, device='cuda:0') norm:  tensor(0.3386, device='cuda:0') MSE:  tensor(1.2711e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  703  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9131, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 70%|███████   | 703/1000 [45:14<18:27,  3.73s/it]Epoch:   704
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0357, device='cuda:0') mean:  tensor(-3.0394e-05, device='cuda:0') min:  tensor(-0.1227, device='cuda:0') norm:  tensor(0.3311, device='cuda:0') MSE:  tensor(1.2428e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  704  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9124, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 70%|███████   | 704/1000 [45:18<18:21,  3.72s/it]Epoch:   705
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-3.2613e-05, device='cuda:0') min:  tensor(-0.1024, device='cuda:0') norm:  tensor(0.3127, device='cuda:0') MSE:  tensor(1.1739e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  705  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  0.0 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 70%|███████   | 705/1000 [45:22<18:31,  3.77s/it]Epoch:   706
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0404, device='cuda:0') mean:  tensor(-3.2100e-05, device='cuda:0') min:  tensor(-0.1217, device='cuda:0') norm:  tensor(0.3421, device='cuda:0') MSE:  tensor(1.2843e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  706  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 71%|███████   | 706/1000 [45:26<18:27,  3.77s/it]Epoch:   707
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0392, device='cuda:0') mean:  tensor(-3.3297e-05, device='cuda:0') min:  tensor(-0.1015, device='cuda:0') norm:  tensor(0.3222, device='cuda:0') MSE:  tensor(1.2094e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  707  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 71%|███████   | 707/1000 [45:30<18:33,  3.80s/it]Epoch:   708
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0354, device='cuda:0') mean:  tensor(-3.6314e-05, device='cuda:0') min:  tensor(-0.1158, device='cuda:0') norm:  tensor(0.3443, device='cuda:0') MSE:  tensor(1.2924e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  708  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 71%|███████   | 708/1000 [45:33<18:30,  3.80s/it]Epoch:   709
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0335, device='cuda:0') mean:  tensor(-2.9560e-05, device='cuda:0') min:  tensor(-0.1037, device='cuda:0') norm:  tensor(0.2951, device='cuda:0') MSE:  tensor(1.1077e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  709  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 71%|███████   | 709/1000 [45:38<18:52,  3.89s/it]Epoch:   710
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0423, device='cuda:0') mean:  tensor(-3.1590e-05, device='cuda:0') min:  tensor(-0.1241, device='cuda:0') norm:  tensor(0.3412, device='cuda:0') MSE:  tensor(1.2809e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  710  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 71%|███████   | 710/1000 [45:42<18:55,  3.91s/it]Epoch:   711
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-3.3754e-05, device='cuda:0') min:  tensor(-0.1118, device='cuda:0') norm:  tensor(0.3284, device='cuda:0') MSE:  tensor(1.2326e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  711  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  9
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 71%|███████   | 711/1000 [45:46<19:02,  3.95s/it]Epoch:   712
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-3.2642e-05, device='cuda:0') min:  tensor(-0.1176, device='cuda:0') norm:  tensor(0.3400, device='cuda:0') MSE:  tensor(1.2762e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  712  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9113, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 71%|███████   | 712/1000 [45:49<18:52,  3.93s/it]Epoch:   713
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0357, device='cuda:0') mean:  tensor(-3.4385e-05, device='cuda:0') min:  tensor(-0.1095, device='cuda:0') norm:  tensor(0.3255, device='cuda:0') MSE:  tensor(1.2219e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  713  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 71%|███████▏  | 713/1000 [45:53<18:41,  3.91s/it]Epoch:   714
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0382, device='cuda:0') mean:  tensor(-3.5704e-05, device='cuda:0') min:  tensor(-0.1094, device='cuda:0') norm:  tensor(0.3468, device='cuda:0') MSE:  tensor(1.3019e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  714  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.9092, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 71%|███████▏  | 714/1000 [45:57<18:39,  3.91s/it]Epoch:   715
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0373, device='cuda:0') mean:  tensor(-2.9944e-05, device='cuda:0') min:  tensor(-0.1039, device='cuda:0') norm:  tensor(0.3079, device='cuda:0') MSE:  tensor(1.1556e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  715  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 72%|███████▏  | 715/1000 [46:01<18:24,  3.87s/it]Epoch:   716
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0334, device='cuda:0') mean:  tensor(-3.1473e-05, device='cuda:0') min:  tensor(-0.1105, device='cuda:0') norm:  tensor(0.3177, device='cuda:0') MSE:  tensor(1.1927e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  716  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  14
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 72%|███████▏  | 716/1000 [46:05<18:06,  3.82s/it]Epoch:   717
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0283, device='cuda:0') mean:  tensor(-3.1215e-05, device='cuda:0') min:  tensor(-0.1031, device='cuda:0') norm:  tensor(0.3048, device='cuda:0') MSE:  tensor(1.1440e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  717  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 72%|███████▏  | 717/1000 [46:09<18:20,  3.89s/it]Epoch:   718
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0387, device='cuda:0') mean:  tensor(-2.9544e-05, device='cuda:0') min:  tensor(-0.1073, device='cuda:0') norm:  tensor(0.3108, device='cuda:0') MSE:  tensor(1.1667e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  718  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 72%|███████▏  | 718/1000 [46:13<18:17,  3.89s/it]Epoch:   719
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0404, device='cuda:0') mean:  tensor(-3.3373e-05, device='cuda:0') min:  tensor(-0.1270, device='cuda:0') norm:  tensor(0.3492, device='cuda:0') MSE:  tensor(1.3108e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  719  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9113, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 72%|███████▏  | 719/1000 [46:16<18:06,  3.87s/it]Epoch:   720
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0315, device='cuda:0') mean:  tensor(-3.2103e-05, device='cuda:0') min:  tensor(-0.0944, device='cuda:0') norm:  tensor(0.3034, device='cuda:0') MSE:  tensor(1.1390e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  720  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2894, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 72%|███████▏  | 720/1000 [46:20<17:59,  3.85s/it]Epoch:   721
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0321, device='cuda:0') mean:  tensor(-3.1226e-05, device='cuda:0') min:  tensor(-0.1029, device='cuda:0') norm:  tensor(0.3037, device='cuda:0') MSE:  tensor(1.1401e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  721  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 72%|███████▏  | 721/1000 [46:24<17:57,  3.86s/it]Epoch:   722
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0385, device='cuda:0') mean:  tensor(-3.1151e-05, device='cuda:0') min:  tensor(-0.1208, device='cuda:0') norm:  tensor(0.3319, device='cuda:0') MSE:  tensor(1.2460e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  722  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 72%|███████▏  | 722/1000 [46:28<17:44,  3.83s/it]Epoch:   723
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0369, device='cuda:0') mean:  tensor(-3.5922e-05, device='cuda:0') min:  tensor(-0.1122, device='cuda:0') norm:  tensor(0.3423, device='cuda:0') MSE:  tensor(1.2851e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  723  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  6.96937998155866e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  14
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2876, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 72%|███████▏  | 723/1000 [46:32<17:41,  3.83s/it]Epoch:   724
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0329, device='cuda:0') mean:  tensor(-3.4627e-05, device='cuda:0') min:  tensor(-0.1025, device='cuda:0') norm:  tensor(0.3315, device='cuda:0') MSE:  tensor(1.2445e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  724  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  6
max of Lambda2 tensor(232.2886, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
 72%|███████▏  | 724/1000 [46:36<17:46,  3.87s/it]Epoch:   725
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0350, device='cuda:0') mean:  tensor(-3.4644e-05, device='cuda:0') min:  tensor(-0.1248, device='cuda:0') norm:  tensor(0.3509, device='cuda:0') MSE:  tensor(1.3171e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  725  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  4
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 72%|███████▎  | 725/1000 [46:40<17:38,  3.85s/it]Epoch:   726
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-3.1731e-05, device='cuda:0') min:  tensor(-0.1109, device='cuda:0') norm:  tensor(0.3156, device='cuda:0') MSE:  tensor(1.1846e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  726  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 73%|███████▎  | 726/1000 [46:43<17:40,  3.87s/it]Epoch:   727
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0359, device='cuda:0') mean:  tensor(-3.3902e-05, device='cuda:0') min:  tensor(-0.1088, device='cuda:0') norm:  tensor(0.3287, device='cuda:0') MSE:  tensor(1.2340e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  727  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 73%|███████▎  | 727/1000 [46:47<17:42,  3.89s/it]Epoch:   728
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-3.4687e-05, device='cuda:0') min:  tensor(-0.1069, device='cuda:0') norm:  tensor(0.3289, device='cuda:0') MSE:  tensor(1.2345e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  728  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 73%|███████▎  | 728/1000 [46:51<17:42,  3.91s/it]Epoch:   729
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0345, device='cuda:0') mean:  tensor(-3.3660e-05, device='cuda:0') min:  tensor(-0.1082, device='cuda:0') norm:  tensor(0.3259, device='cuda:0') MSE:  tensor(1.2235e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  729  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 73%|███████▎  | 729/1000 [46:55<17:48,  3.94s/it]Epoch:   730
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-3.5499e-05, device='cuda:0') min:  tensor(-0.1182, device='cuda:0') norm:  tensor(0.3468, device='cuda:0') MSE:  tensor(1.3019e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  730  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 73%|███████▎  | 730/1000 [46:59<17:28,  3.88s/it]Epoch:   731
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0358, device='cuda:0') mean:  tensor(-3.5473e-05, device='cuda:0') min:  tensor(-0.1245, device='cuda:0') norm:  tensor(0.3555, device='cuda:0') MSE:  tensor(1.3343e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  731  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 73%|███████▎  | 731/1000 [47:03<17:18,  3.86s/it]Epoch:   732
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0367, device='cuda:0') mean:  tensor(-3.6847e-05, device='cuda:0') min:  tensor(-0.1264, device='cuda:0') norm:  tensor(0.3603, device='cuda:0') MSE:  tensor(1.3523e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  732  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 73%|███████▎  | 732/1000 [47:07<17:21,  3.89s/it]Epoch:   733
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0417, device='cuda:0') mean:  tensor(-3.2789e-05, device='cuda:0') min:  tensor(-0.1127, device='cuda:0') norm:  tensor(0.3334, device='cuda:0') MSE:  tensor(1.2515e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  733  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 73%|███████▎  | 733/1000 [47:11<17:26,  3.92s/it]Epoch:   734
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0421, device='cuda:0') mean:  tensor(-3.4208e-05, device='cuda:0') min:  tensor(-0.1310, device='cuda:0') norm:  tensor(0.3570, device='cuda:0') MSE:  tensor(1.3402e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  734  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9097, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 73%|███████▎  | 734/1000 [47:15<17:19,  3.91s/it]Epoch:   735
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0337, device='cuda:0') mean:  tensor(-3.2538e-05, device='cuda:0') min:  tensor(-0.1148, device='cuda:0') norm:  tensor(0.3265, device='cuda:0') MSE:  tensor(1.2254e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  735  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  7
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 74%|███████▎  | 735/1000 [47:19<17:13,  3.90s/it]Epoch:   736
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0394, device='cuda:0') mean:  tensor(-3.6039e-05, device='cuda:0') min:  tensor(-0.1148, device='cuda:0') norm:  tensor(0.3479, device='cuda:0') MSE:  tensor(1.3058e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  736  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2898, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 74%|███████▎  | 736/1000 [47:22<17:06,  3.89s/it]Epoch:   737
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0352, device='cuda:0') mean:  tensor(-3.4516e-05, device='cuda:0') min:  tensor(-0.1122, device='cuda:0') norm:  tensor(0.3281, device='cuda:0') MSE:  tensor(1.2317e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  737  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 74%|███████▎  | 737/1000 [47:26<17:11,  3.92s/it]Epoch:   738
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0321, device='cuda:0') mean:  tensor(-3.3265e-05, device='cuda:0') min:  tensor(-0.1068, device='cuda:0') norm:  tensor(0.3201, device='cuda:0') MSE:  tensor(1.2014e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  738  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 74%|███████▍  | 738/1000 [47:30<17:00,  3.89s/it]Epoch:   739
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0350, device='cuda:0') mean:  tensor(-3.4179e-05, device='cuda:0') min:  tensor(-0.1110, device='cuda:0') norm:  tensor(0.3262, device='cuda:0') MSE:  tensor(1.2246e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  739  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 74%|███████▍  | 739/1000 [47:34<17:05,  3.93s/it]Epoch:   740
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0339, device='cuda:0') mean:  tensor(-3.6109e-05, device='cuda:0') min:  tensor(-0.1066, device='cuda:0') norm:  tensor(0.3391, device='cuda:0') MSE:  tensor(1.2728e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  740  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2877, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 74%|███████▍  | 740/1000 [47:38<16:48,  3.88s/it]Epoch:   741
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0418, device='cuda:0') mean:  tensor(-3.5886e-05, device='cuda:0') min:  tensor(-0.1169, device='cuda:0') norm:  tensor(0.3537, device='cuda:0') MSE:  tensor(1.3276e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  741  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  5.890201144234053e-10 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  5
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2884, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 74%|███████▍  | 741/1000 [47:42<16:56,  3.93s/it]Epoch:   742
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0383, device='cuda:0') mean:  tensor(-3.1292e-05, device='cuda:0') min:  tensor(-0.1213, device='cuda:0') norm:  tensor(0.3241, device='cuda:0') MSE:  tensor(1.2165e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  742  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  6
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 74%|███████▍  | 742/1000 [47:46<16:13,  3.77s/it]Epoch:   743
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-3.6110e-05, device='cuda:0') min:  tensor(-0.1163, device='cuda:0') norm:  tensor(0.3499, device='cuda:0') MSE:  tensor(1.3135e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  743  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 74%|███████▍  | 743/1000 [47:49<16:19,  3.81s/it]Epoch:   744
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0349, device='cuda:0') mean:  tensor(-3.2011e-05, device='cuda:0') min:  tensor(-0.1025, device='cuda:0') norm:  tensor(0.3105, device='cuda:0') MSE:  tensor(1.1657e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  744  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9112, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 74%|███████▍  | 744/1000 [47:53<16:31,  3.87s/it]Epoch:   745
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0369, device='cuda:0') mean:  tensor(-3.5105e-05, device='cuda:0') min:  tensor(-0.1198, device='cuda:0') norm:  tensor(0.3443, device='cuda:0') MSE:  tensor(1.2923e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  745  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 74%|███████▍  | 745/1000 [47:57<16:21,  3.85s/it]Epoch:   746
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0331, device='cuda:0') mean:  tensor(-3.2756e-05, device='cuda:0') min:  tensor(-0.1044, device='cuda:0') norm:  tensor(0.3159, device='cuda:0') MSE:  tensor(1.1858e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  746  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(232.2883, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 75%|███████▍  | 746/1000 [48:01<16:09,  3.82s/it]Epoch:   747
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0402, device='cuda:0') mean:  tensor(-3.2588e-05, device='cuda:0') min:  tensor(-0.1277, device='cuda:0') norm:  tensor(0.3411, device='cuda:0') MSE:  tensor(1.2804e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  747  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 75%|███████▍  | 747/1000 [48:05<16:05,  3.82s/it]Epoch:   748
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0341, device='cuda:0') mean:  tensor(-3.1328e-05, device='cuda:0') min:  tensor(-0.1002, device='cuda:0') norm:  tensor(0.3105, device='cuda:0') MSE:  tensor(1.1657e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  748  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  7
max of Lambda2 tensor(232.2881, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 75%|███████▍  | 748/1000 [48:09<16:12,  3.86s/it]Epoch:   749
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0346, device='cuda:0') mean:  tensor(-3.5418e-05, device='cuda:0') min:  tensor(-0.1070, device='cuda:0') norm:  tensor(0.3391, device='cuda:0') MSE:  tensor(1.2730e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  749  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  6
max of Lambda2 tensor(232.2898, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 75%|███████▍  | 749/1000 [48:13<16:17,  3.89s/it]Epoch:   750
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-3.1485e-05, device='cuda:0') min:  tensor(-0.1152, device='cuda:0') norm:  tensor(0.3200, device='cuda:0') MSE:  tensor(1.2013e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  750  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 75%|███████▌  | 750/1000 [48:17<16:05,  3.86s/it]Epoch:   751
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0366, device='cuda:0') mean:  tensor(-3.4604e-05, device='cuda:0') min:  tensor(-0.1132, device='cuda:0') norm:  tensor(0.3392, device='cuda:0') MSE:  tensor(1.2733e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  751  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 75%|███████▌  | 751/1000 [48:21<16:15,  3.92s/it]Epoch:   752
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0352, device='cuda:0') mean:  tensor(-3.3858e-05, device='cuda:0') min:  tensor(-0.1063, device='cuda:0') norm:  tensor(0.3245, device='cuda:0') MSE:  tensor(1.2182e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  752  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 75%|███████▌  | 752/1000 [48:24<16:08,  3.90s/it]Epoch:   753
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0382, device='cuda:0') mean:  tensor(-3.6437e-05, device='cuda:0') min:  tensor(-0.1113, device='cuda:0') norm:  tensor(0.3448, device='cuda:0') MSE:  tensor(1.2943e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  753  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  11
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 75%|███████▌  | 753/1000 [48:28<16:10,  3.93s/it]Epoch:   754
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0370, device='cuda:0') mean:  tensor(-3.1193e-05, device='cuda:0') min:  tensor(-0.1032, device='cuda:0') norm:  tensor(0.3066, device='cuda:0') MSE:  tensor(1.1510e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  754  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 75%|███████▌  | 754/1000 [48:32<16:10,  3.94s/it]Epoch:   755
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-3.3782e-05, device='cuda:0') min:  tensor(-0.1170, device='cuda:0') norm:  tensor(0.3318, device='cuda:0') MSE:  tensor(1.2457e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  755  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 76%|███████▌  | 755/1000 [48:36<16:09,  3.96s/it]Epoch:   756
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0383, device='cuda:0') mean:  tensor(-3.7233e-05, device='cuda:0') min:  tensor(-0.1131, device='cuda:0') norm:  tensor(0.3543, device='cuda:0') MSE:  tensor(1.3301e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  756  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 76%|███████▌  | 756/1000 [48:40<15:59,  3.93s/it]Epoch:   757
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0357, device='cuda:0') mean:  tensor(-3.2949e-05, device='cuda:0') min:  tensor(-0.1149, device='cuda:0') norm:  tensor(0.3284, device='cuda:0') MSE:  tensor(1.2327e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  757  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 76%|███████▌  | 757/1000 [48:44<15:44,  3.89s/it]Epoch:   758
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0329, device='cuda:0') mean:  tensor(-3.1219e-05, device='cuda:0') min:  tensor(-0.1093, device='cuda:0') norm:  tensor(0.3100, device='cuda:0') MSE:  tensor(1.1636e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  758  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 76%|███████▌  | 758/1000 [48:48<15:37,  3.88s/it]Epoch:   759
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0407, device='cuda:0') mean:  tensor(-3.5464e-05, device='cuda:0') min:  tensor(-0.1154, device='cuda:0') norm:  tensor(0.3521, device='cuda:0') MSE:  tensor(1.3217e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  759  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  9
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 76%|███████▌  | 759/1000 [48:52<15:40,  3.90s/it]Epoch:   760
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0380, device='cuda:0') mean:  tensor(-3.4366e-05, device='cuda:0') min:  tensor(-0.1246, device='cuda:0') norm:  tensor(0.3489, device='cuda:0') MSE:  tensor(1.3096e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  760  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 76%|███████▌  | 760/1000 [48:56<15:40,  3.92s/it]Epoch:   761
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0418, device='cuda:0') mean:  tensor(-3.8789e-05, device='cuda:0') min:  tensor(-0.1184, device='cuda:0') norm:  tensor(0.3752, device='cuda:0') MSE:  tensor(1.4085e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  761  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 76%|███████▌  | 761/1000 [48:59<15:02,  3.78s/it]Epoch:   762
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0313, device='cuda:0') mean:  tensor(-3.3578e-05, device='cuda:0') min:  tensor(-0.1026, device='cuda:0') norm:  tensor(0.3141, device='cuda:0') MSE:  tensor(1.1790e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  762  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 76%|███████▌  | 762/1000 [49:03<15:05,  3.81s/it]Epoch:   763
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0347, device='cuda:0') mean:  tensor(-3.3977e-05, device='cuda:0') min:  tensor(-0.1029, device='cuda:0') norm:  tensor(0.3247, device='cuda:0') MSE:  tensor(1.2190e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  763  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 76%|███████▋  | 763/1000 [49:07<14:54,  3.77s/it]Epoch:   764
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0345, device='cuda:0') mean:  tensor(-3.4028e-05, device='cuda:0') min:  tensor(-0.1086, device='cuda:0') norm:  tensor(0.3266, device='cuda:0') MSE:  tensor(1.2261e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  764  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 76%|███████▋  | 764/1000 [49:11<15:02,  3.82s/it]Epoch:   765
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0395, device='cuda:0') mean:  tensor(-3.5997e-05, device='cuda:0') min:  tensor(-0.1145, device='cuda:0') norm:  tensor(0.3520, device='cuda:0') MSE:  tensor(1.3212e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  765  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.0303717851638795e-05
Preserved_eigens number check:  7
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 76%|███████▋  | 765/1000 [49:15<14:54,  3.81s/it]Epoch:   766
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0411, device='cuda:0') mean:  tensor(-3.5036e-05, device='cuda:0') min:  tensor(-0.1113, device='cuda:0') norm:  tensor(0.3425, device='cuda:0') MSE:  tensor(1.2857e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  766  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 77%|███████▋  | 766/1000 [49:18<14:45,  3.78s/it]Epoch:   767
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0360, device='cuda:0') mean:  tensor(-3.7497e-05, device='cuda:0') min:  tensor(-0.1220, device='cuda:0') norm:  tensor(0.3565, device='cuda:0') MSE:  tensor(1.3382e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  767  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.9018, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 77%|███████▋  | 767/1000 [49:22<14:38,  3.77s/it]Epoch:   768
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0319, device='cuda:0') mean:  tensor(-3.1555e-05, device='cuda:0') min:  tensor(-0.1160, device='cuda:0') norm:  tensor(0.3215, device='cuda:0') MSE:  tensor(1.2067e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  768  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 77%|███████▋  | 768/1000 [49:25<13:50,  3.58s/it]Epoch:   769
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0368, device='cuda:0') mean:  tensor(-3.1640e-05, device='cuda:0') min:  tensor(-0.1159, device='cuda:0') norm:  tensor(0.3249, device='cuda:0') MSE:  tensor(1.2195e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  769  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 77%|███████▋  | 769/1000 [49:29<13:59,  3.63s/it]Epoch:   770
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0396, device='cuda:0') mean:  tensor(-3.5544e-05, device='cuda:0') min:  tensor(-0.1212, device='cuda:0') norm:  tensor(0.3472, device='cuda:0') MSE:  tensor(1.3034e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  770  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 77%|███████▋  | 770/1000 [49:32<13:35,  3.55s/it]Epoch:   771
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0425, device='cuda:0') mean:  tensor(-3.5397e-05, device='cuda:0') min:  tensor(-0.1223, device='cuda:0') norm:  tensor(0.3568, device='cuda:0') MSE:  tensor(1.3395e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  771  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  5.890201144234053e-10 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  6
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9150, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 77%|███████▋  | 771/1000 [49:36<13:58,  3.66s/it]Epoch:   772
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0383, device='cuda:0') mean:  tensor(-3.3386e-05, device='cuda:0') min:  tensor(-0.1241, device='cuda:0') norm:  tensor(0.3555, device='cuda:0') MSE:  tensor(1.3345e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  772  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9114, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 77%|███████▋  | 772/1000 [49:40<14:05,  3.71s/it]Epoch:   773
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0436, device='cuda:0') mean:  tensor(-3.4697e-05, device='cuda:0') min:  tensor(-0.1165, device='cuda:0') norm:  tensor(0.3458, device='cuda:0') MSE:  tensor(1.2979e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  773  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 77%|███████▋  | 773/1000 [49:44<14:21,  3.80s/it]Epoch:   774
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0305, device='cuda:0') mean:  tensor(-3.3834e-05, device='cuda:0') min:  tensor(-0.1042, device='cuda:0') norm:  tensor(0.3173, device='cuda:0') MSE:  tensor(1.1912e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  774  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 77%|███████▋  | 774/1000 [49:48<14:12,  3.77s/it]Epoch:   775
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0392, device='cuda:0') mean:  tensor(-3.3215e-05, device='cuda:0') min:  tensor(-0.1204, device='cuda:0') norm:  tensor(0.3394, device='cuda:0') MSE:  tensor(1.2740e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  775  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2891, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 78%|███████▊  | 775/1000 [49:51<14:09,  3.77s/it]Epoch:   776
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0400, device='cuda:0') mean:  tensor(-3.4612e-05, device='cuda:0') min:  tensor(-0.1293, device='cuda:0') norm:  tensor(0.3597, device='cuda:0') MSE:  tensor(1.3504e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  776  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(232.2901, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 78%|███████▊  | 776/1000 [49:56<14:27,  3.87s/it]Epoch:   777
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0340, device='cuda:0') mean:  tensor(-3.5908e-05, device='cuda:0') min:  tensor(-0.1068, device='cuda:0') norm:  tensor(0.3349, device='cuda:0') MSE:  tensor(1.2573e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  777  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  18
 78%|███████▊  | 777/1000 [49:59<14:07,  3.80s/it]Epoch:   778
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0366, device='cuda:0') mean:  tensor(-3.1580e-05, device='cuda:0') min:  tensor(-0.1039, device='cuda:0') norm:  tensor(0.3106, device='cuda:0') MSE:  tensor(1.1660e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  778  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  18
max of Lambda2 tensor(607.8986, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 78%|███████▊  | 778/1000 [50:03<14:10,  3.83s/it]Epoch:   779
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0369, device='cuda:0') mean:  tensor(-3.4176e-05, device='cuda:0') min:  tensor(-0.1092, device='cuda:0') norm:  tensor(0.3406, device='cuda:0') MSE:  tensor(1.2786e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  779  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 78%|███████▊  | 779/1000 [50:07<13:50,  3.76s/it]Epoch:   780
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0411, device='cuda:0') mean:  tensor(-3.2550e-05, device='cuda:0') min:  tensor(-0.1118, device='cuda:0') norm:  tensor(0.3298, device='cuda:0') MSE:  tensor(1.2378e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  780  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 78%|███████▊  | 780/1000 [50:11<13:52,  3.79s/it]Epoch:   781
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0358, device='cuda:0') mean:  tensor(-3.6199e-05, device='cuda:0') min:  tensor(-0.1103, device='cuda:0') norm:  tensor(0.3404, device='cuda:0') MSE:  tensor(1.2776e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  781  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 78%|███████▊  | 781/1000 [50:15<14:00,  3.84s/it]Epoch:   782
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-3.4336e-05, device='cuda:0') min:  tensor(-0.1258, device='cuda:0') norm:  tensor(0.3465, device='cuda:0') MSE:  tensor(1.3005e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  782  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 78%|███████▊  | 782/1000 [50:19<14:12,  3.91s/it]Epoch:   783
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0425, device='cuda:0') mean:  tensor(-3.7978e-05, device='cuda:0') min:  tensor(-0.1315, device='cuda:0') norm:  tensor(0.3798, device='cuda:0') MSE:  tensor(1.4256e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  783  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  5
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 78%|███████▊  | 783/1000 [50:22<13:52,  3.84s/it]Epoch:   784
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0373, device='cuda:0') mean:  tensor(-3.2124e-05, device='cuda:0') min:  tensor(-0.1167, device='cuda:0') norm:  tensor(0.3284, device='cuda:0') MSE:  tensor(1.2329e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  784  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 78%|███████▊  | 784/1000 [50:26<13:57,  3.88s/it]Epoch:   785
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0361, device='cuda:0') mean:  tensor(-3.1370e-05, device='cuda:0') min:  tensor(-0.1095, device='cuda:0') norm:  tensor(0.3135, device='cuda:0') MSE:  tensor(1.1769e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  785  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
 78%|███████▊  | 785/1000 [50:30<14:00,  3.91s/it]Epoch:   786
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0391, device='cuda:0') mean:  tensor(-3.4144e-05, device='cuda:0') min:  tensor(-0.1089, device='cuda:0') norm:  tensor(0.3328, device='cuda:0') MSE:  tensor(1.2493e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  786  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  4
max of Lambda2 tensor(232.2896, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 79%|███████▊  | 786/1000 [50:34<13:46,  3.86s/it]Epoch:   787
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0372, device='cuda:0') mean:  tensor(-3.2554e-05, device='cuda:0') min:  tensor(-0.1101, device='cuda:0') norm:  tensor(0.3221, device='cuda:0') MSE:  tensor(1.2091e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  787  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9121, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 79%|███████▊  | 787/1000 [50:38<13:53,  3.91s/it]Epoch:   788
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0402, device='cuda:0') mean:  tensor(-3.5433e-05, device='cuda:0') min:  tensor(-0.1255, device='cuda:0') norm:  tensor(0.3587, device='cuda:0') MSE:  tensor(1.3464e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  788  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9005, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 79%|███████▉  | 788/1000 [50:42<13:33,  3.84s/it]Epoch:   789
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0392, device='cuda:0') mean:  tensor(-3.3646e-05, device='cuda:0') min:  tensor(-0.1107, device='cuda:0') norm:  tensor(0.3324, device='cuda:0') MSE:  tensor(1.2478e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  789  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 79%|███████▉  | 789/1000 [50:45<13:22,  3.80s/it]Epoch:   790
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0355, device='cuda:0') mean:  tensor(-3.3150e-05, device='cuda:0') min:  tensor(-0.1070, device='cuda:0') norm:  tensor(0.3186, device='cuda:0') MSE:  tensor(1.1959e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  790  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 79%|███████▉  | 790/1000 [50:49<13:22,  3.82s/it]Epoch:   791
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0367, device='cuda:0') mean:  tensor(-3.3004e-05, device='cuda:0') min:  tensor(-0.1122, device='cuda:0') norm:  tensor(0.3276, device='cuda:0') MSE:  tensor(1.2296e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  791  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 79%|███████▉  | 791/1000 [50:53<13:28,  3.87s/it]Epoch:   792
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0347, device='cuda:0') mean:  tensor(-3.4430e-05, device='cuda:0') min:  tensor(-0.1208, device='cuda:0') norm:  tensor(0.3416, device='cuda:0') MSE:  tensor(1.2822e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  792  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 79%|███████▉  | 792/1000 [50:57<13:37,  3.93s/it]Epoch:   793
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0370, device='cuda:0') mean:  tensor(-3.4595e-05, device='cuda:0') min:  tensor(-0.1164, device='cuda:0') norm:  tensor(0.3403, device='cuda:0') MSE:  tensor(1.2776e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  793  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 79%|███████▉  | 793/1000 [51:01<13:35,  3.94s/it]Epoch:   794
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0362, device='cuda:0') mean:  tensor(-3.4606e-05, device='cuda:0') min:  tensor(-0.1053, device='cuda:0') norm:  tensor(0.3294, device='cuda:0') MSE:  tensor(1.2366e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  794  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 79%|███████▉  | 794/1000 [51:05<13:20,  3.89s/it]Epoch:   795
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-3.2050e-05, device='cuda:0') min:  tensor(-0.1055, device='cuda:0') norm:  tensor(0.3228, device='cuda:0') MSE:  tensor(1.2116e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  795  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  0.0 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9119, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 80%|███████▉  | 795/1000 [51:09<13:11,  3.86s/it]Epoch:   796
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0370, device='cuda:0') mean:  tensor(-3.2647e-05, device='cuda:0') min:  tensor(-0.1053, device='cuda:0') norm:  tensor(0.3206, device='cuda:0') MSE:  tensor(1.2036e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  796  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 80%|███████▉  | 796/1000 [51:13<13:18,  3.92s/it]Epoch:   797
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0344, device='cuda:0') mean:  tensor(-3.2836e-05, device='cuda:0') min:  tensor(-0.1050, device='cuda:0') norm:  tensor(0.3195, device='cuda:0') MSE:  tensor(1.1991e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  797  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 80%|███████▉  | 797/1000 [51:16<12:41,  3.75s/it]Epoch:   798
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0373, device='cuda:0') mean:  tensor(-3.7228e-05, device='cuda:0') min:  tensor(-0.1156, device='cuda:0') norm:  tensor(0.3530, device='cuda:0') MSE:  tensor(1.3251e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  798  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2888, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 80%|███████▉  | 798/1000 [51:20<12:35,  3.74s/it]Epoch:   799
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0386, device='cuda:0') mean:  tensor(-3.1082e-05, device='cuda:0') min:  tensor(-0.1001, device='cuda:0') norm:  tensor(0.3133, device='cuda:0') MSE:  tensor(1.1762e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  799  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 80%|███████▉  | 799/1000 [51:24<12:43,  3.80s/it]Epoch:   800
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0344, device='cuda:0') mean:  tensor(-3.5871e-05, device='cuda:0') min:  tensor(-0.1097, device='cuda:0') norm:  tensor(0.3393, device='cuda:0') MSE:  tensor(1.2736e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  800  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 80%|████████  | 800/1000 [51:28<12:40,  3.80s/it]Epoch:   801
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0364, device='cuda:0') mean:  tensor(-3.3081e-05, device='cuda:0') min:  tensor(-0.1125, device='cuda:0') norm:  tensor(0.3327, device='cuda:0') MSE:  tensor(1.2487e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  801  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  13
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 80%|████████  | 801/1000 [51:32<12:47,  3.86s/it]Epoch:   802
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0354, device='cuda:0') mean:  tensor(-3.1669e-05, device='cuda:0') min:  tensor(-0.1142, device='cuda:0') norm:  tensor(0.3218, device='cuda:0') MSE:  tensor(1.2080e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  802  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 80%|████████  | 802/1000 [51:36<12:49,  3.89s/it]Epoch:   803
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0367, device='cuda:0') mean:  tensor(-3.0688e-05, device='cuda:0') min:  tensor(-0.1128, device='cuda:0') norm:  tensor(0.3185, device='cuda:0') MSE:  tensor(1.1955e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  803  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  5
max of Lambda2 tensor(232.2878, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 80%|████████  | 803/1000 [51:40<12:50,  3.91s/it]Epoch:   804
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0343, device='cuda:0') mean:  tensor(-3.6224e-05, device='cuda:0') min:  tensor(-0.1194, device='cuda:0') norm:  tensor(0.3464, device='cuda:0') MSE:  tensor(1.3002e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  804  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 80%|████████  | 804/1000 [51:43<12:38,  3.87s/it]Epoch:   805
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0401, device='cuda:0') mean:  tensor(-3.4932e-05, device='cuda:0') min:  tensor(-0.1260, device='cuda:0') norm:  tensor(0.3581, device='cuda:0') MSE:  tensor(1.3441e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  805  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  15
max of Lambda2 tensor(232.2887, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 80%|████████  | 805/1000 [51:47<12:41,  3.90s/it]Epoch:   806
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0383, device='cuda:0') mean:  tensor(-3.5611e-05, device='cuda:0') min:  tensor(-0.1192, device='cuda:0') norm:  tensor(0.3528, device='cuda:0') MSE:  tensor(1.3243e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  806  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 81%|████████  | 806/1000 [51:51<12:33,  3.89s/it]Epoch:   807
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0350, device='cuda:0') mean:  tensor(-3.3208e-05, device='cuda:0') min:  tensor(-0.1094, device='cuda:0') norm:  tensor(0.3243, device='cuda:0') MSE:  tensor(1.2173e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  807  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  6.969379981558661e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  7
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 81%|████████  | 807/1000 [51:55<12:40,  3.94s/it]Epoch:   808
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0379, device='cuda:0') mean:  tensor(-3.4284e-05, device='cuda:0') min:  tensor(-0.1142, device='cuda:0') norm:  tensor(0.3321, device='cuda:0') MSE:  tensor(1.2466e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  808  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  5
max of Lambda2 tensor(232.2881, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 81%|████████  | 808/1000 [51:59<12:27,  3.89s/it]Epoch:   809
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0356, device='cuda:0') mean:  tensor(-3.3582e-05, device='cuda:0') min:  tensor(-0.0993, device='cuda:0') norm:  tensor(0.3172, device='cuda:0') MSE:  tensor(1.1905e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  809  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 81%|████████  | 809/1000 [52:03<12:15,  3.85s/it]Epoch:   810
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0380, device='cuda:0') mean:  tensor(-3.1499e-05, device='cuda:0') min:  tensor(-0.1164, device='cuda:0') norm:  tensor(0.3284, device='cuda:0') MSE:  tensor(1.2328e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  810  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 81%|████████  | 810/1000 [52:07<12:24,  3.92s/it]Epoch:   811
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0413, device='cuda:0') mean:  tensor(-3.4102e-05, device='cuda:0') min:  tensor(-0.1129, device='cuda:0') norm:  tensor(0.3425, device='cuda:0') MSE:  tensor(1.2857e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  811  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 81%|████████  | 811/1000 [52:11<12:13,  3.88s/it]Epoch:   812
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0382, device='cuda:0') mean:  tensor(-3.5577e-05, device='cuda:0') min:  tensor(-0.1124, device='cuda:0') norm:  tensor(0.3388, device='cuda:0') MSE:  tensor(1.2718e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  812  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 81%|████████  | 812/1000 [52:14<12:01,  3.84s/it]Epoch:   813
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0355, device='cuda:0') mean:  tensor(-3.4610e-05, device='cuda:0') min:  tensor(-0.1007, device='cuda:0') norm:  tensor(0.3277, device='cuda:0') MSE:  tensor(1.2300e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  813  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  6.969379981558661e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  12
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 81%|████████▏ | 813/1000 [52:18<12:06,  3.88s/it]Epoch:   814
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0380, device='cuda:0') mean:  tensor(-3.5469e-05, device='cuda:0') min:  tensor(-0.1116, device='cuda:0') norm:  tensor(0.3389, device='cuda:0') MSE:  tensor(1.2720e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  814  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 81%|████████▏ | 814/1000 [52:22<12:10,  3.93s/it]Epoch:   815
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0374, device='cuda:0') mean:  tensor(-3.4973e-05, device='cuda:0') min:  tensor(-0.1219, device='cuda:0') norm:  tensor(0.3409, device='cuda:0') MSE:  tensor(1.2795e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  815  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  13
max of Lambda2 tensor(607.9139, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 82%|████████▏ | 815/1000 [52:26<11:59,  3.89s/it]Epoch:   816
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0334, device='cuda:0') mean:  tensor(-3.2769e-05, device='cuda:0') min:  tensor(-0.1013, device='cuda:0') norm:  tensor(0.3166, device='cuda:0') MSE:  tensor(1.1885e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  816  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(232.2889, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 82%|████████▏ | 816/1000 [52:30<12:00,  3.92s/it]Epoch:   817
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0386, device='cuda:0') mean:  tensor(-3.2056e-05, device='cuda:0') min:  tensor(-0.1055, device='cuda:0') norm:  tensor(0.3245, device='cuda:0') MSE:  tensor(1.2180e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  817  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(232.2881, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 82%|████████▏ | 817/1000 [52:34<11:52,  3.90s/it]Epoch:   818
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0353, device='cuda:0') mean:  tensor(-3.3553e-05, device='cuda:0') min:  tensor(-0.1112, device='cuda:0') norm:  tensor(0.3238, device='cuda:0') MSE:  tensor(1.2156e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  818  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 82%|████████▏ | 818/1000 [52:38<11:41,  3.86s/it]Epoch:   819
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-3.1071e-05, device='cuda:0') min:  tensor(-0.1163, device='cuda:0') norm:  tensor(0.3233, device='cuda:0') MSE:  tensor(1.2136e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  819  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.0303717851638795e-05
Preserved_eigens number check:  7
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9057, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 82%|████████▏ | 819/1000 [52:41<11:22,  3.77s/it]Epoch:   820
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0366, device='cuda:0') mean:  tensor(-3.3928e-05, device='cuda:0') min:  tensor(-0.1151, device='cuda:0') norm:  tensor(0.3391, device='cuda:0') MSE:  tensor(1.2730e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  820  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 82%|████████▏ | 820/1000 [52:45<11:23,  3.79s/it]Epoch:   821
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0368, device='cuda:0') mean:  tensor(-3.3194e-05, device='cuda:0') min:  tensor(-0.1113, device='cuda:0') norm:  tensor(0.3281, device='cuda:0') MSE:  tensor(1.2316e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  821  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 82%|████████▏ | 821/1000 [52:49<11:29,  3.85s/it]Epoch:   822
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0365, device='cuda:0') mean:  tensor(-3.2553e-05, device='cuda:0') min:  tensor(-0.1158, device='cuda:0') norm:  tensor(0.3326, device='cuda:0') MSE:  tensor(1.2486e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  822  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  15
max of Lambda2 tensor(232.2897, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 82%|████████▏ | 822/1000 [52:53<11:27,  3.86s/it]Epoch:   823
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0374, device='cuda:0') mean:  tensor(-3.4277e-05, device='cuda:0') min:  tensor(-0.1239, device='cuda:0') norm:  tensor(0.3412, device='cuda:0') MSE:  tensor(1.2809e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  823  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 82%|████████▏ | 823/1000 [52:57<11:24,  3.87s/it]Epoch:   824
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0336, device='cuda:0') mean:  tensor(-3.3944e-05, device='cuda:0') min:  tensor(-0.1035, device='cuda:0') norm:  tensor(0.3198, device='cuda:0') MSE:  tensor(1.2003e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  824  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 82%|████████▏ | 824/1000 [53:00<10:56,  3.73s/it]Epoch:   825
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0410, device='cuda:0') mean:  tensor(-3.6613e-05, device='cuda:0') min:  tensor(-0.1138, device='cuda:0') norm:  tensor(0.3583, device='cuda:0') MSE:  tensor(1.3449e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  825  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  15
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 82%|████████▎ | 825/1000 [53:04<10:42,  3.67s/it]Epoch:   826
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0366, device='cuda:0') mean:  tensor(-3.2456e-05, device='cuda:0') min:  tensor(-0.1084, device='cuda:0') norm:  tensor(0.3224, device='cuda:0') MSE:  tensor(1.2103e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  826  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 83%|████████▎ | 826/1000 [53:08<10:45,  3.71s/it]Epoch:   827
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0403, device='cuda:0') mean:  tensor(-3.3619e-05, device='cuda:0') min:  tensor(-0.1232, device='cuda:0') norm:  tensor(0.3453, device='cuda:0') MSE:  tensor(1.2960e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  827  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 83%|████████▎ | 827/1000 [53:11<10:37,  3.68s/it]Epoch:   828
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0366, device='cuda:0') mean:  tensor(-3.4278e-05, device='cuda:0') min:  tensor(-0.1185, device='cuda:0') norm:  tensor(0.3389, device='cuda:0') MSE:  tensor(1.2721e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  828  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 83%|████████▎ | 828/1000 [53:15<10:51,  3.79s/it]Epoch:   829
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0400, device='cuda:0') mean:  tensor(-3.7013e-05, device='cuda:0') min:  tensor(-0.1311, device='cuda:0') norm:  tensor(0.3714, device='cuda:0') MSE:  tensor(1.3942e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  829  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 83%|████████▎ | 829/1000 [53:19<10:47,  3.79s/it]Epoch:   830
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0380, device='cuda:0') mean:  tensor(-3.4618e-05, device='cuda:0') min:  tensor(-0.1107, device='cuda:0') norm:  tensor(0.3371, device='cuda:0') MSE:  tensor(1.2654e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  830  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 83%|████████▎ | 830/1000 [53:23<10:50,  3.83s/it]Epoch:   831
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0387, device='cuda:0') mean:  tensor(-3.1514e-05, device='cuda:0') min:  tensor(-0.1196, device='cuda:0') norm:  tensor(0.3289, device='cuda:0') MSE:  tensor(1.2345e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  831  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  11
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 83%|████████▎ | 831/1000 [53:27<10:58,  3.90s/it]Epoch:   832
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0303, device='cuda:0') mean:  tensor(-3.1387e-05, device='cuda:0') min:  tensor(-0.1142, device='cuda:0') norm:  tensor(0.3180, device='cuda:0') MSE:  tensor(1.1937e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  832  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 83%|████████▎ | 832/1000 [53:31<10:42,  3.83s/it]Epoch:   833
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0360, device='cuda:0') mean:  tensor(-3.5912e-05, device='cuda:0') min:  tensor(-0.1116, device='cuda:0') norm:  tensor(0.3448, device='cuda:0') MSE:  tensor(1.2943e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  833  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.8989, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 83%|████████▎ | 833/1000 [53:35<10:35,  3.80s/it]Epoch:   834
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0370, device='cuda:0') mean:  tensor(-3.3090e-05, device='cuda:0') min:  tensor(-0.1219, device='cuda:0') norm:  tensor(0.3380, device='cuda:0') MSE:  tensor(1.2686e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  834  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 83%|████████▎ | 834/1000 [53:38<10:28,  3.79s/it]Epoch:   835
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0358, device='cuda:0') mean:  tensor(-3.0156e-05, device='cuda:0') min:  tensor(-0.1093, device='cuda:0') norm:  tensor(0.3109, device='cuda:0') MSE:  tensor(1.1671e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  835  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 84%|████████▎ | 835/1000 [53:42<10:26,  3.80s/it]Epoch:   836
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-3.0900e-05, device='cuda:0') min:  tensor(-0.1027, device='cuda:0') norm:  tensor(0.3010, device='cuda:0') MSE:  tensor(1.1298e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  836  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 84%|████████▎ | 836/1000 [53:46<10:30,  3.84s/it]Epoch:   837
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0327, device='cuda:0') mean:  tensor(-2.9777e-05, device='cuda:0') min:  tensor(-0.1223, device='cuda:0') norm:  tensor(0.3260, device='cuda:0') MSE:  tensor(1.2237e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  837  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.7252902984619143e-10 
thres:  1.030371878296137e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 84%|████████▎ | 837/1000 [53:49<09:56,  3.66s/it]Epoch:   838
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0368, device='cuda:0') mean:  tensor(-3.1081e-05, device='cuda:0') min:  tensor(-0.1176, device='cuda:0') norm:  tensor(0.3211, device='cuda:0') MSE:  tensor(1.2054e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  838  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 84%|████████▍ | 838/1000 [53:53<10:03,  3.73s/it]Epoch:   839
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0383, device='cuda:0') mean:  tensor(-3.6307e-05, device='cuda:0') min:  tensor(-0.1246, device='cuda:0') norm:  tensor(0.3550, device='cuda:0') MSE:  tensor(1.3326e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  839  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 84%|████████▍ | 839/1000 [53:57<10:12,  3.80s/it]Epoch:   840
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0388, device='cuda:0') mean:  tensor(-3.5575e-05, device='cuda:0') min:  tensor(-0.1214, device='cuda:0') norm:  tensor(0.3530, device='cuda:0') MSE:  tensor(1.3252e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  840  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 84%|████████▍ | 840/1000 [54:01<10:12,  3.83s/it]Epoch:   841
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0403, device='cuda:0') mean:  tensor(-3.2435e-05, device='cuda:0') min:  tensor(-0.1063, device='cuda:0') norm:  tensor(0.3263, device='cuda:0') MSE:  tensor(1.2248e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  841  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  10
max of Lambda2 tensor(232.2895, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 84%|████████▍ | 841/1000 [54:05<10:04,  3.80s/it]Epoch:   842
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0408, device='cuda:0') mean:  tensor(-3.1392e-05, device='cuda:0') min:  tensor(-0.1064, device='cuda:0') norm:  tensor(0.3187, device='cuda:0') MSE:  tensor(1.1964e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  842  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 84%|████████▍ | 842/1000 [54:09<09:59,  3.79s/it]Epoch:   843
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0387, device='cuda:0') mean:  tensor(-3.3587e-05, device='cuda:0') min:  tensor(-0.1054, device='cuda:0') norm:  tensor(0.3329, device='cuda:0') MSE:  tensor(1.2496e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  843  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  5.890201144234053e-10 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  9
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.8982, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 84%|████████▍ | 843/1000 [54:12<09:56,  3.80s/it]Epoch:   844
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0334, device='cuda:0') mean:  tensor(-3.3668e-05, device='cuda:0') min:  tensor(-0.1182, device='cuda:0') norm:  tensor(0.3406, device='cuda:0') MSE:  tensor(1.2786e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  844  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494323499500751
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(232.2871, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 84%|████████▍ | 844/1000 [54:16<09:55,  3.82s/it]Epoch:   845
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-3.0559e-05, device='cuda:0') min:  tensor(-0.1033, device='cuda:0') norm:  tensor(0.3066, device='cuda:0') MSE:  tensor(1.1508e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  845  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 84%|████████▍ | 845/1000 [54:20<09:54,  3.83s/it]Epoch:   846
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0345, device='cuda:0') mean:  tensor(-3.5019e-05, device='cuda:0') min:  tensor(-0.1072, device='cuda:0') norm:  tensor(0.3300, device='cuda:0') MSE:  tensor(1.2386e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  846  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  11
max of Lambda2 tensor(232.2888, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 85%|████████▍ | 846/1000 [54:24<09:57,  3.88s/it]Epoch:   847
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0395, device='cuda:0') mean:  tensor(-3.1173e-05, device='cuda:0') min:  tensor(-0.1133, device='cuda:0') norm:  tensor(0.3221, device='cuda:0') MSE:  tensor(1.2089e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  847  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 85%|████████▍ | 847/1000 [54:28<09:51,  3.87s/it]Epoch:   848
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0325, device='cuda:0') mean:  tensor(-3.2928e-05, device='cuda:0') min:  tensor(-0.1070, device='cuda:0') norm:  tensor(0.3145, device='cuda:0') MSE:  tensor(1.1806e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  848  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9124, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 85%|████████▍ | 848/1000 [54:32<09:51,  3.89s/it]Epoch:   849
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0303, device='cuda:0') mean:  tensor(-3.6645e-05, device='cuda:0') min:  tensor(-0.1103, device='cuda:0') norm:  tensor(0.3440, device='cuda:0') MSE:  tensor(1.2912e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  849  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.0303717851638795e-05
Preserved_eigens number check:  6
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 85%|████████▍ | 849/1000 [54:36<09:56,  3.95s/it]Epoch:   850
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0312, device='cuda:0') mean:  tensor(-3.2554e-05, device='cuda:0') min:  tensor(-0.1086, device='cuda:0') norm:  tensor(0.3193, device='cuda:0') MSE:  tensor(1.1984e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  850  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2894, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 85%|████████▌ | 850/1000 [54:40<09:53,  3.96s/it]Epoch:   851
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0364, device='cuda:0') mean:  tensor(-3.3806e-05, device='cuda:0') min:  tensor(-0.0993, device='cuda:0') norm:  tensor(0.3223, device='cuda:0') MSE:  tensor(1.2098e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  851  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 85%|████████▌ | 851/1000 [54:44<09:45,  3.93s/it]Epoch:   852
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0366, device='cuda:0') mean:  tensor(-3.4146e-05, device='cuda:0') min:  tensor(-0.1190, device='cuda:0') norm:  tensor(0.3387, device='cuda:0') MSE:  tensor(1.2715e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  852  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 85%|████████▌ | 852/1000 [54:48<09:51,  3.99s/it]Epoch:   853
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-3.2682e-05, device='cuda:0') min:  tensor(-0.1305, device='cuda:0') norm:  tensor(0.3543, device='cuda:0') MSE:  tensor(1.3300e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  853  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 85%|████████▌ | 853/1000 [54:52<09:33,  3.90s/it]Epoch:   854
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0379, device='cuda:0') mean:  tensor(-3.4577e-05, device='cuda:0') min:  tensor(-0.1058, device='cuda:0') norm:  tensor(0.3352, device='cuda:0') MSE:  tensor(1.2583e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  854  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  6
max of Lambda2 tensor(607.9018, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 85%|████████▌ | 854/1000 [54:56<09:27,  3.89s/it]Epoch:   855
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0336, device='cuda:0') mean:  tensor(-2.8432e-05, device='cuda:0') min:  tensor(-0.1041, device='cuda:0') norm:  tensor(0.2915, device='cuda:0') MSE:  tensor(1.0941e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  855  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  9
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 86%|████████▌ | 855/1000 [54:59<09:14,  3.82s/it]Epoch:   856
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0415, device='cuda:0') mean:  tensor(-3.1211e-05, device='cuda:0') min:  tensor(-0.1242, device='cuda:0') norm:  tensor(0.3367, device='cuda:0') MSE:  tensor(1.2639e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  856  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9006, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 86%|████████▌ | 856/1000 [55:03<09:06,  3.79s/it]Epoch:   857
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0313, device='cuda:0') mean:  tensor(-3.1497e-05, device='cuda:0') min:  tensor(-0.1132, device='cuda:0') norm:  tensor(0.3095, device='cuda:0') MSE:  tensor(1.1617e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  857  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  13
max of Lambda2 tensor(232.2892, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 86%|████████▌ | 857/1000 [55:06<08:51,  3.72s/it]Epoch:   858
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0443, device='cuda:0') mean:  tensor(-3.2068e-05, device='cuda:0') min:  tensor(-0.1093, device='cuda:0') norm:  tensor(0.3335, device='cuda:0') MSE:  tensor(1.2518e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  858  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 86%|████████▌ | 858/1000 [55:11<09:02,  3.82s/it]Epoch:   859
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0404, device='cuda:0') mean:  tensor(-3.6132e-05, device='cuda:0') min:  tensor(-0.1232, device='cuda:0') norm:  tensor(0.3570, device='cuda:0') MSE:  tensor(1.3401e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  859  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  22
 86%|████████▌ | 859/1000 [55:14<09:02,  3.85s/it]Epoch:   860
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0337, device='cuda:0') mean:  tensor(-3.2172e-05, device='cuda:0') min:  tensor(-0.1058, device='cuda:0') norm:  tensor(0.3115, device='cuda:0') MSE:  tensor(1.1692e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  860  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  22
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 86%|████████▌ | 860/1000 [55:18<08:51,  3.80s/it]Epoch:   861
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0329, device='cuda:0') mean:  tensor(-3.0741e-05, device='cuda:0') min:  tensor(-0.1119, device='cuda:0') norm:  tensor(0.3031, device='cuda:0') MSE:  tensor(1.1378e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  861  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  7
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 86%|████████▌ | 861/1000 [55:22<09:01,  3.90s/it]Epoch:   862
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0365, device='cuda:0') mean:  tensor(-3.5013e-05, device='cuda:0') min:  tensor(-0.1059, device='cuda:0') norm:  tensor(0.3370, device='cuda:0') MSE:  tensor(1.2651e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  862  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 86%|████████▌ | 862/1000 [55:26<09:06,  3.96s/it]Epoch:   863
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0462, device='cuda:0') mean:  tensor(-3.4783e-05, device='cuda:0') min:  tensor(-0.1230, device='cuda:0') norm:  tensor(0.3624, device='cuda:0') MSE:  tensor(1.3602e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  863  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 86%|████████▋ | 863/1000 [55:30<08:53,  3.90s/it]Epoch:   864
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0405, device='cuda:0') mean:  tensor(-3.3980e-05, device='cuda:0') min:  tensor(-0.1059, device='cuda:0') norm:  tensor(0.3375, device='cuda:0') MSE:  tensor(1.2669e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  864  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  3
 86%|████████▋ | 864/1000 [55:34<08:56,  3.94s/it]Epoch:   865
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0392, device='cuda:0') mean:  tensor(-3.6673e-05, device='cuda:0') min:  tensor(-0.1289, device='cuda:0') norm:  tensor(0.3630, device='cuda:0') MSE:  tensor(1.3627e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  865  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  3
max of Lambda2 tensor(232.2882, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 86%|████████▋ | 865/1000 [55:38<08:30,  3.78s/it]Epoch:   866
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0405, device='cuda:0') mean:  tensor(-3.3454e-05, device='cuda:0') min:  tensor(-0.1117, device='cuda:0') norm:  tensor(0.3414, device='cuda:0') MSE:  tensor(1.2813e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  866  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 87%|████████▋ | 866/1000 [55:41<08:22,  3.75s/it]Epoch:   867
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0405, device='cuda:0') mean:  tensor(-3.0537e-05, device='cuda:0') min:  tensor(-0.1049, device='cuda:0') norm:  tensor(0.3113, device='cuda:0') MSE:  tensor(1.1686e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  867  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.562530187486071e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 87%|████████▋ | 867/1000 [55:45<08:24,  3.79s/it]Epoch:   868
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0384, device='cuda:0') mean:  tensor(-3.5737e-05, device='cuda:0') min:  tensor(-0.1147, device='cuda:0') norm:  tensor(0.3485, device='cuda:0') MSE:  tensor(1.3083e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  868  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 87%|████████▋ | 868/1000 [55:49<08:18,  3.78s/it]Epoch:   869
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0355, device='cuda:0') mean:  tensor(-3.4969e-05, device='cuda:0') min:  tensor(-0.1220, device='cuda:0') norm:  tensor(0.3429, device='cuda:0') MSE:  tensor(1.2873e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  869  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9116, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 87%|████████▋ | 869/1000 [55:53<08:14,  3.78s/it]Epoch:   870
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0418, device='cuda:0') mean:  tensor(-3.2450e-05, device='cuda:0') min:  tensor(-0.1218, device='cuda:0') norm:  tensor(0.3411, device='cuda:0') MSE:  tensor(1.2803e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  870  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9146, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 87%|████████▋ | 870/1000 [55:57<08:21,  3.86s/it]Epoch:   871
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0400, device='cuda:0') mean:  tensor(-3.2244e-05, device='cuda:0') min:  tensor(-0.1323, device='cuda:0') norm:  tensor(0.3547, device='cuda:0') MSE:  tensor(1.3315e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  871  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9055, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 87%|████████▋ | 871/1000 [56:00<08:08,  3.79s/it]Epoch:   872
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-3.1507e-05, device='cuda:0') min:  tensor(-0.1016, device='cuda:0') norm:  tensor(0.3153, device='cuda:0') MSE:  tensor(1.1837e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  872  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 87%|████████▋ | 872/1000 [56:04<08:05,  3.79s/it]Epoch:   873
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0392, device='cuda:0') mean:  tensor(-3.3135e-05, device='cuda:0') min:  tensor(-0.1087, device='cuda:0') norm:  tensor(0.3304, device='cuda:0') MSE:  tensor(1.2402e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  873  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 87%|████████▋ | 873/1000 [56:08<08:02,  3.80s/it]Epoch:   874
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0384, device='cuda:0') mean:  tensor(-3.4337e-05, device='cuda:0') min:  tensor(-0.1209, device='cuda:0') norm:  tensor(0.3439, device='cuda:0') MSE:  tensor(1.2909e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  874  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.8973, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 87%|████████▋ | 874/1000 [56:12<08:01,  3.82s/it]Epoch:   875
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0323, device='cuda:0') mean:  tensor(-3.4158e-05, device='cuda:0') min:  tensor(-0.1175, device='cuda:0') norm:  tensor(0.3319, device='cuda:0') MSE:  tensor(1.2458e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  875  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 88%|████████▊ | 875/1000 [56:16<08:02,  3.86s/it]Epoch:   876
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0331, device='cuda:0') mean:  tensor(-3.6224e-05, device='cuda:0') min:  tensor(-0.1101, device='cuda:0') norm:  tensor(0.3383, device='cuda:0') MSE:  tensor(1.2699e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  876  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 88%|████████▊ | 876/1000 [56:20<08:07,  3.93s/it]Epoch:   877
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0384, device='cuda:0') mean:  tensor(-3.1923e-05, device='cuda:0') min:  tensor(-0.1018, device='cuda:0') norm:  tensor(0.3179, device='cuda:0') MSE:  tensor(1.1934e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  877  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(232.2887, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 88%|████████▊ | 877/1000 [56:24<08:07,  3.96s/it]Epoch:   878
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0324, device='cuda:0') mean:  tensor(-3.3633e-05, device='cuda:0') min:  tensor(-0.1125, device='cuda:0') norm:  tensor(0.3240, device='cuda:0') MSE:  tensor(1.2163e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  878  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 88%|████████▊ | 878/1000 [56:28<08:00,  3.94s/it]Epoch:   879
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0364, device='cuda:0') mean:  tensor(-3.4659e-05, device='cuda:0') min:  tensor(-0.1251, device='cuda:0') norm:  tensor(0.3558, device='cuda:0') MSE:  tensor(1.3356e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  879  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.7252902984619143e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 88%|████████▊ | 879/1000 [56:32<07:59,  3.96s/it]Epoch:   880
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0348, device='cuda:0') mean:  tensor(-3.4372e-05, device='cuda:0') min:  tensor(-0.1120, device='cuda:0') norm:  tensor(0.3348, device='cuda:0') MSE:  tensor(1.2569e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  880  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 88%|████████▊ | 880/1000 [56:36<07:47,  3.89s/it]Epoch:   881
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0400, device='cuda:0') mean:  tensor(-3.3810e-05, device='cuda:0') min:  tensor(-0.1171, device='cuda:0') norm:  tensor(0.3432, device='cuda:0') MSE:  tensor(1.2884e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  881  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 88%|████████▊ | 881/1000 [56:39<07:35,  3.83s/it]Epoch:   882
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0401, device='cuda:0') mean:  tensor(-3.4533e-05, device='cuda:0') min:  tensor(-0.1220, device='cuda:0') norm:  tensor(0.3494, device='cuda:0') MSE:  tensor(1.3115e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  882  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  5
max of Lambda2 tensor(232.2891, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 88%|████████▊ | 882/1000 [56:43<07:22,  3.75s/it]Epoch:   883
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0410, device='cuda:0') mean:  tensor(-3.7931e-05, device='cuda:0') min:  tensor(-0.1122, device='cuda:0') norm:  tensor(0.3635, device='cuda:0') MSE:  tensor(1.3644e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  883  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  6
max of Lambda2 tensor(232.2885, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 88%|████████▊ | 883/1000 [56:47<07:32,  3.86s/it]Epoch:   884
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0404, device='cuda:0') mean:  tensor(-3.2998e-05, device='cuda:0') min:  tensor(-0.1033, device='cuda:0') norm:  tensor(0.3286, device='cuda:0') MSE:  tensor(1.2335e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  884  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 88%|████████▊ | 884/1000 [56:51<07:30,  3.88s/it]Epoch:   885
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0396, device='cuda:0') mean:  tensor(-3.7095e-05, device='cuda:0') min:  tensor(-0.1189, device='cuda:0') norm:  tensor(0.3588, device='cuda:0') MSE:  tensor(1.3469e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  885  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.030371878296137e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 88%|████████▊ | 885/1000 [56:55<07:22,  3.85s/it]Epoch:   886
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0405, device='cuda:0') mean:  tensor(-3.4310e-05, device='cuda:0') min:  tensor(-0.1162, device='cuda:0') norm:  tensor(0.3415, device='cuda:0') MSE:  tensor(1.2818e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  886  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 89%|████████▊ | 886/1000 [56:59<07:24,  3.90s/it]Epoch:   887
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0387, device='cuda:0') mean:  tensor(-3.0967e-05, device='cuda:0') min:  tensor(-0.1127, device='cuda:0') norm:  tensor(0.3207, device='cuda:0') MSE:  tensor(1.2038e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  887  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9093, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 89%|████████▊ | 887/1000 [57:02<07:19,  3.89s/it]Epoch:   888
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0381, device='cuda:0') mean:  tensor(-3.4205e-05, device='cuda:0') min:  tensor(-0.1112, device='cuda:0') norm:  tensor(0.3334, device='cuda:0') MSE:  tensor(1.2514e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  888  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  6
max of Lambda2 tensor(232.2881, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 89%|████████▉ | 888/1000 [57:06<07:17,  3.90s/it]Epoch:   889
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0374, device='cuda:0') mean:  tensor(-3.7506e-05, device='cuda:0') min:  tensor(-0.1115, device='cuda:0') norm:  tensor(0.3527, device='cuda:0') MSE:  tensor(1.3239e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  889  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 89%|████████▉ | 889/1000 [57:10<07:08,  3.86s/it]Epoch:   890
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0365, device='cuda:0') mean:  tensor(-3.6151e-05, device='cuda:0') min:  tensor(-0.1138, device='cuda:0') norm:  tensor(0.3469, device='cuda:0') MSE:  tensor(1.3022e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  890  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 89%|████████▉ | 890/1000 [57:14<07:05,  3.86s/it]Epoch:   891
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0385, device='cuda:0') mean:  tensor(-3.0663e-05, device='cuda:0') min:  tensor(-0.1116, device='cuda:0') norm:  tensor(0.3171, device='cuda:0') MSE:  tensor(1.1901e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  891  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 89%|████████▉ | 891/1000 [57:18<07:04,  3.90s/it]Epoch:   892
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0370, device='cuda:0') mean:  tensor(-3.3883e-05, device='cuda:0') min:  tensor(-0.1144, device='cuda:0') norm:  tensor(0.3341, device='cuda:0') MSE:  tensor(1.2541e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  892  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 89%|████████▉ | 892/1000 [57:22<06:52,  3.82s/it]Epoch:   893
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0328, device='cuda:0') mean:  tensor(-3.0963e-05, device='cuda:0') min:  tensor(-0.0944, device='cuda:0') norm:  tensor(0.2966, device='cuda:0') MSE:  tensor(1.1135e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  893  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  13
max of Lambda2 tensor(232.2876, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 89%|████████▉ | 893/1000 [57:26<06:52,  3.86s/it]Epoch:   894
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0378, device='cuda:0') mean:  tensor(-3.4217e-05, device='cuda:0') min:  tensor(-0.1195, device='cuda:0') norm:  tensor(0.3440, device='cuda:0') MSE:  tensor(1.2912e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  894  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 89%|████████▉ | 894/1000 [57:29<06:46,  3.83s/it]Epoch:   895
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0396, device='cuda:0') mean:  tensor(-3.4951e-05, device='cuda:0') min:  tensor(-0.1212, device='cuda:0') norm:  tensor(0.3487, device='cuda:0') MSE:  tensor(1.3090e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  895  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 90%|████████▉ | 895/1000 [57:33<06:51,  3.92s/it]Epoch:   896
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-3.5461e-05, device='cuda:0') min:  tensor(-0.1102, device='cuda:0') norm:  tensor(0.3406, device='cuda:0') MSE:  tensor(1.2784e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  896  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  15
max of Lambda2 tensor(607.9089, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 90%|████████▉ | 896/1000 [57:37<06:45,  3.90s/it]Epoch:   897
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0327, device='cuda:0') mean:  tensor(-2.9648e-05, device='cuda:0') min:  tensor(-0.0980, device='cuda:0') norm:  tensor(0.2936, device='cuda:0') MSE:  tensor(1.1019e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  897  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.7252902984619143e-10 
thres:  1.0303717851638795e-05
Preserved_eigens number check:  9
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2881, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  4
 90%|████████▉ | 897/1000 [57:41<06:38,  3.87s/it]Epoch:   898
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0407, device='cuda:0') mean:  tensor(-3.1701e-05, device='cuda:0') min:  tensor(-0.1123, device='cuda:0') norm:  tensor(0.3279, device='cuda:0') MSE:  tensor(1.2309e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  898  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  4
max of Lambda2 tensor(232.2885, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 90%|████████▉ | 898/1000 [57:45<06:39,  3.92s/it]Epoch:   899
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0354, device='cuda:0') mean:  tensor(-3.0844e-05, device='cuda:0') min:  tensor(-0.0926, device='cuda:0') norm:  tensor(0.2967, device='cuda:0') MSE:  tensor(1.1136e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  899  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2872, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 90%|████████▉ | 899/1000 [57:49<06:37,  3.93s/it]Epoch:   900
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-3.5703e-05, device='cuda:0') min:  tensor(-0.1081, device='cuda:0') norm:  tensor(0.3479, device='cuda:0') MSE:  tensor(1.3061e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  900  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 90%|█████████ | 900/1000 [57:53<06:30,  3.91s/it]Epoch:   901
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0400, device='cuda:0') mean:  tensor(-3.4152e-05, device='cuda:0') min:  tensor(-0.1054, device='cuda:0') norm:  tensor(0.3346, device='cuda:0') MSE:  tensor(1.2561e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  901  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 90%|█████████ | 901/1000 [57:57<06:27,  3.92s/it]Epoch:   902
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0359, device='cuda:0') mean:  tensor(-3.1897e-05, device='cuda:0') min:  tensor(-0.1157, device='cuda:0') norm:  tensor(0.3236, device='cuda:0') MSE:  tensor(1.2147e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  902  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2887, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 90%|█████████ | 902/1000 [58:01<06:26,  3.94s/it]Epoch:   903
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0375, device='cuda:0') mean:  tensor(-3.2239e-05, device='cuda:0') min:  tensor(-0.0991, device='cuda:0') norm:  tensor(0.3138, device='cuda:0') MSE:  tensor(1.1781e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  903  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  0.0 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 90%|█████████ | 903/1000 [58:05<06:28,  4.00s/it]Epoch:   904
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0429, device='cuda:0') mean:  tensor(-3.4316e-05, device='cuda:0') min:  tensor(-0.1131, device='cuda:0') norm:  tensor(0.3465, device='cuda:0') MSE:  tensor(1.3008e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  904  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  10
max of Lambda2 tensor(232.2876, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 90%|█████████ | 904/1000 [58:09<06:21,  3.98s/it]Epoch:   905
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0403, device='cuda:0') mean:  tensor(-3.6031e-05, device='cuda:0') min:  tensor(-0.1169, device='cuda:0') norm:  tensor(0.3570, device='cuda:0') MSE:  tensor(1.3399e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  905  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  7
max of Lambda2 tensor(232.2888, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 90%|█████████ | 905/1000 [58:13<06:19,  3.99s/it]Epoch:   906
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0416, device='cuda:0') mean:  tensor(-3.6314e-05, device='cuda:0') min:  tensor(-0.1283, device='cuda:0') norm:  tensor(0.3667, device='cuda:0') MSE:  tensor(1.3764e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  906  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 91%|█████████ | 906/1000 [58:17<06:10,  3.94s/it]Epoch:   907
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0322, device='cuda:0') mean:  tensor(-3.2364e-05, device='cuda:0') min:  tensor(-0.1003, device='cuda:0') norm:  tensor(0.3142, device='cuda:0') MSE:  tensor(1.1794e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  907  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 91%|█████████ | 907/1000 [58:21<06:05,  3.93s/it]Epoch:   908
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0353, device='cuda:0') mean:  tensor(-3.3528e-05, device='cuda:0') min:  tensor(-0.1032, device='cuda:0') norm:  tensor(0.3270, device='cuda:0') MSE:  tensor(1.2274e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  908  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  6
max of Lambda2 tensor(607.9117, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 91%|█████████ | 908/1000 [58:25<06:02,  3.94s/it]Epoch:   909
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-3.5252e-05, device='cuda:0') min:  tensor(-0.1066, device='cuda:0') norm:  tensor(0.3412, device='cuda:0') MSE:  tensor(1.2808e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  909  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.030371878296137e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2883, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 91%|█████████ | 909/1000 [58:28<05:51,  3.87s/it]Epoch:   910
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0373, device='cuda:0') mean:  tensor(-3.2572e-05, device='cuda:0') min:  tensor(-0.1147, device='cuda:0') norm:  tensor(0.3261, device='cuda:0') MSE:  tensor(1.2242e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  910  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  6
max of Lambda2 tensor(232.2885, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 91%|█████████ | 910/1000 [58:32<05:53,  3.93s/it]Epoch:   911
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0369, device='cuda:0') mean:  tensor(-3.6333e-05, device='cuda:0') min:  tensor(-0.1231, device='cuda:0') norm:  tensor(0.3495, device='cuda:0') MSE:  tensor(1.3119e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  911  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 91%|█████████ | 911/1000 [58:36<05:48,  3.91s/it]Epoch:   912
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0427, device='cuda:0') mean:  tensor(-3.1208e-05, device='cuda:0') min:  tensor(-0.1165, device='cuda:0') norm:  tensor(0.3341, device='cuda:0') MSE:  tensor(1.2543e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  912  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 91%|█████████ | 912/1000 [58:40<05:44,  3.91s/it]Epoch:   913
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0362, device='cuda:0') mean:  tensor(-3.0977e-05, device='cuda:0') min:  tensor(-0.1081, device='cuda:0') norm:  tensor(0.3145, device='cuda:0') MSE:  tensor(1.1807e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  913  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  11
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 91%|█████████▏| 913/1000 [58:44<05:35,  3.86s/it]Epoch:   914
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0431, device='cuda:0') mean:  tensor(-3.5755e-05, device='cuda:0') min:  tensor(-0.1241, device='cuda:0') norm:  tensor(0.3626, device='cuda:0') MSE:  tensor(1.3610e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  914  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2896, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 91%|█████████▏| 914/1000 [58:48<05:30,  3.84s/it]Epoch:   915
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0375, device='cuda:0') mean:  tensor(-3.3400e-05, device='cuda:0') min:  tensor(-0.1198, device='cuda:0') norm:  tensor(0.3423, device='cuda:0') MSE:  tensor(1.2848e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  915  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  5
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 92%|█████████▏| 915/1000 [58:52<05:32,  3.91s/it]Epoch:   916
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0386, device='cuda:0') mean:  tensor(-3.4751e-05, device='cuda:0') min:  tensor(-0.1166, device='cuda:0') norm:  tensor(0.3463, device='cuda:0') MSE:  tensor(1.3000e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  916  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  15
max of Lambda2 tensor(607.9113, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 92%|█████████▏| 916/1000 [58:56<05:29,  3.92s/it]Epoch:   917
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0383, device='cuda:0') mean:  tensor(-3.6234e-05, device='cuda:0') min:  tensor(-0.1091, device='cuda:0') norm:  tensor(0.3448, device='cuda:0') MSE:  tensor(1.2943e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  917  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(232.2880, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 92%|█████████▏| 917/1000 [59:00<05:28,  3.95s/it]Epoch:   918
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0406, device='cuda:0') mean:  tensor(-3.1699e-05, device='cuda:0') min:  tensor(-0.0983, device='cuda:0') norm:  tensor(0.3157, device='cuda:0') MSE:  tensor(1.1852e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  918  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 92%|█████████▏| 918/1000 [59:04<05:17,  3.87s/it]Epoch:   919
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0411, device='cuda:0') mean:  tensor(-3.2558e-05, device='cuda:0') min:  tensor(-0.1275, device='cuda:0') norm:  tensor(0.3498, device='cuda:0') MSE:  tensor(1.3130e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  919  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(232.2887, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 92%|█████████▏| 919/1000 [59:07<05:14,  3.88s/it]Epoch:   920
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0353, device='cuda:0') mean:  tensor(-3.4422e-05, device='cuda:0') min:  tensor(-0.1074, device='cuda:0') norm:  tensor(0.3341, device='cuda:0') MSE:  tensor(1.2542e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  920  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(232.2892, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 92%|█████████▏| 920/1000 [59:11<05:05,  3.82s/it]Epoch:   921
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0357, device='cuda:0') mean:  tensor(-3.2101e-05, device='cuda:0') min:  tensor(-0.1080, device='cuda:0') norm:  tensor(0.3175, device='cuda:0') MSE:  tensor(1.1917e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  921  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.7252902984619143e-10 
thres:  1.0303717851638795e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 92%|█████████▏| 921/1000 [59:15<05:06,  3.88s/it]Epoch:   922
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0328, device='cuda:0') mean:  tensor(-3.3084e-05, device='cuda:0') min:  tensor(-0.1117, device='cuda:0') norm:  tensor(0.3234, device='cuda:0') MSE:  tensor(1.2140e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  922  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 92%|█████████▏| 922/1000 [59:19<05:04,  3.91s/it]Epoch:   923
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0354, device='cuda:0') mean:  tensor(-3.4263e-05, device='cuda:0') min:  tensor(-0.1095, device='cuda:0') norm:  tensor(0.3291, device='cuda:0') MSE:  tensor(1.2355e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  923  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 92%|█████████▏| 923/1000 [59:23<05:02,  3.93s/it]Epoch:   924
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0324, device='cuda:0') mean:  tensor(-3.0529e-05, device='cuda:0') min:  tensor(-0.1104, device='cuda:0') norm:  tensor(0.3078, device='cuda:0') MSE:  tensor(1.1553e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  924  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  6
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 92%|█████████▏| 924/1000 [59:27<05:00,  3.96s/it]Epoch:   925
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0405, device='cuda:0') mean:  tensor(-3.2515e-05, device='cuda:0') min:  tensor(-0.1294, device='cuda:0') norm:  tensor(0.3445, device='cuda:0') MSE:  tensor(1.2930e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  925  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2883, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 92%|█████████▎| 925/1000 [59:31<04:56,  3.96s/it]Epoch:   926
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0404, device='cuda:0') mean:  tensor(-3.3350e-05, device='cuda:0') min:  tensor(-0.1066, device='cuda:0') norm:  tensor(0.3332, device='cuda:0') MSE:  tensor(1.2508e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  926  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  15
 93%|█████████▎| 926/1000 [59:35<04:45,  3.86s/it]Epoch:   927
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0355, device='cuda:0') mean:  tensor(-3.4441e-05, device='cuda:0') min:  tensor(-0.1075, device='cuda:0') norm:  tensor(0.3283, device='cuda:0') MSE:  tensor(1.2322e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  927  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  15
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9095, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 93%|█████████▎| 927/1000 [59:39<04:40,  3.85s/it]Epoch:   928
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0415, device='cuda:0') mean:  tensor(-3.2861e-05, device='cuda:0') min:  tensor(-0.1258, device='cuda:0') norm:  tensor(0.3458, device='cuda:0') MSE:  tensor(1.2982e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  928  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 93%|█████████▎| 928/1000 [59:42<04:38,  3.87s/it]Epoch:   929
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0430, device='cuda:0') mean:  tensor(-3.3730e-05, device='cuda:0') min:  tensor(-0.1323, device='cuda:0') norm:  tensor(0.3590, device='cuda:0') MSE:  tensor(1.3476e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  929  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 93%|█████████▎| 929/1000 [59:46<04:34,  3.86s/it]Epoch:   930
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0368, device='cuda:0') mean:  tensor(-3.2131e-05, device='cuda:0') min:  tensor(-0.1082, device='cuda:0') norm:  tensor(0.3162, device='cuda:0') MSE:  tensor(1.1869e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  930  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  6
max of Lambda2 tensor(607.9041, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 93%|█████████▎| 930/1000 [59:50<04:21,  3.73s/it]Epoch:   931
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0398, device='cuda:0') mean:  tensor(-3.5087e-05, device='cuda:0') min:  tensor(-0.1284, device='cuda:0') norm:  tensor(0.3558, device='cuda:0') MSE:  tensor(1.3355e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  931  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 93%|█████████▎| 931/1000 [59:54<04:24,  3.84s/it]Epoch:   932
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-3.2494e-05, device='cuda:0') min:  tensor(-0.1139, device='cuda:0') norm:  tensor(0.3272, device='cuda:0') MSE:  tensor(1.2281e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  932  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 93%|█████████▎| 932/1000 [59:58<04:23,  3.88s/it]Epoch:   933
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0392, device='cuda:0') mean:  tensor(-3.4249e-05, device='cuda:0') min:  tensor(-0.1099, device='cuda:0') norm:  tensor(0.3409, device='cuda:0') MSE:  tensor(1.2796e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  933  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  5
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9048, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 93%|█████████▎| 933/1000 [1:00:02<04:19,  3.87s/it]Epoch:   934
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0409, device='cuda:0') mean:  tensor(-3.3460e-05, device='cuda:0') min:  tensor(-0.1192, device='cuda:0') norm:  tensor(0.3409, device='cuda:0') MSE:  tensor(1.2798e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  934  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 93%|█████████▎| 934/1000 [1:00:05<04:12,  3.83s/it]Epoch:   935
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0435, device='cuda:0') mean:  tensor(-3.5702e-05, device='cuda:0') min:  tensor(-0.1128, device='cuda:0') norm:  tensor(0.3554, device='cuda:0') MSE:  tensor(1.3341e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  935  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 94%|█████████▎| 935/1000 [1:00:09<04:14,  3.91s/it]Epoch:   936
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0367, device='cuda:0') mean:  tensor(-3.2016e-05, device='cuda:0') min:  tensor(-0.1225, device='cuda:0') norm:  tensor(0.3370, device='cuda:0') MSE:  tensor(1.2652e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  936  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 94%|█████████▎| 936/1000 [1:00:13<04:06,  3.85s/it]Epoch:   937
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0312, device='cuda:0') mean:  tensor(-3.4080e-05, device='cuda:0') min:  tensor(-0.1181, device='cuda:0') norm:  tensor(0.3342, device='cuda:0') MSE:  tensor(1.2546e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  937  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 94%|█████████▎| 937/1000 [1:00:17<04:02,  3.85s/it]Epoch:   938
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0342, device='cuda:0') mean:  tensor(-3.3077e-05, device='cuda:0') min:  tensor(-0.1043, device='cuda:0') norm:  tensor(0.3230, device='cuda:0') MSE:  tensor(1.2126e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  938  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  6
max of Lambda2 tensor(232.2899, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 94%|█████████▍| 938/1000 [1:00:21<03:56,  3.82s/it]Epoch:   939
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0345, device='cuda:0') mean:  tensor(-3.2777e-05, device='cuda:0') min:  tensor(-0.0989, device='cuda:0') norm:  tensor(0.3171, device='cuda:0') MSE:  tensor(1.1903e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  939  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  12
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2867, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 94%|█████████▍| 939/1000 [1:00:24<03:43,  3.67s/it]Epoch:   940
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0378, device='cuda:0') mean:  tensor(-3.5617e-05, device='cuda:0') min:  tensor(-0.1280, device='cuda:0') norm:  tensor(0.3532, device='cuda:0') MSE:  tensor(1.3258e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  940  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  6
max of Lambda2 tensor(607.9149, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 94%|█████████▍| 940/1000 [1:00:28<03:46,  3.78s/it]Epoch:   941
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0371, device='cuda:0') mean:  tensor(-3.3936e-05, device='cuda:0') min:  tensor(-0.1028, device='cuda:0') norm:  tensor(0.3282, device='cuda:0') MSE:  tensor(1.2320e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  941  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 94%|█████████▍| 941/1000 [1:00:32<03:48,  3.87s/it]Epoch:   942
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0406, device='cuda:0') mean:  tensor(-3.1927e-05, device='cuda:0') min:  tensor(-0.1145, device='cuda:0') norm:  tensor(0.3354, device='cuda:0') MSE:  tensor(1.2589e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  942  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  13
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 94%|█████████▍| 942/1000 [1:00:36<03:44,  3.87s/it]Epoch:   943
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0367, device='cuda:0') mean:  tensor(-3.3644e-05, device='cuda:0') min:  tensor(-0.1111, device='cuda:0') norm:  tensor(0.3264, device='cuda:0') MSE:  tensor(1.2251e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  943  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2877, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 94%|█████████▍| 943/1000 [1:00:40<03:43,  3.92s/it]Epoch:   944
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0375, device='cuda:0') mean:  tensor(-3.2340e-05, device='cuda:0') min:  tensor(-0.1288, device='cuda:0') norm:  tensor(0.3460, device='cuda:0') MSE:  tensor(1.2987e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  944  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(607.9140, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 94%|█████████▍| 944/1000 [1:00:44<03:34,  3.83s/it]Epoch:   945
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0390, device='cuda:0') mean:  tensor(-3.5577e-05, device='cuda:0') min:  tensor(-0.1219, device='cuda:0') norm:  tensor(0.3585, device='cuda:0') MSE:  tensor(1.3459e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  945  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718410432339e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2892, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 94%|█████████▍| 945/1000 [1:00:48<03:32,  3.87s/it]Epoch:   946
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0411, device='cuda:0') mean:  tensor(-3.2562e-05, device='cuda:0') min:  tensor(-0.1103, device='cuda:0') norm:  tensor(0.3250, device='cuda:0') MSE:  tensor(1.2198e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  946  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 95%|█████████▍| 946/1000 [1:00:52<03:28,  3.87s/it]Epoch:   947
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0335, device='cuda:0') mean:  tensor(-3.4470e-05, device='cuda:0') min:  tensor(-0.1238, device='cuda:0') norm:  tensor(0.3441, device='cuda:0') MSE:  tensor(1.2918e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  947  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  10
max of Lambda2 tensor(232.2885, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 95%|█████████▍| 947/1000 [1:00:55<03:23,  3.84s/it]Epoch:   948
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0363, device='cuda:0') mean:  tensor(-3.3086e-05, device='cuda:0') min:  tensor(-0.1128, device='cuda:0') norm:  tensor(0.3303, device='cuda:0') MSE:  tensor(1.2400e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  948  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 95%|█████████▍| 948/1000 [1:00:59<03:22,  3.90s/it]Epoch:   949
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0366, device='cuda:0') mean:  tensor(-3.5148e-05, device='cuda:0') min:  tensor(-0.1187, device='cuda:0') norm:  tensor(0.3392, device='cuda:0') MSE:  tensor(1.2732e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  949  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 95%|█████████▍| 949/1000 [1:01:03<03:20,  3.94s/it]Epoch:   950
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0366, device='cuda:0') mean:  tensor(-3.1464e-05, device='cuda:0') min:  tensor(-0.0986, device='cuda:0') norm:  tensor(0.3096, device='cuda:0') MSE:  tensor(1.1622e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  950  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(232.2889, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  3
 95%|█████████▌| 950/1000 [1:01:07<03:18,  3.97s/it]Epoch:   951
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0370, device='cuda:0') mean:  tensor(-3.1074e-05, device='cuda:0') min:  tensor(-0.1118, device='cuda:0') norm:  tensor(0.3128, device='cuda:0') MSE:  tensor(1.1741e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  951  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  0.0 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  3
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 95%|█████████▌| 951/1000 [1:01:11<03:15,  3.98s/it]Epoch:   952
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0351, device='cuda:0') mean:  tensor(-3.6817e-05, device='cuda:0') min:  tensor(-0.1145, device='cuda:0') norm:  tensor(0.3476, device='cuda:0') MSE:  tensor(1.3048e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  952  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 95%|█████████▌| 952/1000 [1:01:15<03:09,  3.96s/it]Epoch:   953
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0340, device='cuda:0') mean:  tensor(-3.3347e-05, device='cuda:0') min:  tensor(-0.1160, device='cuda:0') norm:  tensor(0.3296, device='cuda:0') MSE:  tensor(1.2371e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  953  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 95%|█████████▌| 953/1000 [1:01:19<03:03,  3.90s/it]Epoch:   954
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0388, device='cuda:0') mean:  tensor(-3.6777e-05, device='cuda:0') min:  tensor(-0.1156, device='cuda:0') norm:  tensor(0.3548, device='cuda:0') MSE:  tensor(1.3318e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  954  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(607.9130, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 95%|█████████▌| 954/1000 [1:01:23<02:55,  3.82s/it]Epoch:   955
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0391, device='cuda:0') mean:  tensor(-3.1208e-05, device='cuda:0') min:  tensor(-0.1118, device='cuda:0') norm:  tensor(0.3243, device='cuda:0') MSE:  tensor(1.2174e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  955  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2886, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 96%|█████████▌| 955/1000 [1:01:27<02:52,  3.84s/it]Epoch:   956
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0341, device='cuda:0') mean:  tensor(-3.3032e-05, device='cuda:0') min:  tensor(-0.0994, device='cuda:0') norm:  tensor(0.3174, device='cuda:0') MSE:  tensor(1.1916e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  956  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 96%|█████████▌| 956/1000 [1:01:30<02:46,  3.79s/it]Epoch:   957
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0350, device='cuda:0') mean:  tensor(-3.3922e-05, device='cuda:0') min:  tensor(-0.1111, device='cuda:0') norm:  tensor(0.3342, device='cuda:0') MSE:  tensor(1.2546e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  957  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  8
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 96%|█████████▌| 957/1000 [1:01:34<02:42,  3.78s/it]Epoch:   958
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0407, device='cuda:0') mean:  tensor(-3.2759e-05, device='cuda:0') min:  tensor(-0.1136, device='cuda:0') norm:  tensor(0.3359, device='cuda:0') MSE:  tensor(1.2608e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  958  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 96%|█████████▌| 958/1000 [1:01:38<02:41,  3.86s/it]Epoch:   959
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0392, device='cuda:0') mean:  tensor(-3.5555e-05, device='cuda:0') min:  tensor(-0.1165, device='cuda:0') norm:  tensor(0.3525, device='cuda:0') MSE:  tensor(1.3232e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  959  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2894, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 96%|█████████▌| 959/1000 [1:01:42<02:40,  3.91s/it]Epoch:   960
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0338, device='cuda:0') mean:  tensor(-3.3868e-05, device='cuda:0') min:  tensor(-0.1014, device='cuda:0') norm:  tensor(0.3236, device='cuda:0') MSE:  tensor(1.2147e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  960  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 96%|█████████▌| 960/1000 [1:01:46<02:35,  3.90s/it]Epoch:   961
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0442, device='cuda:0') mean:  tensor(-3.3002e-05, device='cuda:0') min:  tensor(-0.1091, device='cuda:0') norm:  tensor(0.3415, device='cuda:0') MSE:  tensor(1.2819e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  961  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 96%|█████████▌| 961/1000 [1:01:50<02:31,  3.89s/it]Epoch:   962
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0334, device='cuda:0') mean:  tensor(-3.5402e-05, device='cuda:0') min:  tensor(-0.1128, device='cuda:0') norm:  tensor(0.3352, device='cuda:0') MSE:  tensor(1.2581e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  962  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  11
 96%|█████████▌| 962/1000 [1:01:54<02:29,  3.93s/it]Epoch:   963
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0358, device='cuda:0') mean:  tensor(-3.2310e-05, device='cuda:0') min:  tensor(-0.0964, device='cuda:0') norm:  tensor(0.3099, device='cuda:0') MSE:  tensor(1.1632e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  963  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  11
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 96%|█████████▋| 963/1000 [1:01:58<02:22,  3.86s/it]Epoch:   964
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0444, device='cuda:0') mean:  tensor(-3.1472e-05, device='cuda:0') min:  tensor(-0.1063, device='cuda:0') norm:  tensor(0.3255, device='cuda:0') MSE:  tensor(1.2220e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  964  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 96%|█████████▋| 964/1000 [1:02:02<02:20,  3.90s/it]Epoch:   965
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0389, device='cuda:0') mean:  tensor(-3.6321e-05, device='cuda:0') min:  tensor(-0.1188, device='cuda:0') norm:  tensor(0.3515, device='cuda:0') MSE:  tensor(1.3196e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  965  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  6
max of Lambda2 tensor(232.2874, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 96%|█████████▋| 965/1000 [1:02:06<02:16,  3.91s/it]Epoch:   966
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0369, device='cuda:0') mean:  tensor(-3.4145e-05, device='cuda:0') min:  tensor(-0.1239, device='cuda:0') norm:  tensor(0.3442, device='cuda:0') MSE:  tensor(1.2921e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  966  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 97%|█████████▋| 966/1000 [1:02:09<02:11,  3.87s/it]Epoch:   967
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0359, device='cuda:0') mean:  tensor(-3.3205e-05, device='cuda:0') min:  tensor(-0.1208, device='cuda:0') norm:  tensor(0.3384, device='cuda:0') MSE:  tensor(1.2704e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  967  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 97%|█████████▋| 967/1000 [1:02:13<02:09,  3.92s/it]Epoch:   968
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0432, device='cuda:0') mean:  tensor(-3.3490e-05, device='cuda:0') min:  tensor(-0.1157, device='cuda:0') norm:  tensor(0.3387, device='cuda:0') MSE:  tensor(1.2715e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  968  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 97%|█████████▋| 968/1000 [1:02:17<02:05,  3.93s/it]Epoch:   969
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0352, device='cuda:0') mean:  tensor(-3.3648e-05, device='cuda:0') min:  tensor(-0.1108, device='cuda:0') norm:  tensor(0.3246, device='cuda:0') MSE:  tensor(1.2186e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  969  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  3.725290298461914e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  13
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2892, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 97%|█████████▋| 969/1000 [1:02:21<02:02,  3.94s/it]Epoch:   970
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0308, device='cuda:0') mean:  tensor(-3.2972e-05, device='cuda:0') min:  tensor(-0.0993, device='cuda:0') norm:  tensor(0.3131, device='cuda:0') MSE:  tensor(1.1753e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  970  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  5
max of Lambda2 tensor(607.9006, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 97%|█████████▋| 970/1000 [1:02:25<01:56,  3.90s/it]Epoch:   971
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0436, device='cuda:0') mean:  tensor(-3.4688e-05, device='cuda:0') min:  tensor(-0.1099, device='cuda:0') norm:  tensor(0.3459, device='cuda:0') MSE:  tensor(1.2984e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  971  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 97%|█████████▋| 971/1000 [1:02:29<01:50,  3.80s/it]Epoch:   972
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0367, device='cuda:0') mean:  tensor(-3.1993e-05, device='cuda:0') min:  tensor(-0.1085, device='cuda:0') norm:  tensor(0.3196, device='cuda:0') MSE:  tensor(1.1996e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  972  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 97%|█████████▋| 972/1000 [1:02:33<01:48,  3.88s/it]Epoch:   973
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0428, device='cuda:0') mean:  tensor(-3.6448e-05, device='cuda:0') min:  tensor(-0.1178, device='cuda:0') norm:  tensor(0.3599, device='cuda:0') MSE:  tensor(1.3509e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  973  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2892, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 97%|█████████▋| 973/1000 [1:02:36<01:43,  3.84s/it]Epoch:   974
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0343, device='cuda:0') mean:  tensor(-3.2798e-05, device='cuda:0') min:  tensor(-0.1002, device='cuda:0') norm:  tensor(0.3192, device='cuda:0') MSE:  tensor(1.1984e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  974  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  14
 97%|█████████▋| 974/1000 [1:02:40<01:40,  3.88s/it]Epoch:   975
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0318, device='cuda:0') mean:  tensor(-3.3151e-05, device='cuda:0') min:  tensor(-0.1110, device='cuda:0') norm:  tensor(0.3208, device='cuda:0') MSE:  tensor(1.2041e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  975  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  6.969379981558661e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  14
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2886, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 98%|█████████▊| 975/1000 [1:02:45<01:38,  3.95s/it]Epoch:   976
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0329, device='cuda:0') mean:  tensor(-3.4083e-05, device='cuda:0') min:  tensor(-0.1227, device='cuda:0') norm:  tensor(0.3469, device='cuda:0') MSE:  tensor(1.3021e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  976  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  9
max of Lambda2 tensor(607.9056, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 98%|█████████▊| 976/1000 [1:02:48<01:31,  3.82s/it]Epoch:   977
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0373, device='cuda:0') mean:  tensor(-3.3655e-05, device='cuda:0') min:  tensor(-0.1046, device='cuda:0') norm:  tensor(0.3283, device='cuda:0') MSE:  tensor(1.2324e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  977  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(232.2874, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 98%|█████████▊| 977/1000 [1:02:52<01:28,  3.87s/it]Epoch:   978
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0370, device='cuda:0') mean:  tensor(-3.5928e-05, device='cuda:0') min:  tensor(-0.1282, device='cuda:0') norm:  tensor(0.3550, device='cuda:0') MSE:  tensor(1.3325e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  978  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9007, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 98%|█████████▊| 978/1000 [1:02:56<01:25,  3.89s/it]Epoch:   979
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0445, device='cuda:0') mean:  tensor(-3.8335e-05, device='cuda:0') min:  tensor(-0.1207, device='cuda:0') norm:  tensor(0.3734, device='cuda:0') MSE:  tensor(1.4016e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  979  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  6
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  16
 98%|█████████▊| 979/1000 [1:03:00<01:20,  3.83s/it]Epoch:   980
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0417, device='cuda:0') mean:  tensor(-3.5839e-05, device='cuda:0') min:  tensor(-0.1292, device='cuda:0') norm:  tensor(0.3614, device='cuda:0') MSE:  tensor(1.3566e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  980  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  16
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
 98%|█████████▊| 980/1000 [1:03:03<01:16,  3.83s/it]Epoch:   981
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0387, device='cuda:0') mean:  tensor(-3.3108e-05, device='cuda:0') min:  tensor(-0.1242, device='cuda:0') norm:  tensor(0.3432, device='cuda:0') MSE:  tensor(1.2884e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  981  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  6.96937998155866e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  7
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9135, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 98%|█████████▊| 981/1000 [1:03:07<01:11,  3.78s/it]Epoch:   982
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0358, device='cuda:0') mean:  tensor(-3.4048e-05, device='cuda:0') min:  tensor(-0.1022, device='cuda:0') norm:  tensor(0.3269, device='cuda:0') MSE:  tensor(1.2272e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  982  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 98%|█████████▊| 982/1000 [1:03:11<01:07,  3.78s/it]Epoch:   983
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0399, device='cuda:0') mean:  tensor(-3.4343e-05, device='cuda:0') min:  tensor(-0.1117, device='cuda:0') norm:  tensor(0.3431, device='cuda:0') MSE:  tensor(1.2878e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  983  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 98%|█████████▊| 983/1000 [1:03:15<01:04,  3.78s/it]Epoch:   984
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0347, device='cuda:0') mean:  tensor(-3.4884e-05, device='cuda:0') min:  tensor(-0.1183, device='cuda:0') norm:  tensor(0.3395, device='cuda:0') MSE:  tensor(1.2743e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  984  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  6
 98%|█████████▊| 984/1000 [1:03:19<01:01,  3.85s/it]Epoch:   985
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0321, device='cuda:0') mean:  tensor(-3.3119e-05, device='cuda:0') min:  tensor(-0.1024, device='cuda:0') norm:  tensor(0.3205, device='cuda:0') MSE:  tensor(1.2029e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  985  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  6
max of Lambda2 tensor(232.2881, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 98%|█████████▊| 985/1000 [1:03:23<00:58,  3.89s/it]Epoch:   986
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0320, device='cuda:0') mean:  tensor(-3.1933e-05, device='cuda:0') min:  tensor(-0.1139, device='cuda:0') norm:  tensor(0.3186, device='cuda:0') MSE:  tensor(1.1961e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  986  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494322335347533
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  9
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  9
 99%|█████████▊| 986/1000 [1:03:26<00:53,  3.81s/it]Epoch:   987
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0376, device='cuda:0') mean:  tensor(-3.2486e-05, device='cuda:0') min:  tensor(-0.1047, device='cuda:0') norm:  tensor(0.3211, device='cuda:0') MSE:  tensor(1.2055e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  987  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  5.890201144234053e-10 
thres:  1.0303718037903308e-05
Preserved_eigens number check:  9
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(232.2881, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  5
 99%|█████████▊| 987/1000 [1:03:30<00:48,  3.76s/it]Epoch:   988
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0378, device='cuda:0') mean:  tensor(-3.2477e-05, device='cuda:0') min:  tensor(-0.1108, device='cuda:0') norm:  tensor(0.3228, device='cuda:0') MSE:  tensor(1.2118e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  988  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  5
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  13
 99%|█████████▉| 988/1000 [1:03:34<00:45,  3.82s/it]Epoch:   989
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0399, device='cuda:0') mean:  tensor(-3.6179e-05, device='cuda:0') min:  tensor(-0.1208, device='cuda:0') norm:  tensor(0.3523, device='cuda:0') MSE:  tensor(1.3225e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  989  
Training Loss: 0.010303717106580734
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  13
max of Lambda2 tensor(607.9097, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 99%|█████████▉| 989/1000 [1:03:38<00:42,  3.87s/it]Epoch:   990
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0336, device='cuda:0') mean:  tensor(-3.3329e-05, device='cuda:0') min:  tensor(-0.0960, device='cuda:0') norm:  tensor(0.3119, device='cuda:0') MSE:  tensor(1.1709e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  990  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
 99%|█████████▉| 990/1000 [1:03:42<00:39,  3.92s/it]Epoch:   991
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0420, device='cuda:0') mean:  tensor(-3.1681e-05, device='cuda:0') min:  tensor(-0.1165, device='cuda:0') norm:  tensor(0.3319, device='cuda:0') MSE:  tensor(1.2457e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  991  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  12
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 99%|█████████▉| 991/1000 [1:03:45<00:33,  3.72s/it]Epoch:   992
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0384, device='cuda:0') mean:  tensor(-3.3459e-05, device='cuda:0') min:  tensor(-0.1011, device='cuda:0') norm:  tensor(0.3209, device='cuda:0') MSE:  tensor(1.2046e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  992  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
 99%|█████████▉| 992/1000 [1:03:49<00:29,  3.70s/it]Epoch:   993
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0377, device='cuda:0') mean:  tensor(-3.5724e-05, device='cuda:0') min:  tensor(-0.1198, device='cuda:0') norm:  tensor(0.3495, device='cuda:0') MSE:  tensor(1.3119e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  993  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
std:  6.969379981558661e-10 
thres:  1.0303718224167824e-05
Preserved_eigens number check:  10
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(607.9056, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 99%|█████████▉| 993/1000 [1:03:52<00:25,  3.68s/it]Epoch:   994
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0370, device='cuda:0') mean:  tensor(-3.2605e-05, device='cuda:0') min:  tensor(-0.1097, device='cuda:0') norm:  tensor(0.3201, device='cuda:0') MSE:  tensor(1.2014e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  994  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
 99%|█████████▉| 994/1000 [1:03:56<00:22,  3.77s/it]Epoch:   995
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0337, device='cuda:0') mean:  tensor(-3.2044e-05, device='cuda:0') min:  tensor(-0.1144, device='cuda:0') norm:  tensor(0.3217, device='cuda:0') MSE:  tensor(1.2077e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  995  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.001690216944552958
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
100%|█████████▉| 995/1000 [1:04:00<00:18,  3.80s/it]Epoch:   996
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0378, device='cuda:0') mean:  tensor(-3.5643e-05, device='cuda:0') min:  tensor(-0.1088, device='cuda:0') norm:  tensor(0.3403, device='cuda:0') MSE:  tensor(1.2773e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  996  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  7
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  8
100%|█████████▉| 996/1000 [1:04:04<00:15,  3.86s/it]Epoch:   997
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0405, device='cuda:0') mean:  tensor(-3.6081e-05, device='cuda:0') min:  tensor(-0.1186, device='cuda:0') norm:  tensor(0.3562, device='cuda:0') MSE:  tensor(1.3369e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  997  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  8
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  10
100%|█████████▉| 997/1000 [1:04:08<00:11,  3.88s/it]Epoch:   998
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0398, device='cuda:0') mean:  tensor(-3.1631e-05, device='cuda:0') min:  tensor(-0.1120, device='cuda:0') norm:  tensor(0.3276, device='cuda:0') MSE:  tensor(1.2296e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  998  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  10
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
100%|█████████▉| 998/1000 [1:04:12<00:07,  3.85s/it]Epoch:   999
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0326, device='cuda:0') mean:  tensor(-3.1203e-05, device='cuda:0') min:  tensor(-0.1096, device='cuda:0') norm:  tensor(0.3135, device='cuda:0') MSE:  tensor(1.1769e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  999  
Training Loss: 0.010303718969225883
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
std:  4.5625301874860716e-10 
thres:  1.0303718596696854e-05
Preserved_eigens number check:  7
**************************************************learning rate decay**************************************************
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  7
100%|█████████▉| 999/1000 [1:04:16<00:03,  3.83s/it]Epoch:   1000
max of grad d_p:  tensor(0.0026, device='cuda:0')
min of grad d_p:  tensor(-0.0019, device='cuda:0')

 check Jacobi res:  torch.Size([266401]) max:  tensor(0.0372, device='cuda:0') mean:  tensor(-3.4060e-05, device='cuda:0') min:  tensor(-0.1216, device='cuda:0') norm:  tensor(0.3426, device='cuda:0') MSE:  tensor(1.2858e-06, device='cuda:0')
BAD Jacobian OCCURS! Gradient Descent instead!
Shape check:  torch.Size([266401, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0019, device='cuda:0')
Epoch:  1000  
Training Loss: 0.010303718037903309
Test Loss:  0.0016494321171194315
Test Acc:  0.0
Valid Loss:  0.0016902170609682798
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  7
max of Lambda2 tensor(607.9008, device='cuda:0')
min of Lambda2 tensor(0., device='cuda:0')
eigenvalues preserved:  12
100%|██████████| 1000/1000 [1:04:20<00:00,  3.81s/it]100%|██████████| 1000/1000 [1:04:20<00:00,  3.86s/it]
