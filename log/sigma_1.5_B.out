train data shape torch.Size([256, 2])
train label shape torch.Size([256, 1])
torch.Size([256, 3])
train_data shape torch.Size([3])
seed is  1
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]/home/yuyi/Documents/ModifiedNGD/utils/readData.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)
  0%|          | 1/500 [00:00<03:27,  2.41it/s]  1%|          | 3/500 [00:00<01:17,  6.43it/s]  1%|          | 5/500 [00:00<00:52,  9.38it/s]  1%|▏         | 7/500 [00:00<00:43, 11.42it/s]  2%|▏         | 9/500 [00:00<00:38, 12.88it/s]  2%|▏         | 11/500 [00:01<00:35, 13.69it/s]  3%|▎         | 13/500 [00:01<00:34, 14.17it/s]  3%|▎         | 15/500 [00:01<00:32, 14.84it/s]  3%|▎         | 17/500 [00:01<00:31, 15.23it/s]  4%|▍         | 19/500 [00:01<00:31, 15.26it/s]  4%|▍         | 21/500 [00:01<00:31, 15.40it/s]  5%|▍         | 23/500 [00:01<00:31, 15.33it/s]  5%|▌         | 25/500 [00:01<00:30, 15.47it/s]  5%|▌         | 27/500 [00:02<00:30, 15.48it/s]  6%|▌         | 29/500 [00:02<00:30, 15.64it/s]  6%|▌         | 31/500 [00:02<00:30, 15.59it/s]  7%|▋         | 33/500 [00:02<00:29, 15.80it/s]  7%|▋         | 35/500 [00:02<00:29, 15.87it/s]  7%|▋         | 37/500 [00:02<00:28, 15.99it/s]  8%|▊         | 39/500 [00:02<00:28, 16.16it/s]  8%|▊         | 41/500 [00:02<00:28, 16.32it/s]  9%|▊         | 43/500 [00:03<00:30, 14.90it/s]  9%|▉         | 45/500 [00:03<00:30, 14.77it/s]  9%|▉         | 47/500 [00:03<00:31, 14.20it/s] 10%|▉         | 49/500 [00:03<00:30, 14.72it/s] 10%|█         | 51/500 [00:03<00:29, 15.10it/s] 11%|█         | 53/500 [00:03<00:29, 15.41it/s] 11%|█         | 55/500 [00:03<00:28, 15.43it/s] 11%|█▏        | 57/500 [00:04<00:28, 15.52it/s] 12%|█▏        | 59/500 [00:04<00:28, 15.74it/s] 12%|█▏        | 61/500 [00:04<00:27, 15.84it/s] 13%|█▎        | 63/500 [00:04<00:27, 15.98it/s] 13%|█▎        | 65/500 [00:04<00:27, 15.81it/s] 13%|█▎        | 67/500 [00:04<00:27, 15.78it/s] 14%|█▍        | 69/500 [00:04<00:27, 15.79it/s] 14%|█▍        | 71/500 [00:04<00:27, 15.53it/s] 15%|█▍        | 73/500 [00:05<00:27, 15.73it/s] 15%|█▌        | 75/500 [00:05<00:26, 15.90it/s] 15%|█▌        | 77/500 [00:05<00:26, 16.11it/s] 16%|█▌        | 79/500 [00:05<00:26, 16.11it/s] 16%|█▌        | 81/500 [00:05<00:25, 16.21it/s] 17%|█▋        | 83/500 [00:05<00:25, 16.17it/s] 17%|█▋        | 85/500 [00:05<00:25, 16.07it/s] 17%|█▋        | 87/500 [00:05<00:25, 15.95it/s] 18%|█▊        | 89/500 [00:06<00:26, 15.38it/s] 18%|█▊        | 91/500 [00:06<00:26, 15.54it/s] 19%|█▊        | 93/500 [00:06<00:26, 15.59it/s] 19%|█▉        | 95/500 [00:06<00:25, 15.67it/s] 19%|█▉        | 97/500 [00:06<00:25, 15.72it/s] 20%|█▉        | 99/500 [00:06<00:25, 15.59it/s] 20%|██        | 101/500 [00:06<00:25, 15.75it/s] 21%|██        | 103/500 [00:06<00:24, 15.90it/s] 21%|██        | 105/500 [00:07<00:25, 15.75it/s] 21%|██▏       | 107/500 [00:07<00:25, 15.44it/s] 22%|██▏       | 109/500 [00:07<00:25, 15.56it/s] 22%|██▏       | 111/500 [00:07<00:24, 15.78it/s] 23%|██▎       | 113/500 [00:07<00:24, 15.63it/s] 23%|██▎       | 115/500 [00:07<00:24, 15.65it/s] 23%|██▎       | 117/500 [00:07<00:24, 15.86it/s] 24%|██▍       | 119/500 [00:07<00:23, 15.92it/s] 24%|██▍       | 121/500 [00:08<00:23, 16.00it/s] 25%|██▍       | 123/500 [00:08<00:23, 15.85it/s]Epoch:  1  	Training Loss: 0.031477488577365875
Test Loss:  65.21719360351562
Valid Loss:  65.27482604980469
Epoch:  2  	Training Loss: 64.86914825439453
Test Loss:  7045155328.0
Valid Loss:  7053011968.0
Epoch:  3  	Training Loss: 7019601920.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 125/500 [00:08<00:23, 15.91it/s] 25%|██▌       | 127/500 [00:08<00:23, 16.10it/s] 26%|██▌       | 129/500 [00:08<00:22, 16.13it/s] 26%|██▌       | 131/500 [00:08<00:22, 16.25it/s] 27%|██▋       | 133/500 [00:08<00:23, 15.88it/s] 27%|██▋       | 135/500 [00:08<00:22, 16.06it/s] 27%|██▋       | 137/500 [00:09<00:22, 16.10it/s] 28%|██▊       | 139/500 [00:09<00:22, 16.07it/s] 28%|██▊       | 141/500 [00:09<00:22, 16.04it/s] 29%|██▊       | 143/500 [00:09<00:22, 15.56it/s] 29%|██▉       | 145/500 [00:09<00:22, 15.46it/s] 29%|██▉       | 147/500 [00:09<00:22, 15.54it/s] 30%|██▉       | 149/500 [00:09<00:22, 15.27it/s] 30%|███       | 151/500 [00:09<00:22, 15.47it/s] 31%|███       | 153/500 [00:10<00:22, 15.69it/s] 31%|███       | 155/500 [00:10<00:21, 15.80it/s] 31%|███▏      | 157/500 [00:10<00:21, 15.82it/s] 32%|███▏      | 159/500 [00:10<00:21, 15.70it/s] 32%|███▏      | 161/500 [00:10<00:21, 15.91it/s] 33%|███▎      | 163/500 [00:10<00:20, 16.08it/s] 33%|███▎      | 165/500 [00:10<00:20, 16.09it/s] 33%|███▎      | 167/500 [00:10<00:20, 16.14it/s] 34%|███▍      | 169/500 [00:11<00:20, 16.09it/s] 34%|███▍      | 171/500 [00:11<00:20, 16.17it/s] 35%|███▍      | 173/500 [00:11<00:20, 16.17it/s] 35%|███▌      | 175/500 [00:11<00:20, 16.06it/s] 35%|███▌      | 177/500 [00:11<00:20, 16.06it/s] 36%|███▌      | 179/500 [00:11<00:20, 15.76it/s] 36%|███▌      | 181/500 [00:11<00:20, 15.93it/s] 37%|███▋      | 183/500 [00:11<00:19, 15.96it/s] 37%|███▋      | 185/500 [00:12<00:19, 16.12it/s] 37%|███▋      | 187/500 [00:12<00:19, 16.02it/s] 38%|███▊      | 189/500 [00:12<00:19, 16.06it/s] 38%|███▊      | 191/500 [00:12<00:19, 15.97it/s] 39%|███▊      | 193/500 [00:12<00:19, 15.80it/s] 39%|███▉      | 195/500 [00:12<00:19, 15.92it/s] 39%|███▉      | 197/500 [00:12<00:19, 15.87it/s] 40%|███▉      | 199/500 [00:12<00:18, 16.01it/s] 40%|████      | 201/500 [00:13<00:18, 16.15it/s] 41%|████      | 203/500 [00:13<00:18, 15.94it/s] 41%|████      | 205/500 [00:13<00:18, 15.97it/s] 41%|████▏     | 207/500 [00:13<00:18, 15.93it/s] 42%|████▏     | 209/500 [00:13<00:18, 15.82it/s] 42%|████▏     | 211/500 [00:13<00:18, 15.56it/s] 43%|████▎     | 213/500 [00:13<00:18, 15.67it/s] 43%|████▎     | 215/500 [00:13<00:17, 15.89it/s] 43%|████▎     | 217/500 [00:14<00:17, 16.05it/s] 44%|████▍     | 219/500 [00:14<00:17, 16.10it/s] 44%|████▍     | 221/500 [00:14<00:17, 15.93it/s] 45%|████▍     | 223/500 [00:14<00:17, 15.96it/s] 45%|████▌     | 225/500 [00:14<00:17, 16.08it/s] 45%|████▌     | 227/500 [00:14<00:17, 15.84it/s] 46%|████▌     | 229/500 [00:14<00:16, 16.06it/s] 46%|████▌     | 231/500 [00:14<00:16, 16.07it/s] 47%|████▋     | 233/500 [00:15<00:16, 16.18it/s] 47%|████▋     | 235/500 [00:15<00:16, 16.18it/s] 47%|████▋     | 237/500 [00:15<00:16, 15.92it/s] 48%|████▊     | 239/500 [00:15<00:16, 15.78it/s] 48%|████▊     | 241/500 [00:15<00:16, 15.90it/s] 49%|████▊     | 243/500 [00:15<00:16, 15.97it/s] 49%|████▉     | 245/500 [00:15<00:15, 16.04it/s] 49%|████▉     | 247/500 [00:15<00:15, 16.04it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|████▉     | 249/500 [00:16<00:15, 16.06it/s] 50%|█████     | 251/500 [00:16<00:15, 16.21it/s] 51%|█████     | 253/500 [00:16<00:15, 16.21it/s] 51%|█████     | 255/500 [00:16<00:15, 16.08it/s] 51%|█████▏    | 257/500 [00:16<00:15, 16.12it/s] 52%|█████▏    | 259/500 [00:16<00:14, 16.14it/s] 52%|█████▏    | 261/500 [00:16<00:14, 16.21it/s] 53%|█████▎    | 263/500 [00:16<00:14, 16.20it/s] 53%|█████▎    | 265/500 [00:17<00:14, 16.19it/s] 53%|█████▎    | 267/500 [00:17<00:14, 16.05it/s] 54%|█████▍    | 269/500 [00:17<00:14, 15.86it/s] 54%|█████▍    | 271/500 [00:17<00:14, 15.99it/s] 55%|█████▍    | 273/500 [00:17<00:14, 16.07it/s] 55%|█████▌    | 275/500 [00:17<00:13, 16.09it/s] 55%|█████▌    | 277/500 [00:17<00:13, 16.17it/s] 56%|█████▌    | 279/500 [00:17<00:13, 16.18it/s] 56%|█████▌    | 281/500 [00:18<00:13, 16.14it/s] 57%|█████▋    | 283/500 [00:18<00:13, 16.16it/s] 57%|█████▋    | 285/500 [00:18<00:13, 16.18it/s] 57%|█████▋    | 287/500 [00:18<00:13, 15.61it/s] 58%|█████▊    | 289/500 [00:18<00:13, 15.83it/s] 58%|█████▊    | 291/500 [00:18<00:17, 12.05it/s] 59%|█████▊    | 293/500 [00:18<00:15, 12.98it/s] 59%|█████▉    | 295/500 [00:19<00:14, 13.73it/s] 59%|█████▉    | 297/500 [00:19<00:14, 14.39it/s] 60%|█████▉    | 299/500 [00:19<00:13, 14.92it/s] 60%|██████    | 301/500 [00:19<00:13, 15.26it/s] 61%|██████    | 303/500 [00:19<00:12, 15.36it/s] 61%|██████    | 305/500 [00:19<00:12, 15.62it/s] 61%|██████▏   | 307/500 [00:19<00:12, 15.84it/s] 62%|██████▏   | 309/500 [00:19<00:11, 16.02it/s] 62%|██████▏   | 311/500 [00:20<00:11, 15.93it/s] 63%|██████▎   | 313/500 [00:20<00:11, 15.88it/s] 63%|██████▎   | 315/500 [00:20<00:11, 15.96it/s] 63%|██████▎   | 317/500 [00:20<00:11, 16.02it/s] 64%|██████▍   | 319/500 [00:20<00:11, 15.97it/s] 64%|██████▍   | 321/500 [00:20<00:11, 15.73it/s] 65%|██████▍   | 323/500 [00:20<00:12, 14.54it/s] 65%|██████▌   | 325/500 [00:20<00:11, 14.93it/s] 65%|██████▌   | 327/500 [00:21<00:11, 15.00it/s] 66%|██████▌   | 329/500 [00:21<00:11, 15.35it/s] 66%|██████▌   | 331/500 [00:21<00:10, 15.53it/s] 67%|██████▋   | 333/500 [00:21<00:10, 15.59it/s] 67%|██████▋   | 335/500 [00:21<00:10, 15.60it/s] 67%|██████▋   | 337/500 [00:21<00:10, 15.73it/s] 68%|██████▊   | 339/500 [00:21<00:10, 15.76it/s] 68%|██████▊   | 341/500 [00:22<00:10, 15.66it/s] 69%|██████▊   | 343/500 [00:22<00:09, 15.78it/s] 69%|██████▉   | 345/500 [00:22<00:09, 15.66it/s] 69%|██████▉   | 347/500 [00:22<00:09, 15.81it/s] 70%|██████▉   | 349/500 [00:22<00:09, 15.93it/s] 70%|███████   | 351/500 [00:22<00:09, 16.08it/s] 71%|███████   | 353/500 [00:22<00:09, 16.15it/s] 71%|███████   | 355/500 [00:22<00:08, 16.17it/s] 71%|███████▏  | 357/500 [00:23<00:08, 16.26it/s] 72%|███████▏  | 359/500 [00:23<00:08, 16.23it/s] 72%|███████▏  | 361/500 [00:23<00:08, 16.13it/s] 73%|███████▎  | 363/500 [00:23<00:08, 16.02it/s] 73%|███████▎  | 365/500 [00:23<00:08, 16.06it/s] 73%|███████▎  | 367/500 [00:23<00:08, 16.20it/s] 74%|███████▍  | 369/500 [00:23<00:08, 16.15it/s] 74%|███████▍  | 371/500 [00:23<00:08, 16.03it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 373/500 [00:24<00:07, 15.99it/s] 75%|███████▌  | 375/500 [00:24<00:07, 15.95it/s] 75%|███████▌  | 377/500 [00:24<00:07, 15.69it/s] 76%|███████▌  | 379/500 [00:24<00:07, 15.47it/s] 76%|███████▌  | 381/500 [00:24<00:07, 15.56it/s] 77%|███████▋  | 383/500 [00:24<00:07, 15.71it/s] 77%|███████▋  | 385/500 [00:24<00:07, 15.72it/s] 77%|███████▋  | 387/500 [00:24<00:07, 15.83it/s] 78%|███████▊  | 389/500 [00:25<00:07, 15.77it/s] 78%|███████▊  | 391/500 [00:25<00:06, 15.83it/s] 79%|███████▊  | 393/500 [00:25<00:06, 15.74it/s] 79%|███████▉  | 395/500 [00:25<00:06, 15.88it/s] 79%|███████▉  | 397/500 [00:25<00:06, 15.96it/s] 80%|███████▉  | 399/500 [00:25<00:06, 16.01it/s] 80%|████████  | 401/500 [00:25<00:06, 15.91it/s] 81%|████████  | 403/500 [00:25<00:06, 15.99it/s] 81%|████████  | 405/500 [00:26<00:05, 15.96it/s] 81%|████████▏ | 407/500 [00:26<00:05, 15.87it/s] 82%|████████▏ | 409/500 [00:26<00:05, 15.85it/s] 82%|████████▏ | 411/500 [00:26<00:05, 15.32it/s] 83%|████████▎ | 413/500 [00:26<00:05, 15.42it/s] 83%|████████▎ | 415/500 [00:26<00:05, 15.68it/s] 83%|████████▎ | 417/500 [00:26<00:05, 15.78it/s] 84%|████████▍ | 419/500 [00:26<00:05, 15.87it/s] 84%|████████▍ | 421/500 [00:27<00:04, 16.01it/s] 85%|████████▍ | 423/500 [00:27<00:04, 15.90it/s] 85%|████████▌ | 425/500 [00:27<00:04, 15.64it/s] 85%|████████▌ | 427/500 [00:27<00:04, 15.35it/s] 86%|████████▌ | 429/500 [00:27<00:04, 15.43it/s] 86%|████████▌ | 431/500 [00:27<00:04, 15.68it/s] 87%|████████▋ | 433/500 [00:27<00:04, 15.76it/s] 87%|████████▋ | 435/500 [00:27<00:04, 15.95it/s] 87%|████████▋ | 437/500 [00:28<00:03, 16.01it/s] 88%|████████▊ | 439/500 [00:28<00:03, 16.07it/s] 88%|████████▊ | 441/500 [00:28<00:03, 15.86it/s] 89%|████████▊ | 443/500 [00:28<00:03, 16.01it/s] 89%|████████▉ | 445/500 [00:28<00:03, 16.03it/s] 89%|████████▉ | 447/500 [00:28<00:03, 16.07it/s] 90%|████████▉ | 449/500 [00:28<00:03, 16.21it/s] 90%|█████████ | 451/500 [00:28<00:03, 16.21it/s] 91%|█████████ | 453/500 [00:29<00:02, 16.17it/s] 91%|█████████ | 455/500 [00:29<00:02, 16.22it/s] 91%|█████████▏| 457/500 [00:29<00:02, 16.21it/s] 92%|█████████▏| 459/500 [00:29<00:02, 16.29it/s] 92%|█████████▏| 461/500 [00:29<00:02, 16.20it/s] 93%|█████████▎| 463/500 [00:29<00:02, 16.31it/s] 93%|█████████▎| 465/500 [00:29<00:02, 16.26it/s] 93%|█████████▎| 467/500 [00:29<00:02, 16.35it/s] 94%|█████████▍| 469/500 [00:30<00:01, 16.35it/s] 94%|█████████▍| 471/500 [00:30<00:01, 16.25it/s] 95%|█████████▍| 473/500 [00:30<00:01, 16.22it/s] 95%|█████████▌| 475/500 [00:30<00:01, 16.11it/s] 95%|█████████▌| 477/500 [00:30<00:01, 16.19it/s] 96%|█████████▌| 479/500 [00:30<00:01, 16.23it/s] 96%|█████████▌| 481/500 [00:30<00:01, 16.26it/s] 97%|█████████▋| 483/500 [00:30<00:01, 16.23it/s] 97%|█████████▋| 485/500 [00:31<00:00, 15.82it/s] 97%|█████████▋| 487/500 [00:31<00:00, 16.04it/s] 98%|█████████▊| 489/500 [00:31<00:00, 16.14it/s] 98%|█████████▊| 491/500 [00:31<00:00, 16.20it/s] 99%|█████████▊| 493/500 [00:31<00:00, 16.08it/s] 99%|█████████▉| 495/500 [00:31<00:00, 15.84it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 99%|█████████▉| 497/500 [00:31<00:00, 15.85it/s]100%|█████████▉| 499/500 [00:31<00:00, 15.93it/s]100%|██████████| 500/500 [00:31<00:00, 15.64it/s]
/home/yuyi/anaconda3/envs/ng/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343967769/work/torch/csrc/autograd/engine.cpp:1151.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  1
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:18,  6.17s/it]  1%|          | 3/500 [00:06<13:39,  1.65s/it]  1%|          | 5/500 [00:06<06:53,  1.20it/s]  1%|▏         | 7/500 [00:06<04:10,  1.97it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:12<10:46,  1.32s/it]  3%|▎         | 13/500 [00:13<07:21,  1.10it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:19<09:30,  1.19s/it]  5%|▍         | 23/500 [00:19<06:44,  1.18it/s]  5%|▌         | 25/500 [00:20<04:49,  1.64it/s]  5%|▌         | 27/500 [00:20<03:30,  2.25it/s]  6%|▌         | 29/500 [00:20<02:35,  3.03it/s]  6%|▌         | 31/500 [00:26<09:08,  1.17s/it]  7%|▋         | 33/500 [00:26<06:32,  1.19it/s]  7%|▋         | 35/500 [00:26<04:42,  1.65it/s]  7%|▋         | 37/500 [00:26<03:25,  2.25it/s]  8%|▊         | 39/500 [00:27<02:32,  3.02it/s]  8%|▊         | 41/500 [00:33<08:54,  1.16s/it]  9%|▊         | 43/500 [00:33<06:22,  1.19it/s]  9%|▉         | 45/500 [00:33<04:35,  1.65it/s]  9%|▉         | 47/500 [00:33<03:21,  2.25it/s] 10%|▉         | 49/500 [00:33<02:29,  3.02it/s] 10%|█         | 51/500 [00:40<08:52,  1.19s/it] 11%|█         | 53/500 [00:40<06:20,  1.17it/s] 11%|█         | 55/500 [00:40<04:34,  1.62it/s] 11%|█▏        | 57/500 [00:40<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:40<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:47<08:42,  1.19s/it] 13%|█▎        | 63/500 [00:47<06:13,  1.17it/s] 13%|█▎        | 65/500 [00:47<04:28,  1.62it/s] 13%|█▎        | 67/500 [00:47<03:15,  2.21it/s] 14%|█▍        | 69/500 [00:47<02:24,  2.98it/s] 14%|█▍        | 71/500 [00:54<08:30,  1.19s/it]Epoch:  1  	Training Loss: 0.031477488577365875
Test Loss:  0.9941449761390686
Valid Loss:  0.9927686452865601
Epoch:  2  	Training Loss: 1.0495554208755493
Test Loss:  5.485337734222412
Valid Loss:  5.4591875076293945
Epoch:  3  	Training Loss: 5.692251205444336
Test Loss:  0.03492729365825653
Valid Loss:  0.031094448640942574
Epoch:  4  	Training Loss: 0.04617185890674591
Test Loss:  0.034912578761577606
Valid Loss:  0.031081009656190872
Epoch:  5  	Training Loss: 0.046150535345077515
Test Loss:  0.03489787131547928
Valid Loss:  0.03106759488582611
Epoch:  6  	Training Loss: 0.04612923040986061
Test Loss:  0.034883178770542145
Valid Loss:  0.03105418011546135
Epoch:  7  	Training Loss: 0.0461079403758049
Test Loss:  0.034868497401475906
Valid Loss:  0.031040789559483528
Epoch:  8  	Training Loss: 0.046086668968200684
Test Loss:  0.03485384210944176
Valid Loss:  0.031027408316731453
Epoch:  9  	Training Loss: 0.04606541991233826
Test Loss:  0.0348392054438591
Valid Loss:  0.03101404570043087
Epoch:  10  	Training Loss: 0.046044185757637024
Test Loss:  0.03482457995414734
Valid Loss:  0.031000696122646332
Epoch:  11  	Training Loss: 0.046022966504096985
Test Loss:  0.034809961915016174
Valid Loss:  0.03098735772073269
Epoch:  12  	Training Loss: 0.04600176960229874
Test Loss:  0.03479421138763428
Valid Loss:  0.030972983688116074
Epoch:  13  	Training Loss: 0.04597891867160797
Test Loss:  0.03478291258215904
Valid Loss:  0.03096233867108822
Epoch:  14  	Training Loss: 0.045963894575834274
Test Loss:  0.03478125482797623
Valid Loss:  0.030960040166974068
Epoch:  15  	Training Loss: 0.045961011201143265
Test Loss:  0.03477960079908371
Valid Loss:  0.030958322808146477
Epoch:  16  	Training Loss: 0.045958489179611206
Test Loss:  0.034777965396642685
Valid Loss:  0.030956793576478958
Epoch:  17  	Training Loss: 0.0459560789167881
Test Loss:  0.03477632626891136
Valid Loss:  0.030955281108617783
Epoch:  18  	Training Loss: 0.045953717082738876
Test Loss:  0.03477469086647034
Valid Loss:  0.030953768640756607
Epoch:  19  	Training Loss: 0.04595135524868965
Test Loss:  0.03477303683757782
Valid Loss:  0.030952248722314835
Epoch:  20  	Training Loss: 0.045948997139930725
Test Loss:  0.034771375358104706
Valid Loss:  0.030950721353292465
Epoch:  21  	Training Loss: 0.04594665765762329
Test Loss:  0.03476971015334129
Valid Loss:  0.030949175357818604
Epoch:  22  	Training Loss: 0.045944325625896454
Test Loss:  0.034765906631946564
Valid Loss:  0.030945701524615288
Epoch:  23  	Training Loss: 0.04593897983431816
Test Loss:  0.03476211428642273
Valid Loss:  0.030942223966121674
Epoch:  24  	Training Loss: 0.04593364894390106
Test Loss:  0.0347583070397377
Valid Loss:  0.030938731506466866
Epoch:  25  	Training Loss: 0.045928310602903366
Test Loss:  0.03475449979305267
Valid Loss:  0.030935246497392654
Epoch:  26  	Training Loss: 0.04592297226190567
Test Loss:  0.03475069999694824
Valid Loss:  0.03093177080154419
Epoch:  27  	Training Loss: 0.04591763764619827
Test Loss:  0.03474689647555351
Valid Loss:  0.03092828392982483
Epoch:  28  	Training Loss: 0.045912303030490875
Test Loss:  0.03474310040473938
Valid Loss:  0.030924798920750618
Epoch:  29  	Training Loss: 0.04590696468949318
Test Loss:  0.03473930060863495
Valid Loss:  0.03092132695019245
Epoch:  30  	Training Loss: 0.04590163752436638
Test Loss:  0.03473550081253052
Valid Loss:  0.03091784380376339
Epoch:  31  	Training Loss: 0.04589630663394928
Test Loss:  0.03473169356584549
Valid Loss:  0.03091435134410858
Epoch:  32  	Training Loss: 0.04589097574353218
Test Loss:  0.03472786769270897
Valid Loss:  0.030910849571228027
Epoch:  33  	Training Loss: 0.0458856076002121
Test Loss:  0.03472403436899185
Valid Loss:  0.030907336622476578
Epoch:  34  	Training Loss: 0.04588024318218231
Test Loss:  0.03472020477056503
Valid Loss:  0.030903827399015427
Epoch:  35  	Training Loss: 0.04587487876415253
Test Loss:  0.034716375172138214
Valid Loss:  0.03090031072497368
Epoch:  36  	Training Loss: 0.04586951807141304
Test Loss:  0.034712549299001694
Valid Loss:  0.030896812677383423
Epoch:  37  	Training Loss: 0.04586416110396385
Test Loss:  0.034708719700574875
Valid Loss:  0.030893299728631973
Epoch:  38  	Training Loss: 0.04585879668593407
Test Loss:  0.03470489755272865
Valid Loss:  0.030889801681041718
Epoch:  39  	Training Loss: 0.04585344344377518
Test Loss:  0.03470107167959213
Valid Loss:  0.030886292457580566
Epoch:  40  	Training Loss: 0.04584807902574539
Test Loss:  0.03469724953174591
Valid Loss:  0.03088279813528061
Epoch:  41  	Training Loss: 0.0458427295088768
Test Loss:  0.034693434834480286
Valid Loss:  0.030879300087690353
Epoch:  42  	Training Loss: 0.04583737254142761
Test Loss:  0.0346897691488266
Valid Loss:  0.030875932425260544
Epoch:  43  	Training Loss: 0.04583224654197693
Test Loss:  0.034686099737882614
Valid Loss:  0.030872583389282227
Epoch:  44  	Training Loss: 0.045827120542526245
Test Loss:  0.03468243405222893
Valid Loss:  0.030869213864207268
Epoch:  45  	Training Loss: 0.04582199454307556
Test Loss:  0.03467877581715584
Valid Loss:  0.0308658629655838
Epoch:  46  	Training Loss: 0.04581686854362488
Test Loss:  0.03467511385679245
Valid Loss:  0.030862508341670036
Epoch:  47  	Training Loss: 0.04581174999475479
Test Loss:  0.03467145189642906
Valid Loss:  0.030859149992465973
Epoch:  48  	Training Loss: 0.04580662399530411
Test Loss:  0.034667789936065674
Valid Loss:  0.030855804681777954
Epoch:  49  	Training Loss: 0.04580150172114372
Test Loss:  0.03466413915157318
Valid Loss:  0.03085245192050934
Epoch:  50  	Training Loss: 0.045796386897563934
Test Loss:  0.03466048091650009
Valid Loss:  0.03084910288453102
Epoch:  51  	Training Loss: 0.04579126462340355
Test Loss:  0.034656822681427
Valid Loss:  0.030845746397972107
Epoch:  52  	Training Loss: 0.04578614979982376
Test Loss:  0.03465341776609421
Valid Loss:  0.030842624604701996
Epoch:  53  	Training Loss: 0.045781392604112625
Test Loss:  0.034650012850761414
Valid Loss:  0.030839502811431885
Epoch:  54  	Training Loss: 0.04577663540840149
Test Loss:  0.03464658930897713
Valid Loss:  0.03083636984229088
Epoch:  55  	Training Loss: 0.04577187821269035
Test Loss:  0.03464319184422493
Valid Loss:  0.030833251774311066
Epoch:  56  	Training Loss: 0.04576712101697922
Test Loss:  0.034639790654182434
Valid Loss:  0.030830133706331253
Epoch:  57  	Training Loss: 0.04576236382126808
Test Loss:  0.03463638573884964
Valid Loss:  0.03082701563835144
Epoch:  58  	Training Loss: 0.045757606625556946
Test Loss:  0.034632984548807144
Valid Loss:  0.03082389384508133
Epoch:  59  	Training Loss: 0.045752860605716705
Test Loss:  0.03462957218289375
Valid Loss:  0.03082076460123062
Epoch:  60  	Training Loss: 0.04574809968471527
Test Loss:  0.03462616726756096
Valid Loss:  0.030817650258541107
Epoch:  61  	Training Loss: 0.04574335366487503
Test Loss:  0.03462277352809906
Valid Loss:  0.030814532190561295
Epoch:  62  	Training Loss: 0.04573860019445419
Test Loss:  0.03461962193250656
Valid Loss:  0.030811646953225136
Epoch:  63  	Training Loss: 0.0457342155277729
Test Loss:  0.034616466611623764
Valid Loss:  0.03080875240266323
Epoch:  64  	Training Loss: 0.045729830861091614
Test Loss:  0.034613318741321564
Valid Loss:  0.03080587089061737
Epoch:  65  	Training Loss: 0.045725446194410324
Test Loss:  0.034610167145729065
Valid Loss:  0.030802981927990913
Epoch:  66  	Training Loss: 0.04572105407714844
Test Loss:  0.03460700809955597
Valid Loss:  0.03080008178949356
Epoch:  67  	Training Loss: 0.045716673135757446
Test Loss:  0.03460386395454407
Valid Loss:  0.030797194689512253
Epoch:  68  	Training Loss: 0.04571228846907616
Test Loss:  0.03460071235895157
Valid Loss:  0.030794303864240646
Epoch:  69  	Training Loss: 0.045707907527685165
Test Loss:  0.03459756821393967
Valid Loss:  0.030791422352194786
Epoch:  70  	Training Loss: 0.04570353031158447
Test Loss:  0.03459441289305687
Valid Loss:  0.030788537114858627
Epoch:  71  	Training Loss: 0.04569914564490318
Test Loss:  0.03459126874804497
Valid Loss:  0.03078565001487732
Epoch:  72  	Training Loss: 0.04569477215409279
Test Loss:  0.03458837419748306
Valid Loss:   15%|█▍        | 73/500 [00:54<06:04,  1.17it/s] 15%|█▌        | 75/500 [00:54<04:22,  1.62it/s] 15%|█▌        | 77/500 [00:54<03:10,  2.22it/s] 16%|█▌        | 79/500 [00:54<02:21,  2.98it/s] 16%|█▌        | 81/500 [01:00<08:12,  1.18s/it] 17%|█▋        | 83/500 [01:00<05:52,  1.18it/s] 17%|█▋        | 85/500 [01:01<04:13,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.01it/s] 18%|█▊        | 91/500 [01:07<08:01,  1.18s/it] 19%|█▊        | 93/500 [01:07<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:07<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:08<03:00,  2.24it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.01it/s] 20%|██        | 101/500 [01:14<07:47,  1.17s/it] 21%|██        | 103/500 [01:14<05:33,  1.19it/s] 21%|██        | 105/500 [01:14<04:00,  1.64it/s] 21%|██▏       | 107/500 [01:14<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:14<02:09,  3.02it/s] 22%|██▏       | 111/500 [01:21<07:38,  1.18s/it] 23%|██▎       | 113/500 [01:21<05:27,  1.18it/s] 23%|██▎       | 115/500 [01:21<03:55,  1.64it/s] 23%|██▎       | 117/500 [01:21<02:51,  2.24it/s] 24%|██▍       | 119/500 [01:21<02:06,  3.01it/s] 24%|██▍       | 121/500 [01:28<07:26,  1.18s/it] 25%|██▍       | 123/500 [01:28<05:18,  1.18it/s] 25%|██▌       | 125/500 [01:28<03:49,  1.64it/s] 25%|██▌       | 127/500 [01:28<02:47,  2.23it/s] 26%|██▌       | 129/500 [01:28<02:03,  2.99it/s] 26%|██▌       | 131/500 [01:34<07:12,  1.17s/it] 27%|██▋       | 133/500 [01:35<05:10,  1.18it/s] 27%|██▋       | 135/500 [01:35<03:45,  1.62it/s] 27%|██▋       | 137/500 [01:35<02:46,  2.18it/s] 28%|██▊       | 139/500 [01:35<02:02,  2.94it/s] 28%|██▊       | 141/500 [01:41<06:59,  1.17s/it] 29%|██▊       | 143/500 [01:41<04:59,  1.19it/s]0.030782992020249367
Epoch:  73  	Training Loss: 0.04569074511528015
Test Loss:  0.03458547592163086
Valid Loss:  0.030780334025621414
Epoch:  74  	Training Loss: 0.04568672180175781
Test Loss:  0.034582577645778656
Valid Loss:  0.030777674168348312
Epoch:  75  	Training Loss: 0.04568270593881607
Test Loss:  0.03457967936992645
Valid Loss:  0.03077501244843006
Epoch:  76  	Training Loss: 0.04567868635058403
Test Loss:  0.03457678109407425
Valid Loss:  0.03077235445380211
Epoch:  77  	Training Loss: 0.04567466676235199
Test Loss:  0.034573882818222046
Valid Loss:  0.030769692733883858
Epoch:  78  	Training Loss: 0.04567064717411995
Test Loss:  0.03457098454236984
Valid Loss:  0.030767034739255905
Epoch:  79  	Training Loss: 0.04566663131117821
Test Loss:  0.03456808626651764
Valid Loss:  0.030764378607273102
Epoch:  80  	Training Loss: 0.04566261172294617
Test Loss:  0.034565187990665436
Valid Loss:  0.030761726200580597
Epoch:  81  	Training Loss: 0.045658595860004425
Test Loss:  0.03456228971481323
Valid Loss:  0.030759060755372047
Epoch:  82  	Training Loss: 0.04565457999706268
Test Loss:  0.034559622406959534
Valid Loss:  0.030756615102291107
Epoch:  83  	Training Loss: 0.045650891959667206
Test Loss:  0.03455694764852524
Valid Loss:  0.030754156410694122
Epoch:  84  	Training Loss: 0.04564719647169113
Test Loss:  0.03455427661538124
Valid Loss:  0.030751708894968033
Epoch:  85  	Training Loss: 0.045643508434295654
Test Loss:  0.03455161303281784
Valid Loss:  0.030749259516596794
Epoch:  86  	Training Loss: 0.045639824122190475
Test Loss:  0.03454894199967384
Valid Loss:  0.030746808275580406
Epoch:  87  	Training Loss: 0.0456361286342144
Test Loss:  0.034546270966529846
Valid Loss:  0.030744358897209167
Epoch:  88  	Training Loss: 0.04563244432210922
Test Loss:  0.03454360365867615
Valid Loss:  0.03074190951883793
Epoch:  89  	Training Loss: 0.04562875255942345
Test Loss:  0.03454093262553215
Valid Loss:  0.03073946386575699
Epoch:  90  	Training Loss: 0.04562506824731827
Test Loss:  0.03453826904296875
Valid Loss:  0.030737007036805153
Epoch:  91  	Training Loss: 0.04562138393521309
Test Loss:  0.03453560173511505
Valid Loss:  0.030734555795788765
Epoch:  92  	Training Loss: 0.04561769962310791
Test Loss:  0.03453311696648598
Valid Loss:  0.030732277780771255
Epoch:  93  	Training Loss: 0.04561427980661392
Test Loss:  0.0345306321978569
Valid Loss:  0.030729999765753746
Epoch:  94  	Training Loss: 0.04561086371541023
Test Loss:  0.03452815115451813
Valid Loss:  0.030727718025445938
Epoch:  95  	Training Loss: 0.04560744762420654
Test Loss:  0.03452567011117935
Valid Loss:  0.030725443735718727
Epoch:  96  	Training Loss: 0.04560403153300285
Test Loss:  0.03452318161725998
Valid Loss:  0.03072316199541092
Epoch:  97  	Training Loss: 0.045600615441799164
Test Loss:  0.0345207080245018
Valid Loss:  0.030720878392457962
Epoch:  98  	Training Loss: 0.045597195625305176
Test Loss:  0.034518223255872726
Valid Loss:  0.030718602240085602
Epoch:  99  	Training Loss: 0.045593783259391785
Test Loss:  0.03451573848724365
Valid Loss:  0.030716322362422943
Epoch:  100  	Training Loss: 0.045590367168188095
Test Loss:  0.03451325744390488
Valid Loss:  0.030714042484760284
Epoch:  101  	Training Loss: 0.045586954802274704
Test Loss:  0.0345107764005661
Valid Loss:  0.030711762607097626
Epoch:  102  	Training Loss: 0.045583538711071014
Test Loss:  0.034508466720581055
Valid Loss:  0.030709639191627502
Epoch:  103  	Training Loss: 0.04558037221431732
Test Loss:  0.03450615704059601
Valid Loss:  0.030707519501447678
Epoch:  104  	Training Loss: 0.04557720571756363
Test Loss:  0.03450384363532066
Valid Loss:  0.030705392360687256
Epoch:  105  	Training Loss: 0.045574039220809937
Test Loss:  0.034501537680625916
Valid Loss:  0.030703268945217133
Epoch:  106  	Training Loss: 0.045570872724056244
Test Loss:  0.03449922427535057
Valid Loss:  0.03070114366710186
Epoch:  107  	Training Loss: 0.04556770622730255
Test Loss:  0.03449691832065582
Valid Loss:  0.030699025839567184
Epoch:  108  	Training Loss: 0.04556454345583916
Test Loss:  0.03449460119009018
Valid Loss:  0.03069690614938736
Epoch:  109  	Training Loss: 0.045561376959085464
Test Loss:  0.03449229896068573
Valid Loss:  0.030694779008626938
Epoch:  110  	Training Loss: 0.04555821418762207
Test Loss:  0.034489989280700684
Valid Loss:  0.030692659318447113
Epoch:  111  	Training Loss: 0.04555504769086838
Test Loss:  0.03448767960071564
Valid Loss:  0.03069053217768669
Epoch:  112  	Training Loss: 0.04555188864469528
Test Loss:  0.03448551148176193
Valid Loss:  0.030688537284731865
Epoch:  113  	Training Loss: 0.04554891958832741
Test Loss:  0.03448333963751793
Valid Loss:  0.03068654239177704
Epoch:  114  	Training Loss: 0.04554596170783043
Test Loss:  0.034481167793273926
Valid Loss:  0.030684545636177063
Epoch:  115  	Training Loss: 0.04554300010204315
Test Loss:  0.03447899967432022
Valid Loss:  0.030682552605867386
Epoch:  116  	Training Loss: 0.04554004222154617
Test Loss:  0.03447682410478592
Valid Loss:  0.030680552124977112
Epoch:  117  	Training Loss: 0.0455370768904686
Test Loss:  0.034474655985832214
Valid Loss:  0.030678559094667435
Epoch:  118  	Training Loss: 0.04553411900997162
Test Loss:  0.03447248414158821
Valid Loss:  0.03067656047642231
Epoch:  119  	Training Loss: 0.04553115367889404
Test Loss:  0.034470319747924805
Valid Loss:  0.030674565583467484
Epoch:  120  	Training Loss: 0.04552818834781647
Test Loss:  0.034468140453100204
Valid Loss:  0.03067256696522236
Epoch:  121  	Training Loss: 0.04552523419260979
Test Loss:  0.0344659723341465
Valid Loss:  0.030670568346977234
Epoch:  122  	Training Loss: 0.04552227258682251
Test Loss:  0.034463927149772644
Valid Loss:  0.03066868707537651
Epoch:  123  	Training Loss: 0.04551949352025986
Test Loss:  0.03446187824010849
Valid Loss:  0.030666805803775787
Epoch:  124  	Training Loss: 0.045516714453697205
Test Loss:  0.03445984423160553
Valid Loss:  0.030664924532175064
Epoch:  125  	Training Loss: 0.04551393538713455
Test Loss:  0.034457795321941376
Valid Loss:  0.030663039535284042
Epoch:  126  	Training Loss: 0.0455111563205719
Test Loss:  0.03445574641227722
Valid Loss:  0.030661161988973618
Epoch:  127  	Training Loss: 0.04550837725400925
Test Loss:  0.034453704953193665
Valid Loss:  0.030659278854727745
Epoch:  128  	Training Loss: 0.045505598187446594
Test Loss:  0.03445166349411011
Valid Loss:  0.03065739944577217
Epoch:  129  	Training Loss: 0.04550281912088394
Test Loss:  0.03444962203502655
Valid Loss:  0.03065551072359085
Epoch:  130  	Training Loss: 0.04550004005432129
Test Loss:  0.034447573125362396
Valid Loss:  0.030653638765215874
Epoch:  131  	Training Loss: 0.045497260987758636
Test Loss:  0.03444553166627884
Valid Loss:  0.030651751905679703
Epoch:  132  	Training Loss: 0.045494481921195984
Test Loss:  0.03444359079003334
Valid Loss:  0.03064996749162674
Epoch:  133  	Training Loss: 0.04549185559153557
Test Loss:  0.03444164618849754
Valid Loss:  0.03064817562699318
Epoch:  134  	Training Loss: 0.04548922926187515
Test Loss:  0.034439701586961746
Valid Loss:  0.030646387487649918
Epoch:  135  	Training Loss: 0.04548660293221474
Test Loss:  0.034437768161296844
Valid Loss:  0.030644597485661507
Epoch:  136  	Training Loss: 0.04548397660255432
Test Loss:  0.03443581983447075
Valid Loss:  0.030642811208963394
Epoch:  137  	Training Loss: 0.04548134654760361
Test Loss:  0.03443387523293495
Valid Loss:  0.030641023069620132
Epoch:  138  	Training Loss: 0.04547872394323349
Test Loss:  0.03443193435668945
Valid Loss:  0.030639231204986572
Epoch:  139  	Training Loss: 0.04547610133886337
Test Loss:  0.03442999720573425
Valid Loss:  0.03063744492828846
Epoch:  140  	Training Loss: 0.04547347500920296
Test Loss:  0.03442806005477905
Valid Loss:  0.030635667964816093
Epoch:  141  	Training Loss: 0.04547084867954254
Test Loss:  0.03442612290382385
Valid Loss:  0.030633877962827682
Epoch:  142  	Training Loss: 0.04546821862459183
Test Loss:  0.034424275159835815
Valid Loss:  0.030632179230451584
Epoch:  143  	Training Loss: 0.04546573758125305
Test Loss:  0.03442244231700897
Valid Loss:  0.03063049167394638
 29%|██▉       | 145/500 [01:42<03:35,  1.65it/s] 29%|██▉       | 147/500 [01:42<02:36,  2.25it/s] 30%|██▉       | 149/500 [01:42<01:55,  3.03it/s] 30%|███       | 151/500 [01:48<06:46,  1.16s/it] 31%|███       | 153/500 [01:48<04:49,  1.20it/s] 31%|███       | 155/500 [01:48<03:28,  1.65it/s] 31%|███▏      | 157/500 [01:48<02:32,  2.25it/s] 32%|███▏      | 159/500 [01:49<01:54,  2.98it/s] 32%|███▏      | 161/500 [01:55<06:33,  1.16s/it] 33%|███▎      | 163/500 [01:55<04:40,  1.20it/s] 33%|███▎      | 165/500 [01:55<03:22,  1.66it/s] 33%|███▎      | 167/500 [01:55<02:27,  2.26it/s] 34%|███▍      | 169/500 [01:55<01:48,  3.04it/s] 34%|███▍      | 171/500 [02:02<06:25,  1.17s/it] 35%|███▍      | 173/500 [02:02<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:02<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:02<02:24,  2.24it/s] 36%|███▌      | 179/500 [02:02<01:46,  3.00it/s] 36%|███▌      | 181/500 [02:08<06:13,  1.17s/it] 37%|███▋      | 183/500 [02:08<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:09<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:09<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:09<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:15<05:59,  1.16s/it] 39%|███▊      | 193/500 [02:15<04:16,  1.20it/s] 39%|███▉      | 195/500 [02:15<03:04,  1.65it/s] 39%|███▉      | 197/500 [02:16<02:14,  2.25it/s] 40%|███▉      | 199/500 [02:16<01:39,  3.02it/s] 40%|████      | 201/500 [02:22<05:53,  1.18s/it] 41%|████      | 203/500 [02:22<04:12,  1.18it/s] 41%|████      | 205/500 [02:22<03:01,  1.63it/s] 41%|████▏     | 207/500 [02:22<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:23<01:37,  3.00it/s] 42%|████▏     | 211/500 [02:29<05:39,  1.18s/it] 43%|████▎     | 213/500 [02:29<04:02,  1.19it/s]Epoch:  144  	Training Loss: 0.04546325281262398
Test Loss:  0.034420594573020935
Valid Loss:  0.03062879480421543
Epoch:  145  	Training Loss: 0.0454607717692852
Test Loss:  0.03441876918077469
Valid Loss:  0.030627110973000526
Epoch:  146  	Training Loss: 0.04545828327536583
Test Loss:  0.03441692516207695
Valid Loss:  0.030625412240624428
Epoch:  147  	Training Loss: 0.04545580595731735
Test Loss:  0.03441508114337921
Valid Loss:  0.03062371164560318
Epoch:  148  	Training Loss: 0.04545331746339798
Test Loss:  0.03441324830055237
Valid Loss:  0.030622025951743126
Epoch:  149  	Training Loss: 0.0454508401453495
Test Loss:  0.03441140800714493
Valid Loss:  0.030620325356721878
Epoch:  150  	Training Loss: 0.04544835537672043
Test Loss:  0.034409571439027786
Valid Loss:  0.030618641525506973
Epoch:  151  	Training Loss: 0.04544587433338165
Test Loss:  0.034407731145620346
Valid Loss:  0.030616942793130875
Epoch:  152  	Training Loss: 0.04544338956475258
Test Loss:  0.03440596163272858
Valid Loss:  0.030615314841270447
Epoch:  153  	Training Loss: 0.04544101655483246
Test Loss:  0.0344042107462883
Valid Loss:  0.030613701790571213
Epoch:  154  	Training Loss: 0.04543864727020264
Test Loss:  0.03440244495868683
Valid Loss:  0.030612075701355934
Epoch:  155  	Training Loss: 0.045436277985572815
Test Loss:  0.03440069407224655
Valid Loss:  0.030610466375947
Epoch:  156  	Training Loss: 0.04543390870094299
Test Loss:  0.03439892828464508
Valid Loss:  0.03060883656144142
Epoch:  157  	Training Loss: 0.045431531965732574
Test Loss:  0.03439715877175331
Valid Loss:  0.030607206746935844
Epoch:  158  	Training Loss: 0.045429158955812454
Test Loss:  0.03439541161060333
Valid Loss:  0.03060559555888176
Epoch:  159  	Training Loss: 0.04542678967118263
Test Loss:  0.03439364209771156
Valid Loss:  0.030603963881731033
Epoch:  160  	Training Loss: 0.04542441666126251
Test Loss:  0.034391891211271286
Valid Loss:  0.03060235269367695
Epoch:  161  	Training Loss: 0.04542204737663269
Test Loss:  0.034390129148960114
Valid Loss:  0.030600719153881073
Epoch:  162  	Training Loss: 0.04541967809200287
Test Loss:  0.034388430416584015
Valid Loss:  0.030599165707826614
Epoch:  163  	Training Loss: 0.04541739821434021
Test Loss:  0.03438673913478851
Valid Loss:  0.030597597360610962
Epoch:  164  	Training Loss: 0.04541512951254845
Test Loss:  0.03438504785299301
Valid Loss:  0.030596042051911354
Epoch:  165  	Training Loss: 0.04541284963488579
Test Loss:  0.03438334912061691
Valid Loss:  0.0305944737046957
Epoch:  166  	Training Loss: 0.045410577207803726
Test Loss:  0.034381650388240814
Valid Loss:  0.030592918395996094
Epoch:  167  	Training Loss: 0.045408301055431366
Test Loss:  0.03437995910644531
Valid Loss:  0.03059135004878044
Epoch:  168  	Training Loss: 0.045406028628349304
Test Loss:  0.034378260374069214
Valid Loss:  0.030589794740080833
Epoch:  169  	Training Loss: 0.04540375620126724
Test Loss:  0.03437656909227371
Valid Loss:  0.030588224530220032
Epoch:  170  	Training Loss: 0.04540148377418518
Test Loss:  0.03437487781047821
Valid Loss:  0.03058667480945587
Epoch:  171  	Training Loss: 0.04539921134710312
Test Loss:  0.03437317907810211
Valid Loss:  0.03058510646224022
Epoch:  172  	Training Loss: 0.04539693146944046
Test Loss:  0.034371569752693176
Valid Loss:  0.03058362379670143
Epoch:  173  	Training Loss: 0.045394785702228546
Test Loss:  0.034369949251413345
Valid Loss:  0.03058212623000145
Epoch:  174  	Training Loss: 0.04539263993501663
Test Loss:  0.03436833992600441
Valid Loss:  0.03058064542710781
Epoch:  175  	Training Loss: 0.04539049416780472
Test Loss:  0.03436671942472458
Valid Loss:  0.03057914786040783
Epoch:  176  	Training Loss: 0.045388348400592804
Test Loss:  0.03436511754989624
Valid Loss:  0.03057767078280449
Epoch:  177  	Training Loss: 0.04538619518280029
Test Loss:  0.03436350077390671
Valid Loss:  0.03057616949081421
Epoch:  178  	Training Loss: 0.04538405314087868
Test Loss:  0.034361887723207474
Valid Loss:  0.03057468682527542
Epoch:  179  	Training Loss: 0.04538190737366676
Test Loss:  0.03436027094721794
Valid Loss:  0.03057318925857544
Epoch:  180  	Training Loss: 0.04537975788116455
Test Loss:  0.034358665347099304
Valid Loss:  0.03057171031832695
Epoch:  181  	Training Loss: 0.045377619564533234
Test Loss:  0.03435704857110977
Valid Loss:  0.030570218339562416
Epoch:  182  	Training Loss: 0.04537547379732132
Test Loss:  0.03435548394918442
Valid Loss:  0.030568772926926613
Epoch:  183  	Training Loss: 0.045373380184173584
Test Loss:  0.03435390442609787
Valid Loss:  0.030567318201065063
Epoch:  184  	Training Loss: 0.04537128657102585
Test Loss:  0.034352343529462814
Valid Loss:  0.03056587278842926
Epoch:  185  	Training Loss: 0.04536920040845871
Test Loss:  0.034350764006376266
Valid Loss:  0.03056442178785801
Epoch:  186  	Training Loss: 0.045367106795310974
Test Loss:  0.03434919938445091
Valid Loss:  0.030562981963157654
Epoch:  187  	Training Loss: 0.04536501690745354
Test Loss:  0.03434762358665466
Valid Loss:  0.030561521649360657
Epoch:  188  	Training Loss: 0.0453629270195961
Test Loss:  0.03434606269001961
Valid Loss:  0.030560078099370003
Epoch:  189  	Training Loss: 0.04536083713173866
Test Loss:  0.034344498068094254
Valid Loss:  0.030558638274669647
Epoch:  190  	Training Loss: 0.045358747243881226
Test Loss:  0.034342918545007706
Valid Loss:  0.030557185411453247
Epoch:  191  	Training Loss: 0.04535665363073349
Test Loss:  0.03434135764837265
Valid Loss:  0.030555738136172295
Epoch:  192  	Training Loss: 0.04535456374287605
Test Loss:  0.034339867532253265
Valid Loss:  0.030554357916116714
Epoch:  193  	Training Loss: 0.045352593064308167
Test Loss:  0.03433837369084358
Valid Loss:  0.03055299073457718
Epoch:  194  	Training Loss: 0.04535061493515968
Test Loss:  0.0343368835747242
Valid Loss:  0.0305516105145216
Epoch:  195  	Training Loss: 0.0453486405313015
Test Loss:  0.03433540090918541
Valid Loss:  0.030550239607691765
Epoch:  196  	Training Loss: 0.045346666127443314
Test Loss:  0.03433391451835632
Valid Loss:  0.03054887056350708
Epoch:  197  	Training Loss: 0.04534469544887543
Test Loss:  0.03433242440223694
Valid Loss:  0.03054748848080635
Epoch:  198  	Training Loss: 0.045342713594436646
Test Loss:  0.034330934286117554
Valid Loss:  0.030546117573976517
Epoch:  199  	Training Loss: 0.04534073919057846
Test Loss:  0.03432944416999817
Valid Loss:  0.030544735491275787
Epoch:  200  	Training Loss: 0.045338764786720276
Test Loss:  0.03432795777916908
Valid Loss:  0.0305433701723814
Epoch:  201  	Training Loss: 0.04533679038286209
Test Loss:  0.034326475113630295
Valid Loss:  0.030542002990841866
Epoch:  202  	Training Loss: 0.045334815979003906
Test Loss:  0.0343250073492527
Valid Loss:  0.030540641397237778
Epoch:  203  	Training Loss: 0.0453328900039196
Test Loss:  0.0343235544860363
Valid Loss:  0.03053930401802063
Epoch:  204  	Training Loss: 0.045330960303545
Test Loss:  0.034322090446949005
Valid Loss:  0.03053794987499714
Epoch:  205  	Training Loss: 0.045329030603170395
Test Loss:  0.034320637583732605
Valid Loss:  0.030536610633134842
Epoch:  206  	Training Loss: 0.04532710462808609
Test Loss:  0.034319184720516205
Valid Loss:  0.030535273253917694
Epoch:  207  	Training Loss: 0.04532517492771149
Test Loss:  0.03431772068142891
Valid Loss:  0.030533911660313606
Epoch:  208  	Training Loss: 0.045323241502046585
Test Loss:  0.03431626409292221
Valid Loss:  0.03053257241845131
Epoch:  209  	Training Loss: 0.04532131552696228
Test Loss:  0.03431481122970581
Valid Loss:  0.03053123503923416
Epoch:  210  	Training Loss: 0.04531938582658768
Test Loss:  0.034313350915908813
Valid Loss:  0.03052988275885582
Epoch:  211  	Training Loss: 0.04531745985150337
Test Loss:  0.03431189805269241
Valid Loss:  0.030528539791703224
Epoch:  212  	Training Loss: 0.04531553015112877
Test Loss:  0.0343104749917984
Valid Loss:  0.030527222901582718
Epoch:  213  	Training Loss: 0.04531366378068924
Test Loss:  0.03430906683206558
Valid Loss:  0.030525926500558853
Epoch:  214  	Training Loss: 0.04531180113554001
Test Loss:  0.034307658672332764
Valid Loss:  0.03052463009953499
 43%|████▎     | 215/500 [02:29<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:29<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:29<01:33,  3.01it/s] 44%|████▍     | 221/500 [02:36<05:28,  1.18s/it] 45%|████▍     | 223/500 [02:36<03:53,  1.18it/s] 45%|████▌     | 225/500 [02:36<02:48,  1.64it/s] 45%|████▌     | 227/500 [02:36<02:02,  2.24it/s] 46%|████▌     | 229/500 [02:36<01:30,  3.01it/s] 46%|████▌     | 231/500 [02:42<05:17,  1.18s/it] 47%|████▋     | 233/500 [02:43<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:43<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:43<01:58,  2.23it/s] 48%|████▊     | 239/500 [02:43<01:27,  2.99it/s] 48%|████▊     | 241/500 [02:49<05:07,  1.19s/it] 49%|████▊     | 243/500 [02:49<03:38,  1.17it/s] 49%|████▉     | 245/500 [02:50<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:50<01:53,  2.22it/s] 50%|████▉     | 249/500 [02:50<01:23,  2.99it/s] 50%|█████     | 251/500 [02:56<04:52,  1.18s/it] 51%|█████     | 253/500 [02:56<03:28,  1.19it/s] 51%|█████     | 255/500 [02:56<02:29,  1.64it/s] 51%|█████▏    | 257/500 [02:57<01:48,  2.24it/s] 52%|█████▏    | 259/500 [02:57<01:19,  3.01it/s] 52%|█████▏    | 261/500 [03:03<04:36,  1.16s/it] 53%|█████▎    | 263/500 [03:03<03:16,  1.21it/s] 53%|█████▎    | 265/500 [03:03<02:20,  1.67it/s] 53%|█████▎    | 267/500 [03:03<01:42,  2.28it/s] 54%|█████▍    | 269/500 [03:03<01:15,  3.06it/s] 54%|█████▍    | 271/500 [03:10<04:28,  1.17s/it] 55%|█████▍    | 273/500 [03:10<03:11,  1.19it/s] 55%|█████▌    | 275/500 [03:10<02:17,  1.64it/s] 55%|█████▌    | 277/500 [03:10<01:39,  2.24it/s] 56%|█████▌    | 279/500 [03:10<01:13,  3.01it/s] 56%|█████▌    | 281/500 [03:16<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:17<03:01,  1.20it/s] 57%|█████▋    | 285/500 [03:17<02:10,  1.65it/s]Epoch:  215  	Training Loss: 0.045309942215681076
Test Loss:  0.03430623561143875
Valid Loss:  0.030523311346769333
Epoch:  216  	Training Loss: 0.04530807584524155
Test Loss:  0.03430482745170593
Valid Loss:  0.030522014945745468
Epoch:  217  	Training Loss: 0.04530620574951172
Test Loss:  0.03430342674255371
Valid Loss:  0.030520718544721603
Epoch:  218  	Training Loss: 0.04530434310436249
Test Loss:  0.0343020036816597
Valid Loss:  0.030519399791955948
Epoch:  219  	Training Loss: 0.04530247673392296
Test Loss:  0.03430059552192688
Valid Loss:  0.030518103390932083
Epoch:  220  	Training Loss: 0.04530061036348343
Test Loss:  0.03429918736219406
Valid Loss:  0.03051679953932762
Epoch:  221  	Training Loss: 0.0452987477183342
Test Loss:  0.03429776802659035
Valid Loss:  0.030515488237142563
Epoch:  222  	Training Loss: 0.04529688134789467
Test Loss:  0.03429637849330902
Valid Loss:  0.030514203011989594
Epoch:  223  	Training Loss: 0.04529505595564842
Test Loss:  0.03429499641060829
Valid Loss:  0.03051292896270752
Epoch:  224  	Training Loss: 0.04529322683811188
Test Loss:  0.03429359570145607
Valid Loss:  0.03051164001226425
Epoch:  225  	Training Loss: 0.04529140517115593
Test Loss:  0.03429222106933594
Valid Loss:  0.03051035851240158
Epoch:  226  	Training Loss: 0.04528957977890968
Test Loss:  0.03429083526134491
Valid Loss:  0.030509084463119507
Epoch:  227  	Training Loss: 0.045287758111953735
Test Loss:  0.034289442002773285
Valid Loss:  0.03050779365003109
Epoch:  228  	Training Loss: 0.04528592526912689
Test Loss:  0.034288059920072556
Valid Loss:  0.030506515875458717
Epoch:  229  	Training Loss: 0.04528410732746124
Test Loss:  0.034286677837371826
Valid Loss:  0.030505236238241196
Epoch:  230  	Training Loss: 0.045282281935214996
Test Loss:  0.0342852920293808
Valid Loss:  0.030503960326313972
Epoch:  231  	Training Loss: 0.04528045281767845
Test Loss:  0.03428389132022858
Valid Loss:  0.030502665787935257
Epoch:  232  	Training Loss: 0.045278631150722504
Test Loss:  0.03428256884217262
Valid Loss:  0.030501440167427063
Epoch:  233  	Training Loss: 0.04527688026428223
Test Loss:  0.03428124263882637
Valid Loss:  0.03050021268427372
Epoch:  234  	Training Loss: 0.045275136828422546
Test Loss:  0.034279897809028625
Valid Loss:  0.030498966574668884
Epoch:  235  	Training Loss: 0.045273393392562866
Test Loss:  0.03427857160568237
Valid Loss:  0.030497737228870392
Epoch:  236  	Training Loss: 0.04527164250612259
Test Loss:  0.03427724167704582
Valid Loss:  0.030496511608362198
Epoch:  237  	Training Loss: 0.04526989907026291
Test Loss:  0.03427590802311897
Valid Loss:  0.030495282262563705
Epoch:  238  	Training Loss: 0.04526815190911293
Test Loss:  0.034274570643901825
Valid Loss:  0.030494045466184616
Epoch:  239  	Training Loss: 0.04526641219854355
Test Loss:  0.03427324444055557
Valid Loss:  0.030492816120386124
Epoch:  240  	Training Loss: 0.04526466503739357
Test Loss:  0.03427191823720932
Valid Loss:  0.03049159049987793
Epoch:  241  	Training Loss: 0.04526291787624359
Test Loss:  0.034270577132701874
Valid Loss:  0.030490346252918243
Epoch:  242  	Training Loss: 0.04526117444038391
Test Loss:  0.03426927328109741
Valid Loss:  0.030489154160022736
Epoch:  243  	Training Loss: 0.04525947570800781
Test Loss:  0.03426798805594444
Valid Loss:  0.03048795275390148
Epoch:  244  	Training Loss: 0.04525778442621231
Test Loss:  0.03426668792963028
Valid Loss:  0.030486764386296272
Epoch:  245  	Training Loss: 0.04525608569383621
Test Loss:  0.034265387803316116
Valid Loss:  0.030485546216368675
Epoch:  246  	Training Loss: 0.045254386961460114
Test Loss:  0.03426408767700195
Valid Loss:  0.03048434481024742
Epoch:  247  	Training Loss: 0.04525268077850342
Test Loss:  0.03426279500126839
Valid Loss:  0.030483148992061615
Epoch:  248  	Training Loss: 0.04525098204612732
Test Loss:  0.03426150232553482
Valid Loss:  0.03048195131123066
Epoch:  249  	Training Loss: 0.04524929076433182
Test Loss:  0.03426019102334976
Valid Loss:  0.03048074245452881
Epoch:  250  	Training Loss: 0.04524758830666542
Test Loss:  0.034258902072906494
Valid Loss:  0.030479544773697853
Epoch:  251  	Training Loss: 0.04524589329957962
Test Loss:  0.03425760567188263
Valid Loss:  0.030478348955512047
Epoch:  252  	Training Loss: 0.04524420201778412
Test Loss:  0.03425634652376175
Valid Loss:  0.030477171763777733
Epoch:  253  	Training Loss: 0.0452425479888916
Test Loss:  0.03425506502389908
Valid Loss:  0.03047599084675312
Epoch:  254  	Training Loss: 0.045240893959999084
Test Loss:  0.0342537946999073
Valid Loss:  0.030474817380309105
Epoch:  255  	Training Loss: 0.04523923993110657
Test Loss:  0.034252531826496124
Valid Loss:  0.030473653227090836
Epoch:  256  	Training Loss: 0.04523759335279465
Test Loss:  0.03425126522779465
Valid Loss:  0.030472485348582268
Epoch:  257  	Training Loss: 0.04523593932390213
Test Loss:  0.03424999117851257
Valid Loss:  0.030471298843622208
Epoch:  258  	Training Loss: 0.04523429274559021
Test Loss:  0.034248724579811096
Valid Loss:  0.03047012910246849
Epoch:  259  	Training Loss: 0.045232634991407394
Test Loss:  0.03424746170639992
Valid Loss:  0.030468950048089027
Epoch:  260  	Training Loss: 0.04523098096251488
Test Loss:  0.03424619138240814
Valid Loss:  0.03046778403222561
Epoch:  261  	Training Loss: 0.04522933065891266
Test Loss:  0.03424490988254547
Valid Loss:  0.0304665956646204
Epoch:  262  	Training Loss: 0.04522767663002014
Test Loss:  0.03424367308616638
Valid Loss:  0.030465450137853622
Epoch:  263  	Training Loss: 0.04522605985403061
Test Loss:  0.03424243628978729
Valid Loss:  0.030464308336377144
Epoch:  264  	Training Loss: 0.04522444307804108
Test Loss:  0.0342411994934082
Valid Loss:  0.03046315908432007
Epoch:  265  	Training Loss: 0.04522283002734184
Test Loss:  0.03423995524644852
Valid Loss:  0.030462007969617844
Epoch:  266  	Training Loss: 0.04522121325135231
Test Loss:  0.03423870727419853
Valid Loss:  0.030460849404335022
Epoch:  267  	Training Loss: 0.045219600200653076
Test Loss:  0.034237466752529144
Valid Loss:  0.030459702014923096
Epoch:  268  	Training Loss: 0.045217983424663544
Test Loss:  0.034236226230859756
Valid Loss:  0.030458558350801468
Epoch:  269  	Training Loss: 0.04521636664867401
Test Loss:  0.03423497825860977
Valid Loss:  0.03045741096138954
Epoch:  270  	Training Loss: 0.045214757323265076
Test Loss:  0.03423374891281128
Valid Loss:  0.030456267297267914
Epoch:  271  	Training Loss: 0.04521314054727554
Test Loss:  0.034232497215270996
Valid Loss:  0.030455101281404495
Epoch:  272  	Training Loss: 0.04521152377128601
Test Loss:  0.0342312827706337
Valid Loss:  0.030453979969024658
Epoch:  273  	Training Loss: 0.04520995169878006
Test Loss:  0.0342300646007061
Valid Loss:  0.030452856793999672
Epoch:  274  	Training Loss: 0.04520837217569351
Test Loss:  0.0342288464307785
Valid Loss:  0.030451735481619835
Epoch:  275  	Training Loss: 0.04520679637789726
Test Loss:  0.0342276468873024
Valid Loss:  0.0304506104439497
Epoch:  276  	Training Loss: 0.04520522058010101
Test Loss:  0.034226417541503906
Valid Loss:  0.030449476093053818
Epoch:  277  	Training Loss: 0.045203644782304764
Test Loss:  0.03422520309686661
Valid Loss:  0.030448351055383682
Epoch:  278  	Training Loss: 0.045202068984508514
Test Loss:  0.03422398865222931
Valid Loss:  0.030447227880358696
Epoch:  279  	Training Loss: 0.045200493186712265
Test Loss:  0.03422277420759201
Valid Loss:  0.030446108430624008
Epoch:  280  	Training Loss: 0.045198917388916016
Test Loss:  0.03422156721353531
Valid Loss:  0.030444983392953873
Epoch:  281  	Training Loss: 0.04519733786582947
Test Loss:  0.03422034531831741
Valid Loss:  0.030443858355283737
Epoch:  282  	Training Loss: 0.04519576579332352
Test Loss:  0.0342191681265831
Valid Loss:  0.03044275939464569
Epoch:  283  	Training Loss: 0.045194245874881744
Test Loss:  0.034217990934848785
Valid Loss:  0.03044166974723339
Epoch:  284  	Training Loss: 0.04519272223114967
Test Loss:  0.03421681374311447
Valid Loss:  0.03044058009982109
Epoch:  285  	Training Loss: 0.0451911985874176
Test Loss:  0.03421563655138016
Valid Loss:  0.03043948858976364
 57%|█████▋    | 287/500 [03:17<01:34,  2.26it/s] 58%|█████▊    | 289/500 [03:17<01:09,  3.04it/s] 58%|█████▊    | 291/500 [03:23<04:02,  1.16s/it] 59%|█████▊    | 293/500 [03:23<02:52,  1.20it/s] 59%|█████▉    | 295/500 [03:23<02:03,  1.66it/s] 59%|█████▉    | 297/500 [03:24<01:29,  2.26it/s] 60%|█████▉    | 299/500 [03:24<01:06,  3.04it/s] 60%|██████    | 301/500 [03:30<03:52,  1.17s/it] 61%|██████    | 303/500 [03:30<02:45,  1.19it/s] 61%|██████    | 305/500 [03:30<01:58,  1.64it/s] 61%|██████▏   | 307/500 [03:30<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:30<01:03,  3.01it/s] 62%|██████▏   | 311/500 [03:37<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:37<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:37<01:52,  1.65it/s] 63%|██████▎   | 317/500 [03:37<01:21,  2.25it/s] 64%|██████▍   | 319/500 [03:37<00:59,  3.02it/s] 64%|██████▍   | 321/500 [03:44<03:28,  1.17s/it] 65%|██████▍   | 323/500 [03:44<02:28,  1.19it/s] 65%|██████▌   | 325/500 [03:44<01:46,  1.65it/s] 65%|██████▌   | 327/500 [03:44<01:16,  2.25it/s] 66%|██████▌   | 329/500 [03:44<00:56,  3.03it/s] 66%|██████▌   | 331/500 [03:50<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:51<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:51<01:41,  1.63it/s] 67%|██████▋   | 337/500 [03:51<01:13,  2.23it/s] 68%|██████▊   | 339/500 [03:51<00:53,  2.99it/s] 68%|██████▊   | 341/500 [03:57<03:08,  1.18s/it] 69%|██████▊   | 343/500 [03:57<02:13,  1.18it/s] 69%|██████▉   | 345/500 [03:58<01:35,  1.63it/s] 69%|██████▉   | 347/500 [03:58<01:08,  2.23it/s] 70%|██████▉   | 349/500 [03:58<00:50,  3.00it/s] 70%|███████   | 351/500 [04:04<02:54,  1.17s/it] 71%|███████   | 353/500 [04:04<02:03,  1.19it/s] 71%|███████   | 355/500 [04:04<01:28,  1.65it/s]Epoch:  286  	Training Loss: 0.04518967866897583
Test Loss:  0.03421446681022644
Valid Loss:  0.03043840453028679
Epoch:  287  	Training Loss: 0.04518815502524376
Test Loss:  0.03421328589320183
Valid Loss:  0.03043731302022934
Epoch:  288  	Training Loss: 0.04518663510680199
Test Loss:  0.03421210125088692
Valid Loss:  0.030436212196946144
Epoch:  289  	Training Loss: 0.045185115188360214
Test Loss:  0.0342109277844429
Valid Loss:  0.030435122549533844
Epoch:  290  	Training Loss: 0.04518359526991844
Test Loss:  0.03420975059270859
Valid Loss:  0.030434031039476395
Epoch:  291  	Training Loss: 0.04518207907676697
Test Loss:  0.03420857712626457
Valid Loss:  0.030432946979999542
Epoch:  292  	Training Loss: 0.0451805517077446
Test Loss:  0.03420740365982056
Valid Loss:  0.03043186292052269
Epoch:  293  	Training Loss: 0.04517904296517372
Test Loss:  0.034206241369247437
Valid Loss:  0.030430778861045837
Epoch:  294  	Training Loss: 0.04517753794789314
Test Loss:  0.03420506790280342
Valid Loss:  0.030429691076278687
Epoch:  295  	Training Loss: 0.045176029205322266
Test Loss:  0.0342039056122303
Valid Loss:  0.030428610742092133
Epoch:  296  	Training Loss: 0.045174527913331985
Test Loss:  0.034202735871076584
Valid Loss:  0.03042753040790558
Epoch:  297  	Training Loss: 0.04517301917076111
Test Loss:  0.034201569855213165
Valid Loss:  0.030426453799009323
Epoch:  298  	Training Loss: 0.04517150670289993
Test Loss:  0.03420040011405945
Valid Loss:  0.03042536973953247
Epoch:  299  	Training Loss: 0.04517000541090965
Test Loss:  0.03419923782348633
Valid Loss:  0.030424287542700768
Epoch:  300  	Training Loss: 0.045168496668338776
Test Loss:  0.03419807180762291
Valid Loss:  0.030423207208514214
Epoch:  301  	Training Loss: 0.0451669879257679
Test Loss:  0.034196898341178894
Valid Loss:  0.030422119423747063
Epoch:  302  	Training Loss: 0.04516548663377762
Test Loss:  0.03419575095176697
Valid Loss:  0.03042105957865715
Epoch:  303  	Training Loss: 0.045164015144109726
Test Loss:  0.034194618463516235
Valid Loss:  0.030420005321502686
Epoch:  304  	Training Loss: 0.04516254737973213
Test Loss:  0.03419347107410431
Valid Loss:  0.03041894920170307
Epoch:  305  	Training Loss: 0.04516107589006424
Test Loss:  0.03419233113527298
Valid Loss:  0.030417893081903458
Epoch:  306  	Training Loss: 0.04515960440039635
Test Loss:  0.03419119864702225
Valid Loss:  0.030416836962103844
Epoch:  307  	Training Loss: 0.04515814036130905
Test Loss:  0.03419005870819092
Valid Loss:  0.03041578084230423
Epoch:  308  	Training Loss: 0.04515666514635086
Test Loss:  0.03418891504406929
Valid Loss:  0.030414726585149765
Epoch:  309  	Training Loss: 0.04515519365668297
Test Loss:  0.03418777137994766
Valid Loss:  0.030413657426834106
Epoch:  310  	Training Loss: 0.04515372961759567
Test Loss:  0.034186623990535736
Valid Loss:  0.030412599444389343
Epoch:  311  	Training Loss: 0.04515226185321808
Test Loss:  0.034185487776994705
Valid Loss:  0.03041154332458973
Epoch:  312  	Training Loss: 0.04515078663825989
Test Loss:  0.03418435901403427
Valid Loss:  0.03041050024330616
Epoch:  313  	Training Loss: 0.045149341225624084
Test Loss:  0.034183237701654434
Valid Loss:  0.03040946088731289
Epoch:  314  	Training Loss: 0.04514789581298828
Test Loss:  0.034182108938694
Valid Loss:  0.030408410355448723
Epoch:  315  	Training Loss: 0.04514644294977188
Test Loss:  0.034180983901023865
Valid Loss:  0.030407363548874855
Epoch:  316  	Training Loss: 0.04514499008655548
Test Loss:  0.03417985513806343
Valid Loss:  0.030406322330236435
Epoch:  317  	Training Loss: 0.04514354467391968
Test Loss:  0.034178726375103
Valid Loss:  0.030405281111598015
Epoch:  318  	Training Loss: 0.045142095535993576
Test Loss:  0.03417760878801346
Valid Loss:  0.030404238030314445
Epoch:  319  	Training Loss: 0.04514065384864807
Test Loss:  0.03417646884918213
Valid Loss:  0.03040318377315998
Epoch:  320  	Training Loss: 0.04513920098543167
Test Loss:  0.03417534381151199
Valid Loss:  0.030402138829231262
Epoch:  321  	Training Loss: 0.04513775557279587
Test Loss:  0.03417421877384186
Valid Loss:  0.030401095747947693
Epoch:  322  	Training Loss: 0.045136310160160065
Test Loss:  0.03417310118675232
Valid Loss:  0.03040006384253502
Epoch:  323  	Training Loss: 0.04513487592339516
Test Loss:  0.03417198359966278
Valid Loss:  0.030399024486541748
Epoch:  324  	Training Loss: 0.04513344168663025
Test Loss:  0.03417087718844414
Valid Loss:  0.030397992581129074
Epoch:  325  	Training Loss: 0.04513201117515564
Test Loss:  0.0341697558760643
Valid Loss:  0.0303969569504261
Epoch:  326  	Training Loss: 0.04513057321310043
Test Loss:  0.03416863828897476
Valid Loss:  0.030395925045013428
Epoch:  327  	Training Loss: 0.045129142701625824
Test Loss:  0.03416752070188522
Valid Loss:  0.030394887551665306
Epoch:  328  	Training Loss: 0.045127712190151215
Test Loss:  0.03416641056537628
Valid Loss:  0.030393851920962334
Epoch:  329  	Training Loss: 0.045126281678676605
Test Loss:  0.03416529670357704
Valid Loss:  0.03039282187819481
Epoch:  330  	Training Loss: 0.045124854892492294
Test Loss:  0.03416416794061661
Valid Loss:  0.030391773208975792
Epoch:  331  	Training Loss: 0.045123420655727386
Test Loss:  0.03416305407881737
Valid Loss:  0.03039073944091797
Epoch:  332  	Training Loss: 0.04512199014425278
Test Loss:  0.03416195884346962
Valid Loss:  0.03038972243666649
Epoch:  333  	Training Loss: 0.04512058198451996
Test Loss:  0.034160856157541275
Valid Loss:  0.030388709157705307
Epoch:  334  	Training Loss: 0.04511917382478714
Test Loss:  0.034159768372774124
Valid Loss:  0.030387692153453827
Epoch:  335  	Training Loss: 0.04511776566505432
Test Loss:  0.03415866196155548
Valid Loss:  0.030386675149202347
Epoch:  336  	Training Loss: 0.0451163575053215
Test Loss:  0.03415757417678833
Valid Loss:  0.030385660007596016
Epoch:  337  	Training Loss: 0.045114949345588684
Test Loss:  0.034156471490859985
Valid Loss:  0.030384644865989685
Epoch:  338  	Training Loss: 0.045113541185855865
Test Loss:  0.03415537625551224
Valid Loss:  0.030383625999093056
Epoch:  339  	Training Loss: 0.045112136751413345
Test Loss:  0.03415428102016449
Valid Loss:  0.030382605269551277
Epoch:  340  	Training Loss: 0.04511072859168053
Test Loss:  0.03415318578481674
Valid Loss:  0.030381590127944946
Epoch:  341  	Training Loss: 0.04510932415723801
Test Loss:  0.034152090549468994
Valid Loss:  0.030380574986338615
Epoch:  342  	Training Loss: 0.04510791599750519
Test Loss:  0.03415100648999214
Valid Loss:  0.03037956915795803
Epoch:  343  	Training Loss: 0.04510653764009476
Test Loss:  0.034149933606386185
Valid Loss:  0.030378572642803192
Epoch:  344  	Training Loss: 0.045105163007974625
Test Loss:  0.03414885327219963
Valid Loss:  0.030377574265003204
Epoch:  345  	Training Loss: 0.045103784650564194
Test Loss:  0.034147776663303375
Valid Loss:  0.030376574024558067
Epoch:  346  	Training Loss: 0.04510240629315376
Test Loss:  0.034146685153245926
Valid Loss:  0.030375560745596886
Epoch:  347  	Training Loss: 0.04510102421045303
Test Loss:  0.03414560854434967
Valid Loss:  0.03037455305457115
Epoch:  348  	Training Loss: 0.0450996495783329
Test Loss:  0.034144528210163116
Valid Loss:  0.030373558402061462
Epoch:  349  	Training Loss: 0.04509827122092247
Test Loss:  0.03414345532655716
Valid Loss:  0.030372556298971176
Epoch:  350  	Training Loss: 0.04509689658880234
Test Loss:  0.034142374992370605
Valid Loss:  0.03037155792117119
Epoch:  351  	Training Loss: 0.04509551823139191
Test Loss:  0.03414129465818405
Valid Loss:  0.030370552092790604
Epoch:  352  	Training Loss: 0.04509413242340088
Test Loss:  0.034140221774578094
Valid Loss:  0.030369559302926064
Epoch:  353  	Training Loss: 0.04509276896715164
Test Loss:  0.034139156341552734
Valid Loss:  0.030368570238351822
Epoch:  354  	Training Loss: 0.0450914092361927
Test Loss:  0.03413808345794678
Valid Loss:  0.03036758117377758
Epoch:  355  	Training Loss: 0.045090049505233765
Test Loss:  0.03413701429963112
Valid Loss:  0.03036658838391304
Epoch:  356  	Training Loss: 0.04508868604898453
Test Loss:  0.03413594514131546
Valid Loss:  0.03036559373140335
 71%|███████▏  | 357/500 [04:04<01:03,  2.25it/s] 72%|███████▏  | 359/500 [04:05<00:46,  3.02it/s] 72%|███████▏  | 361/500 [04:11<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:11<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:11<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:11<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:11<00:43,  3.02it/s] 74%|███████▍  | 371/500 [04:18<02:30,  1.16s/it] 75%|███████▍  | 373/500 [04:18<01:46,  1.20it/s] 75%|███████▌  | 375/500 [04:18<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:18<00:54,  2.26it/s] 76%|███████▌  | 379/500 [04:18<00:40,  3.02it/s] 76%|███████▌  | 381/500 [04:24<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:25<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:25<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:25<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:25<00:37,  3.00it/s] 78%|███████▊  | 391/500 [04:31<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:31<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:32<01:04,  1.64it/s] 79%|███████▉  | 397/500 [04:32<00:46,  2.24it/s] 80%|███████▉  | 399/500 [04:32<00:33,  3.01it/s] 80%|████████  | 401/500 [04:38<01:56,  1.17s/it] 81%|████████  | 403/500 [04:38<01:21,  1.19it/s] 81%|████████  | 405/500 [04:38<00:57,  1.64it/s] 81%|████████▏ | 407/500 [04:38<00:41,  2.24it/s] 82%|████████▏ | 409/500 [04:39<00:30,  3.01it/s] 82%|████████▏ | 411/500 [04:45<01:44,  1.18s/it] 83%|████████▎ | 413/500 [04:45<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:45<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:45<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:45<00:27,  3.00it/s] 84%|████████▍ | 421/500 [04:52<01:31,  1.16s/it] 85%|████████▍ | 423/500 [04:52<01:04,  1.20it/s] 85%|████████▌ | 425/500 [04:52<00:45,  1.65it/s] 85%|████████▌ | 427/500 [04:52<00:32,  2.22it/s]Epoch:  357  	Training Loss: 0.04508732259273529
Test Loss:  0.0341348759829998
Valid Loss:  0.03036459907889366
Epoch:  358  	Training Loss: 0.04508595913648605
Test Loss:  0.03413381054997444
Valid Loss:  0.030363604426383972
Epoch:  359  	Training Loss: 0.045084595680236816
Test Loss:  0.03413273021578789
Valid Loss:  0.03036261349916458
Epoch:  360  	Training Loss: 0.04508323222398758
Test Loss:  0.03413166478276253
Valid Loss:  0.03036162257194519
Epoch:  361  	Training Loss: 0.04508186876773834
Test Loss:  0.03413059562444687
Valid Loss:  0.0303606279194355
Epoch:  362  	Training Loss: 0.045080505311489105
Test Loss:  0.03412952646613121
Valid Loss:  0.03035963885486126
Epoch:  363  	Training Loss: 0.045079149305820465
Test Loss:  0.03412846475839615
Valid Loss:  0.030358655378222466
Epoch:  364  	Training Loss: 0.04507779702544212
Test Loss:  0.03412739932537079
Valid Loss:  0.030357666313648224
Epoch:  365  	Training Loss: 0.04507644474506378
Test Loss:  0.03412633761763573
Valid Loss:  0.030356671661138535
Epoch:  366  	Training Loss: 0.04507508873939514
Test Loss:  0.03412527218461037
Valid Loss:  0.03035568818449974
Epoch:  367  	Training Loss: 0.0450737364590168
Test Loss:  0.034124210476875305
Valid Loss:  0.030354700982570648
Epoch:  368  	Training Loss: 0.04507238045334816
Test Loss:  0.034123145043849945
Valid Loss:  0.030353717505931854
Epoch:  369  	Training Loss: 0.04507103189826012
Test Loss:  0.03412208706140518
Valid Loss:  0.030352722853422165
Epoch:  370  	Training Loss: 0.04506967216730118
Test Loss:  0.034121014177799225
Valid Loss:  0.030351731926202774
Epoch:  371  	Training Loss: 0.04506831616163254
Test Loss:  0.03411995247006416
Valid Loss:  0.03035074472427368
Epoch:  372  	Training Loss: 0.045066967606544495
Test Loss:  0.034118905663490295
Valid Loss:  0.03034977614879608
Epoch:  373  	Training Loss: 0.04506564885377884
Test Loss:  0.03411787375807762
Valid Loss:  0.030348816886544228
Epoch:  374  	Training Loss: 0.045064326375722885
Test Loss:  0.03411683067679405
Valid Loss:  0.030347853899002075
Epoch:  375  	Training Loss: 0.04506300762295723
Test Loss:  0.03411578759551048
Valid Loss:  0.030346889048814774
Epoch:  376  	Training Loss: 0.045061685144901276
Test Loss:  0.03411475196480751
Valid Loss:  0.030345922335982323
Epoch:  377  	Training Loss: 0.04506036639213562
Test Loss:  0.03411371633410454
Valid Loss:  0.030344955623149872
Epoch:  378  	Training Loss: 0.045059043914079666
Test Loss:  0.03411267325282097
Valid Loss:  0.03034399449825287
Epoch:  379  	Training Loss: 0.04505772516131401
Test Loss:  0.034111641347408295
Valid Loss:  0.030343029648065567
Epoch:  380  	Training Loss: 0.04505640268325806
Test Loss:  0.034110598266124725
Valid Loss:  0.030342064797878265
Epoch:  381  	Training Loss: 0.0450550839304924
Test Loss:  0.03410956263542175
Valid Loss:  0.030341096222400665
Epoch:  382  	Training Loss: 0.045053765177726746
Test Loss:  0.03410853073000908
Valid Loss:  0.03034014068543911
Epoch:  383  	Training Loss: 0.04505245387554169
Test Loss:  0.03410749137401581
Valid Loss:  0.030339179560542107
Epoch:  384  	Training Loss: 0.04505114629864693
Test Loss:  0.034106455743312836
Valid Loss:  0.030338216572999954
Epoch:  385  	Training Loss: 0.04504983872175217
Test Loss:  0.03410542383790016
Valid Loss:  0.03033725917339325
Epoch:  386  	Training Loss: 0.04504852369427681
Test Loss:  0.03410439193248749
Valid Loss:  0.030336301773786545
Epoch:  387  	Training Loss: 0.04504720866680145
Test Loss:  0.034103356301784515
Valid Loss:  0.03033534064888954
Epoch:  388  	Training Loss: 0.045045897364616394
Test Loss:  0.03410232067108154
Valid Loss:  0.030334386974573135
Epoch:  389  	Training Loss: 0.045044586062431335
Test Loss:  0.03410128876566887
Valid Loss:  0.030333422124385834
Epoch:  390  	Training Loss: 0.04504327476024628
Test Loss:  0.034100256860256195
Valid Loss:  0.030332457274198532
Epoch:  391  	Training Loss: 0.04504196345806122
Test Loss:  0.034099217504262924
Valid Loss:  0.030331498011946678
Epoch:  392  	Training Loss: 0.04504065215587616
Test Loss:  0.034098200500011444
Valid Loss:  0.03033054992556572
Epoch:  393  	Training Loss: 0.045039355754852295
Test Loss:  0.03409717231988907
Valid Loss:  0.030329599976539612
Epoch:  394  	Training Loss: 0.04503805935382843
Test Loss:  0.03409615159034729
Valid Loss:  0.030328650027513504
Epoch:  395  	Training Loss: 0.04503677040338516
Test Loss:  0.03409513086080551
Valid Loss:  0.030327703803777695
Epoch:  396  	Training Loss: 0.0450354740023613
Test Loss:  0.03409411013126373
Valid Loss:  0.030326753854751587
Epoch:  397  	Training Loss: 0.04503418132662773
Test Loss:  0.03409309685230255
Valid Loss:  0.030325809493660927
Epoch:  398  	Training Loss: 0.045032888650894165
Test Loss:  0.034092068672180176
Valid Loss:  0.030324861407279968
Epoch:  399  	Training Loss: 0.0450315959751606
Test Loss:  0.0340910479426384
Valid Loss:  0.03032391518354416
Epoch:  400  	Training Loss: 0.04503030329942703
Test Loss:  0.03409002721309662
Valid Loss:  0.030322961509227753
Epoch:  401  	Training Loss: 0.04502900689840317
Test Loss:  0.03408900648355484
Valid Loss:  0.030322011560201645
Epoch:  402  	Training Loss: 0.0450277179479599
Test Loss:  0.03408801555633545
Valid Loss:  0.030321083962917328
Epoch:  403  	Training Loss: 0.04502645879983902
Test Loss:  0.03408701717853546
Valid Loss:  0.03032016009092331
Epoch:  404  	Training Loss: 0.04502519965171814
Test Loss:  0.034086018800735474
Valid Loss:  0.030319232493638992
Epoch:  405  	Training Loss: 0.04502394422888756
Test Loss:  0.034085020422935486
Valid Loss:  0.030318304896354675
Epoch:  406  	Training Loss: 0.04502268508076668
Test Loss:  0.034084025770425797
Valid Loss:  0.030317384749650955
Epoch:  407  	Training Loss: 0.045021429657936096
Test Loss:  0.03408302366733551
Valid Loss:  0.030316457152366638
Epoch:  408  	Training Loss: 0.045020170509815216
Test Loss:  0.03408203274011612
Valid Loss:  0.030315527692437172
Epoch:  409  	Training Loss: 0.04501891881227493
Test Loss:  0.03408103436231613
Valid Loss:  0.030314601957798004
Epoch:  410  	Training Loss: 0.04501765966415405
Test Loss:  0.034080035984516144
Valid Loss:  0.030313678085803986
Epoch:  411  	Training Loss: 0.04501640051603317
Test Loss:  0.034079037606716156
Valid Loss:  0.030312754213809967
Epoch:  412  	Training Loss: 0.04501514509320259
Test Loss:  0.034078050404787064
Valid Loss:  0.03031183034181595
Epoch:  413  	Training Loss: 0.045013897120952606
Test Loss:  0.034077055752277374
Valid Loss:  0.03031090833246708
Epoch:  414  	Training Loss: 0.04501264542341232
Test Loss:  0.03407606482505798
Valid Loss:  0.03030998632311821
Epoch:  415  	Training Loss: 0.04501139372587204
Test Loss:  0.034075070172548294
Valid Loss:  0.030309056863188744
Epoch:  416  	Training Loss: 0.04501014202833176
Test Loss:  0.0340740792453289
Valid Loss:  0.030308138579130173
Epoch:  417  	Training Loss: 0.04500889033079147
Test Loss:  0.03407308831810951
Valid Loss:  0.030307210981845856
Epoch:  418  	Training Loss: 0.04500763863325119
Test Loss:  0.03407209739089012
Valid Loss:  0.030306292697787285
Epoch:  419  	Training Loss: 0.04500638693571091
Test Loss:  0.03407110273838043
Valid Loss:  0.030305368825793266
Epoch:  420  	Training Loss: 0.045005135238170624
Test Loss:  0.03407010808587074
Valid Loss:  0.030304446816444397
Epoch:  421  	Training Loss: 0.04500389099121094
Test Loss:  0.03406912088394165
Valid Loss:  0.03030352294445038
Epoch:  422  	Training Loss: 0.045002639293670654
Test Loss:  0.03406812995672226
Valid Loss:  0.030302610248327255
Epoch:  423  	Training Loss: 0.04500139504671097
Test Loss:  0.03406713902950287
Valid Loss:  0.030301688238978386
Epoch:  424  	Training Loss: 0.04500015079975128
Test Loss:  0.034066155552864075
Valid Loss:  0.030300773680210114
Epoch:  425  	Training Loss: 0.044998899102211
Test Loss:  0.03406517207622528
Valid Loss:  0.030299855396151543
Epoch:  426  	Training Loss: 0.04499766230583191
Test Loss:  0.03406418114900589
Valid Loss:  0.030298937112092972
Epoch:  427  	Training Loss: 0.04499641805887222
Test Loss:  0.0340631939470768
Valid Loss:  0.03029801696538925
 86%|████████▌ | 429/500 [04:52<00:24,  2.95it/s] 86%|████████▌ | 431/500 [04:58<01:21,  1.18s/it] 87%|████████▋ | 433/500 [04:59<00:56,  1.18it/s] 87%|████████▋ | 435/500 [04:59<00:39,  1.63it/s] 87%|████████▋ | 437/500 [04:59<00:28,  2.23it/s] 88%|████████▊ | 439/500 [04:59<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:05<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:05<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:06<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:06<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:06<00:17,  3.00it/s] 90%|█████████ | 451/500 [05:12<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:12<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:12<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:13<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:13<00:13,  3.01it/s] 92%|█████████▏| 461/500 [05:19<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:19<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:19<00:21,  1.65it/s] 93%|█████████▎| 467/500 [05:19<00:14,  2.25it/s] 94%|█████████▍| 469/500 [05:19<00:10,  3.03it/s] 94%|█████████▍| 471/500 [05:26<00:34,  1.17s/it] 95%|█████████▍| 473/500 [05:26<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:26<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:26<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:26<00:06,  3.02it/s] 96%|█████████▌| 481/500 [05:33<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:33<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:33<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:33<00:05,  2.25it/s] 98%|█████████▊| 489/500 [05:33<00:03,  3.02it/s] 98%|█████████▊| 491/500 [05:39<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:40<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:40<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:40<00:01,  2.22it/s]Epoch:  428  	Training Loss: 0.04499517381191254
Test Loss:  0.034062206745147705
Valid Loss:  0.03029709868133068
Epoch:  429  	Training Loss: 0.04499392956495285
Test Loss:  0.03406122326850891
Valid Loss:  0.030296185985207558
Epoch:  430  	Training Loss: 0.044992685317993164
Test Loss:  0.03406023979187012
Valid Loss:  0.030295271426439285
Epoch:  431  	Training Loss: 0.04499144107103348
Test Loss:  0.034059248864650726
Valid Loss:  0.030294349417090416
Epoch:  432  	Training Loss: 0.04499020054936409
Test Loss:  0.03405827283859253
Valid Loss:  0.03029344044625759
Epoch:  433  	Training Loss: 0.044988974928855896
Test Loss:  0.03405729681253433
Valid Loss:  0.030292533338069916
Epoch:  434  	Training Loss: 0.044987745583057404
Test Loss:  0.03405631333589554
Valid Loss:  0.03029162436723709
Epoch:  435  	Training Loss: 0.04498651623725891
Test Loss:  0.03405534476041794
Valid Loss:  0.030290719121694565
Epoch:  436  	Training Loss: 0.04498528689146042
Test Loss:  0.03405435383319855
Valid Loss:  0.03028980642557144
Epoch:  437  	Training Loss: 0.04498406499624252
Test Loss:  0.03405338525772095
Valid Loss:  0.030288897454738617
Epoch:  438  	Training Loss: 0.044982828199863434
Test Loss:  0.03405241295695305
Valid Loss:  0.03028799220919609
Epoch:  439  	Training Loss: 0.04498160630464554
Test Loss:  0.03405143320560455
Valid Loss:  0.03028707765042782
Epoch:  440  	Training Loss: 0.044980376958847046
Test Loss:  0.03405044972896576
Valid Loss:  0.030286168679594994
Epoch:  441  	Training Loss: 0.04497914761304855
Test Loss:  0.034049469977617264
Valid Loss:  0.030285263434052467
Epoch:  442  	Training Loss: 0.04497792199254036
Test Loss:  0.03404850512742996
Valid Loss:  0.03028436377644539
Epoch:  443  	Training Loss: 0.04497670382261276
Test Loss:  0.03404753655195236
Valid Loss:  0.030283460393548012
Epoch:  444  	Training Loss: 0.04497549310326576
Test Loss:  0.034046564251184464
Valid Loss:  0.030282551422715187
Epoch:  445  	Training Loss: 0.044974274933338165
Test Loss:  0.03404559940099716
Valid Loss:  0.030281653627753258
Epoch:  446  	Training Loss: 0.04497306048870087
Test Loss:  0.03404463082551956
Valid Loss:  0.03028075397014618
Epoch:  447  	Training Loss: 0.04497184604406357
Test Loss:  0.03404366225004196
Valid Loss:  0.030279850587248802
Epoch:  448  	Training Loss: 0.04497063159942627
Test Loss:  0.03404268994927406
Valid Loss:  0.030278943479061127
Epoch:  449  	Training Loss: 0.044969409704208374
Test Loss:  0.034041717648506165
Valid Loss:  0.030278049409389496
Epoch:  450  	Training Loss: 0.044968198984861374
Test Loss:  0.03404075279831886
Valid Loss:  0.030277151614427567
Epoch:  451  	Training Loss: 0.04496698081493378
Test Loss:  0.034039780497550964
Valid Loss:  0.03027624636888504
Epoch:  452  	Training Loss: 0.04496576637029648
Test Loss:  0.03403881564736366
Valid Loss:  0.030275342985987663
Epoch:  453  	Training Loss: 0.04496455192565918
Test Loss:  0.034037843346595764
Valid Loss:  0.030274445191025734
Epoch:  454  	Training Loss: 0.04496333748102188
Test Loss:  0.034036874771118164
Valid Loss:  0.030273549258708954
Epoch:  455  	Training Loss: 0.04496212303638458
Test Loss:  0.034035906195640564
Valid Loss:  0.03027264215052128
Epoch:  456  	Training Loss: 0.044960908591747284
Test Loss:  0.034034933894872665
Valid Loss:  0.03027174435555935
Epoch:  457  	Training Loss: 0.044959694147109985
Test Loss:  0.03403397649526596
Valid Loss:  0.030270840972661972
Epoch:  458  	Training Loss: 0.04495847597718239
Test Loss:  0.034033000469207764
Valid Loss:  0.03026994690299034
Epoch:  459  	Training Loss: 0.04495726525783539
Test Loss:  0.03403203561902046
Valid Loss:  0.030269037932157516
Epoch:  460  	Training Loss: 0.04495605081319809
Test Loss:  0.034031059592962265
Valid Loss:  0.030268138274550438
Epoch:  461  	Training Loss: 0.04495483636856079
Test Loss:  0.03403009846806526
Valid Loss:  0.03026723489165306
Epoch:  462  	Training Loss: 0.044953614473342896
Test Loss:  0.03402913361787796
Valid Loss:  0.03026634454727173
Epoch:  463  	Training Loss: 0.04495241492986679
Test Loss:  0.034028176218271255
Valid Loss:  0.0302654467523098
Epoch:  464  	Training Loss: 0.04495120793581009
Test Loss:  0.034027211368083954
Valid Loss:  0.03026455268263817
Epoch:  465  	Training Loss: 0.04495000094175339
Test Loss:  0.03402625769376755
Valid Loss:  0.030263662338256836
Epoch:  466  	Training Loss: 0.044948797672986984
Test Loss:  0.034025292843580246
Valid Loss:  0.030262764543294907
Epoch:  467  	Training Loss: 0.04494759440422058
Test Loss:  0.034024327993392944
Valid Loss:  0.030261874198913574
Epoch:  468  	Training Loss: 0.04494638741016388
Test Loss:  0.03402336686849594
Valid Loss:  0.030260980129241943
Epoch:  469  	Training Loss: 0.04494518041610718
Test Loss:  0.034022413194179535
Valid Loss:  0.03026008978486061
Epoch:  470  	Training Loss: 0.044943973422050476
Test Loss:  0.03402144834399223
Valid Loss:  0.03025919571518898
Epoch:  471  	Training Loss: 0.04494277387857437
Test Loss:  0.03402049094438553
Valid Loss:  0.0302582997828722
Epoch:  472  	Training Loss: 0.04494156688451767
Test Loss:  0.034019552171230316
Valid Loss:  0.03025742620229721
Epoch:  473  	Training Loss: 0.044940393418073654
Test Loss:  0.0340186171233654
Valid Loss:  0.03025655820965767
Epoch:  474  	Training Loss: 0.04493922367691994
Test Loss:  0.03401768207550049
Valid Loss:  0.03025568276643753
Epoch:  475  	Training Loss: 0.04493805393576622
Test Loss:  0.03401673585176468
Valid Loss:  0.030254816636443138
Epoch:  476  	Training Loss: 0.044936880469322205
Test Loss:  0.034015800803899765
Valid Loss:  0.03025394305586815
Epoch:  477  	Training Loss: 0.04493570327758789
Test Loss:  0.03401487320661545
Valid Loss:  0.030253073200583458
Epoch:  478  	Training Loss: 0.04493454098701477
Test Loss:  0.034013934433460236
Valid Loss:  0.03025219962000847
Epoch:  479  	Training Loss: 0.044933367520570755
Test Loss:  0.03401299566030502
Valid Loss:  0.03025132790207863
Epoch:  480  	Training Loss: 0.04493219405412674
Test Loss:  0.03401206061244011
Valid Loss:  0.03025045618414879
Epoch:  481  	Training Loss: 0.044931020587682724
Test Loss:  0.034011129289865494
Valid Loss:  0.030249586328864098
Epoch:  482  	Training Loss: 0.04492985084652901
Test Loss:  0.034010183066129684
Valid Loss:  0.03024871274828911
Epoch:  483  	Training Loss: 0.04492867365479469
Test Loss:  0.03400924429297447
Valid Loss:  0.03024783357977867
Epoch:  484  	Training Loss: 0.04492750018835068
Test Loss:  0.03400830551981926
Valid Loss:  0.030246958136558533
Epoch:  485  	Training Loss: 0.044926322996616364
Test Loss:  0.034007370471954346
Valid Loss:  0.030246086418628693
Epoch:  486  	Training Loss: 0.04492514580488205
Test Loss:  0.034006424248218536
Valid Loss:  0.030245210975408554
Epoch:  487  	Training Loss: 0.044923968613147736
Test Loss:  0.034005485475063324
Valid Loss:  0.030244342982769012
Epoch:  488  	Training Loss: 0.04492279142141342
Test Loss:  0.03400454670190811
Valid Loss:  0.030243463814258575
Epoch:  489  	Training Loss: 0.04492161422967911
Test Loss:  0.0340036079287529
Valid Loss:  0.030242588371038437
Epoch:  490  	Training Loss: 0.04492044076323509
Test Loss:  0.03400266915559769
Valid Loss:  0.0302417129278183
Epoch:  491  	Training Loss: 0.04491926729679108
Test Loss:  0.034001730382442474
Valid Loss:  0.030240841209888458
Epoch:  492  	Training Loss: 0.044918086379766464
Test Loss:  0.034000784158706665
Valid Loss:  0.03023996204137802
Epoch:  493  	Training Loss: 0.04491691663861275
Test Loss:  0.03399984538555145
Valid Loss:  0.03023909218609333
Epoch:  494  	Training Loss: 0.04491574317216873
Test Loss:  0.03399891033768654
Valid Loss:  0.030238216742873192
Epoch:  495  	Training Loss: 0.044914573431015015
Test Loss:  0.033997975289821625
Valid Loss:  0.0302373468875885
Epoch:  496  	Training Loss: 0.0449134036898613
Test Loss:  0.033997029066085815
Valid Loss:  0.030236471444368362
Epoch:  497  	Training Loss: 0.04491223022341728
Test Loss:  0.0339960902929306
Valid Loss:  0.030235599726438522
Epoch:  498  	Training Loss: 0.044911064207553864
Test Loss:  0.03399515151977539
Valid Loss:  0.030234724283218384
100%|█████████▉| 499/500 [05:40<00:00,  2.98it/s]100%|██████████| 500/500 [05:40<00:00,  1.47it/s]
Epoch:  499  	Training Loss: 0.044909894466400146
Test Loss:  0.03399421647191048
Valid Loss:  0.030233846977353096
Epoch:  500  	Training Loss: 0.04490872472524643
Test Loss:  0.033993273973464966
Valid Loss:  0.030232975259423256
seed is  1
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:38,  6.21s/it]  1%|          | 3/500 [00:06<13:44,  1.66s/it]  1%|          | 5/500 [00:06<06:55,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.96it/s]  2%|▏         | 9/500 [00:06<02:48,  2.92it/s]  2%|▏         | 11/500 [00:12<10:42,  1.31s/it]  3%|▎         | 13/500 [00:13<07:18,  1.11it/s]  3%|▎         | 15/500 [00:13<05:05,  1.59it/s]  3%|▎         | 17/500 [00:13<03:38,  2.21it/s]  4%|▍         | 19/500 [00:13<02:40,  3.01it/s]  4%|▍         | 21/500 [00:19<09:24,  1.18s/it]  5%|▍         | 23/500 [00:19<06:40,  1.19it/s]  5%|▌         | 25/500 [00:26<12:09,  1.54s/it]  5%|▌         | 27/500 [00:26<08:36,  1.09s/it]  6%|▌         | 29/500 [00:26<06:08,  1.28it/s]  6%|▌         | 31/500 [00:32<11:40,  1.49s/it]  7%|▋         | 33/500 [00:32<08:17,  1.07s/it]  7%|▋         | 35/500 [00:32<05:56,  1.31it/s]  7%|▋         | 37/500 [00:33<04:17,  1.80it/s]  8%|▊         | 39/500 [00:33<03:08,  2.44it/s]  8%|▊         | 41/500 [00:39<09:16,  1.21s/it]  9%|▊         | 43/500 [00:39<06:37,  1.15it/s]  9%|▉         | 45/500 [00:39<04:46,  1.59it/s]  9%|▉         | 47/500 [00:39<03:28,  2.17it/s] 10%|▉         | 49/500 [00:39<02:34,  2.93it/s] 10%|█         | 51/500 [00:46<08:51,  1.18s/it] 11%|█         | 53/500 [00:46<06:19,  1.18it/s] 11%|█         | 55/500 [00:46<04:33,  1.63it/s] 11%|█▏        | 57/500 [00:46<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:46<02:27,  2.99it/s] 12%|█▏        | 61/500 [00:52<08:33,  1.17s/it] 13%|█▎        | 63/500 [00:53<06:07,  1.19it/s] 13%|█▎        | 65/500 [00:53<04:24,  1.64it/s] 13%|█▎        | 67/500 [00:53<03:13,  2.23it/s]Epoch:  1  	Training Loss: 0.031477488577365875
Test Loss:  0.0745231956243515
Valid Loss:  0.0759594738483429
Epoch:  2  	Training Loss: 0.06729264557361603
Test Loss:  0.7907660007476807
Valid Loss:  0.7832408547401428
Epoch:  3  	Training Loss: 0.8550412654876709
Test Loss:  0.05739917233586311
Valid Loss:  0.058039963245391846
Epoch:  4  	Training Loss: 0.04935767501592636
Test Loss:  0.013176853768527508
Valid Loss:  0.013042984530329704
Epoch:  5  	Training Loss: 0.01132099237293005
Test Loss:  0.009154098108410835
Valid Loss:  0.008921376429498196
Epoch:  6  	Training Loss: 0.007548454683274031
Test Loss:  0.008466806262731552
Valid Loss:  0.008279101923108101
Epoch:  7  	Training Loss: 0.006897240877151489
Test Loss:  0.008150631561875343
Valid Loss:  0.007996365427970886
Epoch:  8  	Training Loss: 0.0066000837832689285
Test Loss:  0.007970128208398819
Valid Loss:  0.007846021093428135
Epoch:  9  	Training Loss: 0.006439558230340481
Test Loss:  0.007844475097954273
Valid Loss:  0.007744448725134134
Epoch:  10  	Training Loss: 0.006335068494081497
Test Loss:  0.0077534085139632225
Valid Loss:  0.007662838324904442
Epoch:  11  	Training Loss: 0.006257580127567053
Test Loss:  0.007686414755880833
Valid Loss:  0.007595319766551256
Epoch:  12  	Training Loss: 0.0061976127326488495
Test Loss:  0.0028447615914046764
Valid Loss:  0.00256909872405231
Epoch:  13  	Training Loss: 0.003087347373366356
Test Loss:  0.007774346973747015
Valid Loss:  0.007659622002393007
Epoch:  14  	Training Loss: 0.007048754021525383
Test Loss:  0.012640362605452538
Valid Loss:  0.011712202802300453
Epoch:  15  	Training Loss: 0.015668651089072227
Test Loss:  0.0051347846165299416
Valid Loss:  0.0050020888447761536
Epoch:  16  	Training Loss: 0.004643792752176523
Test Loss:  0.0035088788717985153
Valid Loss:  0.0031527080573141575
Epoch:  17  	Training Loss: 0.0032453001476824284
Test Loss:  0.002607638482004404
Valid Loss:  0.002438665134832263
Epoch:  18  	Training Loss: 0.0019390161614865065
Test Loss:  0.0021730149164795876
Valid Loss:  0.0019954494200646877
Epoch:  19  	Training Loss: 0.0016352778766304255
Test Loss:  0.0019924163352698088
Valid Loss:  0.0018513139802962542
Epoch:  20  	Training Loss: 0.0013962702360004187
Test Loss:  0.0017812312580645084
Valid Loss:  0.0016246240120381117
Epoch:  21  	Training Loss: 0.001261623576283455
Test Loss:  0.00167048629373312
Valid Loss:  0.0015518891159445047
Epoch:  22  	Training Loss: 0.001145032700151205
Test Loss:  0.0013915998861193657
Valid Loss:  0.0012326331343501806
Epoch:  23  	Training Loss: 0.0015262127853929996
Test Loss:  0.004092012997716665
Valid Loss:  0.0039915041998028755
Epoch:  24  	Training Loss: 0.00423650024458766
Test Loss:  0.00456192484125495
Valid Loss:  0.004242758732289076
Epoch:  25  	Training Loss: 0.005409046541899443
Test Loss:  0.002420443342998624
Valid Loss:  0.0024197231978178024
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.0022733500227332115
Test Loss:  0.008539139293134212
Valid Loss:  0.008378064259886742
Epoch:  27  	Training Loss: 0.01025672722607851
Test Loss:  0.01612519472837448
Valid Loss:  0.01615183800458908
Epoch:  28  	Training Loss: 0.016965685412287712
Test Loss:  0.0026872570160776377
Valid Loss:  0.0023362315259873867
Epoch:  29  	Training Loss: 0.0027810544706881046
Test Loss:  0.0017399011412635446
Valid Loss:  0.001564006321132183
Epoch:  30  	Training Loss: 0.0012956876307725906
Test Loss:  0.0013977219350636005
Valid Loss:  0.0012426793109625578
Epoch:  31  	Training Loss: 0.0010255902307108045
Test Loss:  0.0011710997205227613
Valid Loss:  0.0010412863921374083
Epoch:  32  	Training Loss: 0.0008347267284989357
Test Loss:  0.0009527390357106924
Valid Loss:  0.0008401321247220039
Epoch:  33  	Training Loss: 0.0006778975948691368
Test Loss:  0.000787223456427455
Valid Loss:  0.0006895423866808414
Epoch:  34  	Training Loss: 0.0005567800835706294
Test Loss:  0.0006694122566841543
Valid Loss:  0.0005810048314742744
Epoch:  35  	Training Loss: 0.00046915115672163665
Test Loss:  0.0005777241894975305
Valid Loss:  0.0005012926994822919
Epoch:  36  	Training Loss: 0.0004025934904348105
Test Loss:  0.000497403962071985
Valid Loss:  0.00043253679177723825
Epoch:  37  	Training Loss: 0.0003485908964648843
Test Loss:  0.00043295504292473197
Valid Loss:  0.00037903309566900134
Epoch:  38  	Training Loss: 0.00030460976995527744
Test Loss:  0.00037701608380302787
Valid Loss:  0.000333410658640787
Epoch:  39  	Training Loss: 0.00026877765776589513
Test Loss:  0.0003321536642033607
Valid Loss:  0.00029791827546432614
Epoch:  40  	Training Loss: 0.0002395142801105976
Test Loss:  0.00029311279649846256
Valid Loss:  0.0002676659496501088
Epoch:  41  	Training Loss: 0.00021558623120654374
Test Loss:  0.0002616068522911519
Valid Loss:  0.0002440194512018934
Epoch:  42  	Training Loss: 0.0001960134250111878
Test Loss:  0.00018782881670631468
Valid Loss:  0.00019470820552669466
Epoch:  43  	Training Loss: 0.00016527320258319378
Test Loss:  0.00016401155153289437
Valid Loss:  0.00017922348342835903
Epoch:  44  	Training Loss: 0.00014668185031041503
Test Loss:  0.00013697028043679893
Valid Loss:  0.00016307493206113577
Epoch:  45  	Training Loss: 0.00013466723612509668
Test Loss:  0.00012197675823699683
Valid Loss:  0.00015426850586663932
Epoch:  46  	Training Loss: 0.00012651908036787063
Test Loss:  0.00010905110684689134
Valid Loss:  0.00014740860206075013
Epoch:  47  	Training Loss: 0.00012079754378646612
Test Loss:  0.00010049250704469159
Valid Loss:  0.00014280345931183547
Epoch:  48  	Training Loss: 0.0001167334194178693
Test Loss:  9.400218550581485e-05
Valid Loss:  0.00013917061733081937
Epoch:  49  	Training Loss: 0.00011363191879354417
Test Loss:  8.914544014260173e-05
Valid Loss:  0.000136166054289788
Epoch:  50  	Training Loss: 0.00011102845019195229
Test Loss:  8.481511758873239e-05
Valid Loss:  0.00013189009041525424
Epoch:  51  	Training Loss: 0.00010769949585665017
Test Loss:  8.250694372691214e-05
Valid Loss:  0.00012860978313256055
Epoch:  52  	Training Loss: 0.00010504992678761482
Test Loss:  8.143563172779977e-05
Valid Loss:  0.00012810024782083929
Epoch:  53  	Training Loss: 0.00010481104254722595
Test Loss:  8.089953917078674e-05
Valid Loss:  0.00012788853200618178
Epoch:  54  	Training Loss: 0.00010463556100148708
Test Loss:  8.058397361310199e-05
Valid Loss:  0.00012778933160007
Epoch:  55  	Training Loss: 0.00010448346438352019
Test Loss:  8.036762301344424e-05
Valid Loss:  0.00012773790513165295
Epoch:  56  	Training Loss: 0.00010435257718199864
Test Loss:  8.020403038244694e-05
Valid Loss:  0.00012770901957992464
Epoch:  57  	Training Loss: 0.00010423429193906486
Test Loss:  8.006882853806019e-05
Valid Loss:  0.00012769148452207446
Epoch:  58  	Training Loss: 0.0001041291980072856
Test Loss:  7.995109626790509e-05
Valid Loss:  0.00012768112355843186
Epoch:  59  	Training Loss: 0.00010403235501144081
Test Loss:  7.98496330389753e-05
Valid Loss:  0.00012767509906552732
Epoch:  60  	Training Loss: 0.00010394385026302189
Test Loss:  7.976367487572134e-05
Valid Loss:  0.0001276719121960923
Epoch:  61  	Training Loss: 0.00010386222857050598
Test Loss:  7.967639248818159e-05
Valid Loss:  0.00012766951113007963
Epoch:  62  	Training Loss: 0.00010377848957432434
Test Loss:  7.687417382840067e-05
Valid Loss:  0.0001271195651497692
Epoch:  63  	Training Loss: 0.00010027345706475899
Test Loss:  7.374982669716701e-05
Valid Loss:  0.000126373372040689
Epoch:  64  	Training Loss: 9.874928218778223e-05
Test Loss:  7.154980266932398e-05
Valid Loss:  0.00012607786629814655
Epoch:  65  	Training Loss: 9.778758976608515e-05
Test Loss:  6.99520533089526e-05
Valid Loss:  0.00012595969019457698
Epoch:  66  	Training Loss: 9.712805331218988e-05
Test Loss:  6.880566797917709e-05
Valid Loss:  0.00012592806888278574
Epoch:  67  	Training Loss: 9.668542043073103e-05
Test Loss:  6.799239781685174e-05
Valid Loss:  0.0001259611308341846
Epoch:  68  	Training Loss: 9.637358016334474e-05
Test Loss:  6.741580727975816e-05
Valid Loss:  0.00012598276953212917
 14%|█▍        | 69/500 [00:53<02:23,  3.01it/s] 14%|█▍        | 71/500 [00:59<08:29,  1.19s/it] 15%|█▍        | 73/500 [01:00<06:03,  1.17it/s] 15%|█▌        | 75/500 [01:00<04:21,  1.62it/s] 15%|█▌        | 77/500 [01:00<03:10,  2.22it/s] 16%|█▌        | 79/500 [01:00<02:21,  2.98it/s] 16%|█▌        | 81/500 [01:06<08:14,  1.18s/it] 17%|█▋        | 83/500 [01:06<05:53,  1.18it/s] 17%|█▋        | 85/500 [01:06<04:14,  1.63it/s] 17%|█▋        | 87/500 [01:07<03:05,  2.23it/s] 18%|█▊        | 89/500 [01:07<02:17,  2.99it/s] 18%|█▊        | 91/500 [01:13<08:04,  1.18s/it] 19%|█▊        | 93/500 [01:13<05:46,  1.18it/s] 19%|█▉        | 95/500 [01:13<04:08,  1.63it/s] 19%|█▉        | 97/500 [01:13<03:01,  2.22it/s] 20%|█▉        | 99/500 [01:14<02:14,  2.99it/s] 20%|██        | 101/500 [01:20<07:54,  1.19s/it] 21%|██        | 103/500 [01:20<05:38,  1.17it/s] 21%|██        | 105/500 [01:20<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:20<02:57,  2.22it/s] 22%|██▏       | 109/500 [01:21<02:11,  2.98it/s] 22%|██▏       | 111/500 [01:27<07:44,  1.19s/it] 23%|██▎       | 113/500 [01:27<05:31,  1.17it/s] 23%|██▎       | 115/500 [01:27<03:58,  1.61it/s] 23%|██▎       | 117/500 [01:27<02:53,  2.21it/s] 24%|██▍       | 119/500 [01:27<02:08,  2.97it/s] 24%|██▍       | 121/500 [01:34<07:31,  1.19s/it] 25%|██▍       | 123/500 [01:34<05:22,  1.17it/s] 25%|██▌       | 125/500 [01:34<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:34<02:48,  2.21it/s] 26%|██▌       | 129/500 [01:34<02:04,  2.97it/s] 26%|██▌       | 131/500 [01:41<07:17,  1.18s/it] 27%|██▋       | 133/500 [01:41<05:12,  1.18it/s] 27%|██▋       | 135/500 [01:41<03:44,  1.63it/s]Epoch:  69  	Training Loss: 9.616249008104205e-05
Test Loss:  6.703297549393028e-05
Valid Loss:  0.0001260404969798401
Epoch:  70  	Training Loss: 9.599993063602597e-05
Test Loss:  6.676281191175804e-05
Valid Loss:  0.00012609746772795916
Epoch:  71  	Training Loss: 9.586324449628592e-05
Test Loss:  6.646482506766915e-05
Valid Loss:  0.00012608108227141201
Epoch:  72  	Training Loss: 9.571741975378245e-05
Test Loss:  6.699334335280582e-05
Valid Loss:  0.00012371069169603288
Epoch:  73  	Training Loss: 9.445518662687391e-05
Test Loss:  6.73834583722055e-05
Valid Loss:  0.00012130806862842292
Epoch:  74  	Training Loss: 9.315005445387214e-05
Test Loss:  6.756253424100578e-05
Valid Loss:  0.00011892503971466795
Epoch:  75  	Training Loss: 9.167175448965281e-05
Test Loss:  6.750284228473902e-05
Valid Loss:  0.00011633491521934047
Epoch:  76  	Training Loss: 9.008971392177045e-05
Test Loss:  6.712728645652533e-05
Valid Loss:  0.00011368803097866476
Epoch:  77  	Training Loss: 8.831456216285005e-05
Test Loss:  6.649525312241167e-05
Valid Loss:  0.0001108016149373725
Epoch:  78  	Training Loss: 8.628290379419923e-05
Test Loss:  6.57675409456715e-05
Valid Loss:  0.00010798854054883122
Epoch:  79  	Training Loss: 8.43026937218383e-05
Test Loss:  6.509661761811003e-05
Valid Loss:  0.00010542817472014576
Epoch:  80  	Training Loss: 8.251814870163798e-05
Test Loss:  6.457138806581497e-05
Valid Loss:  0.00010335989645682275
Epoch:  81  	Training Loss: 8.098399121081457e-05
Test Loss:  6.431740621337667e-05
Valid Loss:  0.00010212288179900497
Epoch:  82  	Training Loss: 8.004940900718793e-05
Test Loss:  6.414779636543244e-05
Valid Loss:  0.00010248590842820704
Epoch:  83  	Training Loss: 7.960193033795804e-05
Test Loss:  6.368113827193156e-05
Valid Loss:  0.00010259349073749036
Epoch:  84  	Training Loss: 7.94819206930697e-05
Test Loss:  6.314214988378808e-05
Valid Loss:  0.00010258082329528406
Epoch:  85  	Training Loss: 7.941196963656694e-05
Test Loss:  6.267659773584455e-05
Valid Loss:  0.00010256002133246511
Epoch:  86  	Training Loss: 7.936454494483769e-05
Test Loss:  6.228229904081672e-05
Valid Loss:  0.0001025408782879822
Epoch:  87  	Training Loss: 7.933085726108402e-05
Test Loss:  6.194489833433181e-05
Valid Loss:  0.00010252191714243963
Epoch:  88  	Training Loss: 7.930594438221306e-05
Test Loss:  6.165537342894822e-05
Valid Loss:  0.00010250390914734453
Epoch:  89  	Training Loss: 7.928675040602684e-05
Test Loss:  6.140287587186322e-05
Valid Loss:  0.00010247699538012967
Epoch:  90  	Training Loss: 7.927228580228984e-05
Test Loss:  6.118984310887754e-05
Valid Loss:  0.0001024555676849559
Epoch:  91  	Training Loss: 7.92603095760569e-05
Test Loss:  6.100305472500622e-05
Valid Loss:  0.00010243513679597527
Epoch:  92  	Training Loss: 7.925047248136252e-05
Test Loss:  6.005283648846671e-05
Valid Loss:  0.00010159096564166248
Epoch:  93  	Training Loss: 7.884077058406547e-05
Test Loss:  5.9667327150236815e-05
Valid Loss:  0.00010125810513272882
Epoch:  94  	Training Loss: 7.848806853871793e-05
Test Loss:  5.923174467170611e-05
Valid Loss:  0.00010087882401421666
Epoch:  95  	Training Loss: 7.814996934030205e-05
Test Loss:  5.8818153775064275e-05
Valid Loss:  0.00010051024582935497
Epoch:  96  	Training Loss: 7.78272224124521e-05
Test Loss:  5.8449048083275557e-05
Valid Loss:  0.0001001691198325716
Epoch:  97  	Training Loss: 7.752570672892034e-05
Test Loss:  5.8104666095459834e-05
Valid Loss:  9.985182259697467e-05
Epoch:  98  	Training Loss: 7.724839815637097e-05
Test Loss:  5.7774424931267276e-05
Valid Loss:  9.956932626664639e-05
Epoch:  99  	Training Loss: 7.698252738919109e-05
Test Loss:  5.745064117945731e-05
Valid Loss:  9.929809311870486e-05
Epoch:  100  	Training Loss: 7.673045911360532e-05
Test Loss:  5.716711166314781e-05
Valid Loss:  9.905765182338655e-05
Epoch:  101  	Training Loss: 7.649885083083063e-05
Test Loss:  5.691740443580784e-05
Valid Loss:  9.883451275527477e-05
Epoch:  102  	Training Loss: 7.626138540217653e-05
Test Loss:  5.582148878602311e-05
Valid Loss:  9.822038555284962e-05
Epoch:  103  	Training Loss: 7.615849608555436e-05
Test Loss:  5.5714554036967456e-05
Valid Loss:  9.808316099224612e-05
Epoch:  104  	Training Loss: 7.61347109801136e-05
Test Loss:  5.5779040849301964e-05
Valid Loss:  9.802505519473925e-05
Epoch:  105  	Training Loss: 7.611465116497129e-05
Test Loss:  5.587404302787036e-05
Valid Loss:  9.79828109848313e-05
Epoch:  106  	Training Loss: 7.60955226724036e-05
Test Loss:  5.597298877546564e-05
Valid Loss:  9.794395737117156e-05
Epoch:  107  	Training Loss: 7.607760198879987e-05
Test Loss:  5.6068784033413976e-05
Valid Loss:  9.791077172849327e-05
Epoch:  108  	Training Loss: 7.606195867992938e-05
Test Loss:  5.616032285615802e-05
Valid Loss:  9.788043098524213e-05
Epoch:  109  	Training Loss: 7.604779239045456e-05
Test Loss:  5.624989717034623e-05
Valid Loss:  9.785089059732854e-05
Epoch:  110  	Training Loss: 7.60342663852498e-05
Test Loss:  5.633673572447151e-05
Valid Loss:  9.782631241250783e-05
Epoch:  111  	Training Loss: 7.602148980367929e-05
Test Loss:  5.6419637985527515e-05
Valid Loss:  9.780497930478305e-05
Epoch:  112  	Training Loss: 7.601063407491893e-05
Test Loss:  5.656080975313671e-05
Valid Loss:  9.78266034508124e-05
Epoch:  113  	Training Loss: 7.558746438007802e-05
Test Loss:  5.62640416319482e-05
Valid Loss:  9.732395119499415e-05
Epoch:  114  	Training Loss: 7.523998647229746e-05
Test Loss:  5.607990897260606e-05
Valid Loss:  9.696549386717379e-05
Epoch:  115  	Training Loss: 7.490869029425085e-05
Test Loss:  5.5881464504636824e-05
Valid Loss:  9.659756324253976e-05
Epoch:  116  	Training Loss: 7.457689207512885e-05
Test Loss:  5.5714644986437634e-05
Valid Loss:  9.62450576480478e-05
Epoch:  117  	Training Loss: 7.421716873068362e-05
Test Loss:  5.5518488807138056e-05
Valid Loss:  9.586638770997524e-05
Epoch:  118  	Training Loss: 7.387359801214188e-05
Test Loss:  5.533277726499364e-05
Valid Loss:  9.550726099405438e-05
Epoch:  119  	Training Loss: 7.35458088456653e-05
Test Loss:  5.515647353604436e-05
Valid Loss:  9.516988939139992e-05
Epoch:  120  	Training Loss: 7.323199679376557e-05
Test Loss:  5.498522659763694e-05
Valid Loss:  9.484805923420936e-05
Epoch:  121  	Training Loss: 7.292825466720387e-05
Test Loss:  5.480471008922905e-05
Valid Loss:  9.451877849642187e-05
Epoch:  122  	Training Loss: 7.26160651538521e-05
Test Loss:  5.4497591918334365e-05
Valid Loss:  9.433674131287262e-05
Epoch:  123  	Training Loss: 7.25245990906842e-05
Test Loss:  5.4222829930949956e-05
Valid Loss:  9.417506953468546e-05
Epoch:  124  	Training Loss: 7.244035077746958e-05
Test Loss:  5.3968611609889194e-05
Valid Loss:  9.402628347743303e-05
Epoch:  125  	Training Loss: 7.23678749636747e-05
Test Loss:  5.373323801904917e-05
Valid Loss:  9.388120088260621e-05
Epoch:  126  	Training Loss: 7.23073462722823e-05
Test Loss:  5.353043525246903e-05
Valid Loss:  9.375281661050394e-05
Epoch:  127  	Training Loss: 7.22526601748541e-05
Test Loss:  5.335151217877865e-05
Valid Loss:  9.363345452584326e-05
Epoch:  128  	Training Loss: 7.220478437375277e-05
Test Loss:  5.319648334989324e-05
Valid Loss:  9.352537745144218e-05
Epoch:  129  	Training Loss: 7.215999357867986e-05
Test Loss:  5.306277307681739e-05
Valid Loss:  9.343282727058977e-05
Epoch:  130  	Training Loss: 7.211675983853638e-05
Test Loss:  5.294358197716065e-05
Valid Loss:  9.335074719274417e-05
Epoch:  131  	Training Loss: 7.207452290458605e-05
Test Loss:  5.283467908157036e-05
Valid Loss:  9.328071610070765e-05
Epoch:  132  	Training Loss: 7.203439599834383e-05
Test Loss:  5.31780460732989e-05
Valid Loss:  9.367115126224235e-05
Epoch:  133  	Training Loss: 7.190933683887124e-05
Test Loss:  5.3154712077230215e-05
Valid Loss:  9.368203609483317e-05
Epoch:  134  	Training Loss: 7.189014286268502e-05
Test Loss:  5.309741754899733e-05
Valid Loss:  9.365497680846602e-05
Epoch:  135  	Training Loss: 7.187202572822571e-05
Test Loss:  5.3040093916933984e-05
Valid Loss:  9.362502896692604e-05
Epoch:  136  	Training Loss: 7.185402500908822e-05
Test Loss:  5.298497126204893e-05
Valid Loss:  9.359484101878479e-05
 27%|██▋       | 137/500 [01:41<02:43,  2.22it/s] 28%|██▊       | 139/500 [01:41<02:00,  2.99it/s] 28%|██▊       | 141/500 [01:47<07:02,  1.18s/it] 29%|██▊       | 143/500 [01:48<05:01,  1.18it/s] 29%|██▉       | 145/500 [01:48<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:48<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:48<01:56,  3.01it/s] 30%|███       | 151/500 [01:54<06:50,  1.18s/it] 31%|███       | 153/500 [01:54<04:53,  1.18it/s] 31%|███       | 155/500 [01:55<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:55<02:34,  2.22it/s] 32%|███▏      | 159/500 [01:55<01:56,  2.93it/s] 32%|███▏      | 161/500 [02:01<06:46,  1.20s/it] 33%|███▎      | 163/500 [02:01<04:49,  1.16it/s] 33%|███▎      | 165/500 [02:02<03:28,  1.61it/s] 33%|███▎      | 167/500 [02:02<02:31,  2.20it/s] 34%|███▍      | 169/500 [02:02<01:51,  2.96it/s] 34%|███▍      | 171/500 [02:08<06:35,  1.20s/it] 35%|███▍      | 173/500 [02:08<04:42,  1.16it/s] 35%|███▌      | 175/500 [02:09<03:22,  1.60it/s] 35%|███▌      | 177/500 [02:09<02:27,  2.19it/s] 36%|███▌      | 179/500 [02:09<01:48,  2.95it/s] 36%|███▌      | 181/500 [02:15<06:18,  1.19s/it] 37%|███▋      | 183/500 [02:15<04:29,  1.17it/s] 37%|███▋      | 185/500 [02:15<03:13,  1.62it/s] 37%|███▋      | 187/500 [02:16<02:20,  2.22it/s] 38%|███▊      | 189/500 [02:16<01:43,  2.99it/s] 38%|███▊      | 191/500 [02:22<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:22<04:21,  1.17it/s] 39%|███▉      | 195/500 [02:22<03:07,  1.62it/s] 39%|███▉      | 197/500 [02:22<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:23<01:40,  2.99it/s] 40%|████      | 201/500 [02:29<05:54,  1.18s/it] 41%|████      | 203/500 [02:29<04:12,  1.18it/s]Epoch:  137  	Training Loss: 7.183618436101824e-05
Test Loss:  5.2932373364456e-05
Valid Loss:  9.3565191491507e-05
Epoch:  138  	Training Loss: 7.181859109550714e-05
Test Loss:  5.287867315928452e-05
Valid Loss:  9.353543282486498e-05
Epoch:  139  	Training Loss: 7.180108514148742e-05
Test Loss:  5.282539495965466e-05
Valid Loss:  9.350601612823084e-05
Epoch:  140  	Training Loss: 7.17835791874677e-05
Test Loss:  5.277422314975411e-05
Valid Loss:  9.347678133053705e-05
Epoch:  141  	Training Loss: 7.176648796303198e-05
Test Loss:  5.272477210382931e-05
Valid Loss:  9.344764112029225e-05
Epoch:  142  	Training Loss: 7.17493167030625e-05
Test Loss:  5.2448427595663816e-05
Valid Loss:  9.282970859203488e-05
Epoch:  143  	Training Loss: 7.130340964067727e-05
Test Loss:  5.2380815759534016e-05
Valid Loss:  9.259031503461301e-05
Epoch:  144  	Training Loss: 7.091840961948037e-05
Test Loss:  5.22745685884729e-05
Valid Loss:  9.245114051736891e-05
Epoch:  145  	Training Loss: 7.063891098368913e-05
Test Loss:  5.217573925619945e-05
Valid Loss:  9.231733565684408e-05
Epoch:  146  	Training Loss: 7.046527753118426e-05
Test Loss:  5.208453512750566e-05
Valid Loss:  9.218545164912939e-05
Epoch:  147  	Training Loss: 7.037031173240393e-05
Test Loss:  5.2003459131810814e-05
Valid Loss:  9.205599781125784e-05
Epoch:  148  	Training Loss: 7.027700485195965e-05
Test Loss:  5.192997195990756e-05
Valid Loss:  9.192761353915557e-05
Epoch:  149  	Training Loss: 7.018419273663312e-05
Test Loss:  5.186197813600302e-05
Valid Loss:  9.180011693388224e-05
Epoch:  150  	Training Loss: 7.009156252024695e-05
Test Loss:  5.1798422646243125e-05
Valid Loss:  9.167434473056346e-05
Epoch:  151  	Training Loss: 6.999955076025799e-05
Test Loss:  5.17389526066836e-05
Valid Loss:  9.154916187981144e-05
Epoch:  152  	Training Loss: 6.990777183091268e-05
Test Loss:  5.166331538930535e-05
Valid Loss:  9.151312406174839e-05
Epoch:  153  	Training Loss: 6.986929656704888e-05
Test Loss:  5.1588358473964036e-05
Valid Loss:  9.147549280896783e-05
Epoch:  154  	Training Loss: 6.983128696447238e-05
Test Loss:  5.15145729877986e-05
Valid Loss:  9.143603529082611e-05
Epoch:  155  	Training Loss: 6.979383761063218e-05
Test Loss:  5.144217357155867e-05
Valid Loss:  9.139673056779429e-05
Epoch:  156  	Training Loss: 6.975690484978259e-05
Test Loss:  5.1370901928748935e-05
Valid Loss:  9.135719301411882e-05
Epoch:  157  	Training Loss: 6.972062692511827e-05
Test Loss:  5.1301427447469905e-05
Valid Loss:  9.13176336325705e-05
Epoch:  158  	Training Loss: 6.968474917812273e-05
Test Loss:  5.1233851991128176e-05
Valid Loss:  9.12784380489029e-05
Epoch:  159  	Training Loss: 6.964931526454166e-05
Test Loss:  5.1167669880669564e-05
Valid Loss:  9.123953350353986e-05
Epoch:  160  	Training Loss: 6.961433973629028e-05
Test Loss:  5.1103161240462214e-05
Valid Loss:  9.120105823967606e-05
Epoch:  161  	Training Loss: 6.957983714528382e-05
Test Loss:  5.104018418933265e-05
Valid Loss:  9.116324508795515e-05
Epoch:  162  	Training Loss: 6.954564014449716e-05
Test Loss:  5.085934390081093e-05
Valid Loss:  9.098900045501068e-05
Epoch:  163  	Training Loss: 6.945781933609396e-05
Test Loss:  5.073264037491754e-05
Valid Loss:  9.089584636967629e-05
Epoch:  164  	Training Loss: 6.93861220497638e-05
Test Loss:  5.06315627717413e-05
Valid Loss:  9.084133489523083e-05
Epoch:  165  	Training Loss: 6.932448013685644e-05
Test Loss:  5.055184010416269e-05
Valid Loss:  9.080418385565281e-05
Epoch:  166  	Training Loss: 6.926908099558204e-05
Test Loss:  5.0481197831686586e-05
Valid Loss:  9.077640424948186e-05
Epoch:  167  	Training Loss: 6.921893509570509e-05
Test Loss:  5.041978874942288e-05
Valid Loss:  9.075403067981824e-05
Epoch:  168  	Training Loss: 6.917412974871695e-05
Test Loss:  5.03710143675562e-05
Valid Loss:  9.073465480469167e-05
Epoch:  169  	Training Loss: 6.913457764312625e-05
Test Loss:  5.032627086620778e-05
Valid Loss:  9.071705426322296e-05
Epoch:  170  	Training Loss: 6.910022784722969e-05
Test Loss:  5.028590385336429e-05
Valid Loss:  9.070116357179359e-05
Epoch:  171  	Training Loss: 6.906934140715748e-05
Test Loss:  5.0245740567333996e-05
Valid Loss:  9.068622603081167e-05
Epoch:  172  	Training Loss: 6.904143083374947e-05
Test Loss:  5.0187849410576746e-05
Valid Loss:  9.023226448334754e-05
Epoch:  173  	Training Loss: 6.886397750349715e-05
Test Loss:  5.0613394705578685e-05
Valid Loss:  9.002610750030726e-05
Epoch:  174  	Training Loss: 6.872921949252486e-05
Test Loss:  5.095887536299415e-05
Valid Loss:  8.98540674825199e-05
Epoch:  175  	Training Loss: 6.862232112325728e-05
Test Loss:  5.12506376253441e-05
Valid Loss:  8.971069473773241e-05
Epoch:  176  	Training Loss: 6.85355844325386e-05
Test Loss:  5.149429853190668e-05
Valid Loss:  8.95881385076791e-05
Epoch:  177  	Training Loss: 6.846270116511732e-05
Test Loss:  5.169442010810599e-05
Valid Loss:  8.947870810516179e-05
Epoch:  178  	Training Loss: 6.839987327111885e-05
Test Loss:  5.185288318898529e-05
Valid Loss:  8.938332030083984e-05
Epoch:  179  	Training Loss: 6.834555824752897e-05
Test Loss:  5.1985705795232207e-05
Valid Loss:  8.929902105592191e-05
Epoch:  180  	Training Loss: 6.829613266745582e-05
Test Loss:  5.2089006203459576e-05
Valid Loss:  8.922097913455218e-05
Epoch:  181  	Training Loss: 6.825059244874865e-05
Test Loss:  5.2171191782690585e-05
Valid Loss:  8.914899080991745e-05
Epoch:  182  	Training Loss: 6.820785347372293e-05
Test Loss:  5.204477929510176e-05
Valid Loss:  8.928113675210625e-05
Epoch:  183  	Training Loss: 6.795284571126103e-05
Test Loss:  5.0890081183752045e-05
Valid Loss:  8.869531302480027e-05
Epoch:  184  	Training Loss: 6.777011731173843e-05
Test Loss:  5.062366835772991e-05
Valid Loss:  8.865220297593623e-05
Epoch:  185  	Training Loss: 6.762008706573397e-05
Test Loss:  4.995926428819075e-05
Valid Loss:  8.832340245135128e-05
Epoch:  186  	Training Loss: 6.748516170773655e-05
Test Loss:  4.9570655392017215e-05
Valid Loss:  8.816263289190829e-05
Epoch:  187  	Training Loss: 6.736166687915102e-05
Test Loss:  4.911720679956488e-05
Valid Loss:  8.7930508016143e-05
Epoch:  188  	Training Loss: 6.724637933075428e-05
Test Loss:  4.8779613280203193e-05
Valid Loss:  8.775944297667593e-05
Epoch:  189  	Training Loss: 6.713769107591361e-05
Test Loss:  4.84437623526901e-05
Valid Loss:  8.757380419410765e-05
Epoch:  190  	Training Loss: 6.703461986035109e-05
Test Loss:  4.815744614461437e-05
Valid Loss:  8.740725752431899e-05
Epoch:  191  	Training Loss: 6.69363362248987e-05
Test Loss:  4.7893059672787786e-05
Valid Loss:  8.724532381165773e-05
Epoch:  192  	Training Loss: 6.684374966425821e-05
Test Loss:  4.7588815505150706e-05
Valid Loss:  8.696519216755405e-05
Epoch:  193  	Training Loss: 6.63099781377241e-05
Test Loss:  4.731658555101603e-05
Valid Loss:  8.670450188219547e-05
Epoch:  194  	Training Loss: 6.586575182154775e-05
Test Loss:  4.707088373834267e-05
Valid Loss:  8.646300557302311e-05
Epoch:  195  	Training Loss: 6.548984674736857e-05
Test Loss:  4.685141902882606e-05
Valid Loss:  8.624287147540599e-05
Epoch:  196  	Training Loss: 6.517012661788613e-05
Test Loss:  4.66588135168422e-05
Valid Loss:  8.603659807704389e-05
Epoch:  197  	Training Loss: 6.48938657832332e-05
Test Loss:  4.6489098167512566e-05
Valid Loss:  8.584410534240305e-05
Epoch:  198  	Training Loss: 6.46539410809055e-05
Test Loss:  4.6338642277987674e-05
Valid Loss:  8.566764881834388e-05
Epoch:  199  	Training Loss: 6.444565951824188e-05
Test Loss:  4.620073741534725e-05
Valid Loss:  8.549856283934787e-05
Epoch:  200  	Training Loss: 6.425982428481802e-05
Test Loss:  4.6073273551883176e-05
Valid Loss:  8.533967775292695e-05
Epoch:  201  	Training Loss: 6.409563502529636e-05
Test Loss:  4.595643258653581e-05
Valid Loss:  8.518980030203238e-05
Epoch:  202  	Training Loss: 6.394747470039874e-05
Test Loss:  4.6143675717758015e-05
Valid Loss:  8.489257743349299e-05
Epoch:  203  	Training Loss: 6.376110104611143e-05
Test Loss:  4.644376167561859e-05
Valid Loss:  8.474512287648395e-05
Epoch:  204  	Training Loss: 6.360482075251639e-05
Test Loss:  4.672489740187302e-05
Valid Loss:  8.461614925181493e-05
 41%|████      | 205/500 [02:29<03:01,  1.63it/s] 41%|████▏     | 207/500 [02:29<02:11,  2.22it/s] 42%|████▏     | 209/500 [02:29<01:37,  2.99it/s] 42%|████▏     | 211/500 [02:36<05:40,  1.18s/it] 43%|████▎     | 213/500 [02:36<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:36<02:54,  1.63it/s] 43%|████▎     | 217/500 [02:36<02:07,  2.22it/s] 44%|████▍     | 219/500 [02:36<01:33,  2.99it/s] 44%|████▍     | 221/500 [02:43<05:33,  1.20s/it] 45%|████▍     | 223/500 [02:43<03:57,  1.17it/s] 45%|████▌     | 225/500 [02:43<02:50,  1.61it/s] 45%|████▌     | 227/500 [02:43<02:05,  2.18it/s] 46%|████▌     | 229/500 [02:43<01:33,  2.89it/s] 46%|████▌     | 231/500 [02:50<05:26,  1.21s/it] 47%|████▋     | 233/500 [02:50<03:52,  1.15it/s] 47%|████▋     | 235/500 [02:50<02:46,  1.59it/s] 47%|████▋     | 237/500 [02:50<02:02,  2.15it/s] 48%|████▊     | 239/500 [02:50<01:30,  2.88it/s] 48%|████▊     | 241/500 [02:57<05:16,  1.22s/it] 49%|████▊     | 243/500 [02:57<03:45,  1.14it/s] 49%|████▉     | 245/500 [02:57<02:41,  1.58it/s] 49%|████▉     | 247/500 [02:57<01:57,  2.16it/s] 50%|████▉     | 249/500 [02:57<01:26,  2.90it/s] 50%|█████     | 251/500 [03:04<04:54,  1.18s/it] 51%|█████     | 253/500 [03:04<03:29,  1.18it/s] 51%|█████     | 255/500 [03:04<02:30,  1.63it/s] 51%|█████▏    | 257/500 [03:04<01:49,  2.22it/s] 52%|█████▏    | 259/500 [03:04<01:20,  2.99it/s] 52%|█████▏    | 261/500 [03:11<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:11<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:11<02:25,  1.62it/s] 53%|█████▎    | 267/500 [03:11<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:11<01:18,  2.96it/s] 54%|█████▍    | 271/500 [03:17<04:28,  1.17s/it]Epoch:  205  	Training Loss: 6.346194277284667e-05
Test Loss:  4.698254997492768e-05
Valid Loss:  8.449835877399892e-05
Epoch:  206  	Training Loss: 6.333152850857005e-05
Test Loss:  4.7221303248079494e-05
Valid Loss:  8.439052908215672e-05
Epoch:  207  	Training Loss: 6.321338878478855e-05
Test Loss:  4.7443536459468305e-05
Valid Loss:  8.428985893260688e-05
Epoch:  208  	Training Loss: 6.31049697403796e-05
Test Loss:  4.764799086842686e-05
Valid Loss:  8.419601363129914e-05
Epoch:  209  	Training Loss: 6.300784298218787e-05
Test Loss:  4.783160693477839e-05
Valid Loss:  8.410661394009367e-05
Epoch:  210  	Training Loss: 6.29187561571598e-05
Test Loss:  4.8000911192502826e-05
Valid Loss:  8.402293315157294e-05
Epoch:  211  	Training Loss: 6.283717812038958e-05
Test Loss:  4.8156412958633155e-05
Valid Loss:  8.3943348727189e-05
Epoch:  212  	Training Loss: 6.276303611230105e-05
Test Loss:  4.771938256453723e-05
Valid Loss:  8.339036867255345e-05
Epoch:  213  	Training Loss: 6.250111619010568e-05
Test Loss:  4.754101246362552e-05
Valid Loss:  8.316161984112114e-05
Epoch:  214  	Training Loss: 6.240013317437842e-05
Test Loss:  4.7439807531191036e-05
Valid Loss:  8.304366201628e-05
Epoch:  215  	Training Loss: 6.233492604224011e-05
Test Loss:  4.737437848234549e-05
Valid Loss:  8.29685595817864e-05
Epoch:  216  	Training Loss: 6.228827260201797e-05
Test Loss:  4.732831075671129e-05
Valid Loss:  8.291518315672874e-05
Epoch:  217  	Training Loss: 6.224885146366432e-05
Test Loss:  4.7293091483879834e-05
Valid Loss:  8.28682241262868e-05
Epoch:  218  	Training Loss: 6.221880903467536e-05
Test Loss:  4.726803308585659e-05
Valid Loss:  8.283161878352985e-05
Epoch:  219  	Training Loss: 6.219432543730363e-05
Test Loss:  4.725220424006693e-05
Valid Loss:  8.280754263978451e-05
Epoch:  220  	Training Loss: 6.217177724465728e-05
Test Loss:  4.724062455352396e-05
Valid Loss:  8.27826006570831e-05
Epoch:  221  	Training Loss: 6.21515791863203e-05
Test Loss:  4.723487654700875e-05
Valid Loss:  8.276542939711362e-05
Epoch:  222  	Training Loss: 6.213221058715135e-05
Test Loss:  4.71919629490003e-05
Valid Loss:  8.286181400762871e-05
Epoch:  223  	Training Loss: 6.198346090968698e-05
Test Loss:  4.717601404991001e-05
Valid Loss:  8.291937410831451e-05
Epoch:  224  	Training Loss: 6.191989814396948e-05
Test Loss:  4.715698378277011e-05
Valid Loss:  8.293786959256977e-05
Epoch:  225  	Training Loss: 6.188038969412446e-05
Test Loss:  4.713223097496666e-05
Valid Loss:  8.293191785924137e-05
Epoch:  226  	Training Loss: 6.184788071550429e-05
Test Loss:  4.710350913228467e-05
Valid Loss:  8.291279664263129e-05
Epoch:  227  	Training Loss: 6.181796197779477e-05
Test Loss:  4.707256448455155e-05
Valid Loss:  8.28873016871512e-05
Epoch:  228  	Training Loss: 6.178937474032864e-05
Test Loss:  4.704087405116297e-05
Valid Loss:  8.285872172564268e-05
Epoch:  229  	Training Loss: 6.176179158501327e-05
Test Loss:  4.700847057392821e-05
Valid Loss:  8.282910857815295e-05
Epoch:  230  	Training Loss: 6.173510337248445e-05
Test Loss:  4.697750773630105e-05
Valid Loss:  8.280460315290838e-05
Epoch:  231  	Training Loss: 6.171069981064647e-05
Test Loss:  4.694568633567542e-05
Valid Loss:  8.277795132016763e-05
Epoch:  232  	Training Loss: 6.168730033095926e-05
Test Loss:  4.698146221926436e-05
Valid Loss:  8.284058276331052e-05
Epoch:  233  	Training Loss: 6.16763427387923e-05
Test Loss:  4.698924385593273e-05
Valid Loss:  8.284472278319299e-05
Epoch:  234  	Training Loss: 6.16737743257545e-05
Test Loss:  4.699165219790302e-05
Valid Loss:  8.283981878776103e-05
Epoch:  235  	Training Loss: 6.167197716422379e-05
Test Loss:  4.699315468315035e-05
Valid Loss:  8.283302304334939e-05
Epoch:  236  	Training Loss: 6.167028186609969e-05
Test Loss:  4.6994311560411006e-05
Valid Loss:  8.28270276542753e-05
Epoch:  237  	Training Loss: 6.166874663904309e-05
Test Loss:  4.699586861534044e-05
Valid Loss:  8.282132330350578e-05
Epoch:  238  	Training Loss: 6.16672623436898e-05
Test Loss:  4.699698183685541e-05
Valid Loss:  8.28158954391256e-05
Epoch:  239  	Training Loss: 6.166609819047153e-05
Test Loss:  4.699814599007368e-05
Valid Loss:  8.281126793008298e-05
Epoch:  240  	Training Loss: 6.166501407278702e-05
Test Loss:  4.69991318823304e-05
Valid Loss:  8.28066113172099e-05
Epoch:  241  	Training Loss: 6.166383536765352e-05
Test Loss:  4.700022691395134e-05
Valid Loss:  8.280303882202134e-05
Epoch:  242  	Training Loss: 6.166299863252789e-05
Test Loss:  4.698600969277322e-05
Valid Loss:  8.278507448267192e-05
Epoch:  243  	Training Loss: 6.165617378428578e-05
Test Loss:  4.697249460150488e-05
Valid Loss:  8.277050801552832e-05
Epoch:  244  	Training Loss: 6.164963997434825e-05
Test Loss:  4.6959648898337036e-05
Valid Loss:  8.275784057332203e-05
Epoch:  245  	Training Loss: 6.164352089399472e-05
Test Loss:  4.6947265218477696e-05
Valid Loss:  8.274652645923197e-05
Epoch:  246  	Training Loss: 6.163741636555642e-05
Test Loss:  4.693461232818663e-05
Valid Loss:  8.273553248727694e-05
Epoch:  247  	Training Loss: 6.163142097648233e-05
Test Loss:  4.692191578214988e-05
Valid Loss:  8.272524428321049e-05
Epoch:  248  	Training Loss: 6.162511999718845e-05
Test Loss:  4.690883361035958e-05
Valid Loss:  8.271546539617702e-05
Epoch:  249  	Training Loss: 6.16190955042839e-05
Test Loss:  4.689626075560227e-05
Valid Loss:  8.270551916211843e-05
Epoch:  250  	Training Loss: 6.161299825180322e-05
Test Loss:  4.6883469622116536e-05
Valid Loss:  8.269579848274589e-05
Epoch:  251  	Training Loss: 6.160691555123776e-05
Test Loss:  4.68702164653223e-05
Valid Loss:  8.268640522146598e-05
Epoch:  252  	Training Loss: 6.160080374684185e-05
Test Loss:  4.652308416552842e-05
Valid Loss:  8.249670645454898e-05
Epoch:  253  	Training Loss: 6.15381431998685e-05
Test Loss:  4.6267490688478574e-05
Valid Loss:  8.237673318944871e-05
Epoch:  254  	Training Loss: 6.148612010292709e-05
Test Loss:  4.603860361385159e-05
Valid Loss:  8.227561193052679e-05
Epoch:  255  	Training Loss: 6.143654900370166e-05
Test Loss:  4.582103792927228e-05
Valid Loss:  8.218124276027083e-05
Epoch:  256  	Training Loss: 6.138905882835388e-05
Test Loss:  4.561153400572948e-05
Valid Loss:  8.209100633393973e-05
Epoch:  257  	Training Loss: 6.134338036645204e-05
Test Loss:  4.5408709411276504e-05
Valid Loss:  8.200421871151775e-05
Epoch:  258  	Training Loss: 6.129973189672455e-05
Test Loss:  4.521187292994e-05
Valid Loss:  8.192090899683535e-05
Epoch:  259  	Training Loss: 6.125780782895163e-05
Test Loss:  4.5020904508419335e-05
Valid Loss:  8.184062608052045e-05
Epoch:  260  	Training Loss: 6.12174699199386e-05
Test Loss:  4.483686279854737e-05
Valid Loss:  8.176288974937052e-05
Epoch:  261  	Training Loss: 6.117860175436363e-05
Test Loss:  4.465823440114036e-05
Valid Loss:  8.168843487510458e-05
Epoch:  262  	Training Loss: 6.114119605626911e-05
Test Loss:  4.4922569941263646e-05
Valid Loss:  8.170769433490932e-05
Epoch:  263  	Training Loss: 6.109925743658096e-05
Test Loss:  4.514637475949712e-05
Valid Loss:  8.17106629256159e-05
Epoch:  264  	Training Loss: 6.106561340857297e-05
Test Loss:  4.534114123089239e-05
Valid Loss:  8.17052205093205e-05
Epoch:  265  	Training Loss: 6.103636405896395e-05
Test Loss:  4.5513697841670364e-05
Valid Loss:  8.169610373442993e-05
Epoch:  266  	Training Loss: 6.101062899688259e-05
Test Loss:  4.566952702589333e-05
Valid Loss:  8.168494969140738e-05
Epoch:  267  	Training Loss: 6.0986727476119995e-05
Test Loss:  4.58130962215364e-05
Valid Loss:  8.167581108864397e-05
Epoch:  268  	Training Loss: 6.096449214965105e-05
Test Loss:  4.594588972395286e-05
Valid Loss:  8.167060150299221e-05
Epoch:  269  	Training Loss: 6.0943846619920805e-05
Test Loss:  4.6067158109508455e-05
Valid Loss:  8.166538464138284e-05
Epoch:  270  	Training Loss: 6.0924081481061876e-05
Test Loss:  4.617476952262223e-05
Valid Loss:  8.165849430952221e-05
Epoch:  271  	Training Loss: 6.09062917646952e-05
Test Loss:  4.627522503142245e-05
Valid Loss:  8.165354665834457e-05
Epoch:  272  	Training Loss: 6.08891095907893e-05
Test Loss:  4.6284891141112894e-05
Valid Loss:  8.162092854036018e-05
 55%|█████▍    | 273/500 [03:17<03:10,  1.19it/s] 55%|█████▌    | 275/500 [03:18<02:16,  1.65it/s] 55%|█████▌    | 277/500 [03:18<01:39,  2.25it/s] 56%|█████▌    | 279/500 [03:18<01:13,  3.02it/s] 56%|█████▌    | 281/500 [03:24<04:18,  1.18s/it] 57%|█████▋    | 283/500 [03:24<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:24<02:11,  1.63it/s] 57%|█████▋    | 287/500 [03:25<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:25<01:12,  2.92it/s] 58%|█████▊    | 291/500 [03:31<04:08,  1.19s/it] 59%|█████▊    | 293/500 [03:31<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:31<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:32<01:31,  2.21it/s] 60%|█████▉    | 299/500 [03:32<01:07,  2.97it/s] 60%|██████    | 301/500 [03:38<03:58,  1.20s/it] 61%|██████    | 303/500 [03:38<02:48,  1.17it/s] 61%|██████    | 305/500 [03:38<02:00,  1.61it/s] 61%|██████▏   | 307/500 [03:38<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:39<01:04,  2.98it/s] 62%|██████▏   | 311/500 [03:45<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:45<02:40,  1.17it/s] 63%|██████▎   | 315/500 [03:45<01:54,  1.61it/s] 63%|██████▎   | 317/500 [03:45<01:22,  2.21it/s] 64%|██████▍   | 319/500 [03:46<01:00,  2.97it/s] 64%|██████▍   | 321/500 [03:52<03:33,  1.19s/it] 65%|██████▍   | 323/500 [03:52<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:52<01:48,  1.62it/s] 65%|██████▌   | 327/500 [03:52<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:52<00:57,  2.97it/s] 66%|██████▌   | 331/500 [03:59<03:21,  1.19s/it] 67%|██████▋   | 333/500 [03:59<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:59<01:41,  1.62it/s] 67%|██████▋   | 337/500 [03:59<01:13,  2.21it/s] 68%|██████▊   | 339/500 [03:59<00:54,  2.97it/s]Epoch:  273  	Training Loss: 6.087501969886944e-05
Test Loss:  4.6304427087306976e-05
Valid Loss:  8.161089499481022e-05
Epoch:  274  	Training Loss: 6.0862301324959844e-05
Test Loss:  4.632497075363062e-05
Valid Loss:  8.160249126376584e-05
Epoch:  275  	Training Loss: 6.0849492001580074e-05
Test Loss:  4.634568904293701e-05
Valid Loss:  8.159427670761943e-05
Epoch:  276  	Training Loss: 6.083723928895779e-05
Test Loss:  4.6360721171367913e-05
Valid Loss:  8.158623677445576e-05
Epoch:  277  	Training Loss: 6.082588151912205e-05
Test Loss:  4.6375404053833336e-05
Valid Loss:  8.157789125107229e-05
Epoch:  278  	Training Loss: 6.081454921513796e-05
Test Loss:  4.6390290663111955e-05
Valid Loss:  8.15694365883246e-05
Epoch:  279  	Training Loss: 6.080291495891288e-05
Test Loss:  4.6404988097492605e-05
Valid Loss:  8.156112744472921e-05
Epoch:  280  	Training Loss: 6.0791488067479804e-05
Test Loss:  4.6419387217611074e-05
Valid Loss:  8.155252726282924e-05
Epoch:  281  	Training Loss: 6.0779915656894445e-05
Test Loss:  4.6433960960712284e-05
Valid Loss:  8.154340321198106e-05
Epoch:  282  	Training Loss: 6.0768456023652107e-05
Test Loss:  4.5203785703051835e-05
Valid Loss:  8.09060875326395e-05
Epoch:  283  	Training Loss: 6.059382576495409e-05
Test Loss:  4.540201916825026e-05
Valid Loss:  8.082800195552409e-05
Epoch:  284  	Training Loss: 6.0479749663500115e-05
Test Loss:  4.539754445431754e-05
Valid Loss:  8.068050374276936e-05
Epoch:  285  	Training Loss: 6.0370384744601324e-05
Test Loss:  4.542606257018633e-05
Valid Loss:  8.0548990808893e-05
Epoch:  286  	Training Loss: 6.026403571013361e-05
Test Loss:  4.545044794213027e-05
Valid Loss:  8.041935507208109e-05
Epoch:  287  	Training Loss: 6.01599422225263e-05
Test Loss:  4.547271237242967e-05
Valid Loss:  8.029174932744354e-05
Epoch:  288  	Training Loss: 6.005843169987202e-05
Test Loss:  4.549237928586081e-05
Valid Loss:  8.016584615688771e-05
Epoch:  289  	Training Loss: 5.9959500504191965e-05
Test Loss:  4.551045276457444e-05
Valid Loss:  8.00438501755707e-05
Epoch:  290  	Training Loss: 5.986285032122396e-05
Test Loss:  4.553574399324134e-05
Valid Loss:  7.992595783434808e-05
Epoch:  291  	Training Loss: 5.976849206490442e-05
Test Loss:  4.555840132525191e-05
Valid Loss:  7.980996451806277e-05
Epoch:  292  	Training Loss: 5.967631659586914e-05
Test Loss:  4.5453052734956145e-05
Valid Loss:  7.959781942190602e-05
Epoch:  293  	Training Loss: 5.959695408819243e-05
Test Loss:  4.5421380491461605e-05
Valid Loss:  7.951958104968071e-05
Epoch:  294  	Training Loss: 5.954703374300152e-05
Test Loss:  4.5396373025141656e-05
Valid Loss:  7.94420629972592e-05
Epoch:  295  	Training Loss: 5.9500696806935593e-05
Test Loss:  4.5383741962723434e-05
Valid Loss:  7.93972285464406e-05
Epoch:  296  	Training Loss: 5.9455887821968645e-05
Test Loss:  4.5366890844888985e-05
Valid Loss:  7.933598681120202e-05
Epoch:  297  	Training Loss: 5.941001290921122e-05
Test Loss:  4.535595508059487e-05
Valid Loss:  7.92988867033273e-05
Epoch:  298  	Training Loss: 5.9360958402976394e-05
Test Loss:  4.533777973847464e-05
Valid Loss:  7.923864177428186e-05
Epoch:  299  	Training Loss: 5.9314734244253486e-05
Test Loss:  4.532666935119778e-05
Valid Loss:  7.920256757643074e-05
Epoch:  300  	Training Loss: 5.9269754274282604e-05
Test Loss:  4.5310764107853174e-05
Valid Loss:  7.915344758657739e-05
Epoch:  301  	Training Loss: 5.922694981563836e-05
Test Loss:  4.529786383500323e-05
Valid Loss:  7.911531429272145e-05
Epoch:  302  	Training Loss: 5.918635361013003e-05
Test Loss:  4.522379094851203e-05
Valid Loss:  7.91227794252336e-05
Epoch:  303  	Training Loss: 5.8888028434012085e-05
Test Loss:  4.384230851428583e-05
Valid Loss:  7.844005449442193e-05
Epoch:  304  	Training Loss: 5.8635359891923144e-05
Test Loss:  4.365267523098737e-05
Valid Loss:  7.835058204364032e-05
Epoch:  305  	Training Loss: 5.841714300913736e-05
Test Loss:  4.2705760279204696e-05
Valid Loss:  7.7886987128295e-05
Epoch:  306  	Training Loss: 5.822459570481442e-05
Test Loss:  4.2460073018446565e-05
Valid Loss:  7.774277764838189e-05
Epoch:  307  	Training Loss: 5.8051715313922614e-05
Test Loss:  4.182529664831236e-05
Valid Loss:  7.741276931483299e-05
Epoch:  308  	Training Loss: 5.7895176723832265e-05
Test Loss:  4.15859030908905e-05
Valid Loss:  7.725961040705442e-05
Epoch:  309  	Training Loss: 5.7751960412133485e-05
Test Loss:  4.110365262022242e-05
Valid Loss:  7.699141860939562e-05
Epoch:  310  	Training Loss: 5.761819193139672e-05
Test Loss:  4.09008571295999e-05
Valid Loss:  7.683972944505513e-05
Epoch:  311  	Training Loss: 5.749181582359597e-05
Test Loss:  4.053737939102575e-05
Valid Loss:  7.661734707653522e-05
Epoch:  312  	Training Loss: 5.737289029639214e-05
Test Loss:  4.078094571013935e-05
Valid Loss:  7.665425800951198e-05
Epoch:  313  	Training Loss: 5.732745921704918e-05
Test Loss:  4.094324685866013e-05
Valid Loss:  7.664755685254931e-05
Epoch:  314  	Training Loss: 5.7298035244457424e-05
Test Loss:  4.109115252504125e-05
Valid Loss:  7.663627184228972e-05
Epoch:  315  	Training Loss: 5.727194366045296e-05
Test Loss:  4.122980317333713e-05
Valid Loss:  7.662386633455753e-05
Epoch:  316  	Training Loss: 5.724801667383872e-05
Test Loss:  4.136063944315538e-05
Valid Loss:  7.661154813831672e-05
Epoch:  317  	Training Loss: 5.722574860556051e-05
Test Loss:  4.148173684370704e-05
Valid Loss:  7.65974837122485e-05
Epoch:  318  	Training Loss: 5.7204902986995876e-05
Test Loss:  4.159661693847738e-05
Valid Loss:  7.6584197813645e-05
Epoch:  319  	Training Loss: 5.71854216104839e-05
Test Loss:  4.170658212387934e-05
Valid Loss:  7.657171227037907e-05
Epoch:  320  	Training Loss: 5.7167115301126614e-05
Test Loss:  4.181118492851965e-05
Valid Loss:  7.655960507690907e-05
Epoch:  321  	Training Loss: 5.714972212444991e-05
Test Loss:  4.191122206975706e-05
Valid Loss:  7.65487493481487e-05
Epoch:  322  	Training Loss: 5.713323116651736e-05
Test Loss:  4.119687946513295e-05
Valid Loss:  7.62583949835971e-05
Epoch:  323  	Training Loss: 5.706458614440635e-05
Test Loss:  4.092535891686566e-05
Valid Loss:  7.617131632287055e-05
Epoch:  324  	Training Loss: 5.703565329895355e-05
Test Loss:  4.076110781170428e-05
Valid Loss:  7.612632180098444e-05
Epoch:  325  	Training Loss: 5.701244663214311e-05
Test Loss:  4.063454980496317e-05
Valid Loss:  7.609357999172062e-05
Epoch:  326  	Training Loss: 5.6992314057424664e-05
Test Loss:  4.052859731018543e-05
Valid Loss:  7.606605504406616e-05
Epoch:  327  	Training Loss: 5.697493179468438e-05
Test Loss:  4.043820808874443e-05
Valid Loss:  7.60419134167023e-05
Epoch:  328  	Training Loss: 5.6958553614094853e-05
Test Loss:  4.0362410800298676e-05
Valid Loss:  7.602378900628537e-05
Epoch:  329  	Training Loss: 5.694282299373299e-05
Test Loss:  4.0288221498485655e-05
Valid Loss:  7.600350363645703e-05
Epoch:  330  	Training Loss: 5.6928503909148276e-05
Test Loss:  4.0222585084848106e-05
Valid Loss:  7.598360389238223e-05
Epoch:  331  	Training Loss: 5.691545447916724e-05
Test Loss:  4.016603998024948e-05
Valid Loss:  7.596510840812698e-05
Epoch:  332  	Training Loss: 5.690320176654495e-05
Test Loss:  4.016791353933513e-05
Valid Loss:  7.595628267154098e-05
Epoch:  333  	Training Loss: 5.689483805326745e-05
Test Loss:  4.016949242213741e-05
Valid Loss:  7.594715862069279e-05
Epoch:  334  	Training Loss: 5.688704550266266e-05
Test Loss:  4.017115861643106e-05
Valid Loss:  7.593806367367506e-05
Epoch:  335  	Training Loss: 5.687967495759949e-05
Test Loss:  4.0172664739657193e-05
Valid Loss:  7.592915062559769e-05
Epoch:  336  	Training Loss: 5.6872679124353454e-05
Test Loss:  4.017398168798536e-05
Valid Loss:  7.592016481794417e-05
Epoch:  337  	Training Loss: 5.686575605068356e-05
Test Loss:  4.0175604226533324e-05
Valid Loss:  7.591163739562035e-05
Epoch:  338  	Training Loss: 5.6858865718822926e-05
Test Loss:  4.017710671178065e-05
Valid Loss:  7.590307359350845e-05
Epoch:  339  	Training Loss: 5.6852561101550236e-05
Test Loss:  4.017842729808763e-05
Valid Loss:  7.589443703182042e-05
Epoch:  340  	Training Loss: 5.684646384906955e-05
Test Loss:  4.017979517811909e-05
Valid Loss:  7.588599692098796e-05
 68%|██████▊   | 341/500 [04:06<03:12,  1.21s/it] 69%|██████▊   | 343/500 [04:06<02:16,  1.15it/s] 69%|██████▉   | 345/500 [04:06<01:37,  1.60it/s] 69%|██████▉   | 347/500 [04:06<01:10,  2.18it/s] 70%|██████▉   | 349/500 [04:06<00:51,  2.93it/s] 70%|███████   | 351/500 [04:13<02:59,  1.20s/it] 71%|███████   | 353/500 [04:13<02:07,  1.15it/s] 71%|███████   | 355/500 [04:13<01:30,  1.60it/s] 71%|███████▏  | 357/500 [04:13<01:05,  2.18it/s] 72%|███████▏  | 359/500 [04:13<00:48,  2.94it/s] 72%|███████▏  | 361/500 [04:20<02:46,  1.20s/it] 73%|███████▎  | 363/500 [04:20<01:57,  1.16it/s] 73%|███████▎  | 365/500 [04:20<01:23,  1.61it/s] 73%|███████▎  | 367/500 [04:20<01:00,  2.20it/s] 74%|███████▍  | 369/500 [04:20<00:44,  2.96it/s] 74%|███████▍  | 371/500 [04:27<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:27<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:27<01:17,  1.62it/s] 75%|███████▌  | 377/500 [04:27<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:27<00:40,  2.97it/s] 76%|███████▌  | 381/500 [04:34<02:26,  1.23s/it] 77%|███████▋  | 383/500 [04:34<01:43,  1.14it/s] 77%|███████▋  | 385/500 [04:34<01:13,  1.57it/s] 77%|███████▋  | 387/500 [04:34<00:52,  2.15it/s] 78%|███████▊  | 389/500 [04:34<00:38,  2.90it/s] 78%|███████▊  | 391/500 [04:41<02:11,  1.21s/it] 79%|███████▊  | 393/500 [04:41<01:32,  1.15it/s] 79%|███████▉  | 395/500 [04:41<01:05,  1.60it/s] 79%|███████▉  | 397/500 [04:41<00:47,  2.18it/s] 80%|███████▉  | 399/500 [04:41<00:34,  2.93it/s] 80%|████████  | 401/500 [04:48<01:59,  1.21s/it] 81%|████████  | 403/500 [04:48<01:23,  1.16it/s] 81%|████████  | 405/500 [04:48<00:59,  1.60it/s] 81%|████████▏ | 407/500 [04:48<00:42,  2.19it/s]Epoch:  341  	Training Loss: 5.6840555771486834e-05
Test Loss:  4.0181243093684316e-05
Valid Loss:  7.587785512441769e-05
Epoch:  342  	Training Loss: 5.6834873248590156e-05
Test Loss:  4.026083479402587e-05
Valid Loss:  7.589672895846888e-05
Epoch:  343  	Training Loss: 5.680369577021338e-05
Test Loss:  4.0331076888833195e-05
Valid Loss:  7.590088353026658e-05
Epoch:  344  	Training Loss: 5.677845547324978e-05
Test Loss:  4.039538907818496e-05
Valid Loss:  7.589634333271533e-05
Epoch:  345  	Training Loss: 5.6755703553790227e-05
Test Loss:  4.045571404276416e-05
Valid Loss:  7.588772859890014e-05
Epoch:  346  	Training Loss: 5.6734475947450846e-05
Test Loss:  4.0513681597076356e-05
Valid Loss:  7.587668369524181e-05
Epoch:  347  	Training Loss: 5.671431790688075e-05
Test Loss:  4.057114711031318e-05
Valid Loss:  7.586533320136368e-05
Epoch:  348  	Training Loss: 5.66952585359104e-05
Test Loss:  4.0627513953950256e-05
Valid Loss:  7.585310231661424e-05
Epoch:  349  	Training Loss: 5.667709046974778e-05
Test Loss:  4.06784238293767e-05
Valid Loss:  7.58422029321082e-05
Epoch:  350  	Training Loss: 5.666082870448008e-05
Test Loss:  4.0728802559897304e-05
Valid Loss:  7.583129627164453e-05
Epoch:  351  	Training Loss: 5.664500349666923e-05
Test Loss:  4.077835910720751e-05
Valid Loss:  7.582085527246818e-05
Epoch:  352  	Training Loss: 5.6630051403772086e-05
Test Loss:  4.029251795145683e-05
Valid Loss:  7.553512114100158e-05
Epoch:  353  	Training Loss: 5.652165418723598e-05
Test Loss:  4.025540692964569e-05
Valid Loss:  7.5425450631883e-05
Epoch:  354  	Training Loss: 5.642577161779627e-05
Test Loss:  4.0162791265174747e-05
Valid Loss:  7.528907008236274e-05
Epoch:  355  	Training Loss: 5.633337059407495e-05
Test Loss:  4.010777047369629e-05
Valid Loss:  7.516337791457772e-05
Epoch:  356  	Training Loss: 5.624343975796364e-05
Test Loss:  4.006423114333302e-05
Valid Loss:  7.503986853407696e-05
Epoch:  357  	Training Loss: 5.6155458878492936e-05
Test Loss:  4.003275535069406e-05
Valid Loss:  7.491945871151984e-05
Epoch:  358  	Training Loss: 5.606901686405763e-05
Test Loss:  4.000978515250608e-05
Valid Loss:  7.480141357518733e-05
Epoch:  359  	Training Loss: 5.598407733486965e-05
Test Loss:  3.999307955382392e-05
Valid Loss:  7.468591502401978e-05
Epoch:  360  	Training Loss: 5.590044747805223e-05
Test Loss:  3.99804521293845e-05
Valid Loss:  7.457139145117253e-05
Epoch:  361  	Training Loss: 5.5818116379668936e-05
Test Loss:  3.9974220271687955e-05
Valid Loss:  7.446009840350598e-05
Epoch:  362  	Training Loss: 5.573666567215696e-05
Test Loss:  3.999033651780337e-05
Valid Loss:  7.446137169608846e-05
Epoch:  363  	Training Loss: 5.573127054958604e-05
Test Loss:  4.000352055300027e-05
Valid Loss:  7.445991650456563e-05
Epoch:  364  	Training Loss: 5.572600639425218e-05
Test Loss:  4.001425259048119e-05
Valid Loss:  7.445672963513061e-05
Epoch:  365  	Training Loss: 5.572091322392225e-05
Test Loss:  4.002387504442595e-05
Valid Loss:  7.445256051141769e-05
Epoch:  366  	Training Loss: 5.5715670896461233e-05
Test Loss:  4.0032613469520584e-05
Valid Loss:  7.444770744768903e-05
Epoch:  367  	Training Loss: 5.571068686549552e-05
Test Loss:  4.004080983577296e-05
Valid Loss:  7.444257789757103e-05
Epoch:  368  	Training Loss: 5.570564098889008e-05
Test Loss:  4.004881702712737e-05
Valid Loss:  7.443704089382663e-05
Epoch:  369  	Training Loss: 5.570059147430584e-05
Test Loss:  4.0056453144643456e-05
Valid Loss:  7.443124195560813e-05
Epoch:  370  	Training Loss: 5.56954946659971e-05
Test Loss:  4.0064122003968805e-05
Valid Loss:  7.44255812605843e-05
Epoch:  371  	Training Loss: 5.569066706812009e-05
Test Loss:  4.007163079222664e-05
Valid Loss:  7.441958587151021e-05
Epoch:  372  	Training Loss: 5.568551932810806e-05
Test Loss:  4.0178278140956536e-05
Valid Loss:  7.435324368998408e-05
Epoch:  373  	Training Loss: 5.563801096286625e-05
Test Loss:  4.030476702610031e-05
Valid Loss:  7.43000564398244e-05
Epoch:  374  	Training Loss: 5.559271085076034e-05
Test Loss:  4.04308557335753e-05
Valid Loss:  7.425143121508881e-05
Epoch:  375  	Training Loss: 5.554886593017727e-05
Test Loss:  4.055144381709397e-05
Valid Loss:  7.420702604576945e-05
Epoch:  376  	Training Loss: 5.550579953705892e-05
Test Loss:  4.0659637306816876e-05
Valid Loss:  7.416184234898537e-05
Epoch:  377  	Training Loss: 5.5463588068960235e-05
Test Loss:  4.0760547562967986e-05
Valid Loss:  7.411885599140078e-05
Epoch:  378  	Training Loss: 5.54218640900217e-05
Test Loss:  4.0850223740562797e-05
Valid Loss:  7.407418161164969e-05
Epoch:  379  	Training Loss: 5.538093319046311e-05
Test Loss:  4.0932998672360554e-05
Valid Loss:  7.402927440125495e-05
Epoch:  380  	Training Loss: 5.5340711696771905e-05
Test Loss:  4.101126251043752e-05
Valid Loss:  7.398460002150387e-05
Epoch:  381  	Training Loss: 5.530119960894808e-05
Test Loss:  4.108611028641462e-05
Valid Loss:  7.39406532375142e-05
Epoch:  382  	Training Loss: 5.526256427401677e-05
Test Loss:  4.097311102668755e-05
Valid Loss:  7.38349772291258e-05
Epoch:  383  	Training Loss: 5.516209785128012e-05
Test Loss:  4.0863560570869595e-05
Valid Loss:  7.373477274086326e-05
Epoch:  384  	Training Loss: 5.506680463440716e-05
Test Loss:  4.0756756789050996e-05
Valid Loss:  7.363871554844081e-05
Epoch:  385  	Training Loss: 5.497612073668279e-05
Test Loss:  4.065255052410066e-05
Valid Loss:  7.354724948527291e-05
Epoch:  386  	Training Loss: 5.488997703650966e-05
Test Loss:  4.05513055738993e-05
Valid Loss:  7.34597779228352e-05
Epoch:  387  	Training Loss: 5.4808126151328906e-05
Test Loss:  4.0452538087265566e-05
Valid Loss:  7.337619899772108e-05
Epoch:  388  	Training Loss: 5.473010605783202e-05
Test Loss:  4.0356193494517356e-05
Valid Loss:  7.32960834284313e-05
Epoch:  389  	Training Loss: 5.465506546897814e-05
Test Loss:  4.025711677968502e-05
Valid Loss:  7.321503653656691e-05
Epoch:  390  	Training Loss: 5.4580763389822096e-05
Test Loss:  4.016422826680355e-05
Valid Loss:  7.313994865398854e-05
Epoch:  391  	Training Loss: 5.451035394798964e-05
Test Loss:  4.006872040918097e-05
Valid Loss:  7.306040060939267e-05
Epoch:  392  	Training Loss: 5.444290582090616e-05
Test Loss:  4.007903044112027e-05
Valid Loss:  7.30720057617873e-05
Epoch:  393  	Training Loss: 5.441752728074789e-05
Test Loss:  4.001898196293041e-05
Valid Loss:  7.305202598217875e-05
Epoch:  394  	Training Loss: 5.4406802519224584e-05
Test Loss:  3.995067163486965e-05
Valid Loss:  7.302821904886514e-05
Epoch:  395  	Training Loss: 5.4396405175793916e-05
Test Loss:  3.988134631072171e-05
Valid Loss:  7.300391735043377e-05
Epoch:  396  	Training Loss: 5.438645166577771e-05
Test Loss:  3.981518966611475e-05
Valid Loss:  7.297976117115468e-05
Epoch:  397  	Training Loss: 5.437684740172699e-05
Test Loss:  3.975216532126069e-05
Valid Loss:  7.295682007679716e-05
Epoch:  398  	Training Loss: 5.4367723350878805e-05
Test Loss:  3.968997043557465e-05
Valid Loss:  7.293406088137999e-05
Epoch:  399  	Training Loss: 5.435878847492859e-05
Test Loss:  3.962864866480231e-05
Valid Loss:  7.291168731171638e-05
Epoch:  400  	Training Loss: 5.434992635855451e-05
Test Loss:  3.956855653086677e-05
Valid Loss:  7.2889743023552e-05
Epoch:  401  	Training Loss: 5.4341202485375106e-05
Test Loss:  3.9509533962700516e-05
Valid Loss:  7.28679951862432e-05
Epoch:  402  	Training Loss: 5.433266778709367e-05
Test Loss:  3.9505670429207385e-05
Valid Loss:  7.286862819455564e-05
Epoch:  403  	Training Loss: 5.432249599834904e-05
Test Loss:  3.9481477870140225e-05
Valid Loss:  7.285390165634453e-05
Epoch:  404  	Training Loss: 5.431296813185327e-05
Test Loss:  3.945962816942483e-05
Valid Loss:  7.284055755008012e-05
Epoch:  405  	Training Loss: 5.4303440265357494e-05
Test Loss:  3.943788033211604e-05
Valid Loss:  7.282639853656292e-05
Epoch:  406  	Training Loss: 5.4293945140670985e-05
Test Loss:  3.9416681829607114e-05
Valid Loss:  7.281271973624825e-05
Epoch:  407  	Training Loss: 5.4284551879391074e-05
Test Loss:  3.939635644201189e-05
Valid Loss:  7.279893179656938e-05
Epoch:  408  	Training Loss: 5.427536598290317e-05
Test Loss:  3.937545625376515e-05
Valid Loss:  7.278590055648237e-05
 82%|████████▏ | 409/500 [04:48<00:30,  2.94it/s] 82%|████████▏ | 411/500 [04:55<01:46,  1.19s/it] 83%|████████▎ | 413/500 [04:55<01:14,  1.17it/s] 83%|████████▎ | 415/500 [04:55<00:52,  1.62it/s] 83%|████████▎ | 417/500 [04:55<00:37,  2.21it/s] 84%|████████▍ | 419/500 [04:55<00:27,  2.97it/s] 84%|████████▍ | 421/500 [05:02<01:34,  1.20s/it] 85%|████████▍ | 423/500 [05:02<01:06,  1.17it/s] 85%|████████▌ | 425/500 [05:02<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:02<00:33,  2.20it/s] 86%|████████▌ | 429/500 [05:02<00:23,  2.97it/s] 86%|████████▌ | 431/500 [05:09<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:09<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:09<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:09<00:28,  2.21it/s] 88%|████████▊ | 439/500 [05:09<00:20,  2.97it/s] 88%|████████▊ | 441/500 [05:16<01:12,  1.23s/it] 89%|████████▊ | 443/500 [05:16<00:50,  1.13it/s] 89%|████████▉ | 445/500 [05:16<00:35,  1.57it/s] 89%|████████▉ | 447/500 [05:16<00:24,  2.14it/s] 90%|████████▉ | 449/500 [05:16<00:17,  2.88it/s] 90%|█████████ | 451/500 [05:23<01:00,  1.23s/it] 91%|█████████ | 453/500 [05:23<00:41,  1.14it/s] 91%|█████████ | 455/500 [05:23<00:28,  1.58it/s] 91%|█████████▏| 457/500 [05:23<00:19,  2.16it/s] 92%|█████████▏| 459/500 [05:23<00:14,  2.91it/s] 92%|█████████▏| 461/500 [05:30<00:46,  1.20s/it] 93%|█████████▎| 463/500 [05:30<00:31,  1.16it/s] 93%|█████████▎| 465/500 [05:30<00:21,  1.61it/s] 93%|█████████▎| 467/500 [05:30<00:15,  2.20it/s] 94%|█████████▍| 469/500 [05:30<00:10,  2.96it/s] 94%|█████████▍| 471/500 [05:37<00:34,  1.20s/it] 95%|█████████▍| 473/500 [05:37<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:37<00:15,  1.62it/s]Epoch:  409  	Training Loss: 5.42663037776947e-05
Test Loss:  3.935462154913694e-05
Valid Loss:  7.277184340637177e-05
Epoch:  410  	Training Loss: 5.4257343435892835e-05
Test Loss:  3.933334301109426e-05
Valid Loss:  7.275780808413401e-05
Epoch:  411  	Training Loss: 5.424831761047244e-05
Test Loss:  3.931278843083419e-05
Valid Loss:  7.27437945897691e-05
Epoch:  412  	Training Loss: 5.423944821814075e-05
Test Loss:  3.938771988032386e-05
Valid Loss:  7.269092020578682e-05
Epoch:  413  	Training Loss: 5.4186053603189066e-05
Test Loss:  3.947057848563418e-05
Valid Loss:  7.264460145961493e-05
Epoch:  414  	Training Loss: 5.413423787103966e-05
Test Loss:  3.955190550186671e-05
Valid Loss:  7.259947597049177e-05
Epoch:  415  	Training Loss: 5.4084142902866006e-05
Test Loss:  3.9626156649319455e-05
Valid Loss:  7.255659147631377e-05
Epoch:  416  	Training Loss: 5.403585237218067e-05
Test Loss:  3.96974864997901e-05
Valid Loss:  7.251415081555024e-05
Epoch:  417  	Training Loss: 5.3988685976946726e-05
Test Loss:  3.976504012825899e-05
Valid Loss:  7.247253233799711e-05
Epoch:  418  	Training Loss: 5.3942505473969504e-05
Test Loss:  3.982703492511064e-05
Valid Loss:  7.243209984153509e-05
Epoch:  419  	Training Loss: 5.389770376496017e-05
Test Loss:  3.9885868318378925e-05
Valid Loss:  7.239238766487688e-05
Epoch:  420  	Training Loss: 5.3853978897677734e-05
Test Loss:  3.994193684775382e-05
Valid Loss:  7.235377415781841e-05
Epoch:  421  	Training Loss: 5.381084338296205e-05
Test Loss:  3.999452746938914e-05
Valid Loss:  7.231607742141932e-05
Epoch:  422  	Training Loss: 5.376867557060905e-05
Test Loss:  3.9923994336277246e-05
Valid Loss:  7.228802860481665e-05
Epoch:  423  	Training Loss: 5.3757059504278004e-05
Test Loss:  3.98552801925689e-05
Valid Loss:  7.226067828014493e-05
Epoch:  424  	Training Loss: 5.374559259507805e-05
Test Loss:  3.978755194111727e-05
Valid Loss:  7.223329157568514e-05
Epoch:  425  	Training Loss: 5.373447129386477e-05
Test Loss:  3.9721900975564495e-05
Valid Loss:  7.220670522656292e-05
Epoch:  426  	Training Loss: 5.372356463340111e-05
Test Loss:  3.965774521930143e-05
Valid Loss:  7.218035170808434e-05
Epoch:  427  	Training Loss: 5.3712865337729454e-05
Test Loss:  3.959477908210829e-05
Valid Loss:  7.215466757770628e-05
Epoch:  428  	Training Loss: 5.370228973333724e-05
Test Loss:  3.953243140131235e-05
Valid Loss:  7.212840137071908e-05
Epoch:  429  	Training Loss: 5.369184509618208e-05
Test Loss:  3.94719754694961e-05
Valid Loss:  7.210303738247603e-05
Epoch:  430  	Training Loss: 5.368176061892882e-05
Test Loss:  3.941263275919482e-05
Valid Loss:  7.20782918506302e-05
Epoch:  431  	Training Loss: 5.367175617720932e-05
Test Loss:  3.935470886062831e-05
Valid Loss:  7.205369911389425e-05
Epoch:  432  	Training Loss: 5.366186087485403e-05
Test Loss:  3.858962008962408e-05
Valid Loss:  7.17134025762789e-05
Epoch:  433  	Training Loss: 5.35621729795821e-05
Test Loss:  3.870741056744009e-05
Valid Loss:  7.17056100256741e-05
Epoch:  434  	Training Loss: 5.346852049115114e-05
Test Loss:  3.808863402809948e-05
Valid Loss:  7.140752859413624e-05
Epoch:  435  	Training Loss: 5.337879338185303e-05
Test Loss:  3.8227401091717184e-05
Valid Loss:  7.139527588151395e-05
Epoch:  436  	Training Loss: 5.329212581273168e-05
Test Loss:  3.771164483623579e-05
Valid Loss:  7.112619641702622e-05
Epoch:  437  	Training Loss: 5.3207739256322384e-05
Test Loss:  3.786020533880219e-05
Valid Loss:  7.111005834303796e-05
Epoch:  438  	Training Loss: 5.312440043780953e-05
Test Loss:  3.7417001294670627e-05
Valid Loss:  7.086386904120445e-05
Epoch:  439  	Training Loss: 5.3042531362734735e-05
Test Loss:  3.755679426831193e-05
Valid Loss:  7.084054232109338e-05
Epoch:  440  	Training Loss: 5.296195740811527e-05
Test Loss:  3.717423169291578e-05
Valid Loss:  7.061335782054812e-05
Epoch:  441  	Training Loss: 5.2882576710544527e-05
Test Loss:  3.7306748708942905e-05
Valid Loss:  7.058394839987159e-05
Epoch:  442  	Training Loss: 5.280425466480665e-05
Test Loss:  3.7248355511110276e-05
Valid Loss:  7.055932655930519e-05
Epoch:  443  	Training Loss: 5.2797404350712895e-05
Test Loss:  3.719337109941989e-05
Valid Loss:  7.053687295410782e-05
Epoch:  444  	Training Loss: 5.279087054077536e-05
Test Loss:  3.714132253662683e-05
Valid Loss:  7.051535067148507e-05
Epoch:  445  	Training Loss: 5.278462776914239e-05
Test Loss:  3.709202792379074e-05
Valid Loss:  7.049560372252017e-05
Epoch:  446  	Training Loss: 5.277854506857693e-05
Test Loss:  3.704666596604511e-05
Valid Loss:  7.047688268357888e-05
Epoch:  447  	Training Loss: 5.277286982163787e-05
Test Loss:  3.7003381294198334e-05
Valid Loss:  7.045867823762819e-05
Epoch:  448  	Training Loss: 5.2767394663533196e-05
Test Loss:  3.6961999285267666e-05
Valid Loss:  7.04413978382945e-05
Epoch:  449  	Training Loss: 5.2762141422135755e-05
Test Loss:  3.692201426019892e-05
Valid Loss:  7.042501238174736e-05
Epoch:  450  	Training Loss: 5.275704825180583e-05
Test Loss:  3.6885619920212775e-05
Valid Loss:  7.040936179691926e-05
Epoch:  451  	Training Loss: 5.275224975775927e-05
Test Loss:  3.6852721677860245e-05
Valid Loss:  7.039493357297033e-05
Epoch:  452  	Training Loss: 5.2747745939996094e-05
Test Loss:  3.723526606336236e-05
Valid Loss:  7.033483416307718e-05
Epoch:  453  	Training Loss: 5.2643943490693346e-05
Test Loss:  3.741659747902304e-05
Valid Loss:  7.022502541076392e-05
Epoch:  454  	Training Loss: 5.255074938759208e-05
Test Loss:  3.76114112441428e-05
Valid Loss:  7.012928108451888e-05
Epoch:  455  	Training Loss: 5.2462390158325434e-05
Test Loss:  3.77791584469378e-05
Valid Loss:  7.003417704254389e-05
Epoch:  456  	Training Loss: 5.237802542978898e-05
Test Loss:  3.7926005461486056e-05
Valid Loss:  6.994169962126762e-05
Epoch:  457  	Training Loss: 5.2297218644525856e-05
Test Loss:  3.805534288403578e-05
Valid Loss:  6.985048821661621e-05
Epoch:  458  	Training Loss: 5.221911851549521e-05
Test Loss:  3.8169207982718945e-05
Valid Loss:  6.976030999794602e-05
Epoch:  459  	Training Loss: 5.2143746870569885e-05
Test Loss:  3.826822648989037e-05
Valid Loss:  6.967078661546111e-05
Epoch:  460  	Training Loss: 5.207046342547983e-05
Test Loss:  3.835488314507529e-05
Valid Loss:  6.958143058000132e-05
Epoch:  461  	Training Loss: 5.199928273214027e-05
Test Loss:  3.8429920095950365e-05
Valid Loss:  6.949321686988696e-05
Epoch:  462  	Training Loss: 5.1929779147030786e-05
Test Loss:  3.762292180908844e-05
Valid Loss:  6.913431570865214e-05
Epoch:  463  	Training Loss: 5.1838225772371516e-05
Test Loss:  3.812759314314462e-05
Valid Loss:  6.919684528838843e-05
Epoch:  464  	Training Loss: 5.1757131586782634e-05
Test Loss:  3.786249362747185e-05
Valid Loss:  6.901284359628335e-05
Epoch:  465  	Training Loss: 5.168163261259906e-05
Test Loss:  3.809994086623192e-05
Valid Loss:  6.899078289279714e-05
Epoch:  466  	Training Loss: 5.160976434126496e-05
Test Loss:  3.8047008274588734e-05
Valid Loss:  6.887468043714762e-05
Epoch:  467  	Training Loss: 5.154071550350636e-05
Test Loss:  3.8189922634046525e-05
Valid Loss:  6.882227171445265e-05
Epoch:  468  	Training Loss: 5.147440970176831e-05
Test Loss:  3.822213693638332e-05
Valid Loss:  6.873371603433043e-05
Epoch:  469  	Training Loss: 5.141089059179649e-05
Test Loss:  3.834121162071824e-05
Valid Loss:  6.867488264106214e-05
Epoch:  470  	Training Loss: 5.134827733854763e-05
Test Loss:  3.8411544664995745e-05
Valid Loss:  6.860338908154517e-05
Epoch:  471  	Training Loss: 5.128686461830512e-05
Test Loss:  3.849613494821824e-05
Valid Loss:  6.853803643025458e-05
Epoch:  472  	Training Loss: 5.1227274525444955e-05
Test Loss:  3.914426270057447e-05
Valid Loss:  6.860605208203197e-05
Epoch:  473  	Training Loss: 5.113826773595065e-05
Test Loss:  3.915735942428e-05
Valid Loss:  6.846696487627923e-05
Epoch:  474  	Training Loss: 5.107208198751323e-05
Test Loss:  3.933550760848448e-05
Valid Loss:  6.841176218586043e-05
Epoch:  475  	Training Loss: 5.101215356262401e-05
Test Loss:  3.938767622457817e-05
Valid Loss:  6.831651990069076e-05
Epoch:  476  	Training Loss: 5.0954153266502544e-05
Test Loss:  3.94672024413012e-05
Valid Loss:  6.824793672421947e-05
 95%|█████████▌| 477/500 [05:37<00:10,  2.21it/s] 96%|█████████▌| 479/500 [05:37<00:07,  2.98it/s] 96%|█████████▌| 481/500 [05:44<00:23,  1.22s/it] 97%|█████████▋| 483/500 [05:44<00:14,  1.15it/s] 97%|█████████▋| 485/500 [05:44<00:09,  1.59it/s] 97%|█████████▋| 487/500 [05:44<00:06,  2.16it/s] 98%|█████████▊| 489/500 [05:44<00:03,  2.89it/s] 98%|█████████▊| 491/500 [05:51<00:10,  1.21s/it] 99%|█████████▊| 493/500 [05:51<00:06,  1.16it/s] 99%|█████████▉| 495/500 [05:51<00:03,  1.60it/s] 99%|█████████▉| 497/500 [05:51<00:01,  2.18it/s]100%|█████████▉| 499/500 [05:51<00:00,  2.94it/s]100%|██████████| 500/500 [05:51<00:00,  1.42it/s]
Epoch:  477  	Training Loss: 5.0897797336801887e-05
Test Loss:  3.9486731111537665e-05
Valid Loss:  6.816312816226855e-05
Epoch:  478  	Training Loss: 5.084275471745059e-05
Test Loss:  3.950261452700943e-05
Valid Loss:  6.808285252191126e-05
Epoch:  479  	Training Loss: 5.0788745284080505e-05
Test Loss:  3.950582322431728e-05
Valid Loss:  6.800171104259789e-05
Epoch:  480  	Training Loss: 5.0735943659674376e-05
Test Loss:  3.949788515456021e-05
Valid Loss:  6.791624036850408e-05
Epoch:  481  	Training Loss: 5.06835276610218e-05
Test Loss:  3.949664096580818e-05
Valid Loss:  6.783944263588637e-05
Epoch:  482  	Training Loss: 5.063157368567772e-05
Test Loss:  3.930252569261938e-05
Valid Loss:  6.768311141058803e-05
Epoch:  483  	Training Loss: 5.056966620031744e-05
Test Loss:  3.9301772631006315e-05
Valid Loss:  6.761036638636142e-05
Epoch:  484  	Training Loss: 5.051423795521259e-05
Test Loss:  3.923769691027701e-05
Valid Loss:  6.75124247209169e-05
Epoch:  485  	Training Loss: 5.0460770580684766e-05
Test Loss:  3.919566734111868e-05
Valid Loss:  6.742740515619516e-05
Epoch:  486  	Training Loss: 5.040935138822533e-05
Test Loss:  3.9139293221523985e-05
Valid Loss:  6.734003545716405e-05
Epoch:  487  	Training Loss: 5.035928188590333e-05
Test Loss:  3.908185681211762e-05
Valid Loss:  6.72549576847814e-05
Epoch:  488  	Training Loss: 5.0310951337451115e-05
Test Loss:  3.9020109397824854e-05
Valid Loss:  6.717075302731246e-05
Epoch:  489  	Training Loss: 5.0263966841157526e-05
Test Loss:  3.8956437492743134e-05
Valid Loss:  6.708759610773996e-05
Epoch:  490  	Training Loss: 5.021826655138284e-05
Test Loss:  3.8889324059709907e-05
Valid Loss:  6.700629455735907e-05
Epoch:  491  	Training Loss: 5.0173828640254214e-05
Test Loss:  3.882070450345054e-05
Valid Loss:  6.692581519018859e-05
Epoch:  492  	Training Loss: 5.0130220188293606e-05
Test Loss:  3.873107198160142e-05
Valid Loss:  6.687210407108068e-05
Epoch:  493  	Training Loss: 5.007351137464866e-05
Test Loss:  3.860922151943669e-05
Valid Loss:  6.679961370537058e-05
Epoch:  494  	Training Loss: 5.0026021199300885e-05
Test Loss:  3.849869244731963e-05
Valid Loss:  6.672664312645793e-05
Epoch:  495  	Training Loss: 4.998353324481286e-05
Test Loss:  3.841022407868877e-05
Valid Loss:  6.665863475063816e-05
Epoch:  496  	Training Loss: 4.994440678274259e-05
Test Loss:  3.834407471003942e-05
Valid Loss:  6.659580685663968e-05
Epoch:  497  	Training Loss: 4.990808884031139e-05
Test Loss:  3.829375054920092e-05
Valid Loss:  6.653714081039652e-05
Epoch:  498  	Training Loss: 4.987425199942663e-05
Test Loss:  3.826087049674243e-05
Valid Loss:  6.648108683293685e-05
Epoch:  499  	Training Loss: 4.9841724830912426e-05
Test Loss:  3.824232044280507e-05
Valid Loss:  6.642828520853072e-05
Epoch:  500  	Training Loss: 4.981068195775151e-05
Test Loss:  3.8236168620642275e-05
Valid Loss:  6.637847400270402e-05
seed is  2
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:34, 14.58it/s]  1%|          | 4/500 [00:00<00:31, 15.57it/s]  1%|          | 6/500 [00:00<00:31, 15.90it/s]  2%|▏         | 8/500 [00:00<00:30, 16.14it/s]  2%|▏         | 10/500 [00:00<00:30, 16.19it/s]  2%|▏         | 12/500 [00:00<00:30, 16.11it/s]  3%|▎         | 14/500 [00:00<00:30, 16.00it/s]  3%|▎         | 16/500 [00:01<00:30, 15.68it/s]  4%|▎         | 18/500 [00:01<00:30, 15.91it/s]  4%|▍         | 20/500 [00:01<00:29, 16.01it/s]  4%|▍         | 22/500 [00:01<00:29, 16.07it/s]  5%|▍         | 24/500 [00:01<00:30, 15.68it/s]  5%|▌         | 26/500 [00:01<00:30, 15.38it/s]  6%|▌         | 28/500 [00:01<00:31, 14.98it/s]  6%|▌         | 30/500 [00:01<00:34, 13.58it/s]  6%|▋         | 32/500 [00:02<00:35, 13.19it/s]  7%|▋         | 34/500 [00:02<00:33, 13.97it/s]  7%|▋         | 36/500 [00:02<00:32, 14.47it/s]  8%|▊         | 38/500 [00:02<00:30, 14.97it/s]  8%|▊         | 40/500 [00:02<00:30, 15.16it/s]  8%|▊         | 42/500 [00:02<00:29, 15.45it/s]  9%|▉         | 44/500 [00:02<00:28, 15.73it/s]  9%|▉         | 46/500 [00:03<00:28, 15.94it/s] 10%|▉         | 48/500 [00:03<00:28, 16.14it/s] 10%|█         | 50/500 [00:03<00:27, 16.26it/s] 10%|█         | 52/500 [00:03<00:27, 16.30it/s] 11%|█         | 54/500 [00:03<00:27, 16.29it/s] 11%|█         | 56/500 [00:03<00:29, 15.15it/s] 12%|█▏        | 58/500 [00:03<00:29, 15.14it/s] 12%|█▏        | 60/500 [00:03<00:28, 15.39it/s] 12%|█▏        | 62/500 [00:04<00:30, 14.37it/s] 13%|█▎        | 64/500 [00:04<00:29, 14.91it/s] 13%|█▎        | 66/500 [00:04<00:28, 15.38it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.72it/s] 14%|█▍        | 70/500 [00:04<00:27, 15.83it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.04it/s] 15%|█▍        | 74/500 [00:04<00:26, 15.96it/s] 15%|█▌        | 76/500 [00:04<00:26, 15.93it/s] 16%|█▌        | 78/500 [00:05<00:26, 16.08it/s] 16%|█▌        | 80/500 [00:05<00:25, 16.18it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.19it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.14it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.17it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.28it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.35it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.33it/s] 19%|█▉        | 94/500 [00:06<00:24, 16.39it/s] 19%|█▉        | 96/500 [00:06<00:24, 16.39it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.40it/s] 20%|██        | 100/500 [00:06<00:24, 16.28it/s] 20%|██        | 102/500 [00:06<00:24, 16.08it/s] 21%|██        | 104/500 [00:06<00:24, 16.25it/s] 21%|██        | 106/500 [00:06<00:24, 16.11it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.11it/s] 22%|██▏       | 110/500 [00:07<00:24, 16.09it/s] 22%|██▏       | 112/500 [00:07<00:23, 16.29it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.34it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.40it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.42it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.35it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.11it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.00it/s]Epoch:  1  	Training Loss: 0.04927349463105202
Test Loss:  92.63675689697266
Valid Loss:  92.44253540039062
Epoch:  2  	Training Loss: 94.34325408935547
Test Loss:  764374272.0
Valid Loss:  764577664.0
Epoch:  3  	Training Loss: 765275392.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  125  	Training Loss: nan
 25%|██▌       | 126/500 [00:07<00:23, 16.03it/s] 26%|██▌       | 128/500 [00:08<00:22, 16.20it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.74it/s] 26%|██▋       | 132/500 [00:08<00:24, 15.26it/s] 27%|██▋       | 134/500 [00:08<00:25, 14.13it/s] 27%|██▋       | 136/500 [00:08<00:26, 13.73it/s] 28%|██▊       | 138/500 [00:08<00:27, 13.25it/s] 28%|██▊       | 140/500 [00:09<00:27, 13.10it/s] 28%|██▊       | 142/500 [00:09<00:26, 13.36it/s] 29%|██▉       | 144/500 [00:09<00:25, 14.10it/s] 29%|██▉       | 146/500 [00:09<00:25, 13.95it/s] 30%|██▉       | 148/500 [00:09<00:26, 13.47it/s] 30%|███       | 150/500 [00:09<00:24, 14.11it/s] 30%|███       | 152/500 [00:09<00:23, 14.75it/s] 31%|███       | 154/500 [00:09<00:22, 15.22it/s] 31%|███       | 156/500 [00:10<00:22, 15.58it/s] 32%|███▏      | 158/500 [00:10<00:21, 15.71it/s] 32%|███▏      | 160/500 [00:10<00:21, 15.79it/s] 32%|███▏      | 162/500 [00:10<00:21, 15.56it/s] 33%|███▎      | 164/500 [00:10<00:21, 15.85it/s] 33%|███▎      | 166/500 [00:10<00:21, 15.67it/s] 34%|███▎      | 168/500 [00:10<00:21, 15.56it/s] 34%|███▍      | 170/500 [00:11<00:21, 15.15it/s] 34%|███▍      | 172/500 [00:11<00:21, 15.01it/s] 35%|███▍      | 174/500 [00:11<00:21, 15.38it/s] 35%|███▌      | 176/500 [00:11<00:20, 15.67it/s] 36%|███▌      | 178/500 [00:11<00:20, 15.90it/s] 36%|███▌      | 180/500 [00:11<00:20, 15.27it/s] 36%|███▋      | 182/500 [00:11<00:20, 15.63it/s] 37%|███▋      | 184/500 [00:11<00:19, 15.85it/s] 37%|███▋      | 186/500 [00:12<00:19, 16.09it/s] 38%|███▊      | 188/500 [00:12<00:19, 16.10it/s] 38%|███▊      | 190/500 [00:12<00:19, 16.19it/s] 38%|███▊      | 192/500 [00:12<00:18, 16.27it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.35it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.37it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.39it/s] 40%|████      | 200/500 [00:12<00:18, 16.44it/s] 40%|████      | 202/500 [00:12<00:18, 16.45it/s] 41%|████      | 204/500 [00:13<00:18, 16.43it/s] 41%|████      | 206/500 [00:13<00:17, 16.41it/s] 42%|████▏     | 208/500 [00:13<00:17, 16.30it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.21it/s] 42%|████▏     | 212/500 [00:13<00:18, 15.92it/s] 43%|████▎     | 214/500 [00:13<00:18, 15.83it/s] 43%|████▎     | 216/500 [00:13<00:18, 15.63it/s] 44%|████▎     | 218/500 [00:13<00:17, 15.74it/s] 44%|████▍     | 220/500 [00:14<00:17, 15.81it/s] 44%|████▍     | 222/500 [00:14<00:17, 15.97it/s] 45%|████▍     | 224/500 [00:14<00:17, 16.06it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.20it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.29it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.14it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.05it/s] 47%|████▋     | 234/500 [00:14<00:16, 15.90it/s] 47%|████▋     | 236/500 [00:15<00:16, 15.69it/s] 48%|████▊     | 238/500 [00:15<00:16, 15.74it/s] 48%|████▊     | 240/500 [00:15<00:16, 15.70it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.68it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.76it/s] 49%|████▉     | 246/500 [00:15<00:16, 15.55it/s] 50%|████▉     | 248/500 [00:15<00:16, 15.33it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  249  	Training Loss: nan
 50%|█████     | 250/500 [00:16<00:16, 15.56it/s] 50%|█████     | 252/500 [00:16<00:15, 15.60it/s] 51%|█████     | 254/500 [00:16<00:15, 15.90it/s] 51%|█████     | 256/500 [00:16<00:15, 16.09it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.25it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.35it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.45it/s] 53%|█████▎    | 264/500 [00:16<00:14, 15.82it/s] 53%|█████▎    | 266/500 [00:17<00:14, 15.79it/s] 54%|█████▎    | 268/500 [00:17<00:14, 15.89it/s] 54%|█████▍    | 270/500 [00:17<00:14, 16.01it/s] 54%|█████▍    | 272/500 [00:17<00:15, 14.38it/s] 55%|█████▍    | 274/500 [00:17<00:15, 14.93it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.37it/s] 56%|█████▌    | 278/500 [00:17<00:14, 15.71it/s] 56%|█████▌    | 280/500 [00:17<00:13, 15.92it/s] 56%|█████▋    | 282/500 [00:18<00:13, 16.08it/s] 57%|█████▋    | 284/500 [00:18<00:13, 16.21it/s] 57%|█████▋    | 286/500 [00:18<00:13, 16.26it/s] 58%|█████▊    | 288/500 [00:18<00:12, 16.32it/s] 58%|█████▊    | 290/500 [00:18<00:12, 16.22it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.22it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.27it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.26it/s] 60%|█████▉    | 298/500 [00:19<00:12, 16.33it/s] 60%|██████    | 300/500 [00:19<00:12, 16.34it/s] 60%|██████    | 302/500 [00:19<00:12, 16.33it/s] 61%|██████    | 304/500 [00:19<00:11, 16.36it/s] 61%|██████    | 306/500 [00:19<00:11, 16.43it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.44it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.51it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.48it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.46it/s] 63%|██████▎   | 316/500 [00:20<00:11, 16.42it/s] 64%|██████▎   | 318/500 [00:20<00:11, 16.38it/s] 64%|██████▍   | 320/500 [00:20<00:11, 16.25it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.25it/s] 65%|██████▍   | 324/500 [00:20<00:11, 15.58it/s] 65%|██████▌   | 326/500 [00:20<00:11, 15.71it/s] 66%|██████▌   | 328/500 [00:20<00:11, 15.62it/s] 66%|██████▌   | 330/500 [00:21<00:10, 15.87it/s] 66%|██████▋   | 332/500 [00:21<00:10, 16.03it/s] 67%|██████▋   | 334/500 [00:21<00:10, 16.15it/s] 67%|██████▋   | 336/500 [00:21<00:10, 16.24it/s] 68%|██████▊   | 338/500 [00:21<00:09, 16.35it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.40it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.02it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.02it/s] 69%|██████▉   | 346/500 [00:21<00:09, 15.83it/s] 70%|██████▉   | 348/500 [00:22<00:09, 15.91it/s] 70%|███████   | 350/500 [00:22<00:09, 15.74it/s] 70%|███████   | 352/500 [00:22<00:09, 15.54it/s] 71%|███████   | 354/500 [00:22<00:09, 15.60it/s] 71%|███████   | 356/500 [00:22<00:09, 15.81it/s] 72%|███████▏  | 358/500 [00:22<00:09, 15.71it/s] 72%|███████▏  | 360/500 [00:22<00:09, 15.38it/s] 72%|███████▏  | 362/500 [00:23<00:09, 15.33it/s] 73%|███████▎  | 364/500 [00:23<00:08, 15.36it/s] 73%|███████▎  | 366/500 [00:23<00:08, 15.47it/s] 74%|███████▎  | 368/500 [00:23<00:08, 15.58it/s] 74%|███████▍  | 370/500 [00:23<00:08, 15.85it/s] 74%|███████▍  | 372/500 [00:23<00:08, 15.78it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  373  	Training Loss: nan
 75%|███████▍  | 374/500 [00:23<00:08, 15.23it/s] 75%|███████▌  | 376/500 [00:23<00:08, 15.38it/s] 76%|███████▌  | 378/500 [00:24<00:07, 15.59it/s] 76%|███████▌  | 380/500 [00:24<00:07, 15.88it/s] 76%|███████▋  | 382/500 [00:24<00:07, 15.67it/s] 77%|███████▋  | 384/500 [00:24<00:07, 15.87it/s] 77%|███████▋  | 386/500 [00:24<00:07, 16.06it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.17it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.12it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.14it/s] 79%|███████▉  | 394/500 [00:25<00:06, 16.11it/s] 79%|███████▉  | 396/500 [00:25<00:06, 16.06it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.20it/s] 80%|████████  | 400/500 [00:25<00:06, 16.34it/s] 80%|████████  | 402/500 [00:25<00:05, 16.36it/s] 81%|████████  | 404/500 [00:25<00:05, 16.35it/s] 81%|████████  | 406/500 [00:25<00:05, 16.15it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.23it/s] 82%|████████▏ | 410/500 [00:26<00:05, 16.29it/s] 82%|████████▏ | 412/500 [00:26<00:05, 16.35it/s] 83%|████████▎ | 414/500 [00:26<00:05, 16.39it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.37it/s] 84%|████████▎ | 418/500 [00:26<00:05, 16.39it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.40it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.38it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.35it/s] 85%|████████▌ | 426/500 [00:27<00:04, 16.36it/s] 86%|████████▌ | 428/500 [00:27<00:04, 16.37it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.39it/s] 86%|████████▋ | 432/500 [00:27<00:04, 15.88it/s] 87%|████████▋ | 434/500 [00:27<00:04, 15.67it/s] 87%|████████▋ | 436/500 [00:27<00:04, 15.74it/s] 88%|████████▊ | 438/500 [00:27<00:03, 15.95it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.13it/s] 88%|████████▊ | 442/500 [00:28<00:03, 16.19it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.32it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.33it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.35it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.35it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.22it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.14it/s] 91%|█████████ | 456/500 [00:28<00:02, 15.87it/s] 92%|█████████▏| 458/500 [00:29<00:02, 15.75it/s] 92%|█████████▏| 460/500 [00:29<00:02, 15.37it/s] 92%|█████████▏| 462/500 [00:29<00:02, 15.71it/s] 93%|█████████▎| 464/500 [00:29<00:02, 15.74it/s] 93%|█████████▎| 466/500 [00:29<00:02, 15.91it/s] 94%|█████████▎| 468/500 [00:29<00:02, 15.81it/s] 94%|█████████▍| 470/500 [00:29<00:01, 15.84it/s] 94%|█████████▍| 472/500 [00:29<00:01, 15.87it/s] 95%|█████████▍| 474/500 [00:30<00:01, 15.97it/s] 95%|█████████▌| 476/500 [00:30<00:01, 15.86it/s] 96%|█████████▌| 478/500 [00:30<00:01, 15.77it/s] 96%|█████████▌| 480/500 [00:30<00:01, 15.56it/s] 96%|█████████▋| 482/500 [00:30<00:01, 15.76it/s] 97%|█████████▋| 484/500 [00:30<00:01, 15.48it/s] 97%|█████████▋| 486/500 [00:30<00:00, 15.68it/s] 98%|█████████▊| 488/500 [00:30<00:00, 15.62it/s] 98%|█████████▊| 490/500 [00:31<00:00, 15.87it/s] 98%|█████████▊| 492/500 [00:31<00:00, 15.94it/s] 99%|█████████▉| 494/500 [00:31<00:00, 16.07it/s] 99%|█████████▉| 496/500 [00:31<00:00, 16.17it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
100%|█████████▉| 498/500 [00:31<00:00, 16.25it/s]100%|██████████| 500/500 [00:31<00:00, 16.31it/s]100%|██████████| 500/500 [00:31<00:00, 15.80it/s]
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  2
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<50:33,  6.08s/it]  1%|          | 3/500 [00:06<13:28,  1.63s/it]  1%|          | 5/500 [00:06<06:48,  1.21it/s]  1%|▏         | 7/500 [00:06<04:08,  1.99it/s]  2%|▏         | 9/500 [00:06<02:45,  2.96it/s]  2%|▏         | 11/500 [00:12<10:39,  1.31s/it]  3%|▎         | 13/500 [00:12<07:15,  1.12it/s]  3%|▎         | 15/500 [00:19<13:09,  1.63s/it]  3%|▎         | 17/500 [00:19<09:08,  1.14s/it]  4%|▍         | 19/500 [00:19<06:26,  1.25it/s]  4%|▍         | 21/500 [00:31<19:38,  2.46s/it]  5%|▍         | 23/500 [00:32<13:44,  1.73s/it]  5%|▌         | 25/500 [00:38<17:04,  2.16s/it]  5%|▌         | 27/500 [00:38<12:01,  1.53s/it]  6%|▌         | 29/500 [00:38<08:31,  1.09s/it]  6%|▌         | 31/500 [00:51<20:47,  2.66s/it]  7%|▋         | 33/500 [00:51<14:38,  1.88s/it]  7%|▋         | 35/500 [00:57<17:34,  2.27s/it]  7%|▋         | 37/500 [00:57<12:24,  1.61s/it]  8%|▊         | 39/500 [00:57<08:47,  1.14s/it]  8%|▊         | 41/500 [01:10<20:57,  2.74s/it]  9%|▊         | 43/500 [01:11<14:46,  1.94s/it]  9%|▉         | 45/500 [01:17<17:46,  2.34s/it]  9%|▉         | 47/500 [01:17<12:33,  1.66s/it] 10%|▉         | 49/500 [01:17<08:55,  1.19s/it] 10%|█         | 51/500 [01:30<20:35,  2.75s/it] 11%|█         | 53/500 [01:30<14:30,  1.95s/it] 11%|█         | 55/500 [01:37<17:10,  2.32s/it] 11%|█▏        | 57/500 [01:37<12:07,  1.64s/it] 12%|█▏        | 59/500 [01:37<08:35,  1.17s/it]Epoch:  1  	Training Loss: 0.04927349090576172
Test Loss:  2.9702565670013428
Valid Loss:  2.9598028659820557
Epoch:  2  	Training Loss: 3.1372199058532715
Test Loss:  27.464147567749023
Valid Loss:  27.417123794555664
Epoch:  3  	Training Loss: 28.092449188232422
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  4  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  5  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  6  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  7  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  8  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  9  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  10  	Training Loss: 0.039293888956308365
Test Loss:  0.03553702309727669
Valid Loss:  0.032648105174303055
Epoch:  11  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  12  	Training Loss: 0.039293885231018066
Test Loss:  0.03553702309727669
Valid Loss:  0.032648105174303055
Epoch:  13  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  14  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  15  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.03264810889959335
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.039293885231018066
Test Loss:  0.03553702309727669
Valid Loss:  0.03264810889959335
Epoch:  17  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  18  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  19  	Training Loss: 0.039293885231018066
Test Loss:  0.03553702309727669
Valid Loss:  0.03264810889959335
Epoch:  20  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  22  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  23  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  24  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  25  	Training Loss: 0.039293885231018066
Test Loss:  0.03553702309727669
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  27  	Training Loss: 0.039293885231018066
Test Loss:  0.03553702309727669
Valid Loss:  0.032648101449012756
Epoch:  28  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  29  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  30  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701564669609
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  32  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  33  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  34  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  35  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  37  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  38  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  39  	Training Loss: 0.039293888956308365
Test Loss:  0.03553702309727669
Valid Loss:  0.032648101449012756
Epoch:  40  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  42  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  43  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  44  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  45  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  47  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  48  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  49  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  50  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  52  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  53  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  54  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  55  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  57  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  58  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  59  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  60  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
 12%|█▏        | 61/500 [01:49<19:37,  2.68s/it] 13%|█▎        | 63/500 [01:50<13:50,  1.90s/it] 13%|█▎        | 65/500 [01:56<16:24,  2.26s/it] 13%|█▎        | 67/500 [01:56<11:35,  1.61s/it] 14%|█▍        | 69/500 [01:56<08:13,  1.14s/it] 14%|█▍        | 71/500 [02:09<19:14,  2.69s/it] 15%|█▍        | 73/500 [02:09<13:33,  1.91s/it] 15%|█▌        | 75/500 [02:15<16:15,  2.30s/it] 15%|█▌        | 77/500 [02:15<11:29,  1.63s/it] 16%|█▌        | 79/500 [02:16<08:09,  1.16s/it] 16%|█▌        | 81/500 [02:28<18:48,  2.69s/it] 17%|█▋        | 83/500 [02:28<13:15,  1.91s/it] 17%|█▋        | 85/500 [02:34<15:44,  2.28s/it] 17%|█▋        | 87/500 [02:35<11:07,  1.62s/it] 18%|█▊        | 89/500 [02:35<07:52,  1.15s/it] 18%|█▊        | 89/500 [02:45<07:52,  1.15s/it] 18%|█▊        | 91/500 [02:47<18:15,  2.68s/it] 19%|█▊        | 93/500 [02:47<12:51,  1.90s/it] 19%|█▉        | 95/500 [02:54<15:21,  2.27s/it] 19%|█▉        | 97/500 [02:54<10:50,  1.61s/it] 20%|█▉        | 99/500 [02:54<07:40,  1.15s/it] 20%|█▉        | 99/500 [03:05<07:40,  1.15s/it] 20%|██        | 101/500 [03:07<17:51,  2.68s/it] 21%|██        | 103/500 [03:07<12:34,  1.90s/it] 21%|██        | 105/500 [03:13<15:02,  2.28s/it] 21%|██▏       | 107/500 [03:13<10:35,  1.62s/it] 22%|██▏       | 109/500 [03:13<07:30,  1.15s/it] 22%|██▏       | 109/500 [03:25<07:30,  1.15s/it] 22%|██▏       | 111/500 [03:26<17:30,  2.70s/it] 23%|██▎       | 113/500 [03:26<12:19,  1.91s/it] 23%|██▎       | 115/500 [03:32<14:48,  2.31s/it] 23%|██▎       | 117/500 [03:33<10:26,  1.64s/it] 24%|██▍       | 119/500 [03:33<07:23,  1.16s/it]Epoch:  62  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  63  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  64  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  65  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  67  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  68  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  69  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  70  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  72  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  73  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  74  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  75  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  77  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  78  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  79  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  80  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  82  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  83  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  84  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  85  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.03264810889959335
Epoch:  87  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  88  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  89  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  90  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  92  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  93  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  94  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  95  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  97  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  98  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  99  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  100  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  102  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  103  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  104  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  105  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  107  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  108  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  109  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  110  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  112  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  113  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  114  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  115  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  117  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  118  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  119  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  120  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
 24%|██▍       | 119/500 [03:45<07:23,  1.16s/it] 24%|██▍       | 121/500 [03:46<17:16,  2.73s/it] 25%|██▍       | 123/500 [03:46<12:09,  1.93s/it] 25%|██▌       | 125/500 [03:52<14:38,  2.34s/it] 25%|██▌       | 127/500 [03:52<10:19,  1.66s/it] 26%|██▌       | 129/500 [03:53<07:18,  1.18s/it] 26%|██▌       | 131/500 [04:05<16:46,  2.73s/it] 27%|██▋       | 133/500 [04:05<11:48,  1.93s/it] 27%|██▋       | 135/500 [04:12<14:03,  2.31s/it] 27%|██▋       | 137/500 [04:12<09:55,  1.64s/it] 28%|██▊       | 139/500 [04:12<07:01,  1.17s/it] 28%|██▊       | 141/500 [04:25<16:27,  2.75s/it] 29%|██▊       | 143/500 [04:25<11:35,  1.95s/it] 29%|██▉       | 145/500 [04:32<13:52,  2.34s/it] 29%|██▉       | 147/500 [04:32<09:47,  1.67s/it] 30%|██▉       | 149/500 [04:32<06:56,  1.19s/it] 30%|███       | 151/500 [04:45<16:16,  2.80s/it] 31%|███       | 153/500 [04:45<11:26,  1.98s/it] 31%|███       | 155/500 [04:52<13:40,  2.38s/it] 31%|███▏      | 157/500 [04:52<09:39,  1.69s/it] 32%|███▏      | 159/500 [04:52<06:52,  1.21s/it] 32%|███▏      | 161/500 [05:05<15:30,  2.74s/it] 33%|███▎      | 163/500 [05:05<10:54,  1.94s/it] 33%|███▎      | 165/500 [05:11<12:57,  2.32s/it] 33%|███▎      | 167/500 [05:11<09:08,  1.65s/it] 34%|███▍      | 169/500 [05:12<06:27,  1.17s/it] 34%|███▍      | 171/500 [05:24<15:00,  2.74s/it] 35%|███▍      | 173/500 [05:25<10:35,  1.94s/it] 35%|███▌      | 175/500 [05:31<12:35,  2.32s/it] 35%|███▌      | 177/500 [05:31<08:54,  1.65s/it]**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  122  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  123  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  124  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  125  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  127  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  128  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  129  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  130  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  132  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  133  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  134  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  135  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  137  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  138  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  139  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  140  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  142  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  143  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  144  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  145  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  147  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  148  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  149  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  150  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  152  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  153  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  154  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  155  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  157  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  158  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  159  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  160  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.03264810889959335
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  162  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  163  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  164  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  165  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  167  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  168  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  169  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.03264810889959335
Epoch:  170  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  172  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  173  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  174  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  175  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  177  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  178  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
 36%|███▌      | 179/500 [05:31<06:19,  1.18s/it] 36%|███▌      | 180/500 [05:38<11:09,  2.09s/it] 36%|███▌      | 181/500 [05:44<15:39,  2.95s/it] 37%|███▋      | 183/500 [05:44<10:01,  1.90s/it] 37%|███▋      | 185/500 [05:51<12:19,  2.35s/it] 37%|███▋      | 187/500 [05:51<08:20,  1.60s/it] 38%|███▊      | 189/500 [05:51<05:44,  1.11s/it] 38%|███▊      | 191/500 [06:04<14:15,  2.77s/it] 39%|███▊      | 193/500 [06:04<09:53,  1.93s/it] 39%|███▉      | 195/500 [06:10<11:51,  2.33s/it] 39%|███▉      | 197/500 [06:10<08:19,  1.65s/it] 40%|███▉      | 199/500 [06:11<05:53,  1.17s/it] 40%|████      | 201/500 [06:23<13:36,  2.73s/it] 41%|████      | 203/500 [06:23<09:33,  1.93s/it] 41%|████      | 205/500 [06:30<11:24,  2.32s/it] 41%|████▏     | 207/500 [06:30<08:02,  1.65s/it] 42%|████▏     | 209/500 [06:30<05:42,  1.18s/it] 42%|████▏     | 210/500 [06:37<10:14,  2.12s/it] 42%|████▏     | 211/500 [06:43<14:15,  2.96s/it] 43%|████▎     | 213/500 [06:43<09:07,  1.91s/it] 43%|████▎     | 215/500 [06:50<11:09,  2.35s/it] 43%|████▎     | 217/500 [06:50<07:33,  1.60s/it] 44%|████▍     | 219/500 [06:50<05:12,  1.11s/it] 44%|████▍     | 220/500 [06:57<10:01,  2.15s/it] 44%|████▍     | 221/500 [07:03<13:58,  3.00s/it] 45%|████▍     | 223/500 [07:03<08:47,  1.90s/it] 45%|████▌     | 225/500 [07:09<10:40,  2.33s/it] 45%|████▌     | 227/500 [07:09<07:11,  1.58s/it] 46%|████▌     | 229/500 [07:09<04:55,  1.09s/it] 46%|████▌     | 231/500 [07:22<12:05,  2.70s/it] 47%|████▋     | 233/500 [07:22<08:22,  1.88s/it] 47%|████▋     | 235/500 [07:28<10:02,  2.28s/it]Epoch:  179  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  180  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.03264810889959335
Epoch:  182  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  183  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  184  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  185  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  187  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  188  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  189  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  190  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  192  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  193  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  194  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  195  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  197  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  198  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  199  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  200  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  202  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  203  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  204  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  205  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  207  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.03264810889959335
Epoch:  208  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  209  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  210  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  212  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  213  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  214  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  215  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  217  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  218  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  219  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  220  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  222  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  223  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  224  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  225  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  227  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  228  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  229  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  230  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  232  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  233  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  234  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  235  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
 47%|████▋     | 237/500 [07:28<07:01,  1.60s/it] 48%|████▊     | 239/500 [07:29<04:56,  1.14s/it] 48%|████▊     | 241/500 [07:41<11:39,  2.70s/it] 49%|████▊     | 243/500 [07:41<08:10,  1.91s/it] 49%|████▉     | 245/500 [07:48<09:39,  2.27s/it] 49%|████▉     | 247/500 [07:48<06:47,  1.61s/it] 50%|████▉     | 249/500 [07:48<04:47,  1.15s/it] 50%|█████     | 251/500 [08:00<10:55,  2.63s/it] 51%|█████     | 253/500 [08:00<07:39,  1.86s/it] 51%|█████     | 255/500 [08:06<09:06,  2.23s/it] 51%|█████▏    | 257/500 [08:06<06:24,  1.58s/it] 52%|█████▏    | 259/500 [08:07<04:31,  1.13s/it] 52%|█████▏    | 261/500 [08:19<10:27,  2.63s/it] 53%|█████▎    | 263/500 [08:19<07:21,  1.86s/it] 53%|█████▎    | 265/500 [08:25<08:44,  2.23s/it] 53%|█████▎    | 267/500 [08:25<06:08,  1.58s/it] 54%|█████▍    | 269/500 [08:25<04:19,  1.13s/it] 54%|█████▍    | 269/500 [08:36<04:19,  1.13s/it] 54%|█████▍    | 271/500 [08:38<10:09,  2.66s/it] 55%|█████▍    | 273/500 [08:38<07:07,  1.89s/it] 55%|█████▌    | 275/500 [08:44<08:28,  2.26s/it] 55%|█████▌    | 277/500 [08:44<05:57,  1.60s/it] 56%|█████▌    | 279/500 [08:45<04:12,  1.14s/it] 56%|█████▌    | 279/500 [08:56<04:12,  1.14s/it] 56%|█████▌    | 281/500 [08:57<09:38,  2.64s/it] 57%|█████▋    | 283/500 [08:57<06:45,  1.87s/it] 57%|█████▋    | 285/500 [09:03<08:02,  2.24s/it] 57%|█████▋    | 287/500 [09:03<05:39,  1.59s/it] 58%|█████▊    | 289/500 [09:03<03:59,  1.13s/it] 58%|█████▊    | 289/500 [09:16<03:59,  1.13s/it] 58%|█████▊    | 291/500 [09:16<09:11,  2.64s/it] 59%|█████▊    | 293/500 [09:16<06:26,  1.87s/it]Epoch:  237  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  238  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  239  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  240  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  242  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  243  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  244  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  245  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  247  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  248  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  249  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  250  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  252  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  253  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  254  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  255  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  257  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  258  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  259  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  260  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  262  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  263  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  264  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  265  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  267  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  268  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  269  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.03264810889959335
Epoch:  270  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  272  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  273  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  274  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  275  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  277  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  278  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  279  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  280  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  282  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  283  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  284  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  285  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  287  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  288  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  289  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  290  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  292  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  293  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  294  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  295  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
 59%|█████▉    | 295/500 [09:22<07:41,  2.25s/it] 59%|█████▉    | 297/500 [09:22<05:23,  1.60s/it] 60%|█████▉    | 299/500 [09:22<03:48,  1.14s/it] 60%|██████    | 301/500 [09:35<08:50,  2.66s/it] 61%|██████    | 303/500 [09:35<06:11,  1.89s/it] 61%|██████    | 305/500 [09:41<07:20,  2.26s/it] 61%|██████▏   | 307/500 [09:41<05:09,  1.60s/it] 62%|██████▏   | 309/500 [09:42<03:37,  1.14s/it] 62%|██████▏   | 311/500 [09:54<08:24,  2.67s/it] 63%|██████▎   | 313/500 [09:54<05:53,  1.89s/it] 63%|██████▎   | 315/500 [10:01<07:01,  2.28s/it] 63%|██████▎   | 317/500 [10:01<04:55,  1.62s/it] 64%|██████▍   | 319/500 [10:01<03:28,  1.15s/it] 64%|██████▍   | 321/500 [10:13<08:00,  2.68s/it] 65%|██████▍   | 323/500 [10:14<05:36,  1.90s/it] 65%|██████▌   | 325/500 [10:20<06:36,  2.27s/it] 65%|██████▌   | 327/500 [10:20<04:38,  1.61s/it] 66%|██████▌   | 329/500 [10:20<03:15,  1.15s/it] 66%|██████▌   | 331/500 [10:32<07:28,  2.65s/it] 67%|██████▋   | 333/500 [10:33<05:13,  1.88s/it] 67%|██████▋   | 335/500 [10:39<06:16,  2.28s/it] 67%|██████▋   | 337/500 [10:39<04:24,  1.62s/it] 68%|██████▊   | 339/500 [10:39<03:05,  1.15s/it] 68%|██████▊   | 341/500 [10:52<07:08,  2.70s/it] 69%|██████▊   | 343/500 [10:52<04:59,  1.91s/it] 69%|██████▉   | 345/500 [10:58<05:54,  2.29s/it] 69%|██████▉   | 347/500 [10:58<04:08,  1.62s/it] 70%|██████▉   | 349/500 [10:59<02:54,  1.16s/it] 70%|███████   | 351/500 [11:11<06:37,  2.66s/it] 71%|███████   | 353/500 [11:11<04:37,  1.88s/it]**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  297  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  298  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  299  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  300  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  302  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  303  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  304  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  305  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  307  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  308  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  309  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701564669609
Valid Loss:  0.032648105174303055
Epoch:  310  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  312  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  313  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  314  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  315  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  317  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  318  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  319  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  320  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  322  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  323  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  324  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  325  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  327  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  328  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  329  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  330  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  332  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  333  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  334  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  335  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701564669609
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  337  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  338  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  339  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  340  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  342  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  343  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  344  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  345  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  347  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  348  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  349  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  350  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  352  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  353  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
 71%|███████   | 355/500 [11:17<05:28,  2.26s/it] 71%|███████▏  | 357/500 [11:18<03:49,  1.61s/it] 72%|███████▏  | 359/500 [11:18<02:41,  1.14s/it] 72%|███████▏  | 361/500 [11:30<06:11,  2.67s/it] 73%|███████▎  | 363/500 [11:30<04:19,  1.89s/it] 73%|███████▎  | 365/500 [11:37<05:09,  2.29s/it] 73%|███████▎  | 367/500 [11:37<03:36,  1.62s/it] 74%|███████▍  | 369/500 [11:37<02:31,  1.16s/it] 74%|███████▍  | 371/500 [11:49<05:45,  2.68s/it] 75%|███████▍  | 373/500 [11:50<04:00,  1.89s/it] 75%|███████▌  | 375/500 [11:56<04:43,  2.27s/it] 75%|███████▌  | 377/500 [11:56<03:17,  1.61s/it] 76%|███████▌  | 379/500 [11:56<02:18,  1.15s/it] 76%|███████▌  | 381/500 [12:09<05:23,  2.71s/it] 77%|███████▋  | 383/500 [12:09<03:44,  1.92s/it] 77%|███████▋  | 385/500 [12:15<04:23,  2.29s/it] 77%|███████▋  | 387/500 [12:15<03:03,  1.62s/it] 78%|███████▊  | 389/500 [12:16<02:08,  1.15s/it] 78%|███████▊  | 389/500 [12:26<02:08,  1.15s/it] 78%|███████▊  | 391/500 [12:28<04:54,  2.70s/it] 79%|███████▊  | 393/500 [12:28<03:24,  1.91s/it] 79%|███████▉  | 395/500 [12:35<04:02,  2.31s/it] 79%|███████▉  | 397/500 [12:35<02:48,  1.64s/it] 80%|███████▉  | 399/500 [12:35<01:57,  1.16s/it] 80%|███████▉  | 399/500 [12:46<01:57,  1.16s/it] 80%|████████  | 401/500 [12:48<04:27,  2.71s/it] 81%|████████  | 403/500 [12:48<03:05,  1.92s/it] 81%|████████  | 405/500 [12:54<03:38,  2.30s/it] 81%|████████▏ | 407/500 [12:54<02:32,  1.63s/it] 82%|████████▏ | 409/500 [12:55<01:45,  1.16s/it] 82%|████████▏ | 409/500 [13:06<01:45,  1.16s/it] 82%|████████▏ | 411/500 [13:07<03:59,  2.69s/it]Epoch:  354  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  355  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  357  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  358  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  359  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  360  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  362  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  363  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  364  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  365  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  367  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  368  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  369  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  370  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  372  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  373  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  374  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  375  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  377  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  378  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  379  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  380  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  382  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  383  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  384  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  385  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  387  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  388  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  389  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  390  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  392  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  393  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  394  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  395  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  397  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  398  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  399  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  400  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  402  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  403  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  404  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  405  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.03264810889959335
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  407  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  408  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  409  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  410  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
 83%|████████▎ | 413/500 [13:07<02:45,  1.91s/it] 83%|████████▎ | 415/500 [13:14<03:13,  2.28s/it] 83%|████████▎ | 417/500 [13:14<02:14,  1.62s/it] 84%|████████▍ | 419/500 [13:14<01:33,  1.16s/it] 84%|████████▍ | 419/500 [13:26<01:33,  1.16s/it] 84%|████████▍ | 421/500 [13:26<03:31,  2.68s/it] 85%|████████▍ | 423/500 [13:26<02:25,  1.89s/it] 85%|████████▌ | 425/500 [13:33<02:52,  2.30s/it] 85%|████████▌ | 427/500 [13:33<01:58,  1.63s/it] 86%|████████▌ | 429/500 [13:33<01:22,  1.16s/it] 86%|████████▌ | 431/500 [13:46<03:04,  2.67s/it] 87%|████████▋ | 433/500 [13:46<02:06,  1.89s/it] 87%|████████▋ | 435/500 [13:52<02:27,  2.27s/it] 87%|████████▋ | 437/500 [13:52<01:41,  1.61s/it] 88%|████████▊ | 439/500 [13:52<01:10,  1.15s/it] 88%|████████▊ | 441/500 [14:05<02:37,  2.68s/it] 89%|████████▊ | 443/500 [14:05<01:48,  1.90s/it] 89%|████████▉ | 445/500 [14:11<02:03,  2.25s/it] 89%|████████▉ | 447/500 [14:11<01:24,  1.60s/it] 90%|████████▉ | 449/500 [14:11<00:57,  1.14s/it] 90%|█████████ | 451/500 [14:24<02:11,  2.68s/it] 91%|█████████ | 453/500 [14:24<01:29,  1.90s/it] 91%|█████████ | 455/500 [14:30<01:41,  2.26s/it] 91%|█████████▏| 457/500 [14:30<01:09,  1.61s/it] 92%|█████████▏| 459/500 [14:31<00:46,  1.14s/it] 92%|█████████▏| 461/500 [14:43<01:45,  2.71s/it] 93%|█████████▎| 463/500 [14:43<01:10,  1.92s/it] 93%|█████████▎| 465/500 [14:50<01:22,  2.35s/it] 93%|█████████▎| 467/500 [14:50<00:55,  1.67s/it] 94%|█████████▍| 469/500 [14:50<00:36,  1.19s/it]Epoch:  412  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  413  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  414  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  415  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  417  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  418  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  419  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  420  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  422  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  423  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  424  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  425  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  427  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  428  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  429  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  430  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  432  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  433  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  434  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  435  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  437  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  438  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  439  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  440  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  442  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  443  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  444  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  445  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  447  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  448  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  449  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  450  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  452  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  453  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  454  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  455  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  457  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  458  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  459  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  460  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  462  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  463  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  464  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  465  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  467  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  468  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  469  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  470  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
 94%|█████████▍| 471/500 [15:03<01:17,  2.69s/it] 95%|█████████▍| 473/500 [15:03<00:51,  1.90s/it] 95%|█████████▌| 475/500 [15:09<00:57,  2.28s/it] 95%|█████████▌| 477/500 [15:09<00:37,  1.62s/it] 96%|█████████▌| 479/500 [15:10<00:24,  1.15s/it] 96%|█████████▌| 481/500 [15:22<00:51,  2.73s/it] 97%|█████████▋| 483/500 [15:22<00:32,  1.93s/it] 97%|█████████▋| 485/500 [15:29<00:34,  2.31s/it] 97%|█████████▋| 487/500 [15:29<00:21,  1.63s/it] 98%|█████████▊| 489/500 [15:29<00:12,  1.16s/it] 98%|█████████▊| 491/500 [15:42<00:24,  2.71s/it] 99%|█████████▊| 493/500 [15:42<00:13,  1.92s/it] 99%|█████████▉| 495/500 [15:48<00:11,  2.28s/it] 99%|█████████▉| 497/500 [15:48<00:04,  1.62s/it]100%|█████████▉| 499/500 [15:48<00:01,  1.15s/it]100%|██████████| 500/500 [15:55<00:00,  1.91s/it]
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  472  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  473  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  474  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  475  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  477  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  478  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  479  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  480  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  482  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  483  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  484  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  485  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  487  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  488  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  489  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  490  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  492  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  493  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  494  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648101449012756
Epoch:  495  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  497  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  498  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  499  	Training Loss: 0.039293888956308365
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
Epoch:  500  	Training Loss: 0.039293885231018066
Test Loss:  0.03553701937198639
Valid Loss:  0.032648105174303055
**************************************************learning rate decay**************************************************
seed is  2
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<54:30,  6.55s/it]  1%|          | 3/500 [00:06<14:30,  1.75s/it]  1%|          | 5/500 [00:06<07:18,  1.13it/s]  1%|▏         | 7/500 [00:06<04:25,  1.86it/s]  2%|▏         | 9/500 [00:07<02:56,  2.77it/s]  2%|▏         | 11/500 [00:13<11:01,  1.35s/it]  3%|▎         | 13/500 [00:13<07:31,  1.08it/s]  3%|▎         | 15/500 [00:13<05:14,  1.54it/s]  3%|▎         | 17/500 [00:13<03:45,  2.14it/s]  4%|▍         | 19/500 [00:14<02:44,  2.93it/s]  4%|▍         | 21/500 [00:20<09:36,  1.20s/it]  5%|▍         | 23/500 [00:20<06:49,  1.17it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:33,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:33<16:57,  2.17s/it]  7%|▋         | 33/500 [00:33<11:58,  1.54s/it]  7%|▋         | 35/500 [00:33<08:29,  1.10s/it]  7%|▋         | 37/500 [00:34<06:03,  1.27it/s]  8%|▊         | 39/500 [00:34<04:22,  1.76it/s]  8%|▊         | 41/500 [00:40<10:16,  1.34s/it]  9%|▊         | 43/500 [00:40<07:19,  1.04it/s]  9%|▉         | 45/500 [00:40<05:14,  1.45it/s]  9%|▉         | 47/500 [00:40<03:48,  1.99it/s] 10%|▉         | 49/500 [00:41<02:47,  2.69it/s] 10%|█         | 51/500 [00:47<08:52,  1.19s/it] 11%|█         | 53/500 [00:47<06:20,  1.17it/s] 11%|█         | 55/500 [00:47<04:33,  1.63it/s] 11%|█▏        | 57/500 [00:47<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:47<02:27,  2.99it/s] 12%|█▏        | 61/500 [00:54<08:42,  1.19s/it] 13%|█▎        | 63/500 [00:54<06:13,  1.17it/s] 13%|█▎        | 65/500 [01:00<11:07,  1.53s/it] 13%|█▎        | 67/500 [01:00<07:54,  1.10s/it]Epoch:  1  	Training Loss: 0.04927349090576172
Test Loss:  0.36469656229019165
Valid Loss:  0.3676890730857849
Epoch:  2  	Training Loss: 0.36162903904914856
Test Loss:  7.723728179931641
Valid Loss:  7.6846923828125
Epoch:  3  	Training Loss: 8.05038070678711
Test Loss:  0.18973733484745026
Valid Loss:  0.1926528811454773
Epoch:  4  	Training Loss: 0.17487414181232452
Test Loss:  0.18971797823905945
Valid Loss:  0.19262896478176117
Epoch:  5  	Training Loss: 0.17485377192497253
Test Loss:  0.18970884382724762
Valid Loss:  0.1926220953464508
Epoch:  6  	Training Loss: 0.17484523355960846
Test Loss:  0.18970130383968353
Valid Loss:  0.19261857867240906
Epoch:  7  	Training Loss: 0.1748388409614563
Test Loss:  0.1896943747997284
Valid Loss:  0.19261544942855835
Epoch:  8  	Training Loss: 0.17483316361904144
Test Loss:  0.18968802690505981
Valid Loss:  0.19261252880096436
Epoch:  9  	Training Loss: 0.1748281866312027
Test Loss:  0.18968242406845093
Valid Loss:  0.19260981678962708
Epoch:  10  	Training Loss: 0.17482370138168335
Test Loss:  0.18967701494693756
Valid Loss:  0.1926071047782898
Epoch:  11  	Training Loss: 0.17481914162635803
Test Loss:  0.18967178463935852
Valid Loss:  0.1926044076681137
Epoch:  12  	Training Loss: 0.1748146116733551
Test Loss:  0.10376450419425964
Valid Loss:  0.10038828104734421
Epoch:  13  	Training Loss: 0.12285757809877396
Test Loss:  0.036540739238262177
Valid Loss:  0.03681088238954544
Epoch:  14  	Training Loss: 0.033230915665626526
Test Loss:  0.009755387902259827
Valid Loss:  0.008639782667160034
Epoch:  15  	Training Loss: 0.013236574828624725
Test Loss:  0.008592715486884117
Valid Loss:  0.008169746957719326
Epoch:  16  	Training Loss: 0.007454564794898033
Test Loss:  0.0052985744550824165
Valid Loss:  0.004618529230356216
Epoch:  17  	Training Loss: 0.0060741794295609
Test Loss:  0.005880565382540226
Valid Loss:  0.005363352596759796
Epoch:  18  	Training Loss: 0.0056737326085567474
Test Loss:  0.005290853325277567
Valid Loss:  0.004729251377284527
Epoch:  19  	Training Loss: 0.0055039990693330765
Test Loss:  0.00540313683450222
Valid Loss:  0.004891212098300457
Epoch:  20  	Training Loss: 0.005392039660364389
Test Loss:  0.005222610663622618
Valid Loss:  0.004713447764515877
Epoch:  21  	Training Loss: 0.0052981507033109665
Test Loss:  0.005186744965612888
Valid Loss:  0.004700281657278538
Epoch:  22  	Training Loss: 0.005211502779275179
Test Loss:  0.003739631501957774
Valid Loss:  0.0032279363367706537
Epoch:  23  	Training Loss: 0.005090225487947464
Test Loss:  0.010518801398575306
Valid Loss:  0.01026974804699421
Epoch:  24  	Training Loss: 0.009269959293305874
Test Loss:  0.0075073884800076485
Valid Loss:  0.007123482413589954
Epoch:  25  	Training Loss: 0.009832270443439484
Test Loss:  0.021115880459547043
Valid Loss:  0.021146681159734726
Epoch:  26  	Training Loss: 0.017628807574510574
Test Loss:  0.004898708313703537
Valid Loss:  0.004523336887359619
Epoch:  27  	Training Loss: 0.005588890053331852
Test Loss:  0.0019929399713873863
Valid Loss:  0.001814217888750136
Epoch:  28  	Training Loss: 0.0033216369338333607
Test Loss:  0.0015071643283590674
Valid Loss:  0.0015128173399716616
Epoch:  29  	Training Loss: 0.0023119449615478516
Test Loss:  0.0011626456398516893
Valid Loss:  0.0012444957392290235
Epoch:  30  	Training Loss: 0.0019219348905608058
Test Loss:  0.001994685735553503
Valid Loss:  0.0021382784470915794
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.00239473395049572
Test Loss:  0.000724619603715837
Valid Loss:  0.000846928742248565
Epoch:  32  	Training Loss: 0.0011814840836450458
Test Loss:  0.0007092421874403954
Valid Loss:  0.0008464246056973934
Epoch:  33  	Training Loss: 0.0011340577621012926
Test Loss:  0.0006843106239102781
Valid Loss:  0.0008342730579897761
Epoch:  34  	Training Loss: 0.0010953668970614672
Test Loss:  0.0006540564354509115
Valid Loss:  0.0008155096438713372
Epoch:  35  	Training Loss: 0.0010565484408289194
Test Loss:  0.0006249191937968135
Valid Loss:  0.0007955252658575773
Epoch:  36  	Training Loss: 0.0010198066011071205
Test Loss:  0.0006012229714542627
Valid Loss:  0.0007796434802003205
Epoch:  37  	Training Loss: 0.0009889553766697645
Test Loss:  0.0005851901369169354
Valid Loss:  0.0007713004597462714
Epoch:  38  	Training Loss: 0.0009675244800746441
Test Loss:  0.0005739495391026139
Valid Loss:  0.0007674216758459806
Epoch:  39  	Training Loss: 0.0009505260968580842
Test Loss:  0.0005623195902444422
Valid Loss:  0.0007627457962371409
Epoch:  40  	Training Loss: 0.0009348609601147473
Test Loss:  0.0005504353903234005
Valid Loss:  0.0007573565235361457
Epoch:  41  	Training Loss: 0.0009202355286106467
Test Loss:  0.0005387474084272981
Valid Loss:  0.0007516868645325303
Epoch:  42  	Training Loss: 0.000906424829736352
Test Loss:  0.0005129960482008755
Valid Loss:  0.0007386658107861876
Epoch:  43  	Training Loss: 0.0008827359997667372
Test Loss:  0.0004997613141313195
Valid Loss:  0.0007369599188677967
Epoch:  44  	Training Loss: 0.0008647793438285589
Test Loss:  0.0004900391795672476
Valid Loss:  0.0007373603875748813
Epoch:  45  	Training Loss: 0.0008505660807713866
Test Loss:  0.0004827950906474143
Valid Loss:  0.0007390010869130492
Epoch:  46  	Training Loss: 0.0008392746094614267
Test Loss:  0.0004774279659613967
Valid Loss:  0.0007414277642965317
Epoch:  47  	Training Loss: 0.0008302637143060565
Test Loss:  0.00047346751671284437
Valid Loss:  0.000744311255402863
Epoch:  48  	Training Loss: 0.0008230301318690181
Test Loss:  0.00047056120820343494
Valid Loss:  0.0007474144222214818
Epoch:  49  	Training Loss: 0.0008171830559149384
Test Loss:  0.00046843758900649846
Valid Loss:  0.0007505674147978425
Epoch:  50  	Training Loss: 0.0008124181185849011
Test Loss:  0.00046689138980582356
Valid Loss:  0.0007536523626185954
Epoch:  51  	Training Loss: 0.0008084982400760055
Test Loss:  0.0004657722602132708
Valid Loss:  0.0007565909763798118
Epoch:  52  	Training Loss: 0.0008052377961575985
Test Loss:  0.00046888820361346006
Valid Loss:  0.0007647019810974598
Epoch:  53  	Training Loss: 0.0007998627843335271
Test Loss:  0.0004629061440937221
Valid Loss:  0.0007605463033542037
Epoch:  54  	Training Loss: 0.0007955337641760707
Test Loss:  0.0004688884655479342
Valid Loss:  0.0007712229853495955
Epoch:  55  	Training Loss: 0.0007923742523416877
Test Loss:  0.00046077900333330035
Valid Loss:  0.000763149349950254
Epoch:  56  	Training Loss: 0.0007901150383986533
Test Loss:  0.00047081729280762374
Valid Loss:  0.000778216402977705
Epoch:  57  	Training Loss: 0.0007885581580922008
Test Loss:  0.0004590233147609979
Valid Loss:  0.0007643805001862347
Epoch:  58  	Training Loss: 0.0007876374293118715
Test Loss:  0.0004756056296173483
Valid Loss:  0.00078721740283072
Epoch:  59  	Training Loss: 0.0007875969749875367
Test Loss:  0.0004583120462484658
Valid Loss:  0.0007651135674677789
Epoch:  60  	Training Loss: 0.0007887044921517372
Test Loss:  0.00048624956980347633
Valid Loss:  0.0008017875370569527
Epoch:  61  	Training Loss: 0.0007914375746622682
Test Loss:  0.00046164297964423895
Valid Loss:  0.0007682819850742817
Epoch:  62  	Training Loss: 0.0007967679994180799
Test Loss:  0.0004886286333203316
Valid Loss:  0.0008038865635171533
Epoch:  63  	Training Loss: 0.0007901889039203525
Test Loss:  0.00045044938451610506
Valid Loss:  0.0007612667977809906
Epoch:  64  	Training Loss: 0.000784318835940212
Test Loss:  0.00048059827531687915
Valid Loss:  0.0008018899825401604
Epoch:  65  	Training Loss: 0.0007791919633746147
Test Loss:  0.0004416131996549666
Valid Loss:  0.0007556406781077385
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.0007746490882709622
Test Loss:  0.00044599093962460756
Valid Loss:  0.0007750933291390538
Epoch:  67  	Training Loss: 0.0007515544421039522
Test Loss:  0.000433139008237049
Valid Loss:  0.0007567362627014518
Epoch:  68  	Training Loss: 0.0007480501662939787
Test Loss:  0.00043606077088043094
Valid Loss:  0.0007617071969434619
 14%|█▍        | 69/500 [01:00<05:38,  1.27it/s] 14%|█▍        | 71/500 [01:07<10:38,  1.49s/it] 15%|█▍        | 73/500 [01:07<07:33,  1.06s/it] 15%|█▌        | 75/500 [01:07<05:24,  1.31it/s] 15%|█▌        | 77/500 [01:07<03:54,  1.81it/s] 16%|█▌        | 79/500 [01:07<02:51,  2.45it/s] 16%|█▌        | 81/500 [01:13<08:35,  1.23s/it] 17%|█▋        | 83/500 [01:14<06:08,  1.13it/s] 17%|█▋        | 85/500 [01:14<04:24,  1.57it/s] 17%|█▋        | 87/500 [01:14<03:12,  2.14it/s] 18%|█▊        | 89/500 [01:14<02:22,  2.89it/s] 18%|█▊        | 91/500 [01:20<08:05,  1.19s/it] 19%|█▊        | 93/500 [01:20<05:46,  1.17it/s] 19%|█▉        | 95/500 [01:20<04:09,  1.62it/s] 19%|█▉        | 97/500 [01:21<03:01,  2.22it/s] 20%|█▉        | 99/500 [01:21<02:15,  2.97it/s] 20%|██        | 101/500 [01:27<07:45,  1.17s/it] 21%|██        | 103/500 [01:27<05:32,  1.19it/s] 21%|██        | 105/500 [01:27<03:59,  1.65it/s] 21%|██▏       | 107/500 [01:27<02:54,  2.25it/s] 22%|██▏       | 109/500 [01:27<02:08,  3.03it/s] 22%|██▏       | 111/500 [01:34<07:36,  1.17s/it] 23%|██▎       | 113/500 [01:34<05:26,  1.19it/s] 23%|██▎       | 115/500 [01:34<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:34<02:50,  2.24it/s] 24%|██▍       | 119/500 [01:34<02:07,  2.98it/s] 24%|██▍       | 121/500 [01:41<07:26,  1.18s/it] 25%|██▍       | 123/500 [01:41<05:18,  1.18it/s] 25%|██▌       | 125/500 [01:41<03:49,  1.64it/s] 25%|██▌       | 127/500 [01:41<02:46,  2.23it/s] 26%|██▌       | 129/500 [01:41<02:03,  3.01it/s] 26%|██▌       | 131/500 [01:47<07:10,  1.17s/it] 27%|██▋       | 133/500 [01:48<05:07,  1.19it/s] 27%|██▋       | 135/500 [01:48<03:40,  1.65it/s]Epoch:  69  	Training Loss: 0.0007472278084605932
Test Loss:  0.00043444783659651875
Valid Loss:  0.0007593395421281457
Epoch:  70  	Training Loss: 0.0007467735558748245
Test Loss:  0.000434685789514333
Valid Loss:  0.0007598558440804482
Epoch:  71  	Training Loss: 0.000746371631976217
Test Loss:  0.0004342637548688799
Valid Loss:  0.0007593273185193539
Epoch:  72  	Training Loss: 0.0007459771586582065
Test Loss:  0.0004283775924704969
Valid Loss:  0.000754116103053093
Epoch:  73  	Training Loss: 0.0007336362032219768
Test Loss:  0.00041839020559564233
Valid Loss:  0.0007453294238075614
Epoch:  74  	Training Loss: 0.000717497430741787
Test Loss:  0.0004080553480889648
Valid Loss:  0.0007354280678555369
Epoch:  75  	Training Loss: 0.0006996534648351371
Test Loss:  0.00039776222547516227
Valid Loss:  0.0007242035353556275
Epoch:  76  	Training Loss: 0.0006829050253145397
Test Loss:  0.0003890629159286618
Valid Loss:  0.0007151815807446837
Epoch:  77  	Training Loss: 0.0006687067216262221
Test Loss:  0.0003816432727035135
Valid Loss:  0.0007084916578605771
Epoch:  78  	Training Loss: 0.0006574081489816308
Test Loss:  0.00037546869134530425
Valid Loss:  0.0007032584398984909
Epoch:  79  	Training Loss: 0.0006482290336862206
Test Loss:  0.00037079647881910205
Valid Loss:  0.0006987734232097864
Epoch:  80  	Training Loss: 0.0006415346870198846
Test Loss:  0.0003672979073598981
Valid Loss:  0.0006943960324861109
Epoch:  81  	Training Loss: 0.0006371102062985301
Test Loss:  0.0003642475057858974
Valid Loss:  0.0006902830209583044
Epoch:  82  	Training Loss: 0.0006336183287203312
Test Loss:  0.0003629702841863036
Valid Loss:  0.000687524676322937
Epoch:  83  	Training Loss: 0.0006320688407868147
Test Loss:  0.0003616635804064572
Valid Loss:  0.000684820581227541
Epoch:  84  	Training Loss: 0.0006305682472884655
Test Loss:  0.0003603139484766871
Valid Loss:  0.0006822017603553832
Epoch:  85  	Training Loss: 0.0006290777819231153
Test Loss:  0.00035896431654691696
Valid Loss:  0.0006796754314564168
Epoch:  86  	Training Loss: 0.0006276060594245791
Test Loss:  0.0003576574963517487
Valid Loss:  0.0006772637716494501
Epoch:  87  	Training Loss: 0.00062617874937132
Test Loss:  0.0003564135986380279
Valid Loss:  0.0006749751046299934
Epoch:  88  	Training Loss: 0.0006248304853215814
Test Loss:  0.0003553004644345492
Valid Loss:  0.0006728339940309525
Epoch:  89  	Training Loss: 0.0006235939217731357
Test Loss:  0.00035429306444711983
Valid Loss:  0.0006708640139549971
Epoch:  90  	Training Loss: 0.0006225442048162222
Test Loss:  0.0003534047573339194
Valid Loss:  0.0006690877489745617
Epoch:  91  	Training Loss: 0.0006217062473297119
Test Loss:  0.0003526562941260636
Valid Loss:  0.0006674629403278232
Epoch:  92  	Training Loss: 0.0006209684652276337
Test Loss:  0.000351178168784827
Valid Loss:  0.0006649086717516184
Epoch:  93  	Training Loss: 0.0006203129305504262
Test Loss:  0.0003506719949655235
Valid Loss:  0.0006637714104726911
Epoch:  94  	Training Loss: 0.0006197295151650906
Test Loss:  0.00035008901613764465
Valid Loss:  0.0006625442765653133
Epoch:  95  	Training Loss: 0.0006191607099026442
Test Loss:  0.00034953997237607837
Valid Loss:  0.0006613873410969973
Epoch:  96  	Training Loss: 0.0006186043610796332
Test Loss:  0.00034900917671620846
Valid Loss:  0.0006602784851565957
Epoch:  97  	Training Loss: 0.0006180593627505004
Test Loss:  0.00034849741496145725
Valid Loss:  0.0006592166610062122
Epoch:  98  	Training Loss: 0.0006175244343467057
Test Loss:  0.00034800279536284506
Valid Loss:  0.000658198376186192
Epoch:  99  	Training Loss: 0.000616998877376318
Test Loss:  0.00034752272767946124
Valid Loss:  0.000657219672575593
Epoch:  100  	Training Loss: 0.0006164810620248318
Test Loss:  0.00034705715370364487
Valid Loss:  0.0006562802009284496
Epoch:  101  	Training Loss: 0.0006159713957458735
Test Loss:  0.00034660607343539596
Valid Loss:  0.000655375886708498
Epoch:  102  	Training Loss: 0.0006154727307148278
Test Loss:  0.0003399995912332088
Valid Loss:  0.0006482976605184376
Epoch:  103  	Training Loss: 0.0006058780127204955
Test Loss:  0.000332967727445066
Valid Loss:  0.0006410988280549645
Epoch:  104  	Training Loss: 0.000595425721257925
Test Loss:  0.0003247078275308013
Valid Loss:  0.0006334329955279827
Epoch:  105  	Training Loss: 0.0005825816188007593
Test Loss:  0.00031661477987654507
Valid Loss:  0.0006256257183849812
Epoch:  106  	Training Loss: 0.0005698450841009617
Test Loss:  0.00030884117586538196
Valid Loss:  0.0006172168650664389
Epoch:  107  	Training Loss: 0.0005574335809797049
Test Loss:  0.0003011601511389017
Valid Loss:  0.0006087649962864816
Epoch:  108  	Training Loss: 0.0005444413400255144
Test Loss:  0.00029384143999777734
Valid Loss:  0.0005998382112011313
Epoch:  109  	Training Loss: 0.0005318587063811719
Test Loss:  0.00028631550958380103
Valid Loss:  0.0005909634055569768
Epoch:  110  	Training Loss: 0.0005194384139031172
Test Loss:  0.0002779402129817754
Valid Loss:  0.0005823587998747826
Epoch:  111  	Training Loss: 0.0005078425165265799
Test Loss:  0.00027009460609406233
Valid Loss:  0.0005741320783272386
Epoch:  112  	Training Loss: 0.0004969988949596882
Test Loss:  0.00026723428163677454
Valid Loss:  0.0005707741947844625
Epoch:  113  	Training Loss: 0.0004942669183947146
Test Loss:  0.0002658995217643678
Valid Loss:  0.0005704221548512578
Epoch:  114  	Training Loss: 0.0004919191705994308
Test Loss:  0.0002638075384311378
Valid Loss:  0.0005679959431290627
Epoch:  115  	Training Loss: 0.0004900036728940904
Test Loss:  0.00026271308888681233
Valid Loss:  0.0005668889498338103
Epoch:  116  	Training Loss: 0.0004885441157966852
Test Loss:  0.0002614714321680367
Valid Loss:  0.0005648825317621231
Epoch:  117  	Training Loss: 0.0004872741410508752
Test Loss:  0.00026078004157170653
Valid Loss:  0.000563484791200608
Epoch:  118  	Training Loss: 0.00048618484288454056
Test Loss:  0.0002599863219074905
Valid Loss:  0.0005616906564682722
Epoch:  119  	Training Loss: 0.0004851659759879112
Test Loss:  0.00025938943144865334
Valid Loss:  0.0005602128803730011
Epoch:  120  	Training Loss: 0.0004842241760343313
Test Loss:  0.00025869288947433233
Valid Loss:  0.0005584934260696173
Epoch:  121  	Training Loss: 0.0004833528073504567
Test Loss:  0.0002581261214800179
Valid Loss:  0.0005570538341999054
Epoch:  122  	Training Loss: 0.00048250213149003685
Test Loss:  0.0002524488081689924
Valid Loss:  0.0005516617093235254
Epoch:  123  	Training Loss: 0.00047313745017163455
Test Loss:  0.00024664922966621816
Valid Loss:  0.000545441173017025
Epoch:  124  	Training Loss: 0.00046437064884230494
Test Loss:  0.00024097612185869366
Valid Loss:  0.0005392972379922867
Epoch:  125  	Training Loss: 0.00045525230234488845
Test Loss:  0.0002356133481953293
Valid Loss:  0.0005332425935193896
Epoch:  126  	Training Loss: 0.0004467551480047405
Test Loss:  0.00023067384609021246
Valid Loss:  0.0005272339913062751
Epoch:  127  	Training Loss: 0.0004388735396787524
Test Loss:  0.00022603418619837612
Valid Loss:  0.0005210258532315493
Epoch:  128  	Training Loss: 0.0004312789242248982
Test Loss:  0.00022170241572894156
Valid Loss:  0.0005150469369255006
Epoch:  129  	Training Loss: 0.0004240923444740474
Test Loss:  0.000217636683373712
Valid Loss:  0.0005092758219689131
Epoch:  130  	Training Loss: 0.0004171699983999133
Test Loss:  0.0002137871051672846
Valid Loss:  0.0005036548245698214
Epoch:  131  	Training Loss: 0.00041045586112886667
Test Loss:  0.00021002355788368732
Valid Loss:  0.0004982630489394069
Epoch:  132  	Training Loss: 0.0004041477513965219
Test Loss:  0.00020465227134991437
Valid Loss:  0.0004873118014074862
Epoch:  133  	Training Loss: 0.00039840274257585406
Test Loss:  0.00020066436263732612
Valid Loss:  0.00048057560343295336
Epoch:  134  	Training Loss: 0.00039357581408694386
Test Loss:  0.0001985649869311601
Valid Loss:  0.00047468708362430334
Epoch:  135  	Training Loss: 0.0003897970891557634
Test Loss:  0.0001972686150111258
Valid Loss:  0.0004704343737103045
Epoch:  136  	Training Loss: 0.0003868800413329154
Test Loss:  0.00019629995222203434
Valid Loss:  0.00046715204371139407
 27%|██▋       | 137/500 [01:48<02:40,  2.26it/s] 28%|██▊       | 139/500 [01:48<01:59,  3.03it/s] 28%|██▊       | 141/500 [01:54<06:57,  1.16s/it] 29%|██▊       | 143/500 [01:54<04:58,  1.20it/s] 29%|██▉       | 145/500 [01:54<03:34,  1.65it/s] 29%|██▉       | 147/500 [01:55<02:36,  2.26it/s] 30%|██▉       | 149/500 [01:55<01:55,  3.04it/s] 30%|███       | 151/500 [02:01<06:44,  1.16s/it] 31%|███       | 153/500 [02:01<04:48,  1.20it/s] 31%|███       | 155/500 [02:01<03:27,  1.66it/s] 31%|███▏      | 157/500 [02:01<02:31,  2.27it/s] 32%|███▏      | 159/500 [02:01<01:51,  3.05it/s] 32%|███▏      | 161/500 [02:08<06:33,  1.16s/it] 33%|███▎      | 163/500 [02:08<04:40,  1.20it/s] 33%|███▎      | 165/500 [02:08<03:22,  1.66it/s] 33%|███▎      | 167/500 [02:08<02:27,  2.26it/s] 34%|███▍      | 169/500 [02:08<01:48,  3.04it/s] 34%|███▍      | 171/500 [02:14<06:21,  1.16s/it] 35%|███▍      | 173/500 [02:14<04:32,  1.20it/s] 35%|███▌      | 175/500 [02:15<03:16,  1.66it/s] 35%|███▌      | 177/500 [02:15<02:22,  2.26it/s] 36%|███▌      | 179/500 [02:15<01:45,  3.04it/s] 36%|███▌      | 181/500 [02:21<06:11,  1.16s/it] 37%|███▋      | 183/500 [02:21<04:25,  1.20it/s] 37%|███▋      | 185/500 [02:21<03:10,  1.65it/s] 37%|███▋      | 187/500 [02:21<02:18,  2.26it/s] 38%|███▊      | 189/500 [02:22<01:42,  3.03it/s] 38%|███▊      | 191/500 [02:28<05:59,  1.16s/it] 39%|███▊      | 193/500 [02:28<04:16,  1.20it/s] 39%|███▉      | 195/500 [02:28<03:04,  1.65it/s] 39%|███▉      | 197/500 [02:28<02:14,  2.25it/s] 40%|███▉      | 199/500 [02:28<01:39,  3.02it/s] 40%|████      | 201/500 [02:35<05:47,  1.16s/it] 41%|████      | 203/500 [02:35<04:07,  1.20it/s]Epoch:  137  	Training Loss: 0.0003845853207167238
Test Loss:  0.0001956153428182006
Valid Loss:  0.00046528270468115807
Epoch:  138  	Training Loss: 0.0003830085042864084
Test Loss:  0.00019497863831929862
Valid Loss:  0.00046364852460101247
Epoch:  139  	Training Loss: 0.00038165299338288605
Test Loss:  0.00019438542949501425
Valid Loss:  0.0004624950815923512
Epoch:  140  	Training Loss: 0.00038061474333517253
Test Loss:  0.00019390460511203855
Valid Loss:  0.00046184685197658837
Epoch:  141  	Training Loss: 0.0003797932877205312
Test Loss:  0.00019332286319695413
Valid Loss:  0.0004605477151926607
Epoch:  142  	Training Loss: 0.0003790202899836004
Test Loss:  0.00019315359531901777
Valid Loss:  0.0004585182759910822
Epoch:  143  	Training Loss: 0.00037814618553966284
Test Loss:  0.00019314927340019494
Valid Loss:  0.00045719745685346425
Epoch:  144  	Training Loss: 0.0003776832891162485
Test Loss:  0.0001931202714331448
Valid Loss:  0.00045613772817887366
Epoch:  145  	Training Loss: 0.00037733541103079915
Test Loss:  0.00019306196190882474
Valid Loss:  0.00045520742423832417
Epoch:  146  	Training Loss: 0.0003770338371396065
Test Loss:  0.000192989144125022
Valid Loss:  0.0004543643444776535
Epoch:  147  	Training Loss: 0.0003767599118873477
Test Loss:  0.00019291482749395072
Valid Loss:  0.000453589775133878
Epoch:  148  	Training Loss: 0.0003765089495573193
Test Loss:  0.00019284337759017944
Valid Loss:  0.00045287306420505047
Epoch:  149  	Training Loss: 0.00037627542042173445
Test Loss:  0.00019277670071460307
Valid Loss:  0.00045220673200674355
Epoch:  150  	Training Loss: 0.00037605769466608763
Test Loss:  0.00019271601922810078
Valid Loss:  0.0004515869077295065
Epoch:  151  	Training Loss: 0.0003758530947379768
Test Loss:  0.00019266024173703045
Valid Loss:  0.00045100817806087434
Epoch:  152  	Training Loss: 0.0003756600199267268
Test Loss:  0.00019236413936596364
Valid Loss:  0.0004500871291384101
Epoch:  153  	Training Loss: 0.00037552102003246546
Test Loss:  0.00019230588804930449
Valid Loss:  0.0004496817709878087
Epoch:  154  	Training Loss: 0.0003754625213332474
Test Loss:  0.00019229642930440605
Valid Loss:  0.0004494043823797256
Epoch:  155  	Training Loss: 0.0003754118224605918
Test Loss:  0.00019229920872021466
Valid Loss:  0.0004491664585657418
Epoch:  156  	Training Loss: 0.00037536403397098184
Test Loss:  0.00019230559701099992
Valid Loss:  0.0004489467537496239
Epoch:  157  	Training Loss: 0.00037531793350353837
Test Loss:  0.00019231330952607095
Valid Loss:  0.00044873752631247044
Epoch:  158  	Training Loss: 0.00037527410313487053
Test Loss:  0.000192321342183277
Valid Loss:  0.00044853700092062354
Epoch:  159  	Training Loss: 0.00037523225182667375
Test Loss:  0.00019233007333241403
Valid Loss:  0.00044834509026259184
Epoch:  160  	Training Loss: 0.00037519194302149117
Test Loss:  0.00019233865896239877
Valid Loss:  0.00044816109584644437
Epoch:  161  	Training Loss: 0.00037515329313464463
Test Loss:  0.00019234721548855305
Valid Loss:  0.0004479840281419456
Epoch:  162  	Training Loss: 0.00037511621485464275
Test Loss:  0.00019195866480004042
Valid Loss:  0.0004474380984902382
Epoch:  163  	Training Loss: 0.00037474092096090317
Test Loss:  0.00019171522581018507
Valid Loss:  0.0004473595763556659
Epoch:  164  	Training Loss: 0.00037437473656609654
Test Loss:  0.00019140500808134675
Valid Loss:  0.0004470359708648175
Epoch:  165  	Training Loss: 0.0003740162355825305
Test Loss:  0.0001911424333229661
Valid Loss:  0.00044685666216537356
Epoch:  166  	Training Loss: 0.0003736650396604091
Test Loss:  0.00019086472457274795
Valid Loss:  0.0004466066020540893
Epoch:  167  	Training Loss: 0.0003733207122422755
Test Loss:  0.00019060549675486982
Valid Loss:  0.00044640578562393785
Epoch:  168  	Training Loss: 0.00037298345705494285
Test Loss:  0.00019034603610634804
Valid Loss:  0.00044618637184612453
Epoch:  169  	Training Loss: 0.00037265289574861526
Test Loss:  0.00019009658717550337
Valid Loss:  0.000445984594989568
Epoch:  170  	Training Loss: 0.00037232862086966634
Test Loss:  0.0001898510381579399
Valid Loss:  0.0004457815957721323
Epoch:  171  	Training Loss: 0.00037201051600277424
Test Loss:  0.00018961273599416018
Valid Loss:  0.0004455879970919341
Epoch:  172  	Training Loss: 0.00037169919232837856
Test Loss:  0.00018965080380439758
Valid Loss:  0.0004454792069736868
Epoch:  173  	Training Loss: 0.0003715471248142421
Test Loss:  0.00018963028560392559
Valid Loss:  0.00044527038699015975
Epoch:  174  	Training Loss: 0.00037140195490792394
Test Loss:  0.0001896038738777861
Valid Loss:  0.0004450622946023941
Epoch:  175  	Training Loss: 0.0003712592297233641
Test Loss:  0.000189575512195006
Valid Loss:  0.0004448643885552883
Epoch:  176  	Training Loss: 0.000371117377653718
Test Loss:  0.00018954614643007517
Valid Loss:  0.00044467573752626777
Epoch:  177  	Training Loss: 0.00037097680615261197
Test Loss:  0.0001895161549327895
Valid Loss:  0.0004444953228812665
Epoch:  178  	Training Loss: 0.0003708374279085547
Test Loss:  0.00018948504293803126
Valid Loss:  0.0004443222424015403
Epoch:  179  	Training Loss: 0.00037069845711812377
Test Loss:  0.00018945266492664814
Valid Loss:  0.0004441560886334628
Epoch:  180  	Training Loss: 0.00037056018481962383
Test Loss:  0.00018941947200801224
Valid Loss:  0.00044399662874639034
Epoch:  181  	Training Loss: 0.00037042255280539393
Test Loss:  0.00018938520224764943
Valid Loss:  0.000443843484390527
Epoch:  182  	Training Loss: 0.0003702862886711955
Test Loss:  0.00018568783707451075
Valid Loss:  0.0004404970968607813
Epoch:  183  	Training Loss: 0.00036351376911625266
Test Loss:  0.0001823765051085502
Valid Loss:  0.00043736008228734136
Epoch:  184  	Training Loss: 0.00035768671659752727
Test Loss:  0.00017932045739144087
Valid Loss:  0.0004342737083788961
Epoch:  185  	Training Loss: 0.00035256065893918276
Test Loss:  0.00017634316463954747
Valid Loss:  0.0004314230172894895
Epoch:  186  	Training Loss: 0.0003480157465673983
Test Loss:  0.00017368959379382432
Valid Loss:  0.0004287671181373298
Epoch:  187  	Training Loss: 0.0003439619904384017
Test Loss:  0.00017136105452664196
Valid Loss:  0.0004262982401996851
Epoch:  188  	Training Loss: 0.00034033850533887744
Test Loss:  0.00016912483260966837
Valid Loss:  0.0004239642294123769
Epoch:  189  	Training Loss: 0.00033701438223943114
Test Loss:  0.00016701570712029934
Valid Loss:  0.0004217270470689982
Epoch:  190  	Training Loss: 0.0003339175309520215
Test Loss:  0.00016506071551702917
Valid Loss:  0.0004196036315988749
Epoch:  191  	Training Loss: 0.0003311126201879233
Test Loss:  0.0001631148043088615
Valid Loss:  0.0004175776557531208
Epoch:  192  	Training Loss: 0.00032854173332452774
Test Loss:  0.00016199477249756455
Valid Loss:  0.00041373216663487256
Epoch:  193  	Training Loss: 0.00032681383891031146
Test Loss:  0.00016133197641465813
Valid Loss:  0.00041267936467193067
Epoch:  194  	Training Loss: 0.000325762783177197
Test Loss:  0.0001608516031410545
Valid Loss:  0.00041093394975177944
Epoch:  195  	Training Loss: 0.0003248354187235236
Test Loss:  0.00016041443450376391
Valid Loss:  0.0004095410695299506
Epoch:  196  	Training Loss: 0.00032396067399531603
Test Loss:  0.00016000951291061938
Valid Loss:  0.00040807592449709773
Epoch:  197  	Training Loss: 0.00032313723932020366
Test Loss:  0.00015961367171257734
Valid Loss:  0.00040669614099897444
Epoch:  198  	Training Loss: 0.00032233085948973894
Test Loss:  0.00015923575847409666
Valid Loss:  0.00040534132858738303
Epoch:  199  	Training Loss: 0.0003215640317648649
Test Loss:  0.00015888159396126866
Valid Loss:  0.00040404999163001776
Epoch:  200  	Training Loss: 0.00032083981204777956
Test Loss:  0.00015853869263082743
Valid Loss:  0.00040279567474499345
Epoch:  201  	Training Loss: 0.00032012973679229617
Test Loss:  0.00015822923160158098
Valid Loss:  0.00040156481554731727
Epoch:  202  	Training Loss: 0.0003194345044903457
Test Loss:  0.00015823105059098452
Valid Loss:  0.0004006447270512581
Epoch:  203  	Training Loss: 0.0003190365678165108
Test Loss:  0.00015827945026103407
Valid Loss:  0.00039989137439988554
 41%|████      | 205/500 [02:35<02:57,  1.66it/s] 41%|████▏     | 207/500 [02:35<02:09,  2.26it/s] 42%|████▏     | 209/500 [02:35<01:35,  3.04it/s] 42%|████▏     | 211/500 [02:41<05:39,  1.17s/it] 43%|████▎     | 213/500 [02:42<04:02,  1.18it/s] 43%|████▎     | 215/500 [02:42<02:54,  1.64it/s] 43%|████▎     | 217/500 [02:42<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:42<01:33,  3.01it/s] 44%|████▍     | 221/500 [02:48<05:25,  1.17s/it] 45%|████▍     | 223/500 [02:48<03:52,  1.19it/s] 45%|████▌     | 225/500 [02:48<02:46,  1.65it/s] 45%|████▌     | 227/500 [02:49<02:01,  2.24it/s] 46%|████▌     | 229/500 [02:49<01:29,  3.02it/s] 46%|████▌     | 231/500 [02:55<05:11,  1.16s/it] 47%|████▋     | 233/500 [02:55<03:42,  1.20it/s] 47%|████▋     | 235/500 [02:55<02:39,  1.66it/s] 47%|████▋     | 237/500 [02:55<01:55,  2.27it/s] 48%|████▊     | 239/500 [02:55<01:25,  3.05it/s] 48%|████▊     | 241/500 [03:02<05:02,  1.17s/it] 49%|████▊     | 243/500 [03:02<03:35,  1.19it/s] 49%|████▉     | 245/500 [03:02<02:35,  1.64it/s] 49%|████▉     | 247/500 [03:02<01:52,  2.25it/s] 50%|████▉     | 249/500 [03:02<01:23,  3.02it/s] 50%|█████     | 251/500 [03:08<04:50,  1.17s/it] 51%|█████     | 253/500 [03:09<03:27,  1.19it/s] 51%|█████     | 255/500 [03:09<02:28,  1.65it/s] 51%|█████▏    | 257/500 [03:09<01:47,  2.25it/s] 52%|█████▏    | 259/500 [03:09<01:19,  3.03it/s] 52%|█████▏    | 261/500 [03:15<04:38,  1.16s/it] 53%|█████▎    | 263/500 [03:15<03:18,  1.20it/s] 53%|█████▎    | 265/500 [03:15<02:22,  1.65it/s] 53%|█████▎    | 267/500 [03:16<01:43,  2.26it/s] 54%|█████▍    | 269/500 [03:16<01:16,  3.04it/s]Epoch:  204  	Training Loss: 0.0003187381662428379
Test Loss:  0.000158344249939546
Valid Loss:  0.0003992461715824902
Epoch:  205  	Training Loss: 0.0003184995148330927
Test Loss:  0.00015841034473851323
Valid Loss:  0.00039867416489869356
Epoch:  206  	Training Loss: 0.000318298174533993
Test Loss:  0.00015847309259697795
Valid Loss:  0.00039815524360165
Epoch:  207  	Training Loss: 0.0003181225620210171
Test Loss:  0.00015853106742724776
Valid Loss:  0.0003976767184212804
Epoch:  208  	Training Loss: 0.00031796505209058523
Test Loss:  0.0001585839199833572
Valid Loss:  0.0003972301201429218
Epoch:  209  	Training Loss: 0.0003178218612447381
Test Loss:  0.00015863269800320268
Valid Loss:  0.00039681169437244534
Epoch:  210  	Training Loss: 0.0003176912141498178
Test Loss:  0.00015867917682044208
Valid Loss:  0.0003964164643548429
Epoch:  211  	Training Loss: 0.000317570345941931
Test Loss:  0.00015872353105805814
Valid Loss:  0.000396041723433882
Epoch:  212  	Training Loss: 0.0003174580924678594
Test Loss:  0.00015849537157919258
Valid Loss:  0.00039529561763629317
Epoch:  213  	Training Loss: 0.00031717814272269607
Test Loss:  0.00015841783897485584
Valid Loss:  0.00039484555600211024
Epoch:  214  	Training Loss: 0.0003170223208144307
Test Loss:  0.00015838937542866915
Valid Loss:  0.0003945203498005867
Epoch:  215  	Training Loss: 0.0003168979601468891
Test Loss:  0.00015837952378205955
Valid Loss:  0.00039425567956641316
Epoch:  216  	Training Loss: 0.00031678462983109057
Test Loss:  0.0001583779521752149
Valid Loss:  0.00039402261609211564
Epoch:  217  	Training Loss: 0.00031667680013924837
Test Loss:  0.00015838394756428897
Valid Loss:  0.00039381012902595103
Epoch:  218  	Training Loss: 0.0003165727248415351
Test Loss:  0.00015839526895433664
Valid Loss:  0.0003936104476451874
Epoch:  219  	Training Loss: 0.00031647353898733854
Test Loss:  0.00015840830747038126
Valid Loss:  0.0003934212727472186
Epoch:  220  	Training Loss: 0.0003163826768286526
Test Loss:  0.00015842297580093145
Valid Loss:  0.00039324030512943864
Epoch:  221  	Training Loss: 0.000316294957883656
Test Loss:  0.00015843872097320855
Valid Loss:  0.00039306707913056016
Epoch:  222  	Training Loss: 0.0003162100329063833
Test Loss:  0.00015489400539081544
Valid Loss:  0.00039090606151148677
Epoch:  223  	Training Loss: 0.0003118015010841191
Test Loss:  0.00015151017578318715
Valid Loss:  0.00038754919660277665
Epoch:  224  	Training Loss: 0.0003079194575548172
Test Loss:  0.00014885253040120006
Valid Loss:  0.00038594496436417103
Epoch:  225  	Training Loss: 0.000304617453366518
Test Loss:  0.0001464716624468565
Valid Loss:  0.00038350082468241453
Epoch:  226  	Training Loss: 0.00030173308914527297
Test Loss:  0.0001445054222131148
Valid Loss:  0.0003822921426035464
Epoch:  227  	Training Loss: 0.00029922713292762637
Test Loss:  0.00014265818754211068
Valid Loss:  0.00038045906694605947
Epoch:  228  	Training Loss: 0.00029699719743803144
Test Loss:  0.0001411150151398033
Valid Loss:  0.0003794582444243133
Epoch:  229  	Training Loss: 0.0002950031775981188
Test Loss:  0.00013968380517326295
Valid Loss:  0.0003780202241614461
Epoch:  230  	Training Loss: 0.000293122255243361
Test Loss:  0.0001384586066706106
Valid Loss:  0.00037709681782871485
Epoch:  231  	Training Loss: 0.0002914510841947049
Test Loss:  0.0001373747072648257
Valid Loss:  0.0003759831888601184
Epoch:  232  	Training Loss: 0.0002899529645219445
Test Loss:  0.00013668998144567013
Valid Loss:  0.00037278042873367667
Epoch:  233  	Training Loss: 0.000288138457108289
Test Loss:  0.00013633625349029899
Valid Loss:  0.00037052767584100366
Epoch:  234  	Training Loss: 0.0002869069576263428
Test Loss:  0.00013605284038931131
Valid Loss:  0.0003685958217829466
Epoch:  235  	Training Loss: 0.0002858564257621765
Test Loss:  0.00013582693645730615
Valid Loss:  0.0003668744466267526
Epoch:  236  	Training Loss: 0.00028492958517745137
Test Loss:  0.00013564422260969877
Valid Loss:  0.0003653153544291854
Epoch:  237  	Training Loss: 0.00028409576043486595
Test Loss:  0.00013549134018830955
Valid Loss:  0.0003638851339928806
Epoch:  238  	Training Loss: 0.0002833340840879828
Test Loss:  0.00013535661855712533
Valid Loss:  0.0003625594836194068
Epoch:  239  	Training Loss: 0.00028262706473469734
Test Loss:  0.00013523161760531366
Valid Loss:  0.0003613191074691713
Epoch:  240  	Training Loss: 0.00028196300263516605
Test Loss:  0.00013511092402040958
Valid Loss:  0.0003601479693315923
Epoch:  241  	Training Loss: 0.0002813320606946945
Test Loss:  0.00013499183114618063
Valid Loss:  0.0003590332926250994
Epoch:  242  	Training Loss: 0.0002807283599395305
Test Loss:  0.0001339881564490497
Valid Loss:  0.00035737871075980365
Epoch:  243  	Training Loss: 0.0002786223776638508
Test Loss:  0.00013296271208673716
Valid Loss:  0.00035592541098594666
Epoch:  244  	Training Loss: 0.00027679401682689786
Test Loss:  0.00013195167412050068
Valid Loss:  0.0003545383515302092
Epoch:  245  	Training Loss: 0.0002751288120634854
Test Loss:  0.00013098739145789295
Valid Loss:  0.00035316188586875796
Epoch:  246  	Training Loss: 0.0002735746675170958
Test Loss:  0.00013008360110688955
Valid Loss:  0.00035178958205506206
Epoch:  247  	Training Loss: 0.000272107106866315
Test Loss:  0.00012924245675094426
Valid Loss:  0.0003504528431221843
Epoch:  248  	Training Loss: 0.00027070025680586696
Test Loss:  0.000128447194583714
Valid Loss:  0.0003491398529149592
Epoch:  249  	Training Loss: 0.00026932990294881165
Test Loss:  0.00012769356544595212
Valid Loss:  0.00034785058232955635
Epoch:  250  	Training Loss: 0.0002679844619706273
Test Loss:  0.00012697730562649667
Valid Loss:  0.0003465845074970275
Epoch:  251  	Training Loss: 0.00026666512712836266
Test Loss:  0.00012630416313186288
Valid Loss:  0.00034534992300905287
Epoch:  252  	Training Loss: 0.00026539701502770185
Test Loss:  0.0001253165683010593
Valid Loss:  0.00034381909063085914
Epoch:  253  	Training Loss: 0.00026388067635707557
Test Loss:  0.00012458415585570037
Valid Loss:  0.0003423146845307201
Epoch:  254  	Training Loss: 0.00026244777836836874
Test Loss:  0.00012394858640618622
Valid Loss:  0.00034085888182744384
Epoch:  255  	Training Loss: 0.0002610721276141703
Test Loss:  0.00012336578220129013
Valid Loss:  0.0003394158266019076
Epoch:  256  	Training Loss: 0.00025974909658543766
Test Loss:  0.00012282218085601926
Valid Loss:  0.000338012701831758
Epoch:  257  	Training Loss: 0.00025847574579529464
Test Loss:  0.00012231219443492591
Valid Loss:  0.000336669385433197
Epoch:  258  	Training Loss: 0.0002572381927166134
Test Loss:  0.00012182279897388071
Valid Loss:  0.0003353290376253426
Epoch:  259  	Training Loss: 0.00025602831738069654
Test Loss:  0.00012136049917899072
Valid Loss:  0.00033395946957170963
Epoch:  260  	Training Loss: 0.000254862941801548
Test Loss:  0.00012092660472262651
Valid Loss:  0.00033264048397541046
Epoch:  261  	Training Loss: 0.00025374116376042366
Test Loss:  0.00012052039528498426
Valid Loss:  0.0003313498746138066
Epoch:  262  	Training Loss: 0.0002526607713662088
Test Loss:  0.00011963708675466478
Valid Loss:  0.00033030458143912256
Epoch:  263  	Training Loss: 0.00025182237732224166
Test Loss:  0.00011895505303982645
Valid Loss:  0.00032929008011706173
Epoch:  264  	Training Loss: 0.0002510489139240235
Test Loss:  0.00011835373879875988
Valid Loss:  0.00032830098643898964
Epoch:  265  	Training Loss: 0.00025030988035723567
Test Loss:  0.00011780258500948548
Valid Loss:  0.0003273379697930068
Epoch:  266  	Training Loss: 0.0002495989319868386
Test Loss:  0.00011729000834748149
Valid Loss:  0.0003263976832386106
Epoch:  267  	Training Loss: 0.0002489119360689074
Test Loss:  0.00011681053729262203
Valid Loss:  0.00032547733280807734
Epoch:  268  	Training Loss: 0.00024824534193612635
Test Loss:  0.0001163585766335018
Valid Loss:  0.00032457392080686986
Epoch:  269  	Training Loss: 0.0002475963265169412
Test Loss:  0.00011593147064559162
Valid Loss:  0.00032368581742048264
Epoch:  270  	Training Loss: 0.00024696270702406764
Test Loss:  0.000115526097943075
Valid Loss:  0.0003228111600037664
Epoch:  271  	Training Loss: 0.00024634302826598287
 54%|█████▍    | 271/500 [03:22<04:25,  1.16s/it] 55%|█████▍    | 273/500 [03:22<03:09,  1.20it/s] 55%|█████▌    | 275/500 [03:22<02:15,  1.66it/s] 55%|█████▌    | 277/500 [03:22<01:38,  2.27it/s] 56%|█████▌    | 279/500 [03:22<01:12,  3.05it/s] 56%|█████▌    | 281/500 [03:29<04:16,  1.17s/it] 57%|█████▋    | 283/500 [03:29<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:29<02:10,  1.64it/s] 57%|█████▋    | 287/500 [03:29<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:29<01:09,  3.02it/s] 58%|█████▊    | 291/500 [03:35<04:02,  1.16s/it] 59%|█████▊    | 293/500 [03:36<02:52,  1.20it/s] 59%|█████▉    | 295/500 [03:36<02:03,  1.66it/s] 59%|█████▉    | 297/500 [03:36<01:29,  2.26it/s] 60%|█████▉    | 299/500 [03:36<01:06,  3.04it/s] 60%|██████    | 301/500 [03:42<03:51,  1.16s/it] 61%|██████    | 303/500 [03:42<02:44,  1.20it/s] 61%|██████    | 305/500 [03:42<01:57,  1.66it/s] 61%|██████▏   | 307/500 [03:43<01:25,  2.26it/s] 62%|██████▏   | 309/500 [03:43<01:02,  3.04it/s] 62%|██████▏   | 311/500 [03:49<03:40,  1.17s/it] 63%|██████▎   | 313/500 [03:49<02:36,  1.19it/s] 63%|██████▎   | 315/500 [03:49<01:52,  1.65it/s] 63%|██████▎   | 317/500 [03:49<01:21,  2.25it/s] 64%|██████▍   | 319/500 [03:50<00:59,  3.03it/s] 64%|██████▍   | 321/500 [03:56<03:28,  1.16s/it] 65%|██████▍   | 323/500 [03:56<02:27,  1.20it/s] 65%|██████▌   | 325/500 [03:56<01:45,  1.66it/s] 65%|██████▌   | 327/500 [03:56<01:16,  2.26it/s] 66%|██████▌   | 329/500 [03:56<00:56,  3.04it/s] 66%|██████▌   | 331/500 [04:03<03:17,  1.17s/it] 67%|██████▋   | 333/500 [04:03<02:20,  1.19it/s] 67%|██████▋   | 335/500 [04:03<01:40,  1.65it/s] 67%|██████▋   | 337/500 [04:03<01:12,  2.25it/s]Test Loss:  0.00011513916251715273
Valid Loss:  0.0003219495411030948
Epoch:  272  	Training Loss: 0.0002457354567013681
Test Loss:  0.00011497238301672041
Valid Loss:  0.00032158842077478766
Epoch:  273  	Training Loss: 0.0002454826608300209
Test Loss:  0.00011488518794067204
Valid Loss:  0.00032124953577294946
Epoch:  274  	Training Loss: 0.0002452654589433223
Test Loss:  0.00011484512651804835
Valid Loss:  0.00032092584297060966
Epoch:  275  	Training Loss: 0.0002450680185575038
Test Loss:  0.00011483425623737276
Valid Loss:  0.00032061408273875713
Epoch:  276  	Training Loss: 0.0002448851300869137
Test Loss:  0.00011484208516776562
Valid Loss:  0.00032031454611569643
Epoch:  277  	Training Loss: 0.0002447133883833885
Test Loss:  0.00011486336006782949
Valid Loss:  0.0003200274077244103
Epoch:  278  	Training Loss: 0.00024455221137031913
Test Loss:  0.00011489345342852175
Valid Loss:  0.0003197510668542236
Epoch:  279  	Training Loss: 0.0002444004057906568
Test Loss:  0.00011493078636704013
Valid Loss:  0.0003194867167621851
Epoch:  280  	Training Loss: 0.00024425663286820054
Test Loss:  0.00011497295054141432
Valid Loss:  0.0003192330477759242
Epoch:  281  	Training Loss: 0.0002441205724608153
Test Loss:  0.0001150194657384418
Valid Loss:  0.0003189898270647973
Epoch:  282  	Training Loss: 0.00024399228277616203
Test Loss:  0.00011532452481333166
Valid Loss:  0.00031709374161437154
Epoch:  283  	Training Loss: 0.0002425995480734855
Test Loss:  0.00011500291293486953
Valid Loss:  0.00031551779829896986
Epoch:  284  	Training Loss: 0.00024137168657034636
Test Loss:  0.00011460401583462954
Valid Loss:  0.0003140015760436654
Epoch:  285  	Training Loss: 0.00024019976262934506
Test Loss:  0.00011422644456615672
Valid Loss:  0.00031254469649866223
Epoch:  286  	Training Loss: 0.0002390664303675294
Test Loss:  0.00011387115955585614
Valid Loss:  0.000311124837026
Epoch:  287  	Training Loss: 0.0002379424695391208
Test Loss:  0.00011353208537911996
Valid Loss:  0.00030974240507930517
Epoch:  288  	Training Loss: 0.00023682827304583043
Test Loss:  0.00011315950541757047
Valid Loss:  0.00030839344253763556
Epoch:  289  	Training Loss: 0.00023574156512040645
Test Loss:  0.00011279337195446715
Valid Loss:  0.0003070941602345556
Epoch:  290  	Training Loss: 0.0002346887777093798
Test Loss:  0.00011244896450079978
Valid Loss:  0.00030582566978409886
Epoch:  291  	Training Loss: 0.00023365599918179214
Test Loss:  0.00011213032848900184
Valid Loss:  0.00030460258130915463
Epoch:  292  	Training Loss: 0.00023266536300070584
Test Loss:  0.00011192115198355168
Valid Loss:  0.00030447228346019983
Epoch:  293  	Training Loss: 0.00023257665452547371
Test Loss:  0.00011176738189533353
Valid Loss:  0.00030437472742050886
Epoch:  294  	Training Loss: 0.00023251480888575315
Test Loss:  0.0001116534331231378
Valid Loss:  0.0003042972239200026
Epoch:  295  	Training Loss: 0.00023246979981195182
Test Loss:  0.00011156934488099068
Valid Loss:  0.0003042344469577074
Epoch:  296  	Training Loss: 0.00023243585019372404
Test Loss:  0.00011150720092700794
Valid Loss:  0.00030418162350542843
Epoch:  297  	Training Loss: 0.00023240927839651704
Test Loss:  0.0001114619808504358
Valid Loss:  0.0003041354939341545
Epoch:  298  	Training Loss: 0.00023238733410835266
Test Loss:  0.00011142952280351892
Valid Loss:  0.0003040949231944978
Epoch:  299  	Training Loss: 0.00023236832930706441
Test Loss:  0.00011140688002342358
Valid Loss:  0.0003040584269911051
Epoch:  300  	Training Loss: 0.0002323515946045518
Test Loss:  0.00011139149137306958
Valid Loss:  0.0003040236188098788
Epoch:  301  	Training Loss: 0.0002323359076399356
Test Loss:  0.0001113823163905181
Valid Loss:  0.0003039918374270201
Epoch:  302  	Training Loss: 0.00023232123930938542
Test Loss:  0.00011129293125122786
Valid Loss:  0.0003033193643204868
Epoch:  303  	Training Loss: 0.00023183703888207674
Test Loss:  0.00011106835154350847
Valid Loss:  0.0003026744816452265
Epoch:  304  	Training Loss: 0.00023139808035921305
Test Loss:  0.00011080922558903694
Valid Loss:  0.00030201752088032663
Epoch:  305  	Training Loss: 0.0002309681731276214
Test Loss:  0.00011052852642023936
Valid Loss:  0.00030137208523228765
Epoch:  306  	Training Loss: 0.0002305482339579612
Test Loss:  0.00011025115964002907
Valid Loss:  0.0003007282502949238
Epoch:  307  	Training Loss: 0.00023012704332359135
Test Loss:  0.00010998439393006265
Valid Loss:  0.00030009617330506444
Epoch:  308  	Training Loss: 0.000229715442401357
Test Loss:  0.00010969393042614684
Valid Loss:  0.00029947288567200303
Epoch:  309  	Training Loss: 0.00022929393162485212
Test Loss:  0.00010936292528640479
Valid Loss:  0.00029881380032747984
Epoch:  310  	Training Loss: 0.00022882907069288194
Test Loss:  0.0001090267178369686
Valid Loss:  0.00029816385358572006
Epoch:  311  	Training Loss: 0.00022837529832031578
Test Loss:  0.00010867700621020049
Valid Loss:  0.0002975231618620455
Epoch:  312  	Training Loss: 0.00022792241361457855
Test Loss:  0.00010826275683939457
Valid Loss:  0.0002969850320369005
Epoch:  313  	Training Loss: 0.00022764544701203704
Test Loss:  0.00010855383879970759
Valid Loss:  0.0002966094180010259
Epoch:  314  	Training Loss: 0.00022743064619135112
Test Loss:  0.00010864046635106206
Valid Loss:  0.0002962361031677574
Epoch:  315  	Training Loss: 0.00022724131122231483
Test Loss:  0.00010879565525101498
Valid Loss:  0.0002959034754894674
Epoch:  316  	Training Loss: 0.00022707153402734548
Test Loss:  0.00010892988211708143
Valid Loss:  0.00029559223912656307
Epoch:  317  	Training Loss: 0.0002269194374093786
Test Loss:  0.0001090702717192471
Valid Loss:  0.00029530643951147795
Epoch:  318  	Training Loss: 0.00022678241657558829
Test Loss:  0.00010920602653641254
Valid Loss:  0.0002950402849819511
Epoch:  319  	Training Loss: 0.0002266587398480624
Test Loss:  0.00010934074816759676
Valid Loss:  0.0002947944449260831
Epoch:  320  	Training Loss: 0.00022654772328678519
Test Loss:  0.00010947234113700688
Valid Loss:  0.0002945650485344231
Epoch:  321  	Training Loss: 0.00022644700948148966
Test Loss:  0.0001096000341931358
Valid Loss:  0.00029435151373036206
Epoch:  322  	Training Loss: 0.00022635611821897328
Test Loss:  0.00010795007256092504
Valid Loss:  0.0002924808650277555
Epoch:  323  	Training Loss: 0.0002243040653411299
Test Loss:  0.00010694732191041112
Valid Loss:  0.00029065634589642286
Epoch:  324  	Training Loss: 0.00022236566292122006
Test Loss:  0.00010591679892968386
Valid Loss:  0.00028886538348160684
Epoch:  325  	Training Loss: 0.00022047761012800038
Test Loss:  0.00010496209870325401
Valid Loss:  0.00028710172045975924
Epoch:  326  	Training Loss: 0.0002186629717471078
Test Loss:  0.00010405489592812955
Valid Loss:  0.00028537027537822723
Epoch:  327  	Training Loss: 0.00021691693109460175
Test Loss:  0.00010320791625417769
Valid Loss:  0.00028368388302624226
Epoch:  328  	Training Loss: 0.00021524510520976037
Test Loss:  0.00010240495612379164
Valid Loss:  0.00028205919079482555
Epoch:  329  	Training Loss: 0.00021365076827351004
Test Loss:  0.00010165124695049599
Valid Loss:  0.0002804960822686553
Epoch:  330  	Training Loss: 0.00021213528816588223
Test Loss:  0.00010096418554894626
Valid Loss:  0.0002790048602037132
Epoch:  331  	Training Loss: 0.00021070886577945203
Test Loss:  0.00010033734724856913
Valid Loss:  0.00027756282361224294
Epoch:  332  	Training Loss: 0.00020934230997227132
Test Loss:  0.0001006827806122601
Valid Loss:  0.000276107806712389
Epoch:  333  	Training Loss: 0.00020835980831179768
Test Loss:  0.0001006196325761266
Valid Loss:  0.00027525698533281684
Epoch:  334  	Training Loss: 0.00020780698105227202
Test Loss:  0.0001003640063572675
Valid Loss:  0.000274527381407097
Epoch:  335  	Training Loss: 0.0002073089126497507
Test Loss:  0.00010002128692576662
Valid Loss:  0.00027381666586734354
Epoch:  336  	Training Loss: 0.0002068125904770568
Test Loss:  9.966954530682415e-05
Valid Loss:  0.00027312833117321134
Epoch:  337  	Training Loss: 0.00020632741507142782
Test Loss:  9.933629917213693e-05
Valid Loss:  0.00027245297678746283
Epoch:  338  	Training Loss: 0.00020585111633408815
Test Loss:   68%|██████▊   | 339/500 [04:03<00:53,  3.02it/s] 68%|██████▊   | 341/500 [04:09<03:05,  1.17s/it] 69%|██████▊   | 343/500 [04:09<02:11,  1.19it/s] 69%|██████▉   | 345/500 [04:10<01:33,  1.65it/s] 69%|██████▉   | 347/500 [04:10<01:07,  2.26it/s] 70%|██████▉   | 349/500 [04:10<00:49,  3.04it/s] 70%|███████   | 351/500 [04:16<02:51,  1.15s/it] 71%|███████   | 353/500 [04:16<02:01,  1.21it/s] 71%|███████   | 355/500 [04:16<01:26,  1.67it/s] 71%|███████▏  | 357/500 [04:16<01:02,  2.28it/s] 72%|███████▏  | 359/500 [04:16<00:46,  3.06it/s] 72%|███████▏  | 361/500 [04:23<02:39,  1.15s/it] 73%|███████▎  | 363/500 [04:23<01:53,  1.21it/s] 73%|███████▎  | 365/500 [04:23<01:20,  1.67it/s] 73%|███████▎  | 367/500 [04:23<00:58,  2.28it/s] 74%|███████▍  | 369/500 [04:23<00:42,  3.07it/s] 74%|███████▍  | 371/500 [04:29<02:28,  1.15s/it] 75%|███████▍  | 373/500 [04:29<01:45,  1.21it/s] 75%|███████▌  | 375/500 [04:30<01:14,  1.67it/s] 75%|███████▌  | 377/500 [04:30<00:54,  2.28it/s] 76%|███████▌  | 379/500 [04:30<00:39,  3.06it/s] 76%|███████▌  | 381/500 [04:36<02:18,  1.16s/it] 77%|███████▋  | 383/500 [04:36<01:37,  1.20it/s] 77%|███████▋  | 385/500 [04:36<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:37<00:50,  2.24it/s] 78%|███████▊  | 389/500 [04:37<00:36,  3.01it/s] 78%|███████▊  | 391/500 [04:43<02:06,  1.16s/it] 79%|███████▊  | 393/500 [04:43<01:29,  1.20it/s] 79%|███████▉  | 395/500 [04:43<01:03,  1.66it/s] 79%|███████▉  | 397/500 [04:43<00:45,  2.26it/s] 80%|███████▉  | 399/500 [04:43<00:33,  3.04it/s] 80%|████████  | 401/500 [04:50<01:56,  1.17s/it] 81%|████████  | 403/500 [04:50<01:21,  1.19it/s] 81%|████████  | 405/500 [04:50<00:57,  1.64it/s]9.902417514240369e-05
Valid Loss:  0.0002717867027968168
Epoch:  339  	Training Loss: 0.0002053810458164662
Test Loss:  9.873234375845641e-05
Valid Loss:  0.000271126686129719
Epoch:  340  	Training Loss: 0.00020491046598181129
Test Loss:  9.845179010881111e-05
Valid Loss:  0.0002704575890675187
Epoch:  341  	Training Loss: 0.00020443610264919698
Test Loss:  9.817424870561808e-05
Valid Loss:  0.00026979786343872547
Epoch:  342  	Training Loss: 0.00020396776380948722
Test Loss:  9.548159141559154e-05
Valid Loss:  0.0002687450614757836
Epoch:  343  	Training Loss: 0.00020250501984264702
Test Loss:  9.510554082226008e-05
Valid Loss:  0.00026859313948079944
Epoch:  344  	Training Loss: 0.00020219714497216046
Test Loss:  9.495091217104346e-05
Valid Loss:  0.0002684387727640569
Epoch:  345  	Training Loss: 0.00020192690135445446
Test Loss:  9.483005851507187e-05
Valid Loss:  0.0002682846679817885
Epoch:  346  	Training Loss: 0.00020166690228506923
Test Loss:  9.471875091549009e-05
Valid Loss:  0.00026813356089405715
Epoch:  347  	Training Loss: 0.00020141553250141442
Test Loss:  9.461282752454281e-05
Valid Loss:  0.0002679874305613339
Epoch:  348  	Training Loss: 0.00020117327221669257
Test Loss:  9.451563528273255e-05
Valid Loss:  0.000267847441136837
Epoch:  349  	Training Loss: 0.00020094138744752854
Test Loss:  9.442109148949385e-05
Valid Loss:  0.00026771152624860406
Epoch:  350  	Training Loss: 0.00020071731705684215
Test Loss:  9.433009836357087e-05
Valid Loss:  0.00026757954037748277
Epoch:  351  	Training Loss: 0.0002005004498641938
Test Loss:  9.424793825019151e-05
Valid Loss:  0.00026744994102045894
Epoch:  352  	Training Loss: 0.00020029385632369667
Test Loss:  9.511535608908162e-05
Valid Loss:  0.0002663432969711721
Epoch:  353  	Training Loss: 0.00019948152475990355
Test Loss:  9.551098628435284e-05
Valid Loss:  0.0002655911666806787
Epoch:  354  	Training Loss: 0.00019886641530320048
Test Loss:  9.585071529727429e-05
Valid Loss:  0.00026497337967157364
Epoch:  355  	Training Loss: 0.00019834880367852747
Test Loss:  9.619408956496045e-05
Valid Loss:  0.00026445771800354123
Epoch:  356  	Training Loss: 0.00019791099475696683
Test Loss:  9.652226435719058e-05
Valid Loss:  0.00026401999639347196
Epoch:  357  	Training Loss: 0.00019753590459004045
Test Loss:  9.683793905423954e-05
Valid Loss:  0.0002636468270793557
Epoch:  358  	Training Loss: 0.00019721215358003974
Test Loss:  9.713952749734744e-05
Valid Loss:  0.00026333879213780165
Epoch:  359  	Training Loss: 0.00019693071953952312
Test Loss:  9.742423571879044e-05
Valid Loss:  0.00026308116503059864
Epoch:  360  	Training Loss: 0.00019668432651087642
Test Loss:  9.769095049705356e-05
Valid Loss:  0.0002628601505421102
Epoch:  361  	Training Loss: 0.0001964664552360773
Test Loss:  9.793922072276473e-05
Valid Loss:  0.00026267010252922773
Epoch:  362  	Training Loss: 0.00019627224537543952
Test Loss:  9.87764069577679e-05
Valid Loss:  0.0002626890200190246
Epoch:  363  	Training Loss: 0.0001962061651283875
Test Loss:  9.87852763500996e-05
Valid Loss:  0.0002626432105898857
Epoch:  364  	Training Loss: 0.00019619883096311241
Test Loss:  9.888135537039489e-05
Valid Loss:  0.00026261620223522186
Epoch:  365  	Training Loss: 0.00019619340309873223
Test Loss:  9.89587206277065e-05
Valid Loss:  0.0002625906199682504
Epoch:  366  	Training Loss: 0.00019618921214714646
Test Loss:  9.902958845486864e-05
Valid Loss:  0.00026256858836859465
Epoch:  367  	Training Loss: 0.0001961857487913221
Test Loss:  9.909344953484833e-05
Valid Loss:  0.00026254920521751046
Epoch:  368  	Training Loss: 0.00019618275109678507
Test Loss:  9.915122791426256e-05
Valid Loss:  0.0002625316265039146
Epoch:  369  	Training Loss: 0.00019618023361545056
Test Loss:  9.92033164948225e-05
Valid Loss:  0.000262516550719738
Epoch:  370  	Training Loss: 0.00019617867656052113
Test Loss:  9.925001359079033e-05
Valid Loss:  0.0002625027555041015
Epoch:  371  	Training Loss: 0.0001961772213689983
Test Loss:  9.929268708219752e-05
Valid Loss:  0.0002624906483106315
Epoch:  372  	Training Loss: 0.0001961759408004582
Test Loss:  9.879337449092418e-05
Valid Loss:  0.0002616450365167111
Epoch:  373  	Training Loss: 0.0001953937899088487
Test Loss:  9.782776760403067e-05
Valid Loss:  0.0002608185459394008
Epoch:  374  	Training Loss: 0.00019472924759611487
Test Loss:  9.700849477667361e-05
Valid Loss:  0.0002600822481326759
Epoch:  375  	Training Loss: 0.0001941337832249701
Test Loss:  9.629465057514608e-05
Valid Loss:  0.00025941152125597
Epoch:  376  	Training Loss: 0.0001935918116942048
Test Loss:  9.566948574502021e-05
Valid Loss:  0.00025887874653562903
Epoch:  377  	Training Loss: 0.00019311654614284635
Test Loss:  9.514360863249749e-05
Valid Loss:  0.00025839352747425437
Epoch:  378  	Training Loss: 0.00019268388859927654
Test Loss:  9.468630014453083e-05
Valid Loss:  0.0002579264692030847
Epoch:  379  	Training Loss: 0.00019228420569561422
Test Loss:  9.428139310330153e-05
Valid Loss:  0.00025746558094397187
Epoch:  380  	Training Loss: 0.0001919009373523295
Test Loss:  9.391181811224669e-05
Valid Loss:  0.00025701778940856457
Epoch:  381  	Training Loss: 0.00019156286725774407
Test Loss:  9.360934927826747e-05
Valid Loss:  0.00025660416577011347
Epoch:  382  	Training Loss: 0.00019126912229694426
Test Loss:  9.338879317510873e-05
Valid Loss:  0.00025645806454122066
Epoch:  383  	Training Loss: 0.000191185376024805
Test Loss:  9.337518713437021e-05
Valid Loss:  0.0002563638845458627
Epoch:  384  	Training Loss: 0.00019112665904685855
Test Loss:  9.342127304989845e-05
Valid Loss:  0.0002562827430665493
Epoch:  385  	Training Loss: 0.0001910717983264476
Test Loss:  9.348525054519996e-05
Valid Loss:  0.00025620637461543083
Epoch:  386  	Training Loss: 0.0001910197315737605
Test Loss:  9.355344081996009e-05
Valid Loss:  0.00025613498291932046
Epoch:  387  	Training Loss: 0.00019097139011137187
Test Loss:  9.362016862723976e-05
Valid Loss:  0.00025606463896110654
Epoch:  388  	Training Loss: 0.00019092453294433653
Test Loss:  9.368519386043772e-05
Valid Loss:  0.0002559958666097373
Epoch:  389  	Training Loss: 0.0001908786070998758
Test Loss:  9.37490985961631e-05
Valid Loss:  0.00025592901511117816
Epoch:  390  	Training Loss: 0.00019083343795500696
Test Loss:  9.381140989717096e-05
Valid Loss:  0.000255863880738616
Epoch:  391  	Training Loss: 0.00019079107732977718
Test Loss:  9.387267346028239e-05
Valid Loss:  0.0002558031410444528
Epoch:  392  	Training Loss: 0.00019075334421359003
Test Loss:  9.379210678162053e-05
Valid Loss:  0.00025451197871007025
Epoch:  393  	Training Loss: 0.00018974303384311497
Test Loss:  9.327165753347799e-05
Valid Loss:  0.0002537294349167496
Epoch:  394  	Training Loss: 0.0001891671709017828
Test Loss:  9.266832785215229e-05
Valid Loss:  0.00025309144984930754
Epoch:  395  	Training Loss: 0.00018870254280045629
Test Loss:  9.212043369188905e-05
Valid Loss:  0.00025251953047700226
Epoch:  396  	Training Loss: 0.00018828926840797067
Test Loss:  9.165398660115898e-05
Valid Loss:  0.00025198416551575065
Epoch:  397  	Training Loss: 0.00018790617468766868
Test Loss:  9.126124496106058e-05
Valid Loss:  0.00025147077394649386
Epoch:  398  	Training Loss: 0.00018754163465928286
Test Loss:  9.09268856048584e-05
Valid Loss:  0.0002509711775928736
Epoch:  399  	Training Loss: 0.0001871893764473498
Test Loss:  9.063821198651567e-05
Valid Loss:  0.00025048095267266035
Epoch:  400  	Training Loss: 0.00018684528185985982
Test Loss:  9.038402640726417e-05
Valid Loss:  0.0002499980619177222
Epoch:  401  	Training Loss: 0.00018650722631718963
Test Loss:  9.015716204885393e-05
Valid Loss:  0.00024952017702162266
Epoch:  402  	Training Loss: 0.0001861735654529184
Test Loss:  8.735949813853949e-05
Valid Loss:  0.0002482819836586714
Epoch:  403  	Training Loss: 0.00018483921303413808
Test Loss:  8.737435564398766e-05
Valid Loss:  0.0002469793544150889
Epoch:  404  	Training Loss: 0.00018382906273473054
Test Loss:  8.662820619065315e-05
Valid Loss:  0.0002458698581904173
Epoch:  405  	Training Loss: 0.000182886011316441
Test Loss:  8.626138878753409e-05
Valid Loss:  0.00024474289966747165
 81%|████████▏ | 407/500 [04:50<00:41,  2.24it/s] 82%|████████▏ | 409/500 [04:50<00:30,  3.01it/s] 82%|████████▏ | 411/500 [04:57<01:45,  1.18s/it] 83%|████████▎ | 413/500 [04:57<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:57<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:57<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:57<00:27,  3.00it/s] 84%|████████▍ | 421/500 [05:03<01:32,  1.17s/it] 85%|████████▍ | 423/500 [05:03<01:04,  1.19it/s] 85%|████████▌ | 425/500 [05:04<00:45,  1.65it/s] 85%|████████▌ | 427/500 [05:04<00:32,  2.24it/s] 86%|████████▌ | 429/500 [05:04<00:23,  3.01it/s] 86%|████████▌ | 431/500 [05:10<01:20,  1.16s/it] 87%|████████▋ | 433/500 [05:10<00:55,  1.20it/s] 87%|████████▋ | 435/500 [05:10<00:39,  1.66it/s] 87%|████████▋ | 437/500 [05:10<00:27,  2.26it/s] 88%|████████▊ | 439/500 [05:11<00:20,  3.04it/s] 88%|████████▊ | 441/500 [05:17<01:08,  1.17s/it] 89%|████████▊ | 443/500 [05:17<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:17<00:33,  1.65it/s] 89%|████████▉ | 447/500 [05:17<00:23,  2.25it/s] 90%|████████▉ | 449/500 [05:17<00:16,  3.03it/s] 90%|█████████ | 451/500 [05:24<00:56,  1.16s/it] 91%|█████████ | 453/500 [05:24<00:39,  1.20it/s] 91%|█████████ | 455/500 [05:24<00:27,  1.66it/s] 91%|█████████▏| 457/500 [05:24<00:18,  2.27it/s] 92%|█████████▏| 459/500 [05:24<00:13,  3.05it/s] 92%|█████████▏| 461/500 [05:30<00:45,  1.16s/it] 93%|█████████▎| 463/500 [05:30<00:30,  1.20it/s] 93%|█████████▎| 465/500 [05:31<00:21,  1.65it/s] 93%|█████████▎| 467/500 [05:31<00:14,  2.26it/s] 94%|█████████▍| 469/500 [05:31<00:10,  3.04it/s] 94%|█████████▍| 471/500 [05:37<00:34,  1.17s/it]Epoch:  406  	Training Loss: 0.00018197752069681883
Test Loss:  8.582827285863459e-05
Valid Loss:  0.0002436582581140101
Epoch:  407  	Training Loss: 0.0001810979883885011
Test Loss:  8.546304889023304e-05
Valid Loss:  0.000242590467678383
Epoch:  408  	Training Loss: 0.00018025428289547563
Test Loss:  8.517014794051647e-05
Valid Loss:  0.00024155712162610143
Epoch:  409  	Training Loss: 0.00017946469597518444
Test Loss:  8.484224963467568e-05
Valid Loss:  0.0002405542036285624
Epoch:  410  	Training Loss: 0.00017869719886220992
Test Loss:  8.457363583147526e-05
Valid Loss:  0.00023957190569490194
Epoch:  411  	Training Loss: 0.00017796194879338145
Test Loss:  8.42921290313825e-05
Valid Loss:  0.00023861390945967287
Epoch:  412  	Training Loss: 0.0001772376854205504
Test Loss:  8.451046596746892e-05
Valid Loss:  0.0002382512902840972
Epoch:  413  	Training Loss: 0.00017700542230159044
Test Loss:  8.482277189614251e-05
Valid Loss:  0.00023793567379470915
Epoch:  414  	Training Loss: 0.00017681060126051307
Test Loss:  8.512401836924255e-05
Valid Loss:  0.00023766071535646915
Epoch:  415  	Training Loss: 0.0001766454806784168
Test Loss:  8.541333954781294e-05
Valid Loss:  0.00023742223856970668
Epoch:  416  	Training Loss: 0.00017650608788244426
Test Loss:  8.568978228140622e-05
Valid Loss:  0.0002372142771491781
Epoch:  417  	Training Loss: 0.0001763882173690945
Test Loss:  8.595260442234576e-05
Valid Loss:  0.00023703297483734787
Epoch:  418  	Training Loss: 0.0001762882457114756
Test Loss:  8.620150765636936e-05
Valid Loss:  0.0002368745335843414
Epoch:  419  	Training Loss: 0.00017620285507291555
Test Loss:  8.643615001346916e-05
Valid Loss:  0.00023673511168453842
Epoch:  420  	Training Loss: 0.00017613076488487422
Test Loss:  8.665690256748348e-05
Valid Loss:  0.00023661283194087446
Epoch:  421  	Training Loss: 0.0001760690938681364
Test Loss:  8.686409273650497e-05
Valid Loss:  0.00023650540970265865
Epoch:  422  	Training Loss: 0.00017601653235033154
Test Loss:  8.676086144987494e-05
Valid Loss:  0.0002354476018808782
Epoch:  423  	Training Loss: 0.00017520978872198611
Test Loss:  8.608029747847468e-05
Valid Loss:  0.000234791383263655
Epoch:  424  	Training Loss: 0.00017475201457273215
Test Loss:  8.544806041754782e-05
Valid Loss:  0.00023418886121362448
Epoch:  425  	Training Loss: 0.00017433753237128258
Test Loss:  8.490519394399598e-05
Valid Loss:  0.00023362520732916892
Epoch:  426  	Training Loss: 0.00017395312897861004
Test Loss:  8.445137063972652e-05
Valid Loss:  0.00023308170784730464
Epoch:  427  	Training Loss: 0.00017358415061607957
Test Loss:  8.405884727835655e-05
Valid Loss:  0.00023254110419657081
Epoch:  428  	Training Loss: 0.00017321755876764655
Test Loss:  8.370276191271842e-05
Valid Loss:  0.0002320166677236557
Epoch:  429  	Training Loss: 0.00017286006186623126
Test Loss:  8.339151099789888e-05
Valid Loss:  0.00023149124172050506
Epoch:  430  	Training Loss: 0.0001725006732158363
Test Loss:  8.31059442134574e-05
Valid Loss:  0.00023097771918401122
Epoch:  431  	Training Loss: 0.0001721502630971372
Test Loss:  8.284953219117597e-05
Valid Loss:  0.0002304731315234676
Epoch:  432  	Training Loss: 0.00017180698341690004
Test Loss:  8.218320726882666e-05
Valid Loss:  0.00023016086197458208
Epoch:  433  	Training Loss: 0.00017155992100015283
Test Loss:  8.210875967051834e-05
Valid Loss:  0.00022995415201876312
Epoch:  434  	Training Loss: 0.00017143072909675539
Test Loss:  8.220695599447936e-05
Valid Loss:  0.0002297708415426314
Epoch:  435  	Training Loss: 0.00017132496577687562
Test Loss:  8.235766290454194e-05
Valid Loss:  0.00022960323258303106
Epoch:  436  	Training Loss: 0.0001712304074317217
Test Loss:  8.25220558908768e-05
Valid Loss:  0.0002294492587679997
Epoch:  437  	Training Loss: 0.0001711450458969921
Test Loss:  8.268772216979414e-05
Valid Loss:  0.0002293068973813206
Epoch:  438  	Training Loss: 0.00017106796440202743
Test Loss:  8.28505217214115e-05
Valid Loss:  0.00022917616297490895
Epoch:  439  	Training Loss: 0.00017099831893574446
Test Loss:  8.300873741973191e-05
Valid Loss:  0.00022905557125341147
Epoch:  440  	Training Loss: 0.00017093504720833153
Test Loss:  8.316169987665489e-05
Valid Loss:  0.00022894371068105102
Epoch:  441  	Training Loss: 0.00017087774176616222
Test Loss:  8.330940909218043e-05
Valid Loss:  0.00022884097415953875
Epoch:  442  	Training Loss: 0.00017082558770198375
Test Loss:  8.299393812194467e-05
Valid Loss:  0.00022802733292337507
Epoch:  443  	Training Loss: 0.00017012970056384802
Test Loss:  8.25385213829577e-05
Valid Loss:  0.0002273216814501211
Epoch:  444  	Training Loss: 0.0001695083628874272
Test Loss:  8.214081753976643e-05
Valid Loss:  0.00022666090808343142
Epoch:  445  	Training Loss: 0.00016893856809474528
Test Loss:  8.183611498679966e-05
Valid Loss:  0.00022604160767514259
Epoch:  446  	Training Loss: 0.00016843447519931942
Test Loss:  8.156320836860687e-05
Valid Loss:  0.00022545405954588205
Epoch:  447  	Training Loss: 0.00016796845011413097
Test Loss:  8.133092342177406e-05
Valid Loss:  0.00022489290859084576
Epoch:  448  	Training Loss: 0.00016753804811742157
Test Loss:  8.113509102258831e-05
Valid Loss:  0.00022435412392951548
Epoch:  449  	Training Loss: 0.0001671392092248425
Test Loss:  8.096983947325498e-05
Valid Loss:  0.00022383696341421455
Epoch:  450  	Training Loss: 0.00016676157247275114
Test Loss:  8.079705730779096e-05
Valid Loss:  0.00022333198285195976
Epoch:  451  	Training Loss: 0.00016639285604469478
Test Loss:  8.063729183049873e-05
Valid Loss:  0.0002228364464826882
Epoch:  452  	Training Loss: 0.0001660326961427927
Test Loss:  8.064058783929795e-05
Valid Loss:  0.00022240905673243105
Epoch:  453  	Training Loss: 0.00016577581118326634
Test Loss:  8.048278687056154e-05
Valid Loss:  0.000222049216972664
Epoch:  454  	Training Loss: 0.00016554379544686526
Test Loss:  8.030699973460287e-05
Valid Loss:  0.00022169305884744972
Epoch:  455  	Training Loss: 0.00016530795255675912
Test Loss:  8.012817124836147e-05
Valid Loss:  0.00022134778555482626
Epoch:  456  	Training Loss: 0.0001650773483561352
Test Loss:  7.996144995559007e-05
Valid Loss:  0.0002210078964708373
Epoch:  457  	Training Loss: 0.0001648513862164691
Test Loss:  7.980894588399678e-05
Valid Loss:  0.00022067305690143257
Epoch:  458  	Training Loss: 0.00016462888743262738
Test Loss:  7.966939301695675e-05
Valid Loss:  0.00022034093854017556
Epoch:  459  	Training Loss: 0.00016441001207567751
Test Loss:  7.954104512464255e-05
Valid Loss:  0.00022001292381901294
Epoch:  460  	Training Loss: 0.0001641942362766713
Test Loss:  7.942259981064126e-05
Valid Loss:  0.0002196882269345224
Epoch:  461  	Training Loss: 0.0001639814581722021
Test Loss:  7.931307482067496e-05
Valid Loss:  0.0002193664840888232
Epoch:  462  	Training Loss: 0.0001637713867239654
Test Loss:  7.866250234656036e-05
Valid Loss:  0.00021817072411067784
Epoch:  463  	Training Loss: 0.00016269844491034746
Test Loss:  7.807191286701709e-05
Valid Loss:  0.00021700967045035213
Epoch:  464  	Training Loss: 0.00016166671412065625
Test Loss:  7.754550460958853e-05
Valid Loss:  0.0002158988791052252
Epoch:  465  	Training Loss: 0.0001606911391718313
Test Loss:  7.70830811234191e-05
Valid Loss:  0.00021483356249518692
Epoch:  466  	Training Loss: 0.00015976552094798535
Test Loss:  7.667799945920706e-05
Valid Loss:  0.0002138108538929373
Epoch:  467  	Training Loss: 0.00015887588961049914
Test Loss:  7.631094194948673e-05
Valid Loss:  0.00021281163208186626
Epoch:  468  	Training Loss: 0.00015800519031472504
Test Loss:  7.597920921398327e-05
Valid Loss:  0.00021183602802921087
Epoch:  469  	Training Loss: 0.0001571752509335056
Test Loss:  7.567744614789262e-05
Valid Loss:  0.000210853002499789
Epoch:  470  	Training Loss: 0.0001563824771437794
Test Loss:  7.537034980487078e-05
Valid Loss:  0.00020990692428313196
Epoch:  471  	Training Loss: 0.00015563529450446367
Test Loss:  7.48593665775843e-05
Valid Loss:  0.00020907979342155159
Epoch:  472  	Training Loss: 0.000154951136210002
Test Loss:  7.519921200582758e-05
Valid Loss:  0.0002086736640194431
Epoch:  473  	Training Loss: 0.00015468682977370918
Test Loss:   95%|█████████▍| 473/500 [05:37<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:37<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:38<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:38<00:06,  3.01it/s] 96%|█████████▌| 481/500 [05:44<00:21,  1.16s/it] 97%|█████████▋| 483/500 [05:44<00:14,  1.20it/s] 97%|█████████▋| 485/500 [05:44<00:09,  1.66it/s] 97%|█████████▋| 487/500 [05:44<00:05,  2.27it/s] 98%|█████████▊| 489/500 [05:44<00:03,  3.05it/s] 98%|█████████▊| 491/500 [05:51<00:10,  1.16s/it] 99%|█████████▊| 493/500 [05:51<00:05,  1.20it/s] 99%|█████████▉| 495/500 [05:51<00:03,  1.66it/s] 99%|█████████▉| 497/500 [05:51<00:01,  2.27it/s]100%|█████████▉| 499/500 [05:51<00:00,  3.05it/s]100%|██████████| 500/500 [05:51<00:00,  1.42it/s]
7.536219345638528e-05
Valid Loss:  0.00020831095753237605
Epoch:  474  	Training Loss: 0.00015444359451066703
Test Loss:  7.544615073129535e-05
Valid Loss:  0.00020796546596102417
Epoch:  475  	Training Loss: 0.00015420798445120454
Test Loss:  7.549097063019872e-05
Valid Loss:  0.00020762794883921742
Epoch:  476  	Training Loss: 0.00015397746756207198
Test Loss:  7.551380258519202e-05
Valid Loss:  0.00020729769312310964
Epoch:  477  	Training Loss: 0.00015375122893601656
Test Loss:  7.55225628381595e-05
Valid Loss:  0.0002069719776045531
Epoch:  478  	Training Loss: 0.00015352848276961595
Test Loss:  7.552075840067118e-05
Valid Loss:  0.0002066504821414128
Epoch:  479  	Training Loss: 0.000153309156303294
Test Loss:  7.551084854640067e-05
Valid Loss:  0.00020633338135667145
Epoch:  480  	Training Loss: 0.00015309290029108524
Test Loss:  7.5494397606235e-05
Valid Loss:  0.0002060195110971108
Epoch:  481  	Training Loss: 0.00015287977294065058
Test Loss:  7.547287532361224e-05
Valid Loss:  0.00020570943888742477
Epoch:  482  	Training Loss: 0.00015266923583112657
Test Loss:  7.535182521678507e-05
Valid Loss:  0.00020565408340189606
Epoch:  483  	Training Loss: 0.0001526247797301039
Test Loss:  7.525068940594792e-05
Valid Loss:  0.00020560302073135972
Epoch:  484  	Training Loss: 0.00015258579514920712
Test Loss:  7.516663754358888e-05
Valid Loss:  0.00020555751689244062
Epoch:  485  	Training Loss: 0.00015255158359650522
Test Loss:  7.509761780966073e-05
Valid Loss:  0.00020551530178636312
Epoch:  486  	Training Loss: 0.00015252082084771246
Test Loss:  7.504115637857467e-05
Valid Loss:  0.00020547550229821354
Epoch:  487  	Training Loss: 0.00015249302668962628
Test Loss:  7.499589992221445e-05
Valid Loss:  0.00020543826394714415
Epoch:  488  	Training Loss: 0.00015246747352648526
Test Loss:  7.496004400309175e-05
Valid Loss:  0.00020540272817015648
Epoch:  489  	Training Loss: 0.00015244388487190008
Test Loss:  7.493280281778425e-05
Valid Loss:  0.00020536936062853783
Epoch:  490  	Training Loss: 0.00015242162044160068
Test Loss:  7.491275027859956e-05
Valid Loss:  0.00020533689530566335
Epoch:  491  	Training Loss: 0.00015240086941048503
Test Loss:  7.489901327062398e-05
Valid Loss:  0.00020530581241473556
Epoch:  492  	Training Loss: 0.0001523809041827917
Test Loss:  7.515383185818791e-05
Valid Loss:  0.00020505971042439342
Epoch:  493  	Training Loss: 0.000152230029925704
Test Loss:  7.542387174908072e-05
Valid Loss:  0.00020484514243435115
Epoch:  494  	Training Loss: 0.00015210240962915123
Test Loss:  7.568838191218674e-05
Valid Loss:  0.00020465702982619405
Epoch:  495  	Training Loss: 0.000151994259795174
Test Loss:  7.594151247758418e-05
Valid Loss:  0.00020449230214580894
Epoch:  496  	Training Loss: 0.0001519025390734896
Test Loss:  7.618153904331848e-05
Valid Loss:  0.00020434826728887856
Epoch:  497  	Training Loss: 0.00015182462811935693
Test Loss:  7.640737749170512e-05
Valid Loss:  0.00020422143279574811
Epoch:  498  	Training Loss: 0.0001517585915280506
Test Loss:  7.661966083105654e-05
Valid Loss:  0.0002041091356659308
Epoch:  499  	Training Loss: 0.00015170234837569296
Test Loss:  7.681848364882171e-05
Valid Loss:  0.0002040105900960043
Epoch:  500  	Training Loss: 0.00015165406512096524
Test Loss:  7.70044862292707e-05
Valid Loss:  0.00020392313308548182
seed is  3
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.23it/s]  1%|          | 4/500 [00:00<00:30, 16.40it/s]  1%|          | 6/500 [00:00<00:30, 16.42it/s]  2%|▏         | 8/500 [00:00<00:29, 16.43it/s]  2%|▏         | 10/500 [00:00<00:29, 16.45it/s]  2%|▏         | 12/500 [00:00<00:29, 16.53it/s]  3%|▎         | 14/500 [00:00<00:29, 16.52it/s]  3%|▎         | 16/500 [00:00<00:29, 16.43it/s]  4%|▎         | 18/500 [00:01<00:29, 16.49it/s]  4%|▍         | 20/500 [00:01<00:29, 16.47it/s]  4%|▍         | 22/500 [00:01<00:29, 16.46it/s]  5%|▍         | 24/500 [00:01<00:29, 16.28it/s]  5%|▌         | 26/500 [00:01<00:28, 16.38it/s]  6%|▌         | 28/500 [00:01<00:28, 16.43it/s]  6%|▌         | 30/500 [00:01<00:28, 16.49it/s]  6%|▋         | 32/500 [00:01<00:28, 16.51it/s]  7%|▋         | 34/500 [00:02<00:28, 16.51it/s]  7%|▋         | 36/500 [00:02<00:28, 16.53it/s]  8%|▊         | 38/500 [00:02<00:27, 16.52it/s]  8%|▊         | 40/500 [00:02<00:27, 16.51it/s]  8%|▊         | 42/500 [00:02<00:27, 16.54it/s]  9%|▉         | 44/500 [00:02<00:27, 16.56it/s]  9%|▉         | 46/500 [00:02<00:27, 16.53it/s] 10%|▉         | 48/500 [00:02<00:27, 16.57it/s] 10%|█         | 50/500 [00:03<00:27, 16.52it/s] 10%|█         | 52/500 [00:03<00:27, 16.51it/s] 11%|█         | 54/500 [00:03<00:27, 16.30it/s] 11%|█         | 56/500 [00:03<00:27, 16.40it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.42it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.47it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.52it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.52it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.54it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.58it/s] 14%|█▍        | 70/500 [00:04<00:25, 16.55it/s] 14%|█▍        | 72/500 [00:04<00:25, 16.54it/s] 15%|█▍        | 74/500 [00:04<00:25, 16.58it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.59it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.58it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.60it/s] 16%|█▋        | 82/500 [00:04<00:25, 16.61it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.58it/s] 17%|█▋        | 86/500 [00:05<00:24, 16.57it/s] 18%|█▊        | 88/500 [00:05<00:24, 16.58it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.56it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.61it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.62it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.60it/s] 20%|█▉        | 98/500 [00:05<00:24, 16.59it/s] 20%|██        | 100/500 [00:06<00:24, 16.59it/s] 20%|██        | 102/500 [00:06<00:24, 16.57it/s] 21%|██        | 104/500 [00:06<00:23, 16.58it/s] 21%|██        | 106/500 [00:06<00:23, 16.58it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.52it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.29it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.35it/s] 23%|██▎       | 114/500 [00:06<00:23, 16.33it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.37it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.42it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.45it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.49it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.49it/s]Epoch:  1  	Training Loss: 0.0912899374961853
Test Loss:  1685.341796875
Valid Loss:  1686.16748046875
Epoch:  2  	Training Loss: 1682.4306640625
Test Loss:  40638242357248.0
Valid Loss:  40643938222080.0
Epoch:  3  	Training Loss: 40828756033536.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.48it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.52it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.54it/s] 26%|██▋       | 132/500 [00:07<00:22, 16.52it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.59it/s] 27%|██▋       | 136/500 [00:08<00:21, 16.56it/s] 28%|██▊       | 138/500 [00:08<00:21, 16.53it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.53it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.54it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.51it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.55it/s] 30%|██▉       | 148/500 [00:08<00:21, 16.59it/s] 30%|███       | 150/500 [00:09<00:21, 16.57it/s] 30%|███       | 152/500 [00:09<00:21, 16.56it/s] 31%|███       | 154/500 [00:09<00:20, 16.53it/s] 31%|███       | 156/500 [00:09<00:20, 16.51it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.51it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.52it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.50it/s] 33%|███▎      | 164/500 [00:09<00:20, 16.51it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.51it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.51it/s] 34%|███▍      | 170/500 [00:10<00:19, 16.52it/s] 34%|███▍      | 172/500 [00:10<00:19, 16.51it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.53it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.56it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.49it/s] 36%|███▌      | 180/500 [00:10<00:19, 16.49it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.50it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.49it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.48it/s] 38%|███▊      | 188/500 [00:11<00:18, 16.53it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.54it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.51it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.51it/s] 39%|███▉      | 196/500 [00:11<00:18, 16.52it/s] 40%|███▉      | 198/500 [00:11<00:18, 16.54it/s] 40%|████      | 200/500 [00:12<00:18, 16.51it/s] 40%|████      | 202/500 [00:12<00:18, 16.48it/s] 41%|████      | 204/500 [00:12<00:17, 16.49it/s] 41%|████      | 206/500 [00:12<00:17, 16.48it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.38it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.47it/s] 42%|████▏     | 212/500 [00:12<00:17, 16.47it/s] 43%|████▎     | 214/500 [00:12<00:17, 16.50it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.51it/s] 44%|████▎     | 218/500 [00:13<00:16, 16.60it/s] 44%|████▍     | 220/500 [00:13<00:16, 16.62it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.58it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.53it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.58it/s] 46%|████▌     | 228/500 [00:13<00:16, 16.33it/s] 46%|████▌     | 230/500 [00:13<00:16, 16.37it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.39it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.43it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.33it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.38it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.48it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.50it/s] 49%|████▉     | 244/500 [00:14<00:15, 16.52it/s] 49%|████▉     | 246/500 [00:14<00:15, 16.52it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.59it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.33it/s] 50%|█████     | 252/500 [00:15<00:15, 16.38it/s] 51%|█████     | 254/500 [00:15<00:15, 16.12it/s] 51%|█████     | 256/500 [00:15<00:15, 16.25it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.22it/s] 52%|█████▏    | 260/500 [00:15<00:14, 16.28it/s] 52%|█████▏    | 262/500 [00:15<00:14, 16.33it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.37it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.40it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.44it/s] 54%|█████▍    | 270/500 [00:16<00:13, 16.45it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.51it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.55it/s] 55%|█████▌    | 276/500 [00:16<00:13, 16.46it/s] 56%|█████▌    | 278/500 [00:16<00:13, 16.45it/s] 56%|█████▌    | 280/500 [00:16<00:13, 16.45it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.46it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.43it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.45it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.42it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.43it/s] 58%|█████▊    | 292/500 [00:17<00:12, 16.44it/s] 59%|█████▉    | 294/500 [00:17<00:12, 16.47it/s] 59%|█████▉    | 296/500 [00:17<00:12, 16.45it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.45it/s] 60%|██████    | 300/500 [00:18<00:12, 16.40it/s] 60%|██████    | 302/500 [00:18<00:12, 16.42it/s] 61%|██████    | 304/500 [00:18<00:11, 16.43it/s] 61%|██████    | 306/500 [00:18<00:11, 16.45it/s] 62%|██████▏   | 308/500 [00:18<00:11, 16.49it/s] 62%|██████▏   | 310/500 [00:18<00:11, 16.47it/s] 62%|██████▏   | 312/500 [00:18<00:11, 16.46it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.48it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.48it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.49it/s] 64%|██████▍   | 320/500 [00:19<00:10, 16.50it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.49it/s] 65%|██████▍   | 324/500 [00:19<00:10, 16.50it/s] 65%|██████▌   | 326/500 [00:19<00:10, 16.49it/s] 66%|██████▌   | 328/500 [00:19<00:10, 16.48it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.47it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.46it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.46it/s] 67%|██████▋   | 336/500 [00:20<00:09, 16.47it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.45it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.45it/s] 68%|██████▊   | 342/500 [00:20<00:09, 16.51it/s] 69%|██████▉   | 344/500 [00:20<00:09, 16.43it/s] 69%|██████▉   | 346/500 [00:20<00:09, 16.42it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.48it/s] 70%|███████   | 350/500 [00:21<00:09, 16.54it/s] 70%|███████   | 352/500 [00:21<00:08, 16.51it/s] 71%|███████   | 354/500 [00:21<00:08, 16.48it/s] 71%|███████   | 356/500 [00:21<00:08, 16.47it/s] 72%|███████▏  | 358/500 [00:21<00:08, 16.48it/s] 72%|███████▏  | 360/500 [00:21<00:08, 16.48it/s] 72%|███████▏  | 362/500 [00:21<00:08, 16.40it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.46it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.45it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.44it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.43it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.45it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:22<00:07, 16.47it/s] 75%|███████▌  | 376/500 [00:22<00:07, 16.49it/s] 76%|███████▌  | 378/500 [00:22<00:07, 16.52it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.55it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.52it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.50it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.43it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.43it/s] 78%|███████▊  | 390/500 [00:23<00:06, 16.33it/s] 78%|███████▊  | 392/500 [00:23<00:06, 16.40it/s] 79%|███████▉  | 394/500 [00:23<00:06, 16.42it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.46it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.47it/s] 80%|████████  | 400/500 [00:24<00:06, 16.48it/s] 80%|████████  | 402/500 [00:24<00:05, 16.54it/s] 81%|████████  | 404/500 [00:24<00:05, 16.53it/s] 81%|████████  | 406/500 [00:24<00:05, 16.50it/s] 82%|████████▏ | 408/500 [00:24<00:05, 16.57it/s] 82%|████████▏ | 410/500 [00:24<00:05, 16.50it/s] 82%|████████▏ | 412/500 [00:24<00:05, 16.51it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.52it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.54it/s] 84%|████████▎ | 418/500 [00:25<00:04, 16.59it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.58it/s] 84%|████████▍ | 422/500 [00:25<00:04, 16.55it/s] 85%|████████▍ | 424/500 [00:25<00:04, 16.53it/s] 85%|████████▌ | 426/500 [00:25<00:04, 16.57it/s] 86%|████████▌ | 428/500 [00:25<00:04, 16.57it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.50it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.50it/s] 87%|████████▋ | 434/500 [00:26<00:03, 16.50it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.50it/s] 88%|████████▊ | 438/500 [00:26<00:03, 16.33it/s] 88%|████████▊ | 440/500 [00:26<00:03, 16.43it/s] 88%|████████▊ | 442/500 [00:26<00:03, 16.46it/s] 89%|████████▉ | 444/500 [00:26<00:03, 16.51it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.53it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.57it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.54it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.52it/s] 91%|█████████ | 454/500 [00:27<00:02, 16.48it/s] 91%|█████████ | 456/500 [00:27<00:02, 16.54it/s] 92%|█████████▏| 458/500 [00:27<00:02, 16.57it/s] 92%|█████████▏| 460/500 [00:27<00:02, 16.59it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.57it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.61it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.57it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.60it/s] 94%|█████████▍| 470/500 [00:28<00:01, 16.59it/s] 94%|█████████▍| 472/500 [00:28<00:01, 16.56it/s] 95%|█████████▍| 474/500 [00:28<00:01, 16.54it/s] 95%|█████████▌| 476/500 [00:28<00:01, 16.50it/s] 96%|█████████▌| 478/500 [00:28<00:01, 16.51it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.49it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.48it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.50it/s] 97%|█████████▋| 486/500 [00:29<00:00, 16.52it/s] 98%|█████████▊| 488/500 [00:29<00:00, 16.51it/s] 98%|█████████▊| 490/500 [00:29<00:00, 16.50it/s] 98%|█████████▊| 492/500 [00:29<00:00, 16.49it/s] 99%|█████████▉| 494/500 [00:29<00:00, 16.53it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.57it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.52it/s]100%|██████████| 500/500 [00:30<00:00, 16.50it/s]100%|██████████| 500/500 [00:30<00:00, 16.49it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  3
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<50:53,  6.12s/it]  1%|          | 3/500 [00:06<13:34,  1.64s/it]  1%|          | 5/500 [00:06<06:50,  1.21it/s]  1%|▏         | 7/500 [00:06<04:09,  1.98it/s]  2%|▏         | 9/500 [00:06<02:46,  2.95it/s]  2%|▏         | 11/500 [00:12<10:38,  1.31s/it]  3%|▎         | 13/500 [00:12<07:15,  1.12it/s]  3%|▎         | 15/500 [00:13<05:04,  1.59it/s]  3%|▎         | 17/500 [00:13<03:37,  2.22it/s]  4%|▍         | 19/500 [00:13<02:38,  3.03it/s]  4%|▍         | 21/500 [00:19<09:22,  1.17s/it]  5%|▍         | 23/500 [00:19<06:39,  1.19it/s]  5%|▌         | 25/500 [00:19<04:46,  1.66it/s]  5%|▌         | 27/500 [00:19<03:28,  2.27it/s]  6%|▌         | 29/500 [00:20<02:34,  3.06it/s]  6%|▌         | 31/500 [00:26<09:06,  1.16s/it]  7%|▋         | 33/500 [00:26<06:32,  1.19it/s]  7%|▋         | 35/500 [00:26<04:42,  1.65it/s]  7%|▋         | 37/500 [00:26<03:25,  2.25it/s]  8%|▊         | 39/500 [00:26<02:32,  3.02it/s]  8%|▊         | 41/500 [00:32<08:47,  1.15s/it]  9%|▊         | 43/500 [00:33<06:17,  1.21it/s]  9%|▉         | 45/500 [00:33<04:31,  1.68it/s]  9%|▉         | 47/500 [00:33<03:18,  2.29it/s] 10%|▉         | 49/500 [00:33<02:26,  3.07it/s] 10%|█         | 51/500 [00:39<08:43,  1.17s/it] 11%|█         | 53/500 [00:39<06:14,  1.19it/s] 11%|█         | 55/500 [00:40<04:29,  1.65it/s] 11%|█▏        | 57/500 [00:40<03:16,  2.26it/s] 12%|█▏        | 59/500 [00:40<02:25,  3.03it/s] 12%|█▏        | 61/500 [00:46<08:32,  1.17s/it] 13%|█▎        | 63/500 [00:46<06:06,  1.19it/s] 13%|█▎        | 65/500 [00:46<04:23,  1.65it/s] 13%|█▎        | 67/500 [00:46<03:12,  2.25it/s] 14%|█▍        | 69/500 [00:47<02:22,  3.03it/s] 14%|█▍        | 71/500 [00:53<08:18,  1.16s/it]Epoch:  1  	Training Loss: 0.0912899374961853
Test Loss:  141.68154907226562
Valid Loss:  142.15249633789062
Epoch:  2  	Training Loss: 140.20828247070312
Test Loss:  0.19882193207740784
Valid Loss:  0.20189663767814636
Epoch:  3  	Training Loss: 0.16981300711631775
Test Loss:  0.19072553515434265
Valid Loss:  0.19365651905536652
Epoch:  4  	Training Loss: 0.1626577079296112
Test Loss:  0.18301141262054443
Valid Loss:  0.18580381572246552
Epoch:  5  	Training Loss: 0.155853271484375
Test Loss:  0.17566034197807312
Valid Loss:  0.17831909656524658
Epoch:  6  	Training Loss: 0.14938166737556458
Test Loss:  0.16865411400794983
Valid Loss:  0.17118404805660248
Epoch:  7  	Training Loss: 0.14322586357593536
Test Loss:  0.16197553277015686
Valid Loss:  0.16438117623329163
Epoch:  8  	Training Loss: 0.13736969232559204
Test Loss:  0.15560828149318695
Valid Loss:  0.1578940749168396
Epoch:  9  	Training Loss: 0.1317979097366333
Test Loss:  0.14953690767288208
Valid Loss:  0.15170708298683167
Epoch:  10  	Training Loss: 0.12649601697921753
Test Loss:  0.1437467783689499
Valid Loss:  0.14580540359020233
Epoch:  11  	Training Loss: 0.12145034223794937
Test Loss:  0.13822399079799652
Valid Loss:  0.140174999833107
Epoch:  12  	Training Loss: 0.11664791405200958
Test Loss:  0.13375718891620636
Valid Loss:  0.1356184482574463
Epoch:  13  	Training Loss: 0.11275622248649597
Test Loss:  0.12946581840515137
Valid Loss:  0.1312398761510849
Epoch:  14  	Training Loss: 0.10902521759271622
Test Loss:  0.12534263730049133
Valid Loss:  0.12703195214271545
Epoch:  15  	Training Loss: 0.10544805228710175
Test Loss:  0.12138079106807709
Valid Loss:  0.12298773974180222
Epoch:  16  	Training Loss: 0.10201825201511383
Test Loss:  0.11757360398769379
Valid Loss:  0.11910051107406616
Epoch:  17  	Training Loss: 0.09872952848672867
Test Loss:  0.11391472816467285
Valid Loss:  0.11536388099193573
Epoch:  18  	Training Loss: 0.09557591378688812
Test Loss:  0.11039812117815018
Valid Loss:  0.11177168786525726
Epoch:  19  	Training Loss: 0.09255169332027435
Test Loss:  0.10701794922351837
Valid Loss:  0.10831806063652039
Epoch:  20  	Training Loss: 0.08965137600898743
Test Loss:  0.10376861691474915
Valid Loss:  0.10499733686447144
Epoch:  21  	Training Loss: 0.08686971664428711
Test Loss:  0.1006448045372963
Valid Loss:  0.10180414468050003
Epoch:  22  	Training Loss: 0.08420172333717346
Test Loss:  0.09763526916503906
Valid Loss:  0.0987270399928093
Epoch:  23  	Training Loss: 0.08163729310035706
Test Loss:  0.0947418138384819
Valid Loss:  0.09576791524887085
Epoch:  24  	Training Loss: 0.07917764782905579
Test Loss:  0.09195969253778458
Valid Loss:  0.09292197972536087
Epoch:  25  	Training Loss: 0.07681833207607269
Test Loss:  0.08928434550762177
Valid Loss:  0.09018462151288986
Epoch:  26  	Training Loss: 0.07455509901046753
Test Loss:  0.08671142160892487
Valid Loss:  0.08755142986774445
Epoch:  27  	Training Loss: 0.07238385826349258
Test Loss:  0.08423671126365662
Valid Loss:  0.08501818031072617
Epoch:  28  	Training Loss: 0.07030070573091507
Test Loss:  0.08185625076293945
Valid Loss:  0.0825808122754097
Epoch:  29  	Training Loss: 0.06830190122127533
Test Loss:  0.07956618070602417
Valid Loss:  0.08023545145988464
Epoch:  30  	Training Loss: 0.06638389825820923
Test Loss:  0.07736282050609589
Valid Loss:  0.07797837257385254
Epoch:  31  	Training Loss: 0.0645432397723198
Test Loss:  0.07524266839027405
Valid Loss:  0.07580602169036865
Epoch:  32  	Training Loss: 0.06277667731046677
Test Loss:  0.07319393754005432
Valid Loss:  0.07370635122060776
Epoch:  33  	Training Loss: 0.06107409670948982
Test Loss:  0.07122227549552917
Valid Loss:  0.07168518751859665
Epoch:  34  	Training Loss: 0.059439897537231445
Test Loss:  0.0693245530128479
Valid Loss:  0.06973938643932343
Epoch:  35  	Training Loss: 0.05787118524312973
Test Loss:  0.06749780476093292
Valid Loss:  0.06786590814590454
Epoch:  36  	Training Loss: 0.05636519566178322
Test Loss:  0.06573915481567383
Valid Loss:  0.06606186926364899
Epoch:  37  	Training Loss: 0.0549192875623703
Test Loss:  0.06404584646224976
Valid Loss:  0.06432446837425232
Epoch:  38  	Training Loss: 0.053530916571617126
Test Loss:  0.06241527572274208
Valid Loss:  0.06265106797218323
Epoch:  39  	Training Loss: 0.0521976612508297
Test Loss:  0.06084492430090904
Valid Loss:  0.06103910505771637
Epoch:  40  	Training Loss: 0.05091719329357147
Test Loss:  0.05933235585689545
Valid Loss:  0.05948611721396446
Epoch:  41  	Training Loss: 0.04968728870153427
Test Loss:  0.05787527188658714
Valid Loss:  0.05798976868391037
Epoch:  42  	Training Loss: 0.04850582778453827
Test Loss:  0.056458860635757446
Valid Loss:  0.05653494969010353
Epoch:  43  	Training Loss: 0.0473606213927269
Test Loss:  0.055093973875045776
Valid Loss:  0.055132754147052765
Epoch:  44  	Training Loss: 0.046260230243206024
Test Loss:  0.053778596222400665
Valid Loss:  0.053781136870384216
Epoch:  45  	Training Loss: 0.04520277678966522
Test Loss:  0.05251075327396393
Valid Loss:  0.05247809737920761
Epoch:  46  	Training Loss: 0.04418647661805153
Test Loss:  0.05128857120871544
Valid Loss:  0.05122174695134163
Epoch:  47  	Training Loss: 0.04320961609482765
Test Loss:  0.05011024698615074
Valid Loss:  0.05001024529337883
Epoch:  48  	Training Loss: 0.042270541191101074
Test Loss:  0.04897405579686165
Valid Loss:  0.04884183779358864
Epoch:  49  	Training Loss: 0.04136768728494644
Test Loss:  0.047878339886665344
Valid Loss:  0.04771484434604645
Epoch:  50  	Training Loss: 0.04049953445792198
Test Loss:  0.04682149738073349
Valid Loss:  0.04662763327360153
Epoch:  51  	Training Loss: 0.03966463357210159
Test Loss:  0.045802004635334015
Valid Loss:  0.04557867348194122
Epoch:  52  	Training Loss: 0.038861602544784546
Test Loss:  0.04478878527879715
Valid Loss:  0.0445362813770771
Epoch:  53  	Training Loss: 0.03806566447019577
Test Loss:  0.04381212964653969
Valid Loss:  0.04353133589029312
Epoch:  54  	Training Loss: 0.0373007170855999
Test Loss:  0.04287053644657135
Valid Loss:  0.042562320828437805
Epoch:  55  	Training Loss: 0.03656540811061859
Test Loss:  0.041962578892707825
Valid Loss:  0.04162778705358505
Epoch:  56  	Training Loss: 0.03585847467184067
Test Loss:  0.041086915880441666
Valid Loss:  0.040726374834775925
Epoch:  57  	Training Loss: 0.03517868369817734
Test Loss:  0.040242232382297516
Valid Loss:  0.03985673934221268
Epoch:  58  	Training Loss: 0.03452486917376518
Test Loss:  0.03942728787660599
Valid Loss:  0.03901762515306473
Epoch:  59  	Training Loss: 0.03389592468738556
Test Loss:  0.03864087909460068
Valid Loss:  0.03820779547095299
Epoch:  60  	Training Loss: 0.033290766179561615
Test Loss:  0.03788186237215996
Valid Loss:  0.03742610663175583
Epoch:  61  	Training Loss: 0.032708391547203064
Test Loss:  0.03714914619922638
Valid Loss:  0.03667141869664192
Epoch:  62  	Training Loss: 0.03214780241250992
Test Loss:  0.03638415038585663
Valid Loss:  0.035883523523807526
Epoch:  63  	Training Loss: 0.031564146280288696
Test Loss:  0.03564739599823952
Valid Loss:  0.035124652087688446
Epoch:  64  	Training Loss: 0.031003734096884727
Test Loss:  0.03493763506412506
Valid Loss:  0.03441512584686279
Epoch:  65  	Training Loss: 0.030486902222037315
Test Loss:  0.034312158823013306
Valid Loss:  0.033835865557193756
Epoch:  66  	Training Loss: 0.030054448172450066
Test Loss:  0.03378427028656006
Valid Loss:  0.03335883095860481
Epoch:  67  	Training Loss: 0.029692605137825012
Test Loss:  0.03340865671634674
Valid Loss:  0.032966889441013336
Epoch:  68  	Training Loss: 0.02940382994711399
Test Loss:  0.03315146267414093
Valid Loss:  0.032649848610162735
Epoch:  69  	Training Loss: 0.02918054163455963
Test Loss:  0.032959338277578354
Valid Loss:  0.032379478216171265
Epoch:  70  	Training Loss: 0.028995752334594727
Test Loss:  0.03279221057891846
Valid Loss:  0.03216274827718735
Epoch:  71  	Training Loss: 0.028840558603405952
Test Loss:  0.032670531421899796
Valid Loss:  0.03199026361107826
Epoch:  72  	Training Loss: 0.028707584366202354
Test Loss:  0.03258948028087616
Valid Loss:  0.03186959773302078
Epoch:  73  	Training Loss: 0.02860688418149948
 15%|█▍        | 73/500 [00:53<05:56,  1.20it/s] 15%|█▌        | 75/500 [00:53<04:16,  1.66it/s] 15%|█▌        | 77/500 [00:53<03:07,  2.26it/s] 16%|█▌        | 79/500 [00:53<02:18,  3.04it/s] 16%|█▌        | 81/500 [01:00<08:08,  1.17s/it] 17%|█▋        | 83/500 [01:00<05:49,  1.19it/s] 17%|█▋        | 85/500 [01:00<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:00<03:02,  2.26it/s] 18%|█▊        | 89/500 [01:00<02:15,  3.04it/s] 18%|█▊        | 91/500 [01:06<07:56,  1.17s/it] 19%|█▊        | 93/500 [01:06<05:41,  1.19it/s] 19%|█▉        | 95/500 [01:07<04:05,  1.65it/s] 19%|█▉        | 97/500 [01:07<02:58,  2.25it/s] 20%|█▉        | 99/500 [01:07<02:12,  3.03it/s] 20%|██        | 101/500 [01:13<07:37,  1.15s/it] 21%|██        | 103/500 [01:13<05:27,  1.21it/s] 21%|██        | 105/500 [01:13<03:55,  1.68it/s] 21%|██▏       | 107/500 [01:13<02:51,  2.29it/s] 22%|██▏       | 109/500 [01:13<02:07,  3.07it/s] 22%|██▏       | 111/500 [01:20<07:31,  1.16s/it] 23%|██▎       | 113/500 [01:20<05:22,  1.20it/s] 23%|██▎       | 115/500 [01:20<03:51,  1.66it/s] 23%|██▎       | 117/500 [01:20<02:48,  2.27it/s] 24%|██▍       | 119/500 [01:20<02:04,  3.05it/s] 24%|██▍       | 121/500 [01:26<07:17,  1.15s/it] 25%|██▍       | 123/500 [01:27<05:12,  1.21it/s] 25%|██▌       | 125/500 [01:27<03:44,  1.67it/s] 25%|██▌       | 127/500 [01:27<02:43,  2.28it/s] 26%|██▌       | 129/500 [01:27<02:01,  3.06it/s] 26%|██▌       | 131/500 [01:33<07:08,  1.16s/it] 27%|██▋       | 133/500 [01:33<05:06,  1.20it/s] 27%|██▋       | 135/500 [01:33<03:40,  1.66it/s] 27%|██▋       | 137/500 [01:34<02:40,  2.26it/s] 28%|██▊       | 139/500 [01:34<01:58,  3.04it/s] 28%|██▊       | 141/500 [01:40<06:53,  1.15s/it] 29%|██▊       | 143/500 [01:40<04:55,  1.21it/s]Test Loss:  0.03252290189266205
Valid Loss:  0.03176993876695633
Epoch:  74  	Training Loss: 0.02852107211947441
Test Loss:  0.03246229141950607
Valid Loss:  0.031691547483205795
Epoch:  75  	Training Loss: 0.028446316719055176
Test Loss:  0.0324072502553463
Valid Loss:  0.03162319213151932
Epoch:  76  	Training Loss: 0.028385229408740997
Test Loss:  0.03236157447099686
Valid Loss:  0.031571634113788605
Epoch:  77  	Training Loss: 0.028339533135294914
Test Loss:  0.03231937438249588
Valid Loss:  0.03152710944414139
Epoch:  78  	Training Loss: 0.028300445526838303
Test Loss:  0.03228414058685303
Valid Loss:  0.031489044427871704
Epoch:  79  	Training Loss: 0.028268735855817795
Test Loss:  0.032255545258522034
Valid Loss:  0.03145573288202286
Epoch:  80  	Training Loss: 0.028241772204637527
Test Loss:  0.0322272926568985
Valid Loss:  0.03142554312944412
Epoch:  81  	Training Loss: 0.028216321021318436
Test Loss:  0.03220261633396149
Valid Loss:  0.03140003979206085
Epoch:  82  	Training Loss: 0.02819434180855751
Test Loss:  0.03217882290482521
Valid Loss:  0.03137792646884918
Epoch:  83  	Training Loss: 0.028173182159662247
Test Loss:  0.03215526416897774
Valid Loss:  0.03135602921247482
Epoch:  84  	Training Loss: 0.02815258502960205
Test Loss:  0.03213375061750412
Valid Loss:  0.031335387378931046
Epoch:  85  	Training Loss: 0.028132949024438858
Test Loss:  0.03211604431271553
Valid Loss:  0.03131494298577309
Epoch:  86  	Training Loss: 0.028113463893532753
Test Loss:  0.03209942579269409
Valid Loss:  0.03129567578434944
Epoch:  87  	Training Loss: 0.0280955508351326
Test Loss:  0.032085075974464417
Valid Loss:  0.031279485672712326
Epoch:  88  	Training Loss: 0.02808035910129547
Test Loss:  0.03207151219248772
Valid Loss:  0.03126436471939087
Epoch:  89  	Training Loss: 0.028065785765647888
Test Loss:  0.03205800801515579
Valid Loss:  0.031249327585101128
Epoch:  90  	Training Loss: 0.028051581233739853
Test Loss:  0.03204525262117386
Valid Loss:  0.031235914677381516
Epoch:  91  	Training Loss: 0.02803800068795681
Test Loss:  0.03203324228525162
Valid Loss:  0.031225143000483513
Epoch:  92  	Training Loss: 0.02802485227584839
Test Loss:  0.03202025592327118
Valid Loss:  0.031213611364364624
Epoch:  93  	Training Loss: 0.028011279180645943
Test Loss:  0.03200872987508774
Valid Loss:  0.03120388463139534
Epoch:  94  	Training Loss: 0.027998361736536026
Test Loss:  0.0319972038269043
Valid Loss:  0.03119479864835739
Epoch:  95  	Training Loss: 0.027985459193587303
Test Loss:  0.03198571503162384
Valid Loss:  0.031185735017061234
Epoch:  96  	Training Loss: 0.027972685173153877
Test Loss:  0.03197493404150009
Valid Loss:  0.031177252531051636
Epoch:  97  	Training Loss: 0.027960270643234253
Test Loss:  0.03196416050195694
Valid Loss:  0.031168777495622635
Epoch:  98  	Training Loss: 0.027947865426540375
Test Loss:  0.03195339813828468
Valid Loss:  0.03116030991077423
Epoch:  99  	Training Loss: 0.027935480698943138
Test Loss:  0.031943440437316895
Valid Loss:  0.031151847913861275
Epoch:  100  	Training Loss: 0.0279231034219265
Test Loss:  0.031933508813381195
Valid Loss:  0.031143397092819214
Epoch:  101  	Training Loss: 0.02791074477136135
Test Loss:  0.03192358836531639
Valid Loss:  0.03113510087132454
Epoch:  102  	Training Loss: 0.027898402884602547
Test Loss:  0.031913530081510544
Valid Loss:  0.03112734854221344
Epoch:  103  	Training Loss: 0.02788577973842621
Test Loss:  0.03190348669886589
Valid Loss:  0.031119609251618385
Epoch:  104  	Training Loss: 0.027873173356056213
Test Loss:  0.031893447041511536
Valid Loss:  0.03111187182366848
Epoch:  105  	Training Loss: 0.02786058373749256
Test Loss:  0.031883418560028076
Valid Loss:  0.03110414370894432
Epoch:  106  	Training Loss: 0.0278480127453804
Test Loss:  0.03187388554215431
Valid Loss:  0.03109642304480076
Epoch:  107  	Training Loss: 0.027835454791784286
Test Loss:  0.03186463564634323
Valid Loss:  0.031088709831237793
Epoch:  108  	Training Loss: 0.027823062613606453
Test Loss:  0.03185626491904259
Valid Loss:  0.031081873923540115
Epoch:  109  	Training Loss: 0.027811232954263687
Test Loss:  0.031848326325416565
Valid Loss:  0.031075462698936462
Epoch:  110  	Training Loss: 0.027799662202596664
Test Loss:  0.03184082359075546
Valid Loss:  0.03106950782239437
Epoch:  111  	Training Loss: 0.027788221836090088
Test Loss:  0.03183331713080406
Valid Loss:  0.031063811853528023
Epoch:  112  	Training Loss: 0.0277768075466156
Test Loss:  0.03182573616504669
Valid Loss:  0.031058061867952347
Epoch:  113  	Training Loss: 0.027765236794948578
Test Loss:  0.03181815892457962
Valid Loss:  0.03105231188237667
Epoch:  114  	Training Loss: 0.027753712609410286
Test Loss:  0.03181101381778717
Valid Loss:  0.031046880409121513
Epoch:  115  	Training Loss: 0.02774231694638729
Test Loss:  0.03180386871099472
Valid Loss:  0.031041454523801804
Epoch:  116  	Training Loss: 0.02773096226155758
Test Loss:  0.03179670870304108
Valid Loss:  0.031036019325256348
Epoch:  117  	Training Loss: 0.0277196504175663
Test Loss:  0.03178998455405235
Valid Loss:  0.031030915677547455
Epoch:  118  	Training Loss: 0.02770843543112278
Test Loss:  0.03178326040506363
Valid Loss:  0.031025798991322517
Epoch:  119  	Training Loss: 0.027697259560227394
Test Loss:  0.03177652508020401
Valid Loss:  0.031020689755678177
Epoch:  120  	Training Loss: 0.02768613025546074
Test Loss:  0.0317697748541832
Valid Loss:  0.031015563756227493
Epoch:  121  	Training Loss: 0.02767503261566162
Test Loss:  0.031763024628162384
Valid Loss:  0.031010450795292854
Epoch:  122  	Training Loss: 0.027663981541991234
Test Loss:  0.03175632655620575
Valid Loss:  0.0310053788125515
Epoch:  123  	Training Loss: 0.02765301614999771
Test Loss:  0.031749628484249115
Valid Loss:  0.031000304967164993
Epoch:  124  	Training Loss: 0.02764209173619747
Test Loss:  0.031742919236421585
Valid Loss:  0.030995238572359085
Epoch:  125  	Training Loss: 0.027631204575300217
Test Loss:  0.03173620253801346
Valid Loss:  0.030990149825811386
Epoch:  126  	Training Loss: 0.027620352804660797
Test Loss:  0.03172946721315384
Valid Loss:  0.030985062941908836
Epoch:  127  	Training Loss: 0.027609538286924362
Test Loss:  0.03172272816300392
Valid Loss:  0.030979974195361137
Epoch:  128  	Training Loss: 0.027598777785897255
Test Loss:  0.03171643987298012
Valid Loss:  0.03097521699965
Epoch:  129  	Training Loss: 0.02758808434009552
Test Loss:  0.03171014040708542
Valid Loss:  0.030970457941293716
Epoch:  130  	Training Loss: 0.027577433735132217
Test Loss:  0.03170382231473923
Valid Loss:  0.030965691432356834
Epoch:  131  	Training Loss: 0.027566824108362198
Test Loss:  0.031697504222393036
Valid Loss:  0.030960917472839355
Epoch:  132  	Training Loss: 0.02755625545978546
Test Loss:  0.031691137701272964
Valid Loss:  0.030956100672483444
Epoch:  133  	Training Loss: 0.027545694261789322
Test Loss:  0.03168477118015289
Valid Loss:  0.030951283872127533
Epoch:  134  	Training Loss: 0.027535177767276764
Test Loss:  0.03167838603258133
Valid Loss:  0.030946459621191025
Epoch:  135  	Training Loss: 0.02752469852566719
Test Loss:  0.03167198970913887
Valid Loss:  0.030941622331738472
Epoch:  136  	Training Loss: 0.027514249086380005
Test Loss:  0.031665585935115814
Valid Loss:  0.03093678504228592
Epoch:  137  	Training Loss: 0.02750384248793125
Test Loss:  0.031659163534641266
Valid Loss:  0.03093194216489792
Epoch:  138  	Training Loss: 0.027493471279740334
Test Loss:  0.03165273740887642
Valid Loss:  0.030927088111639023
Epoch:  139  	Training Loss: 0.027483131736516953
Test Loss:  0.03164630010724068
Valid Loss:  0.03092222288250923
Epoch:  140  	Training Loss: 0.027472825720906258
Test Loss:  0.03163984417915344
Valid Loss:  0.03091735951602459
Epoch:  141  	Training Loss: 0.027462560683488846
Test Loss:  0.03163386136293411
Valid Loss:  0.0309128500521183
Epoch:  142  	Training Loss: 0.027452372014522552
Test Loss:  0.03162796050310135
Valid Loss:  0.03090841695666313
Epoch:  143  	Training Loss: 0.02744229882955551
Test Loss:  0.031622059643268585
Valid Loss:  0.03090398572385311
Epoch:  144  	Training Loss: 0.027432268485426903
Test Loss:  0.03161613643169403
 29%|██▉       | 145/500 [01:40<03:32,  1.67it/s] 29%|██▉       | 147/500 [01:40<02:34,  2.28it/s] 30%|██▉       | 149/500 [01:40<01:54,  3.06it/s] 30%|███       | 151/500 [01:47<06:44,  1.16s/it] 31%|███       | 153/500 [01:47<04:48,  1.20it/s] 31%|███       | 155/500 [01:47<03:27,  1.66it/s] 31%|███▏      | 157/500 [01:47<02:31,  2.27it/s] 32%|███▏      | 159/500 [01:47<01:52,  3.04it/s] 32%|███▏      | 161/500 [01:54<07:24,  1.31s/it] 33%|███▎      | 163/500 [01:54<05:16,  1.06it/s] 33%|███▎      | 165/500 [01:55<03:46,  1.48it/s] 33%|███▎      | 167/500 [01:55<02:44,  2.02it/s] 34%|███▍      | 169/500 [01:55<02:01,  2.72it/s] 34%|███▍      | 171/500 [02:01<06:33,  1.20s/it] 35%|███▍      | 173/500 [02:01<04:40,  1.16it/s] 35%|███▌      | 175/500 [02:01<03:21,  1.61it/s] 35%|███▌      | 177/500 [02:01<02:26,  2.20it/s] 36%|███▌      | 179/500 [02:02<01:48,  2.97it/s] 36%|███▌      | 181/500 [02:08<06:13,  1.17s/it] 37%|███▋      | 183/500 [02:08<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:08<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:08<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:08<01:43,  3.02it/s] 38%|███▊      | 191/500 [02:15<05:59,  1.16s/it] 39%|███▊      | 193/500 [02:15<04:16,  1.20it/s] 39%|███▉      | 195/500 [02:15<03:04,  1.65it/s] 39%|███▉      | 197/500 [02:15<02:14,  2.26it/s] 40%|███▉      | 199/500 [02:15<01:39,  3.03it/s] 40%|████      | 201/500 [02:21<05:49,  1.17s/it] 41%|████      | 203/500 [02:22<04:09,  1.19it/s] 41%|████      | 205/500 [02:22<02:59,  1.64it/s] 41%|████▏     | 207/500 [02:22<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:22<01:36,  3.02it/s] 42%|████▏     | 211/500 [02:28<05:34,  1.16s/it] 43%|████▎     | 213/500 [02:28<03:58,  1.20it/s]Valid Loss:  0.030899588018655777
Epoch:  145  	Training Loss: 0.027422277256846428
Test Loss:  0.03161019831895828
Valid Loss:  0.030895210802555084
Epoch:  146  	Training Loss: 0.027412325143814087
Test Loss:  0.03160424903035164
Valid Loss:  0.030890824273228645
Epoch:  147  	Training Loss: 0.027402404695749283
Test Loss:  0.0315982848405838
Valid Loss:  0.030886448919773102
Epoch:  148  	Training Loss: 0.027392525225877762
Test Loss:  0.031592316925525665
Valid Loss:  0.03088206797838211
Epoch:  149  	Training Loss: 0.027382679283618927
Test Loss:  0.03158632665872574
Valid Loss:  0.030877694487571716
Epoch:  150  	Training Loss: 0.027372870594263077
Test Loss:  0.03158031776547432
Valid Loss:  0.030873309820890427
Epoch:  151  	Training Loss: 0.027363091707229614
Test Loss:  0.0315743014216423
Valid Loss:  0.030868930742144585
Epoch:  152  	Training Loss: 0.027353346347808838
Test Loss:  0.03156827390193939
Valid Loss:  0.0308645348995924
Epoch:  153  	Training Loss: 0.0273436289280653
Test Loss:  0.03156222403049469
Valid Loss:  0.030860137194395065
Epoch:  154  	Training Loss: 0.027333945035934448
Test Loss:  0.03155616298317909
Valid Loss:  0.03085574321448803
Epoch:  155  	Training Loss: 0.027324292808771133
Test Loss:  0.0315500944852829
Valid Loss:  0.0308513343334198
Epoch:  156  	Training Loss: 0.027314668521285057
Test Loss:  0.031543999910354614
Valid Loss:  0.03084692731499672
Epoch:  157  	Training Loss: 0.02730506844818592
Test Loss:  0.031537897884845734
Valid Loss:  0.030842525884509087
Epoch:  158  	Training Loss: 0.027295514941215515
Test Loss:  0.03153228759765625
Valid Loss:  0.030838392674922943
Epoch:  159  	Training Loss: 0.02728603407740593
Test Loss:  0.03152666240930557
Valid Loss:  0.0308342594653368
Epoch:  160  	Training Loss: 0.02727658860385418
Test Loss:  0.0315210185945034
Valid Loss:  0.030830122530460358
Epoch:  161  	Training Loss: 0.027267180383205414
Test Loss:  0.03151535615324974
Valid Loss:  0.030825980007648468
Epoch:  162  	Training Loss: 0.027257803827524185
Test Loss:  0.03150976449251175
Valid Loss:  0.03082190454006195
Epoch:  163  	Training Loss: 0.027248524129390717
Test Loss:  0.031504154205322266
Valid Loss:  0.030817821621894836
Epoch:  164  	Training Loss: 0.027239277958869934
Test Loss:  0.03149852901697159
Valid Loss:  0.03081374615430832
Epoch:  165  	Training Loss: 0.027230065315961838
Test Loss:  0.03149288892745972
Valid Loss:  0.030809665098786354
Epoch:  166  	Training Loss: 0.02722088061273098
Test Loss:  0.03148723766207695
Valid Loss:  0.030805576592683792
Epoch:  167  	Training Loss: 0.027211729437112808
Test Loss:  0.03148156404495239
Valid Loss:  0.030801482498645782
Epoch:  168  	Training Loss: 0.027202606201171875
Test Loss:  0.03147587925195694
Valid Loss:  0.03079739399254322
Epoch:  169  	Training Loss: 0.02719351463019848
Test Loss:  0.03147017955780029
Valid Loss:  0.030793296173214912
Epoch:  170  	Training Loss: 0.027184447273612022
Test Loss:  0.031464457511901855
Valid Loss:  0.030789190903306007
Epoch:  171  	Training Loss: 0.027175407856702805
Test Loss:  0.03145872801542282
Valid Loss:  0.0307850893586874
Epoch:  172  	Training Loss: 0.027166403830051422
Test Loss:  0.031453609466552734
Valid Loss:  0.030781354755163193
Epoch:  173  	Training Loss: 0.027157554402947426
Test Loss:  0.03144846111536026
Valid Loss:  0.030777614563703537
Epoch:  174  	Training Loss: 0.02714873105287552
Test Loss:  0.03144330158829689
Valid Loss:  0.03077387623488903
Epoch:  175  	Training Loss: 0.027139946818351746
Test Loss:  0.03143816441297531
Valid Loss:  0.030770134180784225
Epoch:  176  	Training Loss: 0.02713119611144066
Test Loss:  0.03143303096294403
Valid Loss:  0.030766384676098824
Epoch:  177  	Training Loss: 0.027122467756271362
Test Loss:  0.03142789378762245
Valid Loss:  0.030762629583477974
Epoch:  178  	Training Loss: 0.02711378037929535
Test Loss:  0.03142274543642998
Valid Loss:  0.030758868902921677
Epoch:  179  	Training Loss: 0.027105119079351425
Test Loss:  0.031418003141880035
Valid Loss:  0.03075540065765381
Epoch:  180  	Training Loss: 0.02709650620818138
Test Loss:  0.03141282871365547
Valid Loss:  0.030751628801226616
Epoch:  181  	Training Loss: 0.027087930589914322
Test Loss:  0.031408071517944336
Valid Loss:  0.0307481586933136
Epoch:  182  	Training Loss: 0.027079390361905098
Test Loss:  0.03140324726700783
Valid Loss:  0.030744614079594612
Epoch:  183  	Training Loss: 0.027070840820670128
Test Loss:  0.031398411840200424
Valid Loss:  0.030741067603230476
Epoch:  184  	Training Loss: 0.027062324807047844
Test Loss:  0.031393565237522125
Valid Loss:  0.03073751926422119
Epoch:  185  	Training Loss: 0.027053844183683395
Test Loss:  0.03138870745897293
Valid Loss:  0.03073396161198616
Epoch:  186  	Training Loss: 0.027045398950576782
Test Loss:  0.03138384222984314
Valid Loss:  0.03073040023446083
Epoch:  187  	Training Loss: 0.027036983519792557
Test Loss:  0.031378962099552155
Valid Loss:  0.0307268388569355
Epoch:  188  	Training Loss: 0.027028601616621017
Test Loss:  0.031374070793390274
Valid Loss:  0.030723262578248978
Epoch:  189  	Training Loss: 0.027020253241062164
Test Loss:  0.031369175761938095
Valid Loss:  0.030719690024852753
Epoch:  190  	Training Loss: 0.0270119346678257
Test Loss:  0.03136426955461502
Valid Loss:  0.03071611002087593
Epoch:  191  	Training Loss: 0.02700364589691162
Test Loss:  0.03135933727025986
Valid Loss:  0.030712516978383064
Epoch:  192  	Training Loss: 0.026995383203029633
Test Loss:  0.03135448694229126
Valid Loss:  0.030709002166986465
Epoch:  193  	Training Loss: 0.02698720432817936
Test Loss:  0.03134962543845177
Valid Loss:  0.03070547990500927
Epoch:  194  	Training Loss: 0.02697906456887722
Test Loss:  0.0313451923429966
Valid Loss:  0.030702270567417145
Epoch:  195  	Training Loss: 0.026970965787768364
Test Loss:  0.03134073689579964
Valid Loss:  0.030699055641889572
Epoch:  196  	Training Loss: 0.026962898671627045
Test Loss:  0.03133627027273178
Valid Loss:  0.030695829540491104
Epoch:  197  	Training Loss: 0.02695486508309841
Test Loss:  0.03133178874850273
Valid Loss:  0.03069259598851204
Epoch:  198  	Training Loss: 0.026946865022182465
Test Loss:  0.031327299773693085
Valid Loss:  0.030689356848597527
Epoch:  199  	Training Loss: 0.026938894763588905
Test Loss:  0.031322792172431946
Valid Loss:  0.030686108395457268
Epoch:  200  	Training Loss: 0.026930958032608032
Test Loss:  0.03131827339529991
Valid Loss:  0.03068285435438156
Epoch:  201  	Training Loss: 0.026923052966594696
Test Loss:  0.03131374344229698
Valid Loss:  0.03067958354949951
Epoch:  202  	Training Loss: 0.0269151758402586
Test Loss:  0.031309131532907486
Valid Loss:  0.03067624382674694
Epoch:  203  	Training Loss: 0.026907283812761307
Test Loss:  0.031304508447647095
Valid Loss:  0.030672887340188026
Epoch:  204  	Training Loss: 0.02689942717552185
Test Loss:  0.03129987418651581
Valid Loss:  0.030669527128338814
Epoch:  205  	Training Loss: 0.026891591027379036
Test Loss:  0.031295228749513626
Valid Loss:  0.030666157603263855
Epoch:  206  	Training Loss: 0.02688378468155861
Test Loss:  0.03129056468605995
Valid Loss:  0.03066277876496315
Epoch:  207  	Training Loss: 0.02687600627541542
Test Loss:  0.03128588944673538
Valid Loss:  0.0306593906134367
Epoch:  208  	Training Loss: 0.026868252083659172
Test Loss:  0.03128119930624962
Valid Loss:  0.03065599873661995
Epoch:  209  	Training Loss: 0.026860523968935013
Test Loss:  0.03127649798989296
Valid Loss:  0.030652593821287155
Epoch:  210  	Training Loss: 0.026852818205952644
Test Loss:  0.031271785497665405
Valid Loss:  0.030649183318018913
Epoch:  211  	Training Loss: 0.026845138520002365
Test Loss:  0.03126705810427666
Valid Loss:  0.030645767226815224
Epoch:  212  	Training Loss: 0.026837483048439026
Test Loss:  0.03126238286495209
Valid Loss:  0.030642393976449966
Epoch:  213  	Training Loss: 0.026829907670617104
Test Loss:  0.031257688999176025
Valid Loss:  0.030639002099633217
Epoch:  214  	Training Loss: 0.026822349056601524
Test Loss:  0.031252991408109665
Valid Loss:  0.030635612085461617
Epoch:  215  	Training Loss: 0.026814822107553482
Test Loss:   43%|████▎     | 215/500 [02:28<02:51,  1.67it/s] 43%|████▎     | 217/500 [02:28<02:04,  2.27it/s] 44%|████▍     | 219/500 [02:29<01:32,  3.05it/s] 44%|████▍     | 221/500 [02:35<05:22,  1.16s/it] 45%|████▍     | 223/500 [02:35<03:49,  1.20it/s] 45%|████▌     | 225/500 [02:35<02:45,  1.66it/s] 45%|████▌     | 227/500 [02:35<02:00,  2.27it/s] 46%|████▌     | 229/500 [02:35<01:28,  3.06it/s] 46%|████▌     | 231/500 [02:42<05:13,  1.16s/it] 47%|████▋     | 233/500 [02:42<03:43,  1.19it/s] 47%|████▋     | 235/500 [02:42<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:42<01:56,  2.26it/s] 48%|████▊     | 239/500 [02:42<01:26,  3.03it/s] 48%|████▊     | 241/500 [02:48<04:58,  1.15s/it] 49%|████▊     | 243/500 [02:48<03:32,  1.21it/s] 49%|████▉     | 245/500 [02:49<02:32,  1.67it/s] 49%|████▉     | 247/500 [02:49<01:50,  2.28it/s] 50%|████▉     | 249/500 [02:49<01:21,  3.06it/s] 50%|█████     | 251/500 [02:55<04:48,  1.16s/it] 51%|█████     | 253/500 [02:55<03:25,  1.20it/s] 51%|█████     | 255/500 [02:55<02:27,  1.66it/s] 51%|█████▏    | 257/500 [02:55<01:47,  2.27it/s] 52%|█████▏    | 259/500 [02:56<01:19,  3.04it/s] 52%|█████▏    | 261/500 [03:02<04:38,  1.17s/it] 53%|█████▎    | 263/500 [03:02<03:18,  1.19it/s] 53%|█████▎    | 265/500 [03:02<02:22,  1.65it/s] 53%|█████▎    | 267/500 [03:02<01:43,  2.25it/s] 54%|█████▍    | 269/500 [03:02<01:16,  3.03it/s] 54%|█████▍    | 271/500 [03:09<04:32,  1.19s/it] 55%|█████▍    | 273/500 [03:09<03:13,  1.17it/s] 55%|█████▌    | 275/500 [03:09<02:18,  1.62it/s] 55%|█████▌    | 277/500 [03:09<01:40,  2.22it/s] 56%|█████▌    | 279/500 [03:09<01:14,  2.98it/s] 56%|█████▌    | 281/500 [03:15<04:16,  1.17s/it] 57%|█████▋    | 283/500 [03:16<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:16<02:10,  1.65it/s]0.031248275190591812
Valid Loss:  0.03063221275806427
Epoch:  216  	Training Loss: 0.026807311922311783
Test Loss:  0.031243549659848213
Valid Loss:  0.030628805980086327
Epoch:  217  	Training Loss: 0.026799838989973068
Test Loss:  0.031239282339811325
Valid Loss:  0.030625740066170692
Epoch:  218  	Training Loss: 0.02679242193698883
Test Loss:  0.031234994530677795
Valid Loss:  0.030622664839029312
Epoch:  219  	Training Loss: 0.026785030961036682
Test Loss:  0.031230691820383072
Valid Loss:  0.030619574710726738
Epoch:  220  	Training Loss: 0.026777662336826324
Test Loss:  0.031226374208927155
Valid Loss:  0.030616480857133865
Epoch:  221  	Training Loss: 0.026770325377583504
Test Loss:  0.03122204914689064
Valid Loss:  0.030613375827670097
Epoch:  222  	Training Loss: 0.026763007044792175
Test Loss:  0.031217802315950394
Valid Loss:  0.030610350891947746
Epoch:  223  	Training Loss: 0.026755787432193756
Test Loss:  0.03121354430913925
Valid Loss:  0.03060731664299965
Epoch:  224  	Training Loss: 0.026748590171337128
Test Loss:  0.031209275126457214
Valid Loss:  0.030604276806116104
Epoch:  225  	Training Loss: 0.02674141898751259
Test Loss:  0.031204987317323685
Valid Loss:  0.030601222068071365
Epoch:  226  	Training Loss: 0.02673427388072014
Test Loss:  0.03120068460702896
Valid Loss:  0.030598163604736328
Epoch:  227  	Training Loss: 0.02672714740037918
Test Loss:  0.031196365132927895
Valid Loss:  0.030595090240240097
Epoch:  228  	Training Loss: 0.026720039546489716
Test Loss:  0.031192028895020485
Valid Loss:  0.030592001974582672
Epoch:  229  	Training Loss: 0.02671295963227749
Test Loss:  0.03118768520653248
Valid Loss:  0.030588915571570396
Epoch:  230  	Training Loss: 0.026705894619226456
Test Loss:  0.031183315441012383
Valid Loss:  0.03058580309152603
Epoch:  231  	Training Loss: 0.026698848232626915
Test Loss:  0.03117894008755684
Valid Loss:  0.030582688748836517
Epoch:  232  	Training Loss: 0.026691827923059464
Test Loss:  0.031174561008810997
Valid Loss:  0.030579563230276108
Epoch:  233  	Training Loss: 0.0266848374158144
Test Loss:  0.031170163303613663
Valid Loss:  0.030576420947909355
Epoch:  234  	Training Loss: 0.02667786367237568
Test Loss:  0.031165756285190582
Valid Loss:  0.030573349446058273
Epoch:  235  	Training Loss: 0.0266709066927433
Test Loss:  0.03116132877767086
Valid Loss:  0.03057033382356167
Epoch:  236  	Training Loss: 0.026663970202207565
Test Loss:  0.03115689381957054
Valid Loss:  0.030567318201065063
Epoch:  237  	Training Loss: 0.02665705233812332
Test Loss:  0.03115244396030903
Valid Loss:  0.030564291402697563
Epoch:  238  	Training Loss: 0.02665015310049057
Test Loss:  0.031147977337241173
Valid Loss:  0.030561262741684914
Epoch:  239  	Training Loss: 0.026643268764019012
Test Loss:  0.03114349953830242
Valid Loss:  0.030558228492736816
Epoch:  240  	Training Loss: 0.026636403053998947
Test Loss:  0.031139006838202477
Valid Loss:  0.03055519238114357
Epoch:  241  	Training Loss: 0.026629559695720673
Test Loss:  0.031134506687521935
Valid Loss:  0.030552150681614876
Epoch:  242  	Training Loss: 0.026622723788022995
Test Loss:  0.031130023300647736
Valid Loss:  0.03054910898208618
Epoch:  243  	Training Loss: 0.026615934446454048
Test Loss:  0.031125526875257492
Valid Loss:  0.03054606355726719
Epoch:  244  	Training Loss: 0.026609154418110847
Test Loss:  0.03112102672457695
Valid Loss:  0.030543018132448196
Epoch:  245  	Training Loss: 0.026602396741509438
Test Loss:  0.031116507947444916
Valid Loss:  0.030539963394403458
Epoch:  246  	Training Loss: 0.02659565582871437
Test Loss:  0.031111976131796837
Valid Loss:  0.03053690865635872
Epoch:  247  	Training Loss: 0.02658892795443535
Test Loss:  0.031107431277632713
Valid Loss:  0.030533846467733383
Epoch:  248  	Training Loss: 0.02658221311867237
Test Loss:  0.031102878972887993
Valid Loss:  0.030530782416462898
Epoch:  249  	Training Loss: 0.026575513184070587
Test Loss:  0.031098315492272377
Valid Loss:  0.030527718365192413
Epoch:  250  	Training Loss: 0.026568831875920296
Test Loss:  0.031093735247850418
Valid Loss:  0.03052464872598648
Epoch:  251  	Training Loss: 0.02656218409538269
Test Loss:  0.03108963556587696
Valid Loss:  0.03052183985710144
Epoch:  252  	Training Loss: 0.026555605232715607
Test Loss:  0.03108571469783783
Valid Loss:  0.030519187450408936
Epoch:  253  	Training Loss: 0.026549190282821655
Test Loss:  0.031081771478056908
Valid Loss:  0.030516523867845535
Epoch:  254  	Training Loss: 0.026542790234088898
Test Loss:  0.03107782080769539
Valid Loss:  0.030513860285282135
Epoch:  255  	Training Loss: 0.02653641253709793
Test Loss:  0.03107384778559208
Valid Loss:  0.030511192977428436
Epoch:  256  	Training Loss: 0.026530049741268158
Test Loss:  0.031069863587617874
Valid Loss:  0.03050851635634899
Epoch:  257  	Training Loss: 0.026523705571889877
Test Loss:  0.031065866351127625
Valid Loss:  0.030505843460559845
Epoch:  258  	Training Loss: 0.026517381891608238
Test Loss:  0.031061850488185883
Valid Loss:  0.030503153800964355
Epoch:  259  	Training Loss: 0.026511069387197495
Test Loss:  0.031057819724082947
Valid Loss:  0.03050045669078827
Epoch:  260  	Training Loss: 0.026504773646593094
Test Loss:  0.03105376847088337
Valid Loss:  0.03049776516854763
Epoch:  261  	Training Loss: 0.026498494669795036
Test Loss:  0.031049709767103195
Valid Loss:  0.03049505688250065
Epoch:  262  	Training Loss: 0.026492230594158173
Test Loss:  0.03104572370648384
Valid Loss:  0.03049241378903389
Epoch:  263  	Training Loss: 0.02648605965077877
Test Loss:  0.03104172646999359
Valid Loss:  0.030489757657051086
Epoch:  264  	Training Loss: 0.026479901745915413
Test Loss:  0.031037718057632446
Valid Loss:  0.030487101525068283
Epoch:  265  	Training Loss: 0.0264737606048584
Test Loss:  0.03103368915617466
Valid Loss:  0.030484436079859734
Epoch:  266  	Training Loss: 0.02646762877702713
Test Loss:  0.031029649078845978
Valid Loss:  0.030481768772006035
Epoch:  267  	Training Loss: 0.026461513713002205
Test Loss:  0.03102559596300125
Valid Loss:  0.03047909028828144
Epoch:  268  	Training Loss: 0.026455413550138474
Test Loss:  0.031021524220705032
Valid Loss:  0.0304764062166214
Epoch:  269  	Training Loss: 0.026449326425790787
Test Loss:  0.031017445027828217
Valid Loss:  0.03047371841967106
Epoch:  270  	Training Loss: 0.026443256065249443
Test Loss:  0.03101334720849991
Valid Loss:  0.03047102317214012
Epoch:  271  	Training Loss: 0.026437193155288696
Test Loss:  0.031009240075945854
Valid Loss:  0.030468324199318886
Epoch:  272  	Training Loss: 0.026431143283843994
Test Loss:  0.03100511059165001
Valid Loss:  0.03046557493507862
Epoch:  273  	Training Loss: 0.026425104588270187
Test Loss:  0.031000977382063866
Valid Loss:  0.03046282008290291
Epoch:  274  	Training Loss: 0.026419077068567276
Test Loss:  0.03099682368338108
Valid Loss:  0.03046005591750145
Epoch:  275  	Training Loss: 0.02641306072473526
Test Loss:  0.0309926588088274
Valid Loss:  0.03045729547739029
Epoch:  276  	Training Loss: 0.02640705741941929
Test Loss:  0.030988484621047974
Valid Loss:  0.030454520136117935
Epoch:  277  	Training Loss: 0.026401065289974213
Test Loss:  0.030984297394752502
Valid Loss:  0.03045174479484558
Epoch:  278  	Training Loss: 0.026395084336400032
Test Loss:  0.030980095267295837
Valid Loss:  0.03044896200299263
Epoch:  279  	Training Loss: 0.026389116421341896
Test Loss:  0.030975889414548874
Valid Loss:  0.030446181073784828
Epoch:  280  	Training Loss: 0.026383161544799805
Test Loss:  0.03097166121006012
Valid Loss:  0.030443381518125534
Epoch:  281  	Training Loss: 0.02637721598148346
Test Loss:  0.030967924743890762
Valid Loss:  0.03044087626039982
Epoch:  282  	Training Loss: 0.026371361687779427
Test Loss:  0.030964341014623642
Valid Loss:  0.03043849766254425
Epoch:  283  	Training Loss: 0.02636564150452614
Test Loss:  0.030960744246840477
Valid Loss:  0.030436109751462936
Epoch:  284  	Training Loss: 0.026359936222434044
Test Loss:  0.03095712698996067
Valid Loss:  0.030433714389801025
Epoch:  285  	Training Loss: 0.026354245841503143
Test Loss:  0.03095349669456482
Valid Loss:  0.030431311577558517
 57%|█████▋    | 287/500 [03:16<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:16<01:09,  3.02it/s] 58%|█████▊    | 291/500 [03:22<04:11,  1.21s/it] 59%|█████▊    | 293/500 [03:23<02:59,  1.16it/s] 59%|█████▉    | 295/500 [03:23<02:08,  1.60it/s] 59%|█████▉    | 297/500 [03:23<01:32,  2.19it/s] 60%|█████▉    | 299/500 [03:23<01:08,  2.95it/s] 60%|██████    | 301/500 [03:29<03:57,  1.20s/it] 61%|██████    | 303/500 [03:30<02:49,  1.17it/s] 61%|██████    | 305/500 [03:30<02:00,  1.61it/s] 61%|██████▏   | 307/500 [03:30<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:30<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:37<03:56,  1.25s/it] 63%|██████▎   | 313/500 [03:37<02:47,  1.12it/s] 63%|██████▎   | 315/500 [03:37<01:59,  1.55it/s] 63%|██████▎   | 317/500 [03:37<01:26,  2.12it/s] 64%|██████▍   | 319/500 [03:37<01:03,  2.86it/s] 64%|██████▍   | 321/500 [03:44<03:33,  1.19s/it] 65%|██████▍   | 323/500 [03:44<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:44<01:48,  1.62it/s] 65%|██████▌   | 327/500 [03:44<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:44<00:57,  2.97it/s] 66%|██████▌   | 331/500 [03:51<03:24,  1.21s/it] 67%|██████▋   | 333/500 [03:51<02:25,  1.15it/s] 67%|██████▋   | 335/500 [03:51<01:43,  1.59it/s] 67%|██████▋   | 337/500 [03:51<01:14,  2.18it/s] 68%|██████▊   | 339/500 [03:51<00:54,  2.94it/s] 68%|██████▊   | 341/500 [03:57<03:07,  1.18s/it] 69%|██████▊   | 343/500 [03:57<02:13,  1.18it/s] 69%|██████▉   | 345/500 [03:58<01:35,  1.63it/s] 69%|██████▉   | 347/500 [03:58<01:08,  2.23it/s] 70%|██████▉   | 349/500 [03:58<00:50,  2.99it/s] 70%|███████   | 351/500 [04:04<02:53,  1.16s/it] 71%|███████   | 353/500 [04:04<02:02,  1.20it/s] 71%|███████   | 355/500 [04:04<01:27,  1.66it/s]Epoch:  286  	Training Loss: 0.026348572224378586
Test Loss:  0.03095034696161747
Valid Loss:  0.030429191887378693
Epoch:  287  	Training Loss: 0.02634294517338276
Test Loss:  0.030947180464863777
Valid Loss:  0.03042706474661827
Epoch:  288  	Training Loss: 0.026337336748838425
Test Loss:  0.030943993479013443
Valid Loss:  0.030424930155277252
Epoch:  289  	Training Loss: 0.026331748813390732
Test Loss:  0.030940789729356766
Valid Loss:  0.030422784388065338
Epoch:  290  	Training Loss: 0.026326175779104233
Test Loss:  0.030937563627958298
Valid Loss:  0.030420631170272827
Epoch:  291  	Training Loss: 0.026320619508624077
Test Loss:  0.030934318900108337
Valid Loss:  0.03041846491396427
Epoch:  292  	Training Loss: 0.026315081864595413
Test Loss:  0.03093104250729084
Valid Loss:  0.03041626140475273
Epoch:  293  	Training Loss: 0.0263095460832119
Test Loss:  0.030927738174796104
Valid Loss:  0.030414056032896042
Epoch:  294  	Training Loss: 0.026304032653570175
Test Loss:  0.030924422666430473
Valid Loss:  0.03041183203458786
Epoch:  295  	Training Loss: 0.026298532262444496
Test Loss:  0.0309210866689682
Valid Loss:  0.03040960431098938
Epoch:  296  	Training Loss: 0.02629304677248001
Test Loss:  0.030917733907699585
Valid Loss:  0.030407367274165154
Epoch:  297  	Training Loss: 0.02628757432103157
Test Loss:  0.03091435879468918
Valid Loss:  0.03040512651205063
Epoch:  298  	Training Loss: 0.026282118633389473
Test Loss:  0.030910976231098175
Valid Loss:  0.03040287271142006
Epoch:  299  	Training Loss: 0.026276681572198868
Test Loss:  0.030907567590475082
Valid Loss:  0.030400611460208893
Epoch:  300  	Training Loss: 0.02627125382423401
Test Loss:  0.030904147773981094
Valid Loss:  0.03039834275841713
Epoch:  301  	Training Loss: 0.026265840977430344
Test Loss:  0.030900705605745316
Valid Loss:  0.03039606474339962
Epoch:  302  	Training Loss: 0.026260443031787872
Test Loss:  0.030897289514541626
Valid Loss:  0.030393807217478752
Epoch:  303  	Training Loss: 0.026255086064338684
Test Loss:  0.03089386224746704
Valid Loss:  0.030391542240977287
Epoch:  304  	Training Loss: 0.02624974586069584
Test Loss:  0.030890416353940964
Valid Loss:  0.030389269813895226
Epoch:  305  	Training Loss: 0.02624441497027874
Test Loss:  0.030886951833963394
Valid Loss:  0.030386988073587418
Epoch:  306  	Training Loss: 0.026239100843667984
Test Loss:  0.03088347241282463
Valid Loss:  0.030384697020053864
Epoch:  307  	Training Loss: 0.026233797892928123
Test Loss:  0.03087998367846012
Valid Loss:  0.03038240410387516
Epoch:  308  	Training Loss: 0.02622850611805916
Test Loss:  0.03087647631764412
Valid Loss:  0.03038010373711586
Epoch:  309  	Training Loss: 0.02622322551906109
Test Loss:  0.030872954055666924
Valid Loss:  0.030377792194485664
Epoch:  310  	Training Loss: 0.026217982172966003
Test Loss:  0.030869929119944572
Valid Loss:  0.030375782400369644
Epoch:  311  	Training Loss: 0.026212770491838455
Test Loss:  0.03086688555777073
Valid Loss:  0.030373763293027878
Epoch:  312  	Training Loss: 0.0262075737118721
Test Loss:  0.030863910913467407
Valid Loss:  0.030371811240911484
Epoch:  313  	Training Loss: 0.026202458888292313
Test Loss:  0.030860919505357742
Valid Loss:  0.030369851738214493
Epoch:  314  	Training Loss: 0.026197358965873718
Test Loss:  0.030857911333441734
Valid Loss:  0.030367881059646606
Epoch:  315  	Training Loss: 0.02619227021932602
Test Loss:  0.030854880809783936
Valid Loss:  0.030365902930498123
Epoch:  316  	Training Loss: 0.026187200099229813
Test Loss:  0.030851837247610092
Valid Loss:  0.030363911762833595
Epoch:  317  	Training Loss: 0.02618214674293995
Test Loss:  0.030848773196339607
Valid Loss:  0.03036191686987877
Epoch:  318  	Training Loss: 0.02617710456252098
Test Loss:  0.030845683068037033
Valid Loss:  0.0303599052131176
Epoch:  319  	Training Loss: 0.026172077283263206
Test Loss:  0.030842583626508713
Valid Loss:  0.03035788983106613
Epoch:  320  	Training Loss: 0.026167061179876328
Test Loss:  0.0308394618332386
Valid Loss:  0.03035586141049862
Epoch:  321  	Training Loss: 0.02616206184029579
Test Loss:  0.030836327001452446
Valid Loss:  0.030353832989931107
Epoch:  322  	Training Loss: 0.02615707367658615
Test Loss:  0.030833233147859573
Valid Loss:  0.03035183623433113
Epoch:  323  	Training Loss: 0.026152141392230988
Test Loss:  0.030830126255750656
Valid Loss:  0.030349839478731155
Epoch:  324  	Training Loss: 0.026147224009037018
Test Loss:  0.030826998874545097
Valid Loss:  0.030347827821969986
Epoch:  325  	Training Loss: 0.026142317801713943
Test Loss:  0.030823854729533195
Valid Loss:  0.03034580871462822
Epoch:  326  	Training Loss: 0.026137426495552063
Test Loss:  0.0308206956833601
Valid Loss:  0.030343782156705856
Epoch:  327  	Training Loss: 0.02613254263997078
Test Loss:  0.03081751987338066
Valid Loss:  0.030341751873493195
Epoch:  328  	Training Loss: 0.02612767368555069
Test Loss:  0.03081432916224003
Valid Loss:  0.03033970482647419
Epoch:  329  	Training Loss: 0.026122814044356346
Test Loss:  0.030811116099357605
Valid Loss:  0.030337655916810036
Epoch:  330  	Training Loss: 0.026117965579032898
Test Loss:  0.030807897448539734
Valid Loss:  0.030335599556565285
Epoch:  331  	Training Loss: 0.026113133877515793
Test Loss:  0.03080466017127037
Valid Loss:  0.03033353015780449
Epoch:  332  	Training Loss: 0.026108305901288986
Test Loss:  0.030801374465227127
Valid Loss:  0.030331408604979515
Epoch:  333  	Training Loss: 0.026103470474481583
Test Loss:  0.030798081308603287
Valid Loss:  0.030329274013638496
Epoch:  334  	Training Loss: 0.026098648086190224
Test Loss:  0.030794769525527954
Valid Loss:  0.030327141284942627
Epoch:  335  	Training Loss: 0.02609383687376976
Test Loss:  0.03079143911600113
Valid Loss:  0.030324986204504967
Epoch:  336  	Training Loss: 0.026089031249284744
Test Loss:  0.03078809566795826
Valid Loss:  0.030322827398777008
Epoch:  337  	Training Loss: 0.026084236800670624
Test Loss:  0.030784741044044495
Valid Loss:  0.0303206630051136
Epoch:  338  	Training Loss: 0.0260794498026371
Test Loss:  0.030781369656324387
Valid Loss:  0.030318493023514748
Epoch:  339  	Training Loss: 0.02607467584311962
Test Loss:  0.030777988955378532
Valid Loss:  0.03031631000339985
Epoch:  340  	Training Loss: 0.02606990933418274
Test Loss:  0.030774585902690887
Valid Loss:  0.030314123257994652
Epoch:  341  	Training Loss: 0.026065150275826454
Test Loss:  0.030771173536777496
Valid Loss:  0.030311932787299156
Epoch:  342  	Training Loss: 0.026060402393341064
Test Loss:  0.030767817050218582
Valid Loss:  0.0303097665309906
Epoch:  343  	Training Loss: 0.0260557159781456
Test Loss:  0.030764440074563026
Valid Loss:  0.0303075909614563
Epoch:  344  	Training Loss: 0.026051035150885582
Test Loss:  0.030761048197746277
Valid Loss:  0.0303054116666317
Epoch:  345  	Training Loss: 0.02604636363685131
Test Loss:  0.030757643282413483
Valid Loss:  0.0303032286465168
Epoch:  346  	Training Loss: 0.026041699573397636
Test Loss:  0.03075423464179039
Valid Loss:  0.030301034450531006
Epoch:  347  	Training Loss: 0.026037044823169708
Test Loss:  0.030750803649425507
Valid Loss:  0.030298832803964615
Epoch:  348  	Training Loss: 0.026032401248812675
Test Loss:  0.030747363343834877
Valid Loss:  0.030296623706817627
Epoch:  349  	Training Loss: 0.02602776139974594
Test Loss:  0.03074391558766365
Valid Loss:  0.03029441088438034
Epoch:  350  	Training Loss: 0.026023129001259804
Test Loss:  0.030740445479750633
Valid Loss:  0.030292188748717308
Epoch:  351  	Training Loss: 0.026018505915999413
Test Loss:  0.030736960470676422
Valid Loss:  0.03028995916247368
Epoch:  352  	Training Loss: 0.02601388841867447
Test Loss:  0.03073357231914997
Valid Loss:  0.030287794768810272
Epoch:  353  	Training Loss: 0.02600933238863945
Test Loss:  0.03073016367852688
Valid Loss:  0.030285630375146866
Epoch:  354  	Training Loss: 0.026004783809185028
Test Loss:  0.03072674572467804
Valid Loss:  0.030283451080322266
Epoch:  355  	Training Loss: 0.026000242680311203
Test Loss:  0.030723311007022858
Valid Loss:  0.03028126433491707
Epoch:  356  	Training Loss: 0.025995705276727676
Test Loss:  0.030719870701432228
 71%|███████▏  | 357/500 [04:04<01:03,  2.26it/s] 72%|███████▏  | 359/500 [04:05<00:46,  3.04it/s] 72%|███████▏  | 361/500 [04:11<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:11<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:11<01:22,  1.65it/s] 73%|███████▎  | 367/500 [04:11<00:59,  2.25it/s] 74%|███████▍  | 369/500 [04:11<00:43,  3.02it/s] 74%|███████▍  | 371/500 [04:18<02:30,  1.17s/it] 75%|███████▍  | 373/500 [04:18<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:18<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:18<00:54,  2.25it/s] 76%|███████▌  | 379/500 [04:18<00:40,  3.02it/s] 76%|███████▌  | 381/500 [04:24<02:18,  1.17s/it] 77%|███████▋  | 383/500 [04:25<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:25<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:25<00:50,  2.26it/s] 78%|███████▊  | 389/500 [04:25<00:36,  3.04it/s] 78%|███████▊  | 391/500 [04:31<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:31<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:31<01:03,  1.64it/s] 79%|███████▉  | 397/500 [04:32<00:45,  2.24it/s] 80%|███████▉  | 399/500 [04:32<00:33,  3.00it/s] 80%|████████  | 401/500 [04:38<01:56,  1.18s/it] 81%|████████  | 403/500 [04:38<01:22,  1.18it/s] 81%|████████  | 405/500 [04:38<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:38<00:41,  2.23it/s] 82%|████████▏ | 409/500 [04:39<00:30,  3.00it/s] 82%|████████▏ | 411/500 [04:45<01:47,  1.20s/it] 83%|████████▎ | 413/500 [04:45<01:15,  1.16it/s] 83%|████████▎ | 415/500 [04:45<00:52,  1.60it/s] 83%|████████▎ | 417/500 [04:45<00:37,  2.19it/s] 84%|████████▍ | 419/500 [04:46<00:27,  2.95it/s] 84%|████████▍ | 421/500 [04:52<01:33,  1.19s/it] 85%|████████▍ | 423/500 [04:52<01:05,  1.17it/s] 85%|████████▌ | 425/500 [04:52<00:46,  1.62it/s]Valid Loss:  0.030279073864221573
Epoch:  357  	Training Loss: 0.025991175323724747
Test Loss:  0.030716415494680405
Valid Loss:  0.030276881530880928
Epoch:  358  	Training Loss: 0.025986656546592712
Test Loss:  0.030712954699993134
Valid Loss:  0.030274681746959686
Epoch:  359  	Training Loss: 0.025982143357396126
Test Loss:  0.03070947900414467
Valid Loss:  0.03027247078716755
Epoch:  360  	Training Loss: 0.025977633893489838
Test Loss:  0.03070598468184471
Valid Loss:  0.030270248651504517
Epoch:  361  	Training Loss: 0.0259731262922287
Test Loss:  0.030702492222189903
Valid Loss:  0.030268028378486633
Epoch:  362  	Training Loss: 0.025968633592128754
Test Loss:  0.030699007213115692
Valid Loss:  0.030265798792243004
Epoch:  363  	Training Loss: 0.025964155793190002
Test Loss:  0.030695520341396332
Valid Loss:  0.030263565480709076
Epoch:  364  	Training Loss: 0.025959692895412445
Test Loss:  0.030692018568515778
Valid Loss:  0.030261322855949402
Epoch:  365  	Training Loss: 0.025955229997634888
Test Loss:  0.03068850375711918
Valid Loss:  0.03025907278060913
Epoch:  366  	Training Loss: 0.025950774550437927
Test Loss:  0.030684981495141983
Valid Loss:  0.030256811529397964
Epoch:  367  	Training Loss: 0.025946326553821564
Test Loss:  0.03068145364522934
Valid Loss:  0.030254550278186798
Epoch:  368  	Training Loss: 0.0259418822824955
Test Loss:  0.03067791275680065
Valid Loss:  0.030252287164330482
Epoch:  369  	Training Loss: 0.025937441736459732
Test Loss:  0.030674364417791367
Valid Loss:  0.03025001846253872
Epoch:  370  	Training Loss: 0.02593301422894001
Test Loss:  0.030670804902911186
Valid Loss:  0.030247744172811508
Epoch:  371  	Training Loss: 0.025928586721420288
Test Loss:  0.03066723421216011
Valid Loss:  0.03024546056985855
Epoch:  372  	Training Loss: 0.025924164801836014
Test Loss:  0.030663788318634033
Valid Loss:  0.030243270099163055
Epoch:  373  	Training Loss: 0.025919891893863678
Test Loss:  0.030660856515169144
Valid Loss:  0.030241407454013824
Epoch:  374  	Training Loss: 0.025915665552020073
Test Loss:  0.03065790981054306
Valid Loss:  0.030239537358283997
Epoch:  375  	Training Loss: 0.025911448523402214
Test Loss:  0.03065495565533638
Valid Loss:  0.03023766353726387
Epoch:  376  	Training Loss: 0.025907237082719803
Test Loss:  0.03065197542309761
Valid Loss:  0.03023577108979225
Epoch:  377  	Training Loss: 0.025903034955263138
Test Loss:  0.030648985877633095
Valid Loss:  0.030233874917030334
Epoch:  378  	Training Loss: 0.02589883655309677
Test Loss:  0.030645985156297684
Valid Loss:  0.03023197501897812
Epoch:  379  	Training Loss: 0.02589465118944645
Test Loss:  0.030642971396446228
Valid Loss:  0.030230063945055008
Epoch:  380  	Training Loss: 0.025890469551086426
Test Loss:  0.03063993714749813
Valid Loss:  0.030228139832615852
Epoch:  381  	Training Loss: 0.025886295363307
Test Loss:  0.03063691034913063
Valid Loss:  0.0302262082695961
Epoch:  382  	Training Loss: 0.02588212490081787
Test Loss:  0.030633976683020592
Valid Loss:  0.03022424876689911
Epoch:  383  	Training Loss: 0.025877948850393295
Test Loss:  0.030631031841039658
Valid Loss:  0.030222270637750626
Epoch:  384  	Training Loss: 0.025873791426420212
Test Loss:  0.0306285098195076
Valid Loss:  0.030220624059438705
Epoch:  385  	Training Loss: 0.02586967684328556
Test Loss:  0.030625976622104645
Valid Loss:  0.03021896444261074
Epoch:  386  	Training Loss: 0.025865569710731506
Test Loss:  0.0306234247982502
Valid Loss:  0.03021729364991188
Epoch:  387  	Training Loss: 0.0258614681661129
Test Loss:  0.030620863661170006
Valid Loss:  0.030215613543987274
Epoch:  388  	Training Loss: 0.025857381522655487
Test Loss:  0.03061828948557377
Valid Loss:  0.030213918536901474
Epoch:  389  	Training Loss: 0.02585330232977867
Test Loss:  0.03061569854617119
Valid Loss:  0.030212221667170525
Epoch:  390  	Training Loss: 0.02584923431277275
Test Loss:  0.03061310201883316
Valid Loss:  0.03021051362156868
Epoch:  391  	Training Loss: 0.025845173746347427
Test Loss:  0.03061048313975334
Valid Loss:  0.03020879253745079
Epoch:  392  	Training Loss: 0.0258411206305027
Test Loss:  0.0306079164147377
Valid Loss:  0.03020711988210678
Epoch:  393  	Training Loss: 0.02583712339401245
Test Loss:  0.030605334788560867
Valid Loss:  0.030205436050891876
Epoch:  394  	Training Loss: 0.02583312802016735
Test Loss:  0.030602741986513138
Valid Loss:  0.030203742906451225
Epoch:  395  	Training Loss: 0.025829143822193146
Test Loss:  0.030600134283304214
Valid Loss:  0.030202040448784828
Epoch:  396  	Training Loss: 0.025825168937444687
Test Loss:  0.030597515404224396
Valid Loss:  0.030200332403182983
Epoch:  397  	Training Loss: 0.025821201503276825
Test Loss:  0.03059488907456398
Valid Loss:  0.030198611319065094
Epoch:  398  	Training Loss: 0.02581724151968956
Test Loss:  0.030592244118452072
Valid Loss:  0.03019687905907631
Epoch:  399  	Training Loss: 0.025813288986682892
Test Loss:  0.030589589849114418
Valid Loss:  0.030195139348506927
Epoch:  400  	Training Loss: 0.02580934576690197
Test Loss:  0.030586928129196167
Valid Loss:  0.03019339218735695
Epoch:  401  	Training Loss: 0.025805408135056496
Test Loss:  0.030584249645471573
Valid Loss:  0.030191633850336075
Epoch:  402  	Training Loss: 0.02580147609114647
Test Loss:  0.030581552535295486
Valid Loss:  0.030189864337444305
Epoch:  403  	Training Loss: 0.025797542184591293
Test Loss:  0.030578847974538803
Valid Loss:  0.03018808364868164
Epoch:  404  	Training Loss: 0.025793615728616714
Test Loss:  0.030576134100556374
Valid Loss:  0.030186288058757782
Epoch:  405  	Training Loss: 0.025789692997932434
Test Loss:  0.03057340905070305
Valid Loss:  0.030184492468833923
Epoch:  406  	Training Loss: 0.0257857795804739
Test Loss:  0.030570674687623978
Valid Loss:  0.03018268197774887
Epoch:  407  	Training Loss: 0.025781873613595963
Test Loss:  0.030567921698093414
Valid Loss:  0.03018086776137352
Epoch:  408  	Training Loss: 0.025777971372008324
Test Loss:  0.03056516870856285
Valid Loss:  0.03017904981970787
Epoch:  409  	Training Loss: 0.02577408030629158
Test Loss:  0.030562398955225945
Valid Loss:  0.03017721325159073
Epoch:  410  	Training Loss: 0.025770191103219986
Test Loss:  0.03055962175130844
Valid Loss:  0.030175384134054184
Epoch:  411  	Training Loss: 0.02576630935072899
Test Loss:  0.03055683523416519
Valid Loss:  0.0301735308021307
Epoch:  412  	Training Loss: 0.02576243132352829
Test Loss:  0.030554063618183136
Valid Loss:  0.030171696096658707
Epoch:  413  	Training Loss: 0.025758611038327217
Test Loss:  0.030551299452781677
Valid Loss:  0.030169857665896416
Epoch:  414  	Training Loss: 0.02575480006635189
Test Loss:  0.030548524111509323
Valid Loss:  0.030168015509843826
Epoch:  415  	Training Loss: 0.025750990957021713
Test Loss:  0.030545726418495178
Valid Loss:  0.030166152864694595
Epoch:  416  	Training Loss: 0.025747189298272133
Test Loss:  0.030542932450771332
Valid Loss:  0.030164293944835663
Epoch:  417  	Training Loss: 0.02574339509010315
Test Loss:  0.030540119856595993
Valid Loss:  0.030162423849105835
Epoch:  418  	Training Loss: 0.025739600881934166
Test Loss:  0.030537307262420654
Valid Loss:  0.03016054630279541
Epoch:  419  	Training Loss: 0.025735817849636078
Test Loss:  0.030534474179148674
Valid Loss:  0.030158668756484985
Epoch:  420  	Training Loss: 0.02573203481733799
Test Loss:  0.030531641095876694
Valid Loss:  0.030156772583723068
Epoch:  421  	Training Loss: 0.0257282592356205
Test Loss:  0.03052879497408867
Valid Loss:  0.030154874548316002
Epoch:  422  	Training Loss: 0.025724487379193306
Test Loss:  0.030525917187333107
Valid Loss:  0.03015294298529625
Epoch:  423  	Training Loss: 0.02572069689631462
Test Loss:  0.0305230300873518
Valid Loss:  0.030150994658470154
Epoch:  424  	Training Loss: 0.025716904550790787
Test Loss:  0.030520135536789894
Valid Loss:  0.030149046331644058
Epoch:  425  	Training Loss: 0.025713123381137848
Test Loss:  0.030517231673002243
Valid Loss:  0.030147090554237366
Epoch:  426  	Training Loss: 0.02570934221148491
Test Loss:  0.030514318495988846
Valid Loss:  0.030145127326250076
Epoch:  427  	Training Loss: 0.025705566629767418
 85%|████████▌ | 427/500 [04:52<00:32,  2.22it/s] 86%|████████▌ | 429/500 [04:52<00:23,  2.98it/s] 86%|████████▌ | 431/500 [04:59<01:20,  1.17s/it] 87%|████████▋ | 433/500 [04:59<00:56,  1.19it/s] 87%|████████▋ | 435/500 [04:59<00:39,  1.65it/s] 87%|████████▋ | 437/500 [04:59<00:28,  2.25it/s] 88%|████████▊ | 439/500 [04:59<00:20,  3.02it/s] 88%|████████▊ | 441/500 [05:05<01:08,  1.17s/it] 89%|████████▊ | 443/500 [05:06<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:06<00:33,  1.65it/s] 89%|████████▉ | 447/500 [05:06<00:23,  2.25it/s] 90%|████████▉ | 449/500 [05:06<00:16,  3.03it/s] 90%|█████████ | 451/500 [05:12<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:12<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:13<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:13<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:13<00:13,  3.00it/s] 92%|█████████▏| 461/500 [05:19<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:19<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:19<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:20<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:20<00:10,  3.02it/s] 94%|█████████▍| 471/500 [05:26<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:26<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:26<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:26<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:26<00:06,  3.01it/s] 96%|█████████▌| 481/500 [05:33<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:33<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:33<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:33<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:33<00:03,  2.99it/s] 98%|█████████▊| 491/500 [05:40<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:40<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:40<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:40<00:01,  2.23it/s]Test Loss:  0.03051140159368515
Valid Loss:  0.03014315664768219
Epoch:  428  	Training Loss: 0.025701798498630524
Test Loss:  0.03050847351551056
Valid Loss:  0.030141178518533707
Epoch:  429  	Training Loss: 0.02569803036749363
Test Loss:  0.03050553984940052
Valid Loss:  0.030139196664094925
Epoch:  430  	Training Loss: 0.025694269686937332
Test Loss:  0.030502595007419586
Valid Loss:  0.030137207359075546
Epoch:  431  	Training Loss: 0.025690512731671333
Test Loss:  0.030499640852212906
Valid Loss:  0.03013521619141102
Epoch:  432  	Training Loss: 0.025686761364340782
Test Loss:  0.030496787279844284
Valid Loss:  0.030133310705423355
Epoch:  433  	Training Loss: 0.02568308636546135
Test Loss:  0.030493924394249916
Valid Loss:  0.030131397768855095
Epoch:  434  	Training Loss: 0.025679418817162514
Test Loss:  0.030491042882204056
Valid Loss:  0.030129482969641685
Epoch:  435  	Training Loss: 0.02567574940621853
Test Loss:  0.030488163232803345
Valid Loss:  0.03012755885720253
Epoch:  436  	Training Loss: 0.02567208744585514
Test Loss:  0.030485276132822037
Valid Loss:  0.030125631019473076
Epoch:  437  	Training Loss: 0.0256684310734272
Test Loss:  0.03048238344490528
Valid Loss:  0.030123693868517876
Epoch:  438  	Training Loss: 0.02566477656364441
Test Loss:  0.03047947958111763
Valid Loss:  0.030121752992272377
Epoch:  439  	Training Loss: 0.025661127641797066
Test Loss:  0.03047657199203968
Valid Loss:  0.03011981025338173
Epoch:  440  	Training Loss: 0.025657478719949722
Test Loss:  0.030473656952381134
Valid Loss:  0.030117861926555634
Epoch:  441  	Training Loss: 0.025653839111328125
Test Loss:  0.03047073632478714
Valid Loss:  0.03011590614914894
Epoch:  442  	Training Loss: 0.025650205090641975
Test Loss:  0.03046777844429016
Valid Loss:  0.030113909393548965
Epoch:  443  	Training Loss: 0.025646544992923737
Test Loss:  0.030464816838502884
Valid Loss:  0.03011190891265869
Epoch:  444  	Training Loss: 0.025642890483140945
Test Loss:  0.030461851507425308
Valid Loss:  0.030109897255897522
Epoch:  445  	Training Loss: 0.025639239698648453
Test Loss:  0.030458882451057434
Valid Loss:  0.030107887461781502
Epoch:  446  	Training Loss: 0.025635598227381706
Test Loss:  0.030455900356173515
Valid Loss:  0.030105870217084885
Epoch:  447  	Training Loss: 0.02563195489346981
Test Loss:  0.030452914535999298
Valid Loss:  0.03010384924709797
Epoch:  448  	Training Loss: 0.025628313422203064
Test Loss:  0.030449945479631424
Valid Loss:  0.030101820826530457
Epoch:  449  	Training Loss: 0.025624677538871765
Test Loss:  0.030447140336036682
Valid Loss:  0.030099792405962944
Epoch:  450  	Training Loss: 0.025621065869927406
Test Loss:  0.030444692820310593
Valid Loss:  0.030098097398877144
Epoch:  451  	Training Loss: 0.025617513805627823
Test Loss:  0.030442235991358757
Valid Loss:  0.030096396803855896
Epoch:  452  	Training Loss: 0.025613971054553986
Test Loss:  0.030440134927630424
Valid Loss:  0.030095025897026062
Epoch:  453  	Training Loss: 0.02561047486960888
Test Loss:  0.030438022688031197
Valid Loss:  0.030093640089035034
Epoch:  454  	Training Loss: 0.025606974959373474
Test Loss:  0.030435901135206223
Valid Loss:  0.03009224683046341
Epoch:  455  	Training Loss: 0.025603484362363815
Test Loss:  0.030433766543865204
Valid Loss:  0.030090849846601486
Epoch:  456  	Training Loss: 0.02560000866651535
Test Loss:  0.03043162077665329
Valid Loss:  0.03008943423628807
Epoch:  457  	Training Loss: 0.025596534833312035
Test Loss:  0.03042946755886078
Valid Loss:  0.03008800745010376
Epoch:  458  	Training Loss: 0.02559307962656021
Test Loss:  0.030427664518356323
Valid Loss:  0.030086923390626907
Epoch:  459  	Training Loss: 0.025589630007743835
Test Loss:  0.03042585588991642
Valid Loss:  0.030085816979408264
Epoch:  460  	Training Loss: 0.025586189702153206
Test Loss:  0.030424030497670174
Valid Loss:  0.030084699392318726
Epoch:  461  	Training Loss: 0.02558276616036892
Test Loss:  0.030421825125813484
Valid Loss:  0.030083220452070236
Epoch:  462  	Training Loss: 0.02557934820652008
Test Loss:  0.030420027673244476
Valid Loss:  0.030082128942012787
Epoch:  463  	Training Loss: 0.025575978681445122
Test Loss:  0.030418215319514275
Valid Loss:  0.030081022530794144
Epoch:  464  	Training Loss: 0.02557262033224106
Test Loss:  0.030416393652558327
Valid Loss:  0.030079912394285202
Epoch:  465  	Training Loss: 0.025569269433617592
Test Loss:  0.030414555221796036
Valid Loss:  0.03007878176867962
Epoch:  466  	Training Loss: 0.02556593157351017
Test Loss:  0.030412711203098297
Valid Loss:  0.03007763996720314
Epoch:  467  	Training Loss: 0.025562599301338196
Test Loss:  0.030410848557949066
Valid Loss:  0.030076488852500916
Epoch:  468  	Training Loss: 0.025559278205037117
Test Loss:  0.03040897846221924
Valid Loss:  0.0300753191113472
Epoch:  469  	Training Loss: 0.025555968284606934
Test Loss:  0.030407093465328217
Valid Loss:  0.030074145644903183
Epoch:  470  	Training Loss: 0.025552663952112198
Test Loss:  0.0304051972925663
Valid Loss:  0.030072955414652824
Epoch:  471  	Training Loss: 0.025549370795488358
Test Loss:  0.030403293669223785
Valid Loss:  0.030071748420596123
Epoch:  472  	Training Loss: 0.025546083226799965
Test Loss:  0.03040136769413948
Valid Loss:  0.030070539563894272
Epoch:  473  	Training Loss: 0.02554279938340187
Test Loss:  0.03039943426847458
Valid Loss:  0.03006930649280548
Epoch:  474  	Training Loss: 0.025539519265294075
Test Loss:  0.030397487804293633
Valid Loss:  0.030068058520555496
Epoch:  475  	Training Loss: 0.025536244735121727
Test Loss:  0.03039553202688694
Valid Loss:  0.030066806823015213
Epoch:  476  	Training Loss: 0.025532981380820274
Test Loss:  0.030393589287996292
Valid Loss:  0.030065547674894333
Epoch:  477  	Training Loss: 0.02552972547709942
Test Loss:  0.030391652137041092
Valid Loss:  0.03006427176296711
Epoch:  478  	Training Loss: 0.02552647888660431
Test Loss:  0.03038971498608589
Valid Loss:  0.03006298653781414
Epoch:  479  	Training Loss: 0.025523245334625244
Test Loss:  0.030388066545128822
Valid Loss:  0.030062049627304077
Epoch:  480  	Training Loss: 0.025520019233226776
Test Loss:  0.030386406928300858
Valid Loss:  0.030061092227697372
Epoch:  481  	Training Loss: 0.025516800582408905
Test Loss:  0.03038443811237812
Valid Loss:  0.03005976602435112
Epoch:  482  	Training Loss: 0.02551359497010708
Test Loss:  0.030382808297872543
Valid Loss:  0.030058827251195908
Epoch:  483  	Training Loss: 0.025510430335998535
Test Loss:  0.03038116730749607
Valid Loss:  0.03005787916481495
Epoch:  484  	Training Loss: 0.025507284328341484
Test Loss:  0.03037952072918415
Valid Loss:  0.030056919902563095
Epoch:  485  	Training Loss: 0.02550414577126503
Test Loss:  0.030377861112356186
Valid Loss:  0.030055943876504898
Epoch:  486  	Training Loss: 0.025501014664769173
Test Loss:  0.030376195907592773
Valid Loss:  0.030054960399866104
Epoch:  487  	Training Loss: 0.025497891008853912
Test Loss:  0.030374515801668167
Valid Loss:  0.03005395457148552
Epoch:  488  	Training Loss: 0.025494776666164398
Test Loss:  0.030372831970453262
Valid Loss:  0.030052943155169487
Epoch:  489  	Training Loss: 0.02549167349934578
Test Loss:  0.03037114068865776
Valid Loss:  0.030051913112401962
Epoch:  490  	Training Loss: 0.025488581508398056
Test Loss:  0.030369441956281662
Valid Loss:  0.03005087934434414
Epoch:  491  	Training Loss: 0.02548549324274063
Test Loss:  0.03036772832274437
Valid Loss:  0.030049823224544525
Epoch:  492  	Training Loss: 0.025482412427663803
Test Loss:  0.030365921556949615
Valid Loss:  0.03004867024719715
Epoch:  493  	Training Loss: 0.0254792720079422
Test Loss:  0.030364109203219414
Valid Loss:  0.030047506093978882
Epoch:  494  	Training Loss: 0.02547614276409149
Test Loss:  0.030362283810973167
Valid Loss:  0.030046328902244568
Epoch:  495  	Training Loss: 0.025473011657595634
Test Loss:  0.030360454693436623
Valid Loss:  0.030045142397284508
Epoch:  496  	Training Loss: 0.025469891726970673
Test Loss:  0.030358612537384033
Valid Loss:  0.030043940991163254
Epoch:  497  	Training Loss: 0.025466781109571457
Test Loss:  0.030356762930750847
Valid Loss:  0.030042722821235657
100%|█████████▉| 499/500 [05:40<00:00,  2.99it/s]100%|██████████| 500/500 [05:40<00:00,  1.47it/s]
Epoch:  498  	Training Loss: 0.02546367421746254
Test Loss:  0.030354909598827362
Valid Loss:  0.03004150092601776
Epoch:  499  	Training Loss: 0.025460578501224518
Test Loss:  0.030353043228387833
Valid Loss:  0.030040264129638672
Epoch:  500  	Training Loss: 0.025457484647631645
Test Loss:  0.030351171270012856
Valid Loss:  0.030039016157388687
seed is  3
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:12,  6.16s/it]  1%|          | 3/500 [00:06<13:40,  1.65s/it]  1%|          | 5/500 [00:06<06:53,  1.20it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:47,  2.93it/s]  2%|▏         | 11/500 [00:12<10:43,  1.32s/it]  3%|▎         | 13/500 [00:13<07:19,  1.11it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  2.99it/s]  4%|▍         | 21/500 [00:19<09:40,  1.21s/it]  5%|▍         | 23/500 [00:20<06:52,  1.16it/s]  5%|▌         | 25/500 [00:20<04:55,  1.61it/s]  5%|▌         | 27/500 [00:20<03:34,  2.21it/s]  6%|▌         | 29/500 [00:20<02:38,  2.97it/s]  6%|▌         | 31/500 [00:27<09:35,  1.23s/it]  7%|▋         | 33/500 [00:27<06:50,  1.14it/s]  7%|▋         | 35/500 [00:33<12:15,  1.58s/it]  7%|▋         | 37/500 [00:33<08:42,  1.13s/it]  8%|▊         | 39/500 [00:33<06:12,  1.24it/s]  8%|▊         | 41/500 [00:40<11:29,  1.50s/it]  9%|▊         | 43/500 [00:40<08:09,  1.07s/it]  9%|▉         | 45/500 [00:40<05:50,  1.30it/s]  9%|▉         | 47/500 [00:40<04:12,  1.79it/s] 10%|▉         | 49/500 [00:40<03:04,  2.44it/s] 10%|█         | 51/500 [00:46<09:12,  1.23s/it] 11%|█         | 53/500 [00:47<06:34,  1.13it/s] 11%|█         | 55/500 [00:47<04:43,  1.57it/s] 11%|█▏        | 57/500 [00:47<03:25,  2.15it/s] 12%|█▏        | 59/500 [00:47<02:32,  2.90it/s] 12%|█▏        | 61/500 [00:53<08:32,  1.17s/it] 13%|█▎        | 63/500 [00:53<06:06,  1.19it/s] 13%|█▎        | 65/500 [00:53<04:23,  1.65it/s] 13%|█▎        | 67/500 [00:53<03:12,  2.25it/s] 14%|█▍        | 69/500 [00:54<02:22,  3.03it/s]Epoch:  1  	Training Loss: 0.0912899374961853
Test Loss:  6.260287284851074
Valid Loss:  6.262086391448975
Epoch:  2  	Training Loss: 6.30792760848999
Test Loss:  102.28870391845703
Valid Loss:  103.27984619140625
Epoch:  3  	Training Loss: 99.60003662109375
Test Loss:  1.4358513355255127
Valid Loss:  1.389249324798584
Epoch:  4  	Training Loss: 1.562504768371582
Test Loss:  1.3944728374481201
Valid Loss:  1.3403838872909546
Epoch:  5  	Training Loss: 1.5163466930389404
Test Loss:  1.3706921339035034
Valid Loss:  1.3113452196121216
Epoch:  6  	Training Loss: 1.4896892309188843
Test Loss:  1.350618600845337
Valid Loss:  1.2889516353607178
Epoch:  7  	Training Loss: 1.4689593315124512
Test Loss:  1.334021806716919
Valid Loss:  1.2705364227294922
Epoch:  8  	Training Loss: 1.4515247344970703
Test Loss:  1.3197600841522217
Valid Loss:  1.2552765607833862
Epoch:  9  	Training Loss: 1.4364171028137207
Test Loss:  1.3076045513153076
Valid Loss:  1.2451322078704834
Epoch:  10  	Training Loss: 1.4241001605987549
Test Loss:  1.2965891361236572
Valid Loss:  1.2385590076446533
Epoch:  11  	Training Loss: 1.4132007360458374
Test Loss:  1.2859201431274414
Valid Loss:  1.2323546409606934
Epoch:  12  	Training Loss: 1.4030979871749878
Test Loss:  0.674058198928833
Valid Loss:  0.6687601804733276
Epoch:  13  	Training Loss: 0.6158636212348938
Test Loss:  0.12268888205289841
Valid Loss:  0.09916756302118301
Epoch:  14  	Training Loss: 0.19729959964752197
Test Loss:  0.12193883955478668
Valid Loss:  0.09887252748012543
Epoch:  15  	Training Loss: 0.19466927647590637
Test Loss:  0.12176772207021713
Valid Loss:  0.09875565022230148
Epoch:  16  	Training Loss: 0.19429853558540344
Test Loss:  0.12155039608478546
Valid Loss:  0.09855328500270844
Epoch:  17  	Training Loss: 0.19388604164123535
Test Loss:  0.12129689007997513
Valid Loss:  0.09832694381475449
Epoch:  18  	Training Loss: 0.19341380894184113
Test Loss:  0.12099498510360718
Valid Loss:  0.09806846082210541
Epoch:  19  	Training Loss: 0.19291040301322937
Test Loss:  0.12063394486904144
Valid Loss:  0.09780190885066986
Epoch:  20  	Training Loss: 0.19237688183784485
Test Loss:  0.12024188786745071
Valid Loss:  0.09752894937992096
Epoch:  21  	Training Loss: 0.19181731343269348
Test Loss:  0.11983980983495712
Valid Loss:  0.0972382053732872
Epoch:  22  	Training Loss: 0.19123968482017517
Test Loss:  0.2857418656349182
Valid Loss:  0.2902818024158478
Epoch:  23  	Training Loss: 0.24270160496234894
Test Loss:  0.6233449578285217
Valid Loss:  0.63662189245224
Epoch:  24  	Training Loss: 0.5360614061355591
Test Loss:  0.07814424484968185
Valid Loss:  0.07652169466018677
Epoch:  25  	Training Loss: 0.06785939633846283
Test Loss:  0.0569574236869812
Valid Loss:  0.055060259997844696
Epoch:  26  	Training Loss: 0.051806963980197906
Test Loss:  0.043638672679662704
Valid Loss:  0.04159659147262573
Epoch:  27  	Training Loss: 0.041869111359119415
Test Loss:  0.0351998507976532
Valid Loss:  0.03308688476681709
Epoch:  28  	Training Loss: 0.035682354122400284
Test Loss:  0.029797017574310303
Valid Loss:  0.027660515159368515
Epoch:  29  	Training Loss: 0.031799618154764175
Test Loss:  0.026290416717529297
Valid Loss:  0.02415907010436058
Epoch:  30  	Training Loss: 0.02932952158153057
Test Loss:  0.023974481970071793
Valid Loss:  0.02186361886560917
Epoch:  31  	Training Loss: 0.027727315202355385
Test Loss:  0.022410184144973755
Valid Loss:  0.020325489342212677
Epoch:  32  	Training Loss: 0.02665899135172367
Test Loss:  0.08647338300943375
Valid Loss:  0.08782505989074707
Epoch:  33  	Training Loss: 0.07562959939241409
Test Loss:  0.16201511025428772
Valid Loss:  0.16173332929611206
Epoch:  34  	Training Loss: 0.16432973742485046
Test Loss:  0.08232078701257706
Valid Loss:  0.0811418890953064
Epoch:  35  	Training Loss: 0.069912850856781
Test Loss:  0.019444841891527176
Valid Loss:  0.017588064074516296
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.023249056190252304
Test Loss:  0.0642424002289772
Valid Loss:  0.0650881975889206
Epoch:  37  	Training Loss: 0.05609949305653572
Test Loss:  0.05269651859998703
Valid Loss:  0.05127949267625809
Epoch:  38  	Training Loss: 0.06132208928465843
Test Loss:  0.027697693556547165
Valid Loss:  0.028049062937498093
Epoch:  39  	Training Loss: 0.03348594158887863
Test Loss:  0.009912921115756035
Valid Loss:  0.009137317538261414
Epoch:  40  	Training Loss: 0.011124295182526112
Test Loss:  0.008455867879092693
Valid Loss:  0.008030164986848831
Epoch:  41  	Training Loss: 0.007235818542540073
Test Loss:  0.0071212491020560265
Valid Loss:  0.0065778931602835655
Epoch:  42  	Training Loss: 0.006723245605826378
Test Loss:  0.007279783487319946
Valid Loss:  0.006779706105589867
Epoch:  43  	Training Loss: 0.006546999793499708
Test Loss:  0.006861312780529261
Valid Loss:  0.0064093805849552155
Epoch:  44  	Training Loss: 0.006014956161379814
Test Loss:  0.0066612884402275085
Valid Loss:  0.006190266460180283
Epoch:  45  	Training Loss: 0.005948303267359734
Test Loss:  0.006557215936481953
Valid Loss:  0.006075882352888584
Epoch:  46  	Training Loss: 0.005921144038438797
Test Loss:  0.006498786620795727
Valid Loss:  0.00601210305467248
Epoch:  47  	Training Loss: 0.005906826816499233
Test Loss:  0.006463427096605301
Valid Loss:  0.005974145606160164
Epoch:  48  	Training Loss: 0.005896582268178463
Test Loss:  0.006440244615077972
Valid Loss:  0.005949913989752531
Epoch:  49  	Training Loss: 0.005887622945010662
Test Loss:  0.006423685234040022
Valid Loss:  0.005933169741183519
Epoch:  50  	Training Loss: 0.0058791181072592735
Test Loss:  0.006410771049559116
Valid Loss:  0.00592015590518713
Epoch:  51  	Training Loss: 0.005870770663022995
Test Loss:  0.006399905309081078
Valid Loss:  0.005909394007176161
Epoch:  52  	Training Loss: 0.005862506106495857
Test Loss:  0.005151884164661169
Valid Loss:  0.0047271763905882835
Epoch:  53  	Training Loss: 0.004780752584338188
Test Loss:  0.004167107865214348
Valid Loss:  0.0038019567728042603
Epoch:  54  	Training Loss: 0.003976357635110617
Test Loss:  0.003402726026251912
Valid Loss:  0.0030899373814463615
Epoch:  55  	Training Loss: 0.003364941803738475
Test Loss:  0.0028075831942260265
Valid Loss:  0.002546340925619006
Epoch:  56  	Training Loss: 0.0028827469795942307
Test Loss:  0.0023413067683577538
Valid Loss:  0.0021312814205884933
Epoch:  57  	Training Loss: 0.00249641016125679
Test Loss:  0.0019723051227629185
Valid Loss:  0.001802643295377493
Epoch:  58  	Training Loss: 0.002185304183512926
Test Loss:  0.00167974759824574
Valid Loss:  0.0015457834815606475
Epoch:  59  	Training Loss: 0.0019336165860295296
Test Loss:  0.0014494562055915594
Valid Loss:  0.0013449760153889656
Epoch:  60  	Training Loss: 0.0017281826585531235
Test Loss:  0.0012663182569667697
Valid Loss:  0.001186249079182744
Epoch:  61  	Training Loss: 0.0015586435329169035
Test Loss:  0.0011193660320714116
Valid Loss:  0.001058756373822689
Epoch:  62  	Training Loss: 0.0014187556225806475
Test Loss:  0.0009281442034989595
Valid Loss:  0.0009482746245339513
Epoch:  63  	Training Loss: 0.001115380204282701
Test Loss:  0.000681099365465343
Valid Loss:  0.0006348318420350552
Epoch:  64  	Training Loss: 0.001044499920681119
Test Loss:  0.0008482018020004034
Valid Loss:  0.0009218757040798664
Epoch:  65  	Training Loss: 0.0010207882151007652
Test Loss:  0.0006875810213387012
Valid Loss:  0.0006640907959081233
Epoch:  66  	Training Loss: 0.001027492806315422
Test Loss:  0.0008661565370857716
Valid Loss:  0.0009674181928858161
Epoch:  67  	Training Loss: 0.0010270163184031844
Test Loss:  0.0007372187101282179
Valid Loss:  0.0007293312810361385
Epoch:  68  	Training Loss: 0.001052884035743773
Test Loss:  0.0008876078063622117
Valid Loss:  0.0010045833187177777
Epoch:  69  	Training Loss: 0.001042575342580676
Test Loss:  0.0007742729503661394
Valid Loss:  0.0007780733285471797
Epoch:  70  	Training Loss: 0.0010729035129770637
Test Loss:  0.0008979861158877611
Valid Loss:  0.0010224052239209414
 14%|█▍        | 71/500 [01:06<15:00,  2.10s/it] 15%|█▍        | 73/500 [01:06<10:36,  1.49s/it] 15%|█▌        | 75/500 [01:06<07:31,  1.06s/it] 15%|█▌        | 77/500 [01:06<05:23,  1.31it/s] 16%|█▌        | 79/500 [01:07<03:53,  1.80it/s] 16%|█▌        | 81/500 [01:13<09:17,  1.33s/it] 17%|█▋        | 83/500 [01:13<06:37,  1.05it/s] 17%|█▋        | 85/500 [01:13<04:44,  1.46it/s] 17%|█▋        | 87/500 [01:13<03:26,  2.00it/s] 18%|█▊        | 89/500 [01:13<02:31,  2.71it/s] 18%|█▊        | 91/500 [01:20<08:11,  1.20s/it] 19%|█▊        | 93/500 [01:20<05:50,  1.16it/s] 19%|█▉        | 95/500 [01:20<04:12,  1.61it/s] 19%|█▉        | 97/500 [01:20<03:03,  2.19it/s] 20%|█▉        | 99/500 [01:20<02:15,  2.96it/s] 20%|██        | 101/500 [01:26<07:45,  1.17s/it] 21%|██        | 103/500 [01:27<05:33,  1.19it/s] 21%|██        | 105/500 [01:27<03:59,  1.65it/s] 21%|██▏       | 107/500 [01:27<02:54,  2.25it/s] 22%|██▏       | 109/500 [01:27<02:10,  3.00it/s] 22%|██▏       | 111/500 [01:33<07:37,  1.18s/it] 23%|██▎       | 113/500 [01:33<05:27,  1.18it/s] 23%|██▎       | 115/500 [01:34<03:55,  1.64it/s] 23%|██▎       | 117/500 [01:34<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:34<02:07,  2.99it/s] 24%|██▍       | 121/500 [01:40<07:22,  1.17s/it] 25%|██▍       | 123/500 [01:40<05:16,  1.19it/s] 25%|██▌       | 125/500 [01:40<03:47,  1.65it/s] 25%|██▌       | 127/500 [01:40<02:45,  2.25it/s] 26%|██▌       | 129/500 [01:41<02:02,  3.03it/s] 26%|██▌       | 131/500 [01:47<07:11,  1.17s/it] 27%|██▋       | 133/500 [01:47<05:08,  1.19it/s] 27%|██▋       | 135/500 [01:47<03:41,  1.64it/s]**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.001048262813128531
Test Loss:  0.000885112036485225
Valid Loss:  0.0010100468061864376
Epoch:  72  	Training Loss: 0.0010321110021322966
Test Loss:  0.0005380160873755813
Valid Loss:  0.0005616160342469811
Epoch:  73  	Training Loss: 0.0007290493231266737
Test Loss:  0.0004564498085528612
Valid Loss:  0.0005210671224631369
Epoch:  74  	Training Loss: 0.0005834243493154645
Test Loss:  0.0003899696166627109
Valid Loss:  0.00043235611519776285
Epoch:  75  	Training Loss: 0.000528469739947468
Test Loss:  0.00037701247492805123
Valid Loss:  0.0004288681084290147
Epoch:  76  	Training Loss: 0.0004964005202054977
Test Loss:  0.0003541941405273974
Valid Loss:  0.00040345758316107094
Epoch:  77  	Training Loss: 0.0004716267576441169
Test Loss:  0.0003425338654778898
Valid Loss:  0.0003953799023292959
Epoch:  78  	Training Loss: 0.0004505474935285747
Test Loss:  0.00032766986987553537
Valid Loss:  0.00038139551179483533
Epoch:  79  	Training Loss: 0.00043188687413930893
Test Loss:  0.00031663128174841404
Valid Loss:  0.00037238607183098793
Epoch:  80  	Training Loss: 0.000415131013141945
Test Loss:  0.00030555613921023905
Valid Loss:  0.00036197452573105693
Epoch:  81  	Training Loss: 0.00039982632733881474
Test Loss:  0.00029611733043566346
Valid Loss:  0.00035364931682124734
Epoch:  82  	Training Loss: 0.00038601463893428445
Test Loss:  0.0002948752080556005
Valid Loss:  0.0003518572775647044
Epoch:  83  	Training Loss: 0.0003851923393085599
Test Loss:  0.0002939567784778774
Valid Loss:  0.0003505120985209942
Epoch:  84  	Training Loss: 0.0003845473111141473
Test Loss:  0.0002932687639258802
Valid Loss:  0.0003494948905427009
Epoch:  85  	Training Loss: 0.00038405528175644577
Test Loss:  0.0002927446330431849
Valid Loss:  0.0003487205249257386
Epoch:  86  	Training Loss: 0.0003836402902379632
Test Loss:  0.0002923404099419713
Valid Loss:  0.0003481297171674669
Epoch:  87  	Training Loss: 0.0003832884831354022
Test Loss:  0.0002920237020589411
Valid Loss:  0.0003476766578387469
Epoch:  88  	Training Loss: 0.0003829876077361405
Test Loss:  0.00029177003307268023
Valid Loss:  0.00034732636413536966
Epoch:  89  	Training Loss: 0.0003827056207228452
Test Loss:  0.0002915640943683684
Valid Loss:  0.0003470583469606936
Epoch:  90  	Training Loss: 0.00038245684118010104
Test Loss:  0.00029139406979084015
Valid Loss:  0.0003468521754257381
Epoch:  91  	Training Loss: 0.00038221542490646243
Test Loss:  0.0002912514901254326
Valid Loss:  0.00034669501474127173
Epoch:  92  	Training Loss: 0.0003819814883172512
Test Loss:  0.00028831034433096647
Valid Loss:  0.0003443362074904144
Epoch:  93  	Training Loss: 0.0003783582942560315
Test Loss:  0.0002859349478967488
Valid Loss:  0.0003426044131629169
Epoch:  94  	Training Loss: 0.00037476193392649293
Test Loss:  0.00028362328885123134
Valid Loss:  0.00034088396932929754
Epoch:  95  	Training Loss: 0.0003712063771672547
Test Loss:  0.00028136372566223145
Valid Loss:  0.00033917592372745275
Epoch:  96  	Training Loss: 0.00036774121690541506
Test Loss:  0.0002792153391055763
Valid Loss:  0.00033762131351977587
Epoch:  97  	Training Loss: 0.000364480831194669
Test Loss:  0.0002775257162284106
Valid Loss:  0.0003361213603056967
Epoch:  98  	Training Loss: 0.0003616356698330492
Test Loss:  0.00027632774435915053
Valid Loss:  0.0003348027530591935
Epoch:  99  	Training Loss: 0.00035917770583182573
Test Loss:  0.00027560495072975755
Valid Loss:  0.0003338817914482206
Epoch:  100  	Training Loss: 0.00035714934347197413
Test Loss:  0.00027498818235471845
Valid Loss:  0.00033334328327327967
Epoch:  101  	Training Loss: 0.0003555275616236031
Test Loss:  0.00027437289827503264
Valid Loss:  0.00033279418130405247
Epoch:  102  	Training Loss: 0.0003543066850397736
Test Loss:  0.00026008859276771545
Valid Loss:  0.00031913176644593477
Epoch:  103  	Training Loss: 0.00033676496241241693
Test Loss:  0.0002470971376169473
Valid Loss:  0.0003065645578317344
Epoch:  104  	Training Loss: 0.00031991596915759146
Test Loss:  0.0002354667813051492
Valid Loss:  0.00029473594622686505
Epoch:  105  	Training Loss: 0.0003035450936295092
Test Loss:  0.00022561330115422606
Valid Loss:  0.00028422102332115173
Epoch:  106  	Training Loss: 0.00028985587414354086
Test Loss:  0.00021659067715518177
Valid Loss:  0.0002745405654422939
Epoch:  107  	Training Loss: 0.0002769236743915826
Test Loss:  0.00020847146515734494
Valid Loss:  0.0002657757140696049
Epoch:  108  	Training Loss: 0.0002650129026733339
Test Loss:  0.0002003937552217394
Valid Loss:  0.00025789428036659956
Epoch:  109  	Training Loss: 0.00025422469479963183
Test Loss:  0.00019259919645264745
Valid Loss:  0.00025110715068876743
Epoch:  110  	Training Loss: 0.00024460561689920723
Test Loss:  0.00018564093625172973
Valid Loss:  0.00024496729020029306
Epoch:  111  	Training Loss: 0.00023604559828527272
Test Loss:  0.00017866029520519078
Valid Loss:  0.0002397861535428092
Epoch:  112  	Training Loss: 0.00022819873993285
Test Loss:  0.0001764167391229421
Valid Loss:  0.00023765937658026814
Epoch:  113  	Training Loss: 0.00022507223184220493
Test Loss:  0.00017439262592233717
Valid Loss:  0.00023534230422228575
Epoch:  114  	Training Loss: 0.00022195378551259637
Test Loss:  0.00017253219266422093
Valid Loss:  0.00023324089124798775
Epoch:  115  	Training Loss: 0.00021876287064515054
Test Loss:  0.00017061547259800136
Valid Loss:  0.00023130871704779565
Epoch:  116  	Training Loss: 0.00021560155437327921
Test Loss:  0.0001685927272774279
Valid Loss:  0.00022934647859074175
Epoch:  117  	Training Loss: 0.00021261977963149548
Test Loss:  0.0001664994197199121
Valid Loss:  0.00022742107103113085
Epoch:  118  	Training Loss: 0.0002098130207741633
Test Loss:  0.00016447255620732903
Valid Loss:  0.00022572046145796776
Epoch:  119  	Training Loss: 0.00020722983754239976
Test Loss:  0.00016246785526163876
Valid Loss:  0.00022425170755013824
Epoch:  120  	Training Loss: 0.0002048719034064561
Test Loss:  0.00016037757450249046
Valid Loss:  0.0002229654637631029
Epoch:  121  	Training Loss: 0.00020272932306397706
Test Loss:  0.00015831615019124
Valid Loss:  0.00022183505643624812
Epoch:  122  	Training Loss: 0.00020070868777111173
Test Loss:  0.0001582149852765724
Valid Loss:  0.00022165630070958287
Epoch:  123  	Training Loss: 0.00020066174329258502
Test Loss:  0.0001581362448632717
Valid Loss:  0.00022152578458189964
Epoch:  124  	Training Loss: 0.00020061945542693138
Test Loss:  0.0001580744283273816
Valid Loss:  0.00022142862144391984
Epoch:  125  	Training Loss: 0.00020057993242517114
Test Loss:  0.0001580223033670336
Valid Loss:  0.0002213566331192851
Epoch:  126  	Training Loss: 0.00020054233027622104
Test Loss:  0.0001579791132826358
Valid Loss:  0.00022130175784695894
Epoch:  127  	Training Loss: 0.00020050627063028514
Test Loss:  0.00015794215141795576
Valid Loss:  0.00022125919349491596
Epoch:  128  	Training Loss: 0.00020047134603373706
Test Loss:  0.00015790890029165894
Valid Loss:  0.00022122636437416077
Epoch:  129  	Training Loss: 0.0002004380221478641
Test Loss:  0.0001578796363901347
Valid Loss:  0.0002212008403148502
Epoch:  130  	Training Loss: 0.000200405134819448
Test Loss:  0.00015785159484948963
Valid Loss:  0.00022118008928373456
Epoch:  131  	Training Loss: 0.00020037373178638518
Test Loss:  0.00015782624541316181
Valid Loss:  0.00022116400941740721
Epoch:  132  	Training Loss: 0.00020034238696098328
Test Loss:  0.0001535374321974814
Valid Loss:  0.00021692166046705097
Epoch:  133  	Training Loss: 0.00019342331506777555
Test Loss:  0.0001519307552371174
Valid Loss:  0.00021515172556973994
Epoch:  134  	Training Loss: 0.00019067809625994414
Test Loss:  0.0001504533865954727
Valid Loss:  0.00021344335982576013
Epoch:  135  	Training Loss: 0.0001886254467535764
Test Loss:  0.00014893841580487788
Valid Loss:  0.00021164611098356545
Epoch:  136  	Training Loss: 0.00018675945466384292
Test Loss:  0.00014727949746884406
Valid Loss:  0.0002097009273711592
Epoch:  137  	Training Loss: 0.00018496268603485078
Test Loss:   27%|██▋       | 137/500 [01:47<02:41,  2.25it/s] 28%|██▊       | 139/500 [01:47<01:59,  3.02it/s] 28%|██▊       | 141/500 [01:54<07:01,  1.17s/it] 29%|██▊       | 143/500 [01:54<05:01,  1.19it/s] 29%|██▉       | 145/500 [01:54<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:54<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:54<01:56,  3.02it/s] 30%|███       | 151/500 [02:00<06:49,  1.17s/it] 31%|███       | 153/500 [02:01<04:53,  1.18it/s] 31%|███       | 155/500 [02:01<03:31,  1.63it/s] 31%|███▏      | 157/500 [02:01<02:33,  2.23it/s] 32%|███▏      | 159/500 [02:01<01:53,  3.00it/s] 32%|███▏      | 161/500 [02:07<06:35,  1.17s/it] 33%|███▎      | 163/500 [02:07<04:44,  1.19it/s] 33%|███▎      | 165/500 [02:08<03:26,  1.63it/s] 33%|███▎      | 167/500 [02:08<02:29,  2.22it/s] 34%|███▍      | 169/500 [02:08<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:14<06:25,  1.17s/it] 35%|███▍      | 173/500 [02:14<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:14<03:17,  1.64it/s] 35%|███▌      | 177/500 [02:15<02:25,  2.22it/s] 36%|███▌      | 179/500 [02:15<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:21<06:11,  1.16s/it] 37%|███▋      | 183/500 [02:21<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:21<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:21<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:21<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:28<06:13,  1.21s/it] 39%|███▊      | 193/500 [02:28<04:26,  1.15it/s] 39%|███▉      | 195/500 [02:28<03:11,  1.60it/s] 39%|███▉      | 197/500 [02:28<02:20,  2.16it/s] 40%|███▉      | 199/500 [02:29<01:46,  2.83it/s] 40%|████      | 201/500 [02:35<06:02,  1.21s/it] 41%|████      | 203/500 [02:35<04:19,  1.15it/s]0.0001455616729799658
Valid Loss:  0.00020769484399352223
Epoch:  138  	Training Loss: 0.00018318003276363015
Test Loss:  0.00014376567560248077
Valid Loss:  0.00020557016250677407
Epoch:  139  	Training Loss: 0.0001814001880120486
Test Loss:  0.00014203591854311526
Valid Loss:  0.0002035272482316941
Epoch:  140  	Training Loss: 0.0001796510478015989
Test Loss:  0.00014027778524905443
Valid Loss:  0.0002014307101489976
Epoch:  141  	Training Loss: 0.00017789992853067815
Test Loss:  0.00013859799946658313
Valid Loss:  0.000199435482500121
Epoch:  142  	Training Loss: 0.000176181536517106
Test Loss:  0.00013795614358969033
Valid Loss:  0.0001986636343644932
Epoch:  143  	Training Loss: 0.00017581781139597297
Test Loss:  0.0001374822750221938
Valid Loss:  0.00019807537319138646
Epoch:  144  	Training Loss: 0.00017555175872985274
Test Loss:  0.00013711581414099783
Valid Loss:  0.00019760530267376453
Epoch:  145  	Training Loss: 0.00017533882055431604
Test Loss:  0.00013681600103154778
Valid Loss:  0.00019721299759112298
Epoch:  146  	Training Loss: 0.00017515677609480917
Test Loss:  0.0001365586358588189
Valid Loss:  0.00019686412997543812
Epoch:  147  	Training Loss: 0.00017499890236649662
Test Loss:  0.00013633148046210408
Valid Loss:  0.00019654646166600287
Epoch:  148  	Training Loss: 0.0001748610520735383
Test Loss:  0.00013612647308036685
Valid Loss:  0.00019625123240984976
Epoch:  149  	Training Loss: 0.00017473468324169517
Test Loss:  0.00013594224583357573
Valid Loss:  0.00019597989739850163
Epoch:  150  	Training Loss: 0.00017461444076616317
Test Loss:  0.0001357730943709612
Valid Loss:  0.00019572721794247627
Epoch:  151  	Training Loss: 0.00017449739971198142
Test Loss:  0.0001356208958895877
Valid Loss:  0.0001954876643139869
Epoch:  152  	Training Loss: 0.0001743833563523367
Test Loss:  0.00013505792594514787
Valid Loss:  0.0001945284311659634
Epoch:  153  	Training Loss: 0.0001740637671900913
Test Loss:  0.00013460233458317816
Valid Loss:  0.00019371192320249975
Epoch:  154  	Training Loss: 0.00017379930068273097
Test Loss:  0.00013422196207102388
Valid Loss:  0.00019299809355288744
Epoch:  155  	Training Loss: 0.00017356981697957963
Test Loss:  0.00013389445666689426
Valid Loss:  0.00019236090884078294
Epoch:  156  	Training Loss: 0.00017336482414975762
Test Loss:  0.00013360790035221726
Valid Loss:  0.0001917829504236579
Epoch:  157  	Training Loss: 0.0001731781812850386
Test Loss:  0.00013335098628886044
Valid Loss:  0.00019125068502034992
Epoch:  158  	Training Loss: 0.00017300518811680377
Test Loss:  0.00013311860675457865
Valid Loss:  0.00019075575983151793
Epoch:  159  	Training Loss: 0.00017284357454627752
Test Loss:  0.00013290597416926175
Valid Loss:  0.00019029249961022288
Epoch:  160  	Training Loss: 0.00017269287491217256
Test Loss:  0.00013270969793666154
Valid Loss:  0.00018985531642101705
Epoch:  161  	Training Loss: 0.00017255071725230664
Test Loss:  0.0001325269549852237
Valid Loss:  0.00018944148905575275
Epoch:  162  	Training Loss: 0.00017241679597645998
Test Loss:  0.00013242074055597186
Valid Loss:  0.0001891795254778117
Epoch:  163  	Training Loss: 0.0001723232853692025
Test Loss:  0.00013231506454758346
Valid Loss:  0.0001889208797365427
Epoch:  164  	Training Loss: 0.00017223395116161555
Test Loss:  0.0001322112511843443
Valid Loss:  0.00018866606114897877
Epoch:  165  	Training Loss: 0.00017214874969795346
Test Loss:  0.00013210964971221983
Valid Loss:  0.00018841508426703513
Epoch:  166  	Training Loss: 0.0001720672007650137
Test Loss:  0.00013201090041548014
Valid Loss:  0.00018816918600350618
Epoch:  167  	Training Loss: 0.00017198914429172873
Test Loss:  0.00013191398466005921
Valid Loss:  0.0001879283518064767
Epoch:  168  	Training Loss: 0.00017191447841469198
Test Loss:  0.0001318205613642931
Valid Loss:  0.00018769269809126854
Epoch:  169  	Training Loss: 0.00017184304306283593
Test Loss:  0.00013172972830943763
Valid Loss:  0.00018746322894003242
Epoch:  170  	Training Loss: 0.00017177456174977124
Test Loss:  0.0001316418347414583
Valid Loss:  0.00018723870743997395
Epoch:  171  	Training Loss: 0.00017170888895634562
Test Loss:  0.000131556938868016
Valid Loss:  0.00018702013767324388
Epoch:  172  	Training Loss: 0.00017164560267701745
Test Loss:  0.0001269069907721132
Valid Loss:  0.00018286920385435224
Epoch:  173  	Training Loss: 0.00016719731502234936
Test Loss:  0.0001226933964062482
Valid Loss:  0.00017912429757416248
Epoch:  174  	Training Loss: 0.00016303558368235826
Test Loss:  0.00011855031334562227
Valid Loss:  0.00017543109424877912
Epoch:  175  	Training Loss: 0.0001589314197190106
Test Loss:  0.0001145754213212058
Valid Loss:  0.0001716827682685107
Epoch:  176  	Training Loss: 0.00015498787979595363
Test Loss:  0.00011076922237407416
Valid Loss:  0.0001680480781942606
Epoch:  177  	Training Loss: 0.00015114314737729728
Test Loss:  0.00010707469482440501
Valid Loss:  0.0001644807489356026
Epoch:  178  	Training Loss: 0.00014740583719685674
Test Loss:  0.0001035274617606774
Valid Loss:  0.00016078379121609032
Epoch:  179  	Training Loss: 0.00014380531501956284
Test Loss:  0.00010011733684223145
Valid Loss:  0.00015695190813858062
Epoch:  180  	Training Loss: 0.00014027408906258643
Test Loss:  9.674641478341073e-05
Valid Loss:  0.00015323044499382377
Epoch:  181  	Training Loss: 0.0001367868680972606
Test Loss:  9.350576146971434e-05
Valid Loss:  0.00014958062092773616
Epoch:  182  	Training Loss: 0.00013342342572286725
Test Loss:  9.330966713605449e-05
Valid Loss:  0.000148904524394311
Epoch:  183  	Training Loss: 0.00013325095642358065
Test Loss:  9.319073433289304e-05
Valid Loss:  0.00014841646770946681
Epoch:  184  	Training Loss: 0.00013313439558260143
Test Loss:  9.310667519457638e-05
Valid Loss:  0.00014803599333390594
Epoch:  185  	Training Loss: 0.00013304231106303632
Test Loss:  9.304152627009898e-05
Valid Loss:  0.00014772058057133108
Epoch:  186  	Training Loss: 0.0001329629449173808
Test Loss:  9.29868983803317e-05
Valid Loss:  0.00014744776126462966
Epoch:  187  	Training Loss: 0.00013289129128679633
Test Loss:  9.293983748648316e-05
Valid Loss:  0.00014720240142196417
Epoch:  188  	Training Loss: 0.00013282542931847274
Test Loss:  9.289752051699907e-05
Valid Loss:  0.00014697763253934681
Epoch:  189  	Training Loss: 0.00013276419485919178
Test Loss:  9.285990381613374e-05
Valid Loss:  0.0001467692491132766
Epoch:  190  	Training Loss: 0.00013270761701278389
Test Loss:  9.282666724175215e-05
Valid Loss:  0.0001465735404053703
Epoch:  191  	Training Loss: 0.00013265470624901354
Test Loss:  9.279577352572232e-05
Valid Loss:  0.0001463899970985949
Epoch:  192  	Training Loss: 0.0001326053898083046
Test Loss:  9.273221803596243e-05
Valid Loss:  0.00014642183668911457
Epoch:  193  	Training Loss: 0.0001325687044300139
Test Loss:  9.272882016375661e-05
Valid Loss:  0.00014643743634223938
Epoch:  194  	Training Loss: 0.00013254240911919624
Test Loss:  9.273899922845885e-05
Valid Loss:  0.00014644746261183172
Epoch:  195  	Training Loss: 0.00013251788914203644
Test Loss:  9.275361662730575e-05
Valid Loss:  0.00014645425835624337
Epoch:  196  	Training Loss: 0.0001324943295912817
Test Loss:  9.276850323658437e-05
Valid Loss:  0.00014646672934759408
Epoch:  197  	Training Loss: 0.0001324717013631016
Test Loss:  9.278373909182847e-05
Valid Loss:  0.0001464800734538585
Epoch:  198  	Training Loss: 0.00013244981528259814
Test Loss:  9.2797759862151e-05
Valid Loss:  0.00014649283548351377
Epoch:  199  	Training Loss: 0.00013243014109320939
Test Loss:  9.277208300773054e-05
Valid Loss:  0.00014650255616288632
Epoch:  200  	Training Loss: 0.00013241080159787089
Test Loss:  9.28058652789332e-05
Valid Loss:  0.00014650961384177208
Epoch:  201  	Training Loss: 0.00013239303370937705
Test Loss:  9.278532525058836e-05
Valid Loss:  0.00014651799574494362
Epoch:  202  	Training Loss: 0.0001323748438153416
Test Loss:  9.15435011847876e-05
Valid Loss:  0.0001451539428671822
Epoch:  203  	Training Loss: 0.0001309273939114064
Test Loss:  9.036019037012011e-05
Valid Loss:  0.00014385045506060123
Epoch:  204  	Training Loss: 0.00012955136480741203
Test Loss:  8.92357129487209e-05
Valid Loss:   41%|████      | 205/500 [02:35<03:07,  1.58it/s] 41%|████▏     | 207/500 [02:35<02:15,  2.16it/s] 42%|████▏     | 209/500 [02:36<01:40,  2.91it/s] 42%|████▏     | 211/500 [02:42<05:44,  1.19s/it] 43%|████▎     | 213/500 [02:42<04:06,  1.17it/s] 43%|████▎     | 215/500 [02:42<02:56,  1.61it/s] 43%|████▎     | 217/500 [02:42<02:08,  2.20it/s] 44%|████▍     | 219/500 [02:42<01:34,  2.97it/s] 44%|████▍     | 221/500 [02:49<05:34,  1.20s/it] 45%|████▍     | 223/500 [02:49<03:58,  1.16it/s] 45%|████▌     | 225/500 [02:49<02:51,  1.60it/s] 45%|████▌     | 227/500 [02:49<02:04,  2.19it/s] 46%|████▌     | 229/500 [02:49<01:32,  2.93it/s] 46%|████▌     | 231/500 [02:56<05:29,  1.23s/it] 47%|████▋     | 233/500 [02:56<03:55,  1.14it/s] 47%|████▋     | 235/500 [02:56<02:48,  1.57it/s] 47%|████▋     | 237/500 [02:56<02:02,  2.15it/s] 48%|████▊     | 239/500 [02:57<01:29,  2.90it/s] 48%|████▊     | 241/500 [03:03<05:11,  1.20s/it] 49%|████▊     | 243/500 [03:03<03:43,  1.15it/s] 49%|████▉     | 245/500 [03:03<02:40,  1.59it/s] 49%|████▉     | 247/500 [03:03<01:56,  2.18it/s] 50%|████▉     | 249/500 [03:04<01:25,  2.94it/s] 50%|█████     | 251/500 [03:10<05:00,  1.21s/it] 51%|█████     | 253/500 [03:10<03:34,  1.15it/s] 51%|█████     | 255/500 [03:10<02:33,  1.60it/s] 51%|█████▏    | 257/500 [03:10<01:51,  2.18it/s] 52%|█████▏    | 259/500 [03:11<01:21,  2.94it/s] 52%|█████▏    | 261/500 [03:17<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:17<03:23,  1.16it/s] 53%|█████▎    | 265/500 [03:17<02:26,  1.61it/s] 53%|█████▎    | 267/500 [03:17<01:46,  2.20it/s] 54%|█████▍    | 269/500 [03:17<01:18,  2.96it/s] 54%|█████▍    | 271/500 [03:24<04:33,  1.19s/it]0.00014261569594964385
Epoch:  205  	Training Loss: 0.00012824762961827219
Test Loss:  8.816608169581741e-05
Valid Loss:  0.0001414452272001654
Epoch:  206  	Training Loss: 0.00012701208470389247
Test Loss:  8.714828436495736e-05
Valid Loss:  0.00014033602201379836
Epoch:  207  	Training Loss: 0.0001258408883586526
Test Loss:  8.617997082183138e-05
Valid Loss:  0.00013928397675044835
Epoch:  208  	Training Loss: 0.0001247274485649541
Test Loss:  8.525448356522247e-05
Valid Loss:  0.00013828178634867072
Epoch:  209  	Training Loss: 0.00012366559531074017
Test Loss:  8.437280484940857e-05
Valid Loss:  0.0001373306440655142
Epoch:  210  	Training Loss: 0.000122653174912557
Test Loss:  8.352878649020568e-05
Valid Loss:  0.00013642273552250117
Epoch:  211  	Training Loss: 0.00012168673856649548
Test Loss:  8.272382547147572e-05
Valid Loss:  0.00013556008343584836
Epoch:  212  	Training Loss: 0.00012076697021257132
Test Loss:  8.212091779569164e-05
Valid Loss:  0.00013393325207289308
Epoch:  213  	Training Loss: 0.00012001856521237642
Test Loss:  8.182722376659513e-05
Valid Loss:  0.00013288170157466084
Epoch:  214  	Training Loss: 0.00011960150732193142
Test Loss:  8.167851046891883e-05
Valid Loss:  0.00013216504885349423
Epoch:  215  	Training Loss: 0.00011935153452213854
Test Loss:  8.159565186360851e-05
Valid Loss:  0.00013164755364414304
Epoch:  216  	Training Loss: 0.00011918606469407678
Test Loss:  8.154060924425721e-05
Valid Loss:  0.00013125414261594415
Epoch:  217  	Training Loss: 0.00011906400322914124
Test Loss:  8.149620407493785e-05
Valid Loss:  0.0001309406361542642
Epoch:  218  	Training Loss: 0.00011896461364813149
Test Loss:  8.145528408931568e-05
Valid Loss:  0.00013067928375676274
Epoch:  219  	Training Loss: 0.00011887794244103134
Test Loss:  8.141465514199808e-05
Valid Loss:  0.00013045372907072306
Epoch:  220  	Training Loss: 0.00011879832163685933
Test Loss:  8.137205441016704e-05
Valid Loss:  0.00013025396037846804
Epoch:  221  	Training Loss: 0.00011872292088810354
Test Loss:  8.132839866448194e-05
Valid Loss:  0.00013007313827984035
Epoch:  222  	Training Loss: 0.00011865049600601196
Test Loss:  8.13264778116718e-05
Valid Loss:  0.0001300621370319277
Epoch:  223  	Training Loss: 0.00011864678526762873
Test Loss:  8.132534276228398e-05
Valid Loss:  0.00013004953507333994
Epoch:  224  	Training Loss: 0.00011864323460031301
Test Loss:  8.132457878673449e-05
Valid Loss:  0.00013003562344238162
Epoch:  225  	Training Loss: 0.00011863998952321708
Test Loss:  8.132435323204845e-05
Valid Loss:  0.00013002019841223955
Epoch:  226  	Training Loss: 0.00011863659892696887
Test Loss:  8.132457878673449e-05
Valid Loss:  0.00013000475883018225
Epoch:  227  	Training Loss: 0.00011863350664498284
Test Loss:  8.132419316098094e-05
Valid Loss:  0.00012998863530810922
Epoch:  228  	Training Loss: 0.00011863038525916636
Test Loss:  8.132477523759007e-05
Valid Loss:  0.0001299721625400707
Epoch:  229  	Training Loss: 0.00011862719838973135
Test Loss:  8.132559742080048e-05
Valid Loss:  0.0001299560972256586
Epoch:  230  	Training Loss: 0.00011862426617881283
Test Loss:  8.132575749186799e-05
Valid Loss:  0.00012993969721719623
Epoch:  231  	Training Loss: 0.00011862130486406386
Test Loss:  8.13264268799685e-05
Valid Loss:  0.00012992334086447954
Epoch:  232  	Training Loss: 0.00011861830716952682
Test Loss:  8.03606235422194e-05
Valid Loss:  0.0001293121458729729
Epoch:  233  	Training Loss: 0.00011783343506976962
Test Loss:  7.950055442051962e-05
Valid Loss:  0.0001287484628846869
Epoch:  234  	Training Loss: 0.00011715588334482163
Test Loss:  7.8813754953444e-05
Valid Loss:  0.00012821448035538197
Epoch:  235  	Training Loss: 0.00011659394658636302
Test Loss:  7.826591900084168e-05
Valid Loss:  0.000127739884192124
Epoch:  236  	Training Loss: 0.00011615175753831863
Test Loss:  7.777231803629547e-05
Valid Loss:  0.00012729805894196033
Epoch:  237  	Training Loss: 0.00011576816905289888
Test Loss:  7.730137440375984e-05
Valid Loss:  0.00012692798918578774
Epoch:  238  	Training Loss: 0.00011540274135768414
Test Loss:  7.685048331040889e-05
Valid Loss:  0.00012659051571972668
Epoch:  239  	Training Loss: 0.00011505304428283125
Test Loss:  7.641939737368375e-05
Valid Loss:  0.00012626936950255185
Epoch:  240  	Training Loss: 0.00011472743062768131
Test Loss:  7.603063568240032e-05
Valid Loss:  0.00012597064778674394
Epoch:  241  	Training Loss: 0.00011443991388659924
Test Loss:  7.565641135443002e-05
Valid Loss:  0.00012568625970743597
Epoch:  242  	Training Loss: 0.00011416455527069047
Test Loss:  7.55822256905958e-05
Valid Loss:  0.00012572846026159823
Epoch:  243  	Training Loss: 0.00011414755863370374
Test Loss:  7.554352487204596e-05
Valid Loss:  0.00012574050924740732
Epoch:  244  	Training Loss: 0.0001141366665251553
Test Loss:  7.551636372227222e-05
Valid Loss:  0.00012573997082654387
Epoch:  245  	Training Loss: 0.00011412705498514697
Test Loss:  7.549327710876241e-05
Valid Loss:  0.00012573448475450277
Epoch:  246  	Training Loss: 0.00011411722516641021
Test Loss:  7.547168206656352e-05
Valid Loss:  0.00012572668492794037
Epoch:  247  	Training Loss: 0.00011410755541874096
Test Loss:  7.545073458459228e-05
Valid Loss:  0.00012571836123242974
Epoch:  248  	Training Loss: 0.00011409830767661333
Test Loss:  7.54309439798817e-05
Valid Loss:  0.0001257159747183323
Epoch:  249  	Training Loss: 0.00011409007129259408
Test Loss:  7.541321974713355e-05
Valid Loss:  0.0001257119292858988
Epoch:  250  	Training Loss: 0.00011408281716285273
Test Loss:  7.539679063484073e-05
Valid Loss:  0.0001257099793292582
Epoch:  251  	Training Loss: 0.0001140758249675855
Test Loss:  7.538186036981642e-05
Valid Loss:  0.00012570610851980746
Epoch:  252  	Training Loss: 0.00011406878184061497
Test Loss:  7.532475865446031e-05
Valid Loss:  0.00012488913489505649
Epoch:  253  	Training Loss: 0.00011329022527206689
Test Loss:  7.544695836259052e-05
Valid Loss:  0.00012469089415390044
Epoch:  254  	Training Loss: 0.00011314103176118806
Test Loss:  7.553484465461224e-05
Valid Loss:  0.0001246628089575097
Epoch:  255  	Training Loss: 0.00011310310947010294
Test Loss:  7.558171637356281e-05
Valid Loss:  0.00012465396139305085
Epoch:  256  	Training Loss: 0.00011309068941045552
Test Loss:  7.560342783108354e-05
Valid Loss:  0.00012464936298783869
Epoch:  257  	Training Loss: 0.00011308425746392459
Test Loss:  7.558021752629429e-05
Valid Loss:  0.00012464627798181027
Epoch:  258  	Training Loss: 0.00011308059038128704
Test Loss:  7.55980217945762e-05
Valid Loss:  0.00012464221799746156
Epoch:  259  	Training Loss: 0.00011307507520541549
Test Loss:  7.557235949207097e-05
Valid Loss:  0.00012463882740121335
Epoch:  260  	Training Loss: 0.00011307100794510916
Test Loss:  7.558926154160872e-05
Valid Loss:  0.00012463494203984737
Epoch:  261  	Training Loss: 0.0001130652308347635
Test Loss:  7.556310447398573e-05
Valid Loss:  0.00012463124585337937
Epoch:  262  	Training Loss: 0.00011306095984764397
Test Loss:  7.556102355010808e-05
Valid Loss:  0.0001246286410605535
Epoch:  263  	Training Loss: 0.00011305882799206302
Test Loss:  7.555905176559463e-05
Valid Loss:  0.0001246262399945408
Epoch:  264  	Training Loss: 0.00011305662337690592
Test Loss:  7.55568835302256e-05
Valid Loss:  0.0001246237225132063
Epoch:  265  	Training Loss: 0.00011305445514153689
Test Loss:  7.555486808996648e-05
Valid Loss:  0.00012462129234336317
Epoch:  266  	Training Loss: 0.00011305223597446457
Test Loss:  7.555250340374187e-05
Valid Loss:  0.00012461887672543526
Epoch:  267  	Training Loss: 0.00011305010411888361
Test Loss:  7.555057527497411e-05
Valid Loss:  0.00012461646110750735
Epoch:  268  	Training Loss: 0.00011304783402010798
Test Loss:  7.554840703960508e-05
Valid Loss:  0.0001246139727300033
Epoch:  269  	Training Loss: 0.00011304571671644226
Test Loss:  7.554634066764265e-05
Valid Loss:  0.00012461178994271904
Epoch:  270  	Training Loss: 0.00011304351937724277
Test Loss:  7.554431795142591e-05
Valid Loss:  0.00012460914149414748
Epoch:  271  	Training Loss: 0.00011304128565825522
Test Loss:  7.554209150839597e-05
Valid Loss:  0.00012460685684345663
 55%|█████▍    | 273/500 [03:24<03:14,  1.17it/s] 55%|█████▌    | 275/500 [03:24<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:24<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:24<01:15,  2.95it/s] 56%|█████▌    | 281/500 [03:31<04:19,  1.19s/it] 57%|█████▋    | 283/500 [03:31<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:31<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:31<01:36,  2.22it/s] 58%|█████▊    | 289/500 [03:31<01:11,  2.96it/s] 58%|█████▊    | 291/500 [03:38<04:09,  1.19s/it] 59%|█████▊    | 293/500 [03:38<02:57,  1.17it/s] 59%|█████▉    | 295/500 [03:38<02:07,  1.61it/s] 59%|█████▉    | 297/500 [03:38<01:32,  2.20it/s] 60%|█████▉    | 299/500 [03:38<01:07,  2.96it/s] 60%|██████    | 301/500 [03:45<03:59,  1.20s/it] 61%|██████    | 303/500 [03:45<02:50,  1.16it/s] 61%|██████    | 305/500 [03:45<02:01,  1.60it/s] 61%|██████▏   | 307/500 [03:45<01:28,  2.19it/s] 62%|██████▏   | 309/500 [03:45<01:04,  2.95it/s] 62%|██████▏   | 311/500 [03:52<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:52<02:40,  1.17it/s] 63%|██████▎   | 315/500 [03:52<01:54,  1.61it/s] 63%|██████▎   | 317/500 [03:52<01:22,  2.21it/s] 64%|██████▍   | 319/500 [03:52<01:00,  2.97it/s] 64%|██████▍   | 321/500 [03:58<03:32,  1.19s/it] 65%|██████▍   | 323/500 [03:59<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:59<01:48,  1.61it/s] 65%|██████▌   | 327/500 [03:59<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:59<00:57,  2.96it/s] 66%|██████▌   | 331/500 [04:05<03:21,  1.19s/it] 67%|██████▋   | 333/500 [04:06<02:23,  1.17it/s] 67%|██████▋   | 335/500 [04:06<01:42,  1.61it/s] 67%|██████▋   | 337/500 [04:06<01:14,  2.19it/s] 68%|██████▊   | 339/500 [04:06<00:54,  2.95it/s]Epoch:  272  	Training Loss: 0.00011303915380267426
Test Loss:  6.971185212023556e-05
Valid Loss:  0.00011779726628446952
Epoch:  273  	Training Loss: 0.00010588156146695837
Test Loss:  6.889894575579092e-05
Valid Loss:  0.00011619397264439613
Epoch:  274  	Training Loss: 0.0001034788292599842
Test Loss:  6.742589903296903e-05
Valid Loss:  0.00011379020725144073
Epoch:  275  	Training Loss: 0.00010248967737425119
Test Loss:  6.664237298537046e-05
Valid Loss:  0.00011304912914056331
Epoch:  276  	Training Loss: 0.00010089044371852651
Test Loss:  6.530436803586781e-05
Valid Loss:  0.00011033566988771781
Epoch:  277  	Training Loss: 9.960331954061985e-05
Test Loss:  6.447797204600647e-05
Valid Loss:  0.00010976879275403917
Epoch:  278  	Training Loss: 9.833395597524941e-05
Test Loss:  6.339779065456241e-05
Valid Loss:  0.00010732416558312252
Epoch:  279  	Training Loss: 9.714026236906648e-05
Test Loss:  6.249934813240543e-05
Valid Loss:  0.00010663867578841746
Epoch:  280  	Training Loss: 9.59021708695218e-05
Test Loss:  6.16396646364592e-05
Valid Loss:  0.00010456699965288863
Epoch:  281  	Training Loss: 9.488283831160516e-05
Test Loss:  6.072523319744505e-05
Valid Loss:  0.00010398745507700369
Epoch:  282  	Training Loss: 9.368937026010826e-05
Test Loss:  6.0646103520412e-05
Valid Loss:  0.00010284494055667892
Epoch:  283  	Training Loss: 9.32178008952178e-05
Test Loss:  6.0621627198997885e-05
Valid Loss:  0.00010193941125180572
Epoch:  284  	Training Loss: 9.285384294344112e-05
Test Loss:  6.062875399948098e-05
Valid Loss:  0.00010120077786268666
Epoch:  285  	Training Loss: 9.256476914742962e-05
Test Loss:  6.0655540437437594e-05
Valid Loss:  0.00010058740735985339
Epoch:  286  	Training Loss: 9.233105811290443e-05
Test Loss:  6.069542723707855e-05
Valid Loss:  0.00010006974480347708
Epoch:  287  	Training Loss: 9.214036981575191e-05
Test Loss:  6.074293196434155e-05
Valid Loss:  9.962834883481264e-05
Epoch:  288  	Training Loss: 9.198296174872667e-05
Test Loss:  6.079664308344945e-05
Valid Loss:  9.924930054694414e-05
Epoch:  289  	Training Loss: 9.18531441129744e-05
Test Loss:  6.085370478103869e-05
Valid Loss:  9.892095113173127e-05
Epoch:  290  	Training Loss: 9.174544538836926e-05
Test Loss:  6.091236718930304e-05
Valid Loss:  9.863491141004488e-05
Epoch:  291  	Training Loss: 9.165567462332547e-05
Test Loss:  6.0971990023972467e-05
Valid Loss:  9.838458936428651e-05
Epoch:  292  	Training Loss: 9.158060129266232e-05
Test Loss:  5.881328979739919e-05
Valid Loss:  9.60684847086668e-05
Epoch:  293  	Training Loss: 8.901188266463578e-05
Test Loss:  5.7025048590730876e-05
Valid Loss:  9.448335185879841e-05
Epoch:  294  	Training Loss: 8.712605631444603e-05
Test Loss:  5.545291060116142e-05
Valid Loss:  9.326414146926254e-05
Epoch:  295  	Training Loss: 8.559235720895231e-05
Test Loss:  5.404648982221261e-05
Valid Loss:  9.224246605299413e-05
Epoch:  296  	Training Loss: 8.428304863628e-05
Test Loss:  5.2777377277379856e-05
Valid Loss:  9.133639105129987e-05
Epoch:  297  	Training Loss: 8.312706631841138e-05
Test Loss:  5.163878813618794e-05
Valid Loss:  9.053708345163614e-05
Epoch:  298  	Training Loss: 8.210972009692341e-05
Test Loss:  5.06156611663755e-05
Valid Loss:  8.980421989690512e-05
Epoch:  299  	Training Loss: 8.119498670566827e-05
Test Loss:  4.96745778946206e-05
Valid Loss:  8.91114177647978e-05
Epoch:  300  	Training Loss: 8.03523653303273e-05
Test Loss:  4.881656786892563e-05
Valid Loss:  8.846379205351695e-05
Epoch:  301  	Training Loss: 7.95744126662612e-05
Test Loss:  4.80157759739086e-05
Valid Loss:  8.784612873569131e-05
Epoch:  302  	Training Loss: 7.88493052823469e-05
Test Loss:  4.795686254510656e-05
Valid Loss:  8.782419899944216e-05
Epoch:  303  	Training Loss: 7.88139586802572e-05
Test Loss:  4.792416802956723e-05
Valid Loss:  8.779626659816131e-05
Epoch:  304  	Training Loss: 7.878769247327e-05
Test Loss:  4.790769162354991e-05
Valid Loss:  8.776273170951754e-05
Epoch:  305  	Training Loss: 7.876611198298633e-05
Test Loss:  4.790211096405983e-05
Valid Loss:  8.772611909080297e-05
Epoch:  306  	Training Loss: 7.874691800680012e-05
Test Loss:  4.790262755705044e-05
Valid Loss:  8.768565021455288e-05
Epoch:  307  	Training Loss: 7.872912829043344e-05
Test Loss:  4.7907869884511456e-05
Valid Loss:  8.764397352933884e-05
Epoch:  308  	Training Loss: 7.871234993217513e-05
Test Loss:  4.7915775212459266e-05
Valid Loss:  8.760124910622835e-05
Epoch:  309  	Training Loss: 7.869605178711936e-05
Test Loss:  4.7925772378221154e-05
Valid Loss:  8.755781163927168e-05
Epoch:  310  	Training Loss: 7.86805321695283e-05
Test Loss:  4.7936689952621236e-05
Valid Loss:  8.751457062317058e-05
Epoch:  311  	Training Loss: 7.866568194003776e-05
Test Loss:  4.7948786232154816e-05
Valid Loss:  8.747231913730502e-05
Epoch:  312  	Training Loss: 7.865097722969949e-05
Test Loss:  4.778394941240549e-05
Valid Loss:  8.73529352247715e-05
Epoch:  313  	Training Loss: 7.851872214814648e-05
Test Loss:  4.774828994413838e-05
Valid Loss:  8.720070763956755e-05
Epoch:  314  	Training Loss: 7.84338335506618e-05
Test Loss:  4.775690831593238e-05
Valid Loss:  8.703419007360935e-05
Epoch:  315  	Training Loss: 7.836232543922961e-05
Test Loss:  4.7783643822185695e-05
Valid Loss:  8.686695218784735e-05
Epoch:  316  	Training Loss: 7.829860260244459e-05
Test Loss:  4.781779716722667e-05
Valid Loss:  8.6706000729464e-05
Epoch:  317  	Training Loss: 7.824039494153112e-05
Test Loss:  4.78491565445438e-05
Valid Loss:  8.65564652485773e-05
Epoch:  318  	Training Loss: 7.818652375135571e-05
Test Loss:  4.788687510881573e-05
Valid Loss:  8.641251770313829e-05
Epoch:  319  	Training Loss: 7.813777483534068e-05
Test Loss:  4.7927223931765184e-05
Valid Loss:  8.627604984212667e-05
Epoch:  320  	Training Loss: 7.809337694197893e-05
Test Loss:  4.796883149538189e-05
Valid Loss:  8.614736725576222e-05
Epoch:  321  	Training Loss: 7.805338827893138e-05
Test Loss:  4.801032264367677e-05
Valid Loss:  8.602678281022236e-05
Epoch:  322  	Training Loss: 7.801705942256376e-05
Test Loss:  4.7851681301835924e-05
Valid Loss:  8.57459963299334e-05
Epoch:  323  	Training Loss: 7.780206942697987e-05
Test Loss:  4.7631459892727435e-05
Valid Loss:  8.551048813387752e-05
Epoch:  324  	Training Loss: 7.759656000416726e-05
Test Loss:  4.744269244838506e-05
Valid Loss:  8.530949708074331e-05
Epoch:  325  	Training Loss: 7.73986685089767e-05
Test Loss:  4.7250247007468715e-05
Valid Loss:  8.512256317771971e-05
Epoch:  326  	Training Loss: 7.720825669821352e-05
Test Loss:  4.706637992057949e-05
Valid Loss:  8.494323265040293e-05
Epoch:  327  	Training Loss: 7.702482980675995e-05
Test Loss:  4.688648186856881e-05
Valid Loss:  8.477311348542571e-05
Epoch:  328  	Training Loss: 7.68534664530307e-05
Test Loss:  4.67256031697616e-05
Valid Loss:  8.461584366159514e-05
Epoch:  329  	Training Loss: 7.669916521990672e-05
Test Loss:  4.6562403440475464e-05
Valid Loss:  8.446662104688585e-05
Epoch:  330  	Training Loss: 7.654904766241089e-05
Test Loss:  4.640524639398791e-05
Valid Loss:  8.432399772573262e-05
Epoch:  331  	Training Loss: 7.640416151843965e-05
Test Loss:  4.625053043127991e-05
Valid Loss:  8.418779179919511e-05
Epoch:  332  	Training Loss: 7.626391743542627e-05
Test Loss:  4.624309440259822e-05
Valid Loss:  8.41449509607628e-05
Epoch:  333  	Training Loss: 7.624621503055096e-05
Test Loss:  4.6252978791017085e-05
Valid Loss:  8.409746806137264e-05
Epoch:  334  	Training Loss: 7.623169949511066e-05
Test Loss:  4.627197631634772e-05
Valid Loss:  8.404810796491802e-05
Epoch:  335  	Training Loss: 7.621820259373635e-05
Test Loss:  4.629415343515575e-05
Valid Loss:  8.399914804613218e-05
Epoch:  336  	Training Loss: 7.620577525813133e-05
Test Loss:  4.631789488485083e-05
Valid Loss:  8.395203622058034e-05
Epoch:  337  	Training Loss: 7.619439566042274e-05
Test Loss:  4.634130164049566e-05
Valid Loss:  8.390629227505997e-05
Epoch:  338  	Training Loss: 7.618342351634055e-05
Test Loss:  4.636502853827551e-05
Valid Loss:  8.386268746107817e-05
Epoch:  339  	Training Loss: 7.617322262376547e-05
Test Loss:  4.6388089685933664e-05
Valid Loss:  8.382130181416869e-05
 68%|██████▊   | 341/500 [04:12<03:09,  1.19s/it] 69%|██████▊   | 343/500 [04:12<02:14,  1.17it/s] 69%|██████▉   | 345/500 [04:13<01:36,  1.61it/s] 69%|██████▉   | 347/500 [04:13<01:09,  2.20it/s] 70%|██████▉   | 349/500 [04:13<00:51,  2.95it/s] 70%|███████   | 351/500 [04:19<02:57,  1.19s/it] 71%|███████   | 353/500 [04:19<02:06,  1.17it/s] 71%|███████   | 355/500 [04:20<01:29,  1.61it/s] 71%|███████▏  | 357/500 [04:20<01:04,  2.21it/s] 72%|███████▏  | 359/500 [04:20<00:47,  2.97it/s] 72%|███████▏  | 361/500 [04:26<02:47,  1.20s/it] 73%|███████▎  | 363/500 [04:26<01:58,  1.16it/s] 73%|███████▎  | 365/500 [04:27<01:24,  1.60it/s] 73%|███████▎  | 367/500 [04:27<01:01,  2.18it/s] 74%|███████▍  | 369/500 [04:27<00:45,  2.90it/s] 74%|███████▍  | 371/500 [04:33<02:37,  1.22s/it] 75%|███████▍  | 373/500 [04:33<01:51,  1.14it/s] 75%|███████▌  | 375/500 [04:34<01:18,  1.58it/s] 75%|███████▌  | 377/500 [04:34<00:56,  2.17it/s] 76%|███████▌  | 379/500 [04:34<00:41,  2.92it/s] 76%|███████▌  | 381/500 [04:40<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:40<01:39,  1.17it/s] 77%|███████▋  | 385/500 [04:40<01:10,  1.62it/s] 77%|███████▋  | 387/500 [04:41<00:50,  2.22it/s] 78%|███████▊  | 389/500 [04:41<00:37,  2.98it/s] 78%|███████▊  | 391/500 [04:47<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:47<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:47<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:47<00:46,  2.23it/s] 80%|███████▉  | 399/500 [04:48<00:33,  2.98it/s] 80%|████████  | 401/500 [04:54<01:58,  1.19s/it] 81%|████████  | 403/500 [04:54<01:23,  1.17it/s] 81%|████████  | 405/500 [04:54<00:58,  1.61it/s] 81%|████████▏ | 407/500 [04:54<00:42,  2.20it/s]Epoch:  340  	Training Loss: 7.61633345973678e-05
Test Loss:  4.6409979404415935e-05
Valid Loss:  8.378181519219652e-05
Epoch:  341  	Training Loss: 7.61544652050361e-05
Test Loss:  4.6431432565441355e-05
Valid Loss:  8.374435128644109e-05
Epoch:  342  	Training Loss: 7.614588685100898e-05
Test Loss:  4.646760498872027e-05
Valid Loss:  8.37052139104344e-05
Epoch:  343  	Training Loss: 7.611500768689439e-05
Test Loss:  4.648035974241793e-05
Valid Loss:  8.3679158706218e-05
Epoch:  344  	Training Loss: 7.608978194184601e-05
Test Loss:  4.647726018447429e-05
Valid Loss:  8.36590479593724e-05
Epoch:  345  	Training Loss: 7.606738654430956e-05
Test Loss:  4.646684101317078e-05
Valid Loss:  8.36406834423542e-05
Epoch:  346  	Training Loss: 7.604609709233046e-05
Test Loss:  4.645447916118428e-05
Valid Loss:  8.362378866877407e-05
Epoch:  347  	Training Loss: 7.602484402013943e-05
Test Loss:  4.644461296265945e-05
Valid Loss:  8.360544597962871e-05
Epoch:  348  	Training Loss: 7.600230310345069e-05
Test Loss:  4.6432232920778915e-05
Valid Loss:  8.358823833987117e-05
Epoch:  349  	Training Loss: 7.598043885082006e-05
Test Loss:  4.641887062462047e-05
Valid Loss:  8.357223850907758e-05
Epoch:  350  	Training Loss: 7.59595277486369e-05
Test Loss:  4.640560655388981e-05
Valid Loss:  8.355564204975963e-05
Epoch:  351  	Training Loss: 7.593907503178343e-05
Test Loss:  4.639249527826905e-05
Valid Loss:  8.354029705515131e-05
Epoch:  352  	Training Loss: 7.591950998175889e-05
Test Loss:  4.6387212933041155e-05
Valid Loss:  8.353912562597543e-05
Epoch:  353  	Training Loss: 7.591671601403505e-05
Test Loss:  4.6382636355701834e-05
Valid Loss:  8.353774319402874e-05
Epoch:  354  	Training Loss: 7.591391477035359e-05
Test Loss:  4.637870006263256e-05
Valid Loss:  8.35364407976158e-05
Epoch:  355  	Training Loss: 7.59110989747569e-05
Test Loss:  4.6374367229873314e-05
Valid Loss:  8.353422163054347e-05
Epoch:  356  	Training Loss: 7.590826135128736e-05
Test Loss:  4.637012170860544e-05
Valid Loss:  8.353299926966429e-05
Epoch:  357  	Training Loss: 7.590546738356352e-05
Test Loss:  4.6366687456611544e-05
Valid Loss:  8.35309037938714e-05
Epoch:  358  	Training Loss: 7.590273162350059e-05
Test Loss:  4.636291123460978e-05
Valid Loss:  8.35288519738242e-05
Epoch:  359  	Training Loss: 7.589990855194628e-05
Test Loss:  4.635930235963315e-05
Valid Loss:  8.35265964269638e-05
Epoch:  360  	Training Loss: 7.589704910060391e-05
Test Loss:  4.63556862086989e-05
Valid Loss:  8.352470467798412e-05
Epoch:  361  	Training Loss: 7.589421875309199e-05
Test Loss:  4.635262303054333e-05
Valid Loss:  8.35224927868694e-05
Epoch:  362  	Training Loss: 7.589151209685951e-05
Test Loss:  4.621209154720418e-05
Valid Loss:  8.352750592166558e-05
Epoch:  363  	Training Loss: 7.587701838929206e-05
Test Loss:  4.619181709131226e-05
Valid Loss:  8.352146687684581e-05
Epoch:  364  	Training Loss: 7.587244181195274e-05
Test Loss:  4.619196261046454e-05
Valid Loss:  8.351188444066793e-05
Epoch:  365  	Training Loss: 7.586822903249413e-05
Test Loss:  4.6196313633117825e-05
Valid Loss:  8.350118878297508e-05
Epoch:  366  	Training Loss: 7.586418360006064e-05
Test Loss:  4.620072286343202e-05
Valid Loss:  8.349094423465431e-05
Epoch:  367  	Training Loss: 7.586024003103375e-05
Test Loss:  4.620541585609317e-05
Valid Loss:  8.348085975740105e-05
Epoch:  368  	Training Loss: 7.585625280626118e-05
Test Loss:  4.620965046342462e-05
Valid Loss:  8.347094262717292e-05
Epoch:  369  	Training Loss: 7.585218554595485e-05
Test Loss:  4.6213801397243515e-05
Valid Loss:  8.346090908162296e-05
Epoch:  370  	Training Loss: 7.584824197692797e-05
Test Loss:  4.6217741328291595e-05
Valid Loss:  8.345130481757224e-05
Epoch:  371  	Training Loss: 7.58443638915196e-05
Test Loss:  4.622167762136087e-05
Valid Loss:  8.34414895507507e-05
Epoch:  372  	Training Loss: 7.584066042909399e-05
Test Loss:  4.600801912602037e-05
Valid Loss:  8.3065104263369e-05
Epoch:  373  	Training Loss: 7.556148921139538e-05
Test Loss:  4.590095340972766e-05
Valid Loss:  8.274720312329009e-05
Epoch:  374  	Training Loss: 7.536158955190331e-05
Test Loss:  4.586180148180574e-05
Valid Loss:  8.246985817095265e-05
Epoch:  375  	Training Loss: 7.52118939999491e-05
Test Loss:  4.586554132401943e-05
Valid Loss:  8.222389442380518e-05
Epoch:  376  	Training Loss: 7.509578426834196e-05
Test Loss:  4.5898163079982623e-05
Valid Loss:  8.200404408853501e-05
Epoch:  377  	Training Loss: 7.500324863940477e-05
Test Loss:  4.5949622290208936e-05
Valid Loss:  8.180636359611526e-05
Epoch:  378  	Training Loss: 7.492837175959721e-05
Test Loss:  4.601180989993736e-05
Valid Loss:  8.162902668118477e-05
Epoch:  379  	Training Loss: 7.486688264179975e-05
Test Loss:  4.6080531319603324e-05
Valid Loss:  8.146941399900243e-05
Epoch:  380  	Training Loss: 7.481614011339843e-05
Test Loss:  4.615263605955988e-05
Valid Loss:  8.132597577059641e-05
Epoch:  381  	Training Loss: 7.477418694179505e-05
Test Loss:  4.622556298272684e-05
Valid Loss:  8.119732956402004e-05
Epoch:  382  	Training Loss: 7.473891309928149e-05
Test Loss:  4.631789124687202e-05
Valid Loss:  8.086630987236276e-05
Epoch:  383  	Training Loss: 7.445794472005218e-05
Test Loss:  4.63522483187262e-05
Valid Loss:  8.064085704972968e-05
Epoch:  384  	Training Loss: 7.42650663596578e-05
Test Loss:  4.634022116078995e-05
Valid Loss:  8.045176946325228e-05
Epoch:  385  	Training Loss: 7.409833779092878e-05
Test Loss:  4.630112380255014e-05
Valid Loss:  8.027961303014308e-05
Epoch:  386  	Training Loss: 7.394277781713754e-05
Test Loss:  4.62466778117232e-05
Valid Loss:  8.012026955839247e-05
Epoch:  387  	Training Loss: 7.379642920568585e-05
Test Loss:  4.618534512701444e-05
Valid Loss:  7.997096690814942e-05
Epoch:  388  	Training Loss: 7.365616329479963e-05
Test Loss:  4.612009070115164e-05
Valid Loss:  7.983001705724746e-05
Epoch:  389  	Training Loss: 7.352194370469078e-05
Test Loss:  4.6052547986619174e-05
Valid Loss:  7.96977401478216e-05
Epoch:  390  	Training Loss: 7.339307921938598e-05
Test Loss:  4.598326631821692e-05
Valid Loss:  7.957197522046044e-05
Epoch:  391  	Training Loss: 7.326886407099664e-05
Test Loss:  4.591346805682406e-05
Valid Loss:  7.945364632178098e-05
Epoch:  392  	Training Loss: 7.31495238142088e-05
Test Loss:  4.5578919525723904e-05
Valid Loss:  7.851234113331884e-05
Epoch:  393  	Training Loss: 7.194448699010536e-05
Test Loss:  4.559982335194945e-05
Valid Loss:  7.834863208699971e-05
Epoch:  394  	Training Loss: 7.168582669692114e-05
Test Loss:  4.55819426861126e-05
Valid Loss:  7.829449168639258e-05
Epoch:  395  	Training Loss: 7.15757196303457e-05
Test Loss:  4.5502038119593635e-05
Valid Loss:  7.82395654823631e-05
Epoch:  396  	Training Loss: 7.149898738134652e-05
Test Loss:  4.541325324680656e-05
Valid Loss:  7.818444282747805e-05
Epoch:  397  	Training Loss: 7.14260313543491e-05
Test Loss:  4.532200182438828e-05
Valid Loss:  7.813078264007345e-05
Epoch:  398  	Training Loss: 7.13562621967867e-05
Test Loss:  4.52142849098891e-05
Valid Loss:  7.807643851265311e-05
Epoch:  399  	Training Loss: 7.129487494239584e-05
Test Loss:  4.51218438684009e-05
Valid Loss:  7.80275440774858e-05
Epoch:  400  	Training Loss: 7.123649993445724e-05
Test Loss:  4.503722084336914e-05
Valid Loss:  7.798206934239715e-05
Epoch:  401  	Training Loss: 7.118047506082803e-05
Test Loss:  4.4941247324459255e-05
Valid Loss:  7.793745317030698e-05
Epoch:  402  	Training Loss: 7.113140600267798e-05
Test Loss:  4.3160100176464766e-05
Valid Loss:  7.78011599322781e-05
Epoch:  403  	Training Loss: 7.087276026140898e-05
Test Loss:  4.4230146158952266e-05
Valid Loss:  7.7576725743711e-05
Epoch:  404  	Training Loss: 7.070429273881018e-05
Test Loss:  4.266182804713026e-05
Valid Loss:  7.766415365040302e-05
Epoch:  405  	Training Loss: 7.058883784338832e-05
Test Loss:  4.3901985918637365e-05
Valid Loss:  7.742796879028901e-05
Epoch:  406  	Training Loss: 7.051419379422441e-05
Test Loss:  4.236345557728782e-05
Valid Loss:  7.761290180496871e-05
Epoch:  407  	Training Loss: 7.045548409223557e-05
Test Loss:  4.371669638203457e-05
Valid Loss:  7.735472172498703e-05
 82%|████████▏ | 409/500 [04:55<00:30,  2.96it/s] 82%|████████▏ | 411/500 [05:01<01:44,  1.18s/it] 83%|████████▎ | 413/500 [05:01<01:13,  1.18it/s] 83%|████████▎ | 415/500 [05:01<00:52,  1.63it/s] 83%|████████▎ | 417/500 [05:01<00:37,  2.22it/s] 84%|████████▍ | 419/500 [05:01<00:27,  2.98it/s] 84%|████████▍ | 421/500 [05:08<01:34,  1.19s/it] 85%|████████▍ | 423/500 [05:08<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:08<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:08<00:33,  2.21it/s] 86%|████████▌ | 429/500 [05:08<00:24,  2.93it/s] 86%|████████▌ | 431/500 [05:15<01:23,  1.20s/it] 87%|████████▋ | 433/500 [05:15<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:15<00:40,  1.60it/s] 87%|████████▋ | 437/500 [05:15<00:28,  2.19it/s] 88%|████████▊ | 439/500 [05:15<00:20,  2.94it/s] 88%|████████▊ | 441/500 [05:22<01:10,  1.20s/it] 89%|████████▊ | 443/500 [05:22<00:49,  1.16it/s] 89%|████████▉ | 445/500 [05:22<00:34,  1.60it/s] 89%|████████▉ | 447/500 [05:22<00:24,  2.19it/s] 90%|████████▉ | 449/500 [05:22<00:17,  2.93it/s] 90%|█████████ | 451/500 [05:29<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:29<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:29<00:27,  1.61it/s] 91%|█████████▏| 457/500 [05:29<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:29<00:13,  2.97it/s] 92%|█████████▏| 461/500 [05:36<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:36<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:36<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:36<00:14,  2.21it/s] 94%|█████████▍| 469/500 [05:36<00:10,  2.97it/s] 94%|█████████▍| 471/500 [05:42<00:34,  1.20s/it] 95%|█████████▍| 473/500 [05:43<00:23,  1.16it/s]Epoch:  408  	Training Loss: 7.040747732389718e-05
Test Loss:  4.2158266296610236e-05
Valid Loss:  7.760256994515657e-05
Epoch:  409  	Training Loss: 7.037463365122676e-05
Test Loss:  4.3648215068969876e-05
Valid Loss:  7.727961201453581e-05
Epoch:  410  	Training Loss: 7.034968439256772e-05
Test Loss:  4.2022958950838074e-05
Valid Loss:  7.756583363516256e-05
Epoch:  411  	Training Loss: 7.031080895103514e-05
Test Loss:  4.363295010989532e-05
Valid Loss:  7.720474968664348e-05
Epoch:  412  	Training Loss: 7.03033510944806e-05
Test Loss:  4.2562394810374826e-05
Valid Loss:  7.710891077294946e-05
Epoch:  413  	Training Loss: 6.99689844623208e-05
Test Loss:  4.2330004362156615e-05
Valid Loss:  7.706458563916385e-05
Epoch:  414  	Training Loss: 6.990130350459367e-05
Test Loss:  4.222846109769307e-05
Valid Loss:  7.699392881477252e-05
Epoch:  415  	Training Loss: 6.984909123275429e-05
Test Loss:  4.22208831878379e-05
Valid Loss:  7.689489575568587e-05
Epoch:  416  	Training Loss: 6.98067742632702e-05
Test Loss:  4.224038639222272e-05
Valid Loss:  7.678996189497411e-05
Epoch:  417  	Training Loss: 6.976787699386477e-05
Test Loss:  4.2267620301572606e-05
Valid Loss:  7.668660691706464e-05
Epoch:  418  	Training Loss: 6.973205745453015e-05
Test Loss:  4.229801561450586e-05
Valid Loss:  7.658779213670641e-05
Epoch:  419  	Training Loss: 6.969846435822546e-05
Test Loss:  4.2328814743086696e-05
Valid Loss:  7.649359031347558e-05
Epoch:  420  	Training Loss: 6.96673450875096e-05
Test Loss:  4.235984670231119e-05
Valid Loss:  7.6403928687796e-05
Epoch:  421  	Training Loss: 6.963861233089119e-05
Test Loss:  4.239090776536614e-05
Valid Loss:  7.631888729520142e-05
Epoch:  422  	Training Loss: 6.961158942431211e-05
Test Loss:  4.161187825957313e-05
Valid Loss:  7.547769200755283e-05
Epoch:  423  	Training Loss: 6.873979873489588e-05
Test Loss:  4.0957202145364136e-05
Valid Loss:  7.48161255614832e-05
Epoch:  424  	Training Loss: 6.803334690630436e-05
Test Loss:  4.039582927362062e-05
Valid Loss:  7.429449033224955e-05
Epoch:  425  	Training Loss: 6.745849532308057e-05
Test Loss:  3.9931001083459705e-05
Valid Loss:  7.389164238702506e-05
Epoch:  426  	Training Loss: 6.700518861180171e-05
Test Loss:  3.954246858484112e-05
Valid Loss:  7.358149741776288e-05
Epoch:  427  	Training Loss: 6.664431566605344e-05
Test Loss:  3.9214835851453245e-05
Valid Loss:  7.334436668315902e-05
Epoch:  428  	Training Loss: 6.635946920141578e-05
Test Loss:  3.8938513171160594e-05
Valid Loss:  7.316413393709809e-05
Epoch:  429  	Training Loss: 6.613590812776238e-05
Test Loss:  3.870207001455128e-05
Valid Loss:  7.302848098333925e-05
Epoch:  430  	Training Loss: 6.59586803521961e-05
Test Loss:  3.84990380553063e-05
Valid Loss:  7.292746158782393e-05
Epoch:  431  	Training Loss: 6.581931666005403e-05
Test Loss:  3.83231854357291e-05
Valid Loss:  7.285372703336179e-05
Epoch:  432  	Training Loss: 6.570980622200295e-05
Test Loss:  3.528624802129343e-05
Valid Loss:  7.127195567591116e-05
Epoch:  433  	Training Loss: 6.371685594785959e-05
Test Loss:  3.447075869189575e-05
Valid Loss:  7.030692358966917e-05
Epoch:  434  	Training Loss: 6.274568295339122e-05
Test Loss:  3.365802695043385e-05
Valid Loss:  6.937231228221208e-05
Epoch:  435  	Training Loss: 6.180624041007832e-05
Test Loss:  3.288672451162711e-05
Valid Loss:  6.846881296951324e-05
Epoch:  436  	Training Loss: 6.090547685744241e-05
Test Loss:  3.215644392184913e-05
Valid Loss:  6.759676762158051e-05
Epoch:  437  	Training Loss: 6.003935413900763e-05
Test Loss:  3.1450843380298465e-05
Valid Loss:  6.675295298919082e-05
Epoch:  438  	Training Loss: 5.9204066928941756e-05
Test Loss:  3.078905865550041e-05
Valid Loss:  6.593675061594695e-05
Epoch:  439  	Training Loss: 5.839964433107525e-05
Test Loss:  3.0159817470121197e-05
Valid Loss:  6.514966662507504e-05
Epoch:  440  	Training Loss: 5.762697765021585e-05
Test Loss:  2.9563598218373954e-05
Valid Loss:  6.439282151404768e-05
Epoch:  441  	Training Loss: 5.688425517291762e-05
Test Loss:  2.8995822503929958e-05
Valid Loss:  6.366314482875168e-05
Epoch:  442  	Training Loss: 5.616967973764986e-05
Test Loss:  2.8530030249385163e-05
Valid Loss:  6.318144005490467e-05
Epoch:  443  	Training Loss: 5.569931090576574e-05
Test Loss:  2.8709973776130937e-05
Valid Loss:  6.269542791415006e-05
Epoch:  444  	Training Loss: 5.52703277207911e-05
Test Loss:  2.8521582862595096e-05
Valid Loss:  6.22789521003142e-05
Epoch:  445  	Training Loss: 5.489885370479897e-05
Test Loss:  2.858900734281633e-05
Valid Loss:  6.190720887389034e-05
Epoch:  446  	Training Loss: 5.457354927784763e-05
Test Loss:  2.858224615920335e-05
Valid Loss:  6.156152812764049e-05
Epoch:  447  	Training Loss: 5.426843563327566e-05
Test Loss:  2.8606635169126093e-05
Valid Loss:  6.125208165030926e-05
Epoch:  448  	Training Loss: 5.399724977905862e-05
Test Loss:  2.8683298296527937e-05
Valid Loss:  6.096856668591499e-05
Epoch:  449  	Training Loss: 5.3739233408123255e-05
Test Loss:  2.8704920623567887e-05
Valid Loss:  6.0702946939272806e-05
Epoch:  450  	Training Loss: 5.351062281988561e-05
Test Loss:  2.8768852644134313e-05
Valid Loss:  6.0467464209068567e-05
Epoch:  451  	Training Loss: 5.330595013219863e-05
Test Loss:  2.8813899916713126e-05
Valid Loss:  6.024705362506211e-05
Epoch:  452  	Training Loss: 5.312100984156132e-05
Test Loss:  2.8940763513674028e-05
Valid Loss:  6.0182537708897144e-05
Epoch:  453  	Training Loss: 5.309105108608492e-05
Test Loss:  2.9040620574960485e-05
Valid Loss:  6.012512312736362e-05
Epoch:  454  	Training Loss: 5.3067487897351384e-05
Test Loss:  2.9120943509042263e-05
Valid Loss:  6.00712992309127e-05
Epoch:  455  	Training Loss: 5.3047020628582686e-05
Test Loss:  2.9187842301325873e-05
Valid Loss:  6.0020054661436006e-05
Epoch:  456  	Training Loss: 5.3028659749543294e-05
Test Loss:  2.92454133159481e-05
Valid Loss:  5.997074913466349e-05
Epoch:  457  	Training Loss: 5.3011732234153897e-05
Test Loss:  2.929677430074662e-05
Valid Loss:  5.9923186199739575e-05
Epoch:  458  	Training Loss: 5.299570329952985e-05
Test Loss:  2.934333315351978e-05
Valid Loss:  5.9877427702303976e-05
Epoch:  459  	Training Loss: 5.298086398397572e-05
Test Loss:  2.9386910682660528e-05
Valid Loss:  5.983309893053956e-05
Epoch:  460  	Training Loss: 5.296651943353936e-05
Test Loss:  2.942802893812768e-05
Valid Loss:  5.9790465456899256e-05
Epoch:  461  	Training Loss: 5.2952942496631294e-05
Test Loss:  2.9467442800523713e-05
Valid Loss:  5.974922169116326e-05
Epoch:  462  	Training Loss: 5.294030415825546e-05
Test Loss:  2.959569974336773e-05
Valid Loss:  5.9631689509842545e-05
Epoch:  463  	Training Loss: 5.289838372846134e-05
Test Loss:  2.9658342100447044e-05
Valid Loss:  5.951171260676347e-05
Epoch:  464  	Training Loss: 5.286218220135197e-05
Test Loss:  2.9775863367831334e-05
Valid Loss:  5.941470590187237e-05
Epoch:  465  	Training Loss: 5.2829076594207436e-05
Test Loss:  2.983000740641728e-05
Valid Loss:  5.931698979111388e-05
Epoch:  466  	Training Loss: 5.279857214190997e-05
Test Loss:  2.9907116186222993e-05
Valid Loss:  5.9232177591184154e-05
Epoch:  467  	Training Loss: 5.277033051243052e-05
Test Loss:  2.994527676491998e-05
Valid Loss:  5.914267967455089e-05
Epoch:  468  	Training Loss: 5.274602153804153e-05
Test Loss:  3.0030856578378007e-05
Valid Loss:  5.90698400628753e-05
Epoch:  469  	Training Loss: 5.272380440146662e-05
Test Loss:  3.0066692488617264e-05
Valid Loss:  5.899437383050099e-05
Epoch:  470  	Training Loss: 5.2702322136610746e-05
Test Loss:  3.012303204741329e-05
Valid Loss:  5.8927969803335145e-05
Epoch:  471  	Training Loss: 5.268206950859167e-05
Test Loss:  3.0154076739563607e-05
Valid Loss:  5.886052895220928e-05
Epoch:  472  	Training Loss: 5.266220250632614e-05
Test Loss:  3.01718737318879e-05
Valid Loss:  5.883349876967259e-05
Epoch:  473  	Training Loss: 5.265535946819e-05
Test Loss:  3.019306495843921e-05
Valid Loss:  5.88075999985449e-05
Epoch:  474  	Training Loss: 5.264890205580741e-05
Test Loss:  3.021628435817547e-05
Valid Loss:  5.8783167332876474e-05
Epoch:  475  	Training Loss: 5.264260107651353e-05
Test Loss:  3.0240145861171186e-05
Valid Loss:   95%|█████████▌| 475/500 [05:43<00:15,  1.61it/s] 95%|█████████▌| 477/500 [05:43<00:10,  2.20it/s] 96%|█████████▌| 479/500 [05:43<00:07,  2.96it/s] 96%|█████████▌| 481/500 [05:49<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:49<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:50<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:50<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:50<00:03,  2.97it/s] 98%|█████████▊| 491/500 [05:56<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:56<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:57<00:03,  1.61it/s] 99%|█████████▉| 497/500 [05:57<00:01,  2.20it/s]100%|█████████▉| 499/500 [05:57<00:00,  2.97it/s]100%|██████████| 500/500 [05:57<00:00,  1.40it/s]
5.8759713283507153e-05
Epoch:  476  	Training Loss: 5.2636900363722816e-05
Test Loss:  3.0264354791142978e-05
Valid Loss:  5.873727786820382e-05
Epoch:  477  	Training Loss: 5.263112689135596e-05
Test Loss:  3.0288034395198338e-05
Valid Loss:  5.871565736015327e-05
Epoch:  478  	Training Loss: 5.262595368549228e-05
Test Loss:  3.0311615773825906e-05
Valid Loss:  5.869480810360983e-05
Epoch:  479  	Training Loss: 5.2620915084844455e-05
Test Loss:  3.033452776435297e-05
Valid Loss:  5.867489380761981e-05
Epoch:  480  	Training Loss: 5.261605838313699e-05
Test Loss:  3.0356972274603322e-05
Valid Loss:  5.8655685279518366e-05
Epoch:  481  	Training Loss: 5.261152546154335e-05
Test Loss:  3.0378745577763766e-05
Valid Loss:  5.8637124311644584e-05
Epoch:  482  	Training Loss: 5.2607043471653014e-05
Test Loss:  3.04500172205735e-05
Valid Loss:  5.861518002348021e-05
Epoch:  483  	Training Loss: 5.2602539653889835e-05
Test Loss:  3.0507870178553276e-05
Valid Loss:  5.859798693563789e-05
Epoch:  484  	Training Loss: 5.259920726530254e-05
Test Loss:  3.055500565096736e-05
Valid Loss:  5.8583846112014726e-05
Epoch:  485  	Training Loss: 5.259636236587539e-05
Test Loss:  3.059334267163649e-05
Valid Loss:  5.857291762367822e-05
Epoch:  486  	Training Loss: 5.259418685454875e-05
Test Loss:  3.062445102841593e-05
Valid Loss:  5.856400457560085e-05
Epoch:  487  	Training Loss: 5.259223689790815e-05
Test Loss:  3.064940756303258e-05
Valid Loss:  5.855631752638146e-05
Epoch:  488  	Training Loss: 5.2590432460419834e-05
Test Loss:  3.066945282625966e-05
Valid Loss:  5.8550471294438466e-05
Epoch:  489  	Training Loss: 5.2588915423257276e-05
Test Loss:  3.068552177865058e-05
Valid Loss:  5.854517439729534e-05
Epoch:  490  	Training Loss: 5.2587391110137105e-05
Test Loss:  3.0698152841068804e-05
Valid Loss:  5.854088522028178e-05
Epoch:  491  	Training Loss: 5.258583405520767e-05
Test Loss:  3.0708135454915464e-05
Valid Loss:  5.8537450968287885e-05
Epoch:  492  	Training Loss: 5.258461169432849e-05
Test Loss:  3.055626439163461e-05
Valid Loss:  5.830938971485011e-05
Epoch:  493  	Training Loss: 5.2447765483520925e-05
Test Loss:  3.0495670216623694e-05
Valid Loss:  5.813320240122266e-05
Epoch:  494  	Training Loss: 5.235414573689923e-05
Test Loss:  3.0490085919154808e-05
Valid Loss:  5.79896877752617e-05
Epoch:  495  	Training Loss: 5.22836999152787e-05
Test Loss:  3.051745443372056e-05
Valid Loss:  5.786817564512603e-05
Epoch:  496  	Training Loss: 5.22268092026934e-05
Test Loss:  3.0564031476387754e-05
Valid Loss:  5.7761841162573546e-05
Epoch:  497  	Training Loss: 5.21781257702969e-05
Test Loss:  3.062224277528003e-05
Valid Loss:  5.766841059084982e-05
Epoch:  498  	Training Loss: 5.2135277655906975e-05
Test Loss:  3.0686380341649055e-05
Valid Loss:  5.758502084063366e-05
Epoch:  499  	Training Loss: 5.2096776926191524e-05
Test Loss:  3.075224594795145e-05
Valid Loss:  5.750995114794932e-05
Epoch:  500  	Training Loss: 5.206160858506337e-05
Test Loss:  3.081784234382212e-05
Valid Loss:  5.74421719647944e-05
seed is  4
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:31, 15.68it/s]  1%|          | 4/500 [00:00<00:33, 14.90it/s]  1%|          | 6/500 [00:00<00:33, 14.84it/s]  2%|▏         | 8/500 [00:00<00:31, 15.46it/s]  2%|▏         | 10/500 [00:00<00:31, 15.76it/s]  2%|▏         | 12/500 [00:00<00:30, 16.01it/s]  3%|▎         | 14/500 [00:00<00:29, 16.21it/s]  3%|▎         | 16/500 [00:01<00:29, 16.32it/s]  4%|▎         | 18/500 [00:01<00:29, 16.39it/s]  4%|▍         | 20/500 [00:01<00:29, 16.45it/s]  4%|▍         | 22/500 [00:01<00:29, 16.48it/s]  5%|▍         | 24/500 [00:01<00:28, 16.52it/s]  5%|▌         | 26/500 [00:01<00:28, 16.41it/s]  6%|▌         | 28/500 [00:01<00:29, 15.75it/s]  6%|▌         | 30/500 [00:01<00:30, 15.32it/s]  6%|▋         | 32/500 [00:02<00:29, 15.60it/s]  7%|▋         | 34/500 [00:02<00:29, 15.86it/s]  7%|▋         | 36/500 [00:02<00:29, 15.69it/s]  8%|▊         | 38/500 [00:02<00:29, 15.77it/s]  8%|▊         | 40/500 [00:02<00:28, 16.00it/s]  8%|▊         | 42/500 [00:02<00:28, 16.14it/s]  9%|▉         | 44/500 [00:02<00:28, 16.20it/s]  9%|▉         | 46/500 [00:02<00:27, 16.22it/s] 10%|▉         | 48/500 [00:03<00:28, 15.72it/s] 10%|█         | 50/500 [00:03<00:28, 15.56it/s] 10%|█         | 52/500 [00:03<00:28, 15.79it/s] 11%|█         | 54/500 [00:03<00:27, 15.99it/s] 11%|█         | 56/500 [00:03<00:27, 15.92it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.01it/s] 12%|█▏        | 60/500 [00:03<00:27, 15.96it/s] 12%|█▏        | 62/500 [00:03<00:27, 16.00it/s] 13%|█▎        | 64/500 [00:04<00:27, 16.09it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.21it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.86it/s] 14%|█▍        | 70/500 [00:04<00:27, 15.88it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.07it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.21it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.34it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.15it/s] 16%|█▌        | 80/500 [00:05<00:27, 15.53it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.76it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.75it/s] 17%|█▋        | 86/500 [00:05<00:26, 15.69it/s] 18%|█▊        | 88/500 [00:05<00:27, 14.73it/s] 18%|█▊        | 90/500 [00:05<00:27, 15.13it/s] 18%|█▊        | 92/500 [00:05<00:26, 15.55it/s] 19%|█▉        | 94/500 [00:05<00:25, 15.86it/s] 19%|█▉        | 96/500 [00:06<00:25, 15.86it/s] 20%|█▉        | 98/500 [00:06<00:25, 16.07it/s] 20%|██        | 100/500 [00:06<00:24, 16.20it/s] 20%|██        | 102/500 [00:06<00:24, 16.21it/s] 21%|██        | 104/500 [00:06<00:24, 16.35it/s] 21%|██        | 106/500 [00:06<00:23, 16.44it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.48it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.30it/s] 22%|██▏       | 112/500 [00:07<00:23, 16.30it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.43it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.45it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.49it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.42it/s] 24%|██▍       | 122/500 [00:07<00:23, 15.98it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.10it/s]Epoch:  1  	Training Loss: 0.06784941256046295
Test Loss:  1265.4302978515625
Valid Loss:  1267.4305419921875
Epoch:  2  	Training Loss: 1257.533203125
Test Loss:  1612354076803072.0
Valid Loss:  1613138042552320.0
Epoch:  3  	Training Loss: 1616729708953600.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:23, 15.70it/s] 26%|██▌       | 128/500 [00:08<00:23, 15.66it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.89it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.07it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.21it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.31it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.27it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.33it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.29it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.30it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.38it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.41it/s] 30%|███       | 150/500 [00:09<00:21, 16.44it/s] 30%|███       | 152/500 [00:09<00:21, 16.42it/s] 31%|███       | 154/500 [00:09<00:21, 16.41it/s] 31%|███       | 156/500 [00:09<00:20, 16.43it/s] 32%|███▏      | 158/500 [00:09<00:21, 16.05it/s] 32%|███▏      | 160/500 [00:09<00:21, 15.54it/s] 32%|███▏      | 162/500 [00:10<00:22, 14.72it/s] 33%|███▎      | 164/500 [00:10<00:23, 14.09it/s] 33%|███▎      | 166/500 [00:10<00:24, 13.88it/s] 34%|███▎      | 168/500 [00:10<00:23, 14.12it/s] 34%|███▍      | 170/500 [00:10<00:23, 14.28it/s] 34%|███▍      | 172/500 [00:10<00:23, 13.69it/s] 35%|███▍      | 174/500 [00:11<00:23, 13.67it/s] 35%|███▌      | 176/500 [00:11<00:24, 13.09it/s] 36%|███▌      | 178/500 [00:11<00:23, 13.87it/s] 36%|███▌      | 180/500 [00:11<00:21, 14.58it/s] 36%|███▋      | 182/500 [00:11<00:21, 15.09it/s] 37%|███▋      | 184/500 [00:11<00:20, 15.47it/s] 37%|███▋      | 186/500 [00:11<00:19, 15.76it/s] 38%|███▊      | 188/500 [00:11<00:19, 15.85it/s] 38%|███▊      | 190/500 [00:12<00:19, 16.02it/s] 38%|███▊      | 192/500 [00:12<00:19, 15.91it/s] 39%|███▉      | 194/500 [00:12<00:19, 16.05it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.07it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.01it/s] 40%|████      | 200/500 [00:12<00:18, 16.13it/s] 40%|████      | 202/500 [00:12<00:18, 15.84it/s] 41%|████      | 204/500 [00:12<00:18, 15.88it/s] 41%|████      | 206/500 [00:13<00:18, 16.05it/s] 42%|████▏     | 208/500 [00:13<00:18, 16.05it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.12it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.24it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.04it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.16it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.27it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.32it/s] 44%|████▍     | 222/500 [00:14<00:16, 16.37it/s] 45%|████▍     | 224/500 [00:14<00:16, 16.26it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.42it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.40it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.39it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.24it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.40it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.49it/s] 48%|████▊     | 238/500 [00:15<00:15, 16.52it/s] 48%|████▊     | 240/500 [00:15<00:15, 16.61it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.62it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.66it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.63it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.66it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.65it/s] 50%|█████     | 252/500 [00:15<00:14, 16.63it/s] 51%|█████     | 254/500 [00:15<00:14, 16.64it/s] 51%|█████     | 256/500 [00:16<00:14, 16.61it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.59it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.60it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.58it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.59it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.58it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.57it/s] 54%|█████▍    | 270/500 [00:16<00:13, 16.57it/s] 54%|█████▍    | 272/500 [00:17<00:13, 16.56it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.61it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.59it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.66it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.64it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.64it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.41it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.46it/s] 58%|█████▊    | 288/500 [00:18<00:12, 16.36it/s] 58%|█████▊    | 290/500 [00:18<00:12, 16.30it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.37it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.41it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.44it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.48it/s] 60%|██████    | 300/500 [00:18<00:12, 16.54it/s] 60%|██████    | 302/500 [00:18<00:12, 16.48it/s] 61%|██████    | 304/500 [00:19<00:12, 15.87it/s] 61%|██████    | 306/500 [00:19<00:12, 16.04it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.19it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.28it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.39it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.44it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.44it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.45it/s] 64%|██████▍   | 320/500 [00:19<00:10, 16.49it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.50it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.53it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.53it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.51it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.49it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.47it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.47it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.37it/s] 68%|██████▊   | 338/500 [00:21<00:09, 16.35it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.39it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.44it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.45it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.54it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.53it/s] 70%|███████   | 350/500 [00:21<00:09, 16.56it/s] 70%|███████   | 352/500 [00:21<00:08, 16.54it/s] 71%|███████   | 354/500 [00:22<00:08, 16.51it/s] 71%|███████   | 356/500 [00:22<00:08, 16.54it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.54it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.57it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.56it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.54it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.50it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.47it/s] 74%|███████▍  | 370/500 [00:23<00:07, 16.45it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.52it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.49it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.41it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.44it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.55it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.43it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.26it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.39it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.40it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.39it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.43it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.49it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.45it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.39it/s] 80%|████████  | 400/500 [00:24<00:06, 16.47it/s] 80%|████████  | 402/500 [00:24<00:05, 16.44it/s] 81%|████████  | 404/500 [00:25<00:05, 16.13it/s] 81%|████████  | 406/500 [00:25<00:05, 15.77it/s] 82%|████████▏ | 408/500 [00:25<00:05, 15.96it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.15it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.25it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.22it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.27it/s] 84%|████████▎ | 418/500 [00:25<00:05, 15.90it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.05it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.30it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.38it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.44it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.47it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.54it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.55it/s] 87%|████████▋ | 434/500 [00:26<00:03, 16.56it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.48it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.51it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.52it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.51it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.35it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.23it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.18it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.28it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.35it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.31it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.41it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.43it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.45it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.50it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.49it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.55it/s] 94%|█████████▎| 468/500 [00:29<00:01, 16.53it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.52it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.48it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.48it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.51it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.50it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.49it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.46it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.46it/s] 97%|█████████▋| 486/500 [00:30<00:00, 16.47it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.45it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.45it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.45it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.43it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.45it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.37it/s]100%|██████████| 500/500 [00:30<00:00, 16.40it/s]100%|██████████| 500/500 [00:30<00:00, 16.15it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  4
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<50:56,  6.13s/it]  1%|          | 3/500 [00:06<13:35,  1.64s/it]  1%|          | 5/500 [00:06<06:51,  1.20it/s]  1%|▏         | 7/500 [00:06<04:09,  1.97it/s]  2%|▏         | 9/500 [00:06<02:46,  2.94it/s]  2%|▏         | 11/500 [00:12<10:40,  1.31s/it]  3%|▎         | 13/500 [00:13<07:16,  1.12it/s]  3%|▎         | 15/500 [00:13<05:05,  1.59it/s]  3%|▎         | 17/500 [00:13<03:37,  2.22it/s]  4%|▍         | 19/500 [00:13<02:39,  3.01it/s]  4%|▍         | 21/500 [00:19<09:27,  1.19s/it]  5%|▍         | 23/500 [00:19<06:43,  1.18it/s]  5%|▌         | 25/500 [00:19<04:48,  1.64it/s]  5%|▌         | 27/500 [00:20<03:30,  2.25it/s]  6%|▌         | 29/500 [00:20<02:36,  3.01it/s]  6%|▌         | 31/500 [00:26<09:09,  1.17s/it]  7%|▋         | 33/500 [00:26<06:32,  1.19it/s]  7%|▋         | 35/500 [00:26<04:42,  1.65it/s]  7%|▋         | 37/500 [00:26<03:25,  2.25it/s]  8%|▊         | 39/500 [00:26<02:32,  3.03it/s]  8%|▊         | 41/500 [00:33<08:52,  1.16s/it]  9%|▊         | 43/500 [00:33<06:20,  1.20it/s]  9%|▉         | 45/500 [00:33<04:34,  1.66it/s]  9%|▉         | 47/500 [00:33<03:20,  2.26it/s] 10%|▉         | 49/500 [00:33<02:28,  3.04it/s] 10%|█         | 51/500 [00:39<08:42,  1.16s/it] 11%|█         | 53/500 [00:40<06:13,  1.20it/s] 11%|█         | 55/500 [00:40<04:29,  1.65it/s] 11%|█▏        | 57/500 [00:40<03:16,  2.26it/s] 12%|█▏        | 59/500 [00:40<02:25,  3.04it/s] 12%|█▏        | 61/500 [00:46<08:37,  1.18s/it] 13%|█▎        | 63/500 [00:46<06:10,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:26,  1.63it/s] 13%|█▎        | 67/500 [00:47<03:14,  2.23it/s] 14%|█▍        | 69/500 [00:47<02:23,  3.00it/s] 14%|█▍        | 71/500 [00:53<08:25,  1.18s/it] 15%|█▍        | 73/500 [00:53<06:01,  1.18it/s]Epoch:  1  	Training Loss: 0.06784941256046295
Test Loss:  84.42682647705078
Valid Loss:  84.9135513305664
Epoch:  2  	Training Loss: 81.89643859863281
Test Loss:  0.1691512018442154
Valid Loss:  0.17209477722644806
Epoch:  3  	Training Loss: 0.14372089505195618
Test Loss:  0.167910635471344
Valid Loss:  0.1708306223154068
Epoch:  4  	Training Loss: 0.14261913299560547
Test Loss:  0.1666804552078247
Valid Loss:  0.1695770025253296
Epoch:  5  	Training Loss: 0.14152705669403076
Test Loss:  0.16546058654785156
Valid Loss:  0.16833382844924927
Epoch:  6  	Training Loss: 0.1404445916414261
Test Loss:  0.1642509251832962
Valid Loss:  0.16710099577903748
Epoch:  7  	Training Loss: 0.13937166333198547
Test Loss:  0.16305139660835266
Valid Loss:  0.16587841510772705
Epoch:  8  	Training Loss: 0.13830816745758057
Test Loss:  0.16186192631721497
Valid Loss:  0.16466601192951202
Epoch:  9  	Training Loss: 0.1372540444135666
Test Loss:  0.16068241000175476
Valid Loss:  0.16346369683742523
Epoch:  10  	Training Loss: 0.13620918989181519
Test Loss:  0.15951278805732727
Valid Loss:  0.1622713804244995
Epoch:  11  	Training Loss: 0.13517355918884277
Test Loss:  0.15835295617580414
Valid Loss:  0.1610890030860901
Epoch:  12  	Training Loss: 0.134147047996521
Test Loss:  0.1575576663017273
Valid Loss:  0.1602783501148224
Epoch:  13  	Training Loss: 0.1334460973739624
Test Loss:  0.15676870942115784
Valid Loss:  0.15947410464286804
Epoch:  14  	Training Loss: 0.13275091350078583
Test Loss:  0.1559859812259674
Valid Loss:  0.15867619216442108
Epoch:  15  	Training Loss: 0.1320614069700241
Test Loss:  0.15520945191383362
Valid Loss:  0.15788456797599792
Epoch:  16  	Training Loss: 0.13137754797935486
Test Loss:  0.1544390767812729
Valid Loss:  0.1570991575717926
Epoch:  17  	Training Loss: 0.1306992769241333
Test Loss:  0.15367472171783447
Valid Loss:  0.15631991624832153
Epoch:  18  	Training Loss: 0.13002654910087585
Test Loss:  0.15291640162467957
Valid Loss:  0.15554676949977875
Epoch:  19  	Training Loss: 0.12935924530029297
Test Loss:  0.1521640121936798
Valid Loss:  0.15477964282035828
Epoch:  20  	Training Loss: 0.12869738042354584
Test Loss:  0.15141750872135162
Valid Loss:  0.15401850640773773
Epoch:  21  	Training Loss: 0.1280408501625061
Test Loss:  0.15067681670188904
Valid Loss:  0.15326327085494995
Epoch:  22  	Training Loss: 0.12738962471485138
Test Loss:  0.1499398946762085
Valid Loss:  0.1525118499994278
Epoch:  23  	Training Loss: 0.1267419159412384
Test Loss:  0.14920754730701447
Valid Loss:  0.15176504850387573
Epoch:  24  	Training Loss: 0.1260983794927597
Test Loss:  0.14847970008850098
Valid Loss:  0.15102282166481018
Epoch:  25  	Training Loss: 0.1254590004682541
Test Loss:  0.14775633811950684
Valid Loss:  0.15028518438339233
Epoch:  26  	Training Loss: 0.12482374906539917
Test Loss:  0.14703743159770966
Valid Loss:  0.14955204725265503
Epoch:  27  	Training Loss: 0.12419258058071136
Test Loss:  0.14632296562194824
Valid Loss:  0.14882338047027588
Epoch:  28  	Training Loss: 0.12356546521186829
Test Loss:  0.14561288058757782
Valid Loss:  0.14809919893741608
Epoch:  29  	Training Loss: 0.12294237315654755
Test Loss:  0.1449071615934372
Valid Loss:  0.14737942814826965
Epoch:  30  	Training Loss: 0.12232328951358795
Test Loss:  0.14420577883720398
Valid Loss:  0.14666405320167542
Epoch:  31  	Training Loss: 0.12170819193124771
Test Loss:  0.1435086876153946
Valid Loss:  0.14595305919647217
Epoch:  32  	Training Loss: 0.12109702825546265
Test Loss:  0.14281387627124786
Valid Loss:  0.14524433016777039
Epoch:  33  	Training Loss: 0.12048797309398651
Test Loss:  0.1421230137348175
Valid Loss:  0.14453962445259094
Epoch:  34  	Training Loss: 0.11988256871700287
Test Loss:  0.1414361149072647
Valid Loss:  0.14383894205093384
Epoch:  35  	Training Loss: 0.11928081512451172
Test Loss:  0.1407531499862671
Valid Loss:  0.1431422233581543
Epoch:  36  	Training Loss: 0.11868266761302948
Test Loss:  0.14007408916950226
Valid Loss:  0.14244946837425232
Epoch:  37  	Training Loss: 0.11808809638023376
Test Loss:  0.13939887285232544
Valid Loss:  0.14176063239574432
Epoch:  38  	Training Loss: 0.11749708652496338
Test Loss:  0.13872751593589783
Valid Loss:  0.14107570052146912
Epoch:  39  	Training Loss: 0.11690960824489594
Test Loss:  0.13805998861789703
Valid Loss:  0.1403946727514267
Epoch:  40  	Training Loss: 0.11632566154003143
Test Loss:  0.13739627599716187
Valid Loss:  0.1397174894809723
Epoch:  41  	Training Loss: 0.11574520915746689
Test Loss:  0.13673633337020874
Valid Loss:  0.1390441358089447
Epoch:  42  	Training Loss: 0.11516822874546051
Test Loss:  0.13607941567897797
Valid Loss:  0.13837386667728424
Epoch:  43  	Training Loss: 0.11459407210350037
Test Loss:  0.13542646169662476
Valid Loss:  0.13770759105682373
Epoch:  44  	Training Loss: 0.11402355134487152
Test Loss:  0.13477742671966553
Valid Loss:  0.13704529404640198
Epoch:  45  	Training Loss: 0.113456591963768
Test Loss:  0.1341322809457779
Valid Loss:  0.1363869607448578
Epoch:  46  	Training Loss: 0.11289321631193161
Test Loss:  0.13349100947380066
Valid Loss:  0.13573254644870758
Epoch:  47  	Training Loss: 0.11233337968587875
Test Loss:  0.13285359740257263
Valid Loss:  0.13508205115795135
Epoch:  48  	Training Loss: 0.11177707463502884
Test Loss:  0.13222000002861023
Valid Loss:  0.13443543016910553
Epoch:  49  	Training Loss: 0.11122424900531769
Test Loss:  0.13159018754959106
Valid Loss:  0.13379265367984772
Epoch:  50  	Training Loss: 0.1106749102473259
Test Loss:  0.13096418976783752
Valid Loss:  0.13315372169017792
Epoch:  51  	Training Loss: 0.11012901365756989
Test Loss:  0.13034188747406006
Valid Loss:  0.13251857459545135
Epoch:  52  	Training Loss: 0.10958655178546906
Test Loss:  0.12972447276115417
Valid Loss:  0.13188838958740234
Epoch:  53  	Training Loss: 0.1090485006570816
Test Loss:  0.12911075353622437
Valid Loss:  0.13126195967197418
Epoch:  54  	Training Loss: 0.10851383209228516
Test Loss:  0.12850071489810944
Valid Loss:  0.13063925504684448
Epoch:  55  	Training Loss: 0.10798251628875732
Test Loss:  0.127894327044487
Valid Loss:  0.13002026081085205
Epoch:  56  	Training Loss: 0.10745453089475632
Test Loss:  0.12729157507419586
Valid Loss:  0.1294049620628357
Epoch:  57  	Training Loss: 0.10692986845970154
Test Loss:  0.12669242918491364
Valid Loss:  0.12879329919815063
Epoch:  58  	Training Loss: 0.1064084991812706
Test Loss:  0.12609684467315674
Valid Loss:  0.12818528711795807
Epoch:  59  	Training Loss: 0.10589039325714111
Test Loss:  0.12550483644008636
Valid Loss:  0.12758088111877441
Epoch:  60  	Training Loss: 0.10537554323673248
Test Loss:  0.12491635978221893
Valid Loss:  0.12698006629943848
Epoch:  61  	Training Loss: 0.10486391186714172
Test Loss:  0.12433139234781265
Valid Loss:  0.12638281285762787
Epoch:  62  	Training Loss: 0.10435548424720764
Test Loss:  0.1237514317035675
Valid Loss:  0.12579065561294556
Epoch:  63  	Training Loss: 0.1038515567779541
Test Loss:  0.12317485362291336
Valid Loss:  0.1252019703388214
Epoch:  64  	Training Loss: 0.10335072875022888
Test Loss:  0.12260164320468903
Valid Loss:  0.12461665272712708
Epoch:  65  	Training Loss: 0.10285294055938721
Test Loss:  0.12203176319599152
Valid Loss:  0.12403473258018494
Epoch:  66  	Training Loss: 0.10235820710659027
Test Loss:  0.12146517634391785
Valid Loss:  0.12345617264509201
Epoch:  67  	Training Loss: 0.10186649858951569
Test Loss:  0.12090189009904861
Valid Loss:  0.12288093566894531
Epoch:  68  	Training Loss: 0.10137778520584106
Test Loss:  0.12034188210964203
Valid Loss:  0.12230905145406723
Epoch:  69  	Training Loss: 0.10089205205440521
Test Loss:  0.11978510767221451
Valid Loss:  0.1217404454946518
Epoch:  70  	Training Loss: 0.10040928423404694
Test Loss:  0.11923157423734665
Valid Loss:  0.121175117790699
Epoch:  71  	Training Loss: 0.09992946684360504
Test Loss:  0.11868124455213547
Valid Loss:  0.12061303853988647
Epoch:  72  	Training Loss: 0.09945257008075714
Test Loss:  0.11813268810510635
Valid Loss:  0.120052769780159
Epoch:  73  	Training Loss: 0.09897733479738235
Test Loss:  0.11758735775947571
Valid Loss:  0.11949576437473297
 15%|█▌        | 75/500 [00:53<04:20,  1.63it/s] 15%|█▌        | 77/500 [00:54<03:09,  2.23it/s] 16%|█▌        | 79/500 [00:54<02:20,  3.00it/s] 16%|█▌        | 81/500 [01:00<08:07,  1.16s/it] 17%|█▋        | 83/500 [01:00<05:48,  1.19it/s] 17%|█▋        | 85/500 [01:00<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:00<03:03,  2.26it/s] 18%|█▊        | 89/500 [01:00<02:15,  3.03it/s] 18%|█▊        | 91/500 [01:07<08:02,  1.18s/it] 19%|█▊        | 93/500 [01:07<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:07<04:08,  1.63it/s] 19%|█▉        | 97/500 [01:07<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:07<02:13,  3.00it/s] 20%|██        | 101/500 [01:13<07:47,  1.17s/it] 21%|██        | 103/500 [01:14<05:33,  1.19it/s] 21%|██        | 105/500 [01:14<04:00,  1.64it/s] 21%|██▏       | 107/500 [01:14<02:54,  2.25it/s] 22%|██▏       | 109/500 [01:14<02:09,  3.02it/s] 22%|██▏       | 111/500 [01:20<07:37,  1.18s/it] 23%|██▎       | 113/500 [01:20<05:26,  1.18it/s] 23%|██▎       | 115/500 [01:21<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:21<02:51,  2.24it/s] 24%|██▍       | 119/500 [01:21<02:06,  3.01it/s] 24%|██▍       | 121/500 [01:27<07:26,  1.18s/it] 25%|██▍       | 123/500 [01:27<05:18,  1.18it/s] 25%|██▌       | 125/500 [01:27<03:49,  1.63it/s] 25%|██▌       | 127/500 [01:28<02:47,  2.23it/s] 26%|██▌       | 129/500 [01:28<02:03,  3.00it/s] 26%|██▌       | 131/500 [01:34<07:18,  1.19s/it] 27%|██▋       | 133/500 [01:34<05:13,  1.17it/s] 27%|██▋       | 135/500 [01:34<03:45,  1.62it/s] 27%|██▋       | 137/500 [01:34<02:43,  2.22it/s] 28%|██▊       | 139/500 [01:35<02:02,  2.95it/s] 28%|██▊       | 141/500 [01:41<07:02,  1.18s/it] 29%|██▊       | 143/500 [01:41<05:01,  1.18it/s] 29%|██▉       | 145/500 [01:41<03:38,  1.63it/s]Epoch:  74  	Training Loss: 0.09850503504276276
Test Loss:  0.11704523861408234
Valid Loss:  0.1189420074224472
Epoch:  75  	Training Loss: 0.09803565591573715
Test Loss:  0.11650631576776505
Valid Loss:  0.11839151382446289
Epoch:  76  	Training Loss: 0.09756917506456375
Test Loss:  0.11597055196762085
Valid Loss:  0.11784421652555466
Epoch:  77  	Training Loss: 0.09710559248924255
Test Loss:  0.11543793976306915
Valid Loss:  0.1173001229763031
Epoch:  78  	Training Loss: 0.09664486348628998
Test Loss:  0.11490845680236816
Valid Loss:  0.11675921082496643
Epoch:  79  	Training Loss: 0.09618698060512543
Test Loss:  0.11438208818435669
Valid Loss:  0.11622146517038345
Epoch:  80  	Training Loss: 0.0957319438457489
Test Loss:  0.11385881155729294
Valid Loss:  0.11568684875965118
Epoch:  81  	Training Loss: 0.09527970850467682
Test Loss:  0.11333858966827393
Valid Loss:  0.11515534669160843
Epoch:  82  	Training Loss: 0.09483025223016739
Test Loss:  0.11281739920377731
Valid Loss:  0.11462283134460449
Epoch:  83  	Training Loss: 0.09438009560108185
Test Loss:  0.1122991144657135
Valid Loss:  0.11409326642751694
Epoch:  84  	Training Loss: 0.09393258392810822
Test Loss:  0.1117836982011795
Valid Loss:  0.11356661468744278
Epoch:  85  	Training Loss: 0.0934876874089241
Test Loss:  0.11127108335494995
Valid Loss:  0.11304281651973724
Epoch:  86  	Training Loss: 0.09304535388946533
Test Loss:  0.11076132953166962
Valid Loss:  0.11252190172672272
Epoch:  87  	Training Loss: 0.09260562062263489
Test Loss:  0.11025437712669373
Valid Loss:  0.1120038628578186
Epoch:  88  	Training Loss: 0.09216844290494919
Test Loss:  0.10975022614002228
Valid Loss:  0.11148865520954132
Epoch:  89  	Training Loss: 0.09173382818698883
Test Loss:  0.10924887657165527
Valid Loss:  0.11097626388072968
Epoch:  90  	Training Loss: 0.09130173921585083
Test Loss:  0.10875023901462555
Valid Loss:  0.11046666651964188
Epoch:  91  	Training Loss: 0.0908721536397934
Test Loss:  0.10825438797473907
Valid Loss:  0.10995987057685852
Epoch:  92  	Training Loss: 0.09044507890939713
Test Loss:  0.10776089131832123
Valid Loss:  0.10945549607276917
Epoch:  93  	Training Loss: 0.09002022445201874
Test Loss:  0.10727018117904663
Valid Loss:  0.10895392298698425
Epoch:  94  	Training Loss: 0.08959789574146271
Test Loss:  0.1067822128534317
Valid Loss:  0.10845516622066498
Epoch:  95  	Training Loss: 0.08917807042598724
Test Loss:  0.10629697889089584
Valid Loss:  0.10795915126800537
Epoch:  96  	Training Loss: 0.08876071870326996
Test Loss:  0.10581444948911667
Valid Loss:  0.10746590793132782
Epoch:  97  	Training Loss: 0.08834584057331085
Test Loss:  0.10533465445041656
Valid Loss:  0.10697543621063232
Epoch:  98  	Training Loss: 0.08793342113494873
Test Loss:  0.10485753417015076
Valid Loss:  0.1064876839518547
Epoch:  99  	Training Loss: 0.0875234454870224
Test Loss:  0.10438309609889984
Valid Loss:  0.10600265115499496
Epoch:  100  	Training Loss: 0.08711590617895126
Test Loss:  0.10391131043434143
Valid Loss:  0.10552031546831131
Epoch:  101  	Training Loss: 0.08671076595783234
Test Loss:  0.10344217717647552
Valid Loss:  0.10504067689180374
Epoch:  102  	Training Loss: 0.08630803972482681
Test Loss:  0.10297324508428574
Valid Loss:  0.1045612320303917
Epoch:  103  	Training Loss: 0.08590560406446457
Test Loss:  0.10250692814588547
Valid Loss:  0.10408443212509155
Epoch:  104  	Training Loss: 0.08550553768873215
Test Loss:  0.10204316675662994
Valid Loss:  0.10361023247241974
Epoch:  105  	Training Loss: 0.08510778844356537
Test Loss:  0.10158197581768036
Valid Loss:  0.10313865542411804
Epoch:  106  	Training Loss: 0.08471237868070602
Test Loss:  0.10112331807613373
Valid Loss:  0.10266964882612228
Epoch:  107  	Training Loss: 0.08431927114725113
Test Loss:  0.10066720098257065
Valid Loss:  0.10220320522785187
Epoch:  108  	Training Loss: 0.08392845839262009
Test Loss:  0.10021359473466873
Valid Loss:  0.1017393171787262
Epoch:  109  	Training Loss: 0.0835399255156517
Test Loss:  0.099762462079525
Valid Loss:  0.10127796232700348
Epoch:  110  	Training Loss: 0.08315365761518478
Test Loss:  0.09931386262178421
Valid Loss:  0.10081915557384491
Epoch:  111  	Training Loss: 0.08276966214179993
Test Loss:  0.09886771440505981
Valid Loss:  0.1003628671169281
Epoch:  112  	Training Loss: 0.08238789439201355
Test Loss:  0.09843157976865768
Valid Loss:  0.09991678595542908
Epoch:  113  	Training Loss: 0.0820147842168808
Test Loss:  0.09799793362617493
Valid Loss:  0.09947323799133301
Epoch:  114  	Training Loss: 0.08164392411708832
Test Loss:  0.09756676852703094
Valid Loss:  0.0990321934223175
Epoch:  115  	Training Loss: 0.08127529919147491
Test Loss:  0.09713802486658096
Valid Loss:  0.09859362244606018
Epoch:  116  	Training Loss: 0.0809088796377182
Test Loss:  0.09671172499656677
Valid Loss:  0.09815755486488342
Epoch:  117  	Training Loss: 0.08054465055465698
Test Loss:  0.09628784656524658
Valid Loss:  0.09772393107414246
Epoch:  118  	Training Loss: 0.08018261194229126
Test Loss:  0.0958663672208786
Valid Loss:  0.09729274362325668
Epoch:  119  	Training Loss: 0.07982274889945984
Test Loss:  0.09544727206230164
Valid Loss:  0.0968639925122261
Epoch:  120  	Training Loss: 0.07946503907442093
Test Loss:  0.09503056108951569
Valid Loss:  0.09643763303756714
Epoch:  121  	Training Loss: 0.07910946011543274
Test Loss:  0.09461618214845657
Valid Loss:  0.09601369500160217
Epoch:  122  	Training Loss: 0.07875601947307587
Test Loss:  0.0941995233297348
Valid Loss:  0.095587357878685
Epoch:  123  	Training Loss: 0.07840073853731155
Test Loss:  0.09378518164157867
Valid Loss:  0.09516339004039764
Epoch:  124  	Training Loss: 0.07804754376411438
Test Loss:  0.09337315708398819
Valid Loss:  0.09474177658557892
Epoch:  125  	Training Loss: 0.07769644260406494
Test Loss:  0.09296341985464096
Valid Loss:  0.09432251006364822
Epoch:  126  	Training Loss: 0.07734741270542145
Test Loss:  0.09255598485469818
Valid Loss:  0.09390555322170258
Epoch:  127  	Training Loss: 0.07700046896934509
Test Loss:  0.09215080738067627
Valid Loss:  0.09349091351032257
Epoch:  128  	Training Loss: 0.0766555517911911
Test Loss:  0.09174787998199463
Valid Loss:  0.09307856112718582
Epoch:  129  	Training Loss: 0.07631267607212067
Test Loss:  0.09134720265865326
Valid Loss:  0.09266848862171173
Epoch:  130  	Training Loss: 0.0759718269109726
Test Loss:  0.09094877541065216
Valid Loss:  0.0922606959939003
Epoch:  131  	Training Loss: 0.07563299685716629
Test Loss:  0.09055256098508835
Valid Loss:  0.09185516834259033
Epoch:  132  	Training Loss: 0.07529616355895996
Test Loss:  0.09016403555870056
Valid Loss:  0.09145750105381012
Epoch:  133  	Training Loss: 0.07496599107980728
Test Loss:  0.08977771550416946
Valid Loss:  0.09106208384037018
Epoch:  134  	Training Loss: 0.07463780790567398
Test Loss:  0.08939358592033386
Valid Loss:  0.09066887199878693
Epoch:  135  	Training Loss: 0.07431158423423767
Test Loss:  0.08901160955429077
Valid Loss:  0.09027787297964096
Epoch:  136  	Training Loss: 0.07398730516433716
Test Loss:  0.08863182365894318
Valid Loss:  0.08988909423351288
Epoch:  137  	Training Loss: 0.07366499304771423
Test Loss:  0.08825419098138809
Valid Loss:  0.0895024836063385
Epoch:  138  	Training Loss: 0.07334460318088531
Test Loss:  0.08787868916988373
Valid Loss:  0.08911807090044022
Epoch:  139  	Training Loss: 0.0730261504650116
Test Loss:  0.08750531077384949
Valid Loss:  0.08873581886291504
Epoch:  140  	Training Loss: 0.0727095901966095
Test Loss:  0.08713404089212418
Valid Loss:  0.08835570514202118
Epoch:  141  	Training Loss: 0.07239493727684021
Test Loss:  0.0867648795247078
Valid Loss:  0.08797772973775864
Epoch:  142  	Training Loss: 0.07208216190338135
Test Loss:  0.0863943099975586
Valid Loss:  0.08759830892086029
Epoch:  143  	Training Loss: 0.07176831364631653
Test Loss:  0.08602580428123474
Valid Loss:  0.08722096681594849
Epoch:  144  	Training Loss: 0.07145628333091736
Test Loss:  0.08565932512283325
Valid Loss:  0.08684569597244263
Epoch:  145  	Training Loss: 0.07114610075950623
Test Loss:  0.08529487252235413
Valid Loss:  0.08647248148918152
 29%|██▉       | 147/500 [01:41<02:38,  2.22it/s] 30%|██▉       | 149/500 [01:41<01:57,  2.98it/s] 30%|███       | 151/500 [01:48<06:50,  1.18s/it] 31%|███       | 153/500 [01:48<04:53,  1.18it/s] 31%|███       | 155/500 [01:48<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:48<02:33,  2.24it/s] 32%|███▏      | 159/500 [01:48<01:53,  3.00it/s] 32%|███▏      | 161/500 [01:55<06:38,  1.17s/it] 33%|███▎      | 163/500 [01:55<04:44,  1.19it/s] 33%|███▎      | 165/500 [01:55<03:24,  1.64it/s] 33%|███▎      | 167/500 [01:55<02:29,  2.23it/s] 34%|███▍      | 169/500 [01:55<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:01<06:33,  1.19s/it] 35%|███▍      | 173/500 [02:02<04:40,  1.17it/s] 35%|███▌      | 175/500 [02:02<03:21,  1.61it/s] 35%|███▌      | 177/500 [02:02<02:26,  2.20it/s] 36%|███▌      | 179/500 [02:02<01:48,  2.95it/s] 36%|███▌      | 181/500 [02:08<06:15,  1.18s/it] 37%|███▋      | 183/500 [02:08<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:09<03:13,  1.63it/s] 37%|███▋      | 187/500 [02:09<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:09<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:15<06:02,  1.17s/it] 39%|███▊      | 193/500 [02:15<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:15<03:06,  1.63it/s] 39%|███▉      | 197/500 [02:16<02:15,  2.23it/s] 40%|███▉      | 199/500 [02:16<01:40,  3.01it/s] 40%|████      | 201/500 [02:22<05:54,  1.19s/it] 41%|████      | 203/500 [02:22<04:12,  1.17it/s] 41%|████      | 205/500 [02:22<03:01,  1.62it/s] 41%|████▏     | 207/500 [02:22<02:12,  2.22it/s] 42%|████▏     | 209/500 [02:23<01:37,  2.98it/s] 42%|████▏     | 211/500 [02:29<05:38,  1.17s/it] 43%|████▎     | 213/500 [02:29<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:29<02:54,  1.64it/s] 43%|████▎     | 217/500 [02:29<02:06,  2.23it/s]Epoch:  146  	Training Loss: 0.07083772122859955
Test Loss:  0.08493243157863617
Valid Loss:  0.08610132336616516
Epoch:  147  	Training Loss: 0.07053115963935852
Test Loss:  0.08457200974225998
Valid Loss:  0.08573222160339355
Epoch:  148  	Training Loss: 0.07022640854120255
Test Loss:  0.08421358466148376
Valid Loss:  0.08536513894796371
Epoch:  149  	Training Loss: 0.06992344558238983
Test Loss:  0.08385713398456573
Valid Loss:  0.08500006794929504
Epoch:  150  	Training Loss: 0.06962226331233978
Test Loss:  0.08350265026092529
Valid Loss:  0.08463701605796814
Epoch:  151  	Training Loss: 0.0693228542804718
Test Loss:  0.08315014094114304
Valid Loss:  0.08427594602108002
Epoch:  152  	Training Loss: 0.06902521103620529
Test Loss:  0.08279994130134583
Valid Loss:  0.08391723781824112
Epoch:  153  	Training Loss: 0.06872960925102234
Test Loss:  0.08245165646076202
Valid Loss:  0.08356049656867981
Epoch:  154  	Training Loss: 0.06843573600053787
Test Loss:  0.08210530132055283
Valid Loss:  0.08320572227239609
Epoch:  155  	Training Loss: 0.06814359128475189
Test Loss:  0.08176086843013763
Valid Loss:  0.08285288512706757
Epoch:  156  	Training Loss: 0.0678531676530838
Test Loss:  0.08141832053661346
Valid Loss:  0.08250196278095245
Epoch:  157  	Training Loss: 0.06756442785263062
Test Loss:  0.08107765018939972
Valid Loss:  0.08215297758579254
Epoch:  158  	Training Loss: 0.06727738678455353
Test Loss:  0.0807388573884964
Valid Loss:  0.08180587738752365
Epoch:  159  	Training Loss: 0.06699201464653015
Test Loss:  0.0804019421339035
Valid Loss:  0.08146069943904877
Epoch:  160  	Training Loss: 0.06670833379030228
Test Loss:  0.08006683737039566
Valid Loss:  0.08111736923456192
Epoch:  161  	Training Loss: 0.06642628461122513
Test Loss:  0.07973362505435944
Valid Loss:  0.08077594637870789
Epoch:  162  	Training Loss: 0.06614590436220169
Test Loss:  0.07940171658992767
Valid Loss:  0.0804358646273613
Epoch:  163  	Training Loss: 0.06586673855781555
Test Loss:  0.07907162606716156
Valid Loss:  0.08009763062000275
Epoch:  164  	Training Loss: 0.06558920443058014
Test Loss:  0.0787433609366417
Valid Loss:  0.07976123690605164
Epoch:  165  	Training Loss: 0.06531329452991486
Test Loss:  0.07841691374778748
Valid Loss:  0.07942670583724976
Epoch:  166  	Training Loss: 0.0650390088558197
Test Loss:  0.07809226214885712
Valid Loss:  0.07909399271011353
Epoch:  167  	Training Loss: 0.06476633250713348
Test Loss:  0.07776937633752823
Valid Loss:  0.07876309752464294
Epoch:  168  	Training Loss: 0.06449525058269501
Test Loss:  0.0774482935667038
Valid Loss:  0.07843402773141861
Epoch:  169  	Training Loss: 0.06422576308250427
Test Loss:  0.07712896913290024
Valid Loss:  0.07810674607753754
Epoch:  170  	Training Loss: 0.06395785510540009
Test Loss:  0.07681140303611755
Valid Loss:  0.07778126001358032
Epoch:  171  	Training Loss: 0.06369151175022125
Test Loss:  0.07649556547403336
Valid Loss:  0.07745754718780518
Epoch:  172  	Training Loss: 0.06342671811580658
Test Loss:  0.07618290185928345
Valid Loss:  0.0771370530128479
Epoch:  173  	Training Loss: 0.06316467374563217
Test Loss:  0.07587192952632904
Valid Loss:  0.07681828737258911
Epoch:  174  	Training Loss: 0.06290414929389954
Test Loss:  0.07556266337633133
Valid Loss:  0.07650125026702881
Epoch:  175  	Training Loss: 0.06264514476060867
Test Loss:  0.07525509595870972
Valid Loss:  0.07618597149848938
Epoch:  176  	Training Loss: 0.062387652695178986
Test Loss:  0.0749492347240448
Valid Loss:  0.07587240636348724
Epoch:  177  	Training Loss: 0.062131691724061966
Test Loss:  0.074645034968853
Valid Loss:  0.0755605399608612
Epoch:  178  	Training Loss: 0.06187720596790314
Test Loss:  0.0743425041437149
Valid Loss:  0.07525036484003067
Epoch:  179  	Training Loss: 0.0616241954267025
Test Loss:  0.07404163479804993
Valid Loss:  0.07494189590215683
Epoch:  180  	Training Loss: 0.061372678726911545
Test Loss:  0.07374240458011627
Valid Loss:  0.0746350884437561
Epoch:  181  	Training Loss: 0.061122626066207886
Test Loss:  0.07344481348991394
Valid Loss:  0.07432996481657028
Epoch:  182  	Training Loss: 0.06087402626872063
Test Loss:  0.07315075397491455
Valid Loss:  0.07402843981981277
Epoch:  183  	Training Loss: 0.06062846630811691
Test Loss:  0.07285831868648529
Valid Loss:  0.07372856140136719
Epoch:  184  	Training Loss: 0.060384348034858704
Test Loss:  0.07256747037172318
Valid Loss:  0.07343032211065292
Epoch:  185  	Training Loss: 0.06014164909720421
Test Loss:  0.07227823138237
Valid Loss:  0.07313369959592819
Epoch:  186  	Training Loss: 0.05990036949515343
Test Loss:  0.07199057191610336
Valid Loss:  0.072838693857193
Epoch:  187  	Training Loss: 0.05966050550341606
Test Loss:  0.07170449197292328
Valid Loss:  0.07254529744386673
Epoch:  188  	Training Loss: 0.05942204222083092
Test Loss:  0.07141996920108795
Valid Loss:  0.0722535029053688
Epoch:  189  	Training Loss: 0.059184957295656204
Test Loss:  0.07113701105117798
Valid Loss:  0.07196328043937683
Epoch:  190  	Training Loss: 0.058949265629053116
Test Loss:  0.07085558772087097
Valid Loss:  0.0716746374964714
Epoch:  191  	Training Loss: 0.05871494114398956
Test Loss:  0.07057571411132812
Valid Loss:  0.07138757407665253
Epoch:  192  	Training Loss: 0.058481987565755844
Test Loss:  0.07029616832733154
Valid Loss:  0.07110084593296051
Epoch:  193  	Training Loss: 0.05824940279126167
Test Loss:  0.07001815736293793
Valid Loss:  0.07081565260887146
Epoch:  194  	Training Loss: 0.058018166571855545
Test Loss:  0.06974165141582489
Valid Loss:  0.07053199410438538
Epoch:  195  	Training Loss: 0.05778828263282776
Test Loss:  0.06946665793657303
Valid Loss:  0.07024990022182465
Epoch:  196  	Training Loss: 0.05755973607301712
Test Loss:  0.06919317692518234
Valid Loss:  0.06996932625770569
Epoch:  197  	Training Loss: 0.057332515716552734
Test Loss:  0.06892119348049164
Valid Loss:  0.06969030201435089
Epoch:  198  	Training Loss: 0.05710664391517639
Test Loss:  0.06865069270133972
Valid Loss:  0.06941279768943787
Epoch:  199  	Training Loss: 0.056882087141275406
Test Loss:  0.06838168948888779
Valid Loss:  0.06913678348064423
Epoch:  200  	Training Loss: 0.05665883421897888
Test Loss:  0.06811415404081345
Valid Loss:  0.06886227428913116
Epoch:  201  	Training Loss: 0.05643688887357712
Test Loss:  0.06784805655479431
Valid Loss:  0.06858924776315689
Epoch:  202  	Training Loss: 0.05621623992919922
Test Loss:  0.06758293509483337
Valid Loss:  0.0683172270655632
Epoch:  203  	Training Loss: 0.05599645525217056
Test Loss:  0.06731924414634705
Valid Loss:  0.06804661452770233
Epoch:  204  	Training Loss: 0.05577792972326279
Test Loss:  0.06705693900585175
Valid Loss:  0.06777745485305786
Epoch:  205  	Training Loss: 0.055560655891895294
Test Loss:  0.06679604947566986
Valid Loss:  0.0675097405910492
Epoch:  206  	Training Loss: 0.05534462630748749
Test Loss:  0.06653658300638199
Valid Loss:  0.06724347174167633
Epoch:  207  	Training Loss: 0.05512985214591026
Test Loss:  0.06627847999334335
Valid Loss:  0.0669785887002945
Epoch:  208  	Training Loss: 0.054916299879550934
Test Loss:  0.06602178514003754
Valid Loss:  0.06671512126922607
Epoch:  209  	Training Loss: 0.0547039695084095
Test Loss:  0.06576644629240036
Valid Loss:  0.06645306944847107
Epoch:  210  	Training Loss: 0.054492853581905365
Test Loss:  0.0655125081539154
Valid Loss:  0.06619243323802948
Epoch:  211  	Training Loss: 0.05428297072649002
Test Loss:  0.0652599036693573
Valid Loss:  0.06593315303325653
Epoch:  212  	Training Loss: 0.05407426506280899
Test Loss:  0.06500643491744995
Valid Loss:  0.06567296385765076
Epoch:  213  	Training Loss: 0.053864941000938416
Test Loss:  0.06475432217121124
Valid Loss:  0.0654141753911972
Epoch:  214  	Training Loss: 0.05365682393312454
Test Loss:  0.06450363248586655
Valid Loss:  0.06515680253505707
Epoch:  215  	Training Loss: 0.05344994366168976
Test Loss:  0.0642542839050293
Valid Loss:  0.06490081548690796
Epoch:  216  	Training Loss: 0.05324424430727959
Test Loss:  0.0640062615275383
Valid Loss:  0.06464619934558868
Epoch:  217  	Training Loss: 0.05303974077105522
Test Loss:  0.06375959515571594
Valid Loss:  0.06439295411109924
 44%|████▍     | 219/500 [02:29<01:33,  3.00it/s] 44%|████▍     | 221/500 [02:36<05:29,  1.18s/it] 45%|████▍     | 223/500 [02:36<03:55,  1.17it/s] 45%|████▌     | 225/500 [02:36<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:36<02:04,  2.20it/s] 46%|████▌     | 229/500 [02:36<01:32,  2.93it/s] 46%|████▌     | 231/500 [02:43<05:16,  1.18s/it] 47%|████▋     | 233/500 [02:43<03:45,  1.18it/s] 47%|████▋     | 235/500 [02:43<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:43<01:59,  2.21it/s] 48%|████▊     | 239/500 [02:43<01:27,  2.97it/s] 48%|████▊     | 241/500 [02:49<05:04,  1.18s/it] 49%|████▊     | 243/500 [02:50<03:37,  1.18it/s] 49%|████▉     | 245/500 [02:50<02:35,  1.63it/s] 49%|████▉     | 247/500 [02:50<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:50<01:23,  3.00it/s] 50%|█████     | 251/500 [02:56<04:51,  1.17s/it] 51%|█████     | 253/500 [02:56<03:27,  1.19it/s] 51%|█████     | 255/500 [02:56<02:29,  1.64it/s] 51%|█████▏    | 257/500 [02:57<01:48,  2.25it/s] 52%|█████▏    | 259/500 [02:57<01:19,  3.01it/s] 52%|█████▏    | 261/500 [03:03<04:38,  1.17s/it] 53%|█████▎    | 263/500 [03:03<03:18,  1.19it/s] 53%|█████▎    | 265/500 [03:03<02:22,  1.64it/s] 53%|█████▎    | 267/500 [03:03<01:43,  2.24it/s] 54%|█████▍    | 269/500 [03:03<01:16,  3.02it/s] 54%|█████▍    | 271/500 [03:10<04:30,  1.18s/it] 55%|█████▍    | 273/500 [03:10<03:12,  1.18it/s] 55%|█████▌    | 275/500 [03:10<02:17,  1.63it/s] 55%|█████▌    | 277/500 [03:10<01:39,  2.23it/s] 56%|█████▌    | 279/500 [03:10<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:17<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:17<03:01,  1.19it/s] 57%|█████▋    | 285/500 [03:17<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:17<01:34,  2.25it/s]Epoch:  218  	Training Loss: 0.05283641815185547
Test Loss:  0.06351427733898163
Valid Loss:  0.06414106488227844
Epoch:  219  	Training Loss: 0.052634283900260925
Test Loss:  0.06327027827501297
Valid Loss:  0.06389054656028748
Epoch:  220  	Training Loss: 0.0524333193898201
Test Loss:  0.06302760541439056
Valid Loss:  0.06364136934280396
Epoch:  221  	Training Loss: 0.05223351716995239
Test Loss:  0.06278622895479202
Valid Loss:  0.06339351832866669
Epoch:  222  	Training Loss: 0.05203486606478691
Test Loss:  0.06253786385059357
Valid Loss:  0.06313847750425339
Epoch:  223  	Training Loss: 0.05183053016662598
Test Loss:  0.062290821224451065
Valid Loss:  0.06288477033376694
Epoch:  224  	Training Loss: 0.051627375185489655
Test Loss:  0.06204508990049362
Valid Loss:  0.06263243407011032
Epoch:  225  	Training Loss: 0.05142538249492645
Test Loss:  0.06180065870285034
Valid Loss:  0.062381401658058167
Epoch:  226  	Training Loss: 0.05122452601790428
Test Loss:  0.06155753508210182
Valid Loss:  0.06213171035051346
Epoch:  227  	Training Loss: 0.05102483183145523
Test Loss:  0.06131571903824806
Valid Loss:  0.061883345246315
Epoch:  228  	Training Loss: 0.050826288759708405
Test Loss:  0.06107519939541817
Valid Loss:  0.0616362988948822
Epoch:  229  	Training Loss: 0.050628889352083206
Test Loss:  0.06083596497774124
Valid Loss:  0.06139056384563446
Epoch:  230  	Training Loss: 0.05043262243270874
Test Loss:  0.06059800088405609
Valid Loss:  0.06114614009857178
Epoch:  231  	Training Loss: 0.05023748427629471
Test Loss:  0.060361314564943314
Valid Loss:  0.06090301275253296
Epoch:  232  	Training Loss: 0.050043463706970215
Test Loss:  0.06013350188732147
Valid Loss:  0.060669004917144775
Epoch:  233  	Training Loss: 0.04985681176185608
Test Loss:  0.059906914830207825
Valid Loss:  0.060436248779296875
Epoch:  234  	Training Loss: 0.0496712327003479
Test Loss:  0.059681545943021774
Valid Loss:  0.06020473316311836
Epoch:  235  	Training Loss: 0.04948671907186508
Test Loss:  0.05945739895105362
Valid Loss:  0.05997446924448013
Epoch:  236  	Training Loss: 0.04930327832698822
Test Loss:  0.05923444777727127
Valid Loss:  0.0597454234957695
Epoch:  237  	Training Loss: 0.04912089556455612
Test Loss:  0.059012703597545624
Valid Loss:  0.05951759219169617
Epoch:  238  	Training Loss: 0.04893955588340759
Test Loss:  0.05879213660955429
Valid Loss:  0.05929099768400192
Epoch:  239  	Training Loss: 0.04875925928354263
Test Loss:  0.05857275426387787
Valid Loss:  0.05906558781862259
Epoch:  240  	Training Loss: 0.04858000576496124
Test Loss:  0.05835454910993576
Valid Loss:  0.05884137749671936
Epoch:  241  	Training Loss: 0.04840177297592163
Test Loss:  0.05813752859830856
Valid Loss:  0.05861838161945343
Epoch:  242  	Training Loss: 0.04822458326816559
Test Loss:  0.05792173743247986
Valid Loss:  0.05839667096734047
Epoch:  243  	Training Loss: 0.0480484813451767
Test Loss:  0.05770713463425636
Valid Loss:  0.05817611142992973
Epoch:  244  	Training Loss: 0.047873396426439285
Test Loss:  0.057493679225444794
Valid Loss:  0.057956762611866
Epoch:  245  	Training Loss: 0.04769933223724365
Test Loss:  0.057281360030174255
Valid Loss:  0.05773857235908508
Epoch:  246  	Training Loss: 0.04752625524997711
Test Loss:  0.05707021802663803
Valid Loss:  0.057521574199199677
Epoch:  247  	Training Loss: 0.04735420644283295
Test Loss:  0.05686017870903015
Valid Loss:  0.0573057122528553
Epoch:  248  	Training Loss: 0.04718312621116638
Test Loss:  0.0566512830555439
Valid Loss:  0.05709099769592285
Epoch:  249  	Training Loss: 0.047013044357299805
Test Loss:  0.05644349753856659
Valid Loss:  0.05687744915485382
Epoch:  250  	Training Loss: 0.046843938529491425
Test Loss:  0.05623682588338852
Valid Loss:  0.05666501447558403
Epoch:  251  	Training Loss: 0.046675801277160645
Test Loss:  0.05603128671646118
Valid Loss:  0.05645372346043587
Epoch:  252  	Training Loss: 0.04650864005088806
Test Loss:  0.055828820914030075
Valid Loss:  0.05624562129378319
Epoch:  253  	Training Loss: 0.046344056725502014
Test Loss:  0.05562745779752731
Valid Loss:  0.05603863298892975
Epoch:  254  	Training Loss: 0.046180419623851776
Test Loss:  0.055427148938179016
Valid Loss:  0.05583272874355316
Epoch:  255  	Training Loss: 0.04601772129535675
Test Loss:  0.05522793158888817
Valid Loss:  0.055627934634685516
Epoch:  256  	Training Loss: 0.04585595801472664
Test Loss:  0.05502976477146149
Valid Loss:  0.055424198508262634
Epoch:  257  	Training Loss: 0.04569511115550995
Test Loss:  0.05483264476060867
Valid Loss:  0.055221542716026306
Epoch:  258  	Training Loss: 0.04553518071770668
Test Loss:  0.054636597633361816
Valid Loss:  0.05501998960971832
Epoch:  259  	Training Loss: 0.04537618160247803
Test Loss:  0.054441601037979126
Valid Loss:  0.0548195019364357
Epoch:  260  	Training Loss: 0.0452180914580822
Test Loss:  0.054247643798589706
Valid Loss:  0.05462008714675903
Epoch:  261  	Training Loss: 0.04506092146039009
Test Loss:  0.05405469983816147
Valid Loss:  0.05442170053720474
Epoch:  262  	Training Loss: 0.04490462690591812
Test Loss:  0.0538610965013504
Valid Loss:  0.05422262102365494
Epoch:  263  	Training Loss: 0.044747866690158844
Test Loss:  0.05366849899291992
Valid Loss:  0.05402457341551781
Epoch:  264  	Training Loss: 0.044591985642910004
Test Loss:  0.05347692221403122
Valid Loss:  0.053827568888664246
Epoch:  265  	Training Loss: 0.0444369837641716
Test Loss:  0.0532863587141037
Valid Loss:  0.053631603717803955
Epoch:  266  	Training Loss: 0.04428287595510483
Test Loss:  0.05309683084487915
Valid Loss:  0.05343668907880783
Epoch:  267  	Training Loss: 0.044129662215709686
Test Loss:  0.052908338606357574
Valid Loss:  0.053242821246385574
Epoch:  268  	Training Loss: 0.04397733509540558
Test Loss:  0.0527208149433136
Valid Loss:  0.0530499704182148
Epoch:  269  	Training Loss: 0.04382586479187012
Test Loss:  0.052534304559230804
Valid Loss:  0.052858151495456696
Epoch:  270  	Training Loss: 0.04367527365684509
Test Loss:  0.052348796278238297
Valid Loss:  0.05266732722520828
Epoch:  271  	Training Loss: 0.04352554678916931
Test Loss:  0.052164237946271896
Valid Loss:  0.05247752368450165
Epoch:  272  	Training Loss: 0.04337666183710098
Test Loss:  0.051980484277009964
Valid Loss:  0.05228850618004799
Epoch:  273  	Training Loss: 0.04322846606373787
Test Loss:  0.051797688007354736
Valid Loss:  0.05210047960281372
Epoch:  274  	Training Loss: 0.043081097304821014
Test Loss:  0.051615845412015915
Valid Loss:  0.051913417875766754
Epoch:  275  	Training Loss: 0.042934563010931015
Test Loss:  0.0514349564909935
Valid Loss:  0.05172733962535858
Epoch:  276  	Training Loss: 0.042788855731487274
Test Loss:  0.05125502496957779
Valid Loss:  0.051542237401008606
Epoch:  277  	Training Loss: 0.04264397919178009
Test Loss:  0.0510760173201561
Valid Loss:  0.05135808885097504
Epoch:  278  	Training Loss: 0.04249991104006767
Test Loss:  0.050897978246212006
Valid Loss:  0.051174912601709366
Epoch:  279  	Training Loss: 0.04235666245222092
Test Loss:  0.05072084814310074
Valid Loss:  0.0509926900267601
Epoch:  280  	Training Loss: 0.04221421480178833
Test Loss:  0.05054464936256409
Valid Loss:  0.05081140622496605
Epoch:  281  	Training Loss: 0.04207257926464081
Test Loss:  0.05036938562989235
Valid Loss:  0.050631068646907806
Epoch:  282  	Training Loss: 0.04193173721432686
Test Loss:  0.050195880234241486
Valid Loss:  0.050452541559934616
Epoch:  283  	Training Loss: 0.0417923778295517
Test Loss:  0.050023287534713745
Valid Loss:  0.05027494952082634
Epoch:  284  	Training Loss: 0.04165380075573921
Test Loss:  0.04985158145427704
Valid Loss:  0.05009827762842178
Epoch:  285  	Training Loss: 0.041516005992889404
Test Loss:  0.04968082159757614
Valid Loss:  0.049922551959753036
Epoch:  286  	Training Loss: 0.04137900471687317
Test Loss:  0.04951094463467598
Valid Loss:  0.049747735261917114
Epoch:  287  	Training Loss: 0.041242778301239014
Test Loss:  0.049341946840286255
Valid Loss:  0.04957381635904312
Epoch:  288  	Training Loss: 0.041107311844825745
Test Loss:  0.04917383939027786
Valid Loss:  0.04940081760287285
Epoch:  289  	Training Loss: 0.04097260907292366
 58%|█████▊    | 289/500 [03:17<01:09,  3.02it/s] 58%|█████▊    | 291/500 [03:23<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:24<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:24<02:05,  1.64it/s] 59%|█████▉    | 297/500 [03:24<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:24<01:06,  3.00it/s] 60%|██████    | 301/500 [03:30<03:53,  1.17s/it] 61%|██████    | 303/500 [03:30<02:45,  1.19it/s] 61%|██████    | 305/500 [03:30<01:58,  1.64it/s] 61%|██████▏   | 307/500 [03:31<01:25,  2.24it/s] 62%|██████▏   | 309/500 [03:31<01:03,  3.01it/s] 62%|██████▏   | 311/500 [03:37<03:42,  1.18s/it] 63%|██████▎   | 313/500 [03:37<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:37<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:37<01:22,  2.23it/s] 64%|██████▍   | 319/500 [03:38<01:00,  3.00it/s] 64%|██████▍   | 321/500 [03:44<03:30,  1.18s/it] 65%|██████▍   | 323/500 [03:44<02:29,  1.18it/s] 65%|██████▌   | 325/500 [03:44<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:44<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:44<00:56,  3.00it/s] 66%|██████▌   | 331/500 [03:51<03:18,  1.17s/it] 67%|██████▋   | 333/500 [03:51<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:51<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:51<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:51<00:53,  3.02it/s] 68%|██████▊   | 341/500 [03:58<03:11,  1.20s/it] 69%|██████▊   | 343/500 [03:58<02:15,  1.16it/s] 69%|██████▉   | 345/500 [03:58<01:36,  1.60it/s] 69%|██████▉   | 347/500 [03:58<01:09,  2.19it/s] 70%|██████▉   | 349/500 [03:58<00:51,  2.94it/s] 70%|███████   | 351/500 [04:04<02:54,  1.17s/it] 71%|███████   | 353/500 [04:05<02:03,  1.19it/s] 71%|███████   | 355/500 [04:05<01:27,  1.65it/s] 71%|███████▏  | 357/500 [04:05<01:03,  2.25it/s] 72%|███████▏  | 359/500 [04:05<00:46,  3.03it/s]Test Loss:  0.04900661110877991
Valid Loss:  0.04922870546579361
Epoch:  290  	Training Loss: 0.04083866626024246
Test Loss:  0.048840250819921494
Valid Loss:  0.0490574911236763
Epoch:  291  	Training Loss: 0.04070548340678215
Test Loss:  0.048674777150154114
Valid Loss:  0.04888717085123062
Epoch:  292  	Training Loss: 0.04057304561138153
Test Loss:  0.04851366579532623
Valid Loss:  0.04872135818004608
Epoch:  293  	Training Loss: 0.040444158017635345
Test Loss:  0.0483534000813961
Valid Loss:  0.04855641722679138
Epoch:  294  	Training Loss: 0.040316008031368256
Test Loss:  0.048193976283073425
Valid Loss:  0.04839232191443443
Epoch:  295  	Training Loss: 0.040188565850257874
Test Loss:  0.048035383224487305
Valid Loss:  0.048229098320007324
Epoch:  296  	Training Loss: 0.04006185010075569
Test Loss:  0.04787762835621834
Valid Loss:  0.04806670546531677
Epoch:  297  	Training Loss: 0.039935849606990814
Test Loss:  0.04772070422768593
Valid Loss:  0.04790518432855606
Epoch:  298  	Training Loss: 0.03981056436896324
Test Loss:  0.04756459593772888
Valid Loss:  0.04774449020624161
Epoch:  299  	Training Loss: 0.03968597576022148
Test Loss:  0.047409333288669586
Valid Loss:  0.047584664076566696
Epoch:  300  	Training Loss: 0.03956210985779762
Test Loss:  0.047254886478185654
Valid Loss:  0.04742565006017685
Epoch:  301  	Training Loss: 0.039438940584659576
Test Loss:  0.0471012257039547
Valid Loss:  0.047267477959394455
Epoch:  302  	Training Loss: 0.039316460490226746
Test Loss:  0.046942971646785736
Valid Loss:  0.04710453748703003
Epoch:  303  	Training Loss: 0.039190374314785004
Test Loss:  0.046785540878772736
Valid Loss:  0.04694242775440216
Epoch:  304  	Training Loss: 0.03906499594449997
Test Loss:  0.0466289296746254
Valid Loss:  0.04678115248680115
Epoch:  305  	Training Loss: 0.03894031420350075
Test Loss:  0.04647311568260193
Valid Loss:  0.04662071913480759
Epoch:  306  	Training Loss: 0.03881633281707764
Test Loss:  0.046318113803863525
Valid Loss:  0.04646109789609909
Epoch:  307  	Training Loss: 0.038693055510520935
Test Loss:  0.04616392403841019
Valid Loss:  0.04630231484770775
Epoch:  308  	Training Loss: 0.03857046365737915
Test Loss:  0.04601052775979042
Valid Loss:  0.04614432528614998
Epoch:  309  	Training Loss: 0.038448553532361984
Test Loss:  0.04585792496800423
Valid Loss:  0.045987166464328766
Epoch:  310  	Training Loss: 0.03832731768488884
Test Loss:  0.0457061231136322
Valid Loss:  0.04583081230521202
Epoch:  311  	Training Loss: 0.03820677846670151
Test Loss:  0.045555081218481064
Valid Loss:  0.045675259083509445
Epoch:  312  	Training Loss: 0.038086898624897
Test Loss:  0.04540980979800224
Valid Loss:  0.04552565515041351
Epoch:  313  	Training Loss: 0.0379716157913208
Test Loss:  0.04526527225971222
Valid Loss:  0.04537680000066757
Epoch:  314  	Training Loss: 0.03785695880651474
Test Loss:  0.04512147605419159
Valid Loss:  0.04522870481014252
Epoch:  315  	Training Loss: 0.037742938846349716
Test Loss:  0.04497843235731125
Valid Loss:  0.04508137330412865
Epoch:  316  	Training Loss: 0.03762955218553543
Test Loss:  0.044836096465587616
Valid Loss:  0.044934771955013275
Epoch:  317  	Training Loss: 0.03751678019762039
Test Loss:  0.04469449073076248
Valid Loss:  0.04478892683982849
Epoch:  318  	Training Loss: 0.037404634058475494
Test Loss:  0.04455361142754555
Valid Loss:  0.044643811881542206
Epoch:  319  	Training Loss: 0.037293095141649246
Test Loss:  0.044413428753614426
Valid Loss:  0.04449941962957382
Epoch:  320  	Training Loss: 0.03718217462301254
Test Loss:  0.0442739836871624
Valid Loss:  0.04435577243566513
Epoch:  321  	Training Loss: 0.03707185387611389
Test Loss:  0.04413524270057678
Valid Loss:  0.04421286657452583
Epoch:  322  	Training Loss: 0.03696215897798538
Test Loss:  0.04399288445711136
Valid Loss:  0.04406621307134628
Epoch:  323  	Training Loss: 0.03684966638684273
Test Loss:  0.04385126382112503
Valid Loss:  0.043920304626226425
Epoch:  324  	Training Loss: 0.03673778846859932
Test Loss:  0.0437103733420372
Valid Loss:  0.04377514868974686
Epoch:  325  	Training Loss: 0.03662654384970665
Test Loss:  0.043570198118686676
Valid Loss:  0.04363073408603668
Epoch:  326  	Training Loss: 0.03651591017842293
Test Loss:  0.04343076050281525
Valid Loss:  0.0434870608150959
Epoch:  327  	Training Loss: 0.03640589118003845
Test Loss:  0.04329203814268112
Valid Loss:  0.04334413260221481
Epoch:  328  	Training Loss: 0.03629649430513382
Test Loss:  0.043154023587703705
Valid Loss:  0.04320191591978073
Epoch:  329  	Training Loss: 0.03618770092725754
Test Loss:  0.0430167093873024
Valid Loss:  0.04306042566895485
Epoch:  330  	Training Loss: 0.03607950359582901
Test Loss:  0.0428800955414772
Valid Loss:  0.04291963949799538
Epoch:  331  	Training Loss: 0.03597189486026764
Test Loss:  0.042744167149066925
Valid Loss:  0.042779579758644104
Epoch:  332  	Training Loss: 0.03586488962173462
Test Loss:  0.042611509561538696
Valid Loss:  0.042642876505851746
Epoch:  333  	Training Loss: 0.035760484635829926
Test Loss:  0.04247952252626419
Valid Loss:  0.0425068661570549
Epoch:  334  	Training Loss: 0.035656653344631195
Test Loss:  0.0423482209444046
Valid Loss:  0.04237154498696327
Epoch:  335  	Training Loss: 0.03555339202284813
Test Loss:  0.04221757873892784
Valid Loss:  0.04223690181970596
Epoch:  336  	Training Loss: 0.03545069321990013
Test Loss:  0.042087581008672714
Valid Loss:  0.04210291802883148
Epoch:  337  	Training Loss: 0.0353485569357872
Test Loss:  0.04195825755596161
Valid Loss:  0.04196963459253311
Epoch:  338  	Training Loss: 0.03524697571992874
Test Loss:  0.041829563677310944
Valid Loss:  0.041836999356746674
Epoch:  339  	Training Loss: 0.035145942121744156
Test Loss:  0.04170152172446251
Valid Loss:  0.04170503467321396
Epoch:  340  	Training Loss: 0.03504545986652374
Test Loss:  0.04157412424683571
Valid Loss:  0.04157371446490288
Epoch:  341  	Training Loss: 0.0349455252289772
Test Loss:  0.04144737496972084
Valid Loss:  0.04144307225942612
Epoch:  342  	Training Loss: 0.03484613820910454
Test Loss:  0.04131987318396568
Valid Loss:  0.04131165146827698
Epoch:  343  	Training Loss: 0.0347461998462677
Test Loss:  0.041193027049303055
Valid Loss:  0.041180890053510666
Epoch:  344  	Training Loss: 0.034646809101104736
Test Loss:  0.04106680303812027
Valid Loss:  0.04105078801512718
Epoch:  345  	Training Loss: 0.03454796224832535
Test Loss:  0.04094122722744942
Valid Loss:  0.04092134162783623
Epoch:  346  	Training Loss: 0.03444965183734894
Test Loss:  0.0408162847161293
Valid Loss:  0.040792547166347504
Epoch:  347  	Training Loss: 0.034351885318756104
Test Loss:  0.040691982954740524
Valid Loss:  0.04066440463066101
Epoch:  348  	Training Loss: 0.03425465524196625
Test Loss:  0.04056832194328308
Valid Loss:  0.04053691402077675
Epoch:  349  	Training Loss: 0.03415796905755997
Test Loss:  0.040445275604724884
Valid Loss:  0.04041004925966263
Epoch:  350  	Training Loss: 0.03406180068850517
Test Loss:  0.04032285511493683
Valid Loss:  0.040283843874931335
Epoch:  351  	Training Loss: 0.03396615386009216
Test Loss:  0.04020105302333832
Valid Loss:  0.04015824943780899
Epoch:  352  	Training Loss: 0.03387103229761124
Test Loss:  0.04007895290851593
Valid Loss:  0.040032364428043365
Epoch:  353  	Training Loss: 0.033775754272937775
Test Loss:  0.03995747119188309
Valid Loss:  0.03990710526704788
Epoch:  354  	Training Loss: 0.0336809977889061
Test Loss:  0.03983662277460098
Valid Loss:  0.039782486855983734
Epoch:  355  	Training Loss: 0.0335867665708065
Test Loss:  0.03971638157963753
Valid Loss:  0.03965849429368973
Epoch:  356  	Training Loss: 0.033493056893348694
Test Loss:  0.0395967923104763
Valid Loss:  0.03953516483306885
Epoch:  357  	Training Loss: 0.03339988738298416
Test Loss:  0.039477795362472534
Valid Loss:  0.03941245377063751
Epoch:  358  	Training Loss: 0.03330722451210022
Test Loss:  0.03935940936207771
Valid Loss:  0.039290353655815125
Epoch:  359  	Training Loss: 0.03321507200598717
Test Loss:  0.03924164921045303
Valid Loss:  0.03916889801621437
Epoch:  360  	Training Loss: 0.0331234335899353
Test Loss:  0.03912445157766342
Valid Loss:   72%|███████▏  | 361/500 [04:11<02:40,  1.15s/it] 73%|███████▎  | 363/500 [04:11<01:53,  1.20it/s] 73%|███████▎  | 365/500 [04:11<01:21,  1.67it/s] 73%|███████▎  | 367/500 [04:11<00:58,  2.28it/s] 74%|███████▍  | 369/500 [04:12<00:43,  3.04it/s] 74%|███████▍  | 371/500 [04:18<02:29,  1.16s/it] 75%|███████▍  | 373/500 [04:18<01:45,  1.20it/s] 75%|███████▌  | 375/500 [04:18<01:15,  1.66it/s] 75%|███████▌  | 377/500 [04:18<00:54,  2.26it/s] 76%|███████▌  | 379/500 [04:18<00:39,  3.04it/s] 76%|███████▌  | 381/500 [04:25<02:18,  1.16s/it] 77%|███████▋  | 383/500 [04:25<01:37,  1.20it/s] 77%|███████▋  | 385/500 [04:25<01:09,  1.66it/s] 77%|███████▋  | 387/500 [04:25<00:49,  2.27it/s] 78%|███████▊  | 389/500 [04:25<00:36,  3.05it/s] 78%|███████▊  | 391/500 [04:31<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:31<01:29,  1.19it/s] 79%|███████▉  | 395/500 [04:32<01:03,  1.65it/s] 79%|███████▉  | 397/500 [04:32<00:45,  2.25it/s] 80%|███████▉  | 399/500 [04:32<00:33,  3.00it/s] 80%|████████  | 401/500 [04:38<01:54,  1.16s/it] 81%|████████  | 403/500 [04:38<01:20,  1.20it/s] 81%|████████  | 405/500 [04:38<00:57,  1.66it/s] 81%|████████▏ | 407/500 [04:38<00:41,  2.26it/s] 82%|████████▏ | 409/500 [04:39<00:29,  3.04it/s] 82%|████████▏ | 411/500 [04:45<01:45,  1.18s/it] 83%|████████▎ | 413/500 [04:45<01:14,  1.17it/s] 83%|████████▎ | 415/500 [04:45<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:45<00:37,  2.22it/s] 84%|████████▍ | 419/500 [04:46<00:27,  2.99it/s] 84%|████████▍ | 421/500 [04:52<01:33,  1.19s/it] 85%|████████▍ | 423/500 [04:52<01:05,  1.17it/s] 85%|████████▌ | 425/500 [04:52<00:46,  1.62it/s] 85%|████████▌ | 427/500 [04:52<00:33,  2.21it/s] 86%|████████▌ | 429/500 [04:52<00:23,  2.97it/s] 86%|████████▌ | 431/500 [04:59<01:21,  1.18s/it]0.03904803842306137
Epoch:  361  	Training Loss: 0.033032290637493134
Test Loss:  0.03900788724422455
Valid Loss:  0.03892781585454941
Epoch:  362  	Training Loss: 0.03294166922569275
Test Loss:  0.03889334201812744
Valid Loss:  0.03880968317389488
Epoch:  363  	Training Loss: 0.03285263478755951
Test Loss:  0.0387793704867363
Valid Loss:  0.03869212418794632
Epoch:  364  	Training Loss: 0.03276407718658447
Test Loss:  0.038665954023599625
Valid Loss:  0.038575150072574615
Epoch:  365  	Training Loss: 0.03267598897218704
Test Loss:  0.03855310007929802
Valid Loss:  0.03845876082777977
Epoch:  366  	Training Loss: 0.03258838504552841
Test Loss:  0.038440801203250885
Valid Loss:  0.03834293410181999
Epoch:  367  	Training Loss: 0.03250123932957649
Test Loss:  0.03832906857132912
Valid Loss:  0.03822768107056618
Epoch:  368  	Training Loss: 0.03241456672549248
Test Loss:  0.03821788728237152
Valid Loss:  0.03811300918459892
Epoch:  369  	Training Loss: 0.03232835978269577
Test Loss:  0.03810727596282959
Valid Loss:  0.03799889609217644
Epoch:  370  	Training Loss: 0.03224261850118637
Test Loss:  0.037997204810380936
Valid Loss:  0.03788535296916962
Epoch:  371  	Training Loss: 0.03215734288096428
Test Loss:  0.037887681275606155
Valid Loss:  0.03777237981557846
Epoch:  372  	Training Loss: 0.0320725291967392
Test Loss:  0.03778025880455971
Valid Loss:  0.037661585956811905
Epoch:  373  	Training Loss: 0.03198938071727753
Test Loss:  0.03767339885234833
Valid Loss:  0.037551332265138626
Epoch:  374  	Training Loss: 0.031906675547361374
Test Loss:  0.03756704553961754
Valid Loss:  0.037441615015268326
Epoch:  375  	Training Loss: 0.031824417412281036
Test Loss:  0.03746122494339943
Valid Loss:  0.037332456558942795
Epoch:  376  	Training Loss: 0.03174259513616562
Test Loss:  0.037355937063694
Valid Loss:  0.037223827093839645
Epoch:  377  	Training Loss: 0.03166121244430542
Test Loss:  0.03725114464759827
Valid Loss:  0.03711573779582977
Epoch:  378  	Training Loss: 0.03158026561141014
Test Loss:  0.037146907299757004
Valid Loss:  0.03700820356607437
Epoch:  379  	Training Loss: 0.031499769538640976
Test Loss:  0.037043165415525436
Valid Loss:  0.036901168525218964
Epoch:  380  	Training Loss: 0.03141968324780464
Test Loss:  0.03693993389606476
Valid Loss:  0.03679466247558594
Epoch:  381  	Training Loss: 0.03134002536535263
Test Loss:  0.036837220191955566
Valid Loss:  0.03668868914246559
Epoch:  382  	Training Loss: 0.03126080334186554
Test Loss:  0.036733631044626236
Valid Loss:  0.03658181056380272
Epoch:  383  	Training Loss: 0.031180931255221367
Test Loss:  0.036630548536777496
Valid Loss:  0.036475446075201035
Epoch:  384  	Training Loss: 0.031101474538445473
Test Loss:  0.03652796894311905
Valid Loss:  0.03636961430311203
Epoch:  385  	Training Loss: 0.03102244809269905
Test Loss:  0.03642589971423149
Valid Loss:  0.036264289170503616
Epoch:  386  	Training Loss: 0.03094383329153061
Test Loss:  0.03632431477308273
Valid Loss:  0.0361594632267952
Epoch:  387  	Training Loss: 0.030865631997585297
Test Loss:  0.03622322902083397
Valid Loss:  0.03605515509843826
Epoch:  388  	Training Loss: 0.030787847936153412
Test Loss:  0.036122649908065796
Valid Loss:  0.03595136106014252
Epoch:  389  	Training Loss: 0.030710486695170403
Test Loss:  0.03602256253361702
Valid Loss:  0.03584807738661766
Epoch:  390  	Training Loss: 0.030633531510829926
Test Loss:  0.03592295199632645
Valid Loss:  0.0357452854514122
Epoch:  391  	Training Loss: 0.030556969344615936
Test Loss:  0.035823822021484375
Valid Loss:  0.035642996430397034
Epoch:  392  	Training Loss: 0.030480820685625076
Test Loss:  0.0357249416410923
Valid Loss:  0.03554096072912216
Epoch:  393  	Training Loss: 0.030404869467020035
Test Loss:  0.03562653809785843
Valid Loss:  0.03543940559029579
Epoch:  394  	Training Loss: 0.030329309403896332
Test Loss:  0.035528600215911865
Valid Loss:  0.03533834218978882
Epoch:  395  	Training Loss: 0.030254147946834564
Test Loss:  0.035431139171123505
Valid Loss:  0.03523778170347214
Epoch:  396  	Training Loss: 0.030179383233189583
Test Loss:  0.035334162414073944
Valid Loss:  0.03513769432902336
Epoch:  397  	Training Loss: 0.030105004087090492
Test Loss:  0.0352376289665699
Valid Loss:  0.03503808379173279
Epoch:  398  	Training Loss: 0.03003101609647274
Test Loss:  0.03514157980680466
Valid Loss:  0.03493894636631012
Epoch:  399  	Training Loss: 0.029957406222820282
Test Loss:  0.035045988857746124
Valid Loss:  0.03484030067920685
Epoch:  400  	Training Loss: 0.02988419495522976
Test Loss:  0.0349508672952652
Valid Loss:  0.03474212810397148
Epoch:  401  	Training Loss: 0.02981136366724968
Test Loss:  0.03485619276762009
Valid Loss:  0.034644417464733124
Epoch:  402  	Training Loss: 0.029738910496234894
Test Loss:  0.03476127237081528
Valid Loss:  0.03454645350575447
Epoch:  403  	Training Loss: 0.02966628223657608
Test Loss:  0.03466680273413658
Valid Loss:  0.03444894775748253
Epoch:  404  	Training Loss: 0.02959403023123741
Test Loss:  0.034572783857584
Valid Loss:  0.03435191512107849
Epoch:  405  	Training Loss: 0.029522158205509186
Test Loss:  0.034479230642318726
Valid Loss:  0.03425535559654236
Epoch:  406  	Training Loss: 0.029450660571455956
Test Loss:  0.034386105835437775
Valid Loss:  0.034159235656261444
Epoch:  407  	Training Loss: 0.029379531741142273
Test Loss:  0.03429342061281204
Valid Loss:  0.03406357392668724
Epoch:  408  	Training Loss: 0.029308754950761795
Test Loss:  0.03420118987560272
Valid Loss:  0.03396837040781975
Epoch:  409  	Training Loss: 0.02923836000263691
Test Loss:  0.03410940244793892
Valid Loss:  0.03387361019849777
Epoch:  410  	Training Loss: 0.029168318957090378
Test Loss:  0.03401803970336914
Valid Loss:  0.0337793305516243
Epoch:  411  	Training Loss: 0.029098644852638245
Test Loss:  0.03392711281776428
Valid Loss:  0.03368546441197395
Epoch:  412  	Training Loss: 0.029029330238699913
Test Loss:  0.03383602946996689
Valid Loss:  0.03359141945838928
Epoch:  413  	Training Loss: 0.028959933668375015
Test Loss:  0.033745381981134415
Valid Loss:  0.03349784016609192
Epoch:  414  	Training Loss: 0.028890904039144516
Test Loss:  0.03365516662597656
Valid Loss:  0.03340468928217888
Epoch:  415  	Training Loss: 0.02882223203778267
Test Loss:  0.033565372228622437
Valid Loss:  0.03331200033426285
Epoch:  416  	Training Loss: 0.028753913938999176
Test Loss:  0.033476024866104126
Valid Loss:  0.03321975842118263
Epoch:  417  	Training Loss: 0.028685959056019783
Test Loss:  0.03338709846138954
Valid Loss:  0.033127956092357635
Epoch:  418  	Training Loss: 0.028618352487683296
Test Loss:  0.03329862654209137
Valid Loss:  0.03303660452365875
Epoch:  419  	Training Loss: 0.028551116585731506
Test Loss:  0.03321058303117752
Valid Loss:  0.03294569253921509
Epoch:  420  	Training Loss: 0.028484225273132324
Test Loss:  0.0331229604780674
Valid Loss:  0.03285522013902664
Epoch:  421  	Training Loss: 0.028417687863111496
Test Loss:  0.033035751432180405
Valid Loss:  0.03276517987251282
Epoch:  422  	Training Loss: 0.028351493179798126
Test Loss:  0.03294824808835983
Valid Loss:  0.032674819231033325
Epoch:  423  	Training Loss: 0.02828509919345379
Test Loss:  0.03286115825176239
Valid Loss:  0.03258489817380905
Epoch:  424  	Training Loss: 0.028219042345881462
Test Loss:  0.03277447819709778
Valid Loss:  0.0324954055249691
Epoch:  425  	Training Loss: 0.028153328225016594
Test Loss:  0.03268822282552719
Valid Loss:  0.03240633383393288
Epoch:  426  	Training Loss: 0.028087954968214035
Test Loss:  0.032602373510599136
Valid Loss:  0.03231769800186157
Epoch:  427  	Training Loss: 0.028022926300764084
Test Loss:  0.03251693770289421
Valid Loss:  0.0322294719517231
Epoch:  428  	Training Loss: 0.027958223596215248
Test Loss:  0.032431911677122116
Valid Loss:  0.03214164823293686
Epoch:  429  	Training Loss: 0.027893856167793274
Test Loss:  0.03234727680683136
Valid Loss:  0.03205427527427673
Epoch:  430  	Training Loss: 0.02782982774078846
Test Loss:  0.03226307034492493
Valid Loss:  0.03196731209754944
Epoch:  431  	Training Loss: 0.027766132727265358
Test Loss:  0.032179251313209534
Valid Loss:  0.03188075125217438
 87%|████████▋ | 433/500 [04:59<00:56,  1.18it/s] 87%|████████▋ | 435/500 [04:59<00:39,  1.63it/s] 87%|████████▋ | 437/500 [04:59<00:28,  2.23it/s] 88%|████████▊ | 439/500 [04:59<00:20,  3.01it/s] 88%|████████▊ | 441/500 [05:06<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:06<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:06<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:06<00:23,  2.24it/s] 90%|████████▉ | 449/500 [05:06<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:12<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:12<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:13<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:13<00:19,  2.24it/s] 92%|█████████▏| 459/500 [05:13<00:13,  3.01it/s] 92%|█████████▏| 461/500 [05:19<00:45,  1.16s/it] 93%|█████████▎| 463/500 [05:19<00:30,  1.20it/s] 93%|█████████▎| 465/500 [05:19<00:21,  1.66it/s] 93%|█████████▎| 467/500 [05:19<00:14,  2.27it/s] 94%|█████████▍| 469/500 [05:20<00:10,  3.04it/s] 94%|█████████▍| 471/500 [05:26<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:26<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:26<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:26<00:10,  2.26it/s] 96%|█████████▌| 479/500 [05:26<00:06,  3.03it/s] 96%|█████████▌| 481/500 [05:33<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:33<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:33<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:33<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:33<00:03,  3.02it/s] 98%|█████████▊| 491/500 [05:39<00:10,  1.16s/it] 99%|█████████▊| 493/500 [05:40<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:40<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:40<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:40<00:00,  3.01it/s]100%|██████████| 500/500 [05:40<00:00,  1.47it/s]
Epoch:  432  	Training Loss: 0.02770276367664337
Test Loss:  0.032097719609737396
Valid Loss:  0.03179655224084854
Epoch:  433  	Training Loss: 0.027641141787171364
Test Loss:  0.032016560435295105
Valid Loss:  0.03171273693442345
Epoch:  434  	Training Loss: 0.02757982909679413
Test Loss:  0.031935784965753555
Valid Loss:  0.031629323959350586
Epoch:  435  	Training Loss: 0.027518829330801964
Test Loss:  0.03185538947582245
Valid Loss:  0.03154629468917847
Epoch:  436  	Training Loss: 0.02745813876390457
Test Loss:  0.03177538141608238
Valid Loss:  0.03146366775035858
Epoch:  437  	Training Loss: 0.027397766709327698
Test Loss:  0.03169575333595276
Valid Loss:  0.031381431967020035
Epoch:  438  	Training Loss: 0.027337701991200447
Test Loss:  0.03161650151014328
Valid Loss:  0.03129957616329193
Epoch:  439  	Training Loss: 0.027277935296297073
Test Loss:  0.031537603586912155
Valid Loss:  0.031218094751238823
Epoch:  440  	Training Loss: 0.027218472212553024
Test Loss:  0.03145907446742058
Valid Loss:  0.031137000769376755
Epoch:  441  	Training Loss: 0.027159299701452255
Test Loss:  0.03138093277812004
Valid Loss:  0.031056281179189682
Epoch:  442  	Training Loss: 0.027100438252091408
Test Loss:  0.03130282089114189
Valid Loss:  0.030975613743066788
Epoch:  443  	Training Loss: 0.027041621506214142
Test Loss:  0.031225092709064484
Valid Loss:  0.03089534305036068
Epoch:  444  	Training Loss: 0.02698311023414135
Test Loss:  0.03114774078130722
Valid Loss:  0.030815452337265015
Epoch:  445  	Training Loss: 0.026924898847937584
Test Loss:  0.03107074275612831
Valid Loss:  0.030735941603779793
Epoch:  446  	Training Loss: 0.02686697617173195
Test Loss:  0.030994104221463203
Valid Loss:  0.03065679222345352
Epoch:  447  	Training Loss: 0.026809347793459892
Test Loss:  0.030917804688215256
Valid Loss:  0.0305780041962862
Epoch:  448  	Training Loss: 0.02675200253725052
Test Loss:  0.030841896310448647
Valid Loss:  0.030499599874019623
Epoch:  449  	Training Loss: 0.02669495716691017
Test Loss:  0.0307663232088089
Valid Loss:  0.030421555042266846
Epoch:  450  	Training Loss: 0.026638202369213104
Test Loss:  0.03069111704826355
Valid Loss:  0.030343884602189064
Epoch:  451  	Training Loss: 0.02658173255622387
Test Loss:  0.03061624802649021
Valid Loss:  0.030266571789979935
Epoch:  452  	Training Loss: 0.02652554027736187
Test Loss:  0.03054271824657917
Valid Loss:  0.03019063174724579
Epoch:  453  	Training Loss: 0.02647034451365471
Test Loss:  0.03046952188014984
Valid Loss:  0.030115054920315742
Epoch:  454  	Training Loss: 0.02641540952026844
Test Loss:  0.03039664216339588
Valid Loss:  0.030039800330996513
Epoch:  455  	Training Loss: 0.026360753923654556
Test Loss:  0.030324097722768784
Valid Loss:  0.029964879155158997
Epoch:  456  	Training Loss: 0.02630634978413582
Test Loss:  0.03025187738239765
Valid Loss:  0.02989029884338379
Epoch:  457  	Training Loss: 0.02625221386551857
Test Loss:  0.030179958790540695
Valid Loss:  0.02981605753302574
Epoch:  458  	Training Loss: 0.026198336854577065
Test Loss:  0.030108392238616943
Valid Loss:  0.029742151498794556
Epoch:  459  	Training Loss: 0.026144729927182198
Test Loss:  0.03003714606165886
Valid Loss:  0.029668571427464485
Epoch:  460  	Training Loss: 0.026091378182172775
Test Loss:  0.029966216534376144
Valid Loss:  0.02959531918168068
Epoch:  461  	Training Loss: 0.026038289070129395
Test Loss:  0.0298956036567688
Valid Loss:  0.029522424563765526
Epoch:  462  	Training Loss: 0.025985464453697205
Test Loss:  0.029823657125234604
Valid Loss:  0.029448093846440315
Epoch:  463  	Training Loss: 0.02593167871236801
Test Loss:  0.029752040281891823
Valid Loss:  0.02937411703169346
Epoch:  464  	Training Loss: 0.025878161191940308
Test Loss:  0.02968074008822441
Valid Loss:  0.02930048294365406
Epoch:  465  	Training Loss: 0.025824911892414093
Test Loss:  0.02960977703332901
Valid Loss:  0.029227180406451225
Epoch:  466  	Training Loss: 0.025771919637918472
Test Loss:  0.029539132490754128
Valid Loss:  0.029154211282730103
Epoch:  467  	Training Loss: 0.02571919560432434
Test Loss:  0.0294688381254673
Valid Loss:  0.029081590473651886
Epoch:  468  	Training Loss: 0.0256667360663414
Test Loss:  0.029398847371339798
Valid Loss:  0.029009297490119934
Epoch:  469  	Training Loss: 0.0256145391613245
Test Loss:  0.02932918630540371
Valid Loss:  0.02893735095858574
Epoch:  470  	Training Loss: 0.025562599301338196
Test Loss:  0.02925986424088478
Valid Loss:  0.028865739703178406
Epoch:  471  	Training Loss: 0.02551092952489853
Test Loss:  0.029190843924880028
Valid Loss:  0.02879444509744644
Epoch:  472  	Training Loss: 0.02545950561761856
Test Loss:  0.02912135049700737
Valid Loss:  0.028722647577524185
Epoch:  473  	Training Loss: 0.02540777251124382
Test Loss:  0.02905217558145523
Valid Loss:  0.028651192784309387
Epoch:  474  	Training Loss: 0.02535630390048027
Test Loss:  0.028983334079384804
Valid Loss:  0.0285800714045763
Epoch:  475  	Training Loss: 0.025305092334747314
Test Loss:  0.028914805501699448
Valid Loss:  0.02850925549864769
Epoch:  476  	Training Loss: 0.025254132226109505
Test Loss:  0.028846584260463715
Valid Loss:  0.028438791632652283
Epoch:  477  	Training Loss: 0.025203431025147438
Test Loss:  0.028778687119483948
Valid Loss:  0.028368648141622543
Epoch:  478  	Training Loss: 0.025152981281280518
Test Loss:  0.028711091727018356
Valid Loss:  0.028298819437623024
Epoch:  479  	Training Loss: 0.025102775543928146
Test Loss:  0.02864382043480873
Valid Loss:  0.028229311108589172
Epoch:  480  	Training Loss: 0.025052819401025772
Test Loss:  0.028576862066984177
Valid Loss:  0.028160126879811287
Epoch:  481  	Training Loss: 0.02500312030315399
Test Loss:  0.028510194271802902
Valid Loss:  0.028091249987483025
Epoch:  482  	Training Loss: 0.024953655898571014
Test Loss:  0.028445258736610413
Valid Loss:  0.028024181723594666
Epoch:  483  	Training Loss: 0.024905461817979813
Test Loss:  0.028380613774061203
Valid Loss:  0.027957413345575333
Epoch:  484  	Training Loss: 0.024857506155967712
Test Loss:  0.02831627056002617
Valid Loss:  0.027890952304005623
Epoch:  485  	Training Loss: 0.024809779599308968
Test Loss:  0.028252217918634415
Valid Loss:  0.027824779972434044
Epoch:  486  	Training Loss: 0.024762291461229324
Test Loss:  0.028188448399305344
Valid Loss:  0.02775890938937664
Epoch:  487  	Training Loss: 0.024715019389986992
Test Loss:  0.028124965727329254
Valid Loss:  0.02769334241747856
Epoch:  488  	Training Loss: 0.02466798946261406
Test Loss:  0.028061779215931892
Valid Loss:  0.02762807160615921
Epoch:  489  	Training Loss: 0.024621181190013885
Test Loss:  0.02799885720014572
Valid Loss:  0.02756308764219284
Epoch:  490  	Training Loss: 0.02457459643483162
Test Loss:  0.02793622761964798
Valid Loss:  0.027498392388224602
Epoch:  491  	Training Loss: 0.02452823892235756
Test Loss:  0.02787388116121292
Valid Loss:  0.027433989569544792
Epoch:  492  	Training Loss: 0.024482104927301407
Test Loss:  0.027811121195554733
Valid Loss:  0.02736916020512581
Epoch:  493  	Training Loss: 0.02443569153547287
Test Loss:  0.02774864435195923
Valid Loss:  0.027304632589221
Epoch:  494  	Training Loss: 0.024389496073126793
Test Loss:  0.027686450630426407
Valid Loss:  0.02724037878215313
Epoch:  495  	Training Loss: 0.024343527853488922
Test Loss:  0.027624547481536865
Valid Loss:  0.02717643417418003
Epoch:  496  	Training Loss: 0.02429778501391411
Test Loss:  0.027562908828258514
Valid Loss:  0.027112774550914764
Epoch:  497  	Training Loss: 0.024252261966466904
Test Loss:  0.027501557022333145
Valid Loss:  0.02704939804971218
Epoch:  498  	Training Loss: 0.024206962436437607
Test Loss:  0.027440477162599564
Valid Loss:  0.026986300945281982
Epoch:  499  	Training Loss: 0.024161873385310173
Test Loss:  0.02737966924905777
Valid Loss:  0.026923485100269318
Epoch:  500  	Training Loss: 0.02411700040102005
Test Loss:  0.027319129556417465
Valid Loss:  0.026860956102609634
seed is  4
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:22,  6.18s/it]  1%|          | 3/500 [00:06<13:42,  1.65s/it]  1%|          | 5/500 [00:06<06:54,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:12<10:35,  1.30s/it]  3%|▎         | 13/500 [00:13<07:14,  1.12it/s]  3%|▎         | 15/500 [00:13<05:03,  1.60it/s]  3%|▎         | 17/500 [00:13<03:36,  2.23it/s]  4%|▍         | 19/500 [00:13<02:38,  3.04it/s]  4%|▍         | 21/500 [00:19<09:29,  1.19s/it]  5%|▍         | 23/500 [00:19<06:44,  1.18it/s]  5%|▌         | 25/500 [00:26<12:12,  1.54s/it]  5%|▌         | 27/500 [00:26<08:38,  1.10s/it]  6%|▌         | 29/500 [00:26<06:09,  1.27it/s]  6%|▌         | 31/500 [00:32<11:43,  1.50s/it]  7%|▋         | 33/500 [00:32<08:19,  1.07s/it]  7%|▋         | 35/500 [00:32<05:59,  1.29it/s]  7%|▋         | 37/500 [00:33<04:20,  1.78it/s]  8%|▊         | 39/500 [00:33<03:10,  2.42it/s]  8%|▊         | 41/500 [00:39<09:29,  1.24s/it]  9%|▊         | 43/500 [00:39<06:46,  1.12it/s]  9%|▉         | 45/500 [00:45<11:47,  1.56s/it]  9%|▉         | 47/500 [00:46<08:23,  1.11s/it] 10%|▉         | 49/500 [00:46<05:59,  1.25it/s] 10%|█         | 51/500 [00:52<11:14,  1.50s/it] 11%|█         | 53/500 [00:52<07:59,  1.07s/it] 11%|█         | 55/500 [00:52<05:42,  1.30it/s] 11%|█▏        | 57/500 [00:52<04:08,  1.79it/s] 12%|█▏        | 59/500 [00:53<03:02,  2.42it/s] 12%|█▏        | 61/500 [00:59<09:00,  1.23s/it] 13%|█▎        | 63/500 [00:59<06:25,  1.13it/s] 13%|█▎        | 65/500 [00:59<04:37,  1.57it/s] 13%|█▎        | 67/500 [00:59<03:21,  2.15it/s] 14%|█▍        | 69/500 [00:59<02:29,  2.88it/s]Epoch:  1  	Training Loss: 0.06784941256046295
Test Loss:  8.158529281616211
Valid Loss:  8.090752601623535
Epoch:  2  	Training Loss: 8.670282363891602
Test Loss:  6.517979621887207
Valid Loss:  6.63758659362793
Epoch:  3  	Training Loss: 5.237337112426758
Test Loss:  1.0546729564666748
Valid Loss:  1.01513671875
Epoch:  4  	Training Loss: 1.283756971359253
Test Loss:  0.6751775741577148
Valid Loss:  0.6277577877044678
Epoch:  5  	Training Loss: 0.8414306640625
Test Loss:  0.6071751117706299
Valid Loss:  0.5581954717636108
Epoch:  6  	Training Loss: 0.8157263398170471
Test Loss:  0.6135112047195435
Valid Loss:  0.5646283626556396
Epoch:  7  	Training Loss: 0.8111478090286255
Test Loss:  0.6094755530357361
Valid Loss:  0.5604782104492188
Epoch:  8  	Training Loss: 0.8082599639892578
Test Loss:  0.6088131666183472
Valid Loss:  0.559687614440918
Epoch:  9  	Training Loss: 0.8056508302688599
Test Loss:  0.6074122786521912
Valid Loss:  0.5581331849098206
Epoch:  10  	Training Loss: 0.8031578063964844
Test Loss:  0.6062459349632263
Valid Loss:  0.5568403005599976
Epoch:  11  	Training Loss: 0.8007846474647522
Test Loss:  0.6050592064857483
Valid Loss:  0.5555866956710815
Epoch:  12  	Training Loss: 0.7985355257987976
Test Loss:  1.3530343770980835
Valid Loss:  1.3788421154022217
Epoch:  13  	Training Loss: 1.1319162845611572
Test Loss:  2.608492851257324
Valid Loss:  2.613382339477539
Epoch:  14  	Training Loss: 2.5799808502197266
Test Loss:  0.4866211414337158
Valid Loss:  0.45928895473480225
Epoch:  15  	Training Loss: 0.6198453903198242
Test Loss:  0.12472692877054214
Valid Loss:  0.112242192029953
Epoch:  16  	Training Loss: 0.17227870225906372
Test Loss:  0.08016078919172287
Valid Loss:  0.07281994819641113
Epoch:  17  	Training Loss: 0.10008566826581955
Test Loss:  0.07837357372045517
Valid Loss:  0.07299485802650452
Epoch:  18  	Training Loss: 0.08819438517093658
Test Loss:  0.08031324297189713
Valid Loss:  0.07571075856685638
Epoch:  19  	Training Loss: 0.08621733635663986
Test Loss:  0.08152835816144943
Valid Loss:  0.0772390067577362
Epoch:  20  	Training Loss: 0.085871621966362
Test Loss:  0.08208155632019043
Valid Loss:  0.07792055606842041
Epoch:  21  	Training Loss: 0.08579413592815399
Test Loss:  0.08230604231357574
Valid Loss:  0.07819877564907074
Epoch:  22  	Training Loss: 0.08576247096061707
Test Loss:  0.12235784530639648
Valid Loss:  0.11559771001338959
Epoch:  23  	Training Loss: 0.1553344875574112
Test Loss:  3.0453484058380127
Valid Loss:  3.0380866527557373
Epoch:  24  	Training Loss: 3.04455828666687
Test Loss:  0.27026796340942383
Valid Loss:  0.26702648401260376
Epoch:  25  	Training Loss: 0.28474363684654236
Test Loss:  0.014872445724904537
Valid Loss:  0.013377838768064976
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.023626457899808884
Test Loss:  0.009179925546050072
Valid Loss:  0.008273480460047722
Epoch:  27  	Training Loss: 0.01528969407081604
Test Loss:  0.007853623479604721
Valid Loss:  0.007554821670055389
Epoch:  28  	Training Loss: 0.012253891676664352
Test Loss:  0.00632505165413022
Valid Loss:  0.00605390127748251
Epoch:  29  	Training Loss: 0.01057211309671402
Test Loss:  0.006247720215469599
Valid Loss:  0.00620456226170063
Epoch:  30  	Training Loss: 0.00977293774485588
Test Loss:  0.005753917619585991
Valid Loss:  0.005723712965846062
Epoch:  31  	Training Loss: 0.00927736796438694
Test Loss:  0.005564392544329166
Valid Loss:  0.005620679818093777
Epoch:  32  	Training Loss: 0.008860478177666664
Test Loss:  0.007333826273679733
Valid Loss:  0.008029896765947342
Epoch:  33  	Training Loss: 0.008908338844776154
Test Loss:  0.005196657031774521
Valid Loss:  0.0052284845151007175
Epoch:  34  	Training Loss: 0.008530719205737114
Test Loss:  0.003233415773138404
Valid Loss:  0.0036741362418979406
Epoch:  35  	Training Loss: 0.004948125220835209
Test Loss:  0.002748119179159403
Valid Loss:  0.0032107289880514145
Epoch:  36  	Training Loss: 0.004247559234499931
Test Loss:  0.002491924911737442
Valid Loss:  0.002993308939039707
Epoch:  37  	Training Loss: 0.003760651219636202
Test Loss:  0.0023004631511867046
Valid Loss:  0.0028329258784651756
Epoch:  38  	Training Loss: 0.0034047896042466164
Test Loss:  0.00215649651363492
Valid Loss:  0.0027180530596524477
Epoch:  39  	Training Loss: 0.0031384776812046766
Test Loss:  0.002042377833276987
Valid Loss:  0.0026297355070710182
Epoch:  40  	Training Loss: 0.002929149894043803
Test Loss:  0.0019495777087286115
Valid Loss:  0.002554783131927252
Epoch:  41  	Training Loss: 0.0027658208273351192
Test Loss:  0.0018802298000082374
Valid Loss:  0.0024926450569182634
Epoch:  42  	Training Loss: 0.002642623148858547
Test Loss:  0.0019904489163309336
Valid Loss:  0.0024875542148947716
Epoch:  43  	Training Loss: 0.0027927090413868427
Test Loss:  0.003515285672619939
Valid Loss:  0.0043212962336838245
Epoch:  44  	Training Loss: 0.004285926930606365
Test Loss:  0.002053503878414631
Valid Loss:  0.0025280823465436697
Epoch:  45  	Training Loss: 0.002953592222183943
Test Loss:  0.0022422000765800476
Valid Loss:  0.002930731512606144
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.002947889268398285
Test Loss:  0.0018132459372282028
Valid Loss:  0.0023911234457045794
Epoch:  47  	Training Loss: 0.002534977626055479
Test Loss:  0.0017466056160628796
Valid Loss:  0.0023671207018196583
Epoch:  48  	Training Loss: 0.0024337698705494404
Test Loss:  0.001735065714456141
Valid Loss:  0.0023481310345232487
Epoch:  49  	Training Loss: 0.0024099063593894243
Test Loss:  0.0017309366958215833
Valid Loss:  0.002343337517231703
Epoch:  50  	Training Loss: 0.0024031740613281727
Test Loss:  0.00172621535602957
Valid Loss:  0.002335764467716217
Epoch:  51  	Training Loss: 0.002398654818534851
Test Loss:  0.0017220760928466916
Valid Loss:  0.0023297653533518314
Epoch:  52  	Training Loss: 0.002394372597336769
Test Loss:  0.0017126998864114285
Valid Loss:  0.002318722428753972
Epoch:  53  	Training Loss: 0.002381294034421444
Test Loss:  0.0017014986369758844
Valid Loss:  0.0023032273165881634
Epoch:  54  	Training Loss: 0.0023629763163626194
Test Loss:  0.0016809265362098813
Valid Loss:  0.0022824625484645367
Epoch:  55  	Training Loss: 0.0023393286392092705
Test Loss:  0.0016544053796678782
Valid Loss:  0.002255997620522976
Epoch:  56  	Training Loss: 0.0023091319017112255
Test Loss:  0.0016287020407617092
Valid Loss:  0.0022286316379904747
Epoch:  57  	Training Loss: 0.002279274631291628
Test Loss:  0.0016152559546753764
Valid Loss:  0.002209906931966543
Epoch:  58  	Training Loss: 0.002258425811305642
Test Loss:  0.001602396834641695
Valid Loss:  0.0021972237154841423
Epoch:  59  	Training Loss: 0.00224179495126009
Test Loss:  0.001588247949257493
Valid Loss:  0.002183145610615611
Epoch:  60  	Training Loss: 0.0022252253256738186
Test Loss:  0.0015769253950566053
Valid Loss:  0.0021721054799854755
Epoch:  61  	Training Loss: 0.0022099013440310955
Test Loss:  0.0015640961937606335
Valid Loss:  0.002159029245376587
Epoch:  62  	Training Loss: 0.0021933887619525194
Test Loss:  0.001546071725897491
Valid Loss:  0.0021408619359135628
Epoch:  63  	Training Loss: 0.0021655617747455835
Test Loss:  0.0015296423807740211
Valid Loss:  0.00212711188942194
Epoch:  64  	Training Loss: 0.00213741697371006
Test Loss:  0.0015117466682568192
Valid Loss:  0.002110942266881466
Epoch:  65  	Training Loss: 0.0021083177998661995
Test Loss:  0.001490522176027298
Valid Loss:  0.0020922941621392965
Epoch:  66  	Training Loss: 0.00207718787714839
Test Loss:  0.0014630529331043363
Valid Loss:  0.0020685491617769003
Epoch:  67  	Training Loss: 0.002038885373622179
Test Loss:  0.0014205069746822119
Valid Loss:  0.002025216817855835
Epoch:  68  	Training Loss: 0.001982409507036209
Test Loss:  0.0013954656897112727
Valid Loss:  0.0019812858663499355
Epoch:  69  	Training Loss: 0.0019213687628507614
Test Loss:  0.0013870641123503447
Valid Loss:  0.0019784849137067795
Epoch:  70  	Training Loss: 0.0019010758260264993
 14%|█▍        | 71/500 [01:06<08:23,  1.17s/it] 15%|█▍        | 73/500 [01:06<06:00,  1.18it/s] 15%|█▌        | 75/500 [01:06<04:21,  1.63it/s] 15%|█▌        | 77/500 [01:06<03:11,  2.21it/s] 16%|█▌        | 79/500 [01:06<02:22,  2.96it/s] 16%|█▌        | 81/500 [01:12<08:08,  1.17s/it] 17%|█▋        | 83/500 [01:13<05:49,  1.19it/s] 17%|█▋        | 85/500 [01:13<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:13<03:03,  2.25it/s] 18%|█▊        | 89/500 [01:13<02:15,  3.03it/s] 18%|█▊        | 91/500 [01:19<08:07,  1.19s/it] 19%|█▊        | 93/500 [01:19<05:48,  1.17it/s] 19%|█▉        | 95/500 [01:20<04:10,  1.62it/s] 19%|█▉        | 97/500 [01:20<03:02,  2.21it/s] 20%|█▉        | 99/500 [01:20<02:15,  2.97it/s] 20%|██        | 101/500 [01:26<07:46,  1.17s/it] 21%|██        | 103/500 [01:26<05:33,  1.19it/s] 21%|██        | 105/500 [01:26<03:59,  1.65it/s] 21%|██▏       | 107/500 [01:26<02:54,  2.25it/s] 22%|██▏       | 109/500 [01:27<02:09,  3.02it/s] 22%|██▏       | 109/500 [01:39<02:09,  3.02it/s] 22%|██▏       | 111/500 [01:39<13:38,  2.11s/it] 23%|██▎       | 113/500 [01:39<09:39,  1.50s/it] 23%|██▎       | 115/500 [01:39<06:51,  1.07s/it] 23%|██▎       | 117/500 [01:40<04:53,  1.30it/s] 24%|██▍       | 119/500 [01:40<03:32,  1.79it/s] 24%|██▍       | 121/500 [01:46<08:27,  1.34s/it] 25%|██▍       | 123/500 [01:46<06:01,  1.04it/s] 25%|██▌       | 125/500 [01:46<04:19,  1.45it/s] 25%|██▌       | 127/500 [01:46<03:07,  1.99it/s] 26%|██▌       | 129/500 [01:47<02:17,  2.69it/s] 26%|██▌       | 131/500 [01:53<07:29,  1.22s/it] 27%|██▋       | 133/500 [01:53<05:20,  1.14it/s] 27%|██▋       | 135/500 [01:53<03:50,  1.58it/s] 27%|██▋       | 137/500 [01:53<02:47,  2.16it/s]Test Loss:  0.001370952115394175
Valid Loss:  0.0019669542089104652
Epoch:  71  	Training Loss: 0.0018845772137865424
Test Loss:  0.0013748505152761936
Valid Loss:  0.0019700434058904648
Epoch:  72  	Training Loss: 0.0018698472995311022
Test Loss:  0.0013160172384232283
Valid Loss:  0.001870213309302926
Epoch:  73  	Training Loss: 0.0018215677700936794
Test Loss:  0.0012986162910237908
Valid Loss:  0.0018447577022016048
Epoch:  74  	Training Loss: 0.0018131679389625788
Test Loss:  0.0012852627551183105
Valid Loss:  0.0018246392719447613
Epoch:  75  	Training Loss: 0.0018065697513520718
Test Loss:  0.0012743020197376609
Valid Loss:  0.0018078571883961558
Epoch:  76  	Training Loss: 0.001801086007617414
Test Loss:  0.0012650584103539586
Valid Loss:  0.0017935719806700945
Epoch:  77  	Training Loss: 0.0017963666468858719
Test Loss:  0.0012571737170219421
Valid Loss:  0.0017812460428103805
Epoch:  78  	Training Loss: 0.0017921710386872292
Test Loss:  0.0012503439793363214
Valid Loss:  0.0017704922938719392
Epoch:  79  	Training Loss: 0.001788353081792593
Test Loss:  0.0012442490551620722
Valid Loss:  0.001760892104357481
Epoch:  80  	Training Loss: 0.0017848459538072348
Test Loss:  0.0012387544848024845
Valid Loss:  0.00175219657830894
Epoch:  81  	Training Loss: 0.0017816147301346064
Test Loss:  0.0012338153319433331
Valid Loss:  0.0017443802207708359
Epoch:  82  	Training Loss: 0.0017785639502108097
Test Loss:  0.0012258377391844988
Valid Loss:  0.001728304661810398
Epoch:  83  	Training Loss: 0.001771498704329133
Test Loss:  0.001222437247633934
Valid Loss:  0.0017299196915701032
Epoch:  84  	Training Loss: 0.001764932181686163
Test Loss:  0.0012166243977844715
Valid Loss:  0.0017204164760187268
Epoch:  85  	Training Loss: 0.0017587186302989721
Test Loss:  0.001212741481140256
Valid Loss:  0.0017185687320306897
Epoch:  86  	Training Loss: 0.0017528240568935871
Test Loss:  0.001207808731123805
Valid Loss:  0.0017119422554969788
Epoch:  87  	Training Loss: 0.001747066038660705
Test Loss:  0.0012037333799526095
Valid Loss:  0.0017086395528167486
Epoch:  88  	Training Loss: 0.0017414586618542671
Test Loss:  0.0011992318322882056
Valid Loss:  0.0017032583709806204
Epoch:  89  	Training Loss: 0.001735907164402306
Test Loss:  0.0011950971093028784
Valid Loss:  0.0016993202734738588
Epoch:  90  	Training Loss: 0.0017304185312241316
Test Loss:  0.0011908087180927396
Valid Loss:  0.0016945275710895658
Epoch:  91  	Training Loss: 0.0017250515520572662
Test Loss:  0.001186722656711936
Valid Loss:  0.0016904366202652454
Epoch:  92  	Training Loss: 0.001719821710139513
Test Loss:  0.0011868954170495272
Valid Loss:  0.0016913461731746793
Epoch:  93  	Training Loss: 0.0017177639529109001
Test Loss:  0.0011869764421135187
Valid Loss:  0.0016910836566239595
Epoch:  94  	Training Loss: 0.001716120634227991
Test Loss:  0.0011872214963659644
Valid Loss:  0.0016914294101297855
Epoch:  95  	Training Loss: 0.001714752521365881
Test Loss:  0.0011875570053234696
Valid Loss:  0.0016918405890464783
Epoch:  96  	Training Loss: 0.001713568577542901
Test Loss:  0.0011879629455506802
Valid Loss:  0.0016922145150601864
Epoch:  97  	Training Loss: 0.001712556928396225
Test Loss:  0.0011882358230650425
Valid Loss:  0.0016923449002206326
Epoch:  98  	Training Loss: 0.0017117175739258528
Test Loss:  0.0011885878629982471
Valid Loss:  0.0016926254611462355
Epoch:  99  	Training Loss: 0.0017109315376728773
Test Loss:  0.001188953872770071
Valid Loss:  0.0016928785480558872
Epoch:  100  	Training Loss: 0.0017101988196372986
Test Loss:  0.0011892925249412656
Valid Loss:  0.001693071681074798
Epoch:  101  	Training Loss: 0.0017095524817705154
Test Loss:  0.0011894450290128589
Valid Loss:  0.001693112775683403
Epoch:  102  	Training Loss: 0.0017089622560888529
Test Loss:  0.0011893778573721647
Valid Loss:  0.0016928059048950672
Epoch:  103  	Training Loss: 0.0017089571338146925
Test Loss:  0.0011893641203641891
Valid Loss:  0.0016927422257140279
Epoch:  104  	Training Loss: 0.0017089564353227615
Test Loss:  0.0011893610935658216
Valid Loss:  0.0016927295364439487
Epoch:  105  	Training Loss: 0.0017089573666453362
Test Loss:  0.0011893609771504998
Valid Loss:  0.0016927262768149376
Epoch:  106  	Training Loss: 0.0017089569009840488
Test Loss:  0.0011893620248883963
Valid Loss:  0.001692726043984294
Epoch:  107  	Training Loss: 0.0017089564353227615
Test Loss:  0.0011893613263964653
Valid Loss:  0.0016927254619076848
Epoch:  108  	Training Loss: 0.0017089570173993707
Test Loss:  0.0011893614428117871
Valid Loss:  0.0016927265096455812
Epoch:  109  	Training Loss: 0.0017089565517380834
Test Loss:  0.0011893610935658216
Valid Loss:  0.0016927251126617193
Epoch:  110  	Training Loss: 0.0017089566681534052
Test Loss:  0.0011893613263964653
Valid Loss:  0.0016927258111536503
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.0017089563189074397
Test Loss:  0.0011782130459323525
Valid Loss:  0.001682940637692809
Epoch:  112  	Training Loss: 0.0016917039174586535
Test Loss:  0.001170279225334525
Valid Loss:  0.001675899955444038
Epoch:  113  	Training Loss: 0.0016787901986390352
Test Loss:  0.0011626222403720021
Valid Loss:  0.0016691437922418118
Epoch:  114  	Training Loss: 0.0016663052374497056
Test Loss:  0.0011552296346053481
Valid Loss:  0.001662643626332283
Epoch:  115  	Training Loss: 0.001654237974435091
Test Loss:  0.0011480915127322078
Valid Loss:  0.0016563921235501766
Epoch:  116  	Training Loss: 0.0016425704816356301
Test Loss:  0.001141199260018766
Valid Loss:  0.0016503804363310337
Epoch:  117  	Training Loss: 0.0016312955413013697
Test Loss:  0.0011345504317432642
Valid Loss:  0.0016445990186184645
Epoch:  118  	Training Loss: 0.0016204004641622305
Test Loss:  0.0011281277984380722
Valid Loss:  0.0016390364617109299
Epoch:  119  	Training Loss: 0.0016098720952868462
Test Loss:  0.001122018089517951
Valid Loss:  0.0016337621491402388
Epoch:  120  	Training Loss: 0.0016000225441530347
Test Loss:  0.0011161167640239
Valid Loss:  0.0016286906320601702
Epoch:  121  	Training Loss: 0.0015904931351542473
Test Loss:  0.0011104097357019782
Valid Loss:  0.0016238015377894044
Epoch:  122  	Training Loss: 0.0015812612837180495
Test Loss:  0.0011033571790903807
Valid Loss:  0.001616557827219367
Epoch:  123  	Training Loss: 0.0015713672619313002
Test Loss:  0.0010953424498438835
Valid Loss:  0.0016081775538623333
Epoch:  124  	Training Loss: 0.0015594585565850139
Test Loss:  0.0010824233759194613
Valid Loss:  0.0015940447337925434
Epoch:  125  	Training Loss: 0.001540278666652739
Test Loss:  0.0010700102429836988
Valid Loss:  0.0015808574389666319
Epoch:  126  	Training Loss: 0.001518296543508768
Test Loss:  0.001056805718690157
Valid Loss:  0.001568150008097291
Epoch:  127  	Training Loss: 0.00149989640340209
Test Loss:  0.0010505986865609884
Valid Loss:  0.0015638007316738367
Epoch:  128  	Training Loss: 0.001487972098402679
Test Loss:  0.001041580457240343
Valid Loss:  0.00155469193123281
Epoch:  129  	Training Loss: 0.0014789883280172944
Test Loss:  0.0010390302632004023
Valid Loss:  0.0015529269585385919
Epoch:  130  	Training Loss: 0.0014710640534758568
Test Loss:  0.001031284686177969
Valid Loss:  0.0015458029229193926
Epoch:  131  	Training Loss: 0.0014642128953710198
Test Loss:  0.0010298320557922125
Valid Loss:  0.0015451175859197974
Epoch:  132  	Training Loss: 0.0014571580104529858
Test Loss:  0.001027562189847231
Valid Loss:  0.0015407332684844732
Epoch:  133  	Training Loss: 0.0014544441364705563
Test Loss:  0.0010256022214889526
Valid Loss:  0.001538346870802343
Epoch:  134  	Training Loss: 0.0014521077973768115
Test Loss:  0.0010237295646220446
Valid Loss:  0.0015363245038315654
Epoch:  135  	Training Loss: 0.0014499312965199351
Test Loss:  0.0010222047567367554
Valid Loss:  0.001534683397039771
Epoch:  136  	Training Loss: 0.001447841408662498
Test Loss:  0.0010202034609392285
Valid Loss:  0.0015327276196330786
Epoch:  137  	Training Loss: 0.001445920206606388
Test Loss:  0.0010190906468778849
Valid Loss:  0.001531307934783399
 28%|██▊       | 139/500 [01:53<02:04,  2.89it/s] 28%|██▊       | 141/500 [02:00<07:06,  1.19s/it] 29%|██▊       | 143/500 [02:00<05:04,  1.17it/s] 29%|██▉       | 145/500 [02:00<03:39,  1.62it/s] 29%|██▉       | 147/500 [02:00<02:40,  2.19it/s] 30%|██▉       | 149/500 [02:00<01:58,  2.96it/s] 30%|███       | 151/500 [02:07<06:54,  1.19s/it] 31%|███       | 153/500 [02:07<04:55,  1.17it/s] 31%|███       | 155/500 [02:07<03:33,  1.61it/s] 31%|███▏      | 157/500 [02:07<02:35,  2.20it/s] 32%|███▏      | 159/500 [02:07<01:55,  2.96it/s] 32%|███▏      | 161/500 [02:14<06:40,  1.18s/it] 33%|███▎      | 163/500 [02:14<04:46,  1.18it/s] 33%|███▎      | 165/500 [02:14<03:25,  1.63it/s] 33%|███▎      | 167/500 [02:14<02:29,  2.22it/s] 34%|███▍      | 169/500 [02:14<01:51,  2.96it/s] 34%|███▍      | 171/500 [02:20<06:32,  1.19s/it] 35%|███▍      | 173/500 [02:21<04:39,  1.17it/s] 35%|███▌      | 175/500 [02:21<03:21,  1.62it/s] 35%|███▌      | 177/500 [02:21<02:26,  2.21it/s] 36%|███▌      | 179/500 [02:21<01:48,  2.96it/s] 36%|███▌      | 181/500 [02:27<06:19,  1.19s/it] 37%|███▋      | 183/500 [02:27<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:28<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:28<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:28<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:34<06:03,  1.18s/it] 39%|███▊      | 193/500 [02:34<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:34<03:06,  1.63it/s] 39%|███▉      | 197/500 [02:35<02:17,  2.20it/s] 40%|███▉      | 199/500 [02:35<01:43,  2.91it/s] 40%|████      | 201/500 [02:41<05:53,  1.18s/it] 41%|████      | 203/500 [02:41<04:12,  1.18it/s] 41%|████      | 205/500 [02:41<03:01,  1.63it/s]Epoch:  138  	Training Loss: 0.0014439441729336977
Test Loss:  0.0010171266039833426
Valid Loss:  0.0015294607728719711
Epoch:  139  	Training Loss: 0.0014420178486034274
Test Loss:  0.0010159311350435019
Valid Loss:  0.001528034801594913
Epoch:  140  	Training Loss: 0.0014401755761355162
Test Loss:  0.0010140268132090569
Valid Loss:  0.0015261978842318058
Epoch:  141  	Training Loss: 0.0014383818488568068
Test Loss:  0.0010130349546670914
Valid Loss:  0.0015249863499775529
Epoch:  142  	Training Loss: 0.0014366417890414596
Test Loss:  0.0010109012946486473
Valid Loss:  0.0015222751535475254
Epoch:  143  	Training Loss: 0.0014356509782373905
Test Loss:  0.001008907100185752
Valid Loss:  0.0015196732711046934
Epoch:  144  	Training Loss: 0.0014347390970215201
Test Loss:  0.001007028971798718
Valid Loss:  0.0015171642880886793
Epoch:  145  	Training Loss: 0.0014338912442326546
Test Loss:  0.001005249097943306
Valid Loss:  0.0015147322556003928
Epoch:  146  	Training Loss: 0.0014330940321087837
Test Loss:  0.0010035487357527018
Valid Loss:  0.0015123696066439152
Epoch:  147  	Training Loss: 0.0014323394279927015
Test Loss:  0.001001920085400343
Valid Loss:  0.0015100676100701094
Epoch:  148  	Training Loss: 0.0014316202141344547
Test Loss:  0.0010003532515838742
Valid Loss:  0.001507819746620953
Epoch:  149  	Training Loss: 0.001430932548828423
Test Loss:  0.0009988417150452733
Valid Loss:  0.0015056254342198372
Epoch:  150  	Training Loss: 0.0014302718918770552
Test Loss:  0.0009973791893571615
Valid Loss:  0.0015034773387014866
Epoch:  151  	Training Loss: 0.0014296366134658456
Test Loss:  0.0009959624148905277
Valid Loss:  0.0015013768570497632
Epoch:  152  	Training Loss: 0.0014290238032117486
Test Loss:  0.000992045272141695
Valid Loss:  0.0014976112870499492
Epoch:  153  	Training Loss: 0.0014243943151086569
Test Loss:  0.0009883271995931864
Valid Loss:  0.001493966206908226
Epoch:  154  	Training Loss: 0.00141988939139992
Test Loss:  0.0009846857283264399
Valid Loss:  0.0014903424307703972
Epoch:  155  	Training Loss: 0.0014154647942632437
Test Loss:  0.0009813000215217471
Valid Loss:  0.001486936118453741
Epoch:  156  	Training Loss: 0.0014111280906945467
Test Loss:  0.0009779445827007294
Valid Loss:  0.0014834757894277573
Epoch:  157  	Training Loss: 0.0014068428426980972
Test Loss:  0.000974612426944077
Valid Loss:  0.001480024540796876
Epoch:  158  	Training Loss: 0.0014026088174432516
Test Loss:  0.0009713135659694672
Valid Loss:  0.0014765923842787743
Epoch:  159  	Training Loss: 0.0013984288088977337
Test Loss:  0.0009681713418103755
Valid Loss:  0.001473236596211791
Epoch:  160  	Training Loss: 0.001394317951053381
Test Loss:  0.0009650698048062623
Valid Loss:  0.0014698870945721865
Epoch:  161  	Training Loss: 0.001390212681144476
Test Loss:  0.0009620158816687763
Valid Loss:  0.0014665820635855198
Epoch:  162  	Training Loss: 0.0013861351180821657
Test Loss:  0.0009586065425537527
Valid Loss:  0.001460876315832138
Epoch:  163  	Training Loss: 0.0013838410377502441
Test Loss:  0.0009554026764817536
Valid Loss:  0.0014559068949893117
Epoch:  164  	Training Loss: 0.0013818491715937853
Test Loss:  0.0009523013141006231
Valid Loss:  0.001451294869184494
Epoch:  165  	Training Loss: 0.0013799734879285097
Test Loss:  0.0009493152610957623
Valid Loss:  0.0014469143934547901
Epoch:  166  	Training Loss: 0.001378196175210178
Test Loss:  0.0009464438771829009
Valid Loss:  0.0014427240239456296
Epoch:  167  	Training Loss: 0.001376512460410595
Test Loss:  0.0009437362896278501
Valid Loss:  0.001438703155145049
Epoch:  168  	Training Loss: 0.0013749694917351007
Test Loss:  0.000941136502660811
Valid Loss:  0.0014348711119964719
Epoch:  169  	Training Loss: 0.0013734784442931414
Test Loss:  0.0009376023663207889
Valid Loss:  0.001428737654350698
Epoch:  170  	Training Loss: 0.0013690793421119452
Test Loss:  0.0009238102938979864
Valid Loss:  0.0014094049111008644
Epoch:  171  	Training Loss: 0.0013451265404000878
Test Loss:  0.0009052968816831708
Valid Loss:  0.001385498559102416
Epoch:  172  	Training Loss: 0.001308994833379984
Test Loss:  0.0008856338681653142
Valid Loss:  0.0013696723617613316
Epoch:  173  	Training Loss: 0.0012899632565677166
Test Loss:  0.0008763584773987532
Valid Loss:  0.0013616173528134823
Epoch:  174  	Training Loss: 0.0012806816957890987
Test Loss:  0.0008697807788848877
Valid Loss:  0.0013549611903727055
Epoch:  175  	Training Loss: 0.0012736100470647216
Test Loss:  0.0008640257874503732
Valid Loss:  0.0013486543903127313
Epoch:  176  	Training Loss: 0.0012671861331909895
Test Loss:  0.0008586397743783891
Valid Loss:  0.0013423962518572807
Epoch:  177  	Training Loss: 0.0012610226403921843
Test Loss:  0.0008534516091458499
Valid Loss:  0.0013362935278564692
Epoch:  178  	Training Loss: 0.0012549851089715958
Test Loss:  0.00084836152382195
Valid Loss:  0.0013302144361659884
Epoch:  179  	Training Loss: 0.001248947810381651
Test Loss:  0.0008434012997895479
Valid Loss:  0.0013242170680314302
Epoch:  180  	Training Loss: 0.0012429936323314905
Test Loss:  0.0008384871762245893
Valid Loss:  0.0013182673137634993
Epoch:  181  	Training Loss: 0.001236909069120884
Test Loss:  0.0008336325408890843
Valid Loss:  0.001312383683398366
Epoch:  182  	Training Loss: 0.0012308401055634022
Test Loss:  0.0008320824708789587
Valid Loss:  0.001309945248067379
Epoch:  183  	Training Loss: 0.0012289667502045631
Test Loss:  0.0008305624360218644
Valid Loss:  0.0013076618779450655
Epoch:  184  	Training Loss: 0.001227138563990593
Test Loss:  0.0008290692348964512
Valid Loss:  0.0013054815353825688
Epoch:  185  	Training Loss: 0.0012253313325345516
Test Loss:  0.0008275904692709446
Valid Loss:  0.0013033640570938587
Epoch:  186  	Training Loss: 0.0012235345784574747
Test Loss:  0.0008261210168711841
Valid Loss:  0.0013012875569984317
Epoch:  187  	Training Loss: 0.001221745042130351
Test Loss:  0.0008246641955338418
Valid Loss:  0.0012992469128221273
Epoch:  188  	Training Loss: 0.0012199808843433857
Test Loss:  0.0008232127875089645
Valid Loss:  0.001297262031584978
Epoch:  189  	Training Loss: 0.001218227669596672
Test Loss:  0.0008217744762077928
Valid Loss:  0.0012953002005815506
Epoch:  190  	Training Loss: 0.001216495642438531
Test Loss:  0.0008203408215194941
Valid Loss:  0.0012933481484651566
Epoch:  191  	Training Loss: 0.0012147788656875491
Test Loss:  0.0008189126383513212
Valid Loss:  0.0012914068065583706
Epoch:  192  	Training Loss: 0.0012130787363275886
Test Loss:  0.0008085872977972031
Valid Loss:  0.0012803553836420178
Epoch:  193  	Training Loss: 0.0012021162547171116
Test Loss:  0.0008027824806049466
Valid Loss:  0.0012752098264172673
Epoch:  194  	Training Loss: 0.0011920566903427243
Test Loss:  0.0007942495285533369
Valid Loss:  0.0012659471249207854
Epoch:  195  	Training Loss: 0.0011817901395261288
Test Loss:  0.0007865324150770903
Valid Loss:  0.0012576216831803322
Epoch:  196  	Training Loss: 0.0011722308117896318
Test Loss:  0.0007813753327354789
Valid Loss:  0.00125290104188025
Epoch:  197  	Training Loss: 0.0011630079243332148
Test Loss:  0.0007738415151834488
Valid Loss:  0.0012446185573935509
Epoch:  198  	Training Loss: 0.0011535778176039457
Test Loss:  0.0007667858153581619
Valid Loss:  0.0012367996387183666
Epoch:  199  	Training Loss: 0.0011446767020970583
Test Loss:  0.0007617006776854396
Valid Loss:  0.0012319637462496758
Epoch:  200  	Training Loss: 0.0011360468342900276
Test Loss:  0.000754769891500473
Valid Loss:  0.0012242961674928665
Epoch:  201  	Training Loss: 0.001127229304984212
Test Loss:  0.0007486444665119052
Valid Loss:  0.0012175650335848331
Epoch:  202  	Training Loss: 0.0011188273783773184
Test Loss:  0.0007478398038074374
Valid Loss:  0.001215444877743721
Epoch:  203  	Training Loss: 0.0011175883701071143
Test Loss:  0.0007451690034940839
Valid Loss:  0.0012109107337892056
Epoch:  204  	Training Loss: 0.0011160534340888262
Test Loss:  0.000742668635211885
Valid Loss:  0.00120675063226372
Epoch:  205  	Training Loss: 0.0011152590159326792
Test Loss:  0.0007429061224684119
Valid Loss:  0.001206441200338304
Epoch:  206  	Training Loss: 0.0011142038274556398
Test Loss:   41%|████▏     | 207/500 [02:41<02:11,  2.22it/s] 42%|████▏     | 209/500 [02:42<01:37,  2.98it/s] 42%|████▏     | 211/500 [02:48<05:40,  1.18s/it] 43%|████▎     | 213/500 [02:48<04:02,  1.18it/s] 43%|████▎     | 215/500 [02:48<02:54,  1.64it/s] 43%|████▎     | 217/500 [02:48<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:48<01:33,  3.00it/s] 44%|████▍     | 221/500 [02:55<05:30,  1.19s/it] 45%|████▍     | 223/500 [02:55<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:55<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:55<02:04,  2.20it/s] 46%|████▌     | 229/500 [02:55<01:31,  2.96it/s] 46%|████▌     | 231/500 [03:02<05:15,  1.17s/it] 47%|████▋     | 233/500 [03:02<03:45,  1.19it/s] 47%|████▋     | 235/500 [03:02<02:41,  1.64it/s] 47%|████▋     | 237/500 [03:02<01:57,  2.24it/s] 48%|████▊     | 239/500 [03:02<01:26,  3.01it/s] 48%|████▊     | 241/500 [03:08<05:03,  1.17s/it] 49%|████▊     | 243/500 [03:09<03:36,  1.19it/s] 49%|████▉     | 245/500 [03:09<02:35,  1.64it/s] 49%|████▉     | 247/500 [03:09<01:52,  2.25it/s] 50%|████▉     | 249/500 [03:09<01:23,  3.01it/s] 50%|█████     | 251/500 [03:15<04:52,  1.18s/it] 51%|█████     | 253/500 [03:15<03:28,  1.18it/s] 51%|█████     | 255/500 [03:15<02:29,  1.64it/s] 51%|█████▏    | 257/500 [03:16<01:49,  2.22it/s] 52%|█████▏    | 259/500 [03:16<01:20,  2.98it/s] 52%|█████▏    | 261/500 [03:22<04:40,  1.17s/it] 53%|█████▎    | 263/500 [03:22<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:22<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:22<01:43,  2.24it/s] 54%|█████▍    | 269/500 [03:23<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:29<04:26,  1.17s/it] 55%|█████▍    | 273/500 [03:29<03:10,  1.19it/s]0.0007402756600640714
Valid Loss:  0.0012022966984659433
Epoch:  207  	Training Loss: 0.001112796482630074
Test Loss:  0.0007379380986094475
Valid Loss:  0.001198502373881638
Epoch:  208  	Training Loss: 0.0011120556155219674
Test Loss:  0.0007382871117442846
Valid Loss:  0.0011985513847321272
Epoch:  209  	Training Loss: 0.0011111617786809802
Test Loss:  0.0007358846487477422
Valid Loss:  0.001194795360788703
Epoch:  210  	Training Loss: 0.0011098799295723438
Test Loss:  0.0007337690913118422
Valid Loss:  0.0011913168709725142
Epoch:  211  	Training Loss: 0.0011090519838035107
Test Loss:  0.0007338298601098359
Valid Loss:  0.0011910531902685761
Epoch:  212  	Training Loss: 0.0011082720011472702
Test Loss:  0.0007319918368011713
Valid Loss:  0.001188289257697761
Epoch:  213  	Training Loss: 0.0011074135545641184
Test Loss:  0.000730450265109539
Valid Loss:  0.001185893313959241
Epoch:  214  	Training Loss: 0.001107031013816595
Test Loss:  0.0007309573702514172
Valid Loss:  0.0011866068234667182
Epoch:  215  	Training Loss: 0.0011065913131460547
Test Loss:  0.0007295480463653803
Valid Loss:  0.0011843519750982523
Epoch:  216  	Training Loss: 0.0011058792006224394
Test Loss:  0.0007282047299668193
Valid Loss:  0.0011822134256362915
Epoch:  217  	Training Loss: 0.0011053336784243584
Test Loss:  0.0007284338935278356
Valid Loss:  0.0011825021356344223
Epoch:  218  	Training Loss: 0.0011050216853618622
Test Loss:  0.0007271277718245983
Valid Loss:  0.0011804148089140654
Epoch:  219  	Training Loss: 0.001104382099583745
Test Loss:  0.0007259708363562822
Valid Loss:  0.001178524922579527
Epoch:  220  	Training Loss: 0.001103846589103341
Test Loss:  0.0007256007520481944
Valid Loss:  0.0011778661282733083
Epoch:  221  	Training Loss: 0.0011034091003239155
Test Loss:  0.0007245328743010759
Valid Loss:  0.0011761031346395612
Epoch:  222  	Training Loss: 0.0011029356392100453
Test Loss:  0.0007239620899781585
Valid Loss:  0.0011748599354177713
Epoch:  223  	Training Loss: 0.0011025378480553627
Test Loss:  0.000723465986084193
Valid Loss:  0.001173809403553605
Epoch:  224  	Training Loss: 0.0011022282997146249
Test Loss:  0.0007230128394439816
Valid Loss:  0.0011728908866643906
Epoch:  225  	Training Loss: 0.001101969974115491
Test Loss:  0.0007225858280435205
Valid Loss:  0.0011720632901415229
Epoch:  226  	Training Loss: 0.0011017386568710208
Test Loss:  0.0007221715059131384
Valid Loss:  0.001171295065432787
Epoch:  227  	Training Loss: 0.0011015234049409628
Test Loss:  0.0007217697566375136
Valid Loss:  0.0011705777142196894
Epoch:  228  	Training Loss: 0.0011013185139745474
Test Loss:  0.0007213760982267559
Valid Loss:  0.0011698950547724962
Epoch:  229  	Training Loss: 0.001101119676604867
Test Loss:  0.0007209880277514458
Valid Loss:  0.001169239287264645
Epoch:  230  	Training Loss: 0.001100926543585956
Test Loss:  0.0007206075824797153
Valid Loss:  0.0011686086654663086
Epoch:  231  	Training Loss: 0.0011007371358573437
Test Loss:  0.0007202333072200418
Valid Loss:  0.0011679967865347862
Epoch:  232  	Training Loss: 0.0011005513370037079
Test Loss:  0.0007198828971013427
Valid Loss:  0.0011676084250211716
Epoch:  233  	Training Loss: 0.0010998246725648642
Test Loss:  0.0007195434300228953
Valid Loss:  0.0011672449763864279
Epoch:  234  	Training Loss: 0.001099113142117858
Test Loss:  0.0007192090270109475
Valid Loss:  0.0011669003870338202
Epoch:  235  	Training Loss: 0.0010984048712998629
Test Loss:  0.0007188773015514016
Valid Loss:  0.0011665674392133951
Epoch:  236  	Training Loss: 0.0010977003257721663
Test Loss:  0.0007185492431744933
Valid Loss:  0.001166243921034038
Epoch:  237  	Training Loss: 0.0010969997383654118
Test Loss:  0.0007182232802733779
Valid Loss:  0.0011659299489110708
Epoch:  238  	Training Loss: 0.0010963021777570248
Test Loss:  0.0007179009262472391
Valid Loss:  0.0011656202841550112
Epoch:  239  	Training Loss: 0.0010956148616969585
Test Loss:  0.0007175830542109907
Valid Loss:  0.0011653206311166286
Epoch:  240  	Training Loss: 0.0010949429124593735
Test Loss:  0.0007172687328420579
Valid Loss:  0.0011650247033685446
Epoch:  241  	Training Loss: 0.001094273990020156
Test Loss:  0.0007169565069489181
Valid Loss:  0.0011647283099591732
Epoch:  242  	Training Loss: 0.0010936076287180185
Test Loss:  0.0007169503951445222
Valid Loss:  0.0011650527594611049
Epoch:  243  	Training Loss: 0.0010930511634796858
Test Loss:  0.000715574948117137
Valid Loss:  0.0011632114183157682
Epoch:  244  	Training Loss: 0.0010921298526227474
Test Loss:  0.0007144723203964531
Valid Loss:  0.0011616423726081848
Epoch:  245  	Training Loss: 0.0010915773455053568
Test Loss:  0.0007151714526116848
Valid Loss:  0.001162780448794365
Epoch:  246  	Training Loss: 0.00109108944889158
Test Loss:  0.000714014342520386
Valid Loss:  0.0011610776418820024
Epoch:  247  	Training Loss: 0.0010902867652475834
Test Loss:  0.0007130356971174479
Valid Loss:  0.001159562380053103
Epoch:  248  	Training Loss: 0.001089557190425694
Test Loss:  0.000712744367774576
Valid Loss:  0.0011590694775804877
Epoch:  249  	Training Loss: 0.0010890166740864515
Test Loss:  0.0007118370849639177
Valid Loss:  0.001157615683041513
Epoch:  250  	Training Loss: 0.001088420976884663
Test Loss:  0.0007123928517103195
Valid Loss:  0.0011584474705159664
Epoch:  251  	Training Loss: 0.001088020857423544
Test Loss:  0.0007112340535968542
Valid Loss:  0.0011566763278096914
Epoch:  252  	Training Loss: 0.0010872858110815287
Test Loss:  0.0007103597745299339
Valid Loss:  0.0011557384859770536
Epoch:  253  	Training Loss: 0.0010862482013180852
Test Loss:  0.0007096050539985299
Valid Loss:  0.0011548418551683426
Epoch:  254  	Training Loss: 0.0010852746199816465
Test Loss:  0.0007089258870109916
Valid Loss:  0.0011539570987224579
Epoch:  255  	Training Loss: 0.001084380317479372
Test Loss:  0.0007082897936925292
Valid Loss:  0.0011530742049217224
Epoch:  256  	Training Loss: 0.0010835264110937715
Test Loss:  0.0007076718611642718
Valid Loss:  0.0011521215783432126
Epoch:  257  	Training Loss: 0.0010827475925907493
Test Loss:  0.000707093917299062
Valid Loss:  0.0011511725606396794
Epoch:  258  	Training Loss: 0.0010819798335433006
Test Loss:  0.0007065363461151719
Valid Loss:  0.0011502255219966173
Epoch:  259  	Training Loss: 0.001081216149032116
Test Loss:  0.0007059951312839985
Valid Loss:  0.0011492917547002435
Epoch:  260  	Training Loss: 0.0010804617777466774
Test Loss:  0.0007054503657855093
Valid Loss:  0.0011483390117064118
Epoch:  261  	Training Loss: 0.0010797494323924184
Test Loss:  0.0007048861589282751
Valid Loss:  0.0011473640333861113
Epoch:  262  	Training Loss: 0.0010790496598929167
Test Loss:  0.0007035654271021485
Valid Loss:  0.0011443919502198696
Epoch:  263  	Training Loss: 0.0010777658317238092
Test Loss:  0.0007025214727036655
Valid Loss:  0.0011424317490309477
Epoch:  264  	Training Loss: 0.0010768006322905421
Test Loss:  0.0007015238516032696
Valid Loss:  0.0011407936690375209
Epoch:  265  	Training Loss: 0.0010758829303085804
Test Loss:  0.0007005499210208654
Valid Loss:  0.0011392788728699088
Epoch:  266  	Training Loss: 0.00107498187571764
Test Loss:  0.0006996009033173323
Valid Loss:  0.0011378333438187838
Epoch:  267  	Training Loss: 0.0010740954894572496
Test Loss:  0.0006986779626458883
Valid Loss:  0.001136438688263297
Epoch:  268  	Training Loss: 0.0010732340160757303
Test Loss:  0.0006977762677706778
Valid Loss:  0.001135083264671266
Epoch:  269  	Training Loss: 0.0010723834857344627
Test Loss:  0.000696893606800586
Valid Loss:  0.0011337636969983578
Epoch:  270  	Training Loss: 0.001071541802957654
Test Loss:  0.0006960330647416413
Valid Loss:  0.0011324784718453884
Epoch:  271  	Training Loss: 0.001070710364729166
Test Loss:  0.0006951909745112062
Valid Loss:  0.0011312260758131742
Epoch:  272  	Training Loss: 0.001069885678589344
Test Loss:  0.0006925432244315743
Valid Loss:  0.0011287006782367826
Epoch:  273  	Training Loss: 0.0010651291813701391
Test Loss:  0.0006898295250721276
Valid Loss:  0.0011258692247793078
Epoch:  274  	Training Loss: 0.0010605019051581621
Test Loss:  0.0006872862577438354
Valid Loss:  0.0011231433600187302
 55%|█████▌    | 275/500 [03:29<02:16,  1.65it/s] 55%|█████▌    | 277/500 [03:29<01:39,  2.25it/s] 56%|█████▌    | 279/500 [03:29<01:13,  3.02it/s] 56%|█████▌    | 281/500 [03:36<04:18,  1.18s/it] 57%|█████▋    | 283/500 [03:36<03:04,  1.18it/s] 57%|█████▋    | 285/500 [03:36<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:36<01:36,  2.22it/s] 58%|█████▊    | 289/500 [03:36<01:11,  2.95it/s] 58%|█████▊    | 291/500 [03:43<04:09,  1.19s/it] 59%|█████▊    | 293/500 [03:43<02:57,  1.17it/s] 59%|█████▉    | 295/500 [03:43<02:07,  1.61it/s] 59%|█████▉    | 297/500 [03:43<01:31,  2.21it/s] 60%|█████▉    | 299/500 [03:43<01:07,  2.96it/s] 60%|██████    | 301/500 [03:49<03:52,  1.17s/it] 61%|██████    | 303/500 [03:50<02:45,  1.19it/s] 61%|██████    | 305/500 [03:50<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:50<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:50<01:03,  3.02it/s] 62%|██████▏   | 311/500 [03:56<03:42,  1.18s/it] 63%|██████▎   | 313/500 [03:56<02:37,  1.18it/s] 63%|██████▎   | 315/500 [03:56<01:53,  1.64it/s] 63%|██████▎   | 317/500 [03:57<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:57<01:00,  3.01it/s] 64%|██████▍   | 321/500 [04:03<03:28,  1.17s/it] 65%|██████▍   | 323/500 [04:03<02:28,  1.19it/s] 65%|██████▌   | 325/500 [04:03<01:46,  1.65it/s] 65%|██████▌   | 327/500 [04:03<01:16,  2.25it/s] 66%|██████▌   | 329/500 [04:04<00:56,  3.03it/s] 66%|██████▌   | 331/500 [04:10<03:16,  1.16s/it] 67%|██████▋   | 333/500 [04:10<02:19,  1.20it/s] 67%|██████▋   | 335/500 [04:10<01:39,  1.65it/s] 67%|██████▋   | 337/500 [04:10<01:12,  2.25it/s] 68%|██████▊   | 339/500 [04:10<00:53,  3.03it/s] 68%|██████▊   | 341/500 [04:16<03:04,  1.16s/it]Epoch:  275  	Training Loss: 0.0010559281799942255
Test Loss:  0.0006846952019259334
Valid Loss:  0.0011202860623598099
Epoch:  276  	Training Loss: 0.0010513616725802422
Test Loss:  0.0006821092683821917
Valid Loss:  0.0011173868551850319
Epoch:  277  	Training Loss: 0.0010468157706782222
Test Loss:  0.0006796052912250161
Valid Loss:  0.0011145907919853926
Epoch:  278  	Training Loss: 0.0010423408821225166
Test Loss:  0.0006769959582015872
Valid Loss:  0.0011116128880530596
Epoch:  279  	Training Loss: 0.0010378648294135928
Test Loss:  0.0006745134596712887
Valid Loss:  0.0011087876046076417
Epoch:  280  	Training Loss: 0.0010333992540836334
Test Loss:  0.0006719324737787247
Valid Loss:  0.0011057655792683363
Epoch:  281  	Training Loss: 0.001028979429975152
Test Loss:  0.0006696053314954042
Valid Loss:  0.0011030957102775574
Epoch:  282  	Training Loss: 0.0010246388847008348
Test Loss:  0.0006677680648863316
Valid Loss:  0.0011005040723830462
Epoch:  283  	Training Loss: 0.0010228818282485008
Test Loss:  0.0006661658408120275
Valid Loss:  0.001098096719942987
Epoch:  284  	Training Loss: 0.0010212290799245238
Test Loss:  0.0006646753172390163
Valid Loss:  0.0010957762133330107
Epoch:  285  	Training Loss: 0.0010196631774306297
Test Loss:  0.0006632624426856637
Valid Loss:  0.0010935446480289102
Epoch:  286  	Training Loss: 0.001018135342746973
Test Loss:  0.0006619134801439941
Valid Loss:  0.0010913785081356764
Epoch:  287  	Training Loss: 0.0010166466236114502
Test Loss:  0.0006606108509004116
Valid Loss:  0.0010892691789194942
Epoch:  288  	Training Loss: 0.0010152059840038419
Test Loss:  0.0006593335419893265
Valid Loss:  0.0010872120037674904
Epoch:  289  	Training Loss: 0.0010137723293155432
Test Loss:  0.0006580891786143184
Valid Loss:  0.0010852119885385036
Epoch:  290  	Training Loss: 0.0010123460087925196
Test Loss:  0.0006568989483639598
Valid Loss:  0.0010832470143213868
Epoch:  291  	Training Loss: 0.0010109290014952421
Test Loss:  0.0006557260057888925
Valid Loss:  0.0010813171975314617
Epoch:  292  	Training Loss: 0.0010095257312059402
Test Loss:  0.0006533821579068899
Valid Loss:  0.0010793835390359163
Epoch:  293  	Training Loss: 0.001005497295409441
Test Loss:  0.000651060719974339
Valid Loss:  0.0010774119291454554
Epoch:  294  	Training Loss: 0.0010015538427978754
Test Loss:  0.0006487683858722448
Valid Loss:  0.0010754117975011468
Epoch:  295  	Training Loss: 0.0009976985165849328
Test Loss:  0.0006465013138949871
Valid Loss:  0.0010733924573287368
Epoch:  296  	Training Loss: 0.000993929454125464
Test Loss:  0.0006442702724598348
Valid Loss:  0.0010713768424466252
Epoch:  297  	Training Loss: 0.0009902489837259054
Test Loss:  0.0006421075668185949
Valid Loss:  0.001069371704943478
Epoch:  298  	Training Loss: 0.0009866690961644053
Test Loss:  0.0006399708217941225
Valid Loss:  0.0010673702927306294
Epoch:  299  	Training Loss: 0.0009831704664975405
Test Loss:  0.0006378745893016458
Valid Loss:  0.0010653813369572163
Epoch:  300  	Training Loss: 0.000979738892056048
Test Loss:  0.0006358313839882612
Valid Loss:  0.0010634148493409157
Epoch:  301  	Training Loss: 0.000976377516053617
Test Loss:  0.0006338342791423202
Valid Loss:  0.001061482704244554
Epoch:  302  	Training Loss: 0.0009730962920002639
Test Loss:  0.0006331983022391796
Valid Loss:  0.0010601951507851481
Epoch:  303  	Training Loss: 0.0009724862757138908
Test Loss:  0.0006325677968561649
Valid Loss:  0.0010589691810309887
Epoch:  304  	Training Loss: 0.000971904955804348
Test Loss:  0.0006320442189462483
Valid Loss:  0.0010579435620456934
Epoch:  305  	Training Loss: 0.0009713303879834712
Test Loss:  0.0006314180791378021
Valid Loss:  0.0010567795252427459
Epoch:  306  	Training Loss: 0.0009707671124488115
Test Loss:  0.0006309007294476032
Valid Loss:  0.0010558073408901691
Epoch:  307  	Training Loss: 0.000970195047557354
Test Loss:  0.0006303366972133517
Valid Loss:  0.001054768217727542
Epoch:  308  	Training Loss: 0.0009696347406134009
Test Loss:  0.0006297800573520362
Valid Loss:  0.0010537493508309126
Epoch:  309  	Training Loss: 0.0009690782171674073
Test Loss:  0.000629281101282686
Valid Loss:  0.0010528266429901123
Epoch:  310  	Training Loss: 0.0009685297263786197
Test Loss:  0.000628684414550662
Valid Loss:  0.0010517546907067299
Epoch:  311  	Training Loss: 0.0009679754730314016
Test Loss:  0.0006281979731284082
Valid Loss:  0.0010508585255593061
Epoch:  312  	Training Loss: 0.0009674387983977795
Test Loss:  0.0006034016842022538
Valid Loss:  0.001027315971441567
Epoch:  313  	Training Loss: 0.0009250579169020057
Test Loss:  0.0005963078001514077
Valid Loss:  0.0010215669171884656
Epoch:  314  	Training Loss: 0.0009088378865271807
Test Loss:  0.0005931889754720032
Valid Loss:  0.0010185625869780779
Epoch:  315  	Training Loss: 0.0009007791522890329
Test Loss:  0.0005905652651563287
Valid Loss:  0.001015199115499854
Epoch:  316  	Training Loss: 0.0008950995979830623
Test Loss:  0.0005877088406123221
Valid Loss:  0.0010119822109118104
Epoch:  317  	Training Loss: 0.0008901595720089972
Test Loss:  0.0005849308799952269
Valid Loss:  0.0010087083792313933
Epoch:  318  	Training Loss: 0.0008854953921400011
Test Loss:  0.0005818929057568312
Valid Loss:  0.001005307538434863
Epoch:  319  	Training Loss: 0.0008811425068415701
Test Loss:  0.0005789912538602948
Valid Loss:  0.0010022062342613935
Epoch:  320  	Training Loss: 0.0008769254782237113
Test Loss:  0.0005763371009379625
Valid Loss:  0.0009993250714614987
Epoch:  321  	Training Loss: 0.0008728557731956244
Test Loss:  0.0005736709572374821
Valid Loss:  0.000996380695141852
Epoch:  322  	Training Loss: 0.0008690011454746127
Test Loss:  0.0005732179852202535
Valid Loss:  0.0009965630015358329
Epoch:  323  	Training Loss: 0.0008676830912008882
Test Loss:  0.0005732652498409152
Valid Loss:  0.0009969072416424751
Epoch:  324  	Training Loss: 0.0008667962392792106
Test Loss:  0.0005731582641601562
Valid Loss:  0.0009971129475161433
Epoch:  325  	Training Loss: 0.0008661353494971991
Test Loss:  0.0005730434786528349
Valid Loss:  0.000997308292426169
Epoch:  326  	Training Loss: 0.0008656045538373291
Test Loss:  0.0005730377743020654
Valid Loss:  0.0009975642897188663
Epoch:  327  	Training Loss: 0.0008651488460600376
Test Loss:  0.000573105295188725
Valid Loss:  0.000997842289507389
Epoch:  328  	Training Loss: 0.0008647408103570342
Test Loss:  0.0005732148420065641
Valid Loss:  0.0009981237817555666
Epoch:  329  	Training Loss: 0.0008643747423775494
Test Loss:  0.0005733163561671972
Valid Loss:  0.0009983968921005726
Epoch:  330  	Training Loss: 0.0008640464511699975
Test Loss:  0.000573275494389236
Valid Loss:  0.000998536474071443
Epoch:  331  	Training Loss: 0.0008637619903311133
Test Loss:  0.0005732706049457192
Valid Loss:  0.000998706673271954
Epoch:  332  	Training Loss: 0.0008635041303932667
Test Loss:  0.0005709772813133895
Valid Loss:  0.0009963364573195577
Epoch:  333  	Training Loss: 0.0008621492888778448
Test Loss:  0.0005691200494766235
Valid Loss:  0.0009942138567566872
Epoch:  334  	Training Loss: 0.0008610598742961884
Test Loss:  0.0005675143329426646
Valid Loss:  0.0009922226890921593
Epoch:  335  	Training Loss: 0.0008601063163951039
Test Loss:  0.0005660682218149304
Valid Loss:  0.0009903053287416697
Epoch:  336  	Training Loss: 0.0008592415833845735
Test Loss:  0.0005647079669870436
Valid Loss:  0.0009884770261123776
Epoch:  337  	Training Loss: 0.000858438084833324
Test Loss:  0.0005634381086565554
Valid Loss:  0.0009866920299828053
Epoch:  338  	Training Loss: 0.0008576744003221393
Test Loss:  0.0005622331518679857
Valid Loss:  0.00098494254052639
Epoch:  339  	Training Loss: 0.000856938655488193
Test Loss:  0.0005610792431980371
Valid Loss:  0.0009832225041463971
Epoch:  340  	Training Loss: 0.0008562254952266812
Test Loss:  0.0005599632859230042
Valid Loss:  0.000981527497060597
Epoch:  341  	Training Loss: 0.000855535501614213
Test Loss:  0.000558882427867502
Valid Loss:  0.0009798640385270119
Epoch:  342  	Training Loss: 0.0008548622718080878
Test Loss:  0.0005553480586968362
Valid Loss:  0.0009745883289724588
Epoch:  343  	Training Loss: 0.0008523577125743032
Test Loss:   69%|██████▊   | 343/500 [04:17<02:10,  1.20it/s] 69%|██████▉   | 345/500 [04:17<01:33,  1.66it/s] 69%|██████▉   | 347/500 [04:17<01:07,  2.27it/s] 70%|██████▉   | 349/500 [04:17<00:49,  3.04it/s] 70%|███████   | 351/500 [04:23<02:53,  1.16s/it] 71%|███████   | 353/500 [04:23<02:02,  1.20it/s] 71%|███████   | 355/500 [04:23<01:27,  1.65it/s] 71%|███████▏  | 357/500 [04:24<01:03,  2.26it/s] 72%|███████▏  | 359/500 [04:24<00:46,  3.04it/s] 72%|███████▏  | 361/500 [04:30<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:30<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:30<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:30<00:59,  2.23it/s] 74%|███████▍  | 369/500 [04:31<00:43,  3.00it/s] 74%|███████▍  | 371/500 [04:37<02:30,  1.17s/it] 75%|███████▍  | 373/500 [04:37<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:37<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:37<00:55,  2.22it/s] 76%|███████▌  | 379/500 [04:37<00:40,  2.98it/s] 76%|███████▌  | 381/500 [04:44<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:44<01:39,  1.17it/s] 77%|███████▋  | 385/500 [04:44<01:11,  1.62it/s] 77%|███████▋  | 387/500 [04:44<00:51,  2.21it/s] 78%|███████▊  | 389/500 [04:44<00:37,  2.97it/s] 78%|███████▊  | 391/500 [04:51<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:51<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:51<01:04,  1.64it/s] 79%|███████▉  | 397/500 [04:51<00:46,  2.21it/s] 80%|███████▉  | 399/500 [04:51<00:34,  2.95it/s] 80%|████████  | 401/500 [04:57<01:57,  1.18s/it] 81%|████████  | 403/500 [04:58<01:22,  1.18it/s] 81%|████████  | 405/500 [04:58<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:58<00:41,  2.22it/s] 82%|████████▏ | 409/500 [04:58<00:30,  2.99it/s]0.0005521384300664067
Valid Loss:  0.0009695673943497241
Epoch:  344  	Training Loss: 0.0008500694530084729
Test Loss:  0.0005492228083312511
Valid Loss:  0.0009648303966969252
Epoch:  345  	Training Loss: 0.0008479095413349569
Test Loss:  0.0005465510184876621
Valid Loss:  0.0009603479411453009
Epoch:  346  	Training Loss: 0.0008458612719550729
Test Loss:  0.0005440034437924623
Valid Loss:  0.0009560605976730585
Epoch:  347  	Training Loss: 0.0008439322700724006
Test Loss:  0.0005416384665295482
Valid Loss:  0.0009519789600744843
Epoch:  348  	Training Loss: 0.0008420813828706741
Test Loss:  0.0005394316394813359
Valid Loss:  0.0009480943554081023
Epoch:  349  	Training Loss: 0.0008403030224144459
Test Loss:  0.0005373279564082623
Valid Loss:  0.0009443792514503002
Epoch:  350  	Training Loss: 0.0008386202389374375
Test Loss:  0.0005352742737159133
Valid Loss:  0.0009408134501427412
Epoch:  351  	Training Loss: 0.0008370199939236045
Test Loss:  0.0005333543522283435
Valid Loss:  0.0009374095243401825
Epoch:  352  	Training Loss: 0.0008354737656190991
Test Loss:  0.0005315054440870881
Valid Loss:  0.0009344519930891693
Epoch:  353  	Training Loss: 0.0008342337096109986
Test Loss:  0.0005298968171700835
Valid Loss:  0.0009317590156570077
Epoch:  354  	Training Loss: 0.0008330934215337038
Test Loss:  0.0005284532671794295
Valid Loss:  0.0009292452596127987
Epoch:  355  	Training Loss: 0.0008320301421917975
Test Loss:  0.0005270821857266128
Valid Loss:  0.0009268515859730542
Epoch:  356  	Training Loss: 0.0008310404373332858
Test Loss:  0.0005257426528260112
Valid Loss:  0.000924563966691494
Epoch:  357  	Training Loss: 0.0008301005000248551
Test Loss:  0.0005245109787210822
Valid Loss:  0.0009223967790603638
Epoch:  358  	Training Loss: 0.0008292007260024548
Test Loss:  0.000523323193192482
Valid Loss:  0.000920322781894356
Epoch:  359  	Training Loss: 0.0008283343631774187
Test Loss:  0.0005222143372520804
Valid Loss:  0.0009183434885926545
Epoch:  360  	Training Loss: 0.0008274990832433105
Test Loss:  0.0005211743409745395
Valid Loss:  0.0009164477232843637
Epoch:  361  	Training Loss: 0.0008266880759038031
Test Loss:  0.0005201936583034694
Valid Loss:  0.0009146358352154493
Epoch:  362  	Training Loss: 0.0008259003516286612
Test Loss:  0.00051801314111799
Valid Loss:  0.000912370509468019
Epoch:  363  	Training Loss: 0.0008212404791265726
Test Loss:  0.0005158861167728901
Valid Loss:  0.0009100981988012791
Epoch:  364  	Training Loss: 0.0008167292689904571
Test Loss:  0.0005137721891514957
Valid Loss:  0.0009078155853785574
Epoch:  365  	Training Loss: 0.0008123250445351005
Test Loss:  0.0005122256698086858
Valid Loss:  0.0009064037003554404
Epoch:  366  	Training Loss: 0.0008081288542598486
Test Loss:  0.0005102614522911608
Valid Loss:  0.0009040669538080692
Epoch:  367  	Training Loss: 0.0008040826651267707
Test Loss:  0.0005094973603263497
Valid Loss:  0.0009034713148139417
Epoch:  368  	Training Loss: 0.0008001691312529147
Test Loss:  0.0005074897198937833
Valid Loss:  0.0009009592467918992
Epoch:  369  	Training Loss: 0.0007961558876559138
Test Loss:  0.0005060917465016246
Valid Loss:  0.0008993998635560274
Epoch:  370  	Training Loss: 0.0007923903176560998
Test Loss:  0.0005040862015448511
Valid Loss:  0.0008968542097136378
Epoch:  371  	Training Loss: 0.0007888888940215111
Test Loss:  0.0005036411457695067
Valid Loss:  0.0008967146277427673
Epoch:  372  	Training Loss: 0.0007852773414924741
Test Loss:  0.0004951950395479798
Valid Loss:  0.0008839487563818693
Epoch:  373  	Training Loss: 0.0007778938743285835
Test Loss:  0.0004883153596892953
Valid Loss:  0.0008735561277717352
Epoch:  374  	Training Loss: 0.0007717296830378473
Test Loss:  0.0004830472753383219
Valid Loss:  0.0008650493109598756
Epoch:  375  	Training Loss: 0.0007666282472200692
Test Loss:  0.0004789465747307986
Valid Loss:  0.0008580329595133662
Epoch:  376  	Training Loss: 0.000762236479204148
Test Loss:  0.0004755570844281465
Valid Loss:  0.0008522496791556478
Epoch:  377  	Training Loss: 0.0007582658436149359
Test Loss:  0.000472608080599457
Valid Loss:  0.0008472214685752988
Epoch:  378  	Training Loss: 0.0007546079577878118
Test Loss:  0.0004700573335867375
Valid Loss:  0.0008427917491644621
Epoch:  379  	Training Loss: 0.0007513080490753055
Test Loss:  0.0004679511475842446
Valid Loss:  0.0008389481226913631
Epoch:  380  	Training Loss: 0.0007483195513486862
Test Loss:  0.000466036144644022
Valid Loss:  0.0008354521705769002
Epoch:  381  	Training Loss: 0.0007454637088812888
Test Loss:  0.0004642664280254394
Valid Loss:  0.0008322825888171792
Epoch:  382  	Training Loss: 0.0007427636301144958
Test Loss:  0.0004574849153868854
Valid Loss:  0.0008228165097534657
Epoch:  383  	Training Loss: 0.0007318620919249952
Test Loss:  0.0004551164456643164
Valid Loss:  0.000819048669654876
Epoch:  384  	Training Loss: 0.000725847901776433
Test Loss:  0.000453409506008029
Valid Loss:  0.0008167928317561746
Epoch:  385  	Training Loss: 0.0007216986268758774
Test Loss:  0.0004525854019448161
Valid Loss:  0.0008148698834702373
Epoch:  386  	Training Loss: 0.0007185628055594862
Test Loss:  0.0004520775401033461
Valid Loss:  0.0008129669586196542
Epoch:  387  	Training Loss: 0.0007162896217778325
Test Loss:  0.00045163132017478347
Valid Loss:  0.0008110658964142203
Epoch:  388  	Training Loss: 0.0007144533446989954
Test Loss:  0.00045105264871381223
Valid Loss:  0.0008091629715636373
Epoch:  389  	Training Loss: 0.0007130028679966927
Test Loss:  0.0004504225216805935
Valid Loss:  0.0008073828648775816
Epoch:  390  	Training Loss: 0.000711719156242907
Test Loss:  0.00044973695185035467
Valid Loss:  0.0008057633531279862
Epoch:  391  	Training Loss: 0.000710571650415659
Test Loss:  0.00044891959987580776
Valid Loss:  0.0008041214896366
Epoch:  392  	Training Loss: 0.0007096280460245907
Test Loss:  0.0004485031822696328
Valid Loss:  0.0008036020444706082
Epoch:  393  	Training Loss: 0.00070911122020334
Test Loss:  0.0004481291980482638
Valid Loss:  0.0008030030876398087
Epoch:  394  	Training Loss: 0.0007086222758516669
Test Loss:  0.0004477702605072409
Valid Loss:  0.0008023595437407494
Epoch:  395  	Training Loss: 0.0007081529474817216
Test Loss:  0.0004474189772736281
Valid Loss:  0.0008017022628337145
Epoch:  396  	Training Loss: 0.0007076872861944139
Test Loss:  0.0004470701969694346
Valid Loss:  0.0008010439341887832
Epoch:  397  	Training Loss: 0.0007072244770824909
Test Loss:  0.0004467233084142208
Valid Loss:  0.0008003857801668346
Epoch:  398  	Training Loss: 0.0007067611441016197
Test Loss:  0.0004463813384063542
Valid Loss:  0.0007997308275662363
Epoch:  399  	Training Loss: 0.0007062996155582368
Test Loss:  0.0004460404743440449
Valid Loss:  0.0007990796002559364
Epoch:  400  	Training Loss: 0.0007058405899442732
Test Loss:  0.000445702753495425
Valid Loss:  0.0007984313415363431
Epoch:  401  	Training Loss: 0.0007053848821669817
Test Loss:  0.0004453676810953766
Valid Loss:  0.0007977882050909102
Epoch:  402  	Training Loss: 0.0007049342384561896
Test Loss:  0.00044480818905867636
Valid Loss:  0.0007970754522830248
Epoch:  403  	Training Loss: 0.0007042856886982918
Test Loss:  0.00044426650856621563
Valid Loss:  0.0007964072283357382
Epoch:  404  	Training Loss: 0.0007036590250208974
Test Loss:  0.0004437465686351061
Valid Loss:  0.0007957619382068515
Epoch:  405  	Training Loss: 0.0007030610577203333
Test Loss:  0.0004432460991665721
Valid Loss:  0.0007951349252834916
Epoch:  406  	Training Loss: 0.0007024865481071174
Test Loss:  0.00044275884283706546
Valid Loss:  0.0007945232791826129
Epoch:  407  	Training Loss: 0.0007019316544756293
Test Loss:  0.0004422812780831009
Valid Loss:  0.0007939300267025828
Epoch:  408  	Training Loss: 0.0007013860158622265
Test Loss:  0.00044181320117786527
Valid Loss:  0.0007933513843454421
Epoch:  409  	Training Loss: 0.0007008498650975525
Test Loss:  0.0004413429996930063
Valid Loss:  0.0007927746046334505
Epoch:  410  	Training Loss: 0.0007003257051110268
Test Loss:  0.00044088446884416044
Valid Loss:  0.0007922066142782569
Epoch:  411  	Training Loss: 0.0006998167373239994
Test Loss:  0.00044045396498404443
Valid Loss:   82%|████████▏ | 411/500 [05:04<01:43,  1.16s/it] 83%|████████▎ | 413/500 [05:04<01:12,  1.20it/s] 83%|████████▎ | 415/500 [05:04<00:51,  1.66it/s] 83%|████████▎ | 417/500 [05:05<00:36,  2.26it/s] 84%|████████▍ | 419/500 [05:05<00:26,  3.04it/s] 84%|████████▍ | 421/500 [05:11<01:32,  1.17s/it] 85%|████████▍ | 423/500 [05:11<01:04,  1.19it/s] 85%|████████▌ | 425/500 [05:11<00:45,  1.64it/s] 85%|████████▌ | 427/500 [05:11<00:32,  2.24it/s] 86%|████████▌ | 429/500 [05:11<00:23,  3.01it/s] 86%|████████▌ | 431/500 [05:18<01:21,  1.19s/it] 87%|████████▋ | 433/500 [05:18<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:18<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:18<00:28,  2.21it/s] 88%|████████▊ | 439/500 [05:18<00:20,  2.97it/s] 88%|████████▊ | 441/500 [05:25<01:10,  1.19s/it] 89%|████████▊ | 443/500 [05:25<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:25<00:34,  1.61it/s] 89%|████████▉ | 447/500 [05:25<00:24,  2.21it/s] 90%|████████▉ | 449/500 [05:25<00:17,  2.96it/s] 90%|█████████ | 451/500 [05:32<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:32<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:32<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:32<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:32<00:13,  2.99it/s] 92%|█████████▏| 461/500 [05:38<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:39<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:39<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:39<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:39<00:10,  3.00it/s] 94%|█████████▍| 471/500 [05:45<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:45<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:45<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:46<00:10,  2.24it/s]0.0007916517788544297
Epoch:  412  	Training Loss: 0.0006993228453211486
Test Loss:  0.00043232133612036705
Valid Loss:  0.0007816060679033399
Epoch:  413  	Training Loss: 0.0006925435736775398
Test Loss:  0.00042635263525880873
Valid Loss:  0.0007743816240690649
Epoch:  414  	Training Loss: 0.0006875397521071136
Test Loss:  0.00042170233791694045
Valid Loss:  0.0007685042801313102
Epoch:  415  	Training Loss: 0.00068352569360286
Test Loss:  0.00041787890950217843
Valid Loss:  0.000763221993111074
Epoch:  416  	Training Loss: 0.0006800631526857615
Test Loss:  0.00041476706974208355
Valid Loss:  0.0007586440769955516
Epoch:  417  	Training Loss: 0.0006770750042051077
Test Loss:  0.00041221699211746454
Valid Loss:  0.000754496781155467
Epoch:  418  	Training Loss: 0.0006745309801772237
Test Loss:  0.00041027850238606334
Valid Loss:  0.000751171784941107
Epoch:  419  	Training Loss: 0.00067247508559376
Test Loss:  0.00040848139906302094
Valid Loss:  0.0007481591310352087
Epoch:  420  	Training Loss: 0.0006706614512950182
Test Loss:  0.00040693566552363336
Valid Loss:  0.0007455172017216682
Epoch:  421  	Training Loss: 0.0006690521258860826
Test Loss:  0.0004054795717820525
Valid Loss:  0.0007431614794768393
Epoch:  422  	Training Loss: 0.0006675479235127568
Test Loss:  0.0004047382972203195
Valid Loss:  0.0007417910383082926
Epoch:  423  	Training Loss: 0.0006660207291133702
Test Loss:  0.0004042146319989115
Valid Loss:  0.000740818795748055
Epoch:  424  	Training Loss: 0.0006647540722042322
Test Loss:  0.0004038027545902878
Valid Loss:  0.0007400853792205453
Epoch:  425  	Training Loss: 0.000663653074298054
Test Loss:  0.0004034437006339431
Valid Loss:  0.0007394900312647223
Epoch:  426  	Training Loss: 0.0006626115646213293
Test Loss:  0.00040311511838808656
Valid Loss:  0.0007389808306470513
Epoch:  427  	Training Loss: 0.0006616087048314512
Test Loss:  0.00040280813118442893
Valid Loss:  0.000738526345230639
Epoch:  428  	Training Loss: 0.0006606324459426105
Test Loss:  0.00040251354221254587
Valid Loss:  0.0007381097530014813
Epoch:  429  	Training Loss: 0.0006596786552108824
Test Loss:  0.0004022271023131907
Valid Loss:  0.0007377183064818382
Epoch:  430  	Training Loss: 0.0006587429670616984
Test Loss:  0.0004019454645458609
Valid Loss:  0.0007373442640528083
Epoch:  431  	Training Loss: 0.0006578243337571621
Test Loss:  0.000401670957216993
Valid Loss:  0.0007369820377789438
Epoch:  432  	Training Loss: 0.000656922347843647
Test Loss:  0.00040134642040356994
Valid Loss:  0.0007367538055405021
Epoch:  433  	Training Loss: 0.0006563301431015134
Test Loss:  0.00040103058563545346
Valid Loss:  0.0007365333731286228
Epoch:  434  	Training Loss: 0.0006557482993230224
Test Loss:  0.0004007211828138679
Valid Loss:  0.0007363201584666967
Epoch:  435  	Training Loss: 0.000655176758300513
Test Loss:  0.0004004183574579656
Valid Loss:  0.0007361150928772986
Epoch:  436  	Training Loss: 0.0006546138320118189
Test Loss:  0.00040012248791754246
Valid Loss:  0.0007359174778684974
Epoch:  437  	Training Loss: 0.0006540607428178191
Test Loss:  0.00039983278838917613
Valid Loss:  0.0007357258000411093
Epoch:  438  	Training Loss: 0.0006535102147608995
Test Loss:  0.00039954495150595903
Valid Loss:  0.0007355381967499852
Epoch:  439  	Training Loss: 0.0006529552047140896
Test Loss:  0.0003992605779785663
Valid Loss:  0.0007353540859185159
Epoch:  440  	Training Loss: 0.0006524017080664635
Test Loss:  0.00039898010436445475
Valid Loss:  0.0007351754466071725
Epoch:  441  	Training Loss: 0.0006518569425679743
Test Loss:  0.0003987060918007046
Valid Loss:  0.0007350016967393458
Epoch:  442  	Training Loss: 0.0006513078697025776
Test Loss:  0.000397612078813836
Valid Loss:  0.0007339412113651633
Epoch:  443  	Training Loss: 0.0006490451632998884
Test Loss:  0.0003965434734709561
Valid Loss:  0.0007328753126785159
Epoch:  444  	Training Loss: 0.0006468320498242974
Test Loss:  0.0003954854910261929
Valid Loss:  0.0007316877017728984
Epoch:  445  	Training Loss: 0.0006446401821449399
Test Loss:  0.00039445116999559104
Valid Loss:  0.0007304971222765744
Epoch:  446  	Training Loss: 0.0006425076862797141
Test Loss:  0.0003933200496248901
Valid Loss:  0.0007292941445484757
Epoch:  447  	Training Loss: 0.0006403737934306264
Test Loss:  0.0003922023461200297
Valid Loss:  0.0007280974532477558
Epoch:  448  	Training Loss: 0.0006382885621860623
Test Loss:  0.00039108196506276727
Valid Loss:  0.0007269023917615414
Epoch:  449  	Training Loss: 0.0006362514104694128
Test Loss:  0.00038990218308754265
Valid Loss:  0.0007257121615111828
Epoch:  450  	Training Loss: 0.0006342566339299083
Test Loss:  0.00038874009624123573
Valid Loss:  0.0007245236774906516
Epoch:  451  	Training Loss: 0.0006322795525193214
Test Loss:  0.0003875838010571897
Valid Loss:  0.0007233261130750179
Epoch:  452  	Training Loss: 0.0006303165573626757
Test Loss:  0.00038707797648385167
Valid Loss:  0.0007220861152745783
Epoch:  453  	Training Loss: 0.0006294871564023197
Test Loss:  0.00038662098813802004
Valid Loss:  0.0007210468174889684
Epoch:  454  	Training Loss: 0.0006287654396146536
Test Loss:  0.00038617156678810716
Valid Loss:  0.0007200851105153561
Epoch:  455  	Training Loss: 0.0006280820816755295
Test Loss:  0.0003857105621136725
Valid Loss:  0.0007191640324890614
Epoch:  456  	Training Loss: 0.0006274163606576622
Test Loss:  0.00038524798583239317
Valid Loss:  0.000718270312063396
Epoch:  457  	Training Loss: 0.000626755238045007
Test Loss:  0.00038478535134345293
Valid Loss:  0.0007173914927989244
Epoch:  458  	Training Loss: 0.0006260956870391965
Test Loss:  0.00038432536530308425
Valid Loss:  0.0007165296119637787
Epoch:  459  	Training Loss: 0.0006254392210394144
Test Loss:  0.0003838675038423389
Valid Loss:  0.0007156754145398736
Epoch:  460  	Training Loss: 0.0006247835117392242
Test Loss:  0.0003834133967757225
Valid Loss:  0.000714830297511071
Epoch:  461  	Training Loss: 0.0006241314113140106
Test Loss:  0.0003829690394923091
Valid Loss:  0.0007139918743632734
Epoch:  462  	Training Loss: 0.0006234861211851239
Test Loss:  0.0003828237531706691
Valid Loss:  0.0007137967040762305
Epoch:  463  	Training Loss: 0.0006230490398593247
Test Loss:  0.0003826715983450413
Valid Loss:  0.0007135941996239126
Epoch:  464  	Training Loss: 0.0006226395489647985
Test Loss:  0.000382525147870183
Valid Loss:  0.0007133873295970261
Epoch:  465  	Training Loss: 0.0006222364027053118
Test Loss:  0.0003823930455837399
Valid Loss:  0.000713180925231427
Epoch:  466  	Training Loss: 0.0006218485068529844
Test Loss:  0.0003822619910351932
Valid Loss:  0.0007129713776521385
Epoch:  467  	Training Loss: 0.0006214729510247707
Test Loss:  0.00038213044172152877
Valid Loss:  0.0007127723656594753
Epoch:  468  	Training Loss: 0.0006210999563336372
Test Loss:  0.0003819983685389161
Valid Loss:  0.0007125857518985868
Epoch:  469  	Training Loss: 0.0006207320257090032
Test Loss:  0.00038186300662346184
Valid Loss:  0.0007124008843675256
Epoch:  470  	Training Loss: 0.0006203740485943854
Test Loss:  0.00038172712083905935
Valid Loss:  0.0007122121751308441
Epoch:  471  	Training Loss: 0.0006200255593284965
Test Loss:  0.00038159708492457867
Valid Loss:  0.0007120194495655596
Epoch:  472  	Training Loss: 0.0006196880713105202
Test Loss:  0.0003812303766608238
Valid Loss:  0.0007114087929949164
Epoch:  473  	Training Loss: 0.0006188290426507592
Test Loss:  0.0003808677429333329
Valid Loss:  0.0007107995334081352
Epoch:  474  	Training Loss: 0.0006179836927913129
Test Loss:  0.0003805115120485425
Valid Loss:  0.0007101938826963305
Epoch:  475  	Training Loss: 0.0006171490531414747
Test Loss:  0.00038017818587832153
Valid Loss:  0.0007095924229361117
Epoch:  476  	Training Loss: 0.0006163323414511979
Test Loss:  0.0003798433463089168
Valid Loss:  0.0007089803693816066
Epoch:  477  	Training Loss: 0.000615535827819258
Test Loss:  0.0003795127267949283
Valid Loss:  0.0007083742530085146
Epoch:  478  	Training Loss: 0.0006147645763121545
Test Loss:  0.0003791886265389621
Valid Loss:  0.0007077771006152034
Epoch:  479  	Training Loss: 0.0006140262121334672
Test Loss:  0.00037887011421844363
Valid Loss:   96%|█████████▌| 479/500 [05:46<00:06,  3.00it/s] 96%|█████████▌| 481/500 [05:52<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:52<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:52<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:52<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:53<00:03,  3.01it/s] 98%|█████████▊| 491/500 [05:59<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:59<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:59<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:59<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:59<00:00,  3.00it/s]100%|██████████| 500/500 [05:59<00:00,  1.39it/s]
0.0007071858271956444
Epoch:  480  	Training Loss: 0.0006132959388196468
Test Loss:  0.0003785579465329647
Valid Loss:  0.000706597464159131
Epoch:  481  	Training Loss: 0.000612577423453331
Test Loss:  0.0003782464482355863
Valid Loss:  0.0007060111383907497
Epoch:  482  	Training Loss: 0.0006118693854659796
Test Loss:  0.00037781335413455963
Valid Loss:  0.000705051061231643
Epoch:  483  	Training Loss: 0.000611104303970933
Test Loss:  0.0003773861099034548
Valid Loss:  0.0007041216595098376
Epoch:  484  	Training Loss: 0.0006103521445766091
Test Loss:  0.0003769701288547367
Valid Loss:  0.0007032203138805926
Epoch:  485  	Training Loss: 0.0006096133729442954
Test Loss:  0.00037656392669305205
Valid Loss:  0.0007023480138741434
Epoch:  486  	Training Loss: 0.0006088865920901299
Test Loss:  0.00037616764893755317
Valid Loss:  0.000701497308909893
Epoch:  487  	Training Loss: 0.0006081704050302505
Test Loss:  0.00037578213959932327
Valid Loss:  0.0007006707601249218
Epoch:  488  	Training Loss: 0.000607465161010623
Test Loss:  0.00037540789344348013
Valid Loss:  0.000699863419868052
Epoch:  489  	Training Loss: 0.0006067701615393162
Test Loss:  0.0003750426694750786
Valid Loss:  0.0006990780821070075
Epoch:  490  	Training Loss: 0.0006060845917090774
Test Loss:  0.00037468585651367903
Valid Loss:  0.0006983104394748807
Epoch:  491  	Training Loss: 0.0006054089753888547
Test Loss:  0.0003743395791389048
Valid Loss:  0.000697561539709568
Epoch:  492  	Training Loss: 0.000604743545409292
Test Loss:  0.0003729871823452413
Valid Loss:  0.0006959218299016356
Epoch:  493  	Training Loss: 0.000602615182287991
Test Loss:  0.0003716789942700416
Valid Loss:  0.000694270187523216
Epoch:  494  	Training Loss: 0.0006005304167047143
Test Loss:  0.0003703972906805575
Valid Loss:  0.000692609406542033
Epoch:  495  	Training Loss: 0.0005984813906252384
Test Loss:  0.00036913255462422967
Valid Loss:  0.0006909366929903626
Epoch:  496  	Training Loss: 0.0005964586162008345
Test Loss:  0.0003678636276163161
Valid Loss:  0.0006892474484629929
Epoch:  497  	Training Loss: 0.0005944311851635575
Test Loss:  0.00036660919431596994
Valid Loss:  0.0006875555263832211
Epoch:  498  	Training Loss: 0.0005924318684265018
Test Loss:  0.0003653072635643184
Valid Loss:  0.0006858588894829154
Epoch:  499  	Training Loss: 0.000590460782404989
Test Loss:  0.00036397934309206903
Valid Loss:  0.0006841769791208208
Epoch:  500  	Training Loss: 0.000588496623095125
Test Loss:  0.00036263454239815474
Valid Loss:  0.0006824723677709699
seed is  5
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.28it/s]  1%|          | 4/500 [00:00<00:30, 16.37it/s]  1%|          | 6/500 [00:00<00:30, 16.31it/s]  2%|▏         | 8/500 [00:00<00:30, 16.36it/s]  2%|▏         | 10/500 [00:00<00:30, 16.21it/s]  2%|▏         | 12/500 [00:00<00:29, 16.29it/s]  3%|▎         | 14/500 [00:00<00:29, 16.38it/s]  3%|▎         | 16/500 [00:00<00:29, 16.33it/s]  4%|▎         | 18/500 [00:01<00:29, 16.38it/s]  4%|▍         | 20/500 [00:01<00:29, 16.22it/s]  4%|▍         | 22/500 [00:01<00:29, 16.24it/s]  5%|▍         | 24/500 [00:01<00:29, 16.30it/s]  5%|▌         | 26/500 [00:01<00:28, 16.36it/s]  6%|▌         | 28/500 [00:01<00:28, 16.41it/s]  6%|▌         | 30/500 [00:01<00:28, 16.43it/s]  6%|▋         | 32/500 [00:01<00:28, 16.49it/s]  7%|▋         | 34/500 [00:02<00:28, 16.45it/s]  7%|▋         | 36/500 [00:02<00:28, 16.47it/s]  8%|▊         | 38/500 [00:02<00:28, 16.49it/s]  8%|▊         | 40/500 [00:02<00:27, 16.48it/s]  8%|▊         | 42/500 [00:02<00:27, 16.48it/s]  9%|▉         | 44/500 [00:02<00:27, 16.50it/s]  9%|▉         | 46/500 [00:02<00:27, 16.54it/s] 10%|▉         | 48/500 [00:02<00:27, 16.54it/s] 10%|█         | 50/500 [00:03<00:27, 16.51it/s] 10%|█         | 52/500 [00:03<00:27, 16.48it/s] 11%|█         | 54/500 [00:03<00:27, 16.48it/s] 11%|█         | 56/500 [00:03<00:26, 16.48it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.49it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.09it/s] 12%|█▏        | 62/500 [00:03<00:28, 15.55it/s] 13%|█▎        | 64/500 [00:03<00:27, 15.81it/s] 13%|█▎        | 66/500 [00:04<00:27, 16.00it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.15it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.24it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.24it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.27it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.29it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.38it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.23it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.14it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.17it/s] 17%|█▋        | 86/500 [00:05<00:25, 15.95it/s] 18%|█▊        | 88/500 [00:05<00:26, 15.31it/s] 18%|█▊        | 90/500 [00:05<00:27, 14.84it/s] 18%|█▊        | 92/500 [00:05<00:26, 15.28it/s] 19%|█▉        | 94/500 [00:05<00:28, 14.26it/s] 19%|█▉        | 96/500 [00:05<00:28, 14.31it/s] 20%|█▉        | 98/500 [00:06<00:29, 13.70it/s] 20%|██        | 100/500 [00:06<00:30, 13.18it/s] 20%|██        | 102/500 [00:06<00:28, 13.98it/s] 21%|██        | 104/500 [00:06<00:27, 14.66it/s] 21%|██        | 106/500 [00:06<00:25, 15.16it/s] 22%|██▏       | 108/500 [00:06<00:25, 15.42it/s] 22%|██▏       | 110/500 [00:06<00:24, 15.65it/s] 22%|██▏       | 112/500 [00:07<00:24, 15.82it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.08it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.19it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.18it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.30it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.20it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.34it/s]Epoch:  1  	Training Loss: 0.17302650213241577
Test Loss:  4031.4736328125
Valid Loss:  4032.317626953125
Epoch:  2  	Training Loss: 4023.46728515625
Test Loss:  6112272648765440.0
Valid Loss:  6115246376747008.0
Epoch:  3  	Training Loss: 6129518553071616.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.43it/s] 26%|██▌       | 128/500 [00:08<00:22, 16.45it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.48it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.43it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.49it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.51it/s] 28%|██▊       | 138/500 [00:08<00:21, 16.57it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.53it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.48it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.52it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.50it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.14it/s] 30%|███       | 150/500 [00:09<00:21, 16.21it/s] 30%|███       | 152/500 [00:09<00:21, 16.28it/s] 31%|███       | 154/500 [00:09<00:21, 16.41it/s] 31%|███       | 156/500 [00:09<00:20, 16.48it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.39it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.39it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.46it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.45it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.43it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.40it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.41it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.37it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.35it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.22it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.26it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.31it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.38it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.37it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.39it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.39it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.40it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.32it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.22it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.24it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.27it/s] 40%|████      | 200/500 [00:12<00:18, 16.28it/s] 40%|████      | 202/500 [00:12<00:19, 15.56it/s] 41%|████      | 204/500 [00:12<00:20, 14.48it/s] 41%|████      | 206/500 [00:12<00:20, 14.70it/s] 42%|████▏     | 208/500 [00:12<00:19, 15.01it/s] 42%|████▏     | 210/500 [00:13<00:18, 15.29it/s] 42%|████▏     | 212/500 [00:13<00:19, 14.88it/s] 43%|████▎     | 214/500 [00:13<00:18, 15.34it/s] 43%|████▎     | 216/500 [00:13<00:18, 15.63it/s] 44%|████▎     | 218/500 [00:13<00:17, 15.87it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.00it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.10it/s] 45%|████▍     | 224/500 [00:13<00:17, 16.17it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.12it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.23it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.31it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.35it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.38it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.40it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.38it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.46it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.44it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.42it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.43it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.44it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.45it/s] 50%|█████     | 252/500 [00:15<00:15, 16.44it/s] 51%|█████     | 254/500 [00:15<00:14, 16.44it/s] 51%|█████     | 256/500 [00:15<00:14, 16.44it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.37it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.44it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.45it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.35it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.39it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.33it/s] 54%|█████▍    | 270/500 [00:16<00:13, 16.45it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.34it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.41it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.43it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.46it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.52it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.31it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.35it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.36it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.35it/s] 58%|█████▊    | 290/500 [00:18<00:12, 16.19it/s] 58%|█████▊    | 292/500 [00:18<00:14, 14.50it/s] 59%|█████▉    | 294/500 [00:18<00:14, 14.30it/s] 59%|█████▉    | 296/500 [00:18<00:13, 14.84it/s] 60%|█████▉    | 298/500 [00:18<00:13, 15.31it/s] 60%|██████    | 300/500 [00:18<00:12, 15.74it/s] 60%|██████    | 302/500 [00:18<00:12, 15.96it/s] 61%|██████    | 304/500 [00:18<00:12, 16.02it/s] 61%|██████    | 306/500 [00:19<00:12, 16.04it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.15it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.21it/s] 62%|██████▏   | 312/500 [00:19<00:12, 15.52it/s] 63%|██████▎   | 314/500 [00:19<00:12, 15.17it/s] 63%|██████▎   | 316/500 [00:19<00:11, 15.53it/s] 64%|██████▎   | 318/500 [00:19<00:11, 15.79it/s] 64%|██████▍   | 320/500 [00:19<00:11, 15.87it/s] 64%|██████▍   | 322/500 [00:20<00:11, 16.03it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.13it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.03it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.07it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.16it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.23it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.29it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.32it/s] 68%|██████▊   | 338/500 [00:21<00:09, 16.34it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.31it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.32it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.34it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.15it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.24it/s] 70%|███████   | 350/500 [00:21<00:09, 16.30it/s] 70%|███████   | 352/500 [00:21<00:09, 16.36it/s] 71%|███████   | 354/500 [00:22<00:08, 16.40it/s] 71%|███████   | 356/500 [00:22<00:08, 16.48it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.51it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.51it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.48it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.49it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.50it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.46it/s] 74%|███████▍  | 370/500 [00:23<00:07, 16.48it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.47it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.52it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.47it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.50it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.54it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.40it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.45it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.47it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.45it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.41it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.42it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.47it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.42it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.41it/s] 80%|████████  | 400/500 [00:24<00:06, 16.39it/s] 80%|████████  | 402/500 [00:24<00:06, 16.30it/s] 81%|████████  | 404/500 [00:25<00:05, 16.04it/s] 81%|████████  | 406/500 [00:25<00:05, 16.13it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.23it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.27it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.22it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.28it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.39it/s] 84%|████████▎ | 418/500 [00:25<00:05, 16.39it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.26it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.20it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.14it/s] 85%|████████▌ | 426/500 [00:26<00:04, 15.31it/s] 86%|████████▌ | 428/500 [00:26<00:05, 14.37it/s] 86%|████████▌ | 430/500 [00:26<00:04, 14.93it/s] 86%|████████▋ | 432/500 [00:26<00:04, 15.39it/s] 87%|████████▋ | 434/500 [00:26<00:04, 15.16it/s] 87%|████████▋ | 436/500 [00:27<00:04, 14.87it/s] 88%|████████▊ | 438/500 [00:27<00:04, 15.35it/s] 88%|████████▊ | 440/500 [00:27<00:03, 15.58it/s] 88%|████████▊ | 442/500 [00:27<00:03, 15.84it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.03it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.21it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.30it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.39it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.22it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.27it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.16it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.16it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.31it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.33it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.23it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.20it/s] 94%|█████████▎| 468/500 [00:29<00:01, 16.28it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.37it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.40it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.46it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.44it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.42it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.47it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.49it/s] 97%|█████████▋| 484/500 [00:30<00:00, 16.48it/s] 97%|█████████▋| 486/500 [00:30<00:00, 16.46it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.33it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.37it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.38it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.43it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.42it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.24it/s]100%|██████████| 500/500 [00:31<00:00, 16.22it/s]100%|██████████| 500/500 [00:31<00:00, 16.10it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  5
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:31,  6.19s/it]  1%|          | 3/500 [00:06<13:44,  1.66s/it]  1%|          | 5/500 [00:06<06:55,  1.19it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:13<10:48,  1.33s/it]  3%|▎         | 13/500 [00:13<07:22,  1.10it/s]  3%|▎         | 15/500 [00:13<05:08,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:40,  2.99it/s]  4%|▍         | 21/500 [00:19<09:33,  1.20s/it]  5%|▍         | 23/500 [00:19<06:47,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  3.00it/s]  6%|▌         | 31/500 [00:26<09:10,  1.17s/it]  7%|▋         | 33/500 [00:26<06:33,  1.19it/s]  7%|▋         | 35/500 [00:26<04:43,  1.64it/s]  7%|▋         | 37/500 [00:27<03:26,  2.24it/s]  8%|▊         | 39/500 [00:27<02:32,  3.02it/s]  8%|▊         | 41/500 [00:33<08:59,  1.17s/it]  9%|▊         | 43/500 [00:33<06:25,  1.19it/s]  9%|▉         | 45/500 [00:33<04:37,  1.64it/s]  9%|▉         | 47/500 [00:33<03:22,  2.24it/s] 10%|▉         | 49/500 [00:33<02:29,  3.01it/s] 10%|█         | 51/500 [00:40<08:46,  1.17s/it] 11%|█         | 53/500 [00:40<06:16,  1.19it/s] 11%|█         | 55/500 [00:40<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.24it/s] 12%|█▏        | 59/500 [00:40<02:26,  3.02it/s] 12%|█▏        | 61/500 [00:47<08:40,  1.19s/it] 13%|█▎        | 63/500 [00:47<06:13,  1.17it/s] 13%|█▎        | 65/500 [00:47<04:28,  1.62it/s] 13%|█▎        | 67/500 [00:47<03:15,  2.21it/s] 14%|█▍        | 69/500 [00:47<02:24,  2.97it/s]Epoch:  1  	Training Loss: 0.17302650213241577
Test Loss:  0.02188263088464737
Valid Loss:  0.020097851753234863
Epoch:  2  	Training Loss: 0.024314522743225098
Test Loss:  0.019186176359653473
Valid Loss:  0.01791314408183098
Epoch:  3  	Training Loss: 0.019913142547011375
Test Loss:  0.01563688926398754
Valid Loss:  0.014513136819005013
Epoch:  4  	Training Loss: 0.01668975129723549
Test Loss:  0.013076694682240486
Valid Loss:  0.012144802138209343
Epoch:  5  	Training Loss: 0.014033765532076359
Test Loss:  0.010853584855794907
Valid Loss:  0.010065453127026558
Epoch:  6  	Training Loss: 0.011864740401506424
Test Loss:  0.00904521532356739
Valid Loss:  0.0083802854642272
Epoch:  7  	Training Loss: 0.010098077356815338
Test Loss:  0.007632218301296234
Valid Loss:  0.007090725004673004
Epoch:  8  	Training Loss: 0.008643561974167824
Test Loss:  0.00642916327342391
Valid Loss:  0.005984129849821329
Epoch:  9  	Training Loss: 0.007463518064469099
Test Loss:  0.005463781300932169
Valid Loss:  0.005105894058942795
Epoch:  10  	Training Loss: 0.006500218994915485
Test Loss:  0.004696803167462349
Valid Loss:  0.004421399440616369
Epoch:  11  	Training Loss: 0.005705544725060463
Test Loss:  0.004068369045853615
Valid Loss:  0.0038668308407068253
Epoch:  12  	Training Loss: 0.005048946011811495
Test Loss:  0.0035569577012211084
Valid Loss:  0.003421545261517167
Epoch:  13  	Training Loss: 0.004506368190050125
Test Loss:  0.003138689324259758
Valid Loss:  0.0030620733741670847
Epoch:  14  	Training Loss: 0.00405777245759964
Test Loss:  0.0027988767251372337
Valid Loss:  0.002775510773062706
Epoch:  15  	Training Loss: 0.003686966374516487
Test Loss:  0.002523421309888363
Valid Loss:  0.002548562828451395
Epoch:  16  	Training Loss: 0.003380464855581522
Test Loss:  0.0022972149308770895
Valid Loss:  0.002365053864195943
Epoch:  17  	Training Loss: 0.0031270389445126057
Test Loss:  0.0021161185577511787
Valid Loss:  0.0022232974879443645
Epoch:  18  	Training Loss: 0.0029174797236919403
Test Loss:  0.001968949567526579
Valid Loss:  0.0021113769616931677
Epoch:  19  	Training Loss: 0.002744181314483285
Test Loss:  0.0018501977901905775
Valid Loss:  0.0020243681501597166
Epoch:  20  	Training Loss: 0.0026008463464677334
Test Loss:  0.001754680648446083
Valid Loss:  0.001957411179319024
Epoch:  21  	Training Loss: 0.0024822168052196503
Test Loss:  0.0016784303588792682
Valid Loss:  0.001906928839161992
Epoch:  22  	Training Loss: 0.00238398602232337
Test Loss:  0.0016177077777683735
Valid Loss:  0.0018694987520575523
Epoch:  23  	Training Loss: 0.0023025397676974535
Test Loss:  0.0015698543284088373
Valid Loss:  0.0018429574556648731
Epoch:  24  	Training Loss: 0.002235138090327382
Test Loss:  0.0015322507824748755
Valid Loss:  0.0018249655840918422
Epoch:  25  	Training Loss: 0.002179333008825779
Test Loss:  0.0015021867584437132
Valid Loss:  0.0018123167101293802
Epoch:  26  	Training Loss: 0.0021331224124878645
Test Loss:  0.0014791376888751984
Valid Loss:  0.0018052642699331045
Epoch:  27  	Training Loss: 0.002094852039590478
Test Loss:  0.001461077481508255
Valid Loss:  0.0018013960216194391
Epoch:  28  	Training Loss: 0.002063150517642498
Test Loss:  0.00144773384090513
Valid Loss:  0.001801168080419302
Epoch:  29  	Training Loss: 0.002036872785538435
Test Loss:  0.0014377624029293656
Valid Loss:  0.0018031084910035133
Epoch:  30  	Training Loss: 0.002015079837292433
Test Loss:  0.001430470496416092
Valid Loss:  0.0018065760377794504
Epoch:  31  	Training Loss: 0.0019970100838690996
Test Loss:  0.0014253261033445597
Valid Loss:  0.0018111236859112978
Epoch:  32  	Training Loss: 0.001982005313038826
Test Loss:  0.0014220213051885366
Valid Loss:  0.0018167837988585234
Epoch:  33  	Training Loss: 0.001969508593901992
Test Loss:  0.0014198841527104378
Valid Loss:  0.001822667196393013
Epoch:  34  	Training Loss: 0.0019591120071709156
Test Loss:  0.0014188203494995832
Valid Loss:  0.00182889134157449
Epoch:  35  	Training Loss: 0.0019504622323438525
Test Loss:  0.0014186450280249119
Valid Loss:  0.0018355015199631453
Epoch:  36  	Training Loss: 0.0019432459957897663
Test Loss:  0.0014189404901117086
Valid Loss:  0.0018418370746076107
Epoch:  37  	Training Loss: 0.0019372246460989118
Test Loss:  0.001419717795215547
Valid Loss:  0.0018480551661923528
Epoch:  38  	Training Loss: 0.0019321732688695192
Test Loss:  0.0014208104694262147
Valid Loss:  0.0018540701130405068
Epoch:  39  	Training Loss: 0.0019279483240097761
Test Loss:  0.001422136789187789
Valid Loss:  0.001859863754361868
Epoch:  40  	Training Loss: 0.00192442093975842
Test Loss:  0.0014235889539122581
Valid Loss:  0.0018653732258826494
Epoch:  41  	Training Loss: 0.0019214488565921783
Test Loss:  0.001425109338015318
Valid Loss:  0.0018706114497035742
Epoch:  42  	Training Loss: 0.0019189368467777967
Test Loss:  0.0014266896760091186
Valid Loss:  0.0018755755154415965
Epoch:  43  	Training Loss: 0.0019168260041624308
Test Loss:  0.001428250689059496
Valid Loss:  0.0018802093109115958
Epoch:  44  	Training Loss: 0.001915025757625699
Test Loss:  0.0014297806192189455
Valid Loss:  0.0018845219165086746
Epoch:  45  	Training Loss: 0.0019134796457365155
Test Loss:  0.0014312614221125841
Valid Loss:  0.0018885217141360044
Epoch:  46  	Training Loss: 0.00191213795915246
Test Loss:  0.0014326670207083225
Valid Loss:  0.0018922286108136177
Epoch:  47  	Training Loss: 0.0019109665881842375
Test Loss:  0.0014339962508529425
Valid Loss:  0.0018956452840939164
Epoch:  48  	Training Loss: 0.00190993573050946
Test Loss:  0.0014352528378367424
Valid Loss:  0.0018987806979566813
Epoch:  49  	Training Loss: 0.0019090349087491632
Test Loss:  0.0014364469097927213
Valid Loss:  0.0019017021404579282
Epoch:  50  	Training Loss: 0.0019083002116531134
Test Loss:  0.0014377222396433353
Valid Loss:  0.0019048338290303946
Epoch:  51  	Training Loss: 0.0019076971802860498
Test Loss:  0.0014388381969183683
Valid Loss:  0.0019074693555012345
Epoch:  52  	Training Loss: 0.001907180529087782
Test Loss:  0.0014398739440366626
Valid Loss:  0.001909901387989521
Epoch:  53  	Training Loss: 0.0019067309331148863
Test Loss:  0.0014408356510102749
Valid Loss:  0.0019121253862977028
Epoch:  54  	Training Loss: 0.0019063397776335478
Test Loss:  0.0014417347265407443
Valid Loss:  0.0019141724333167076
Epoch:  55  	Training Loss: 0.0019060058984905481
Test Loss:  0.0014425591798499227
Valid Loss:  0.0019160396186634898
Epoch:  56  	Training Loss: 0.0019057169556617737
Test Loss:  0.0014433915494009852
Valid Loss:  0.0019179686205461621
Epoch:  57  	Training Loss: 0.0019054533913731575
Test Loss:  0.0014440385857596993
Valid Loss:  0.001919389353133738
Epoch:  58  	Training Loss: 0.0019052179995924234
Test Loss:  0.001444734982214868
Valid Loss:  0.0019210263853892684
Epoch:  59  	Training Loss: 0.0019050026312470436
Test Loss:  0.001445260364562273
Valid Loss:  0.001922164112329483
Epoch:  60  	Training Loss: 0.0019048107787966728
Test Loss:  0.001445831498131156
Valid Loss:  0.0019235399086028337
Epoch:  61  	Training Loss: 0.0019046261440962553
Test Loss:  0.001446328591555357
Valid Loss:  0.0019246638985350728
Epoch:  62  	Training Loss: 0.001904466887935996
Test Loss:  0.0014467013534158468
Valid Loss:  0.001925492426380515
Epoch:  63  	Training Loss: 0.0019043181091547012
Test Loss:  0.0014471248723566532
Valid Loss:  0.001926545170135796
Epoch:  64  	Training Loss: 0.0019041728228330612
Test Loss:  0.0014474834315478802
Valid Loss:  0.0019273877842351794
Epoch:  65  	Training Loss: 0.0019040373153984547
Test Loss:  0.0014477991499006748
Valid Loss:  0.0019281459972262383
Epoch:  66  	Training Loss: 0.0019039087928831577
Test Loss:  0.0014480105601251125
Valid Loss:  0.0019286400638520718
Epoch:  67  	Training Loss: 0.0019037877209484577
Test Loss:  0.0014482749393209815
Valid Loss:  0.0019293799996376038
Epoch:  68  	Training Loss: 0.0019036645535379648
Test Loss:  0.0014484943822026253
Valid Loss:  0.0019299350678920746
Epoch:  69  	Training Loss: 0.0019035495351999998
Test Loss:  0.001448697061277926
Valid Loss:  0.0019304559100419283
Epoch:  70  	Training Loss: 0.0019034416181966662
Test Loss:  0.0014488747110590339
 14%|█▍        | 71/500 [00:53<08:23,  1.17s/it] 15%|█▍        | 73/500 [00:54<06:00,  1.19it/s] 15%|█▌        | 75/500 [00:54<04:19,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.24it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.01it/s] 16%|█▌        | 81/500 [01:00<08:10,  1.17s/it] 17%|█▋        | 83/500 [01:00<05:50,  1.19it/s] 17%|█▋        | 85/500 [01:01<04:12,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.01it/s] 18%|█▊        | 91/500 [01:07<07:59,  1.17s/it] 19%|█▊        | 93/500 [01:07<05:42,  1.19it/s] 19%|█▉        | 95/500 [01:07<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:07<02:59,  2.24it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.01it/s] 20%|██        | 101/500 [01:14<07:47,  1.17s/it] 21%|██        | 103/500 [01:14<05:35,  1.18it/s] 21%|██        | 105/500 [01:14<04:01,  1.64it/s] 21%|██▏       | 107/500 [01:14<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:14<02:10,  3.00it/s] 22%|██▏       | 111/500 [01:21<07:39,  1.18s/it] 23%|██▎       | 113/500 [01:21<05:28,  1.18it/s] 23%|██▎       | 115/500 [01:21<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:21<02:52,  2.23it/s] 24%|██▍       | 119/500 [01:21<02:07,  2.98it/s] 24%|██▍       | 121/500 [01:28<07:26,  1.18s/it] 25%|██▍       | 123/500 [01:28<05:19,  1.18it/s] 25%|██▌       | 125/500 [01:28<03:49,  1.63it/s] 25%|██▌       | 127/500 [01:28<02:47,  2.23it/s] 26%|██▌       | 129/500 [01:28<02:03,  3.00it/s] 26%|██▌       | 131/500 [01:34<07:16,  1.18s/it] 27%|██▋       | 133/500 [01:35<05:11,  1.18it/s] 27%|██▋       | 135/500 [01:35<03:44,  1.63it/s] 27%|██▋       | 137/500 [01:35<02:43,  2.22it/s]Valid Loss:  0.0019309103954583406
Epoch:  71  	Training Loss: 0.0019033377757295966
Test Loss:  0.0014490311732515693
Valid Loss:  0.0019313315860927105
Epoch:  72  	Training Loss: 0.001903238007798791
Test Loss:  0.001449087867513299
Valid Loss:  0.001931490609422326
Epoch:  73  	Training Loss: 0.0019031371921300888
Test Loss:  0.0014492117334157228
Valid Loss:  0.0019319277489557862
Epoch:  74  	Training Loss: 0.0019030324183404446
Test Loss:  0.0014493055641651154
Valid Loss:  0.0019322162261232734
Epoch:  75  	Training Loss: 0.001902932533994317
Test Loss:  0.0014493807684630156
Valid Loss:  0.0019324836321175098
Epoch:  76  	Training Loss: 0.001902831601910293
Test Loss:  0.0014494520146399736
Valid Loss:  0.0019327141344547272
Epoch:  77  	Training Loss: 0.0019027380039915442
Test Loss:  0.0014495243085548282
Valid Loss:  0.0019329343922436237
Epoch:  78  	Training Loss: 0.0019026531372219324
Test Loss:  0.0014495893847197294
Valid Loss:  0.0019331254297867417
Epoch:  79  	Training Loss: 0.0019025696674361825
Test Loss:  0.0014496363000944257
Valid Loss:  0.0019332931842654943
Epoch:  80  	Training Loss: 0.00190248666331172
Test Loss:  0.0014496755320578814
Valid Loss:  0.0019334371900185943
Epoch:  81  	Training Loss: 0.0019024035427719355
Test Loss:  0.001449698582291603
Valid Loss:  0.0019335516262799501
Epoch:  82  	Training Loss: 0.001902320422232151
Test Loss:  0.0014497124357149005
Valid Loss:  0.0019336652476340532
Epoch:  83  	Training Loss: 0.0019022385822609067
Test Loss:  0.001449718838557601
Valid Loss:  0.0019337509293109179
Epoch:  84  	Training Loss: 0.001902156276628375
Test Loss:  0.0014497207012027502
Valid Loss:  0.0019338256679475307
Epoch:  85  	Training Loss: 0.0019020723411813378
Test Loss:  0.0014497131342068315
Valid Loss:  0.001933885389007628
Epoch:  86  	Training Loss: 0.00190199154894799
Test Loss:  0.0014497009105980396
Valid Loss:  0.0019339382415637374
Epoch:  87  	Training Loss: 0.0019019132014364004
Test Loss:  0.0014496641233563423
Valid Loss:  0.001933919033035636
Epoch:  88  	Training Loss: 0.0019018348539248109
Test Loss:  0.0014496514340862632
Valid Loss:  0.0019339785212650895
Epoch:  89  	Training Loss: 0.001901756040751934
Test Loss:  0.0014495804207399487
Valid Loss:  0.0019338568672537804
Epoch:  90  	Training Loss: 0.0019016768783330917
Test Loss:  0.001449566101655364
Valid Loss:  0.001933947904035449
Epoch:  91  	Training Loss: 0.0019015984144061804
Test Loss:  0.0014495397917926311
Valid Loss:  0.0019339557038620114
Epoch:  92  	Training Loss: 0.001901519251987338
Test Loss:  0.0014495074283331633
Valid Loss:  0.0019339608261361718
Epoch:  93  	Training Loss: 0.0019014407880604267
Test Loss:  0.0014494750648736954
Valid Loss:  0.0019339582649990916
Epoch:  94  	Training Loss: 0.0019013599958270788
Test Loss:  0.0014494352508336306
Valid Loss:  0.0019339497666805983
Epoch:  95  	Training Loss: 0.0019012810662388802
Test Loss:  0.0014493935741484165
Valid Loss:  0.001933938474394381
Epoch:  96  	Training Loss: 0.0019012014381587505
Test Loss:  0.0014493500348180532
Valid Loss:  0.0019339264836162329
Epoch:  97  	Training Loss: 0.0019011213444173336
Test Loss:  0.0014493048656731844
Valid Loss:  0.0019339057616889477
Epoch:  98  	Training Loss: 0.0019010452087968588
Test Loss:  0.0014492579502984881
Valid Loss:  0.0019338810816407204
Epoch:  99  	Training Loss: 0.0019009679090231657
Test Loss:  0.001449208939447999
Valid Loss:  0.001933859195560217
Epoch:  100  	Training Loss: 0.0019008913077414036
Test Loss:  0.001449159812182188
Valid Loss:  0.0019338267156854272
Epoch:  101  	Training Loss: 0.0019008140079677105
Test Loss:  0.0014491082401946187
Valid Loss:  0.0019337964477017522
Epoch:  102  	Training Loss: 0.0019007378723472357
Test Loss:  0.0014490545727312565
Valid Loss:  0.0019337561680004
Epoch:  103  	Training Loss: 0.00190066103823483
Test Loss:  0.0014489989262074232
Valid Loss:  0.0019337162375450134
Epoch:  104  	Training Loss: 0.0019005832727998495
Test Loss:  0.0014489408349618316
Valid Loss:  0.0019336759578436613
Epoch:  105  	Training Loss: 0.0019005067879334092
Test Loss:  0.001448882045224309
Valid Loss:  0.0019336286932229996
Epoch:  106  	Training Loss: 0.0019004298374056816
Test Loss:  0.0014488226734101772
Valid Loss:  0.0019335810793563724
Epoch:  107  	Training Loss: 0.0019003518391400576
Test Loss:  0.001448763650842011
Valid Loss:  0.0019335364922881126
Epoch:  108  	Training Loss: 0.0019002752378582954
Test Loss:  0.0014487014850601554
Valid Loss:  0.0019334823591634631
Epoch:  109  	Training Loss: 0.0019001984037458897
Test Loss:  0.0014486410655081272
Valid Loss:  0.0019334300886839628
Epoch:  110  	Training Loss: 0.0019001218024641275
Test Loss:  0.001448577269911766
Valid Loss:  0.0019333807285875082
Epoch:  111  	Training Loss: 0.0019000440370291471
Test Loss:  0.0014485132414847612
Valid Loss:  0.00193333241622895
Epoch:  112  	Training Loss: 0.0018999659223482013
Test Loss:  0.0014484473504126072
Valid Loss:  0.0019332803785800934
Epoch:  113  	Training Loss: 0.0018998903688043356
Test Loss:  0.0014483819250017405
Valid Loss:  0.0019332249648869038
Epoch:  114  	Training Loss: 0.0018998126033693552
Test Loss:  0.00144831626676023
Valid Loss:  0.0019331722287461162
Epoch:  115  	Training Loss: 0.0018997358856722713
Test Loss:  0.0014482534024864435
Valid Loss:  0.0019331201910972595
Epoch:  116  	Training Loss: 0.00189965998288244
Test Loss:  0.0014481906546279788
Valid Loss:  0.001933068735525012
Epoch:  117  	Training Loss: 0.0018995869904756546
Test Loss:  0.0014481269754469395
Valid Loss:  0.001933012274093926
Epoch:  118  	Training Loss: 0.0018995101563632488
Test Loss:  0.0014480615500360727
Valid Loss:  0.0019329598871991038
Epoch:  119  	Training Loss: 0.0018994368147104979
Test Loss:  0.0014479958917945623
Valid Loss:  0.0019329050555825233
Epoch:  120  	Training Loss: 0.0018993639387190342
Test Loss:  0.0014479378005489707
Valid Loss:  0.0019328526686877012
Epoch:  121  	Training Loss: 0.0018992915283888578
Test Loss:  0.0014478774974122643
Valid Loss:  0.0019328012131154537
Epoch:  122  	Training Loss: 0.0018992202822118998
Test Loss:  0.001447818474844098
Valid Loss:  0.0019327427726238966
Epoch:  123  	Training Loss: 0.0018991483375430107
Test Loss:  0.0014477557269856334
Valid Loss:  0.0019326889887452126
Epoch:  124  	Training Loss: 0.001899076160043478
Test Loss:  0.0014476928627118468
Valid Loss:  0.0019326322944834828
Epoch:  125  	Training Loss: 0.0018990051466971636
Test Loss:  0.0014476319774985313
Valid Loss:  0.0019325771136209369
Epoch:  126  	Training Loss: 0.0018989325035363436
Test Loss:  0.0014475699281319976
Valid Loss:  0.0019325162284076214
Epoch:  127  	Training Loss: 0.0018988610245287418
Test Loss:  0.0014475134667009115
Valid Loss:  0.0019324577879160643
Epoch:  128  	Training Loss: 0.0018987894291058183
Test Loss:  0.0014474510680884123
Valid Loss:  0.0019324005115777254
Epoch:  129  	Training Loss: 0.0018987174844369292
Test Loss:  0.0014473870396614075
Valid Loss:  0.0019323392771184444
Epoch:  130  	Training Loss: 0.0018986478680744767
Test Loss:  0.0014473276678472757
Valid Loss:  0.0019322792068123817
Epoch:  131  	Training Loss: 0.0018985740607604384
Test Loss:  0.0014472650364041328
Valid Loss:  0.0019322199514135718
Epoch:  132  	Training Loss: 0.0018985024653375149
Test Loss:  0.0014472038019448519
Valid Loss:  0.0019321583677083254
Epoch:  133  	Training Loss: 0.001898431684821844
Test Loss:  0.0014471417525783181
Valid Loss:  0.001932100160047412
Epoch:  134  	Training Loss: 0.0018983609043061733
Test Loss:  0.00144708261359483
Valid Loss:  0.0019320417195558548
Epoch:  135  	Training Loss: 0.001898288493975997
Test Loss:  0.0014470212627202272
Valid Loss:  0.0019319832790642977
Epoch:  136  	Training Loss: 0.0018982174806296825
Test Loss:  0.0014469625893980265
Valid Loss:  0.0019319197162985802
Epoch:  137  	Training Loss: 0.0018981490284204483
Test Loss:  0.0014469004236161709
Valid Loss:  0.001931860577315092
Epoch:  138  	Training Loss: 0.001898077316582203
Test Loss:  0.0014468398876488209
Valid Loss:  0.0019317986443638802
Epoch:  139  	Training Loss: 0.0018980070017278194
Test Loss:   28%|██▊       | 139/500 [01:35<02:00,  2.99it/s] 28%|██▊       | 141/500 [01:41<07:01,  1.18s/it] 29%|██▊       | 143/500 [01:41<05:01,  1.18it/s] 29%|██▉       | 145/500 [01:42<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:42<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:42<01:56,  3.01it/s] 30%|███       | 151/500 [01:48<06:50,  1.18s/it] 31%|███       | 153/500 [01:48<04:53,  1.18it/s] 31%|███       | 155/500 [01:48<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:48<02:33,  2.23it/s] 32%|███▏      | 159/500 [01:49<01:53,  3.00it/s] 32%|███▏      | 161/500 [01:55<06:38,  1.18s/it] 33%|███▎      | 163/500 [01:55<04:44,  1.18it/s] 33%|███▎      | 165/500 [01:55<03:24,  1.64it/s] 33%|███▎      | 167/500 [01:55<02:28,  2.24it/s] 34%|███▍      | 169/500 [01:55<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:02<06:27,  1.18s/it] 35%|███▍      | 173/500 [02:02<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:02<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:02<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:02<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:09<06:17,  1.18s/it] 37%|███▋      | 183/500 [02:09<04:29,  1.17it/s] 37%|███▋      | 185/500 [02:09<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:09<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:09<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:15<06:04,  1.18s/it] 39%|███▊      | 193/500 [02:16<04:20,  1.18it/s] 39%|███▉      | 195/500 [02:16<03:07,  1.63it/s] 39%|███▉      | 197/500 [02:16<02:15,  2.23it/s] 40%|███▉      | 199/500 [02:16<01:40,  2.99it/s] 40%|████      | 201/500 [02:22<05:59,  1.20s/it] 41%|████      | 203/500 [02:23<04:16,  1.16it/s] 41%|████      | 205/500 [02:23<03:03,  1.60it/s] 41%|████▏     | 207/500 [02:23<02:13,  2.19it/s]0.00144678121432662
Valid Loss:  0.0019317393889650702
Epoch:  140  	Training Loss: 0.0018979362212121487
Test Loss:  0.0014467197470366955
Valid Loss:  0.0019316771067678928
Epoch:  141  	Training Loss: 0.001897866721265018
Test Loss:  0.0014466599095612764
Valid Loss:  0.0019316154066473246
Epoch:  142  	Training Loss: 0.0018977957079187036
Test Loss:  0.0014465989079326391
Valid Loss:  0.0019315584795549512
Epoch:  143  	Training Loss: 0.001897725509479642
Test Loss:  0.001446535810828209
Valid Loss:  0.001931492704898119
Epoch:  144  	Training Loss: 0.0018976547289639711
Test Loss:  0.0014464770210906863
Valid Loss:  0.0019314325181767344
Epoch:  145  	Training Loss: 0.0018975853454321623
Test Loss:  0.001446413341909647
Valid Loss:  0.0019313681405037642
Epoch:  146  	Training Loss: 0.0018975144485011697
Test Loss:  0.0014463544357568026
Valid Loss:  0.0019313055090606213
Epoch:  147  	Training Loss: 0.0018974440172314644
Test Loss:  0.0014462919207289815
Valid Loss:  0.001931245205923915
Epoch:  148  	Training Loss: 0.0018973733531311154
Test Loss:  0.0014462340623140335
Valid Loss:  0.001931182574480772
Epoch:  149  	Training Loss: 0.001897303620353341
Test Loss:  0.0014461709652096033
Valid Loss:  0.0019311185460537672
Epoch:  150  	Training Loss: 0.0018972328398376703
Test Loss:  0.0014461083337664604
Valid Loss:  0.0019310587085783482
Epoch:  151  	Training Loss: 0.0018971648532897234
Test Loss:  0.0014460482634603977
Valid Loss:  0.0019309924682602286
Epoch:  152  	Training Loss: 0.0018970947712659836
Test Loss:  0.001445989590138197
Valid Loss:  0.0019309301860630512
Epoch:  153  	Training Loss: 0.0018970246892422438
Test Loss:  0.0014459288213402033
Valid Loss:  0.0019308668561279774
Epoch:  154  	Training Loss: 0.0018969537923112512
Test Loss:  0.0014458693331107497
Valid Loss:  0.0019308060873299837
Epoch:  155  	Training Loss: 0.0018968854565173388
Test Loss:  0.001445814035832882
Valid Loss:  0.0019307432230561972
Epoch:  156  	Training Loss: 0.0018968168878927827
Test Loss:  0.0014457541983574629
Valid Loss:  0.0019306810572743416
Epoch:  157  	Training Loss: 0.0018967475043609738
Test Loss:  0.001445696922019124
Valid Loss:  0.001930617610923946
Epoch:  158  	Training Loss: 0.0018966777715831995
Test Loss:  0.001445635687559843
Valid Loss:  0.0019305564928799868
Epoch:  159  	Training Loss: 0.0018966090865433216
Test Loss:  0.0014455784112215042
Valid Loss:  0.001930493162944913
Epoch:  160  	Training Loss: 0.0018965404015034437
Test Loss:  0.0014455196214839816
Valid Loss:  0.0019304323941469193
Epoch:  161  	Training Loss: 0.0018964711343869567
Test Loss:  0.0014454596675932407
Valid Loss:  0.0019303668523207307
Epoch:  162  	Training Loss: 0.001896402332931757
Test Loss:  0.0014454011106863618
Valid Loss:  0.0019303036388009787
Epoch:  163  	Training Loss: 0.0018963328329846263
Test Loss:  0.0014453418552875519
Valid Loss:  0.0019302369328215718
Epoch:  164  	Training Loss: 0.0018962628673762083
Test Loss:  0.0014452798059210181
Valid Loss:  0.0019301758147776127
Epoch:  165  	Training Loss: 0.0018961940659210086
Test Loss:  0.0014452210161834955
Valid Loss:  0.0019301101565361023
Epoch:  166  	Training Loss: 0.0018961257301270962
Test Loss:  0.001445162808522582
Valid Loss:  0.0019300467101857066
Epoch:  167  	Training Loss: 0.0018960559973493218
Test Loss:  0.0014451025053858757
Valid Loss:  0.0019299826817587018
Epoch:  168  	Training Loss: 0.0018959882436320186
Test Loss:  0.0014450452290475368
Valid Loss:  0.0019299219129607081
Epoch:  169  	Training Loss: 0.0018959194421768188
Test Loss:  0.0014449870213866234
Valid Loss:  0.0019298586994409561
Epoch:  170  	Training Loss: 0.0018958497093990445
Test Loss:  0.0014449256705120206
Valid Loss:  0.0019297939725220203
Epoch:  171  	Training Loss: 0.0018957811407744884
Test Loss:  0.0014448694419115782
Valid Loss:  0.001929733669385314
Epoch:  172  	Training Loss: 0.0018957123393192887
Test Loss:  0.0014448101865127683
Valid Loss:  0.0019296681275591254
Epoch:  173  	Training Loss: 0.001895644934847951
Test Loss:  0.0014447519788518548
Valid Loss:  0.001929606543853879
Epoch:  174  	Training Loss: 0.0018955778796225786
Test Loss:  0.0014446936547756195
Valid Loss:  0.001929544610902667
Epoch:  175  	Training Loss: 0.001895509078167379
Test Loss:  0.0014446352142840624
Valid Loss:  0.0019294803496450186
Epoch:  176  	Training Loss: 0.0018954407423734665
Test Loss:  0.0014445765409618616
Valid Loss:  0.001929418183863163
Epoch:  177  	Training Loss: 0.0018953735707327724
Test Loss:  0.00144451844971627
Valid Loss:  0.0019293526420369744
Epoch:  178  	Training Loss: 0.001895305817015469
Test Loss:  0.0014444590779021382
Valid Loss:  0.0019292919896543026
Epoch:  179  	Training Loss: 0.001895238528959453
Test Loss:  0.0014444006374105811
Valid Loss:  0.0019292279612272978
Epoch:  180  	Training Loss: 0.0018951697275042534
Test Loss:  0.0014443404506891966
Valid Loss:  0.0019291628850623965
Epoch:  181  	Training Loss: 0.0018951023230329156
Test Loss:  0.0014442831743508577
Valid Loss:  0.001929101417772472
Epoch:  182  	Training Loss: 0.001895034802146256
Test Loss:  0.0014442249666899443
Valid Loss:  0.0019290391355752945
Epoch:  183  	Training Loss: 0.0018949672812595963
Test Loss:  0.0014441660605370998
Valid Loss:  0.0019289766205474734
Epoch:  184  	Training Loss: 0.0018949001096189022
Test Loss:  0.0014441090170294046
Valid Loss:  0.0019289152696728706
Epoch:  185  	Training Loss: 0.001894833636470139
Test Loss:  0.001444049645215273
Valid Loss:  0.001928848447278142
Epoch:  186  	Training Loss: 0.0018947641365230083
Test Loss:  0.0014439914375543594
Valid Loss:  0.001928789308294654
Epoch:  187  	Training Loss: 0.0018946980126202106
Test Loss:  0.0014439341612160206
Valid Loss:  0.0019287238828837872
Epoch:  188  	Training Loss: 0.0018946306081488729
Test Loss:  0.0014438768848776817
Valid Loss:  0.001928663463331759
Epoch:  189  	Training Loss: 0.0018945618066936731
Test Loss:  0.001443814137019217
Valid Loss:  0.0019286001333966851
Epoch:  190  	Training Loss: 0.0018944955663755536
Test Loss:  0.001443757675588131
Valid Loss:  0.0019285384332761168
Epoch:  191  	Training Loss: 0.0018944283947348595
Test Loss:  0.001443698420189321
Valid Loss:  0.0019284714944660664
Epoch:  192  	Training Loss: 0.0018943613395094872
Test Loss:  0.001443639979697764
Valid Loss:  0.0019284107256680727
Epoch:  193  	Training Loss: 0.001894294866360724
Test Loss:  0.001443582819774747
Valid Loss:  0.0019283494912087917
Epoch:  194  	Training Loss: 0.0018942260649055243
Test Loss:  0.001443524844944477
Valid Loss:  0.001928282785229385
Epoch:  195  	Training Loss: 0.0018941608723253012
Test Loss:  0.0014434652402997017
Valid Loss:  0.0019282195717096329
Epoch:  196  	Training Loss: 0.0018940935842692852
Test Loss:  0.001443406566977501
Valid Loss:  0.0019281578715890646
Epoch:  197  	Training Loss: 0.0018940280424430966
Test Loss:  0.001443347311578691
Valid Loss:  0.0019280926790088415
Epoch:  198  	Training Loss: 0.0018939613364636898
Test Loss:  0.0014432905009016395
Valid Loss:  0.0019280309788882732
Epoch:  199  	Training Loss: 0.0018938935827463865
Test Loss:  0.0014432328753173351
Valid Loss:  0.001927967881783843
Epoch:  200  	Training Loss: 0.0018938275752589107
Test Loss:  0.0014431752497330308
Valid Loss:  0.0019279064144939184
Epoch:  201  	Training Loss: 0.0018937615677714348
Test Loss:  0.0014431156450882554
Valid Loss:  0.0019278386607766151
Epoch:  202  	Training Loss: 0.0018936950946226716
Test Loss:  0.0014430586015805602
Valid Loss:  0.0019277837127447128
Epoch:  203  	Training Loss: 0.0018936297856271267
Test Loss:  0.0014430044684559107
Valid Loss:  0.0019277191022410989
Epoch:  204  	Training Loss: 0.0018935644766315818
Test Loss:  0.0014429471921175718
Valid Loss:  0.0019276603125035763
Epoch:  205  	Training Loss: 0.0018935003317892551
Test Loss:  0.001442890614271164
Valid Loss:  0.0019275976810604334
Epoch:  206  	Training Loss: 0.0018934349063783884
Test Loss:  0.0014428356662392616
Valid Loss:  0.0019275383092463017
Epoch:  207  	Training Loss: 0.00189337064512074
Test Loss:  0.0014427799033001065
Valid Loss:  0.001927476841956377
 42%|████▏     | 209/500 [02:23<01:38,  2.95it/s] 42%|████▏     | 211/500 [02:29<05:42,  1.19s/it] 43%|████▎     | 213/500 [02:29<04:04,  1.18it/s] 43%|████▎     | 215/500 [02:30<02:55,  1.63it/s] 43%|████▎     | 217/500 [02:30<02:07,  2.22it/s] 44%|████▍     | 219/500 [02:30<01:34,  2.97it/s] 44%|████▍     | 221/500 [02:36<05:33,  1.19s/it] 45%|████▍     | 223/500 [02:36<03:58,  1.16it/s] 45%|████▌     | 225/500 [02:37<02:51,  1.61it/s] 45%|████▌     | 227/500 [02:37<02:04,  2.19it/s] 46%|████▌     | 229/500 [02:37<01:31,  2.95it/s] 46%|████▌     | 231/500 [02:43<05:16,  1.18s/it] 47%|████▋     | 233/500 [02:43<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:43<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:44<01:57,  2.23it/s] 48%|████▊     | 239/500 [02:44<01:26,  3.00it/s] 48%|████▊     | 241/500 [02:50<05:06,  1.18s/it] 49%|████▊     | 243/500 [02:50<03:38,  1.18it/s] 49%|████▉     | 245/500 [02:50<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:50<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:51<01:23,  2.99it/s] 50%|█████     | 251/500 [02:57<04:53,  1.18s/it] 51%|█████     | 253/500 [02:57<03:29,  1.18it/s] 51%|█████     | 255/500 [02:57<02:30,  1.63it/s] 51%|█████▏    | 257/500 [02:57<01:48,  2.23it/s] 52%|█████▏    | 259/500 [02:57<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:04<04:43,  1.18s/it] 53%|█████▎    | 263/500 [03:04<03:21,  1.18it/s] 53%|█████▎    | 265/500 [03:04<02:24,  1.63it/s] 53%|█████▎    | 267/500 [03:04<01:44,  2.23it/s] 54%|█████▍    | 269/500 [03:04<01:17,  2.99it/s] 54%|█████▍    | 271/500 [03:11<04:31,  1.19s/it] 55%|█████▍    | 273/500 [03:11<03:13,  1.17it/s] 55%|█████▌    | 275/500 [03:11<02:18,  1.62it/s]Epoch:  208  	Training Loss: 0.0018933049868792295
Test Loss:  0.0014427248388528824
Valid Loss:  0.0019274188671261072
Epoch:  209  	Training Loss: 0.001893240842036903
Test Loss:  0.0014426687266677618
Valid Loss:  0.0019273555371910334
Epoch:  210  	Training Loss: 0.0018931750673800707
Test Loss:  0.001442612148821354
Valid Loss:  0.0019272958161309361
Epoch:  211  	Training Loss: 0.0018931101076304913
Test Loss:  0.0014425583649426699
Valid Loss:  0.0019272355129942298
Epoch:  212  	Training Loss: 0.0018930451478809118
Test Loss:  0.0014425020199269056
Valid Loss:  0.0019271713681519032
Epoch:  213  	Training Loss: 0.0018929801881313324
Test Loss:  0.0014424404362216592
Valid Loss:  0.0019271066412329674
Epoch:  214  	Training Loss: 0.0018929140642285347
Test Loss:  0.0014423835091292858
Valid Loss:  0.0019270458724349737
Epoch:  215  	Training Loss: 0.001892847241833806
Test Loss:  0.0014423278626054525
Valid Loss:  0.0019269816111773252
Epoch:  216  	Training Loss: 0.0018927822820842266
Test Loss:  0.001442269654944539
Valid Loss:  0.001926920609548688
Epoch:  217  	Training Loss: 0.0018927145283669233
Test Loss:  0.0014422116801142693
Valid Loss:  0.0019268568139523268
Epoch:  218  	Training Loss: 0.0018926511984318495
Test Loss:  0.0014421562664210796
Valid Loss:  0.0019267946481704712
Epoch:  219  	Training Loss: 0.0018925843760371208
Test Loss:  0.0014420985244214535
Valid Loss:  0.0019267324823886156
Epoch:  220  	Training Loss: 0.0018925184849649668
Test Loss:  0.0014420407824218273
Valid Loss:  0.0019266679883003235
Epoch:  221  	Training Loss: 0.001892452361062169
Test Loss:  0.0014419832732528448
Valid Loss:  0.001926606404595077
Epoch:  222  	Training Loss: 0.0018923875177279115
Test Loss:  0.001441925298422575
Valid Loss:  0.0019265448208898306
Epoch:  223  	Training Loss: 0.0018923224415630102
Test Loss:  0.001441870117560029
Valid Loss:  0.0019264852162450552
Epoch:  224  	Training Loss: 0.001892254687845707
Test Loss:  0.0014418133068829775
Valid Loss:  0.0019264195580035448
Epoch:  225  	Training Loss: 0.0018921892624348402
Test Loss:  0.0014417569618672132
Valid Loss:  0.0019263598369434476
Epoch:  226  	Training Loss: 0.0018921236041933298
Test Loss:  0.0014416989870369434
Valid Loss:  0.0019262948771938682
Epoch:  227  	Training Loss: 0.0018920587608590722
Test Loss:  0.0014416433405131102
Valid Loss:  0.0019262352725490928
Epoch:  228  	Training Loss: 0.00189199298620224
Test Loss:  0.001441585598513484
Valid Loss:  0.0019261733395978808
Epoch:  229  	Training Loss: 0.0018919282592833042
Test Loss:  0.001441527041606605
Valid Loss:  0.0019261102424934506
Epoch:  230  	Training Loss: 0.0018918607383966446
Test Loss:  0.0014414708130061626
Valid Loss:  0.0019260469125583768
Epoch:  231  	Training Loss: 0.0018917950801551342
Test Loss:  0.0014414133038371801
Valid Loss:  0.0019259849796071649
Epoch:  232  	Training Loss: 0.0018917301204055548
Test Loss:  0.001441358937881887
Valid Loss:  0.0019259279360994697
Epoch:  233  	Training Loss: 0.0018916651606559753
Test Loss:  0.0014413028256967664
Valid Loss:  0.0019258634420111775
Epoch:  234  	Training Loss: 0.0018915992695838213
Test Loss:  0.0014412475284188986
Valid Loss:  0.001925803255289793
Epoch:  235  	Training Loss: 0.00189153419341892
Test Loss:  0.0014411904849112034
Valid Loss:  0.0019257394596934319
Epoch:  236  	Training Loss: 0.0018914693500846624
Test Loss:  0.0014411353040486574
Valid Loss:  0.001925680786371231
Epoch:  237  	Training Loss: 0.0018914054380729795
Test Loss:  0.0014410762814804912
Valid Loss:  0.0019256164086982608
Epoch:  238  	Training Loss: 0.0018913389649242163
Test Loss:  0.0014410216826945543
Valid Loss:  0.0019255538936704397
Epoch:  239  	Training Loss: 0.0018912756349891424
Test Loss:  0.0014409637078642845
Valid Loss:  0.0019254949875175953
Epoch:  240  	Training Loss: 0.0018912096275016665
Test Loss:  0.0014409091090783477
Valid Loss:  0.0019254336366429925
Epoch:  241  	Training Loss: 0.0018911443185061216
Test Loss:  0.0014408519491553307
Valid Loss:  0.0019253726350143552
Epoch:  242  	Training Loss: 0.001891078893095255
Test Loss:  0.00144079583697021
Valid Loss:  0.0019253084901720285
Epoch:  243  	Training Loss: 0.0018910137005150318
Test Loss:  0.001440740656107664
Valid Loss:  0.001925247022882104
Epoch:  244  	Training Loss: 0.0018909501377493143
Test Loss:  0.0014406805858016014
Valid Loss:  0.0019251862540841103
Epoch:  245  	Training Loss: 0.0018908859929069877
Test Loss:  0.0014406258706003428
Valid Loss:  0.0019251240883022547
Epoch:  246  	Training Loss: 0.0018908192869275808
Test Loss:  0.001440569176338613
Valid Loss:  0.0019250591285526752
Epoch:  247  	Training Loss: 0.0018907557241618633
Test Loss:  0.0014405129477381706
Valid Loss:  0.0019249991746619344
Epoch:  248  	Training Loss: 0.0018906916957348585
Test Loss:  0.0014404560206457973
Valid Loss:  0.0019249378237873316
Epoch:  249  	Training Loss: 0.00189062743447721
Test Loss:  0.0014404014218598604
Valid Loss:  0.0019248744938522577
Epoch:  250  	Training Loss: 0.0018905624747276306
Test Loss:  0.001440343912690878
Valid Loss:  0.0019248127937316895
Epoch:  251  	Training Loss: 0.0018904993776232004
Test Loss:  0.001440288033336401
Valid Loss:  0.001924753189086914
Epoch:  252  	Training Loss: 0.001890433020889759
Test Loss:  0.0014402330853044987
Valid Loss:  0.0019246942829340696
Epoch:  253  	Training Loss: 0.0018903699237853289
Test Loss:  0.0014401780208572745
Valid Loss:  0.0019246329320594668
Epoch:  254  	Training Loss: 0.0018903044983744621
Test Loss:  0.0014401203952729702
Valid Loss:  0.0019245690200477839
Epoch:  255  	Training Loss: 0.0018902408191934228
Test Loss:  0.0014400627696886659
Valid Loss:  0.0019245079020038247
Epoch:  256  	Training Loss: 0.0018901762086898088
Test Loss:  0.0014400093350559473
Valid Loss:  0.0019244491122663021
Epoch:  257  	Training Loss: 0.0018901112489402294
Test Loss:  0.0014399525243788958
Valid Loss:  0.0019243842689320445
Epoch:  258  	Training Loss: 0.0018900467548519373
Test Loss:  0.0014398954808712006
Valid Loss:  0.0019243239657953382
Epoch:  259  	Training Loss: 0.0018899833085015416
Test Loss:  0.0014398399507626891
Valid Loss:  0.0019242661073803902
Epoch:  260  	Training Loss: 0.0018899190472438931
Test Loss:  0.0014397853519767523
Valid Loss:  0.0019242059206590056
Epoch:  261  	Training Loss: 0.0018898560665547848
Test Loss:  0.0014397272607311606
Valid Loss:  0.001924141775816679
Epoch:  262  	Training Loss: 0.001889790059067309
Test Loss:  0.0014396758051589131
Valid Loss:  0.001924081239849329
Epoch:  263  	Training Loss: 0.0018897268455475569
Test Loss:  0.0014396185288205743
Valid Loss:  0.0019240211695432663
Epoch:  264  	Training Loss: 0.001889662235043943
Test Loss:  0.0014395636972039938
Valid Loss:  0.0019239590037614107
Epoch:  265  	Training Loss: 0.0018895980902016163
Test Loss:  0.0014395085163414478
Valid Loss:  0.0019239006796851754
Epoch:  266  	Training Loss: 0.0018895339453592896
Test Loss:  0.0014394531026482582
Valid Loss:  0.0019238393288105726
Epoch:  267  	Training Loss: 0.0018894706154242158
Test Loss:  0.0014393988531082869
Valid Loss:  0.001923779142089188
Epoch:  268  	Training Loss: 0.00188940588850528
Test Loss:  0.0014393418096005917
Valid Loss:  0.001923720701597631
Epoch:  269  	Training Loss: 0.0018893429078161716
Test Loss:  0.0014392868615686893
Valid Loss:  0.0019236588850617409
Epoch:  270  	Training Loss: 0.0018892782973125577
Test Loss:  0.001439231913536787
Valid Loss:  0.0019236020743846893
Epoch:  271  	Training Loss: 0.001889212871901691
Test Loss:  0.0014391751028597355
Valid Loss:  0.0019235361833125353
Epoch:  272  	Training Loss: 0.0018891494255512953
Test Loss:  0.0014391223667189479
Valid Loss:  0.0019234770443290472
Epoch:  273  	Training Loss: 0.0018890869105234742
Test Loss:  0.0014390656724572182
Valid Loss:  0.0019234197679907084
Epoch:  274  	Training Loss: 0.0018890236970037222
Test Loss:  0.0014390102587640285
Valid Loss:  0.0019233569037169218
Epoch:  275  	Training Loss: 0.0018889597849920392
Test Loss:  0.0014389557763934135
Valid Loss:  0.0019232967169955373
Epoch:  276  	Training Loss: 0.0018888949416577816
Test Loss:   55%|█████▌    | 277/500 [03:11<01:40,  2.22it/s] 56%|█████▌    | 279/500 [03:11<01:14,  2.99it/s] 56%|█████▌    | 281/500 [03:17<04:21,  1.19s/it] 57%|█████▋    | 283/500 [03:18<03:06,  1.17it/s] 57%|█████▋    | 285/500 [03:18<02:13,  1.61it/s] 57%|█████▋    | 287/500 [03:18<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:18<01:11,  2.97it/s] 58%|█████▊    | 291/500 [03:24<04:08,  1.19s/it] 59%|█████▊    | 293/500 [03:25<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:25<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:25<01:31,  2.21it/s] 60%|█████▉    | 299/500 [03:25<01:07,  2.98it/s] 60%|██████    | 301/500 [03:31<03:55,  1.19s/it] 61%|██████    | 303/500 [03:31<02:47,  1.17it/s] 61%|██████    | 305/500 [03:32<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:32<01:26,  2.22it/s] 62%|██████▏   | 309/500 [03:32<01:04,  2.98it/s] 62%|██████▏   | 311/500 [03:38<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:38<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:38<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:39<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:39<01:00,  2.99it/s] 64%|██████▍   | 321/500 [03:45<03:30,  1.17s/it] 65%|██████▍   | 323/500 [03:45<02:29,  1.19it/s] 65%|██████▌   | 325/500 [03:45<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:45<01:17,  2.24it/s] 66%|██████▌   | 329/500 [03:45<00:56,  3.01it/s] 66%|██████▌   | 331/500 [03:52<03:20,  1.19s/it] 67%|██████▋   | 333/500 [03:52<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:52<01:41,  1.62it/s] 67%|██████▋   | 337/500 [03:52<01:13,  2.21it/s] 68%|██████▊   | 339/500 [03:52<00:54,  2.97it/s] 68%|██████▊   | 341/500 [03:59<03:07,  1.18s/it] 69%|██████▊   | 343/500 [03:59<02:13,  1.18it/s]0.0014389001298695803
Valid Loss:  0.0019232373451814055
Epoch:  277  	Training Loss: 0.0018888316117227077
Test Loss:  0.001438845181837678
Valid Loss:  0.0019231768092140555
Epoch:  278  	Training Loss: 0.0018887680489569902
Test Loss:  0.001438787905499339
Valid Loss:  0.001923118019476533
Epoch:  279  	Training Loss: 0.0018887050682678819
Test Loss:  0.0014387344708666205
Valid Loss:  0.0019230550387874246
Epoch:  280  	Training Loss: 0.0018886409234255552
Test Loss:  0.001438678940758109
Valid Loss:  0.0019229974132031202
Epoch:  281  	Training Loss: 0.0018885766621679068
Test Loss:  0.001438621198758483
Valid Loss:  0.0019229359459131956
Epoch:  282  	Training Loss: 0.0018885137978941202
Test Loss:  0.00143857067450881
Valid Loss:  0.001922878553159535
Epoch:  283  	Training Loss: 0.0018884505843743682
Test Loss:  0.001438515610061586
Valid Loss:  0.0019228197634220123
Epoch:  284  	Training Loss: 0.0018883878365159035
Test Loss:  0.0014384619425982237
Valid Loss:  0.001922763418406248
Epoch:  285  	Training Loss: 0.001888324972242117
Test Loss:  0.0014384074602276087
Valid Loss:  0.0019227031152695417
Epoch:  286  	Training Loss: 0.001888261642307043
Test Loss:  0.0014383518137037754
Valid Loss:  0.0019226442091166973
Epoch:  287  	Training Loss: 0.0018881987780332565
Test Loss:  0.0014382979134097695
Valid Loss:  0.0019225870491936803
Epoch:  288  	Training Loss: 0.0018881350988522172
Test Loss:  0.0014382442459464073
Valid Loss:  0.0019225252326577902
Epoch:  289  	Training Loss: 0.0018880721181631088
Test Loss:  0.001438188599422574
Valid Loss:  0.001922468189150095
Epoch:  290  	Training Loss: 0.0018880097195506096
Test Loss:  0.0014381349319592118
Valid Loss:  0.001922408351674676
Epoch:  291  	Training Loss: 0.001887946156784892
Test Loss:  0.0014380814973264933
Valid Loss:  0.0019223496783524752
Epoch:  292  	Training Loss: 0.0018878845730796456
Test Loss:  0.0014380246866494417
Valid Loss:  0.0019222891423851252
Epoch:  293  	Training Loss: 0.001887819729745388
Test Loss:  0.0014379722997546196
Valid Loss:  0.0019222309347242117
Epoch:  294  	Training Loss: 0.001887757214717567
Test Loss:  0.0014379185158759356
Valid Loss:  0.0019221731927245855
Epoch:  295  	Training Loss: 0.0018876942340284586
Test Loss:  0.0014378618216142058
Valid Loss:  0.001922115683555603
Epoch:  296  	Training Loss: 0.0018876309040933847
Test Loss:  0.001437808503396809
Valid Loss:  0.0019220539834350348
Epoch:  297  	Training Loss: 0.001887565478682518
Test Loss:  0.0014377522747963667
Valid Loss:  0.001921996707096696
Epoch:  298  	Training Loss: 0.0018875026144087315
Test Loss:  0.001437696861103177
Valid Loss:  0.0019219355890527368
Epoch:  299  	Training Loss: 0.001887440332211554
Test Loss:  0.0014376428443938494
Valid Loss:  0.0019218737725168467
Epoch:  300  	Training Loss: 0.001887377118691802
Test Loss:  0.0014375889440998435
Valid Loss:  0.0019218171946704388
Epoch:  301  	Training Loss: 0.0018873142544180155
Test Loss:  0.0014375337632372975
Valid Loss:  0.0019217557273805141
Epoch:  302  	Training Loss: 0.0018872511573135853
Test Loss:  0.0014374805614352226
Valid Loss:  0.0019216989167034626
Epoch:  303  	Training Loss: 0.0018871868960559368
Test Loss:  0.001437424449250102
Valid Loss:  0.0019216365180909634
Epoch:  304  	Training Loss: 0.0018871240317821503
Test Loss:  0.0014373685698956251
Valid Loss:  0.00192158087156713
Epoch:  305  	Training Loss: 0.0018870625644922256
Test Loss:  0.0014373131562024355
Valid Loss:  0.001921519753523171
Epoch:  306  	Training Loss: 0.0018869985360652208
Test Loss:  0.0014372598379850388
Valid Loss:  0.0019214584026485682
Epoch:  307  	Training Loss: 0.0018869368359446526
Test Loss:  0.0014372053556144238
Valid Loss:  0.001921400660648942
Epoch:  308  	Training Loss: 0.0018868745537474751
Test Loss:  0.0014371522702276707
Valid Loss:  0.0019213424529880285
Epoch:  309  	Training Loss: 0.0018868113402277231
Test Loss:  0.0014370959252119064
Valid Loss:  0.001921282266266644
Epoch:  310  	Training Loss: 0.0018867491744458675
Test Loss:  0.0014370402786880732
Valid Loss:  0.001921221031807363
Epoch:  311  	Training Loss: 0.0018866858445107937
Test Loss:  0.0014369875425472856
Valid Loss:  0.0019211610779166222
Epoch:  312  	Training Loss: 0.0018866229802370071
Test Loss:  0.0014369329437613487
Valid Loss:  0.001921102055348456
Epoch:  313  	Training Loss: 0.001886560581624508
Test Loss:  0.001436880324035883
Valid Loss:  0.0019210452446714044
Epoch:  314  	Training Loss: 0.0018864981830120087
Test Loss:  0.001436824444681406
Valid Loss:  0.001920985640026629
Epoch:  315  	Training Loss: 0.0018864357843995094
Test Loss:  0.0014367704279720783
Valid Loss:  0.0019209247548133135
Epoch:  316  	Training Loss: 0.001886372221633792
Test Loss:  0.001436716876924038
Valid Loss:  0.0019208634039387107
Epoch:  317  	Training Loss: 0.0018863120349124074
Test Loss:  0.0014366611139848828
Valid Loss:  0.0019208064768463373
Epoch:  318  	Training Loss: 0.0018862498691305518
Test Loss:  0.0014366073301061988
Valid Loss:  0.0019207483856007457
Epoch:  319  	Training Loss: 0.0018861860735341907
Test Loss:  0.0014365531969815493
Valid Loss:  0.0019206898286938667
Epoch:  320  	Training Loss: 0.0018861234420910478
Test Loss:  0.0014364990638568997
Valid Loss:  0.001920630456879735
Epoch:  321  	Training Loss: 0.001886062091216445
Test Loss:  0.0014364435337483883
Valid Loss:  0.0019205682910978794
Epoch:  322  	Training Loss: 0.0018859991105273366
Test Loss:  0.0014363923110067844
Valid Loss:  0.0019205119460821152
Epoch:  323  	Training Loss: 0.0018859365954995155
Test Loss:  0.001436334801837802
Valid Loss:  0.001920452807098627
Epoch:  324  	Training Loss: 0.0018858746625483036
Test Loss:  0.0014362813672050834
Valid Loss:  0.0019203939009457827
Epoch:  325  	Training Loss: 0.0018858129624277353
Test Loss:  0.001436229096725583
Valid Loss:  0.0019203319679945707
Epoch:  326  	Training Loss: 0.0018857500981539488
Test Loss:  0.0014361736830323935
Valid Loss:  0.0019202734110876918
Epoch:  327  	Training Loss: 0.0018856881652027369
Test Loss:  0.0014361197827383876
Valid Loss:  0.0019202139228582382
Epoch:  328  	Training Loss: 0.001885625533759594
Test Loss:  0.001436064951121807
Valid Loss:  0.001920158858411014
Epoch:  329  	Training Loss: 0.0018855612725019455
Test Loss:  0.0014360100030899048
Valid Loss:  0.0019200982060283422
Epoch:  330  	Training Loss: 0.0018855007365345955
Test Loss:  0.001435957383364439
Valid Loss:  0.0019200386013835669
Epoch:  331  	Training Loss: 0.001885437872260809
Test Loss:  0.001435903599485755
Valid Loss:  0.0019199815578758717
Epoch:  332  	Training Loss: 0.001885375240817666
Test Loss:  0.0014358493499457836
Valid Loss:  0.0019199233502149582
Epoch:  333  	Training Loss: 0.0018853130750358105
Test Loss:  0.0014357967302203178
Valid Loss:  0.0019198625814169645
Epoch:  334  	Training Loss: 0.0018852511420845985
Test Loss:  0.0014357430627569556
Valid Loss:  0.0019198056543245912
Epoch:  335  	Training Loss: 0.0018851908389478922
Test Loss:  0.0014356888132169843
Valid Loss:  0.00191974313929677
Epoch:  336  	Training Loss: 0.001885129022412002
Test Loss:  0.0014356361934915185
Valid Loss:  0.0019196881912648678
Epoch:  337  	Training Loss: 0.0018850675551220775
Test Loss:  0.0014355811290442944
Valid Loss:  0.0019196299836039543
Epoch:  338  	Training Loss: 0.001885005971416831
Test Loss:  0.0014355293242260814
Valid Loss:  0.0019195728236809373
Epoch:  339  	Training Loss: 0.0018849432235583663
Test Loss:  0.0014354741433635354
Valid Loss:  0.0019195127533748746
Epoch:  340  	Training Loss: 0.0018848816398531199
Test Loss:  0.0014354207087308168
Valid Loss:  0.001919453265145421
Epoch:  341  	Training Loss: 0.0018848192412406206
Test Loss:  0.001435368089005351
Valid Loss:  0.0019193985499441624
Epoch:  342  	Training Loss: 0.001884757075458765
Test Loss:  0.001435315003618598
Valid Loss:  0.0019193425541743636
Epoch:  343  	Training Loss: 0.001884695840999484
Test Loss:  0.0014352597063407302
Valid Loss:  0.0019192819017916918
Epoch:  344  	Training Loss: 0.0018846356542780995
Test Loss:  0.001435206038877368
Valid Loss:  0.001919221831485629
 69%|██████▉   | 345/500 [03:59<01:35,  1.63it/s] 69%|██████▉   | 347/500 [03:59<01:08,  2.22it/s] 70%|██████▉   | 349/500 [03:59<00:50,  2.99it/s] 70%|███████   | 351/500 [04:06<02:55,  1.18s/it] 71%|███████   | 353/500 [04:06<02:04,  1.18it/s] 71%|███████   | 355/500 [04:06<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:06<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:06<00:46,  3.01it/s] 72%|███████▏  | 361/500 [04:12<02:41,  1.17s/it] 73%|███████▎  | 363/500 [04:12<01:54,  1.19it/s] 73%|███████▎  | 365/500 [04:13<01:21,  1.65it/s] 73%|███████▎  | 367/500 [04:13<00:59,  2.25it/s] 74%|███████▍  | 369/500 [04:13<00:43,  3.02it/s] 74%|███████▍  | 371/500 [04:19<02:29,  1.16s/it] 75%|███████▍  | 373/500 [04:19<01:45,  1.20it/s] 75%|███████▌  | 375/500 [04:19<01:15,  1.66it/s] 75%|███████▌  | 377/500 [04:19<00:54,  2.26it/s] 76%|███████▌  | 379/500 [04:20<00:39,  3.04it/s] 76%|███████▌  | 381/500 [04:26<02:17,  1.16s/it] 77%|███████▋  | 383/500 [04:26<01:37,  1.20it/s] 77%|███████▋  | 385/500 [04:26<01:09,  1.66it/s] 77%|███████▋  | 387/500 [04:26<00:49,  2.27it/s] 78%|███████▊  | 389/500 [04:26<00:36,  3.04it/s] 78%|███████▊  | 391/500 [04:32<02:06,  1.16s/it] 79%|███████▊  | 393/500 [04:33<01:29,  1.20it/s] 79%|███████▉  | 395/500 [04:33<01:03,  1.66it/s] 79%|███████▉  | 397/500 [04:33<00:45,  2.26it/s] 80%|███████▉  | 399/500 [04:33<00:33,  3.00it/s] 80%|████████  | 401/500 [04:39<01:55,  1.17s/it] 81%|████████  | 403/500 [04:39<01:21,  1.19it/s] 81%|████████  | 405/500 [04:40<00:57,  1.65it/s] 81%|████████▏ | 407/500 [04:40<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:40<00:30,  3.02it/s] 82%|████████▏ | 411/500 [04:46<01:45,  1.19s/it]Epoch:  345  	Training Loss: 0.0018845738377422094
Test Loss:  0.001435152254998684
Valid Loss:  0.0019191682804375887
Epoch:  346  	Training Loss: 0.001884511555545032
Test Loss:  0.0014350984711199999
Valid Loss:  0.001919108908623457
Epoch:  347  	Training Loss: 0.001884451019577682
Test Loss:  0.0014350457349792123
Valid Loss:  0.0019190452294424176
Epoch:  348  	Training Loss: 0.0018843908328562975
Test Loss:  0.0014349925331771374
Valid Loss:  0.0019189901649951935
Epoch:  349  	Training Loss: 0.0018843284342437983
Test Loss:  0.0014349407283589244
Valid Loss:  0.0019189331214874983
Epoch:  350  	Training Loss: 0.0018842670833691955
Test Loss:  0.0014348867116495967
Valid Loss:  0.0019188746809959412
Epoch:  351  	Training Loss: 0.0018842052668333054
Test Loss:  0.0014348311815410852
Valid Loss:  0.0019188157748430967
Epoch:  352  	Training Loss: 0.0018841454293578863
Test Loss:  0.001434780191630125
Valid Loss:  0.0019187612924724817
Epoch:  353  	Training Loss: 0.0018840825650840998
Test Loss:  0.0014347254764288664
Valid Loss:  0.0019187018042430282
Epoch:  354  	Training Loss: 0.0018840222619473934
Test Loss:  0.0014346730895340443
Valid Loss:  0.0019186465069651604
Epoch:  355  	Training Loss: 0.0018839605618268251
Test Loss:  0.0014346197713166475
Valid Loss:  0.0019185857381671667
Epoch:  356  	Training Loss: 0.0018838983960449696
Test Loss:  0.0014345659874379635
Valid Loss:  0.001918531721457839
Epoch:  357  	Training Loss: 0.0018838373944163322
Test Loss:  0.0014345129020512104
Valid Loss:  0.0019184722332283854
Epoch:  358  	Training Loss: 0.0018837766256183386
Test Loss:  0.001434460747987032
Valid Loss:  0.0019184163538739085
Epoch:  359  	Training Loss: 0.0018837159732356668
Test Loss:  0.0014344081282615662
Valid Loss:  0.0019183591939508915
Epoch:  360  	Training Loss: 0.0018836550880223513
Test Loss:  0.0014343538787215948
Valid Loss:  0.0019182973774150014
Epoch:  361  	Training Loss: 0.001883594086393714
Test Loss:  0.001434303354471922
Valid Loss:  0.0019182413816452026
Epoch:  362  	Training Loss: 0.0018835330847650766
Test Loss:  0.001434248872101307
Valid Loss:  0.0019181828247383237
Epoch:  363  	Training Loss: 0.0018834739457815886
Test Loss:  0.0014341957867145538
Valid Loss:  0.0019181269453838468
Epoch:  364  	Training Loss: 0.0018834113143384457
Test Loss:  0.0014341442147269845
Valid Loss:  0.0019180693197995424
Epoch:  365  	Training Loss: 0.0018833511276170611
Test Loss:  0.0014340928755700588
Valid Loss:  0.0019180134404450655
Epoch:  366  	Training Loss: 0.0018832895439118147
Test Loss:  0.0014340376947075129
Valid Loss:  0.0019179587252438068
Epoch:  367  	Training Loss: 0.001883228775113821
Test Loss:  0.0014339876361191273
Valid Loss:  0.0019179016817361116
Epoch:  368  	Training Loss: 0.001883168239146471
Test Loss:  0.0014339345507323742
Valid Loss:  0.0019178437069058418
Epoch:  369  	Training Loss: 0.001883109798654914
Test Loss:  0.0014338807668536901
Valid Loss:  0.001917783753015101
Epoch:  370  	Training Loss: 0.0018830480985343456
Test Loss:  0.0014338286127895117
Valid Loss:  0.001917728572152555
Epoch:  371  	Training Loss: 0.001882987329736352
Test Loss:  0.0014337761094793677
Valid Loss:  0.0019176724599674344
Epoch:  372  	Training Loss: 0.001882926793769002
Test Loss:  0.0014337250031530857
Valid Loss:  0.0019176206551492214
Epoch:  373  	Training Loss: 0.0018828671891242266
Test Loss:  0.001433671684935689
Valid Loss:  0.0019175633788108826
Epoch:  374  	Training Loss: 0.0018828078173100948
Test Loss:  0.0014336202293634415
Valid Loss:  0.001917507266625762
Epoch:  375  	Training Loss: 0.0018827492604032159
Test Loss:  0.001433568773791194
Valid Loss:  0.0019174517365172505
Epoch:  376  	Training Loss: 0.0018826889572665095
Test Loss:  0.001433518249541521
Valid Loss:  0.0019173952750861645
Epoch:  377  	Training Loss: 0.0018826298182830215
Test Loss:  0.0014334656298160553
Valid Loss:  0.001917341141961515
Epoch:  378  	Training Loss: 0.0018825712613761425
Test Loss:  0.0014334142906591296
Valid Loss:  0.0019172823522239923
Epoch:  379  	Training Loss: 0.0018825122388079762
Test Loss:  0.0014333619037643075
Valid Loss:  0.0019172290340065956
Epoch:  380  	Training Loss: 0.001882451819255948
Test Loss:  0.0014333113795146346
Valid Loss:  0.0019171710591763258
Epoch:  381  	Training Loss: 0.001882393378764391
Test Loss:  0.0014332608552649617
Valid Loss:  0.001917111687362194
Epoch:  382  	Training Loss: 0.001882334123365581
Test Loss:  0.0014332096325233579
Valid Loss:  0.0019170602317899466
Epoch:  383  	Training Loss: 0.0018822732381522655
Test Loss:  0.0014331541024148464
Valid Loss:  0.0019170026062056422
Epoch:  384  	Training Loss: 0.0018822134006768465
Test Loss:  0.0014331021811813116
Valid Loss:  0.0019169447477906942
Epoch:  385  	Training Loss: 0.0018821521662175655
Test Loss:  0.0014330516569316387
Valid Loss:  0.0019168866565451026
Epoch:  386  	Training Loss: 0.0018820917466655374
Test Loss:  0.0014329957775771618
Valid Loss:  0.001916829263791442
Epoch:  387  	Training Loss: 0.001882031443528831
Test Loss:  0.0014329456025734544
Valid Loss:  0.0019167748978361487
Epoch:  388  	Training Loss: 0.001881972188130021
Test Loss:  0.0014328948454931378
Valid Loss:  0.0019167156424373388
Epoch:  389  	Training Loss: 0.0018819115357473493
Test Loss:  0.0014328437391668558
Valid Loss:  0.0019166618585586548
Epoch:  390  	Training Loss: 0.0018818516982719302
Test Loss:  0.0014327897224575281
Valid Loss:  0.001916605862788856
Epoch:  391  	Training Loss: 0.0018817909294739366
Test Loss:  0.0014327362878248096
Valid Loss:  0.001916547422297299
Epoch:  392  	Training Loss: 0.0018817312084138393
Test Loss:  0.0014326864620670676
Valid Loss:  0.0019164932891726494
Epoch:  393  	Training Loss: 0.0018816717201843858
Test Loss:  0.0014326327946037054
Valid Loss:  0.0019164327532052994
Epoch:  394  	Training Loss: 0.0018816108349710703
Test Loss:  0.0014325820375233889
Valid Loss:  0.0019163796678185463
Epoch:  395  	Training Loss: 0.0018815509974956512
Test Loss:  0.0014325279043987393
Valid Loss:  0.0019163195975124836
Epoch:  396  	Training Loss: 0.0018814923241734505
Test Loss:  0.0014324784278869629
Valid Loss:  0.0019162653479725122
Epoch:  397  	Training Loss: 0.0018814330687746406
Test Loss:  0.0014324263902381063
Valid Loss:  0.0019162100506946445
Epoch:  398  	Training Loss: 0.0018813718343153596
Test Loss:  0.0014323733048513532
Valid Loss:  0.0019161561504006386
Epoch:  399  	Training Loss: 0.001881311647593975
Test Loss:  0.0014323240611702204
Valid Loss:  0.0019160960800945759
Epoch:  400  	Training Loss: 0.0018812536727637053
Test Loss:  0.001432271208614111
Valid Loss:  0.001916038105264306
Epoch:  401  	Training Loss: 0.0018811918562278152
Test Loss:  0.0014322178903967142
Valid Loss:  0.001915983040817082
Epoch:  402  	Training Loss: 0.0018811350455507636
Test Loss:  0.0014321678318083286
Valid Loss:  0.001915928442031145
Epoch:  403  	Training Loss: 0.0018810741603374481
Test Loss:  0.0014321156777441502
Valid Loss:  0.0019158727955073118
Epoch:  404  	Training Loss: 0.001881014322862029
Test Loss:  0.0014320630580186844
Valid Loss:  0.0019158140057697892
Epoch:  405  	Training Loss: 0.0018809556495398283
Test Loss:  0.001432010903954506
Valid Loss:  0.0019157568458467722
Epoch:  406  	Training Loss: 0.0018808969762176275
Test Loss:  0.001431959681212902
Valid Loss:  0.0019156993366777897
Epoch:  407  	Training Loss: 0.001880835392512381
Test Loss:  0.0014319091569632292
Valid Loss:  0.0019156452035531402
Epoch:  408  	Training Loss: 0.001880776952020824
Test Loss:  0.0014318593312054873
Valid Loss:  0.0019155906047672033
Epoch:  409  	Training Loss: 0.001880716998130083
Test Loss:  0.0014318060129880905
Valid Loss:  0.0019155326299369335
Epoch:  410  	Training Loss: 0.0018806590232998133
Test Loss:  0.001431753858923912
Valid Loss:  0.0019154769834131002
Epoch:  411  	Training Loss: 0.0018805982545018196
Test Loss:  0.0014317010063678026
Valid Loss:  0.001915421336889267
Epoch:  412  	Training Loss: 0.001880538184195757
Test Loss:  0.001431650365702808
Valid Loss:  0.0019153621979057789
Epoch:  413  	Training Loss: 0.001880479627288878
Test Loss:   83%|████████▎ | 413/500 [04:46<01:14,  1.17it/s] 83%|████████▎ | 415/500 [04:46<00:52,  1.62it/s] 83%|████████▎ | 417/500 [04:47<00:37,  2.21it/s] 84%|████████▍ | 419/500 [04:47<00:27,  2.97it/s] 84%|████████▍ | 421/500 [04:53<01:33,  1.19s/it] 85%|████████▍ | 423/500 [04:53<01:05,  1.17it/s] 85%|████████▌ | 425/500 [04:53<00:46,  1.62it/s] 85%|████████▌ | 427/500 [04:54<00:33,  2.20it/s] 86%|████████▌ | 429/500 [04:54<00:24,  2.95it/s] 86%|████████▌ | 431/500 [05:00<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:00<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:00<00:39,  1.64it/s] 87%|████████▋ | 437/500 [05:00<00:28,  2.24it/s] 88%|████████▊ | 439/500 [05:00<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:07<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:07<00:48,  1.19it/s] 89%|████████▉ | 445/500 [05:07<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:07<00:23,  2.21it/s] 90%|████████▉ | 449/500 [05:07<00:17,  2.93it/s] 90%|█████████ | 451/500 [05:14<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:14<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:14<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:14<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:14<00:13,  2.99it/s] 92%|█████████▏| 461/500 [05:20<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:21<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:21<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:21<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:21<00:10,  3.01it/s] 94%|█████████▍| 471/500 [05:27<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:27<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:27<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:28<00:10,  2.25it/s] 96%|█████████▌| 479/500 [05:28<00:06,  3.03it/s] 96%|█████████▌| 481/500 [05:34<00:22,  1.19s/it]0.0014316006563603878
Valid Loss:  0.0019153084140270948
Epoch:  414  	Training Loss: 0.0018804206047207117
Test Loss:  0.0014315485022962093
Valid Loss:  0.0019152512541040778
Epoch:  415  	Training Loss: 0.0018803608836606145
Test Loss:  0.0014314977452158928
Valid Loss:  0.0019151974702253938
Epoch:  416  	Training Loss: 0.0018803024431690574
Test Loss:  0.0014314430300146341
Valid Loss:  0.0019151410087943077
Epoch:  417  	Training Loss: 0.0018802419072017074
Test Loss:  0.0014313918072730303
Valid Loss:  0.001915085595101118
Epoch:  418  	Training Loss: 0.0018801840487867594
Test Loss:  0.0014313417486846447
Valid Loss:  0.001915027853101492
Epoch:  419  	Training Loss: 0.0018801249098032713
Test Loss:  0.001431289128959179
Valid Loss:  0.001914972672238946
Epoch:  420  	Training Loss: 0.0018800650723278522
Test Loss:  0.0014312402345240116
Valid Loss:  0.0019149151630699635
Epoch:  421  	Training Loss: 0.0018800059333443642
Test Loss:  0.0014311857521533966
Valid Loss:  0.0019148590508848429
Epoch:  422  	Training Loss: 0.001879946794360876
Test Loss:  0.0014311379054561257
Valid Loss:  0.0019148043356835842
Epoch:  423  	Training Loss: 0.0018798888195306063
Test Loss:  0.0014310847036540508
Valid Loss:  0.0019147510174661875
Epoch:  424  	Training Loss: 0.0018798287492245436
Test Loss:  0.001431033480912447
Valid Loss:  0.0019146918784826994
Epoch:  425  	Training Loss: 0.0018797698430716991
Test Loss:  0.0014309815596789122
Valid Loss:  0.0019146373961120844
Epoch:  426  	Training Loss: 0.001879710704088211
Test Loss:  0.0014309324324131012
Valid Loss:  0.0019145840778946877
Epoch:  427  	Training Loss: 0.0018796517979353666
Test Loss:  0.0014308795798569918
Valid Loss:  0.0019145237747579813
Epoch:  428  	Training Loss: 0.0018795942887663841
Test Loss:  0.0014308253303170204
Valid Loss:  0.00191446952521801
Epoch:  429  	Training Loss: 0.0018795349169522524
Test Loss:  0.0014307779492810369
Valid Loss:  0.0019144162070006132
Epoch:  430  	Training Loss: 0.0018794755451381207
Test Loss:  0.0014307256788015366
Valid Loss:  0.0019143583485856652
Epoch:  431  	Training Loss: 0.0018794164061546326
Test Loss:  0.0014306714292615652
Valid Loss:  0.0019143004901707172
Epoch:  432  	Training Loss: 0.0018793572671711445
Test Loss:  0.001430622418411076
Valid Loss:  0.0019142444944009185
Epoch:  433  	Training Loss: 0.0018792985938489437
Test Loss:  0.001430569333024323
Valid Loss:  0.0019141904776915908
Epoch:  434  	Training Loss: 0.00187923782505095
Test Loss:  0.0014305184595286846
Valid Loss:  0.0019141335505992174
Epoch:  435  	Training Loss: 0.001879179384559393
Test Loss:  0.0014304661890491843
Valid Loss:  0.001914078020490706
Epoch:  436  	Training Loss: 0.0018791178008541465
Test Loss:  0.0014304150827229023
Valid Loss:  0.0019140202784910798
Epoch:  437  	Training Loss: 0.001879059593193233
Test Loss:  0.0014303652569651604
Valid Loss:  0.0019139653304591775
Epoch:  438  	Training Loss: 0.0018790008034557104
Test Loss:  0.0014303125208243728
Valid Loss:  0.0019139084033668041
Epoch:  439  	Training Loss: 0.0018789408495649695
Test Loss:  0.0014302609488368034
Valid Loss:  0.0019138527568429708
Epoch:  440  	Training Loss: 0.001878881361335516
Test Loss:  0.001430212752893567
Valid Loss:  0.0019137989729642868
Epoch:  441  	Training Loss: 0.0018788223387673497
Test Loss:  0.0014301579212769866
Valid Loss:  0.001913742977194488
Epoch:  442  	Training Loss: 0.0018787630833685398
Test Loss:  0.0014301089104264975
Valid Loss:  0.001913684536702931
Epoch:  443  	Training Loss: 0.0018787034787237644
Test Loss:  0.0014300555922091007
Valid Loss:  0.0019136294722557068
Epoch:  444  	Training Loss: 0.0018786455038934946
Test Loss:  0.0014300064649432898
Valid Loss:  0.001913574174977839
Epoch:  445  	Training Loss: 0.001878587994724512
Test Loss:  0.0014299547765403986
Valid Loss:  0.0019135193433612585
Epoch:  446  	Training Loss: 0.0018785304855555296
Test Loss:  0.0014299030881375074
Valid Loss:  0.0019134634640067816
Epoch:  447  	Training Loss: 0.0018784707644954324
Test Loss:  0.0014298525638878345
Valid Loss:  0.0019134110771119595
Epoch:  448  	Training Loss: 0.0018784112762659788
Test Loss:  0.001429801806807518
Valid Loss:  0.0019133577588945627
Epoch:  449  	Training Loss: 0.0018783544655889273
Test Loss:  0.001429751981049776
Valid Loss:  0.0019132986199110746
Epoch:  450  	Training Loss: 0.0018782949773594737
Test Loss:  0.0014297016896307468
Valid Loss:  0.0019132430898025632
Epoch:  451  	Training Loss: 0.0018782350234687328
Test Loss:  0.001429649768397212
Valid Loss:  0.0019131876761093736
Epoch:  452  	Training Loss: 0.0018781780963763595
Test Loss:  0.0014295994769781828
Valid Loss:  0.001913132262416184
Epoch:  453  	Training Loss: 0.0018781207036226988
Test Loss:  0.001429547555744648
Valid Loss:  0.0019130739383399487
Epoch:  454  	Training Loss: 0.0018780624959617853
Test Loss:  0.0014294958673417568
Valid Loss:  0.001913017826154828
Epoch:  455  	Training Loss: 0.0018780031241476536
Test Loss:  0.0014294451102614403
Valid Loss:  0.0019129675347357988
Epoch:  456  	Training Loss: 0.0018779461970552802
Test Loss:  0.001429396914318204
Valid Loss:  0.00191291025839746
Epoch:  457  	Training Loss: 0.001877887174487114
Test Loss:  0.0014293440617620945
Valid Loss:  0.0019128583371639252
Epoch:  458  	Training Loss: 0.0018778289668262005
Test Loss:  0.0014292935375124216
Valid Loss:  0.0019128000130876899
Epoch:  459  	Training Loss: 0.0018777702935039997
Test Loss:  0.0014292439445853233
Valid Loss:  0.0019127465784549713
Epoch:  460  	Training Loss: 0.0018777137156575918
Test Loss:  0.001429192372597754
Valid Loss:  0.0019126890692859888
Epoch:  461  	Training Loss: 0.0018776551587507129
Test Loss:  0.0014291433617472649
Valid Loss:  0.001912634470500052
Epoch:  462  	Training Loss: 0.0018775969510897994
Test Loss:  0.0014290923718363047
Valid Loss:  0.0019125810358673334
Epoch:  463  	Training Loss: 0.0018775390926748514
Test Loss:  0.0014290427789092064
Valid Loss:  0.0019125270191580057
Epoch:  464  	Training Loss: 0.0018774819327518344
Test Loss:  0.0014289922546595335
Valid Loss:  0.0019124734681099653
Epoch:  465  	Training Loss: 0.0018774218624457717
Test Loss:  0.0014289410319179296
Valid Loss:  0.0019124182872474194
Epoch:  466  	Training Loss: 0.001877365866675973
Test Loss:  0.001428890391252935
Valid Loss:  0.001912364037707448
Epoch:  467  	Training Loss: 0.0018773082410916686
Test Loss:  0.0014288421953096986
Valid Loss:  0.0019123100209981203
Epoch:  468  	Training Loss: 0.0018772482872009277
Test Loss:  0.0014287938829511404
Valid Loss:  0.0019122575176879764
Epoch:  469  	Training Loss: 0.001877192291431129
Test Loss:  0.0014287445228546858
Valid Loss:  0.001912199892103672
Epoch:  470  	Training Loss: 0.0018771346658468246
Test Loss:  0.00142869190312922
Valid Loss:  0.0019121466903015971
Epoch:  471  	Training Loss: 0.0018770743627101183
Test Loss:  0.0014286425430327654
Valid Loss:  0.0019120967481285334
Epoch:  472  	Training Loss: 0.001877018017694354
Test Loss:  0.0014285922516137362
Valid Loss:  0.0019120392389595509
Epoch:  473  	Training Loss: 0.0018769610906019807
Test Loss:  0.0014285441720858216
Valid Loss:  0.0019119840580970049
Epoch:  474  	Training Loss: 0.0018769041635096073
Test Loss:  0.0014284930657595396
Valid Loss:  0.0019119302742183208
Epoch:  475  	Training Loss: 0.0018768456066027284
Test Loss:  0.0014284405624493957
Valid Loss:  0.0019118761410936713
Epoch:  476  	Training Loss: 0.0018767878646031022
Test Loss:  0.0014283913187682629
Valid Loss:  0.0019118208438158035
Epoch:  477  	Training Loss: 0.0018767300061881542
Test Loss:  0.0014283424243330956
Valid Loss:  0.0019117665942758322
Epoch:  478  	Training Loss: 0.0018766724970191717
Test Loss:  0.0014282927149906754
Valid Loss:  0.0019117139745503664
Epoch:  479  	Training Loss: 0.0018766152206808329
Test Loss:  0.0014282413758337498
Valid Loss:  0.0019116587936878204
Epoch:  480  	Training Loss: 0.0018765567801892757
Test Loss:  0.0014281945768743753
Valid Loss:  0.0019116043113172054
Epoch:  481  	Training Loss: 0.0018765006680041552
Test Loss:  0.0014281425392255187
Valid Loss:  0.001911546802148223
 97%|█████████▋| 483/500 [05:34<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:34<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:34<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:35<00:03,  2.98it/s] 98%|█████████▊| 491/500 [05:41<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:41<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:41<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:41<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:41<00:00,  3.01it/s]100%|██████████| 500/500 [05:41<00:00,  1.46it/s]
Epoch:  482  	Training Loss: 0.0018764417618513107
Test Loss:  0.0014280914328992367
Valid Loss:  0.0019114933675155044
Epoch:  483  	Training Loss: 0.0018763853004202247
Test Loss:  0.001428040093742311
Valid Loss:  0.0019114399328827858
Epoch:  484  	Training Loss: 0.0018763276748359203
Test Loss:  0.001427993644028902
Valid Loss:  0.0019113868474960327
Epoch:  485  	Training Loss: 0.0018762706313282251
Test Loss:  0.0014279424212872982
Valid Loss:  0.001911331433802843
Epoch:  486  	Training Loss: 0.0018762130057439208
Test Loss:  0.001427892711944878
Valid Loss:  0.001911279046908021
Epoch:  487  	Training Loss: 0.0018761544488370419
Test Loss:  0.00142784568015486
Valid Loss:  0.0019112250301986933
Epoch:  488  	Training Loss: 0.0018760982202365994
Test Loss:  0.0014277943409979343
Valid Loss:  0.001911172759719193
Epoch:  489  	Training Loss: 0.0018760398961603642
Test Loss:  0.001427744748070836
Valid Loss:  0.001911114202812314
Epoch:  490  	Training Loss: 0.0018759823869913816
Test Loss:  0.0014276945730671287
Valid Loss:  0.001911063794977963
Epoch:  491  	Training Loss: 0.0018759268568828702
Test Loss:  0.0014276436995714903
Valid Loss:  0.0019110087305307388
Epoch:  492  	Training Loss: 0.0018758696969598532
Test Loss:  0.0014275953872129321
Valid Loss:  0.0019109552958980203
Epoch:  493  	Training Loss: 0.0018758100923150778
Test Loss:  0.0014275445137172937
Valid Loss:  0.0019109002314507961
Epoch:  494  	Training Loss: 0.0018757546786218882
Test Loss:  0.0014274956192821264
Valid Loss:  0.0019108442356809974
Epoch:  495  	Training Loss: 0.001875696936622262
Test Loss:  0.0014274464920163155
Valid Loss:  0.0019107889384031296
Epoch:  496  	Training Loss: 0.0018756394274532795
Test Loss:  0.0014273955021053553
Valid Loss:  0.0019107384141534567
Epoch:  497  	Training Loss: 0.001875582616776228
Test Loss:  0.0014273453271016479
Valid Loss:  0.001910684397444129
Epoch:  498  	Training Loss: 0.0018755249911919236
Test Loss:  0.0014272965490818024
Valid Loss:  0.0019106309628114104
Epoch:  499  	Training Loss: 0.0018754673656076193
Test Loss:  0.0014272453263401985
Valid Loss:  0.0019105745013803244
Epoch:  500  	Training Loss: 0.001875411719083786
Test Loss:  0.0014271948020905256
Valid Loss:  0.0019105207175016403
seed is  5
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:55,  6.24s/it]  1%|          | 3/500 [00:06<13:51,  1.67s/it]  1%|          | 5/500 [00:06<06:59,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.89it/s]  2%|▏         | 11/500 [00:12<10:39,  1.31s/it]  3%|▎         | 13/500 [00:13<07:16,  1.12it/s]  3%|▎         | 15/500 [00:13<05:04,  1.59it/s]  3%|▎         | 17/500 [00:13<03:37,  2.22it/s]  4%|▍         | 19/500 [00:13<02:39,  3.02it/s]  4%|▍         | 21/500 [00:19<09:30,  1.19s/it]  5%|▍         | 23/500 [00:19<06:45,  1.18it/s]  5%|▌         | 25/500 [00:20<04:50,  1.64it/s]  5%|▌         | 27/500 [00:20<03:31,  2.24it/s]  6%|▌         | 29/500 [00:20<02:36,  3.02it/s]  6%|▌         | 31/500 [00:26<09:11,  1.18s/it]  7%|▋         | 33/500 [00:26<06:33,  1.19it/s]  7%|▋         | 35/500 [00:26<04:43,  1.64it/s]  7%|▋         | 37/500 [00:26<03:27,  2.24it/s]  8%|▊         | 39/500 [00:27<02:33,  3.01it/s]  8%|▊         | 41/500 [00:33<08:56,  1.17s/it]  9%|▊         | 43/500 [00:33<06:23,  1.19it/s]  9%|▉         | 45/500 [00:33<04:36,  1.65it/s]  9%|▉         | 47/500 [00:33<03:21,  2.25it/s] 10%|▉         | 49/500 [00:33<02:29,  3.02it/s] 10%|█         | 51/500 [00:40<08:51,  1.18s/it] 11%|█         | 53/500 [00:40<06:20,  1.18it/s] 11%|█         | 55/500 [00:40<04:33,  1.63it/s] 11%|█▏        | 57/500 [00:40<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:40<02:27,  2.98it/s] 12%|█▏        | 61/500 [00:47<08:32,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:06,  1.19it/s] 13%|█▎        | 65/500 [00:47<04:24,  1.65it/s] 13%|█▎        | 67/500 [00:47<03:13,  2.24it/s] 14%|█▍        | 69/500 [00:47<02:23,  3.01it/s]Epoch:  1  	Training Loss: 0.17302650213241577
Test Loss:  0.15482711791992188
Valid Loss:  0.15724042057991028
Epoch:  2  	Training Loss: 0.13194715976715088
Test Loss:  0.11368841677904129
Valid Loss:  0.11527444422245026
Epoch:  3  	Training Loss: 0.09498836100101471
Test Loss:  0.08765015006065369
Valid Loss:  0.0885927751660347
Epoch:  4  	Training Loss: 0.07231210172176361
Test Loss:  0.07012970000505447
Valid Loss:  0.07055984437465668
Epoch:  5  	Training Loss: 0.05760527029633522
Test Loss:  0.05822799354791641
Valid Loss:  0.05824347585439682
Epoch:  6  	Training Loss: 0.04801391810178757
Test Loss:  0.050022829324007034
Valid Loss:  0.049710579216480255
Epoch:  7  	Training Loss: 0.04168180376291275
Test Loss:  0.044221553951501846
Valid Loss:  0.043667279183864594
Epoch:  8  	Training Loss: 0.037389323115348816
Test Loss:  0.04003877192735672
Valid Loss:  0.0392913818359375
Epoch:  9  	Training Loss: 0.034422602504491806
Test Loss:  0.03696221485733986
Valid Loss:  0.0360531210899353
Epoch:  10  	Training Loss: 0.032327841967344284
Test Loss:  0.034620918333530426
Valid Loss:  0.03359435498714447
Epoch:  11  	Training Loss: 0.0307919941842556
Test Loss:  0.03279232606291771
Valid Loss:  0.03167730197310448
Epoch:  12  	Training Loss: 0.029610000550746918
Test Loss:  0.03042871691286564
Valid Loss:  0.029269002377986908
Epoch:  13  	Training Loss: 0.02791985496878624
Test Loss:  0.02874869480729103
Valid Loss:  0.027629796415567398
Epoch:  14  	Training Loss: 0.02631838619709015
Test Loss:  0.026700209826231003
Valid Loss:  0.025513898581266403
Epoch:  15  	Training Loss: 0.024961229413747787
Test Loss:  0.025125492364168167
Valid Loss:  0.023919766768813133
Epoch:  16  	Training Loss: 0.023838911205530167
Test Loss:  0.023810451850295067
Valid Loss:  0.022625790908932686
Epoch:  17  	Training Loss: 0.02282736450433731
Test Loss:  0.022649481892585754
Valid Loss:  0.02149369940161705
Epoch:  18  	Training Loss: 0.02188589796423912
Test Loss:  0.021594980731606483
Valid Loss:  0.02047228440642357
Epoch:  19  	Training Loss: 0.020995348691940308
Test Loss:  0.020620733499526978
Valid Loss:  0.01953510195016861
Epoch:  20  	Training Loss: 0.020146194845438004
Test Loss:  0.01970801129937172
Valid Loss:  0.01865912787616253
Epoch:  21  	Training Loss: 0.019334867596626282
Test Loss:  0.018848419189453125
Valid Loss:  0.017835622653365135
Epoch:  22  	Training Loss: 0.018561547622084618
Test Loss:  0.018151000142097473
Valid Loss:  0.017124418169260025
Epoch:  23  	Training Loss: 0.01797507330775261
Test Loss:  0.01779877580702305
Valid Loss:  0.016771525144577026
Epoch:  24  	Training Loss: 0.017651185393333435
Test Loss:  0.017473535612225533
Valid Loss:  0.01645302027463913
Epoch:  25  	Training Loss: 0.017351191490888596
Test Loss:  0.017165713012218475
Valid Loss:  0.016150888055562973
Epoch:  26  	Training Loss: 0.01707025058567524
Test Loss:  0.01687716878950596
Valid Loss:  0.01586850918829441
Epoch:  27  	Training Loss: 0.016807369887828827
Test Loss:  0.016599074006080627
Valid Loss:  0.01559679489582777
Epoch:  28  	Training Loss: 0.01655905321240425
Test Loss:  0.016330616548657417
Valid Loss:  0.015330381691455841
Epoch:  29  	Training Loss: 0.016323847696185112
Test Loss:  0.01607615500688553
Valid Loss:  0.015075165778398514
Epoch:  30  	Training Loss: 0.016096793115139008
Test Loss:  0.0158231183886528
Valid Loss:  0.01482211984694004
Epoch:  31  	Training Loss: 0.015876082703471184
Test Loss:  0.015579993836581707
Valid Loss:  0.014581374824047089
Epoch:  32  	Training Loss: 0.01566266641020775
Test Loss:  0.01366328913718462
Valid Loss:  0.012831013649702072
Epoch:  33  	Training Loss: 0.013673007488250732
Test Loss:  0.01177813857793808
Valid Loss:  0.011108214035630226
Epoch:  34  	Training Loss: 0.011507919058203697
Test Loss:  0.010332316160202026
Valid Loss:  0.009697306901216507
Epoch:  35  	Training Loss: 0.010242372751235962
Test Loss:  0.009176943451166153
Valid Loss:  0.00857757031917572
Epoch:  36  	Training Loss: 0.009298059158027172
Test Loss:  0.008230616338551044
Valid Loss:  0.007670336402952671
Epoch:  37  	Training Loss: 0.008488301187753677
Test Loss:  0.007428459823131561
Valid Loss:  0.006909627933055162
Epoch:  38  	Training Loss: 0.007768923882395029
Test Loss:  0.0067268311977386475
Valid Loss:  0.006248170975595713
Epoch:  39  	Training Loss: 0.007125049829483032
Test Loss:  0.006107022054493427
Valid Loss:  0.005663220304995775
Epoch:  40  	Training Loss: 0.006545719690620899
Test Loss:  0.005557578057050705
Valid Loss:  0.005148386117070913
Epoch:  41  	Training Loss: 0.006021894048899412
Test Loss:  0.005065849516540766
Valid Loss:  0.004688961897045374
Epoch:  42  	Training Loss: 0.005547724198549986
Test Loss:  0.004529149737209082
Valid Loss:  0.0042046187445521355
Epoch:  43  	Training Loss: 0.005061501637101173
Test Loss:  0.004140595905482769
Valid Loss:  0.0038473373278975487
Epoch:  44  	Training Loss: 0.004695394076406956
Test Loss:  0.003838260192424059
Valid Loss:  0.00357692688703537
Epoch:  45  	Training Loss: 0.0043987249955534935
Test Loss:  0.0035873635206371546
Valid Loss:  0.0033520180732011795
Epoch:  46  	Training Loss: 0.004144844599068165
Test Loss:  0.0033800234086811543
Valid Loss:  0.0031651111785322428
Epoch:  47  	Training Loss: 0.003932737745344639
Test Loss:  0.003200980369001627
Valid Loss:  0.00300640519708395
Epoch:  48  	Training Loss: 0.0037483733613044024
Test Loss:  0.0030570512171834707
Valid Loss:  0.0028747059404850006
Epoch:  49  	Training Loss: 0.003591888351365924
Test Loss:  0.002931237919256091
Valid Loss:  0.0027604354545474052
Epoch:  50  	Training Loss: 0.003455540630966425
Test Loss:  0.002815034706145525
Valid Loss:  0.0026573108043521643
Epoch:  51  	Training Loss: 0.0033345655538141727
Test Loss:  0.002706415019929409
Valid Loss:  0.002561775967478752
Epoch:  52  	Training Loss: 0.0032228869386017323
Test Loss:  0.0025323769077658653
Valid Loss:  0.0024230151902884245
Epoch:  53  	Training Loss: 0.002985249739140272
Test Loss:  0.002367827808484435
Valid Loss:  0.002272165846079588
Epoch:  54  	Training Loss: 0.0028336038812994957
Test Loss:  0.0022294726222753525
Valid Loss:  0.0021453863009810448
Epoch:  55  	Training Loss: 0.002702356781810522
Test Loss:  0.0021095857955515385
Valid Loss:  0.002036284189671278
Epoch:  56  	Training Loss: 0.0025853521656244993
Test Loss:  0.002015652135014534
Valid Loss:  0.0019517886685207486
Epoch:  57  	Training Loss: 0.00248725526034832
Test Loss:  0.0019334681564942002
Valid Loss:  0.0018795374780893326
Epoch:  58  	Training Loss: 0.0024041919969022274
Test Loss:  0.0018576481379568577
Valid Loss:  0.0018127919174730778
Epoch:  59  	Training Loss: 0.0023283823393285275
Test Loss:  0.0017879726365208626
Valid Loss:  0.0017514810897409916
Epoch:  60  	Training Loss: 0.0022575845941901207
Test Loss:  0.0017234992701560259
Valid Loss:  0.0016945692477747798
Epoch:  61  	Training Loss: 0.0021913948003202677
Test Loss:  0.001663475763052702
Valid Loss:  0.0016408625524491072
Epoch:  62  	Training Loss: 0.0021298034116625786
Test Loss:  0.0014365592505782843
Valid Loss:  0.0014211442321538925
Epoch:  63  	Training Loss: 0.0018616127781569958
Test Loss:  0.0012490011285990477
Valid Loss:  0.0012314654886722565
Epoch:  64  	Training Loss: 0.001665213843807578
Test Loss:  0.0011481842957437038
Valid Loss:  0.0011379302013665438
Epoch:  65  	Training Loss: 0.001526636304333806
Test Loss:  0.0010635771322995424
Valid Loss:  0.0010515261674299836
Epoch:  66  	Training Loss: 0.0014243468176573515
Test Loss:  0.0009951452957466245
Valid Loss:  0.0009832512587308884
Epoch:  67  	Training Loss: 0.0013440577313303947
Test Loss:  0.0009383612778037786
Valid Loss:  0.0009271672461181879
Epoch:  68  	Training Loss: 0.00127579050604254
Test Loss:  0.0008890960598364472
Valid Loss:  0.0008813231252133846
Epoch:  69  	Training Loss: 0.0012159609468653798
Test Loss:  0.0008454299531877041
Valid Loss:  0.0008418344659730792
Epoch:  70  	Training Loss: 0.0011628849897533655
Test Loss:  0.000805955845862627
Valid Loss:  0.0008063893765211105
Epoch:  71  	Training Loss: 0.001114870305173099
Test Loss:  0.0007713302038609982 14%|█▍        | 71/500 [00:53<08:20,  1.17s/it] 15%|█▍        | 73/500 [00:53<05:59,  1.19it/s] 15%|█▌        | 75/500 [00:54<04:22,  1.62it/s] 15%|█▌        | 77/500 [00:54<03:11,  2.21it/s] 16%|█▌        | 79/500 [00:54<02:21,  2.97it/s] 16%|█▌        | 81/500 [01:00<08:12,  1.17s/it] 17%|█▋        | 83/500 [01:00<05:52,  1.18it/s] 17%|█▋        | 85/500 [01:00<04:13,  1.63it/s] 17%|█▋        | 87/500 [01:01<03:05,  2.23it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.00it/s] 18%|█▊        | 91/500 [01:07<08:04,  1.19s/it] 19%|█▊        | 93/500 [01:07<05:48,  1.17it/s] 19%|█▉        | 95/500 [01:07<04:12,  1.61it/s] 19%|█▉        | 97/500 [01:08<03:04,  2.19it/s] 20%|█▉        | 99/500 [01:08<02:16,  2.94it/s] 20%|██        | 101/500 [01:14<07:54,  1.19s/it] 21%|██        | 103/500 [01:14<05:39,  1.17it/s] 21%|██        | 105/500 [01:14<04:04,  1.62it/s] 21%|██▏       | 107/500 [01:14<02:57,  2.21it/s] 22%|██▏       | 109/500 [01:15<02:12,  2.96it/s] 22%|██▏       | 111/500 [01:21<07:42,  1.19s/it] 23%|██▎       | 113/500 [01:21<05:30,  1.17it/s] 23%|██▎       | 115/500 [01:21<03:57,  1.62it/s] 23%|██▎       | 117/500 [01:21<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:21<02:07,  2.98it/s] 24%|██▍       | 121/500 [01:28<07:22,  1.17s/it] 25%|██▍       | 123/500 [01:28<05:16,  1.19it/s] 25%|██▌       | 125/500 [01:28<03:47,  1.65it/s] 25%|██▌       | 127/500 [01:28<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:28<02:03,  3.01it/s] 26%|██▌       | 131/500 [01:34<07:08,  1.16s/it] 27%|██▋       | 133/500 [01:35<05:06,  1.20it/s] 27%|██▋       | 135/500 [01:35<03:40,  1.66it/s] 27%|██▋       | 137/500 [01:35<02:40,  2.26it/s]
Valid Loss:  0.0007765875197947025
Epoch:  72  	Training Loss: 0.0010715557727962732
Test Loss:  0.0007461579516530037
Valid Loss:  0.0007502332446165383
Epoch:  73  	Training Loss: 0.0010443681385368109
Test Loss:  0.0007248718175105751
Valid Loss:  0.0007284751627594233
Epoch:  74  	Training Loss: 0.0010195362847298384
Test Loss:  0.0007062538061290979
Valid Loss:  0.000709890911821276
Epoch:  75  	Training Loss: 0.0009964876808226109
Test Loss:  0.0006890773074701428
Valid Loss:  0.0006932034739293158
Epoch:  76  	Training Loss: 0.0009750452009029686
Test Loss:  0.0006733339396305382
Valid Loss:  0.000677984207868576
Epoch:  77  	Training Loss: 0.0009548788657411933
Test Loss:  0.0006588254473172128
Valid Loss:  0.0006642112857662141
Epoch:  78  	Training Loss: 0.0009360368130728602
Test Loss:  0.0006451036897487938
Valid Loss:  0.0006518330774269998
Epoch:  79  	Training Loss: 0.0009180961642414331
Test Loss:  0.0006320500979200006
Valid Loss:  0.0006404932355508208
Epoch:  80  	Training Loss: 0.0009008335182443261
Test Loss:  0.0006196405156515539
Valid Loss:  0.0006298288935795426
Epoch:  81  	Training Loss: 0.0008843883406370878
Test Loss:  0.000607891590334475
Valid Loss:  0.0006198730552569032
Epoch:  82  	Training Loss: 0.0008687362424097955
Test Loss:  0.0005939612165093422
Valid Loss:  0.0006077911821193993
Epoch:  83  	Training Loss: 0.0008509471081197262
Test Loss:  0.0005808926071040332
Valid Loss:  0.0005968577461317182
Epoch:  84  	Training Loss: 0.0008342245710082352
Test Loss:  0.0005686238291673362
Valid Loss:  0.0005867074942216277
Epoch:  85  	Training Loss: 0.0008184455218724906
Test Loss:  0.0005569468485191464
Valid Loss:  0.0005771986325271428
Epoch:  86  	Training Loss: 0.0008033439517021179
Test Loss:  0.0005457987426780164
Valid Loss:  0.0005683199851773679
Epoch:  87  	Training Loss: 0.0007888613035902381
Test Loss:  0.0005351288127712905
Valid Loss:  0.0005598560092039406
Epoch:  88  	Training Loss: 0.0007750223157927394
Test Loss:  0.0005249622045084834
Valid Loss:  0.0005518406396731734
Epoch:  89  	Training Loss: 0.0007618373492732644
Test Loss:  0.0005152144003659487
Valid Loss:  0.0005441816756501794
Epoch:  90  	Training Loss: 0.0007491447031497955
Test Loss:  0.0005059785326011479
Valid Loss:  0.0005368280690163374
Epoch:  91  	Training Loss: 0.0007370110834017396
Test Loss:  0.000497182656545192
Valid Loss:  0.0005298165488056839
Epoch:  92  	Training Loss: 0.000725356163457036
Test Loss:  0.00048776710173115134
Valid Loss:  0.00052458985010162
Epoch:  93  	Training Loss: 0.0007028066320344806
Test Loss:  0.0004764704208355397
Valid Loss:  0.000516463303938508
Epoch:  94  	Training Loss: 0.0006857234402559698
Test Loss:  0.0004650084301829338
Valid Loss:  0.0005078053800389171
Epoch:  95  	Training Loss: 0.0006698810029774904
Test Loss:  0.00045359463547356427
Valid Loss:  0.0004989589797332883
Epoch:  96  	Training Loss: 0.0006549942772835493
Test Loss:  0.0004427262756507844
Valid Loss:  0.0004906016984023154
Epoch:  97  	Training Loss: 0.0006408950430341065
Test Loss:  0.0004327712522353977
Valid Loss:  0.00048313988372683525
Epoch:  98  	Training Loss: 0.0006276039639487863
Test Loss:  0.00042309207492507994
Valid Loss:  0.00047586107393726707
Epoch:  99  	Training Loss: 0.0006149692926555872
Test Loss:  0.0004140377277508378
Valid Loss:  0.0004691493813879788
Epoch:  100  	Training Loss: 0.000602979795075953
Test Loss:  0.00040515849832445383
Valid Loss:  0.00046247095451690257
Epoch:  101  	Training Loss: 0.000591510790400207
Test Loss:  0.0003967217053286731
Valid Loss:  0.0004562488757073879
Epoch:  102  	Training Loss: 0.0005805155960842967
Test Loss:  0.0003902461030520499
Valid Loss:  0.0004514392639975995
Epoch:  103  	Training Loss: 0.0005718009197153151
Test Loss:  0.000383879232686013
Valid Loss:  0.0004467173130251467
Epoch:  104  	Training Loss: 0.0005633619148284197
Test Loss:  0.00037760514533147216
Valid Loss:  0.00044204178266227245
Epoch:  105  	Training Loss: 0.0005553546361625195
Test Loss:  0.0003716322244144976
Valid Loss:  0.000437729962868616
Epoch:  106  	Training Loss: 0.000547743053175509
Test Loss:  0.0003657771449070424
Valid Loss:  0.00043338275281712413
Epoch:  107  	Training Loss: 0.0005405009142123163
Test Loss:  0.0003608637780416757
Valid Loss:  0.00042991252848878503
Epoch:  108  	Training Loss: 0.0005346405669115484
Test Loss:  0.00035356427542865276
Valid Loss:  0.00042356550693511963
Epoch:  109  	Training Loss: 0.0005291974521242082
Test Loss:  0.00034966348903253675
Valid Loss:  0.00042128830682486296
Epoch:  110  	Training Loss: 0.0005223297048360109
Test Loss:  0.00034525734372437
Valid Loss:  0.0004181009717285633
Epoch:  111  	Training Loss: 0.0005159244174137712
Test Loss:  0.00034082611091434956
Valid Loss:  0.0004147309809923172
Epoch:  112  	Training Loss: 0.0005099182017147541
Test Loss:  0.0003401103022042662
Valid Loss:  0.0004150074964854866
Epoch:  113  	Training Loss: 0.0005077737150713801
Test Loss:  0.0003394625964574516
Valid Loss:  0.0004153361660428345
Epoch:  114  	Training Loss: 0.0005059125833213329
Test Loss:  0.0003389430930837989
Valid Loss:  0.0004156565119046718
Epoch:  115  	Training Loss: 0.0005042640259489417
Test Loss:  0.00033847338636405766
Valid Loss:  0.0004159283998887986
Epoch:  116  	Training Loss: 0.0005027925944887102
Test Loss:  0.00033800568780861795
Valid Loss:  0.0004161994147580117
Epoch:  117  	Training Loss: 0.0005014627240598202
Test Loss:  0.0003375110973138362
Valid Loss:  0.0004164576530456543
Epoch:  118  	Training Loss: 0.0005002378020435572
Test Loss:  0.0003370383055880666
Valid Loss:  0.00041668707854114473
Epoch:  119  	Training Loss: 0.0004991174209862947
Test Loss:  0.00033656717278063297
Valid Loss:  0.00041691074147820473
Epoch:  120  	Training Loss: 0.0004980736412107944
Test Loss:  0.00033611321123316884
Valid Loss:  0.00041714130202308297
Epoch:  121  	Training Loss: 0.0004970867303200066
Test Loss:  0.0003356593078933656
Valid Loss:  0.000417383766034618
Epoch:  122  	Training Loss: 0.0004961425438523293
Test Loss:  0.0003342985874041915
Valid Loss:  0.0004160274693276733
Epoch:  123  	Training Loss: 0.0004940287908539176
Test Loss:  0.0003329314640723169
Valid Loss:  0.00041466770926490426
Epoch:  124  	Training Loss: 0.0004920140490867198
Test Loss:  0.0003315210633445531
Valid Loss:  0.00041326996870338917
Epoch:  125  	Training Loss: 0.0004901781212538481
Test Loss:  0.00033011712366715074
Valid Loss:  0.000411899178288877
Epoch:  126  	Training Loss: 0.0004884239169768989
Test Loss:  0.0003287453146185726
Valid Loss:  0.0004106045817025006
Epoch:  127  	Training Loss: 0.00048671182594262064
Test Loss:  0.00032736556022427976
Valid Loss:  0.0004092510207556188
Epoch:  128  	Training Loss: 0.00048509816406294703
Test Loss:  0.000325982051435858
Valid Loss:  0.0004079179489053786
Epoch:  129  	Training Loss: 0.000483561831060797
Test Loss:  0.00032460613874718547
Valid Loss:  0.0004066049004904926
Epoch:  130  	Training Loss: 0.00048206563224084675
Test Loss:  0.00032323249615728855
Valid Loss:  0.00040533102583140135
Epoch:  131  	Training Loss: 0.00048064079601317644
Test Loss:  0.0003218778583686799
Valid Loss:  0.00040415459079667926
Epoch:  132  	Training Loss: 0.000479250680655241
Test Loss:  0.0003179375780746341
Valid Loss:  0.00040101230842992663
Epoch:  133  	Training Loss: 0.0004742380406241864
Test Loss:  0.0003141184861306101
Valid Loss:  0.0003979747125413269
Epoch:  134  	Training Loss: 0.00046944560017436743
Test Loss:  0.0003104655770584941
Valid Loss:  0.00039510996430180967
Epoch:  135  	Training Loss: 0.0004648369213100523
Test Loss:  0.0003068836231250316
Valid Loss:  0.0003923475160263479
Epoch:  136  	Training Loss: 0.000460418697912246
Test Loss:  0.00030340056400746107
Valid Loss:  0.00038967476575635374
Epoch:  137  	Training Loss: 0.0004561237001325935
Test Loss:  0.00029994104988873005
Valid Loss:  0.0003870110085699707
Epoch:  138  	Training Loss: 0.00045193047844804823
Test Loss:  0.0002965543244499713
Valid Loss:  0.00038440662319771945
Epoch:  139  	Training Loss: 0.00044787657679989934
Test Loss:  0.0002932138158939779
Valid Loss:  0.00038186454912647605
 28%|██▊       | 139/500 [01:35<01:58,  3.04it/s] 28%|██▊       | 141/500 [01:41<06:59,  1.17s/it] 29%|██▊       | 143/500 [01:41<04:59,  1.19it/s] 29%|██▉       | 145/500 [01:41<03:35,  1.65it/s] 29%|██▉       | 147/500 [01:42<02:36,  2.25it/s] 30%|██▉       | 149/500 [01:42<01:55,  3.03it/s] 30%|███       | 151/500 [01:48<06:43,  1.16s/it] 31%|███       | 153/500 [01:48<04:48,  1.20it/s] 31%|███       | 155/500 [01:48<03:27,  1.66it/s] 31%|███▏      | 157/500 [01:48<02:31,  2.27it/s] 32%|███▏      | 159/500 [01:48<01:52,  3.04it/s] 32%|███▏      | 161/500 [01:55<06:34,  1.16s/it] 33%|███▎      | 163/500 [01:55<04:42,  1.19it/s] 33%|███▎      | 165/500 [01:55<03:23,  1.65it/s] 33%|███▎      | 167/500 [01:55<02:27,  2.25it/s] 34%|███▍      | 169/500 [01:55<01:49,  3.03it/s] 34%|███▍      | 171/500 [02:02<06:26,  1.17s/it] 35%|███▍      | 173/500 [02:02<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:02<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:02<02:24,  2.24it/s] 36%|███▌      | 179/500 [02:02<01:46,  3.00it/s] 36%|███▌      | 181/500 [02:08<06:13,  1.17s/it] 37%|███▋      | 183/500 [02:08<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:09<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:09<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:09<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:15<06:01,  1.17s/it] 39%|███▊      | 193/500 [02:15<04:17,  1.19it/s] 39%|███▉      | 195/500 [02:15<03:05,  1.65it/s] 39%|███▉      | 197/500 [02:15<02:14,  2.25it/s] 40%|███▉      | 199/500 [02:16<01:39,  3.02it/s] 40%|████      | 201/500 [02:22<05:49,  1.17s/it] 41%|████      | 203/500 [02:22<04:09,  1.19it/s] 41%|████      | 205/500 [02:22<02:59,  1.65it/s]Epoch:  140  	Training Loss: 0.0004439160693436861
Test Loss:  0.00028994769672863185
Valid Loss:  0.0003794985532294959
Epoch:  141  	Training Loss: 0.00044006312964484096
Test Loss:  0.0002867986331693828
Valid Loss:  0.0003772535710595548
Epoch:  142  	Training Loss: 0.0004363022162579
Test Loss:  0.0002830670273397118
Valid Loss:  0.00037386055919341743
Epoch:  143  	Training Loss: 0.00043208952411077917
Test Loss:  0.00027982547180727124
Valid Loss:  0.00037090532714501023
Epoch:  144  	Training Loss: 0.00042807654244825244
Test Loss:  0.00027687809779308736
Valid Loss:  0.00036817463114857674
Epoch:  145  	Training Loss: 0.00042422942351549864
Test Loss:  0.0002741249045357108
Valid Loss:  0.0003657065099105239
Epoch:  146  	Training Loss: 0.000420528172980994
Test Loss:  0.0002715584705583751
Valid Loss:  0.00036340299993753433
Epoch:  147  	Training Loss: 0.0004169343737885356
Test Loss:  0.0002690970432013273
Valid Loss:  0.0003611328429542482
Epoch:  148  	Training Loss: 0.00041340390453115106
Test Loss:  0.0002666596556082368
Valid Loss:  0.0003588871331885457
Epoch:  149  	Training Loss: 0.0004099389770999551
Test Loss:  0.0002642128092702478
Valid Loss:  0.0003566910163499415
Epoch:  150  	Training Loss: 0.00040653671021573246
Test Loss:  0.00026174995582550764
Valid Loss:  0.00035449344431981444
Epoch:  151  	Training Loss: 0.0004031636635772884
Test Loss:  0.00025940261548385024
Valid Loss:  0.00035240943543612957
Epoch:  152  	Training Loss: 0.00039987967466004193
Test Loss:  0.00025806674966588616
Valid Loss:  0.0003510817186906934
Epoch:  153  	Training Loss: 0.00039783091051504016
Test Loss:  0.0002567813207861036
Valid Loss:  0.00034979070187546313
Epoch:  154  	Training Loss: 0.0003959422174375504
Test Loss:  0.0002555427490733564
Valid Loss:  0.00034856132697314024
Epoch:  155  	Training Loss: 0.0003941231407225132
Test Loss:  0.0002543197479099035
Valid Loss:  0.00034731824416667223
Epoch:  156  	Training Loss: 0.00039238546742126346
Test Loss:  0.00025311511126346886
Valid Loss:  0.0003460940788500011
Epoch:  157  	Training Loss: 0.000390686938771978
Test Loss:  0.00025194534100592136
Valid Loss:  0.000344871892593801
Epoch:  158  	Training Loss: 0.00038903718814253807
Test Loss:  0.00025079777697101235
Valid Loss:  0.00034364894963800907
Epoch:  159  	Training Loss: 0.00038744951598346233
Test Loss:  0.0002496664528734982
Valid Loss:  0.00034247527946718037
Epoch:  160  	Training Loss: 0.0003859050921164453
Test Loss:  0.0002485621953383088
Valid Loss:  0.0003413290251046419
Epoch:  161  	Training Loss: 0.0003843872691504657
Test Loss:  0.0002474539796821773
Valid Loss:  0.00034017825964838266
Epoch:  162  	Training Loss: 0.0003829215420410037
Test Loss:  0.00024641159689053893
Valid Loss:  0.00033937444095499814
Epoch:  163  	Training Loss: 0.00038108829176053405
Test Loss:  0.00024527276400476694
Valid Loss:  0.0003384661686141044
Epoch:  164  	Training Loss: 0.00037931776023469865
Test Loss:  0.00024408749595750123
Valid Loss:  0.0003374888328835368
Epoch:  165  	Training Loss: 0.0003775812510866672
Test Loss:  0.00024287319683935493
Valid Loss:  0.00033647764939814806
Epoch:  166  	Training Loss: 0.00037587215774692595
Test Loss:  0.00024162768386304379
Valid Loss:  0.00033543637255206704
Epoch:  167  	Training Loss: 0.0003741921973414719
Test Loss:  0.0002403704565949738
Valid Loss:  0.0003343870921526104
Epoch:  168  	Training Loss: 0.0003725287097040564
Test Loss:  0.0002391108573647216
Valid Loss:  0.00033335425541736186
Epoch:  169  	Training Loss: 0.00037089065881446004
Test Loss:  0.00023785763187333941
Valid Loss:  0.00033233204158023
Epoch:  170  	Training Loss: 0.00036928121699020267
Test Loss:  0.0002366079279454425
Valid Loss:  0.0003313120687380433
Epoch:  171  	Training Loss: 0.00036769313737750053
Test Loss:  0.00023537251399829984
Valid Loss:  0.00033030283520929515
Epoch:  172  	Training Loss: 0.0003661232767626643
Test Loss:  0.00023446000705007464
Valid Loss:  0.00032948952866718173
Epoch:  173  	Training Loss: 0.00036508258199319243
Test Loss:  0.0002336113539058715
Valid Loss:  0.00032870384166017175
Epoch:  174  	Training Loss: 0.0003640561772044748
Test Loss:  0.00023278166190721095
Valid Loss:  0.00032793302671052516
Epoch:  175  	Training Loss: 0.0003630648134276271
Test Loss:  0.0002319898339919746
Valid Loss:  0.00032719894079491496
Epoch:  176  	Training Loss: 0.00036211867700330913
Test Loss:  0.00023120305559132248
Valid Loss:  0.0003264931438025087
Epoch:  177  	Training Loss: 0.00036119253491051495
Test Loss:  0.00023042738030198961
Valid Loss:  0.0003258215729147196
Epoch:  178  	Training Loss: 0.00036029444891028106
Test Loss:  0.000229662808123976
Valid Loss:  0.00032517476938664913
Epoch:  179  	Training Loss: 0.00035941333044320345
Test Loss:  0.00022891932167112827
Valid Loss:  0.00032454050960950553
Epoch:  180  	Training Loss: 0.0003585446975193918
Test Loss:  0.00022818907746113837
Valid Loss:  0.00032392959110438824
Epoch:  181  	Training Loss: 0.00035768517409451306
Test Loss:  0.00022747415641788393
Valid Loss:  0.0003233334282413125
Epoch:  182  	Training Loss: 0.00035683304304257035
Test Loss:  0.00022363639436662197
Valid Loss:  0.0003197213518433273
Epoch:  183  	Training Loss: 0.0003538709715940058
Test Loss:  0.00022065879602450877
Valid Loss:  0.0003169689152855426
Epoch:  184  	Training Loss: 0.00035133404890075326
Test Loss:  0.00021812511840835214
Valid Loss:  0.0003146831295453012
Epoch:  185  	Training Loss: 0.0003490045201033354
Test Loss:  0.00021591491531580687
Valid Loss:  0.00031271239276975393
Epoch:  186  	Training Loss: 0.0003468405338935554
Test Loss:  0.00021388987079262733
Valid Loss:  0.00031094171572476625
Epoch:  187  	Training Loss: 0.0003447892377153039
Test Loss:  0.00021200613991823047
Valid Loss:  0.0003093396662734449
Epoch:  188  	Training Loss: 0.0003428085765335709
Test Loss:  0.0002102457801811397
Valid Loss:  0.0003078926238231361
Epoch:  189  	Training Loss: 0.00034089916152879596
Test Loss:  0.0002085650194203481
Valid Loss:  0.0003065337659791112
Epoch:  190  	Training Loss: 0.00033903843723237514
Test Loss:  0.00020695406419690698
Valid Loss:  0.0003052547690458596
Epoch:  191  	Training Loss: 0.00033725026878528297
Test Loss:  0.0002053876523859799
Valid Loss:  0.00030401471303775907
Epoch:  192  	Training Loss: 0.0003355091321282089
Test Loss:  0.00020543347636703402
Valid Loss:  0.0003042415191885084
Epoch:  193  	Training Loss: 0.00033371103927493095
Test Loss:  0.0002052266790997237
Valid Loss:  0.00030417880043387413
Epoch:  194  	Training Loss: 0.0003322810516692698
Test Loss:  0.00020485385903157294
Valid Loss:  0.00030391773907467723
Epoch:  195  	Training Loss: 0.000330997456330806
Test Loss:  0.0002043577842414379
Valid Loss:  0.0003035445115529001
Epoch:  196  	Training Loss: 0.00032980216201394796
Test Loss:  0.00020374098676256835
Valid Loss:  0.0003030526277143508
Epoch:  197  	Training Loss: 0.00032865587854757905
Test Loss:  0.00020306292572058737
Valid Loss:  0.0003024950565304607
Epoch:  198  	Training Loss: 0.00032755386200733483
Test Loss:  0.00020234653493389487
Valid Loss:  0.0003019047435373068
Epoch:  199  	Training Loss: 0.00032649689819663763
Test Loss:  0.0002016156940953806
Valid Loss:  0.0003013187670148909
Epoch:  200  	Training Loss: 0.00032547421869821846
Test Loss:  0.00020088814198970795
Valid Loss:  0.00030073680682107806
Epoch:  201  	Training Loss: 0.00032448407728224993
Test Loss:  0.00020016878261230886
Valid Loss:  0.0003001742879860103
Epoch:  202  	Training Loss: 0.00032351852860301733
Test Loss:  0.00019775793771259487
Valid Loss:  0.00029801635537296534
Epoch:  203  	Training Loss: 0.00032108102459460497
Test Loss:  0.00019549590069800615
Valid Loss:  0.00029602774884551764
Epoch:  204  	Training Loss: 0.00031877780565992
Test Loss:  0.0001933994353748858
Valid Loss:  0.0002941969141829759
Epoch:  205  	Training Loss: 0.00031662615947425365
Test Loss:  0.00019144585530739278
Valid Loss:  0.00029248412465676665
Epoch:  206  	Training Loss: 0.00031459471210837364
Test Loss:  0.0001896355242934078
Valid Loss:  0.0002908689493779093
Epoch:  207  	Training Loss: 0.0003126634401269257
 41%|████▏     | 207/500 [02:22<02:10,  2.25it/s] 42%|████▏     | 209/500 [02:22<01:36,  3.02it/s] 42%|████▏     | 211/500 [02:29<05:40,  1.18s/it] 43%|████▎     | 213/500 [02:29<04:02,  1.18it/s] 43%|████▎     | 215/500 [02:29<02:54,  1.64it/s] 43%|████▎     | 217/500 [02:29<02:07,  2.22it/s] 44%|████▍     | 219/500 [02:29<01:34,  2.96it/s] 44%|████▍     | 221/500 [02:35<05:26,  1.17s/it] 45%|████▍     | 223/500 [02:36<03:52,  1.19it/s] 45%|████▌     | 225/500 [02:36<02:46,  1.65it/s] 45%|████▌     | 227/500 [02:36<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:36<01:29,  3.01it/s] 46%|████▌     | 231/500 [02:42<05:16,  1.18s/it] 47%|████▋     | 233/500 [02:42<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:43<02:43,  1.62it/s] 47%|████▋     | 237/500 [02:43<01:59,  2.20it/s] 48%|████▊     | 239/500 [02:43<01:28,  2.96it/s] 48%|████▊     | 241/500 [02:49<05:05,  1.18s/it] 49%|████▊     | 243/500 [02:49<03:37,  1.18it/s] 49%|████▉     | 245/500 [02:49<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:50<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:50<01:23,  3.00it/s] 50%|█████     | 251/500 [02:56<04:53,  1.18s/it] 51%|█████     | 253/500 [02:56<03:28,  1.18it/s] 51%|█████     | 255/500 [02:56<02:29,  1.64it/s] 51%|█████▏    | 257/500 [02:56<01:48,  2.24it/s] 52%|█████▏    | 259/500 [02:57<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:03<04:39,  1.17s/it] 53%|█████▎    | 263/500 [03:03<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:03<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:03<01:43,  2.24it/s] 54%|█████▍    | 269/500 [03:03<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:10<04:30,  1.18s/it] 55%|█████▍    | 273/500 [03:10<03:12,  1.18it/s]Test Loss:  0.00018794610514305532
Valid Loss:  0.000289338844595477
Epoch:  208  	Training Loss: 0.0003108242526650429
Test Loss:  0.0001863174547906965
Valid Loss:  0.0002878846717067063
Epoch:  209  	Training Loss: 0.00030903462902642787
Test Loss:  0.000184771663043648
Valid Loss:  0.0002865142305381596
Epoch:  210  	Training Loss: 0.0003073337720707059
Test Loss:  0.00018326941062696278
Valid Loss:  0.0002851899480447173
Epoch:  211  	Training Loss: 0.0003056623099837452
Test Loss:  0.0001818069868022576
Valid Loss:  0.00028391857631504536
Epoch:  212  	Training Loss: 0.0003040191368199885
Test Loss:  0.0001803539926186204
Valid Loss:  0.00028269478934817016
Epoch:  213  	Training Loss: 0.00030200305627658963
Test Loss:  0.00017938987002708018
Valid Loss:  0.00028199300868436694
Epoch:  214  	Training Loss: 0.0002997892443090677
Test Loss:  0.00017814338207244873
Valid Loss:  0.0002809891593642533
Epoch:  215  	Training Loss: 0.00029792808345519006
Test Loss:  0.0001759328442858532
Valid Loss:  0.00027900695567950606
Epoch:  216  	Training Loss: 0.00029616645770147443
Test Loss:  0.00017488538287580013
Valid Loss:  0.000278231396805495
Epoch:  217  	Training Loss: 0.00029416853794828057
Test Loss:  0.00017355341697111726
Valid Loss:  0.00027719204081222415
Epoch:  218  	Training Loss: 0.00029226834885776043
Test Loss:  0.00017213865066878498
Valid Loss:  0.0002760497445706278
Epoch:  219  	Training Loss: 0.00029049161821603775
Test Loss:  0.0001702495210338384
Valid Loss:  0.00027441789279691875
Epoch:  220  	Training Loss: 0.0002888114540837705
Test Loss:  0.00016914651496335864
Valid Loss:  0.0002735996386036277
Epoch:  221  	Training Loss: 0.000287024537101388
Test Loss:  0.0001678886474110186
Valid Loss:  0.00027260699425823987
Epoch:  222  	Training Loss: 0.00028537478647194803
Test Loss:  0.00016653721104376018
Valid Loss:  0.0002714485744945705
Epoch:  223  	Training Loss: 0.0002840203233063221
Test Loss:  0.00016529238200746477
Valid Loss:  0.00027037999825552106
Epoch:  224  	Training Loss: 0.00028270657639950514
Test Loss:  0.00016414441051892936
Valid Loss:  0.0002693877322599292
Epoch:  225  	Training Loss: 0.00028143287636339664
Test Loss:  0.00016307391342706978
Valid Loss:  0.0002684510836843401
Epoch:  226  	Training Loss: 0.0002802020753733814
Test Loss:  0.00016203269478864968
Valid Loss:  0.00026753946440294385
Epoch:  227  	Training Loss: 0.00027898838743567467
Test Loss:  0.00016101179062388837
Valid Loss:  0.00026665025507099926
Epoch:  228  	Training Loss: 0.000277786108199507
Test Loss:  0.00016001943731680512
Valid Loss:  0.00026577647076919675
Epoch:  229  	Training Loss: 0.0002765972458291799
Test Loss:  0.0001590997417224571
Valid Loss:  0.000264934787992388
Epoch:  230  	Training Loss: 0.0002754608285613358
Test Loss:  0.00015819977852515876
Valid Loss:  0.00026410818099975586
Epoch:  231  	Training Loss: 0.0002743413206189871
Test Loss:  0.00015731820894870907
Valid Loss:  0.00026329318643547595
Epoch:  232  	Training Loss: 0.00027323170797899365
Test Loss:  0.00015724351396784186
Valid Loss:  0.0002633699623402208
Epoch:  233  	Training Loss: 0.00027241610223427415
Test Loss:  0.0001570116146467626
Valid Loss:  0.0002632664982229471
Epoch:  234  	Training Loss: 0.0002716854796744883
Test Loss:  0.00015668472042307258
Valid Loss:  0.0002630528178997338
Epoch:  235  	Training Loss: 0.00027100282022729516
Test Loss:  0.00015628057008143514
Valid Loss:  0.00026275243726558983
Epoch:  236  	Training Loss: 0.00027033640071749687
Test Loss:  0.00015583529602736235
Valid Loss:  0.00026240962324663997
Epoch:  237  	Training Loss: 0.00026968534803017974
Test Loss:  0.00015536375576630235
Valid Loss:  0.00026203447487205267
Epoch:  238  	Training Loss: 0.0002690510591492057
Test Loss:  0.00015488493954762816
Valid Loss:  0.00026165490271523595
Epoch:  239  	Training Loss: 0.0002684269566088915
Test Loss:  0.00015439157141372561
Valid Loss:  0.00026125801377929747
Epoch:  240  	Training Loss: 0.00026781571796163917
Test Loss:  0.00015390587213914841
Valid Loss:  0.0002608783543109894
Epoch:  241  	Training Loss: 0.00026721577160060406
Test Loss:  0.00015342366532422602
Valid Loss:  0.0002604968030937016
Epoch:  242  	Training Loss: 0.0002666199579834938
Test Loss:  0.00015312997857108712
Valid Loss:  0.0002601999440230429
Epoch:  243  	Training Loss: 0.0002664523490238935
Test Loss:  0.00015287232236005366
Valid Loss:  0.0002599448780529201
Epoch:  244  	Training Loss: 0.0002662901533767581
Test Loss:  0.00015264614194165915
Valid Loss:  0.00025972098228521645
Epoch:  245  	Training Loss: 0.0002661324688233435
Test Loss:  0.00015244618407450616
Valid Loss:  0.00025952188298106194
Epoch:  246  	Training Loss: 0.00026598243857733905
Test Loss:  0.00015227198309730738
Valid Loss:  0.00025935968733392656
Epoch:  247  	Training Loss: 0.0002658402663655579
Test Loss:  0.00015211274148896337
Valid Loss:  0.0002592121309135109
Epoch:  248  	Training Loss: 0.00026570106274448335
Test Loss:  0.00015196498134173453
Valid Loss:  0.000259077874943614
Epoch:  249  	Training Loss: 0.0002655654097907245
Test Loss:  0.00015182730567175895
Valid Loss:  0.0002589582290966064
Epoch:  250  	Training Loss: 0.0002654318232089281
Test Loss:  0.00015169499965850264
Valid Loss:  0.0002588474308140576
Epoch:  251  	Training Loss: 0.000265300739556551
Test Loss:  0.00015157228335738182
Valid Loss:  0.00025874096900224686
Epoch:  252  	Training Loss: 0.0002651719842106104
Test Loss:  0.00015028516645543277
Valid Loss:  0.00025782352895475924
Epoch:  253  	Training Loss: 0.00026345319929532707
Test Loss:  0.00014897834626026452
Valid Loss:  0.0002568701165728271
Epoch:  254  	Training Loss: 0.0002617717254906893
Test Loss:  0.0001477040641475469
Valid Loss:  0.0002559162676334381
Epoch:  255  	Training Loss: 0.0002601317537482828
Test Loss:  0.00014645280316472054
Valid Loss:  0.00025495802401565015
Epoch:  256  	Training Loss: 0.0002585268230177462
Test Loss:  0.0001452288997825235
Valid Loss:  0.0002539963461458683
Epoch:  257  	Training Loss: 0.0002569679054431617
Test Loss:  0.00014400403597392142
Valid Loss:  0.00025299537810496986
Epoch:  258  	Training Loss: 0.0002554512466304004
Test Loss:  0.00014281904441304505
Valid Loss:  0.0002520483685657382
Epoch:  259  	Training Loss: 0.0002539658162277192
Test Loss:  0.00014165771426633
Valid Loss:  0.00025111762806773186
Epoch:  260  	Training Loss: 0.0002525085292290896
Test Loss:  0.00014052090409677476
Valid Loss:  0.0002502063871361315
Epoch:  261  	Training Loss: 0.0002510775229893625
Test Loss:  0.00013940519420430064
Valid Loss:  0.0002493099309504032
Epoch:  262  	Training Loss: 0.00024967192439362407
Test Loss:  0.00013892410788685083
Valid Loss:  0.0002488811151124537
Epoch:  263  	Training Loss: 0.00024912692606449127
Test Loss:  0.00013849814422428608
Valid Loss:  0.00024851696798577905
Epoch:  264  	Training Loss: 0.000248598720645532
Test Loss:  0.0001380778558086604
Valid Loss:  0.0002481563133187592
Epoch:  265  	Training Loss: 0.00024807368754409254
Test Loss:  0.00013766527990810573
Valid Loss:  0.0002478050591889769
Epoch:  266  	Training Loss: 0.0002475534856785089
Test Loss:  0.0001372851838823408
Valid Loss:  0.0002474967041052878
Epoch:  267  	Training Loss: 0.0002470393665134907
Test Loss:  0.00013689979095943272
Valid Loss:  0.0002471810148563236
Epoch:  268  	Training Loss: 0.0002465293509885669
Test Loss:  0.00013651243352796882
Valid Loss:  0.0002468604943715036
Epoch:  269  	Training Loss: 0.0002460224786773324
Test Loss:  0.00013612405746243894
Valid Loss:  0.0002465386933181435
Epoch:  270  	Training Loss: 0.0002455190406180918
Test Loss:  0.0001357344735879451
Valid Loss:  0.00024622230557724833
Epoch:  271  	Training Loss: 0.0002450177271384746
Test Loss:  0.0001353447587462142
Valid Loss:  0.0002459018141962588
Epoch:  272  	Training Loss: 0.00024452246725559235
Test Loss:  0.0001342775794910267
Valid Loss:  0.00024493844830431044
Epoch:  273  	Training Loss: 0.00024344353005290031
Test Loss:  0.00013333652168512344
Valid Loss:  0.00024411670165136456
Epoch:  274  	Training Loss: 0.00024239602498710155
Test Loss:  0.00013246014714241028
Valid Loss:   55%|█████▌    | 275/500 [03:10<02:17,  1.63it/s] 55%|█████▌    | 277/500 [03:10<01:39,  2.23it/s] 56%|█████▌    | 279/500 [03:10<01:14,  2.98it/s] 56%|█████▌    | 281/500 [03:16<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:17<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:17<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:17<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:17<01:09,  3.03it/s] 58%|█████▊    | 291/500 [03:23<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:23<02:53,  1.19it/s] 59%|█████▉    | 295/500 [03:24<02:04,  1.65it/s] 59%|█████▉    | 297/500 [03:24<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:24<01:06,  3.03it/s] 60%|██████    | 301/500 [03:30<03:52,  1.17s/it] 61%|██████    | 303/500 [03:30<02:45,  1.19it/s] 61%|██████    | 305/500 [03:30<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:30<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:31<01:03,  3.03it/s] 62%|██████▏   | 311/500 [03:37<03:38,  1.16s/it] 63%|██████▎   | 313/500 [03:37<02:35,  1.20it/s] 63%|██████▎   | 315/500 [03:37<01:51,  1.66it/s] 63%|██████▎   | 317/500 [03:37<01:20,  2.27it/s] 64%|██████▍   | 319/500 [03:37<00:59,  3.05it/s] 64%|██████▍   | 321/500 [03:44<03:32,  1.18s/it] 65%|██████▍   | 323/500 [03:44<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:44<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:44<01:17,  2.22it/s] 66%|██████▌   | 329/500 [03:44<00:57,  2.99it/s] 66%|██████▌   | 331/500 [03:50<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:51<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:51<01:41,  1.63it/s] 67%|██████▋   | 337/500 [03:51<01:13,  2.22it/s] 68%|██████▊   | 339/500 [03:51<00:54,  2.98it/s]0.00024336724891327322
Epoch:  275  	Training Loss: 0.00024136928550433367
Test Loss:  0.00013163448602426797
Valid Loss:  0.00024265922547783703
Epoch:  276  	Training Loss: 0.00024035821843426675
Test Loss:  0.00013085764658171684
Valid Loss:  0.00024200178449973464
Epoch:  277  	Training Loss: 0.0002393626928096637
Test Loss:  0.0001300989097217098
Valid Loss:  0.00024136167485266924
Epoch:  278  	Training Loss: 0.00023838227207306772
Test Loss:  0.00012939132284373045
Valid Loss:  0.0002407568390481174
Epoch:  279  	Training Loss: 0.00023743259953334928
Test Loss:  0.00012870528735220432
Valid Loss:  0.00024016588577069342
Epoch:  280  	Training Loss: 0.00023650747607462108
Test Loss:  0.0001280317228520289
Valid Loss:  0.0002395859337411821
Epoch:  281  	Training Loss: 0.00023559729743283242
Test Loss:  0.0001273720117751509
Valid Loss:  0.00023902009706944227
Epoch:  282  	Training Loss: 0.00023469941515941173
Test Loss:  0.00012626900570467114
Valid Loss:  0.00023799538030289114
Epoch:  283  	Training Loss: 0.00023367196263279766
Test Loss:  0.0001256322138942778
Valid Loss:  0.00023750876425765455
Epoch:  284  	Training Loss: 0.00023260104353539646
Test Loss:  0.00012495223199948668
Valid Loss:  0.00023696557036601007
Epoch:  285  	Training Loss: 0.00023157120449468493
Test Loss:  0.00012409711780492216
Valid Loss:  0.00023619140847586095
Epoch:  286  	Training Loss: 0.00023060236708261073
Test Loss:  0.00012345796858426183
Valid Loss:  0.00023566570598632097
Epoch:  287  	Training Loss: 0.00022962168441154063
Test Loss:  0.00012256824993528426
Valid Loss:  0.00023483208497054875
Epoch:  288  	Training Loss: 0.00022869826352689415
Test Loss:  0.00012197584874229506
Valid Loss:  0.00023435337061528116
Epoch:  289  	Training Loss: 0.00022772964439354837
Test Loss:  0.00012135728320572525
Valid Loss:  0.00023384977248497307
Epoch:  290  	Training Loss: 0.00022682672715745866
Test Loss:  0.00012040665751555935
Valid Loss:  0.00023293914273381233
Epoch:  291  	Training Loss: 0.00022594384790863842
Test Loss:  0.00011986949539277703
Valid Loss:  0.00023253416293300688
Epoch:  292  	Training Loss: 0.00022501868079416454
Test Loss:  0.00011984360025962815
Valid Loss:  0.00023256518761627376
Epoch:  293  	Training Loss: 0.00022460946638602763
Test Loss:  0.0001197206147480756
Valid Loss:  0.00023248160141520202
Epoch:  294  	Training Loss: 0.0002242211194243282
Test Loss:  0.00011954513320233673
Valid Loss:  0.0002323364606127143
Epoch:  295  	Training Loss: 0.00022384295880328864
Test Loss:  0.00011933040514122695
Valid Loss:  0.00023215082183014601
Epoch:  296  	Training Loss: 0.00022346798505168408
Test Loss:  0.00011909131717402488
Valid Loss:  0.00023192985099740326
Epoch:  297  	Training Loss: 0.00022309774067252874
Test Loss:  0.00011884413834195584
Valid Loss:  0.0002317043108632788
Epoch:  298  	Training Loss: 0.00022273378272075206
Test Loss:  0.00011859720689244568
Valid Loss:  0.00023148061882238835
Epoch:  299  	Training Loss: 0.0002223746123490855
Test Loss:  0.00011834785982500762
Valid Loss:  0.0002312538563273847
Epoch:  300  	Training Loss: 0.00022201999672688544
Test Loss:  0.00011810133582912385
Valid Loss:  0.00023102399427443743
Epoch:  301  	Training Loss: 0.0002216717111878097
Test Loss:  0.00011785543756559491
Valid Loss:  0.00023079465609043837
Epoch:  302  	Training Loss: 0.00022133003221824765
Test Loss:  0.00011759753397200257
Valid Loss:  0.00023055275960359722
Epoch:  303  	Training Loss: 0.00022090462152846158
Test Loss:  0.00011731350241461769
Valid Loss:  0.00023028429131954908
Epoch:  304  	Training Loss: 0.00022048287792131305
Test Loss:  0.00011702497431542724
Valid Loss:  0.00023000940564088523
Epoch:  305  	Training Loss: 0.0002200641029048711
Test Loss:  0.00011672940308926627
Valid Loss:  0.00022973032901063561
Epoch:  306  	Training Loss: 0.0002196484711021185
Test Loss:  0.00011644138430710882
Valid Loss:  0.00022945030650589615
Epoch:  307  	Training Loss: 0.00021923740860074759
Test Loss:  0.00011615583207458258
Valid Loss:  0.0002291739801876247
Epoch:  308  	Training Loss: 0.0002188333310186863
Test Loss:  0.00011587480548769236
Valid Loss:  0.00022889864339958876
Epoch:  309  	Training Loss: 0.00021843446302227676
Test Loss:  0.00011560047278180718
Valid Loss:  0.00022862476180307567
Epoch:  310  	Training Loss: 0.00021803764684591442
Test Loss:  0.00011533559882082045
Valid Loss:  0.00022835267009213567
Epoch:  311  	Training Loss: 0.0002176436100853607
Test Loss:  0.00011507677845656872
Valid Loss:  0.00022808235371485353
Epoch:  312  	Training Loss: 0.00021725488477386534
Test Loss:  0.00011446217831689864
Valid Loss:  0.00022751516371499747
Epoch:  313  	Training Loss: 0.0002165916666854173
Test Loss:  0.00011387384438421577
Valid Loss:  0.00022698119573760778
Epoch:  314  	Training Loss: 0.00021594366990029812
Test Loss:  0.00011331182031426579
Valid Loss:  0.000226474367082119
Epoch:  315  	Training Loss: 0.00021530923550017178
Test Loss:  0.00011277283192612231
Valid Loss:  0.0002259937464259565
Epoch:  316  	Training Loss: 0.00021469072089530528
Test Loss:  0.00011225507478229702
Valid Loss:  0.0002255347790196538
Epoch:  317  	Training Loss: 0.0002140814031008631
Test Loss:  0.00011175224062753841
Valid Loss:  0.00022508918482344598
Epoch:  318  	Training Loss: 0.00021348221343941987
Test Loss:  0.00011126578465336934
Valid Loss:  0.0002246601798105985
Epoch:  319  	Training Loss: 0.00021289283176884055
Test Loss:  0.00011079538671765476
Valid Loss:  0.00022424524649977684
Epoch:  320  	Training Loss: 0.00021231347636785358
Test Loss:  0.00011033695045625791
Valid Loss:  0.00022384290059562773
Epoch:  321  	Training Loss: 0.000211742939427495
Test Loss:  0.00010989813745254651
Valid Loss:  0.0002234520943602547
Epoch:  322  	Training Loss: 0.0002111823414452374
Test Loss:  0.00011002132669091225
Valid Loss:  0.00022365136828739196
Epoch:  323  	Training Loss: 0.0002109833585564047
Test Loss:  0.0001100657755159773
Valid Loss:  0.00022374186664819717
Epoch:  324  	Training Loss: 0.00021081126760691404
Test Loss:  0.0001100568551919423
Valid Loss:  0.00022376069682650268
Epoch:  325  	Training Loss: 0.00021064994507469237
Test Loss:  0.00011002593964803964
Valid Loss:  0.0002237476728623733
Epoch:  326  	Training Loss: 0.00021049522911198437
Test Loss:  0.00010997193749062717
Valid Loss:  0.0002237048902316019
Epoch:  327  	Training Loss: 0.0002103460719808936
Test Loss:  0.00010990104783559218
Valid Loss:  0.0002236411819467321
Epoch:  328  	Training Loss: 0.00021019820997025818
Test Loss:  0.0001098232387448661
Valid Loss:  0.00022356075351126492
Epoch:  329  	Training Loss: 0.00021005136659368873
Test Loss:  0.00010974142787745222
Valid Loss:  0.00022347300546243787
Epoch:  330  	Training Loss: 0.00020990677876397967
Test Loss:  0.00010965607361868024
Valid Loss:  0.00022338246344588697
Epoch:  331  	Training Loss: 0.0002097622345900163
Test Loss:  0.00010957024642266333
Valid Loss:  0.0002232894767075777
Epoch:  332  	Training Loss: 0.00020961789414286613
Test Loss:  0.00010942138032987714
Valid Loss:  0.00022321674623526633
Epoch:  333  	Training Loss: 0.0002093215734930709
Test Loss:  0.00010925245442194864
Valid Loss:  0.00022310798522084951
Epoch:  334  	Training Loss: 0.00020903759286738932
Test Loss:  0.00010907469550147653
Valid Loss:  0.00022296802490018308
Epoch:  335  	Training Loss: 0.00020876506459899247
Test Loss:  0.00010889511031564325
Valid Loss:  0.00022282241843640804
Epoch:  336  	Training Loss: 0.00020850200962740928
Test Loss:  0.00010871367703657597
Valid Loss:  0.00022267211170401424
Epoch:  337  	Training Loss: 0.0002082506543956697
Test Loss:  0.00010852823470486328
Valid Loss:  0.0002225116768386215
Epoch:  338  	Training Loss: 0.00020800474158022553
Test Loss:  0.00010834643035195768
Valid Loss:  0.00022235212964005768
Epoch:  339  	Training Loss: 0.0002077604876831174
Test Loss:  0.00010816915892064571
Valid Loss:  0.00022219005040824413
Epoch:  340  	Training Loss: 0.00020752035197801888
Test Loss:  0.00010798903531394899
Valid Loss:  0.00022201785759534687
Epoch:  341  	Training Loss: 0.00020728856907226145
Test Loss:  0.00010781260061776266
 68%|██████▊   | 341/500 [03:57<03:05,  1.17s/it] 69%|██████▊   | 343/500 [03:57<02:11,  1.19it/s] 69%|██████▉   | 345/500 [03:58<01:34,  1.64it/s] 69%|██████▉   | 347/500 [03:58<01:08,  2.24it/s] 70%|██████▉   | 349/500 [03:58<00:50,  3.01it/s] 70%|███████   | 351/500 [04:04<02:55,  1.18s/it] 71%|███████   | 353/500 [04:04<02:04,  1.18it/s] 71%|███████   | 355/500 [04:04<01:28,  1.63it/s] 71%|███████▏  | 357/500 [04:04<01:04,  2.23it/s] 72%|███████▏  | 359/500 [04:05<00:47,  2.99it/s] 72%|███████▏  | 361/500 [04:11<02:41,  1.16s/it] 73%|███████▎  | 363/500 [04:11<01:54,  1.19it/s] 73%|███████▎  | 365/500 [04:11<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:11<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:11<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:18<02:30,  1.17s/it] 75%|███████▍  | 373/500 [04:18<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:18<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:18<00:54,  2.25it/s] 76%|███████▌  | 379/500 [04:18<00:40,  3.02it/s] 76%|███████▌  | 381/500 [04:24<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:25<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:25<01:09,  1.64it/s] 77%|███████▋  | 387/500 [04:25<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:25<00:37,  2.97it/s] 78%|███████▊  | 391/500 [04:31<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:31<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:32<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:32<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:32<00:34,  2.97it/s] 80%|████████  | 401/500 [04:38<01:55,  1.17s/it] 81%|████████  | 403/500 [04:38<01:21,  1.19it/s] 81%|████████  | 405/500 [04:38<00:57,  1.65it/s] 81%|████████▏ | 407/500 [04:39<00:41,  2.25it/s]Valid Loss:  0.00022185177658684552
Epoch:  342  	Training Loss: 0.00020705976930912584
Test Loss:  0.000107574240246322
Valid Loss:  0.0002215972781414166
Epoch:  343  	Training Loss: 0.0002068503526970744
Test Loss:  0.00010735843534348533
Valid Loss:  0.00022136404004413635
Epoch:  344  	Training Loss: 0.0002066454035229981
Test Loss:  0.00010715963435359299
Valid Loss:  0.0002211534883826971
Epoch:  345  	Training Loss: 0.0002064431901089847
Test Loss:  0.00010697290417738259
Valid Loss:  0.0002209576196037233
Epoch:  346  	Training Loss: 0.00020624330500140786
Test Loss:  0.0001067974153556861
Valid Loss:  0.00022077650646679103
Epoch:  347  	Training Loss: 0.00020604467135854065
Test Loss:  0.00010663186549209058
Valid Loss:  0.00022060144692659378
Epoch:  348  	Training Loss: 0.0002058466343441978
Test Loss:  0.0001064714597305283
Valid Loss:  0.0002204336633440107
Epoch:  349  	Training Loss: 0.00020565175509545952
Test Loss:  0.00010631790064508095
Valid Loss:  0.00022026861552149057
Epoch:  350  	Training Loss: 0.0002054584037978202
Test Loss:  0.0001061679286067374
Valid Loss:  0.0002201087336288765
Epoch:  351  	Training Loss: 0.00020526652224361897
Test Loss:  0.00010602206748444587
Valid Loss:  0.00021995333372615278
Epoch:  352  	Training Loss: 0.00020507523731794208
Test Loss:  0.00010550403385423124
Valid Loss:  0.00021938567806500942
Epoch:  353  	Training Loss: 0.00020427827257663012
Test Loss:  0.00010496590402908623
Valid Loss:  0.00021880073472857475
Epoch:  354  	Training Loss: 0.00020350368868093938
Test Loss:  0.00010442311759106815
Valid Loss:  0.0002182170719606802
Epoch:  355  	Training Loss: 0.00020274354028515518
Test Loss:  0.0001039102062350139
Valid Loss:  0.0002176373964175582
Epoch:  356  	Training Loss: 0.0002019931562244892
Test Loss:  0.0001034192755469121
Valid Loss:  0.00021706981351599097
Epoch:  357  	Training Loss: 0.00020125260925851762
Test Loss:  0.00010293707600794733
Valid Loss:  0.00021651125280186534
Epoch:  358  	Training Loss: 0.00020052511536050588
Test Loss:  0.00010247417958453298
Valid Loss:  0.00021596861188299954
Epoch:  359  	Training Loss: 0.00019981861987616867
Test Loss:  0.00010202309931628406
Valid Loss:  0.00021544110495597124
Epoch:  360  	Training Loss: 0.0001991385652218014
Test Loss:  0.0001015885645756498
Valid Loss:  0.0002149363572243601
Epoch:  361  	Training Loss: 0.00019848448573611677
Test Loss:  0.00010115754412254319
Valid Loss:  0.00021443964214995503
Epoch:  362  	Training Loss: 0.00019784210599027574
Test Loss:  0.00010121667583007365
Valid Loss:  0.0002145423204638064
Epoch:  363  	Training Loss: 0.00019768369384109974
Test Loss:  0.00010123541869688779
Valid Loss:  0.00021459348499774933
Epoch:  364  	Training Loss: 0.0001975355262402445
Test Loss:  0.00010122309322468936
Valid Loss:  0.000214604806387797
Epoch:  365  	Training Loss: 0.00019739441631827503
Test Loss:  0.0001011871499940753
Valid Loss:  0.00021458585979416966
Epoch:  366  	Training Loss: 0.00019725538732018322
Test Loss:  0.00010113594180438668
Valid Loss:  0.00021454814122989774
Epoch:  367  	Training Loss: 0.0001971190213225782
Test Loss:  0.00010107220441568643
Valid Loss:  0.00021449275664053857
Epoch:  368  	Training Loss: 0.00019698341202456504
Test Loss:  0.00010099921200890094
Valid Loss:  0.00021442730212584138
Epoch:  369  	Training Loss: 0.00019684762810356915
Test Loss:  0.00010092138836625963
Valid Loss:  0.0002143554447684437
Epoch:  370  	Training Loss: 0.0001967125863302499
Test Loss:  0.00010084132372867316
Valid Loss:  0.0002142756275134161
Epoch:  371  	Training Loss: 0.00019657780649140477
Test Loss:  0.00010075767931994051
Valid Loss:  0.00021419217227958143
Epoch:  372  	Training Loss: 0.00019644381245598197
Test Loss:  0.00010009462130255997
Valid Loss:  0.0002134668466169387
Epoch:  373  	Training Loss: 0.00019586412236094475
Test Loss:  9.957904694601893e-05
Valid Loss:  0.0002129410277120769
Epoch:  374  	Training Loss: 0.00019531420548446476
Test Loss:  9.913718531606719e-05
Valid Loss:  0.00021250938880257308
Epoch:  375  	Training Loss: 0.0001947754790307954
Test Loss:  9.873607632471249e-05
Valid Loss:  0.00021213293075561523
Epoch:  376  	Training Loss: 0.00019424626952968538
Test Loss:  9.835861419560388e-05
Valid Loss:  0.00021179139730520546
Epoch:  377  	Training Loss: 0.00019372079987078905
Test Loss:  9.79959440883249e-05
Valid Loss:  0.0002114696690114215
Epoch:  378  	Training Loss: 0.00019320216961205006
Test Loss:  9.764231799636036e-05
Valid Loss:  0.00021115678828209639
Epoch:  379  	Training Loss: 0.00019268815231043845
Test Loss:  9.729529119795188e-05
Valid Loss:  0.00021086014749016613
Epoch:  380  	Training Loss: 0.0001921773364301771
Test Loss:  9.695137123344466e-05
Valid Loss:  0.00021056512196082622
Epoch:  381  	Training Loss: 0.0001916715264087543
Test Loss:  9.660943760536611e-05
Valid Loss:  0.00021027305047027767
Epoch:  382  	Training Loss: 0.00019117114425171167
Test Loss:  9.634602611185983e-05
Valid Loss:  0.00020996876992285252
Epoch:  383  	Training Loss: 0.00019080148194916546
Test Loss:  9.608818800188601e-05
Valid Loss:  0.00020966914598830044
Epoch:  384  	Training Loss: 0.0001904377422761172
Test Loss:  9.583418432157487e-05
Valid Loss:  0.00020937318913638592
Epoch:  385  	Training Loss: 0.00019007801893167198
Test Loss:  9.558588499203324e-05
Valid Loss:  0.00020908804435748607
Epoch:  386  	Training Loss: 0.00018972271936945617
Test Loss:  9.534294076729566e-05
Valid Loss:  0.00020880793454125524
Epoch:  387  	Training Loss: 0.0001893734879558906
Test Loss:  9.510507516097277e-05
Valid Loss:  0.00020853102614637464
Epoch:  388  	Training Loss: 0.00018902857846114784
Test Loss:  9.488120122114196e-05
Valid Loss:  0.00020827536354772747
Epoch:  389  	Training Loss: 0.00018868796178139746
Test Loss:  9.465613402426243e-05
Valid Loss:  0.00020801983191631734
Epoch:  390  	Training Loss: 0.00018835050286725163
Test Loss:  9.443159069633111e-05
Valid Loss:  0.00020776284509338439
Epoch:  391  	Training Loss: 0.00018801554688252509
Test Loss:  9.42104816203937e-05
Valid Loss:  0.00020750766270793974
Epoch:  392  	Training Loss: 0.0001876862079370767
Test Loss:  9.413705993210897e-05
Valid Loss:  0.00020743785717058927
Epoch:  393  	Training Loss: 0.00018739674123935401
Test Loss:  9.401165880262852e-05
Valid Loss:  0.0002073015202768147
Epoch:  394  	Training Loss: 0.00018711262964643538
Test Loss:  9.385958401253447e-05
Valid Loss:  0.00020713353296741843
Epoch:  395  	Training Loss: 0.00018683189409784973
Test Loss:  9.369352483190596e-05
Valid Loss:  0.00020694819977506995
Epoch:  396  	Training Loss: 0.00018655418534763157
Test Loss:  9.352117194794118e-05
Valid Loss:  0.00020675371342804283
Epoch:  397  	Training Loss: 0.00018627896497491747
Test Loss:  9.334181959275156e-05
Valid Loss:  0.00020654991385526955
Epoch:  398  	Training Loss: 0.00018600486509967595
Test Loss:  9.316352952737361e-05
Valid Loss:  0.0002063473657472059
Epoch:  399  	Training Loss: 0.00018573363195173442
Test Loss:  9.298535587731749e-05
Valid Loss:  0.0002061434497591108
Epoch:  400  	Training Loss: 0.00018546311184763908
Test Loss:  9.280841914005578e-05
Valid Loss:  0.0002059432736132294
Epoch:  401  	Training Loss: 0.00018519569130148739
Test Loss:  9.263351967092603e-05
Valid Loss:  0.00020574024529196322
Epoch:  402  	Training Loss: 0.00018492928938940167
Test Loss:  9.20420789043419e-05
Valid Loss:  0.0002050927432719618
Epoch:  403  	Training Loss: 0.0001842054771259427
Test Loss:  9.151382255367935e-05
Valid Loss:  0.00020453485194593668
Epoch:  404  	Training Loss: 0.00018349666788708419
Test Loss:  9.102295734919608e-05
Valid Loss:  0.0002040326944552362
Epoch:  405  	Training Loss: 0.00018280294898431748
Test Loss:  9.055570990312845e-05
Valid Loss:  0.00020356490858830512
Epoch:  406  	Training Loss: 0.00018212065333500504
Test Loss:  9.010567737277597e-05
Valid Loss:  0.00020313356071710587
Epoch:  407  	Training Loss: 0.0001814485585782677
Test Loss:  8.966860332293436e-05
Valid Loss:  0.00020271568791940808
Epoch:  408  	Training Loss: 0.00018079271831084043
Test Loss:  8.924221037887037e-05
Valid Loss:  0.00020230704103596509
 82%|████████▏ | 409/500 [04:39<00:30,  3.02it/s] 82%|████████▏ | 411/500 [04:45<01:44,  1.17s/it] 83%|████████▎ | 413/500 [04:45<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:45<00:51,  1.65it/s] 83%|████████▎ | 417/500 [04:45<00:36,  2.25it/s] 84%|████████▍ | 419/500 [04:45<00:26,  3.02it/s] 84%|████████▍ | 421/500 [04:52<01:31,  1.16s/it] 85%|████████▍ | 423/500 [04:52<01:04,  1.20it/s] 85%|████████▌ | 425/500 [04:52<00:45,  1.66it/s] 85%|████████▌ | 427/500 [04:52<00:32,  2.26it/s] 86%|████████▌ | 429/500 [04:52<00:23,  3.02it/s] 86%|████████▌ | 431/500 [04:58<01:21,  1.18s/it] 87%|████████▋ | 433/500 [04:59<00:56,  1.18it/s] 87%|████████▋ | 435/500 [04:59<00:39,  1.63it/s] 87%|████████▋ | 437/500 [04:59<00:28,  2.23it/s] 88%|████████▊ | 439/500 [04:59<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:05<01:08,  1.17s/it] 89%|████████▊ | 443/500 [05:05<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:06<00:33,  1.65it/s] 89%|████████▉ | 447/500 [05:06<00:23,  2.25it/s] 90%|████████▉ | 449/500 [05:06<00:16,  3.02it/s] 90%|█████████ | 451/500 [05:12<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:12<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:12<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:12<00:19,  2.25it/s] 92%|█████████▏| 459/500 [05:13<00:13,  3.02it/s] 92%|█████████▏| 461/500 [05:19<00:46,  1.18s/it] 93%|█████████▎| 463/500 [05:19<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:19<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:19<00:14,  2.22it/s] 94%|█████████▍| 469/500 [05:19<00:10,  2.99it/s] 94%|█████████▍| 471/500 [05:26<00:34,  1.17s/it] 95%|█████████▍| 473/500 [05:26<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:26<00:15,  1.64it/s]Epoch:  409  	Training Loss: 0.0001801502367015928
Test Loss:  8.882461406756192e-05
Valid Loss:  0.00020191294606775045
Epoch:  410  	Training Loss: 0.0001795165444491431
Test Loss:  8.841375529300421e-05
Valid Loss:  0.00020152490469627082
Epoch:  411  	Training Loss: 0.00017889123409986496
Test Loss:  8.80074585438706e-05
Valid Loss:  0.00020114099606871605
Epoch:  412  	Training Loss: 0.00017827465489972383
Test Loss:  8.777235052548349e-05
Valid Loss:  0.00020087446318939328
Epoch:  413  	Training Loss: 0.00017794608720578253
Test Loss:  8.754442387726158e-05
Valid Loss:  0.00020061395480297506
Epoch:  414  	Training Loss: 0.00017761967319529504
Test Loss:  8.732206333661452e-05
Valid Loss:  0.00020036094065289944
Epoch:  415  	Training Loss: 0.00017729747924022377
Test Loss:  8.710664405953139e-05
Valid Loss:  0.00020011639571748674
Epoch:  416  	Training Loss: 0.00017697783187031746
Test Loss:  8.689714741194621e-05
Valid Loss:  0.00019987764244433492
Epoch:  417  	Training Loss: 0.00017666243365965784
Test Loss:  8.669155795359984e-05
Valid Loss:  0.00019964572857134044
Epoch:  418  	Training Loss: 0.00017634921823628247
Test Loss:  8.649010851513594e-05
Valid Loss:  0.00019941857317462564
Epoch:  419  	Training Loss: 0.00017603926244191825
Test Loss:  8.62929446157068e-05
Valid Loss:  0.00019919680198654532
Epoch:  420  	Training Loss: 0.00017573327932041138
Test Loss:  8.609940414316952e-05
Valid Loss:  0.00019897788297384977
Epoch:  421  	Training Loss: 0.0001754286204231903
Test Loss:  8.59100982779637e-05
Valid Loss:  0.00019876348960679024
Epoch:  422  	Training Loss: 0.00017512762860860676
Test Loss:  8.554426312912256e-05
Valid Loss:  0.00019836376304738224
Epoch:  423  	Training Loss: 0.00017461716197431087
Test Loss:  8.51934528327547e-05
Valid Loss:  0.00019798288121819496
Epoch:  424  	Training Loss: 0.00017411494627594948
Test Loss:  8.485526632284746e-05
Valid Loss:  0.00019761663861572742
Epoch:  425  	Training Loss: 0.00017362379003316164
Test Loss:  8.453093323623762e-05
Valid Loss:  0.00019726554455701262
Epoch:  426  	Training Loss: 0.00017314081196673214
Test Loss:  8.421599341090769e-05
Valid Loss:  0.00019692102796398103
Epoch:  427  	Training Loss: 0.00017266551731154323
Test Loss:  8.391040319111198e-05
Valid Loss:  0.00019659657846204937
Epoch:  428  	Training Loss: 0.00017219815345015377
Test Loss:  8.361396612599492e-05
Valid Loss:  0.00019628883455879986
Epoch:  429  	Training Loss: 0.0001717382692731917
Test Loss:  8.332402649102733e-05
Valid Loss:  0.00019599046208895743
Epoch:  430  	Training Loss: 0.00017128308536484838
Test Loss:  8.304375660372898e-05
Valid Loss:  0.0001957003551069647
Epoch:  431  	Training Loss: 0.00017084024148061872
Test Loss:  8.277020970126614e-05
Valid Loss:  0.00019541283836588264
Epoch:  432  	Training Loss: 0.0001704052701825276
Test Loss:  8.27249969006516e-05
Valid Loss:  0.0001953459286596626
Epoch:  433  	Training Loss: 0.00017010653391480446
Test Loss:  8.264658390544355e-05
Valid Loss:  0.00019523740047588944
Epoch:  434  	Training Loss: 0.00016982002125587314
Test Loss:  8.254453859990463e-05
Valid Loss:  0.00019509797857608646
Epoch:  435  	Training Loss: 0.00016954063903540373
Test Loss:  8.242696640081704e-05
Valid Loss:  0.00019493667059578001
Epoch:  436  	Training Loss: 0.00016926569514907897
Test Loss:  8.230068488046527e-05
Valid Loss:  0.00019476197485346347
Epoch:  437  	Training Loss: 0.00016899529146030545
Test Loss:  8.216733112931252e-05
Valid Loss:  0.0001945802359841764
Epoch:  438  	Training Loss: 0.000168726866832003
Test Loss:  8.202991739381105e-05
Valid Loss:  0.00019439338939264417
Epoch:  439  	Training Loss: 0.00016846063954290003
Test Loss:  8.189086656784639e-05
Valid Loss:  0.00019420690659899265
Epoch:  440  	Training Loss: 0.00016819735174067318
Test Loss:  8.175133552867919e-05
Valid Loss:  0.0001940155343618244
Epoch:  441  	Training Loss: 0.00016793707618489861
Test Loss:  8.161295409081504e-05
Valid Loss:  0.00019382525351829827
Epoch:  442  	Training Loss: 0.00016767915803939104
Test Loss:  8.154945680871606e-05
Valid Loss:  0.00019373884424567223
Epoch:  443  	Training Loss: 0.00016753413365222514
Test Loss:  8.148149936459959e-05
Valid Loss:  0.0001936492626555264
Epoch:  444  	Training Loss: 0.00016738887643441558
Test Loss:  8.140895806718618e-05
Valid Loss:  0.00019355295808054507
Epoch:  445  	Training Loss: 0.00016724455053918064
Test Loss:  8.133508526952937e-05
Valid Loss:  0.00019345650798641145
Epoch:  446  	Training Loss: 0.00016710041381884366
Test Loss:  8.125921158352867e-05
Valid Loss:  0.000193360960111022
Epoch:  447  	Training Loss: 0.00016695640806574374
Test Loss:  8.118215919239447e-05
Valid Loss:  0.00019326151232235134
Epoch:  448  	Training Loss: 0.00016681314446032047
Test Loss:  8.110378257697448e-05
Valid Loss:  0.00019316226826049387
Epoch:  449  	Training Loss: 0.00016667015734128654
Test Loss:  8.102536958176643e-05
Valid Loss:  0.00019306350441183895
Epoch:  450  	Training Loss: 0.00016652802878525108
Test Loss:  8.094670192804188e-05
Valid Loss:  0.00019296444952487946
Epoch:  451  	Training Loss: 0.00016638566739857197
Test Loss:  8.086567686405033e-05
Valid Loss:  0.00019286645692773163
Epoch:  452  	Training Loss: 0.00016624429554212838
Test Loss:  8.065068686846644e-05
Valid Loss:  0.0001926604745676741
Epoch:  453  	Training Loss: 0.00016595737542957067
Test Loss:  8.044455898925662e-05
Valid Loss:  0.00019246921874582767
Epoch:  454  	Training Loss: 0.00016567313286941499
Test Loss:  8.024621638469398e-05
Valid Loss:  0.00019228672317694873
Epoch:  455  	Training Loss: 0.00016539129137527198
Test Loss:  8.005498966667801e-05
Valid Loss:  0.00019211282778996974
Epoch:  456  	Training Loss: 0.00016511308785993606
Test Loss:  7.986909622559324e-05
Valid Loss:  0.00019194306514691561
Epoch:  457  	Training Loss: 0.00016483856597915292
Test Loss:  7.969295256771147e-05
Valid Loss:  0.00019178632646799088
Epoch:  458  	Training Loss: 0.0001645692391321063
Test Loss:  7.951905718073249e-05
Valid Loss:  0.000191628496395424
Epoch:  459  	Training Loss: 0.00016430327377747744
Test Loss:  7.935427129268646e-05
Valid Loss:  0.00019148277351632714
Epoch:  460  	Training Loss: 0.0001640397240407765
Test Loss:  7.918993651401252e-05
Valid Loss:  0.00019133632304146886
Epoch:  461  	Training Loss: 0.0001637806708458811
Test Loss:  7.902660581748933e-05
Valid Loss:  0.00019118805357720703
Epoch:  462  	Training Loss: 0.00016352342208847404
Test Loss:  7.88679244578816e-05
Valid Loss:  0.00019095774041488767
Epoch:  463  	Training Loss: 0.00016323586169164628
Test Loss:  7.871403795434162e-05
Valid Loss:  0.0001907297846628353
Epoch:  464  	Training Loss: 0.00016295199748128653
Test Loss:  7.856651791371405e-05
Valid Loss:  0.00019051440176554024
Epoch:  465  	Training Loss: 0.0001626702432986349
Test Loss:  7.842003833502531e-05
Valid Loss:  0.0001902987132780254
Epoch:  466  	Training Loss: 0.000162391341291368
Test Loss:  7.82727001933381e-05
Valid Loss:  0.0001900817296700552
Epoch:  467  	Training Loss: 0.00016211265756282955
Test Loss:  7.812540570739657e-05
Valid Loss:  0.00018986855866387486
Epoch:  468  	Training Loss: 0.0001618363312445581
Test Loss:  7.798477599862963e-05
Valid Loss:  0.0001896671310532838
Epoch:  469  	Training Loss: 0.00016156415222212672
Test Loss:  7.784771878505126e-05
Valid Loss:  0.00018947021453641355
Epoch:  470  	Training Loss: 0.0001612965716049075
Test Loss:  7.771211676299572e-05
Valid Loss:  0.00018927409837488085
Epoch:  471  	Training Loss: 0.0001610300096217543
Test Loss:  7.757387356832623e-05
Valid Loss:  0.00018907268531620502
Epoch:  472  	Training Loss: 0.00016076750762294978
Test Loss:  7.740583532722667e-05
Valid Loss:  0.00018885359168052673
Epoch:  473  	Training Loss: 0.00016064564988482744
Test Loss:  7.728383206995204e-05
Valid Loss:  0.0001887006510514766
Epoch:  474  	Training Loss: 0.00016053830040618777
Test Loss:  7.721621659584343e-05
Valid Loss:  0.0001886254467535764
Epoch:  475  	Training Loss: 0.00016043732466641814
Test Loss:  7.71489430917427e-05
Valid Loss:  0.00018855510279536247
Epoch:  476  	Training Loss: 0.00016033688734751195
 95%|█████████▌| 477/500 [05:26<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:26<00:06,  3.02it/s] 96%|█████████▌| 481/500 [05:32<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:33<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:33<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:33<00:05,  2.25it/s] 98%|█████████▊| 489/500 [05:33<00:03,  3.01it/s] 98%|█████████▊| 491/500 [05:39<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:39<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:40<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:40<00:01,  2.22it/s]100%|█████████▉| 499/500 [05:40<00:00,  2.98it/s]100%|██████████| 500/500 [05:40<00:00,  1.47it/s]
Test Loss:  7.708375051151961e-05
Valid Loss:  0.00018848474428523332
Epoch:  477  	Training Loss: 0.000160236784722656
Test Loss:  7.701779395574704e-05
Valid Loss:  0.00018841246492229402
Epoch:  478  	Training Loss: 0.0001601378753548488
Test Loss:  7.696816464886069e-05
Valid Loss:  0.00018836368690244853
Epoch:  479  	Training Loss: 0.00016004103235900402
Test Loss:  7.691432256251574e-05
Valid Loss:  0.00018830635235644877
Epoch:  480  	Training Loss: 0.00015994493151083589
Test Loss:  7.685638411203399e-05
Valid Loss:  0.00018824281869456172
Epoch:  481  	Training Loss: 0.00015984944184310734
Test Loss:  7.679707778152078e-05
Valid Loss:  0.0001881767821032554
Epoch:  482  	Training Loss: 0.00015975299174897373
Test Loss:  7.675814413232729e-05
Valid Loss:  0.00018800084944814444
Epoch:  483  	Training Loss: 0.0001595151552464813
Test Loss:  7.668799662496895e-05
Valid Loss:  0.00018779258243739605
Epoch:  484  	Training Loss: 0.00015928110224194825
Test Loss:  7.660800474695861e-05
Valid Loss:  0.0001875784801086411
Epoch:  485  	Training Loss: 0.00015905065811239183
Test Loss:  7.651537453057244e-05
Valid Loss:  0.0001873529690783471
Epoch:  486  	Training Loss: 0.00015882150910329074
Test Loss:  7.64177311793901e-05
Valid Loss:  0.00018712686141952872
Epoch:  487  	Training Loss: 0.00015859400446061045
Test Loss:  7.63176940381527e-05
Valid Loss:  0.00018689977878239006
Epoch:  488  	Training Loss: 0.00015836860984563828
Test Loss:  7.621469558216631e-05
Valid Loss:  0.00018667566473595798
Epoch:  489  	Training Loss: 0.00015814471407793462
Test Loss:  7.611133332829922e-05
Valid Loss:  0.00018645357340574265
Epoch:  490  	Training Loss: 0.00015792108024470508
Test Loss:  7.600829121656716e-05
Valid Loss:  0.0001862327044364065
Epoch:  491  	Training Loss: 0.0001576993818162009
Test Loss:  7.590452878503129e-05
Valid Loss:  0.00018601628835313022
Epoch:  492  	Training Loss: 0.00015747906581964344
Test Loss:  7.572321192128584e-05
Valid Loss:  0.00018579605966806412
Epoch:  493  	Training Loss: 0.0001572440523887053
Test Loss:  7.556195487268269e-05
Valid Loss:  0.00018560215539764613
Epoch:  494  	Training Loss: 0.00015701260417699814
Test Loss:  7.54127831896767e-05
Valid Loss:  0.00018542478210292757
Epoch:  495  	Training Loss: 0.0001567816361784935
Test Loss:  7.526928675360978e-05
Valid Loss:  0.00018525395717006177
Epoch:  496  	Training Loss: 0.00015655293827876449
Test Loss:  7.513136370107532e-05
Valid Loss:  0.00018508805078454316
Epoch:  497  	Training Loss: 0.0001563256373628974
Test Loss:  7.499538332922384e-05
Valid Loss:  0.00018492582603357732
Epoch:  498  	Training Loss: 0.0001560993114253506
Test Loss:  7.486171671189368e-05
Valid Loss:  0.00018476413970347494
Epoch:  499  	Training Loss: 0.00015587407688144594
Test Loss:  7.472930883523077e-05
Valid Loss:  0.00018460271530784667
Epoch:  500  	Training Loss: 0.000155646848725155
Test Loss:  7.459819607902318e-05
Valid Loss:  0.00018443955923430622
seed is  6
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:31, 16.06it/s]  1%|          | 4/500 [00:00<00:30, 16.22it/s]  1%|          | 6/500 [00:00<00:30, 16.32it/s]  2%|▏         | 8/500 [00:00<00:30, 16.18it/s]  2%|▏         | 10/500 [00:00<00:30, 16.29it/s]  2%|▏         | 12/500 [00:00<00:29, 16.35it/s]  3%|▎         | 14/500 [00:00<00:29, 16.40it/s]  3%|▎         | 16/500 [00:00<00:29, 16.40it/s]  4%|▎         | 18/500 [00:01<00:29, 16.43it/s]  4%|▍         | 20/500 [00:01<00:29, 16.43it/s]  4%|▍         | 22/500 [00:01<00:29, 16.45it/s]  5%|▍         | 24/500 [00:01<00:28, 16.47it/s]  5%|▌         | 26/500 [00:01<00:28, 16.47it/s]  6%|▌         | 28/500 [00:01<00:28, 16.47it/s]  6%|▌         | 30/500 [00:01<00:28, 16.48it/s]  6%|▋         | 32/500 [00:01<00:28, 16.32it/s]  7%|▋         | 34/500 [00:02<00:28, 16.35it/s]  7%|▋         | 36/500 [00:02<00:28, 16.23it/s]  8%|▊         | 38/500 [00:02<00:28, 16.23it/s]  8%|▊         | 40/500 [00:02<00:28, 16.25it/s]  8%|▊         | 42/500 [00:02<00:28, 16.27it/s]  9%|▉         | 44/500 [00:02<00:28, 16.25it/s]  9%|▉         | 46/500 [00:02<00:27, 16.28it/s] 10%|▉         | 48/500 [00:02<00:27, 16.34it/s] 10%|█         | 50/500 [00:03<00:27, 16.27it/s] 10%|█         | 52/500 [00:03<00:27, 16.29it/s] 11%|█         | 54/500 [00:03<00:27, 16.36it/s] 11%|█         | 56/500 [00:03<00:27, 16.32it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.32it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.35it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.36it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.34it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.35it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.26it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.21it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.26it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.29it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.32it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.32it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.31it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.16it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.09it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.17it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.24it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.30it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.39it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.30it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.23it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.32it/s] 20%|██        | 100/500 [00:06<00:24, 16.39it/s] 20%|██        | 102/500 [00:06<00:24, 16.35it/s] 21%|██        | 104/500 [00:06<00:24, 16.34it/s] 21%|██        | 106/500 [00:06<00:24, 16.34it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.01it/s] 22%|██▏       | 110/500 [00:06<00:24, 16.13it/s] 22%|██▏       | 112/500 [00:06<00:24, 16.14it/s] 23%|██▎       | 114/500 [00:07<00:25, 15.21it/s] 23%|██▎       | 116/500 [00:07<00:26, 14.29it/s] 24%|██▎       | 118/500 [00:07<00:27, 13.77it/s] 24%|██▍       | 120/500 [00:07<00:28, 13.30it/s] 24%|██▍       | 122/500 [00:07<00:28, 13.05it/s] 25%|██▍       | 124/500 [00:07<00:28, 13.22it/s]Epoch:  1  	Training Loss: 0.023515261709690094
Test Loss:  6.851985931396484
Valid Loss:  6.847030162811279
Epoch:  2  	Training Loss: 6.825981140136719
Test Loss:  39549184.0
Valid Loss:  39581172.0
Epoch:  3  	Training Loss: 39613352.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  125  	Training Loss: nan
 25%|██▌       | 126/500 [00:07<00:27, 13.84it/s] 26%|██▌       | 128/500 [00:08<00:26, 13.85it/s] 26%|██▌       | 130/500 [00:08<00:25, 14.54it/s] 26%|██▋       | 132/500 [00:08<00:24, 15.06it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.47it/s] 27%|██▋       | 136/500 [00:08<00:23, 15.60it/s] 28%|██▊       | 138/500 [00:08<00:22, 15.82it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.04it/s] 28%|██▊       | 142/500 [00:08<00:22, 16.09it/s] 29%|██▉       | 144/500 [00:09<00:21, 16.19it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.31it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.38it/s] 30%|███       | 150/500 [00:09<00:21, 16.40it/s] 30%|███       | 152/500 [00:09<00:21, 16.43it/s] 31%|███       | 154/500 [00:09<00:21, 16.41it/s] 31%|███       | 156/500 [00:09<00:20, 16.41it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.38it/s] 32%|███▏      | 160/500 [00:10<00:20, 16.36it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.34it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.12it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.22it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.28it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.31it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.12it/s] 35%|███▍      | 174/500 [00:10<00:20, 16.16it/s] 35%|███▌      | 176/500 [00:11<00:20, 16.15it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.26it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.30it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.35it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.42it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.38it/s] 38%|███▊      | 188/500 [00:11<00:18, 16.43it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.42it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.38it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.38it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.37it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.22it/s] 40%|████      | 200/500 [00:12<00:18, 16.13it/s] 40%|████      | 202/500 [00:12<00:18, 16.23it/s] 41%|████      | 204/500 [00:12<00:18, 16.27it/s] 41%|████      | 206/500 [00:12<00:18, 16.31it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.33it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.36it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.38it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.36it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.36it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.39it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.37it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.36it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.34it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.32it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.33it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.14it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.26it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.31it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.35it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.38it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.38it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.38it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.44it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.42it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.38it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  249  	Training Loss: nan
 50%|█████     | 250/500 [00:15<00:15, 16.34it/s] 50%|█████     | 252/500 [00:15<00:15, 16.31it/s] 51%|█████     | 254/500 [00:15<00:15, 16.24it/s] 51%|█████     | 256/500 [00:15<00:14, 16.29it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.44it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.52it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.56it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.58it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.54it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.53it/s] 54%|█████▍    | 270/500 [00:16<00:13, 16.52it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.56it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.57it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.55it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.52it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.49it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.45it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.46it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.44it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.48it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.43it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.39it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.39it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.38it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.18it/s] 60%|██████    | 300/500 [00:18<00:12, 16.18it/s] 60%|██████    | 302/500 [00:18<00:12, 16.31it/s] 61%|██████    | 304/500 [00:18<00:11, 16.34it/s] 61%|██████    | 306/500 [00:18<00:11, 16.41it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.37it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.19it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.17it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.18it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.23it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.35it/s] 64%|██████▍   | 320/500 [00:19<00:10, 16.37it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.37it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.38it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.39it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.38it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.31it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.20it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.26it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.14it/s] 68%|██████▊   | 338/500 [00:20<00:10, 16.14it/s] 68%|██████▊   | 340/500 [00:21<00:10, 15.92it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.03it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.17it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.24it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.18it/s] 70%|███████   | 350/500 [00:21<00:09, 15.71it/s] 70%|███████   | 352/500 [00:21<00:09, 15.77it/s] 71%|███████   | 354/500 [00:21<00:09, 15.65it/s] 71%|███████   | 356/500 [00:22<00:09, 15.88it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.05it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.16it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.23it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.28it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.32it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.39it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.37it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.41it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  373  	Training Loss: nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.45it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.51it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.52it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.53it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.50it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.47it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.48it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.45it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.29it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.37it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.40it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.26it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.22it/s] 80%|████████  | 400/500 [00:24<00:06, 16.24it/s] 80%|████████  | 402/500 [00:24<00:06, 16.29it/s] 81%|████████  | 404/500 [00:24<00:05, 16.20it/s] 81%|████████  | 406/500 [00:25<00:05, 16.31it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.13it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.24it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.31it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.21it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.20it/s] 84%|████████▎ | 418/500 [00:25<00:05, 16.26it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.33it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.16it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.21it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.33it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.33it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.34it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.35it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.35it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.37it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.36it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.23it/s] 88%|████████▊ | 442/500 [00:27<00:03, 15.93it/s] 89%|████████▉ | 444/500 [00:27<00:03, 15.28it/s] 89%|████████▉ | 446/500 [00:27<00:03, 14.98it/s] 90%|████████▉ | 448/500 [00:27<00:03, 15.41it/s] 90%|█████████ | 450/500 [00:27<00:03, 15.70it/s] 90%|█████████ | 452/500 [00:27<00:03, 15.93it/s] 91%|█████████ | 454/500 [00:28<00:02, 15.86it/s] 91%|█████████ | 456/500 [00:28<00:02, 15.65it/s] 92%|█████████▏| 458/500 [00:28<00:02, 14.39it/s] 92%|█████████▏| 460/500 [00:28<00:02, 14.94it/s] 92%|█████████▏| 462/500 [00:28<00:02, 15.30it/s] 93%|█████████▎| 464/500 [00:28<00:02, 15.44it/s] 93%|█████████▎| 466/500 [00:28<00:02, 15.71it/s] 94%|█████████▎| 468/500 [00:29<00:02, 15.90it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.03it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.14it/s] 95%|█████████▍| 474/500 [00:29<00:01, 14.91it/s] 95%|█████████▌| 476/500 [00:29<00:01, 14.65it/s] 96%|█████████▌| 478/500 [00:29<00:01, 15.13it/s] 96%|█████████▌| 480/500 [00:29<00:01, 15.42it/s] 96%|█████████▋| 482/500 [00:29<00:01, 15.58it/s] 97%|█████████▋| 484/500 [00:30<00:01, 15.63it/s] 97%|█████████▋| 486/500 [00:30<00:00, 15.81it/s] 98%|█████████▊| 488/500 [00:30<00:00, 15.97it/s] 98%|█████████▊| 490/500 [00:30<00:00, 15.92it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.07it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.15it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.18it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
100%|█████████▉| 498/500 [00:30<00:00, 16.22it/s]100%|██████████| 500/500 [00:31<00:00, 16.23it/s]100%|██████████| 500/500 [00:31<00:00, 16.10it/s]
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  6
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:16,  6.17s/it]  1%|          | 3/500 [00:06<13:40,  1.65s/it]  1%|          | 5/500 [00:06<06:53,  1.20it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:48,  2.92it/s]  2%|▏         | 11/500 [00:12<10:43,  1.32s/it]  3%|▎         | 13/500 [00:13<07:18,  1.11it/s]  3%|▎         | 15/500 [00:13<05:06,  1.58it/s]  3%|▎         | 17/500 [00:13<03:38,  2.21it/s]  4%|▍         | 19/500 [00:13<02:39,  3.01it/s]  4%|▍         | 21/500 [00:19<09:28,  1.19s/it]  5%|▍         | 23/500 [00:19<06:43,  1.18it/s]  5%|▌         | 25/500 [00:19<04:49,  1.64it/s]  5%|▌         | 27/500 [00:20<03:30,  2.25it/s]  6%|▌         | 29/500 [00:20<02:35,  3.02it/s]  6%|▌         | 31/500 [00:26<09:05,  1.16s/it]  7%|▋         | 33/500 [00:26<06:29,  1.20it/s]  7%|▋         | 35/500 [00:26<04:40,  1.66it/s]  7%|▋         | 37/500 [00:26<03:24,  2.26it/s]  8%|▊         | 39/500 [00:26<02:32,  3.03it/s]  8%|▊         | 41/500 [00:33<08:56,  1.17s/it]  9%|▊         | 43/500 [00:33<06:23,  1.19it/s]  9%|▉         | 45/500 [00:33<04:36,  1.65it/s]  9%|▉         | 47/500 [00:33<03:21,  2.25it/s] 10%|▉         | 49/500 [00:33<02:29,  3.02it/s] 10%|█         | 51/500 [00:40<08:45,  1.17s/it] 11%|█         | 53/500 [00:40<06:15,  1.19it/s] 11%|█         | 55/500 [00:40<04:30,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.24it/s] 12%|█▏        | 59/500 [00:40<02:26,  3.02it/s] 12%|█▏        | 61/500 [00:46<08:39,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:11,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:27,  1.63it/s] 13%|█▎        | 67/500 [00:47<03:14,  2.22it/s] 14%|█▍        | 69/500 [00:47<02:24,  2.99it/s] 14%|█▍        | 71/500 [00:53<08:29,  1.19s/it]Epoch:  1  	Training Loss: 0.023515261709690094
Test Loss:  0.02927178144454956
Valid Loss:  0.03068471886217594
Epoch:  2  	Training Loss: 0.02548222616314888
Test Loss:  0.706411600112915
Valid Loss:  0.7128890752792358
Epoch:  3  	Training Loss: 0.6844223141670227
Test Loss:  0.0355696864426136
Valid Loss:  0.034869205206632614
Epoch:  4  	Training Loss: 0.03156963735818863
Test Loss:  0.03549470379948616
Valid Loss:  0.03479146957397461
Epoch:  5  	Training Loss: 0.031514972448349
Test Loss:  0.03542006388306618
Valid Loss:  0.034714095294475555
Epoch:  6  	Training Loss: 0.031460583209991455
Test Loss:  0.03534574806690216
Valid Loss:  0.03463706374168396
Epoch:  7  	Training Loss: 0.0314064584672451
Test Loss:  0.0352717787027359
Valid Loss:  0.03456038609147072
Epoch:  8  	Training Loss: 0.03135260194540024
Test Loss:  0.035198140889406204
Valid Loss:  0.034484051167964935
Epoch:  9  	Training Loss: 0.031299009919166565
Test Loss:  0.03512483090162277
Valid Loss:  0.03440805524587631
Epoch:  10  	Training Loss: 0.031245678663253784
Test Loss:  0.0350518599152565
Valid Loss:  0.034332405775785446
Epoch:  11  	Training Loss: 0.031192613765597343
Test Loss:  0.0349792018532753
Valid Loss:  0.03425709158182144
Epoch:  12  	Training Loss: 0.031139802187681198
Test Loss:  0.03490334004163742
Valid Loss:  0.03417855128645897
Epoch:  13  	Training Loss: 0.03108447603881359
Test Loss:  0.03482784330844879
Valid Loss:  0.03410039097070694
Epoch:  14  	Training Loss: 0.031029433012008667
Test Loss:  0.03475271165370941
Valid Loss:  0.034022603183984756
Epoch:  15  	Training Loss: 0.030974674969911575
Test Loss:  0.03467794135212898
Valid Loss:  0.033945199102163315
Epoch:  16  	Training Loss: 0.030920205637812614
Test Loss:  0.034603532403707504
Valid Loss:  0.033868156373500824
Epoch:  17  	Training Loss: 0.030866017565131187
Test Loss:  0.03452947363257408
Valid Loss:  0.033791493624448776
Epoch:  18  	Training Loss: 0.030812110751867294
Test Loss:  0.03445577621459961
Valid Loss:  0.03371519595384598
Epoch:  19  	Training Loss: 0.030758488923311234
Test Loss:  0.03438243269920349
Valid Loss:  0.03363926708698273
Epoch:  20  	Training Loss: 0.03070513904094696
Test Loss:  0.034309446811676025
Valid Loss:  0.033563703298568726
Epoch:  21  	Training Loss: 0.030652068555355072
Test Loss:  0.03423679992556572
Valid Loss:  0.033488497138023376
Epoch:  22  	Training Loss: 0.03059927187860012
Test Loss:  0.034165725111961365
Valid Loss:  0.03341488912701607
Epoch:  23  	Training Loss: 0.030547672882676125
Test Loss:  0.034094952046871185
Valid Loss:  0.03334159776568413
Epoch:  24  	Training Loss: 0.030496319755911827
Test Loss:  0.034024499356746674
Valid Loss:  0.03326863795518875
Epoch:  25  	Training Loss: 0.030445218086242676
Test Loss:  0.03395436331629753
Valid Loss:  0.03319600597023964
Epoch:  26  	Training Loss: 0.030394360423088074
Test Loss:  0.033884529024362564
Valid Loss:  0.0331236869096756
Epoch:  27  	Training Loss: 0.03034374490380287
Test Loss:  0.033815011382102966
Valid Loss:  0.03305169939994812
Epoch:  28  	Training Loss: 0.030293378978967667
Test Loss:  0.033745795488357544
Valid Loss:  0.03298003226518631
Epoch:  29  	Training Loss: 0.030243247747421265
Test Loss:  0.03367689624428749
Valid Loss:  0.03290867805480957
Epoch:  30  	Training Loss: 0.03019336238503456
Test Loss:  0.033608295023441315
Valid Loss:  0.0328376367688179
Epoch:  31  	Training Loss: 0.03014371544122696
Test Loss:  0.033539995551109314
Valid Loss:  0.032766908407211304
Epoch:  32  	Training Loss: 0.030094299465417862
Test Loss:  0.03347255289554596
Valid Loss:  0.03269704431295395
Epoch:  33  	Training Loss: 0.03004557266831398
Test Loss:  0.033405423164367676
Valid Loss:  0.032627515494823456
Epoch:  34  	Training Loss: 0.029997102916240692
Test Loss:  0.033338624984025955
Valid Loss:  0.032558321952819824
Epoch:  35  	Training Loss: 0.029948879033327103
Test Loss:  0.033272139728069305
Valid Loss:  0.032489459961652756
Epoch:  36  	Training Loss: 0.02990090474486351
Test Loss:  0.03320597857236862
Valid Loss:  0.03242092579603195
Epoch:  37  	Training Loss: 0.029853176325559616
Test Loss:  0.03314013406634331
Valid Loss:  0.03235272318124771
Epoch:  38  	Training Loss: 0.02980569377541542
Test Loss:  0.033074598759412766
Valid Loss:  0.032284852117300034
Epoch:  39  	Training Loss: 0.029758457094430923
Test Loss:  0.03300938010215759
Valid Loss:  0.03221729397773743
Epoch:  40  	Training Loss: 0.029711458832025528
Test Loss:  0.03294447809457779
Valid Loss:  0.03215006738901138
Epoch:  41  	Training Loss: 0.02966470643877983
Test Loss:  0.03287987411022186
Valid Loss:  0.032083164900541306
Epoch:  42  	Training Loss: 0.029618188738822937
Test Loss:  0.032816220074892044
Valid Loss:  0.03201722353696823
Epoch:  43  	Training Loss: 0.02957238256931305
Test Loss:  0.032752856612205505
Valid Loss:  0.03195159137248993
Epoch:  44  	Training Loss: 0.02952680177986622
Test Loss:  0.03268979489803314
Valid Loss:  0.0318862721323967
Epoch:  45  	Training Loss: 0.029481451958417892
Test Loss:  0.03262702375650406
Valid Loss:  0.03182124346494675
Epoch:  46  	Training Loss: 0.029436323791742325
Test Loss:  0.03256453573703766
Valid Loss:  0.03175652399659157
Epoch:  47  	Training Loss: 0.029391424730420113
Test Loss:  0.032502345740795135
Valid Loss:  0.031692106276750565
Epoch:  48  	Training Loss: 0.02934674732387066
Test Loss:  0.032440438866615295
Valid Loss:  0.03162799030542374
Epoch:  49  	Training Loss: 0.029302291572093964
Test Loss:  0.032378822565078735
Valid Loss:  0.03156416118144989
Epoch:  50  	Training Loss: 0.02925805374979973
Test Loss:  0.03231748938560486
Valid Loss:  0.03150063753128052
Epoch:  51  	Training Loss: 0.029214031994342804
Test Loss:  0.03225643187761307
Valid Loss:  0.03143740072846413
Epoch:  52  	Training Loss: 0.02917023003101349
Test Loss:  0.03219582885503769
Valid Loss:  0.03137462958693504
Epoch:  53  	Training Loss: 0.029126789420843124
Test Loss:  0.032135505229234695
Valid Loss:  0.031312134116888046
Epoch:  54  	Training Loss: 0.029083561152219772
Test Loss:  0.032075442373752594
Valid Loss:  0.031249918043613434
Epoch:  55  	Training Loss: 0.029040537774562836
Test Loss:  0.03201565146446228
Valid Loss:  0.031187983229756355
Epoch:  56  	Training Loss: 0.028997717425227165
Test Loss:  0.03195612132549286
Valid Loss:  0.03112632781267166
Epoch:  57  	Training Loss: 0.02895510196685791
Test Loss:  0.031896866858005524
Valid Loss:  0.031064951792359352
Epoch:  58  	Training Loss: 0.02891269326210022
Test Loss:  0.031837861984968185
Valid Loss:  0.031003836542367935
Epoch:  59  	Training Loss: 0.028870481997728348
Test Loss:  0.031779125332832336
Valid Loss:  0.030943000689148903
Epoch:  60  	Training Loss: 0.028828473761677742
Test Loss:  0.03172064572572708
Valid Loss:  0.03088243305683136
Epoch:  61  	Training Loss: 0.028786659240722656
Test Loss:  0.03166243061423302
Valid Loss:  0.030822133645415306
Epoch:  62  	Training Loss: 0.028745047748088837
Test Loss:  0.03160469979047775
Valid Loss:  0.030762335285544395
Epoch:  63  	Training Loss: 0.028703823685646057
Test Loss:  0.031547240912914276
Valid Loss:  0.03070281445980072
Epoch:  64  	Training Loss: 0.028662797063589096
Test Loss:  0.031490035355091095
Valid Loss:  0.030643559992313385
Epoch:  65  	Training Loss: 0.028621966019272804
Test Loss:  0.03143308684229851
Valid Loss:  0.03058457560837269
Epoch:  66  	Training Loss: 0.02858133241534233
Test Loss:  0.03137638792395592
Valid Loss:  0.030525850132107735
Epoch:  67  	Training Loss: 0.02854088880121708
Test Loss:  0.03131994605064392
Valid Loss:  0.030467398464679718
Epoch:  68  	Training Loss: 0.028500646352767944
Test Loss:  0.03126376122236252
Valid Loss:  0.030409201979637146
Epoch:  69  	Training Loss: 0.028460588306188583
Test Loss:  0.03120782971382141
Valid Loss:  0.030351271852850914
Epoch:  70  	Training Loss: 0.02842072769999504
Test Loss:  0.031152136623859406
Valid Loss:  0.030293596908450127
Epoch:  71  	Training Loss: 0.028381045907735825
Test Loss:  0.031096700578927994
Valid Loss:  0.03023618459701538
Epoch:  72  	Training Loss: 0.028341565281152725
Test Loss:  0.03104155696928501
 15%|█▍        | 73/500 [00:53<06:04,  1.17it/s] 15%|█▌        | 75/500 [00:54<04:22,  1.62it/s] 15%|█▌        | 77/500 [00:54<03:11,  2.21it/s] 16%|█▌        | 79/500 [00:54<02:21,  2.98it/s] 16%|█▌        | 81/500 [01:00<08:13,  1.18s/it] 17%|█▋        | 83/500 [01:00<05:52,  1.18it/s] 17%|█▋        | 85/500 [01:00<04:13,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:04,  2.23it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.00it/s] 18%|█▊        | 91/500 [01:07<08:03,  1.18s/it] 19%|█▊        | 93/500 [01:07<05:45,  1.18it/s] 19%|█▉        | 95/500 [01:07<04:08,  1.63it/s] 19%|█▉        | 97/500 [01:07<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.00it/s] 20%|██        | 101/500 [01:14<07:51,  1.18s/it] 21%|██        | 103/500 [01:14<05:36,  1.18it/s] 21%|██        | 105/500 [01:14<04:02,  1.63it/s] 21%|██▏       | 107/500 [01:14<02:56,  2.23it/s] 22%|██▏       | 109/500 [01:14<02:10,  3.00it/s] 22%|██▏       | 111/500 [01:21<07:32,  1.16s/it] 23%|██▎       | 113/500 [01:21<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:21<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:21<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:21<02:07,  2.98it/s] 24%|██▍       | 121/500 [01:27<07:18,  1.16s/it] 25%|██▍       | 123/500 [01:27<05:13,  1.20it/s] 25%|██▌       | 125/500 [01:28<03:46,  1.66it/s] 25%|██▌       | 127/500 [01:28<02:45,  2.26it/s] 26%|██▌       | 129/500 [01:28<02:02,  3.03it/s] 26%|██▌       | 131/500 [01:34<07:14,  1.18s/it] 27%|██▋       | 133/500 [01:34<05:10,  1.18it/s] 27%|██▋       | 135/500 [01:34<03:43,  1.63it/s] 27%|██▋       | 137/500 [01:35<02:42,  2.23it/s] 28%|██▊       | 139/500 [01:35<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:41<06:56,  1.16s/it]Valid Loss:  0.03017907775938511
Epoch:  73  	Training Loss: 0.02830231375992298
Test Loss:  0.030986666679382324
Valid Loss:  0.03012222610414028
Epoch:  74  	Training Loss: 0.02826325036585331
Test Loss:  0.030932020395994186
Valid Loss:  0.0300656296312809
Epoch:  75  	Training Loss: 0.028224371373653412
Test Loss:  0.03087760880589485
Valid Loss:  0.030009279027581215
Epoch:  76  	Training Loss: 0.02818567305803299
Test Loss:  0.030823443084955215
Valid Loss:  0.029953189194202423
Epoch:  77  	Training Loss: 0.02814715914428234
Test Loss:  0.03076951578259468
Valid Loss:  0.02989734709262848
Epoch:  78  	Training Loss: 0.028108827769756317
Test Loss:  0.03071582317352295
Valid Loss:  0.029841741546988487
Epoch:  79  	Training Loss: 0.028070667758584023
Test Loss:  0.030662374570965767
Valid Loss:  0.029786396771669388
Epoch:  80  	Training Loss: 0.02803269401192665
Test Loss:  0.03060915879905224
Valid Loss:  0.02973128855228424
Epoch:  81  	Training Loss: 0.027994899079203606
Test Loss:  0.030556166544556618
Valid Loss:  0.029676420614123344
Epoch:  82  	Training Loss: 0.027957268059253693
Test Loss:  0.03050345927476883
Valid Loss:  0.029621843248605728
Epoch:  83  	Training Loss: 0.027919868007302284
Test Loss:  0.030450981110334396
Valid Loss:  0.029567498713731766
Epoch:  84  	Training Loss: 0.027882633730769157
Test Loss:  0.030398715287446976
Valid Loss:  0.02951338142156601
Epoch:  85  	Training Loss: 0.027845565229654312
Test Loss:  0.030346686020493507
Valid Loss:  0.029459508135914803
Epoch:  86  	Training Loss: 0.027808669954538345
Test Loss:  0.0302948746830225
Valid Loss:  0.0294058658182621
Epoch:  87  	Training Loss: 0.02777194231748581
Test Loss:  0.03024328127503395
Valid Loss:  0.029352443292737007
Epoch:  88  	Training Loss: 0.027735373005270958
Test Loss:  0.03019190952181816
Valid Loss:  0.029299255460500717
Epoch:  89  	Training Loss: 0.027698975056409836
Test Loss:  0.030140753835439682
Valid Loss:  0.029246293008327484
Epoch:  90  	Training Loss: 0.027662737295031548
Test Loss:  0.030089817941188812
Valid Loss:  0.029193565249443054
Epoch:  91  	Training Loss: 0.02762666530907154
Test Loss:  0.0300391037017107
Valid Loss:  0.029141057282686234
Epoch:  92  	Training Loss: 0.027590755373239517
Test Loss:  0.029988747090101242
Valid Loss:  0.02908892184495926
Epoch:  93  	Training Loss: 0.02755512297153473
Test Loss:  0.029938608407974243
Valid Loss:  0.02903701737523079
Epoch:  94  	Training Loss: 0.027519654482603073
Test Loss:  0.02988869696855545
Valid Loss:  0.028985345736145973
Epoch:  95  	Training Loss: 0.027484357357025146
Test Loss:  0.029838990420103073
Valid Loss:  0.028933892026543617
Epoch:  96  	Training Loss: 0.02744920551776886
Test Loss:  0.029789499938488007
Valid Loss:  0.028882654383778572
Epoch:  97  	Training Loss: 0.027414219453930855
Test Loss:  0.029740221798419952
Valid Loss:  0.028831645846366882
Epoch:  98  	Training Loss: 0.027379393577575684
Test Loss:  0.029691150411963463
Valid Loss:  0.028780853375792503
Epoch:  99  	Training Loss: 0.0273447223007679
Test Loss:  0.029642289504408836
Valid Loss:  0.028730280697345734
Epoch:  100  	Training Loss: 0.02731020376086235
Test Loss:  0.02959364838898182
Valid Loss:  0.02867993339896202
Epoch:  101  	Training Loss: 0.027275849133729935
Test Loss:  0.02954520285129547
Valid Loss:  0.028629792854189873
Epoch:  102  	Training Loss: 0.02724163979291916
Test Loss:  0.029497293755412102
Valid Loss:  0.028580207377672195
Epoch:  103  	Training Loss: 0.027207812294363976
Test Loss:  0.029449578374624252
Valid Loss:  0.02853083238005638
Epoch:  104  	Training Loss: 0.027174130082130432
Test Loss:  0.02940208464860916
Valid Loss:  0.028481680899858475
Epoch:  105  	Training Loss: 0.027140609920024872
Test Loss:  0.029354793950915337
Valid Loss:  0.02843273989856243
Epoch:  106  	Training Loss: 0.0271072406321764
Test Loss:  0.02930770441889763
Valid Loss:  0.02838401310145855
Epoch:  107  	Training Loss: 0.027074014768004417
Test Loss:  0.02926081232726574
Valid Loss:  0.02833550237119198
Epoch:  108  	Training Loss: 0.027040943503379822
Test Loss:  0.029214121401309967
Valid Loss:  0.02828717976808548
Epoch:  109  	Training Loss: 0.027008015662431717
Test Loss:  0.02916763350367546
Valid Loss:  0.028239089995622635
Epoch:  110  	Training Loss: 0.02697524055838585
Test Loss:  0.02912135049700737
Valid Loss:  0.028191199526190758
Epoch:  111  	Training Loss: 0.02694261074066162
Test Loss:  0.029075248166918755
Valid Loss:  0.028143510222434998
Epoch:  112  	Training Loss: 0.026910122483968735
Test Loss:  0.029029496014118195
Valid Loss:  0.028096169233322144
Epoch:  113  	Training Loss: 0.026877889409661293
Test Loss:  0.02898392453789711
Valid Loss:  0.028049029409885406
Epoch:  114  	Training Loss: 0.026845796033740044
Test Loss:  0.028938543051481247
Valid Loss:  0.028002077713608742
Epoch:  115  	Training Loss: 0.02681383118033409
Test Loss:  0.028893351554870605
Valid Loss:  0.027955319732427597
Epoch:  116  	Training Loss: 0.026782017201185226
Test Loss:  0.028848350048065186
Valid Loss:  0.027908766642212868
Epoch:  117  	Training Loss: 0.026750335469841957
Test Loss:  0.028803523629903793
Valid Loss:  0.02786239981651306
Epoch:  118  	Training Loss: 0.02671878971159458
Test Loss:  0.028758887201547623
Valid Loss:  0.027816230431199074
Epoch:  119  	Training Loss: 0.0266873799264431
Test Loss:  0.028714440762996674
Valid Loss:  0.027770254760980606
Epoch:  120  	Training Loss: 0.026656102389097214
Test Loss:  0.028670165687799454
Valid Loss:  0.027724461629986763
Epoch:  121  	Training Loss: 0.02662496082484722
Test Loss:  0.028626076877117157
Valid Loss:  0.02767886407673359
Epoch:  122  	Training Loss: 0.026593953371047974
Test Loss:  0.028582267463207245
Valid Loss:  0.027633551508188248
Epoch:  123  	Training Loss: 0.02656315639615059
Test Loss:  0.028538649901747704
Valid Loss:  0.027588441967964172
Epoch:  124  	Training Loss: 0.026532499119639397
Test Loss:  0.02849520742893219
Valid Loss:  0.027543507516384125
Epoch:  125  	Training Loss: 0.0265019703656435
Test Loss:  0.028451943770051003
Valid Loss:  0.0274987630546093
Epoch:  126  	Training Loss: 0.0264715738594532
Test Loss:  0.028408855199813843
Valid Loss:  0.027454210445284843
Epoch:  127  	Training Loss: 0.026441309601068497
Test Loss:  0.028365951031446457
Valid Loss:  0.02740984410047531
Epoch:  128  	Training Loss: 0.02641117200255394
Test Loss:  0.028323233127593994
Valid Loss:  0.027365680783987045
Epoch:  129  	Training Loss: 0.026381174102425575
Test Loss:  0.02828069031238556
Valid Loss:  0.02732168696820736
Epoch:  130  	Training Loss: 0.02635129541158676
Test Loss:  0.028238311409950256
Valid Loss:  0.027277871966362
Epoch:  131  	Training Loss: 0.026321547105908394
Test Loss:  0.028196115046739578
Valid Loss:  0.027234241366386414
Epoch:  132  	Training Loss: 0.026291923597455025
Test Loss:  0.028153935447335243
Valid Loss:  0.027190644294023514
Epoch:  133  	Training Loss: 0.026262307539582253
Test Loss:  0.028111910447478294
Valid Loss:  0.02714720368385315
Epoch:  134  	Training Loss: 0.026232808828353882
Test Loss:  0.028070060536265373
Valid Loss:  0.02710394188761711
Epoch:  135  	Training Loss: 0.02620343118906021
Test Loss:  0.028028367087244987
Valid Loss:  0.027060847729444504
Epoch:  136  	Training Loss: 0.026174170896410942
Test Loss:  0.02798685058951378
Valid Loss:  0.02701793983578682
Epoch:  137  	Training Loss: 0.02614503726363182
Test Loss:  0.027945484966039658
Valid Loss:  0.02697518840432167
Epoch:  138  	Training Loss: 0.026116009801626205
Test Loss:  0.027904294431209564
Valid Loss:  0.026932615786790848
Epoch:  139  	Training Loss: 0.026087108999490738
Test Loss:  0.027863256633281708
Valid Loss:  0.02689020335674286
Epoch:  140  	Training Loss: 0.026058319956064224
Test Loss:  0.027822384610772133
Valid Loss:  0.026847973465919495
Epoch:  141  	Training Loss: 0.02602965384721756
Test Loss:  0.027781667187809944
Valid Loss:  0.026805907487869263
Epoch:  142  	Training Loss: 0.02600109949707985
Test Loss:  0.02774137631058693
Valid Loss:  0.02676427736878395
Epoch:  143  	Training Loss: 0.02597285434603691
Test Loss:  0.027701247483491898
 29%|██▊       | 143/500 [01:41<04:57,  1.20it/s] 29%|██▉       | 145/500 [01:41<03:34,  1.66it/s] 29%|██▉       | 147/500 [01:41<02:35,  2.27it/s] 30%|██▉       | 149/500 [01:41<01:55,  3.04it/s] 30%|███       | 151/500 [01:48<06:43,  1.16s/it] 31%|███       | 153/500 [01:48<04:48,  1.20it/s] 31%|███       | 155/500 [01:48<03:27,  1.66it/s] 31%|███▏      | 157/500 [01:48<02:31,  2.27it/s] 32%|███▏      | 159/500 [01:48<01:51,  3.05it/s] 32%|███▏      | 161/500 [01:54<06:34,  1.16s/it] 33%|███▎      | 163/500 [01:55<04:42,  1.19it/s] 33%|███▎      | 165/500 [01:55<03:22,  1.65it/s] 33%|███▎      | 167/500 [01:55<02:27,  2.26it/s] 34%|███▍      | 169/500 [01:55<01:49,  3.03it/s] 34%|███▍      | 171/500 [02:01<06:25,  1.17s/it] 35%|███▍      | 173/500 [02:01<04:34,  1.19it/s] 35%|███▌      | 175/500 [02:01<03:17,  1.65it/s] 35%|███▌      | 177/500 [02:02<02:23,  2.25it/s] 36%|███▌      | 179/500 [02:02<01:46,  3.02it/s] 36%|███▌      | 181/500 [02:08<06:10,  1.16s/it] 37%|███▋      | 183/500 [02:08<04:24,  1.20it/s] 37%|███▋      | 185/500 [02:08<03:10,  1.66it/s] 37%|███▋      | 187/500 [02:08<02:18,  2.26it/s] 38%|███▊      | 189/500 [02:08<01:42,  3.04it/s] 38%|███▊      | 191/500 [02:15<06:05,  1.18s/it] 39%|███▊      | 193/500 [02:15<04:20,  1.18it/s] 39%|███▉      | 195/500 [02:15<03:07,  1.63it/s] 39%|███▉      | 197/500 [02:15<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:15<01:41,  2.97it/s] 40%|████      | 201/500 [02:22<05:55,  1.19s/it] 41%|████      | 203/500 [02:22<04:13,  1.17it/s] 41%|████      | 205/500 [02:22<03:01,  1.62it/s] 41%|████▏     | 207/500 [02:22<02:12,  2.22it/s] 42%|████▏     | 209/500 [02:22<01:37,  2.98it/s] 42%|████▏     | 211/500 [02:28<05:39,  1.17s/it] 43%|████▎     | 213/500 [02:29<04:01,  1.19it/s]Valid Loss:  0.026722799986600876
Epoch:  144  	Training Loss: 0.02594471164047718
Test Loss:  0.027661263942718506
Valid Loss:  0.026681501418352127
Epoch:  145  	Training Loss: 0.025916688144207
Test Loss:  0.027621444314718246
Valid Loss:  0.026640355587005615
Epoch:  146  	Training Loss: 0.025888776406645775
Test Loss:  0.027581773698329926
Valid Loss:  0.026599373668432236
Epoch:  147  	Training Loss: 0.025860970839858055
Test Loss:  0.027542250230908394
Valid Loss:  0.02655855193734169
Epoch:  148  	Training Loss: 0.02583327889442444
Test Loss:  0.027502883225679398
Valid Loss:  0.026517875492572784
Epoch:  149  	Training Loss: 0.02580568939447403
Test Loss:  0.02746366709470749
Valid Loss:  0.026477381587028503
Epoch:  150  	Training Loss: 0.025778213515877724
Test Loss:  0.027424607425928116
Valid Loss:  0.02643703669309616
Epoch:  151  	Training Loss: 0.025750845670700073
Test Loss:  0.02738569676876068
Valid Loss:  0.02639683708548546
Epoch:  152  	Training Loss: 0.02572358399629593
Test Loss:  0.027346882969141006
Valid Loss:  0.026356752961874008
Epoch:  153  	Training Loss: 0.025696400552988052
Test Loss:  0.027308210730552673
Valid Loss:  0.026316823437809944
Epoch:  154  	Training Loss: 0.025669323280453682
Test Loss:  0.027269698679447174
Valid Loss:  0.02627704292535782
Epoch:  155  	Training Loss: 0.02564235031604767
Test Loss:  0.02723132260143757
Valid Loss:  0.026237420737743378
Epoch:  156  	Training Loss: 0.025615479797124863
Test Loss:  0.0271931029856205
Valid Loss:  0.026197955012321472
Epoch:  157  	Training Loss: 0.02558872103691101
Test Loss:  0.027155030518770218
Valid Loss:  0.02615865133702755
Epoch:  158  	Training Loss: 0.025562066584825516
Test Loss:  0.02711709588766098
Valid Loss:  0.026119492948055267
Epoch:  159  	Training Loss: 0.02553551271557808
Test Loss:  0.02707931026816368
Valid Loss:  0.026080479845404625
Epoch:  160  	Training Loss: 0.02550906129181385
Test Loss:  0.027041669934988022
Valid Loss:  0.02604162134230137
Epoch:  161  	Training Loss: 0.02548271045088768
Test Loss:  0.027004163712263107
Valid Loss:  0.02600291557610035
Epoch:  162  	Training Loss: 0.02545645833015442
Test Loss:  0.026967402547597885
Valid Loss:  0.025964967906475067
Epoch:  163  	Training Loss: 0.02543073706328869
Test Loss:  0.026930782943964005
Valid Loss:  0.025927171111106873
Epoch:  164  	Training Loss: 0.02540510892868042
Test Loss:  0.026894310489296913
Valid Loss:  0.025889528915286064
Epoch:  165  	Training Loss: 0.025379590690135956
Test Loss:  0.02685798518359661
Valid Loss:  0.025852035731077194
Epoch:  166  	Training Loss: 0.02535417675971985
Test Loss:  0.026821793988347054
Valid Loss:  0.025814693421125412
Epoch:  167  	Training Loss: 0.025328852236270905
Test Loss:  0.026785746216773987
Valid Loss:  0.02577749267220497
Epoch:  168  	Training Loss: 0.025303635746240616
Test Loss:  0.02674984559416771
Valid Loss:  0.025740453973412514
Epoch:  169  	Training Loss: 0.025278517976403236
Test Loss:  0.026714082807302475
Valid Loss:  0.0257035493850708
Epoch:  170  	Training Loss: 0.02525349147617817
Test Loss:  0.026678457856178284
Valid Loss:  0.025666797533631325
Epoch:  171  	Training Loss: 0.025228573009371758
Test Loss:  0.026642968878149986
Valid Loss:  0.02563019096851349
Epoch:  172  	Training Loss: 0.025203745812177658
Test Loss:  0.02660716325044632
Valid Loss:  0.02559325098991394
Epoch:  173  	Training Loss: 0.025178691372275352
Test Loss:  0.026571493595838547
Valid Loss:  0.02555645816028118
Epoch:  174  	Training Loss: 0.025153744965791702
Test Loss:  0.026535946875810623
Valid Loss:  0.025519799441099167
Epoch:  175  	Training Loss: 0.025128882378339767
Test Loss:  0.02650054171681404
Valid Loss:  0.025483276695013046
Epoch:  176  	Training Loss: 0.025104111060500145
Test Loss:  0.02646525576710701
Valid Loss:  0.02544689178466797
Epoch:  177  	Training Loss: 0.025079432874917984
Test Loss:  0.026430105790495872
Valid Loss:  0.025410639122128487
Epoch:  178  	Training Loss: 0.025054842233657837
Test Loss:  0.026395078748464584
Valid Loss:  0.025374524295330048
Epoch:  179  	Training Loss: 0.02503034472465515
Test Loss:  0.026360174641013145
Valid Loss:  0.025338541716337204
Epoch:  180  	Training Loss: 0.02500593289732933
Test Loss:  0.02632540464401245
Valid Loss:  0.025302689522504807
Epoch:  181  	Training Loss: 0.024981608614325523
Test Loss:  0.026290755718946457
Valid Loss:  0.025266963988542557
Epoch:  182  	Training Loss: 0.02495737001299858
Test Loss:  0.026256289333105087
Valid Loss:  0.02523142844438553
Epoch:  183  	Training Loss: 0.024933278560638428
Test Loss:  0.02622194215655327
Valid Loss:  0.025196021422743797
Epoch:  184  	Training Loss: 0.02490927465260029
Test Loss:  0.026187729090452194
Valid Loss:  0.02516074851155281
Epoch:  185  	Training Loss: 0.02488536387681961
Test Loss:  0.026153642684221268
Valid Loss:  0.025125615298748016
Epoch:  186  	Training Loss: 0.02486153319478035
Test Loss:  0.02611968107521534
Valid Loss:  0.02509060874581337
Epoch:  187  	Training Loss: 0.0248377937823534
Test Loss:  0.02608584426343441
Valid Loss:  0.02505573257803917
Epoch:  188  	Training Loss: 0.024814143776893616
Test Loss:  0.02605212852358818
Valid Loss:  0.025020994246006012
Epoch:  189  	Training Loss: 0.024790575727820396
Test Loss:  0.026018541306257248
Valid Loss:  0.024986373260617256
Epoch:  190  	Training Loss: 0.02476709708571434
Test Loss:  0.025985080748796463
Valid Loss:  0.024951890110969543
Epoch:  191  	Training Loss: 0.02474370226264
Test Loss:  0.025951730087399483
Valid Loss:  0.02491753175854683
Epoch:  192  	Training Loss: 0.024720387533307076
Test Loss:  0.025918995961546898
Valid Loss:  0.024883810430765152
Epoch:  193  	Training Loss: 0.024697482585906982
Test Loss:  0.025886375457048416
Valid Loss:  0.024850212037563324
Epoch:  194  	Training Loss: 0.024674661457538605
Test Loss:  0.025853879749774933
Valid Loss:  0.02481674589216709
Epoch:  195  	Training Loss: 0.024651920422911644
Test Loss:  0.025821503251791
Valid Loss:  0.02478339895606041
Epoch:  196  	Training Loss: 0.02462926134467125
Test Loss:  0.02578924223780632
Valid Loss:  0.024750180542469025
Epoch:  197  	Training Loss: 0.02460668608546257
Test Loss:  0.02575710229575634
Valid Loss:  0.02471708133816719
Epoch:  198  	Training Loss: 0.02458418905735016
Test Loss:  0.025725074112415314
Valid Loss:  0.024684112519025803
Epoch:  199  	Training Loss: 0.024561775848269463
Test Loss:  0.025693172588944435
Valid Loss:  0.024651266634464264
Epoch:  200  	Training Loss: 0.024539444595575333
Test Loss:  0.02566138468682766
Valid Loss:  0.024618547409772873
Epoch:  201  	Training Loss: 0.02451719343662262
Test Loss:  0.025629710406064987
Valid Loss:  0.02458592876791954
Epoch:  202  	Training Loss: 0.024495018646121025
Test Loss:  0.025597719475626945
Valid Loss:  0.024552999064326286
Epoch:  203  	Training Loss: 0.024472631514072418
Test Loss:  0.02556583285331726
Valid Loss:  0.024520181119441986
Epoch:  204  	Training Loss: 0.02445031702518463
Test Loss:  0.02553405612707138
Valid Loss:  0.02448747679591179
Epoch:  205  	Training Loss: 0.024428080767393112
Test Loss:  0.025502391159534454
Valid Loss:  0.024454884231090546
Epoch:  206  	Training Loss: 0.024405919015407562
Test Loss:  0.02547084167599678
Valid Loss:  0.0244224201887846
Epoch:  207  	Training Loss: 0.02438383176922798
Test Loss:  0.025439396500587463
Valid Loss:  0.02439006045460701
Epoch:  208  	Training Loss: 0.02436182089149952
Test Loss:  0.025408057495951653
Valid Loss:  0.024357818067073822
Epoch:  209  	Training Loss: 0.024339884519577026
Test Loss:  0.025376828387379646
Valid Loss:  0.02432568557560444
Epoch:  210  	Training Loss: 0.024318020790815353
Test Loss:  0.025345705449581146
Valid Loss:  0.024293653666973114
Epoch:  211  	Training Loss: 0.024296225979924202
Test Loss:  0.025314688682556152
Valid Loss:  0.02426176145672798
Epoch:  212  	Training Loss: 0.02427450381219387
Test Loss:  0.02528376877307892
Valid Loss:  0.024229947477579117
Epoch:  213  	Training Loss: 0.024252865463495255
Test Loss:  0.02525296062231064
Valid Loss:  0.0241982564330101
Epoch:  214  	Training Loss: 0.02423129417002201
Test Loss:   43%|████▎     | 215/500 [02:29<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:29<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:29<01:33,  3.01it/s] 44%|████▍     | 221/500 [02:35<05:26,  1.17s/it] 45%|████▍     | 223/500 [02:35<03:52,  1.19it/s] 45%|████▌     | 225/500 [02:36<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:36<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:36<01:30,  3.01it/s] 46%|████▌     | 231/500 [02:42<05:16,  1.18s/it] 47%|████▋     | 233/500 [02:42<03:45,  1.18it/s] 47%|████▋     | 235/500 [02:42<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:43<01:57,  2.23it/s] 48%|████▊     | 239/500 [02:43<01:26,  3.00it/s] 48%|████▊     | 241/500 [02:49<05:03,  1.17s/it] 49%|████▊     | 243/500 [02:49<03:36,  1.19it/s] 49%|████▉     | 245/500 [02:49<02:35,  1.64it/s] 49%|████▉     | 247/500 [02:49<01:52,  2.24it/s] 50%|████▉     | 249/500 [02:49<01:23,  3.01it/s] 50%|█████     | 251/500 [02:56<04:55,  1.19s/it] 51%|█████     | 253/500 [02:56<03:30,  1.17it/s] 51%|█████     | 255/500 [02:56<02:30,  1.62it/s] 51%|█████▏    | 257/500 [02:56<01:49,  2.22it/s] 52%|█████▏    | 259/500 [02:56<01:20,  2.98it/s] 52%|█████▏    | 261/500 [03:03<04:43,  1.19s/it] 53%|█████▎    | 263/500 [03:03<03:21,  1.18it/s] 53%|█████▎    | 265/500 [03:03<02:24,  1.62it/s] 53%|█████▎    | 267/500 [03:03<01:44,  2.22it/s] 54%|█████▍    | 269/500 [03:03<01:17,  2.98it/s] 54%|█████▍    | 271/500 [03:10<04:32,  1.19s/it] 55%|█████▍    | 273/500 [03:10<03:14,  1.17it/s] 55%|█████▌    | 275/500 [03:10<02:19,  1.62it/s] 55%|█████▌    | 277/500 [03:10<01:40,  2.21it/s] 56%|█████▌    | 279/500 [03:10<01:14,  2.97it/s] 56%|█████▌    | 281/500 [03:16<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:16<03:01,  1.19it/s]0.025222256779670715
Valid Loss:  0.02416667900979519
Epoch:  215  	Training Loss: 0.024209797382354736
Test Loss:  0.025191646069288254
Valid Loss:  0.024135194718837738
Epoch:  216  	Training Loss: 0.024188362061977386
Test Loss:  0.025161147117614746
Valid Loss:  0.024103831499814987
Epoch:  217  	Training Loss: 0.024167008697986603
Test Loss:  0.025130748748779297
Valid Loss:  0.02407257817685604
Epoch:  218  	Training Loss: 0.02414572238922119
Test Loss:  0.025100460276007652
Valid Loss:  0.02404142916202545
Epoch:  219  	Training Loss: 0.0241245049983263
Test Loss:  0.025070268660783768
Valid Loss:  0.02401038445532322
Epoch:  220  	Training Loss: 0.024103350937366486
Test Loss:  0.025040175765752792
Valid Loss:  0.023979458957910538
Epoch:  221  	Training Loss: 0.024082273244857788
Test Loss:  0.025010183453559875
Valid Loss:  0.023948628455400467
Epoch:  222  	Training Loss: 0.024061260744929314
Test Loss:  0.024980224668979645
Valid Loss:  0.023917831480503082
Epoch:  223  	Training Loss: 0.024040278047323227
Test Loss:  0.02495037019252777
Valid Loss:  0.023887138813734055
Epoch:  224  	Training Loss: 0.02401936799287796
Test Loss:  0.02492060884833336
Valid Loss:  0.023856554180383682
Epoch:  225  	Training Loss: 0.02399851754307747
Test Loss:  0.024890946224331856
Valid Loss:  0.02382606640458107
Epoch:  226  	Training Loss: 0.02397773414850235
Test Loss:  0.024861380457878113
Valid Loss:  0.02379569038748741
Epoch:  227  	Training Loss: 0.023957017809152603
Test Loss:  0.024831920862197876
Valid Loss:  0.023765407502651215
Epoch:  228  	Training Loss: 0.023936370387673378
Test Loss:  0.02480255253612995
Valid Loss:  0.02373523823916912
Epoch:  229  	Training Loss: 0.023915790021419525
Test Loss:  0.024773284792900085
Valid Loss:  0.023705167695879936
Epoch:  230  	Training Loss: 0.023895271122455597
Test Loss:  0.024744106456637383
Valid Loss:  0.02367520146071911
Epoch:  231  	Training Loss: 0.023874817416071892
Test Loss:  0.024715032428503036
Valid Loss:  0.023645326495170593
Epoch:  232  	Training Loss: 0.02385443076491356
Test Loss:  0.024686478078365326
Valid Loss:  0.023616015911102295
Epoch:  233  	Training Loss: 0.02383437752723694
Test Loss:  0.024658024311065674
Valid Loss:  0.02358679473400116
Epoch:  234  	Training Loss: 0.02381439507007599
Test Loss:  0.024629659950733185
Valid Loss:  0.023557676002383232
Epoch:  235  	Training Loss: 0.023794470354914665
Test Loss:  0.024601392447948456
Valid Loss:  0.023528654128313065
Epoch:  236  	Training Loss: 0.023774610832333565
Test Loss:  0.024573208764195442
Valid Loss:  0.02349971979856491
Epoch:  237  	Training Loss: 0.02375480905175209
Test Loss:  0.02454511448740959
Valid Loss:  0.023470893502235413
Epoch:  238  	Training Loss: 0.02373506873846054
Test Loss:  0.02451712265610695
Valid Loss:  0.023442164063453674
Epoch:  239  	Training Loss: 0.023715389892458916
Test Loss:  0.024489210918545723
Valid Loss:  0.0234135240316391
Epoch:  240  	Training Loss: 0.023695770651102066
Test Loss:  0.02446139231324196
Valid Loss:  0.023384977132081985
Epoch:  241  	Training Loss: 0.02367621473968029
Test Loss:  0.024433664977550507
Valid Loss:  0.02335653081536293
Epoch:  242  	Training Loss: 0.023656710982322693
Test Loss:  0.024405762553215027
Valid Loss:  0.0233279038220644
Epoch:  243  	Training Loss: 0.023637108504772186
Test Loss:  0.02437794953584671
Valid Loss:  0.02329936996102333
Epoch:  244  	Training Loss: 0.023617565631866455
Test Loss:  0.024350233376026154
Valid Loss:  0.02327093668282032
Epoch:  245  	Training Loss: 0.0235980823636055
Test Loss:  0.024322599172592163
Valid Loss:  0.023242590948939323
Epoch:  246  	Training Loss: 0.02357865683734417
Test Loss:  0.024295056238770485
Valid Loss:  0.02321433648467064
Epoch:  247  	Training Loss: 0.023559287190437317
Test Loss:  0.02426759898662567
Valid Loss:  0.023186182603240013
Epoch:  248  	Training Loss: 0.02353997901082039
Test Loss:  0.024240240454673767
Valid Loss:  0.02315811812877655
Epoch:  249  	Training Loss: 0.023520730435848236
Test Loss:  0.024212954565882683
Valid Loss:  0.023130137473344803
Epoch:  250  	Training Loss: 0.02350153774023056
Test Loss:  0.024185756221413612
Valid Loss:  0.023102253675460815
Epoch:  251  	Training Loss: 0.02348240092396736
Test Loss:  0.024158643558621407
Valid Loss:  0.02307445928454399
Epoch:  252  	Training Loss: 0.02346331626176834
Test Loss:  0.024131765589118004
Valid Loss:  0.023046905174851418
Epoch:  253  	Training Loss: 0.023444386199116707
Test Loss:  0.02410496398806572
Valid Loss:  0.023019438609480858
Epoch:  254  	Training Loss: 0.02342550829052925
Test Loss:  0.02407824620604515
Valid Loss:  0.022992057725787163
Epoch:  255  	Training Loss: 0.02340669371187687
Test Loss:  0.024051614105701447
Valid Loss:  0.02296477183699608
Epoch:  256  	Training Loss: 0.023387925699353218
Test Loss:  0.024025075137615204
Valid Loss:  0.022937573492527008
Epoch:  257  	Training Loss: 0.02336921915411949
Test Loss:  0.02399861067533493
Valid Loss:  0.02291046269237995
Epoch:  258  	Training Loss: 0.023350566625595093
Test Loss:  0.023972226306796074
Valid Loss:  0.02288343757390976
Epoch:  259  	Training Loss: 0.023331966251134872
Test Loss:  0.02394593507051468
Valid Loss:  0.02285649999976158
Epoch:  260  	Training Loss: 0.02331342175602913
Test Loss:  0.023919716477394104
Valid Loss:  0.022829653695225716
Epoch:  261  	Training Loss: 0.023294931277632713
Test Loss:  0.02389359474182129
Valid Loss:  0.022802893072366714
Epoch:  262  	Training Loss: 0.023276496678590775
Test Loss:  0.023867424577474594
Valid Loss:  0.022776100784540176
Epoch:  263  	Training Loss: 0.023258045315742493
Test Loss:  0.023841343820095062
Valid Loss:  0.022749390453100204
Epoch:  264  	Training Loss: 0.02323964796960354
Test Loss:  0.0238153338432312
Valid Loss:  0.0227227583527565
Epoch:  265  	Training Loss: 0.023221299052238464
Test Loss:  0.023789413273334503
Valid Loss:  0.02269621565937996
Epoch:  266  	Training Loss: 0.023203004151582718
Test Loss:  0.023763570934534073
Valid Loss:  0.022669754922389984
Epoch:  267  	Training Loss: 0.0231847632676363
Test Loss:  0.023737795650959015
Valid Loss:  0.022643376141786575
Epoch:  268  	Training Loss: 0.02316657081246376
Test Loss:  0.023712104186415672
Valid Loss:  0.022617075592279434
Epoch:  269  	Training Loss: 0.02314842864871025
Test Loss:  0.023686490952968597
Valid Loss:  0.022590860724449158
Epoch:  270  	Training Loss: 0.02313033863902092
Test Loss:  0.02366095408797264
Valid Loss:  0.022564727813005447
Epoch:  271  	Training Loss: 0.02311229333281517
Test Loss:  0.023635495454072952
Valid Loss:  0.0225386843085289
Epoch:  272  	Training Loss: 0.0230943001806736
Test Loss:  0.023610157892107964
Valid Loss:  0.022512754425406456
Epoch:  273  	Training Loss: 0.023076405748724937
Test Loss:  0.02358490228652954
Valid Loss:  0.022486906498670578
Epoch:  274  	Training Loss: 0.02305854670703411
Test Loss:  0.02355971746146679
Valid Loss:  0.022461149841547012
Epoch:  275  	Training Loss: 0.023040741682052612
Test Loss:  0.023534609004855156
Valid Loss:  0.022435471415519714
Epoch:  276  	Training Loss: 0.023022986948490143
Test Loss:  0.023509573191404343
Valid Loss:  0.02240985631942749
Epoch:  277  	Training Loss: 0.023005280643701553
Test Loss:  0.023484613746404648
Valid Loss:  0.022384334355592728
Epoch:  278  	Training Loss: 0.022987622767686844
Test Loss:  0.023459721356630325
Valid Loss:  0.022358888760209084
Epoch:  279  	Training Loss: 0.022970005869865417
Test Loss:  0.023434916511178017
Valid Loss:  0.02233351580798626
Epoch:  280  	Training Loss: 0.022952444851398468
Test Loss:  0.023410174995660782
Valid Loss:  0.022308215498924255
Epoch:  281  	Training Loss: 0.0229349248111248
Test Loss:  0.023385506123304367
Valid Loss:  0.022282999008893967
Epoch:  282  	Training Loss: 0.022917453199625015
Test Loss:  0.023361019790172577
Valid Loss:  0.022257976233959198
Epoch:  283  	Training Loss: 0.02290009707212448
Test Loss:  0.023336604237556458
Valid Loss:  0.022233035415410995
Epoch:  284  	Training Loss: 0.02288278564810753
Test Loss:  0.023312263190746307
Valid Loss:  0.02220815420150757
 57%|█████▋    | 285/500 [03:17<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:17<01:34,  2.24it/s] 58%|█████▊    | 289/500 [03:17<01:10,  3.01it/s] 58%|█████▊    | 291/500 [03:23<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:23<02:53,  1.19it/s] 59%|█████▉    | 295/500 [03:23<02:04,  1.64it/s] 59%|█████▉    | 297/500 [03:24<01:30,  2.23it/s] 60%|█████▉    | 299/500 [03:24<01:06,  3.00it/s] 60%|██████    | 301/500 [03:30<03:51,  1.16s/it] 61%|██████    | 303/500 [03:30<02:44,  1.20it/s] 61%|██████    | 305/500 [03:30<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:30<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:30<01:03,  3.03it/s] 62%|██████▏   | 311/500 [03:37<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:37<02:37,  1.18it/s] 63%|██████▎   | 315/500 [03:37<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:37<01:22,  2.23it/s] 64%|██████▍   | 319/500 [03:37<01:00,  2.98it/s] 64%|██████▍   | 321/500 [03:44<03:33,  1.19s/it] 65%|██████▍   | 323/500 [03:44<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:44<01:48,  1.62it/s] 65%|██████▌   | 327/500 [03:44<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:44<00:57,  2.98it/s] 66%|██████▌   | 331/500 [03:51<03:20,  1.19s/it] 67%|██████▋   | 333/500 [03:51<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:51<01:41,  1.63it/s] 67%|██████▋   | 337/500 [03:51<01:13,  2.22it/s] 68%|██████▊   | 339/500 [03:51<00:53,  2.99it/s] 68%|██████▊   | 341/500 [03:58<03:12,  1.21s/it] 69%|██████▊   | 343/500 [03:58<02:16,  1.15it/s] 69%|██████▉   | 345/500 [03:58<01:37,  1.59it/s] 69%|██████▉   | 347/500 [03:58<01:10,  2.18it/s] 70%|██████▉   | 349/500 [03:58<00:51,  2.93it/s] 70%|███████   | 351/500 [04:04<02:55,  1.18s/it] 71%|███████   | 353/500 [04:05<02:04,  1.18it/s]Epoch:  285  	Training Loss: 0.022865522652864456
Test Loss:  0.023287992924451828
Valid Loss:  0.022183353081345558
Epoch:  286  	Training Loss: 0.022848300635814667
Test Loss:  0.023263785988092422
Valid Loss:  0.022158633917570114
Epoch:  287  	Training Loss: 0.02283112332224846
Test Loss:  0.023239649832248688
Valid Loss:  0.02213399112224579
Epoch:  288  	Training Loss: 0.022813992574810982
Test Loss:  0.02321559190750122
Valid Loss:  0.022109419107437134
Epoch:  289  	Training Loss: 0.022796910256147385
Test Loss:  0.02319161407649517
Valid Loss:  0.02208491787314415
Epoch:  290  	Training Loss: 0.02277986705303192
Test Loss:  0.023167684674263
Valid Loss:  0.022060485556721687
Epoch:  291  	Training Loss: 0.022762876003980637
Test Loss:  0.0231438297778368
Valid Loss:  0.022036144509911537
Epoch:  292  	Training Loss: 0.022745925933122635
Test Loss:  0.023120097815990448
Valid Loss:  0.022011907771229744
Epoch:  293  	Training Loss: 0.0227290540933609
Test Loss:  0.023096423596143723
Valid Loss:  0.02198774367570877
Epoch:  294  	Training Loss: 0.0227122213691473
Test Loss:  0.023072823882102966
Valid Loss:  0.021963652223348618
Epoch:  295  	Training Loss: 0.022695433348417282
Test Loss:  0.023049291223287582
Valid Loss:  0.021939631551504135
Epoch:  296  	Training Loss: 0.022678684443235397
Test Loss:  0.023025820031762123
Valid Loss:  0.02191568911075592
Epoch:  297  	Training Loss: 0.022661985829472542
Test Loss:  0.023002417758107185
Valid Loss:  0.021891813725233078
Epoch:  298  	Training Loss: 0.02264532819390297
Test Loss:  0.022979091852903366
Valid Loss:  0.021868009120225906
Epoch:  299  	Training Loss: 0.02262871153652668
Test Loss:  0.022955825552344322
Valid Loss:  0.021844271570444107
Epoch:  300  	Training Loss: 0.022612132132053375
Test Loss:  0.022932622581720352
Valid Loss:  0.021820608526468277
Epoch:  301  	Training Loss: 0.0225956030189991
Test Loss:  0.022909488528966904
Valid Loss:  0.02179701253771782
Epoch:  302  	Training Loss: 0.022579114884138107
Test Loss:  0.022886399179697037
Valid Loss:  0.02177347242832184
Epoch:  303  	Training Loss: 0.022562656551599503
Test Loss:  0.02286337874829769
Valid Loss:  0.02174999564886093
Epoch:  304  	Training Loss: 0.02254623919725418
Test Loss:  0.022840427234768867
Valid Loss:  0.021726597100496292
Epoch:  305  	Training Loss: 0.02252986468374729
Test Loss:  0.02281753532588482
Valid Loss:  0.021703245118260384
Epoch:  306  	Training Loss: 0.022513527423143387
Test Loss:  0.022794703021645546
Valid Loss:  0.02167997509241104
Epoch:  307  	Training Loss: 0.022497236728668213
Test Loss:  0.022771945223212242
Valid Loss:  0.021656770259141922
Epoch:  308  	Training Loss: 0.022480979561805725
Test Loss:  0.022749245166778564
Valid Loss:  0.021633634343743324
Epoch:  309  	Training Loss: 0.02246476151049137
Test Loss:  0.022726599127054214
Valid Loss:  0.0216105654835701
Epoch:  310  	Training Loss: 0.0224485881626606
Test Loss:  0.022704023867845535
Valid Loss:  0.021587565541267395
Epoch:  311  	Training Loss: 0.02243245393037796
Test Loss:  0.02268151566386223
Valid Loss:  0.021564623340964317
Epoch:  312  	Training Loss: 0.022416356950998306
Test Loss:  0.022659219801425934
Valid Loss:  0.021541917696595192
Epoch:  313  	Training Loss: 0.022400401532649994
Test Loss:  0.02263697236776352
Valid Loss:  0.021519266068935394
Epoch:  314  	Training Loss: 0.022384483367204666
Test Loss:  0.022614795714616776
Valid Loss:  0.021496690809726715
Epoch:  315  	Training Loss: 0.02236860617995262
Test Loss:  0.022592689841985703
Valid Loss:  0.02147417515516281
Epoch:  316  	Training Loss: 0.02235276624560356
Test Loss:  0.022570636123418808
Valid Loss:  0.021451715379953384
Epoch:  317  	Training Loss: 0.022336965426802635
Test Loss:  0.022548653185367584
Valid Loss:  0.021429330110549927
Epoch:  318  	Training Loss: 0.022321201860904694
Test Loss:  0.022526714950799942
Valid Loss:  0.021407004445791245
Epoch:  319  	Training Loss: 0.022305481135845184
Test Loss:  0.022504843771457672
Valid Loss:  0.02138475328683853
Epoch:  320  	Training Loss: 0.02228979393839836
Test Loss:  0.022483032196760178
Valid Loss:  0.021362558007240295
Epoch:  321  	Training Loss: 0.022274145856499672
Test Loss:  0.02246128022670746
Valid Loss:  0.021340426057577133
Epoch:  322  	Training Loss: 0.02225853130221367
Test Loss:  0.022439446300268173
Valid Loss:  0.021318210288882256
Epoch:  323  	Training Loss: 0.022242870181798935
Test Loss:  0.022417675703763962
Valid Loss:  0.021296050399541855
Epoch:  324  	Training Loss: 0.022227250039577484
Test Loss:  0.022395962849259377
Valid Loss:  0.021273961290717125
Epoch:  325  	Training Loss: 0.02221166156232357
Test Loss:  0.022374305874109268
Valid Loss:  0.021251937374472618
Epoch:  326  	Training Loss: 0.02219611220061779
Test Loss:  0.022352710366249084
Valid Loss:  0.02122996188700199
Epoch:  327  	Training Loss: 0.022180596366524696
Test Loss:  0.02233116887509823
Valid Loss:  0.02120806649327278
Epoch:  328  	Training Loss: 0.022165119647979736
Test Loss:  0.022309688851237297
Valid Loss:  0.021186212077736855
Epoch:  329  	Training Loss: 0.02214968018233776
Test Loss:  0.022288266569375992
Valid Loss:  0.021164434030652046
Epoch:  330  	Training Loss: 0.02213427424430847
Test Loss:  0.022266894578933716
Valid Loss:  0.021142710000276566
Epoch:  331  	Training Loss: 0.02211890183389187
Test Loss:  0.022245582193136215
Valid Loss:  0.02112104743719101
Epoch:  332  	Training Loss: 0.02210356295108795
Test Loss:  0.022224172949790955
Valid Loss:  0.021099280565977097
Epoch:  333  	Training Loss: 0.02208816632628441
Test Loss:  0.022202827036380768
Valid Loss:  0.02107757143676281
Epoch:  334  	Training Loss: 0.02207280322909355
Test Loss:  0.02218152955174446
Valid Loss:  0.021055929362773895
Epoch:  335  	Training Loss: 0.02205747365951538
Test Loss:  0.022160284221172333
Valid Loss:  0.021034350618720055
Epoch:  336  	Training Loss: 0.022042179480195045
Test Loss:  0.02213909476995468
Valid Loss:  0.02101282775402069
Epoch:  337  	Training Loss: 0.022026918828487396
Test Loss:  0.022117964923381805
Valid Loss:  0.020991355180740356
Epoch:  338  	Training Loss: 0.022011687979102135
Test Loss:  0.022096898406744003
Valid Loss:  0.020969949662685394
Epoch:  339  	Training Loss: 0.021996498107910156
Test Loss:  0.022075876593589783
Valid Loss:  0.02094860002398491
Epoch:  340  	Training Loss: 0.021981336176395416
Test Loss:  0.02205490693449974
Valid Loss:  0.020927302539348602
Epoch:  341  	Training Loss: 0.02196621522307396
Test Loss:  0.02203400433063507
Valid Loss:  0.020906079560518265
Epoch:  342  	Training Loss: 0.02195112407207489
Test Loss:  0.022013220936059952
Valid Loss:  0.020884983241558075
Epoch:  343  	Training Loss: 0.02193611115217209
Test Loss:  0.021992502734065056
Valid Loss:  0.020863942801952362
Epoch:  344  	Training Loss: 0.02192113548517227
Test Loss:  0.021971823647618294
Valid Loss:  0.020842954516410828
Epoch:  345  	Training Loss: 0.021906185895204544
Test Loss:  0.021951204165816307
Valid Loss:  0.020822033286094666
Epoch:  346  	Training Loss: 0.0218912772834301
Test Loss:  0.02193063497543335
Valid Loss:  0.020801151171326637
Epoch:  347  	Training Loss: 0.021876394748687744
Test Loss:  0.02191011607646942
Valid Loss:  0.020780343562364578
Epoch:  348  	Training Loss: 0.021861545741558075
Test Loss:  0.02188965119421482
Valid Loss:  0.02075957879424095
Epoch:  349  	Training Loss: 0.021846724674105644
Test Loss:  0.0218692384660244
Valid Loss:  0.020738869905471802
Epoch:  350  	Training Loss: 0.021831940859556198
Test Loss:  0.021848879754543304
Valid Loss:  0.020718220621347427
Epoch:  351  	Training Loss: 0.02181718870997429
Test Loss:  0.02182857319712639
Valid Loss:  0.02069762349128723
Epoch:  352  	Training Loss: 0.02180246077477932
Test Loss:  0.021807894110679626
Valid Loss:  0.020676638931035995
Epoch:  353  	Training Loss: 0.02178751677274704
Test Loss:  0.02178727090358734
Valid Loss:  0.020655717700719833
Epoch:  354  	Training Loss: 0.021772604435682297
Test Loss:  0.021766692399978638
Valid Loss:  0.020634841173887253
Epoch:  355  	Training Loss: 0.02175772376358509
Test Loss:  0.02174616977572441
 71%|███████   | 355/500 [04:05<01:29,  1.63it/s] 71%|███████▏  | 357/500 [04:05<01:04,  2.22it/s] 72%|███████▏  | 359/500 [04:05<00:47,  2.99it/s] 72%|███████▏  | 361/500 [04:11<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:11<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:12<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:12<00:59,  2.23it/s] 74%|███████▍  | 369/500 [04:12<00:43,  2.99it/s] 74%|███████▍  | 371/500 [04:18<02:31,  1.17s/it] 75%|███████▍  | 373/500 [04:18<01:47,  1.19it/s] 75%|███████▌  | 375/500 [04:18<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:18<00:54,  2.24it/s] 76%|███████▌  | 379/500 [04:19<00:40,  3.01it/s] 76%|███████▌  | 381/500 [04:25<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:25<01:38,  1.18it/s] 77%|███████▋  | 385/500 [04:25<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:25<00:50,  2.24it/s] 78%|███████▊  | 389/500 [04:25<00:36,  3.00it/s] 78%|███████▊  | 391/500 [04:32<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:32<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:32<01:03,  1.64it/s] 79%|███████▉  | 397/500 [04:32<00:45,  2.24it/s] 80%|███████▉  | 399/500 [04:32<00:33,  3.01it/s] 80%|████████  | 401/500 [04:38<01:56,  1.17s/it] 81%|████████  | 403/500 [04:39<01:21,  1.18it/s] 81%|████████  | 405/500 [04:39<00:58,  1.64it/s] 81%|████████▏ | 407/500 [04:39<00:41,  2.23it/s] 82%|████████▏ | 409/500 [04:39<00:30,  3.00it/s] 82%|████████▏ | 411/500 [04:45<01:45,  1.18s/it] 83%|████████▎ | 413/500 [04:46<01:14,  1.18it/s] 83%|████████▎ | 415/500 [04:46<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:46<00:37,  2.22it/s] 84%|████████▍ | 419/500 [04:46<00:27,  2.99it/s] 84%|████████▍ | 421/500 [04:52<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:52<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:52<00:45,  1.64it/s]Valid Loss:  0.02061401680111885
Epoch:  356  	Training Loss: 0.021742869168519974
Test Loss:  0.021725688129663467
Valid Loss:  0.02059325762093067
Epoch:  357  	Training Loss: 0.021728046238422394
Test Loss:  0.021705269813537598
Valid Loss:  0.020572545006871223
Epoch:  358  	Training Loss: 0.0217132568359375
Test Loss:  0.021684888750314713
Valid Loss:  0.020551878958940506
Epoch:  359  	Training Loss: 0.021698495373129845
Test Loss:  0.0216645710170269
Valid Loss:  0.020531274378299713
Epoch:  360  	Training Loss: 0.02168375998735428
Test Loss:  0.021644290536642075
Valid Loss:  0.0205107182264328
Epoch:  361  	Training Loss: 0.0216690581291914
Test Loss:  0.021624058485031128
Valid Loss:  0.02049020677804947
Epoch:  362  	Training Loss: 0.021654382348060608
Test Loss:  0.021604429930448532
Valid Loss:  0.020470332354307175
Epoch:  363  	Training Loss: 0.021640077233314514
Test Loss:  0.02158483862876892
Valid Loss:  0.020450502634048462
Epoch:  364  	Training Loss: 0.02162579819560051
Test Loss:  0.021565305069088936
Valid Loss:  0.020430726930499077
Epoch:  365  	Training Loss: 0.02161155641078949
Test Loss:  0.021545816212892532
Valid Loss:  0.020410997793078423
Epoch:  366  	Training Loss: 0.02159733511507511
Test Loss:  0.02152637019753456
Valid Loss:  0.020391320809721947
Epoch:  367  	Training Loss: 0.02158314548432827
Test Loss:  0.021506981924176216
Valid Loss:  0.0203716941177845
Epoch:  368  	Training Loss: 0.021568981930613518
Test Loss:  0.021487634629011154
Valid Loss:  0.020352128893136978
Epoch:  369  	Training Loss: 0.021554848179221153
Test Loss:  0.021468333899974823
Valid Loss:  0.02033259905874729
Epoch:  370  	Training Loss: 0.021540746092796326
Test Loss:  0.021449077874422073
Valid Loss:  0.020313119515776634
Epoch:  371  	Training Loss: 0.02152666449546814
Test Loss:  0.021429874002933502
Valid Loss:  0.020293690264225006
Epoch:  372  	Training Loss: 0.02151261642575264
Test Loss:  0.021410644054412842
Valid Loss:  0.02027423307299614
Epoch:  373  	Training Loss: 0.021498557180166245
Test Loss:  0.021391447633504868
Valid Loss:  0.020254839211702347
Epoch:  374  	Training Loss: 0.02148452401161194
Test Loss:  0.021372314542531967
Valid Loss:  0.020235471427440643
Epoch:  375  	Training Loss: 0.02147051878273487
Test Loss:  0.021353216841816902
Valid Loss:  0.020216159522533417
Epoch:  376  	Training Loss: 0.021456537768244743
Test Loss:  0.021334165707230568
Valid Loss:  0.020196903496980667
Epoch:  377  	Training Loss: 0.021442588418722153
Test Loss:  0.021315163001418114
Valid Loss:  0.02017769031226635
Epoch:  378  	Training Loss: 0.021428663283586502
Test Loss:  0.021296195685863495
Valid Loss:  0.02015853300690651
Epoch:  379  	Training Loss: 0.02141476795077324
Test Loss:  0.021277286112308502
Valid Loss:  0.020139407366514206
Epoch:  380  	Training Loss: 0.021400898694992065
Test Loss:  0.021258411929011345
Valid Loss:  0.020120341330766678
Epoch:  381  	Training Loss: 0.021387051790952682
Test Loss:  0.021239589899778366
Valid Loss:  0.020101333037018776
Epoch:  382  	Training Loss: 0.021373238414525986
Test Loss:  0.021220864728093147
Valid Loss:  0.020082421600818634
Epoch:  383  	Training Loss: 0.021359477192163467
Test Loss:  0.021202191710472107
Valid Loss:  0.020063558593392372
Epoch:  384  	Training Loss: 0.021345745772123337
Test Loss:  0.021183565258979797
Valid Loss:  0.02004474587738514
Epoch:  385  	Training Loss: 0.021332040429115295
Test Loss:  0.02116497978568077
Valid Loss:  0.02002597786486149
Epoch:  386  	Training Loss: 0.021318363025784492
Test Loss:  0.02114642783999443
Valid Loss:  0.020007256418466568
Epoch:  387  	Training Loss: 0.02130470983684063
Test Loss:  0.02112792432308197
Valid Loss:  0.019988583400845528
Epoch:  388  	Training Loss: 0.021291077136993408
Test Loss:  0.02110947109758854
Valid Loss:  0.01996995508670807
Epoch:  389  	Training Loss: 0.021277476102113724
Test Loss:  0.02109105885028839
Valid Loss:  0.019951367750763893
Epoch:  390  	Training Loss: 0.02126389741897583
Test Loss:  0.02107267454266548
Valid Loss:  0.019932830706238747
Epoch:  391  	Training Loss: 0.021250344812870026
Test Loss:  0.021054347977042198
Valid Loss:  0.019914336502552032
Epoch:  392  	Training Loss: 0.021236814558506012
Test Loss:  0.021035920828580856
Valid Loss:  0.01989574171602726
Epoch:  393  	Training Loss: 0.021223237738013268
Test Loss:  0.02101752907037735
Valid Loss:  0.019877184182405472
Epoch:  394  	Training Loss: 0.021209681406617165
Test Loss:  0.020999189466238022
Valid Loss:  0.01985868439078331
Epoch:  395  	Training Loss: 0.0211961530148983
Test Loss:  0.02098088525235653
Valid Loss:  0.019840219989418983
Epoch:  396  	Training Loss: 0.021182652562856674
Test Loss:  0.020962627604603767
Valid Loss:  0.019821802154183388
Epoch:  397  	Training Loss: 0.02116917073726654
Test Loss:  0.020944412797689438
Valid Loss:  0.01980343461036682
Epoch:  398  	Training Loss: 0.021155718713998795
Test Loss:  0.020926235243678093
Valid Loss:  0.01978510618209839
Epoch:  399  	Training Loss: 0.02114228904247284
Test Loss:  0.02090809866786003
Valid Loss:  0.019766828045248985
Epoch:  400  	Training Loss: 0.021128883585333824
Test Loss:  0.0208900086581707
Valid Loss:  0.019748594611883163
Epoch:  401  	Training Loss: 0.0211155004799366
Test Loss:  0.020871957764029503
Valid Loss:  0.019730394706130028
Epoch:  402  	Training Loss: 0.021102147176861763
Test Loss:  0.020854152739048004
Valid Loss:  0.019712457433342934
Epoch:  403  	Training Loss: 0.021088946610689163
Test Loss:  0.02083638682961464
Valid Loss:  0.01969456858932972
Epoch:  404  	Training Loss: 0.021075766533613205
Test Loss:  0.020818665623664856
Valid Loss:  0.01967671513557434
Epoch:  405  	Training Loss: 0.021062614396214485
Test Loss:  0.020800985395908356
Valid Loss:  0.01965891197323799
Epoch:  406  	Training Loss: 0.021049484610557556
Test Loss:  0.02078334614634514
Valid Loss:  0.019641157239675522
Epoch:  407  	Training Loss: 0.021036384627223015
Test Loss:  0.020765751600265503
Valid Loss:  0.019623439759016037
Epoch:  408  	Training Loss: 0.021023299545049667
Test Loss:  0.020748190581798553
Valid Loss:  0.01960575580596924
Epoch:  409  	Training Loss: 0.021010246127843857
Test Loss:  0.020730668678879738
Valid Loss:  0.019588124006986618
Epoch:  410  	Training Loss: 0.02099720761179924
Test Loss:  0.020713187754154205
Valid Loss:  0.019570529460906982
Epoch:  411  	Training Loss: 0.02098419889807701
Test Loss:  0.020695745944976807
Valid Loss:  0.01955297589302063
Epoch:  412  	Training Loss: 0.020971208810806274
Test Loss:  0.020678412169218063
Valid Loss:  0.01953553408384323
Epoch:  413  	Training Loss: 0.02095828391611576
Test Loss:  0.02066110447049141
Valid Loss:  0.019518136978149414
Epoch:  414  	Training Loss: 0.02094537951052189
Test Loss:  0.02064383774995804
Valid Loss:  0.019500769674777985
Epoch:  415  	Training Loss: 0.020932499319314957
Test Loss:  0.02062661200761795
Valid Loss:  0.019483443349599838
Epoch:  416  	Training Loss: 0.020919639617204666
Test Loss:  0.020609423518180847
Valid Loss:  0.01946616917848587
Epoch:  417  	Training Loss: 0.020906798541545868
Test Loss:  0.02059226855635643
Valid Loss:  0.01944892108440399
Epoch:  418  	Training Loss: 0.02089398354291916
Test Loss:  0.020575150847434998
Valid Loss:  0.019431717693805695
Epoch:  419  	Training Loss: 0.02088119089603424
Test Loss:  0.020558075979351997
Valid Loss:  0.019414549693465233
Epoch:  420  	Training Loss: 0.020868416875600815
Test Loss:  0.020541034638881683
Valid Loss:  0.019397426396608353
Epoch:  421  	Training Loss: 0.02085566706955433
Test Loss:  0.0205240361392498
Valid Loss:  0.019380345940589905
Epoch:  422  	Training Loss: 0.020842937752604485
Test Loss:  0.02050686813890934
Valid Loss:  0.01936308480799198
Epoch:  423  	Training Loss: 0.02083011157810688
Test Loss:  0.020489737391471863
Valid Loss:  0.019345862790942192
Epoch:  424  	Training Loss: 0.02081730216741562
Test Loss:  0.02047264575958252
Valid Loss:  0.019328689202666283
Epoch:  425  	Training Loss: 0.020804518833756447
Test Loss:  0.02045559138059616
Valid Loss:  0.019311556592583656
Epoch:  426  	Training Loss: 0.020791757851839066
 85%|████████▌ | 427/500 [04:53<00:32,  2.24it/s] 86%|████████▌ | 429/500 [04:53<00:23,  3.01it/s] 86%|████████▌ | 431/500 [04:59<01:20,  1.17s/it] 87%|████████▋ | 433/500 [04:59<00:56,  1.19it/s] 87%|████████▋ | 435/500 [04:59<00:39,  1.64it/s] 87%|████████▋ | 437/500 [04:59<00:28,  2.25it/s] 88%|████████▊ | 439/500 [04:59<00:20,  3.02it/s] 88%|████████▊ | 441/500 [05:06<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:06<00:48,  1.19it/s] 89%|████████▉ | 445/500 [05:06<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:06<00:23,  2.24it/s] 90%|████████▉ | 449/500 [05:06<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:13<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:13<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:13<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:13<00:19,  2.25it/s] 92%|█████████▏| 459/500 [05:13<00:13,  3.02it/s] 92%|█████████▏| 461/500 [05:19<00:45,  1.18s/it] 93%|█████████▎| 463/500 [05:20<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:20<00:21,  1.61it/s] 93%|█████████▎| 467/500 [05:20<00:15,  2.19it/s] 94%|█████████▍| 469/500 [05:20<00:10,  2.94it/s] 94%|█████████▍| 471/500 [05:26<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:26<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:27<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:27<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:27<00:06,  3.01it/s] 96%|█████████▌| 481/500 [05:33<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:33<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:33<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:34<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:34<00:03,  2.99it/s] 98%|█████████▊| 491/500 [05:40<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:40<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:40<00:03,  1.63it/s]Test Loss:  0.02043857052922249
Valid Loss:  0.019294459372758865
Epoch:  427  	Training Loss: 0.020779017359018326
Test Loss:  0.020421583205461502
Valid Loss:  0.01927739940583706
Epoch:  428  	Training Loss: 0.02076629176735878
Test Loss:  0.020404640585184097
Valid Loss:  0.019260376691818237
Epoch:  429  	Training Loss: 0.02075359597802162
Test Loss:  0.020387724041938782
Valid Loss:  0.019243400543928146
Epoch:  430  	Training Loss: 0.020740915089845657
Test Loss:  0.020370859652757645
Valid Loss:  0.019226454198360443
Epoch:  431  	Training Loss: 0.02072826400399208
Test Loss:  0.020354025065898895
Valid Loss:  0.01920955628156662
Epoch:  432  	Training Loss: 0.02071562595665455
Test Loss:  0.02033722959458828
Valid Loss:  0.019192706793546677
Epoch:  433  	Training Loss: 0.020703010261058807
Test Loss:  0.020320482552051544
Valid Loss:  0.01917589083313942
Epoch:  434  	Training Loss: 0.020690415054559708
Test Loss:  0.02030375599861145
Valid Loss:  0.019159112125635147
Epoch:  435  	Training Loss: 0.020677845925092697
Test Loss:  0.02028706669807434
Valid Loss:  0.01914236694574356
Epoch:  436  	Training Loss: 0.02066528983414173
Test Loss:  0.020270423963665962
Valid Loss:  0.019125670194625854
Epoch:  437  	Training Loss: 0.020652757957577705
Test Loss:  0.020253809168934822
Valid Loss:  0.019109006971120834
Epoch:  438  	Training Loss: 0.020640240982174873
Test Loss:  0.02023722417652607
Valid Loss:  0.019092373549938202
Epoch:  439  	Training Loss: 0.020627744495868683
Test Loss:  0.02022067829966545
Valid Loss:  0.019075775519013405
Epoch:  440  	Training Loss: 0.020615268498659134
Test Loss:  0.02020416408777237
Valid Loss:  0.01905922405421734
Epoch:  441  	Training Loss: 0.020602812990546227
Test Loss:  0.020187679678201675
Valid Loss:  0.019042696803808212
Epoch:  442  	Training Loss: 0.02059037610888481
Test Loss:  0.020170768722891808
Valid Loss:  0.019025731831789017
Epoch:  443  	Training Loss: 0.02057766355574131
Test Loss:  0.020153887569904327
Valid Loss:  0.019008804112672806
Epoch:  444  	Training Loss: 0.02056497149169445
Test Loss:  0.02013704553246498
Valid Loss:  0.018991898745298386
Epoch:  445  	Training Loss: 0.020552298054099083
Test Loss:  0.020120229572057724
Valid Loss:  0.018975038081407547
Epoch:  446  	Training Loss: 0.02053963951766491
Test Loss:  0.02010345086455345
Valid Loss:  0.018958210945129395
Epoch:  447  	Training Loss: 0.020527003332972527
Test Loss:  0.020086705684661865
Valid Loss:  0.018941421061754227
Epoch:  448  	Training Loss: 0.020514385774731636
Test Loss:  0.020069994032382965
Valid Loss:  0.018924668431282043
Epoch:  449  	Training Loss: 0.02050178498029709
Test Loss:  0.02005331963300705
Valid Loss:  0.018907949328422546
Epoch:  450  	Training Loss: 0.020489200949668884
Test Loss:  0.020036663860082626
Valid Loss:  0.018891263753175735
Epoch:  451  	Training Loss: 0.020476633682847023
Test Loss:  0.020020049065351486
Valid Loss:  0.018874600529670715
Epoch:  452  	Training Loss: 0.020464086905121803
Test Loss:  0.02000346966087818
Valid Loss:  0.01885799691081047
Epoch:  453  	Training Loss: 0.02045157179236412
Test Loss:  0.019986934959888458
Valid Loss:  0.018841423094272614
Epoch:  454  	Training Loss: 0.02043907344341278
Test Loss:  0.019970418885350227
Valid Loss:  0.018824893981218338
Epoch:  455  	Training Loss: 0.020426589995622635
Test Loss:  0.01995394378900528
Valid Loss:  0.018808383494615555
Epoch:  456  	Training Loss: 0.02041412703692913
Test Loss:  0.01993750035762787
Valid Loss:  0.018791913986206055
Epoch:  457  	Training Loss: 0.02040168270468712
Test Loss:  0.019921092316508293
Valid Loss:  0.018775485455989838
Epoch:  458  	Training Loss: 0.0203892569988966
Test Loss:  0.019904710352420807
Valid Loss:  0.018759090453386307
Epoch:  459  	Training Loss: 0.02037685364484787
Test Loss:  0.019888365641236305
Valid Loss:  0.018742727115750313
Epoch:  460  	Training Loss: 0.020364459604024887
Test Loss:  0.01987205073237419
Valid Loss:  0.018726397305727005
Epoch:  461  	Training Loss: 0.020352084189653397
Test Loss:  0.019855763763189316
Valid Loss:  0.018710097298026085
Epoch:  462  	Training Loss: 0.020339731127023697
Test Loss:  0.019840192049741745
Valid Loss:  0.018694542348384857
Epoch:  463  	Training Loss: 0.02032782882452011
Test Loss:  0.019824650138616562
Valid Loss:  0.018679019063711166
Epoch:  464  	Training Loss: 0.020315933972597122
Test Loss:  0.019809145480394363
Valid Loss:  0.01866353116929531
Epoch:  465  	Training Loss: 0.020304061472415924
Test Loss:  0.019793666899204254
Valid Loss:  0.018648074939846992
Epoch:  466  	Training Loss: 0.020292207598686218
Test Loss:  0.019778212532401085
Valid Loss:  0.01863265037536621
Epoch:  467  	Training Loss: 0.020280372351408005
Test Loss:  0.019762786105275154
Valid Loss:  0.018617257475852966
Epoch:  468  	Training Loss: 0.020268548280000687
Test Loss:  0.019747400656342506
Valid Loss:  0.01860189065337181
Epoch:  469  	Training Loss: 0.02025674656033516
Test Loss:  0.0197320356965065
Valid Loss:  0.01858655922114849
Epoch:  470  	Training Loss: 0.020244954153895378
Test Loss:  0.019716709852218628
Valid Loss:  0.01857125572860241
Epoch:  471  	Training Loss: 0.020233187824487686
Test Loss:  0.019701402634382248
Valid Loss:  0.018555985763669014
Epoch:  472  	Training Loss: 0.02022143080830574
Test Loss:  0.01968597248196602
Valid Loss:  0.018540576100349426
Epoch:  473  	Training Loss: 0.020209606736898422
Test Loss:  0.019670560956001282
Valid Loss:  0.018525192514061928
Epoch:  474  	Training Loss: 0.020197793841362
Test Loss:  0.019655179232358932
Valid Loss:  0.01850985176861286
Epoch:  475  	Training Loss: 0.020186003297567368
Test Loss:  0.019639836624264717
Valid Loss:  0.018494538962841034
Epoch:  476  	Training Loss: 0.02017422765493393
Test Loss:  0.019624516367912292
Valid Loss:  0.018479246646165848
Epoch:  477  	Training Loss: 0.020162466913461685
Test Loss:  0.019609220325946808
Valid Loss:  0.018463991582393646
Epoch:  478  	Training Loss: 0.020150721073150635
Test Loss:  0.019593961536884308
Valid Loss:  0.018448764458298683
Epoch:  479  	Training Loss: 0.020138993859291077
Test Loss:  0.0195787213742733
Valid Loss:  0.018433570861816406
Epoch:  480  	Training Loss: 0.020127281546592712
Test Loss:  0.019563524052500725
Valid Loss:  0.018418405205011368
Epoch:  481  	Training Loss: 0.02011558786034584
Test Loss:  0.01954834721982479
Valid Loss:  0.018403271213173866
Epoch:  482  	Training Loss: 0.02010391093790531
Test Loss:  0.019533256068825722
Valid Loss:  0.018388239666819572
Epoch:  483  	Training Loss: 0.020092269405722618
Test Loss:  0.019518200308084488
Valid Loss:  0.018373236060142517
Epoch:  484  	Training Loss: 0.020080648362636566
Test Loss:  0.019503170624375343
Valid Loss:  0.018358264118433
Epoch:  485  	Training Loss: 0.020069044083356857
Test Loss:  0.019488167017698288
Valid Loss:  0.01834331639111042
Epoch:  486  	Training Loss: 0.020057450979948044
Test Loss:  0.01947319693863392
Valid Loss:  0.018328404054045677
Epoch:  487  	Training Loss: 0.02004588022828102
Test Loss:  0.019458258524537086
Valid Loss:  0.018313514068722725
Epoch:  488  	Training Loss: 0.020034320652484894
Test Loss:  0.019443335011601448
Valid Loss:  0.018298666924238205
Epoch:  489  	Training Loss: 0.02002277597784996
Test Loss:  0.019428446888923645
Valid Loss:  0.01828383281826973
Epoch:  490  	Training Loss: 0.02001124806702137
Test Loss:  0.019413575530052185
Valid Loss:  0.018269039690494537
Epoch:  491  	Training Loss: 0.019999735057353973
Test Loss:  0.01939874328672886
Valid Loss:  0.018254268914461136
Epoch:  492  	Training Loss: 0.01998823508620262
Test Loss:  0.019383957609534264
Valid Loss:  0.01823955774307251
Epoch:  493  	Training Loss: 0.019976766780018806
Test Loss:  0.019369203597307205
Valid Loss:  0.01822487637400627
Epoch:  494  	Training Loss: 0.019965313374996185
Test Loss:  0.01935446262359619
Valid Loss:  0.01821022480726242
Epoch:  495  	Training Loss: 0.019953876733779907
Test Loss:  0.01933976635336876
Valid Loss:  0.01819559372961521
Epoch:  496  	Training Loss: 0.019942454993724823
Test Loss:  0.01932508498430252
Valid Loss:  0.01818099617958069
 99%|█████████▉| 497/500 [05:40<00:01,  2.22it/s]100%|█████████▉| 499/500 [05:41<00:00,  2.98it/s]100%|██████████| 500/500 [05:41<00:00,  1.47it/s]
Epoch:  497  	Training Loss: 0.019931048154830933
Test Loss:  0.019310440868139267
Valid Loss:  0.018166426569223404
Epoch:  498  	Training Loss: 0.019919652491807938
Test Loss:  0.019295817241072655
Valid Loss:  0.01815188303589821
Epoch:  499  	Training Loss: 0.019908275455236435
Test Loss:  0.01928122341632843
Valid Loss:  0.018137378618121147
Epoch:  500  	Training Loss: 0.019896917045116425
Test Loss:  0.019266655668616295
Valid Loss:  0.01812288910150528
seed is  6
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:34,  6.20s/it]  1%|          | 3/500 [00:06<13:46,  1.66s/it]  1%|          | 5/500 [00:06<07:01,  1.17it/s]  1%|▏         | 7/500 [00:06<04:19,  1.90it/s]  2%|▏         | 9/500 [00:06<02:53,  2.83it/s]  2%|▏         | 11/500 [00:13<10:48,  1.33s/it]  3%|▎         | 13/500 [00:13<07:22,  1.10it/s]  3%|▎         | 15/500 [00:13<05:08,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:40,  2.99it/s]  4%|▍         | 21/500 [00:20<09:45,  1.22s/it]  5%|▍         | 23/500 [00:20<06:55,  1.15it/s]  5%|▌         | 25/500 [00:26<12:33,  1.59s/it]  5%|▌         | 27/500 [00:26<08:53,  1.13s/it]  6%|▌         | 29/500 [00:26<06:20,  1.24it/s]  6%|▌         | 31/500 [00:33<11:54,  1.52s/it]  7%|▋         | 33/500 [00:33<08:27,  1.09s/it]  7%|▋         | 35/500 [00:33<06:02,  1.28it/s]  7%|▋         | 37/500 [00:33<04:22,  1.76it/s]  8%|▊         | 39/500 [00:33<03:14,  2.37it/s]  8%|▊         | 41/500 [00:40<09:30,  1.24s/it]  9%|▊         | 43/500 [00:40<06:47,  1.12it/s]  9%|▉         | 45/500 [00:40<04:52,  1.55it/s]  9%|▉         | 47/500 [00:40<03:32,  2.13it/s] 10%|▉         | 49/500 [00:40<02:37,  2.87it/s] 10%|█         | 51/500 [00:46<08:49,  1.18s/it] 11%|█         | 53/500 [00:47<06:19,  1.18it/s] 11%|█         | 55/500 [00:47<04:33,  1.63it/s] 11%|█▏        | 57/500 [00:47<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:47<02:28,  2.98it/s] 12%|█▏        | 61/500 [00:53<08:40,  1.19s/it] 13%|█▎        | 63/500 [00:54<06:12,  1.17it/s] 13%|█▎        | 65/500 [00:54<04:29,  1.61it/s] 13%|█▎        | 67/500 [00:54<03:19,  2.17it/s]Epoch:  1  	Training Loss: 0.023515261709690094
Test Loss:  0.012178508564829826
Valid Loss:  0.011545330286026001
Epoch:  2  	Training Loss: 0.01588929072022438
Test Loss:  0.031157173216342926
Valid Loss:  0.031672459095716476
Epoch:  3  	Training Loss: 0.027343984693288803
Test Loss:  0.005606797523796558
Valid Loss:  0.005263872444629669
Epoch:  4  	Training Loss: 0.007101114839315414
Test Loss:  0.00470182579010725
Valid Loss:  0.00443320581689477
Epoch:  5  	Training Loss: 0.006022405810654163
Test Loss:  0.0037344181910157204
Valid Loss:  0.003539642784744501
Epoch:  6  	Training Loss: 0.005068983417004347
Test Loss:  0.003987223841249943
Valid Loss:  0.003925005905330181
Epoch:  7  	Training Loss: 0.004940375220030546
Test Loss:  0.0032058716751635075
Valid Loss:  0.0030880761332809925
Epoch:  8  	Training Loss: 0.00455887708812952
Test Loss:  0.0032806117087602615
Valid Loss:  0.003366970457136631
Epoch:  9  	Training Loss: 0.004075281322002411
Test Loss:  0.0027437228709459305
Valid Loss:  0.0027301697991788387
Epoch:  10  	Training Loss: 0.003965514712035656
Test Loss:  0.0027679065242409706
Valid Loss:  0.0029306337237358093
Epoch:  11  	Training Loss: 0.003529916750267148
Test Loss:  0.0023536081425845623
Valid Loss:  0.002495665568858385
Epoch:  12  	Training Loss: 0.0032854669261723757
Test Loss:  0.001933360006660223
Valid Loss:  0.0023150737397372723
Epoch:  13  	Training Loss: 0.002577049657702446
Test Loss:  0.003502353560179472
Valid Loss:  0.003672190010547638
Epoch:  14  	Training Loss: 0.004575170576572418
Test Loss:  0.015192418359220028
Valid Loss:  0.01620989665389061
Epoch:  15  	Training Loss: 0.015085253864526749
Test Loss:  0.006695267278701067
Valid Loss:  0.006901364773511887
Epoch:  16  	Training Loss: 0.007907911203801632
Test Loss:  0.004023554734885693
Valid Loss:  0.0042183492332696915
Epoch:  17  	Training Loss: 0.004510615020990372
Test Loss:  0.002534525003284216
Valid Loss:  0.002706887200474739
Epoch:  18  	Training Loss: 0.003485290100798011
Test Loss:  0.0023500812239944935
Valid Loss:  0.0025715494994074106
Epoch:  19  	Training Loss: 0.0032265547197312117
Test Loss:  0.002159368246793747
Valid Loss:  0.0024092800449579954
Epoch:  20  	Training Loss: 0.0030352030880749226
Test Loss:  0.0020040119998157024
Valid Loss:  0.002275175182148814
Epoch:  21  	Training Loss: 0.0028849560767412186
Test Loss:  0.00189022917766124
Valid Loss:  0.0021872990764677525
Epoch:  22  	Training Loss: 0.0027619092725217342
Test Loss:  0.0019889448303729296
Valid Loss:  0.0024541490711271763
Epoch:  23  	Training Loss: 0.0025624081026762724
Test Loss:  0.00213656690903008
Valid Loss:  0.0024091980885714293
Epoch:  24  	Training Loss: 0.003114486811682582
Test Loss:  0.003004903206601739
Valid Loss:  0.003604752477258444
Epoch:  25  	Training Loss: 0.00356709654442966
Test Loss:  0.0033581892494112253
Valid Loss:  0.003599956165999174
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.004391716793179512
Test Loss:  0.0017809737473726273
Valid Loss:  0.0021464359015226364
Epoch:  27  	Training Loss: 0.0025483006611466408
Test Loss:  0.001598200760781765
Valid Loss:  0.00196185358799994
Epoch:  28  	Training Loss: 0.002350713824853301
Test Loss:  0.001515155890956521
Valid Loss:  0.0018999887397512794
Epoch:  29  	Training Loss: 0.0022107150871306658
Test Loss:  0.0014886942226439714
Valid Loss:  0.001869711559265852
Epoch:  30  	Training Loss: 0.002147153951227665
Test Loss:  0.0014752066927030683
Valid Loss:  0.00186615576967597
Epoch:  31  	Training Loss: 0.002117168391123414
Test Loss:  0.0014664529589936137
Valid Loss:  0.0018519629957154393
Epoch:  32  	Training Loss: 0.0020931775216013193
Test Loss:  0.0013888116227462888
Valid Loss:  0.0018061230657622218
Epoch:  33  	Training Loss: 0.0019562742672860622
Test Loss:  0.001379132503643632
Valid Loss:  0.0017960488330572844
Epoch:  34  	Training Loss: 0.0019164234399795532
Test Loss:  0.001372288796119392
Valid Loss:  0.0017932441551238298
Epoch:  35  	Training Loss: 0.0018994613783434033
Test Loss:  0.0013664126163348556
Valid Loss:  0.0017882065149024129
Epoch:  36  	Training Loss: 0.0018899939022958279
Test Loss:  0.0013650935143232346
Valid Loss:  0.001794433337636292
Epoch:  37  	Training Loss: 0.0018817317904904485
Test Loss:  0.0013570762239396572
Valid Loss:  0.0017831228906288743
Epoch:  38  	Training Loss: 0.0018735469784587622
Test Loss:  0.00135706621222198
Valid Loss:  0.0017881868407130241
Epoch:  39  	Training Loss: 0.0018638325855135918
Test Loss:  0.0013509935233741999
Valid Loss:  0.0017802820075303316
Epoch:  40  	Training Loss: 0.0018571678083389997
Test Loss:  0.0013506566174328327
Valid Loss:  0.0017852716846391559
Epoch:  41  	Training Loss: 0.0018503378378227353
Test Loss:  0.0013456917367875576
Valid Loss:  0.0017770810518413782
Epoch:  42  	Training Loss: 0.0018447034526616335
Test Loss:  0.001330640516243875
Valid Loss:  0.00177311385050416
Epoch:  43  	Training Loss: 0.0018078726716339588
Test Loss:  0.0013100674841552973
Valid Loss:  0.001752739422954619
Epoch:  44  	Training Loss: 0.001787516288459301
Test Loss:  0.001299426076002419
Valid Loss:  0.0017423066310584545
Epoch:  45  	Training Loss: 0.0017701283795759082
Test Loss:  0.0012840413255617023
Valid Loss:  0.0017276403959840536
Epoch:  46  	Training Loss: 0.0017551740165799856
Test Loss:  0.0012722109677270055
Valid Loss:  0.0017185297328978777
Epoch:  47  	Training Loss: 0.0017422283999621868
Test Loss:  0.001258840668015182
Valid Loss:  0.0017075513023883104
Epoch:  48  	Training Loss: 0.0017299316823482513
Test Loss:  0.0012488565407693386
Valid Loss:  0.0017004564870148897
Epoch:  49  	Training Loss: 0.0017178477719426155
Test Loss:  0.001236998476088047
Valid Loss:  0.0016908919205889106
Epoch:  50  	Training Loss: 0.0017066259169951081
Test Loss:  0.001228962792083621
Valid Loss:  0.001685798866674304
Epoch:  51  	Training Loss: 0.001697525498457253
Test Loss:  0.0012200662167742848
Valid Loss:  0.0016796840354800224
Epoch:  52  	Training Loss: 0.0016894835280254483
Test Loss:  0.0012087970972061157
Valid Loss:  0.0016688688192516565
Epoch:  53  	Training Loss: 0.0016810712404549122
Test Loss:  0.0012010204372927547
Valid Loss:  0.0016647102311253548
Epoch:  54  	Training Loss: 0.0016741211293265224
Test Loss:  0.0011929571628570557
Valid Loss:  0.001658448949456215
Epoch:  55  	Training Loss: 0.001668385462835431
Test Loss:  0.0011871283641085029
Valid Loss:  0.001654221909120679
Epoch:  56  	Training Loss: 0.0016632776241749525
Test Loss:  0.001181888859719038
Valid Loss:  0.0016524011734873056
Epoch:  57  	Training Loss: 0.0016579737421125174
Test Loss:  0.001175998360849917
Valid Loss:  0.0016487606335431337
Epoch:  58  	Training Loss: 0.0016532556619495153
Test Loss:  0.0011705306824296713
Valid Loss:  0.0016435752622783184
Epoch:  59  	Training Loss: 0.001648963545449078
Test Loss:  0.0011664247140288353
Valid Loss:  0.0016420776955783367
Epoch:  60  	Training Loss: 0.0016444862121716142
Test Loss:  0.0011616505216807127
Valid Loss:  0.0016371828969568014
Epoch:  61  	Training Loss: 0.001640717382542789
Test Loss:  0.0011587245389819145
Valid Loss:  0.0016357230488210917
Epoch:  62  	Training Loss: 0.0016371484380215406
Test Loss:  0.0011222746688872576
Valid Loss:  0.001605285913683474
Epoch:  63  	Training Loss: 0.0015829866752028465
Test Loss:  0.0010886064264923334
Valid Loss:  0.0015741427196189761
Epoch:  64  	Training Loss: 0.0015278548235073686
Test Loss:  0.0010653446661308408
Valid Loss:  0.0015481339069083333
Epoch:  65  	Training Loss: 0.0014828722923994064
Test Loss:  0.0010520960204303265
Valid Loss:  0.0015344555722549558
Epoch:  66  	Training Loss: 0.0014536735834553838
Test Loss:  0.0010453183203935623
Valid Loss:  0.0015265801921486855
Epoch:  67  	Training Loss: 0.0014365448150783777
Test Loss:  0.0010395835852250457
Valid Loss:  0.0015216129831969738
Epoch:  68  	Training Loss: 0.0014257989823818207
Test Loss:  0.0010339489672333002
Valid Loss:  0.0015169379767030478
Epoch:  69  	Training Loss: 0.001417218241840601
Test Loss:   14%|█▍        | 69/500 [00:54<02:30,  2.87it/s] 14%|█▍        | 71/500 [01:01<08:43,  1.22s/it] 15%|█▍        | 73/500 [01:01<06:13,  1.14it/s] 15%|█▌        | 75/500 [01:01<04:28,  1.58it/s] 15%|█▌        | 77/500 [01:01<03:15,  2.16it/s] 16%|█▌        | 79/500 [01:01<02:24,  2.92it/s] 16%|█▌        | 81/500 [01:07<08:22,  1.20s/it] 17%|█▋        | 83/500 [01:08<05:58,  1.16it/s] 17%|█▋        | 85/500 [01:08<04:18,  1.61it/s] 17%|█▋        | 87/500 [01:08<03:07,  2.20it/s] 18%|█▊        | 89/500 [01:08<02:18,  2.96it/s] 18%|█▊        | 91/500 [01:14<07:59,  1.17s/it] 19%|█▊        | 93/500 [01:14<05:42,  1.19it/s] 19%|█▉        | 95/500 [01:15<04:06,  1.64it/s] 19%|█▉        | 97/500 [01:15<02:59,  2.24it/s] 20%|█▉        | 99/500 [01:15<02:13,  3.01it/s] 20%|██        | 101/500 [01:21<07:59,  1.20s/it] 21%|██        | 103/500 [01:21<05:42,  1.16it/s] 21%|██        | 105/500 [01:21<04:06,  1.60it/s] 21%|██▏       | 107/500 [01:22<02:59,  2.19it/s] 22%|██▏       | 109/500 [01:22<02:12,  2.95it/s] 22%|██▏       | 111/500 [01:28<07:43,  1.19s/it] 23%|██▎       | 113/500 [01:28<05:31,  1.17it/s] 23%|██▎       | 115/500 [01:28<03:58,  1.62it/s] 23%|██▎       | 117/500 [01:29<02:53,  2.21it/s] 24%|██▍       | 119/500 [01:29<02:08,  2.97it/s] 24%|██▍       | 121/500 [01:35<07:27,  1.18s/it] 25%|██▍       | 123/500 [01:35<05:19,  1.18it/s] 25%|██▌       | 125/500 [01:35<03:50,  1.63it/s] 25%|██▌       | 127/500 [01:35<02:47,  2.23it/s] 26%|██▌       | 129/500 [01:36<02:03,  2.99it/s] 26%|██▌       | 131/500 [01:42<07:15,  1.18s/it] 27%|██▋       | 133/500 [01:42<05:10,  1.18it/s] 27%|██▋       | 135/500 [01:42<03:43,  1.63it/s] 27%|██▋       | 137/500 [01:42<02:42,  2.23it/s]0.0010284269228577614
Valid Loss:  0.0015120586613193154
Epoch:  70  	Training Loss: 0.0014092396013438702
Test Loss:  0.0010233297944068909
Valid Loss:  0.0015077642165124416
Epoch:  71  	Training Loss: 0.0014020252274349332
Test Loss:  0.0010183686390519142
Valid Loss:  0.0015030994545668364
Epoch:  72  	Training Loss: 0.0013956165639683604
Test Loss:  0.0010045652743428946
Valid Loss:  0.0014896928332746029
Epoch:  73  	Training Loss: 0.0013858871534466743
Test Loss:  0.0009954364504665136
Valid Loss:  0.00148029497358948
Epoch:  74  	Training Loss: 0.001380091649480164
Test Loss:  0.0009875225368887186
Valid Loss:  0.0014718149323016405
Epoch:  75  	Training Loss: 0.001375121995806694
Test Loss:  0.0009806115413084626
Valid Loss:  0.0014641128946095705
Epoch:  76  	Training Loss: 0.001370733603835106
Test Loss:  0.0009740968234837055
Valid Loss:  0.001456916332244873
Epoch:  77  	Training Loss: 0.0013665644219145179
Test Loss:  0.0009680404327809811
Valid Loss:  0.0014502103440463543
Epoch:  78  	Training Loss: 0.0013626199215650558
Test Loss:  0.0009631799766793847
Valid Loss:  0.0014442066894844174
Epoch:  79  	Training Loss: 0.0013594052288681269
Test Loss:  0.00095869175856933
Valid Loss:  0.0014386626426130533
Epoch:  80  	Training Loss: 0.0013564135879278183
Test Loss:  0.0009544421918690205
Valid Loss:  0.0014334622537717223
Epoch:  81  	Training Loss: 0.0013535383623093367
Test Loss:  0.0009504000772722065
Valid Loss:  0.0014285743236541748
Epoch:  82  	Training Loss: 0.0013508060947060585
Test Loss:  0.0009445039904676378
Valid Loss:  0.0014221450546756387
Epoch:  83  	Training Loss: 0.0013413387350738049
Test Loss:  0.0009395204251632094
Valid Loss:  0.0014180003199726343
Epoch:  84  	Training Loss: 0.0013351639499887824
Test Loss:  0.0009373849024996161
Valid Loss:  0.0014172622468322515
Epoch:  85  	Training Loss: 0.0013306655455380678
Test Loss:  0.00093472795560956
Valid Loss:  0.0014141876017674804
Epoch:  86  	Training Loss: 0.001326850731857121
Test Loss:  0.0009315718780271709
Valid Loss:  0.0014104151632636786
Epoch:  87  	Training Loss: 0.0013233863282948732
Test Loss:  0.0009290806483477354
Valid Loss:  0.0014075830113142729
Epoch:  88  	Training Loss: 0.001320384442806244
Test Loss:  0.0009270255686715245
Valid Loss:  0.0014049333985894918
Epoch:  89  	Training Loss: 0.001317764399573207
Test Loss:  0.0009253816097043455
Valid Loss:  0.0014026984572410583
Epoch:  90  	Training Loss: 0.0013154847547411919
Test Loss:  0.0009251497685909271
Valid Loss:  0.0014029666781425476
Epoch:  91  	Training Loss: 0.0013133854372426867
Test Loss:  0.0009237667545676231
Valid Loss:  0.0014011086896061897
Epoch:  92  	Training Loss: 0.001311186933889985
Test Loss:  0.0009202549117617309
Valid Loss:  0.0013952068984508514
Epoch:  93  	Training Loss: 0.001310317195020616
Test Loss:  0.0009189194533973932
Valid Loss:  0.0013923565857112408
Epoch:  94  	Training Loss: 0.001309671439230442
Test Loss:  0.0009176799794659019
Valid Loss:  0.0013895634328946471
Epoch:  95  	Training Loss: 0.0013091103173792362
Test Loss:  0.0009164246148429811
Valid Loss:  0.0013868422247469425
Epoch:  96  	Training Loss: 0.0013086157850921154
Test Loss:  0.0009151867125183344
Valid Loss:  0.0013842619955539703
Epoch:  97  	Training Loss: 0.0013081824872642756
Test Loss:  0.0009142070775851607
Valid Loss:  0.0013820633757859468
Epoch:  98  	Training Loss: 0.001307842554524541
Test Loss:  0.0009130901889875531
Valid Loss:  0.0013801211025565863
Epoch:  99  	Training Loss: 0.001307666185311973
Test Loss:  0.0009125956567004323
Valid Loss:  0.0013788238866254687
Epoch:  100  	Training Loss: 0.0013075373135507107
Test Loss:  0.0009117108420468867
Valid Loss:  0.0013772756792604923
Epoch:  101  	Training Loss: 0.0013074495363980532
Test Loss:  0.0009114964632317424
Valid Loss:  0.0013764600735157728
Epoch:  102  	Training Loss: 0.0013073822483420372
Test Loss:  0.0009057687129825354
Valid Loss:  0.0013700895942747593
Epoch:  103  	Training Loss: 0.0013026699889451265
Test Loss:  0.0008996085962280631
Valid Loss:  0.0013637482188642025
Epoch:  104  	Training Loss: 0.0012977265287190676
Test Loss:  0.0008951880154199898
Valid Loss:  0.0013601368991658092
Epoch:  105  	Training Loss: 0.0012943758629262447
Test Loss:  0.0008920941036194563
Valid Loss:  0.0013579048682004213
Epoch:  106  	Training Loss: 0.0012915292754769325
Test Loss:  0.0008894961792975664
Valid Loss:  0.0013555838959291577
Epoch:  107  	Training Loss: 0.00128915102686733
Test Loss:  0.0008873182232491672
Valid Loss:  0.0013536278856918216
Epoch:  108  	Training Loss: 0.001286954153329134
Test Loss:  0.0008849529549479485
Valid Loss:  0.0013514477759599686
Epoch:  109  	Training Loss: 0.001284787431359291
Test Loss:  0.0008827904239296913
Valid Loss:  0.0013494737213477492
Epoch:  110  	Training Loss: 0.0012826541205868125
Test Loss:  0.0008804327808320522
Valid Loss:  0.0013472556602209806
Epoch:  111  	Training Loss: 0.0012806232552975416
Test Loss:  0.0008786186808720231
Valid Loss:  0.0013453580904752016
Epoch:  112  	Training Loss: 0.0012786905281245708
Test Loss:  0.0008637815481051803
Valid Loss:  0.0013387913350015879
Epoch:  113  	Training Loss: 0.0012555867433547974
Test Loss:  0.000849627424031496
Valid Loss:  0.0013237311504781246
Epoch:  114  	Training Loss: 0.0012411244679242373
Test Loss:  0.0008418114739470184
Valid Loss:  0.0013188121374696493
Epoch:  115  	Training Loss: 0.0012290667509660125
Test Loss:  0.0008317825850099325
Valid Loss:  0.0013084766687825322
Epoch:  116  	Training Loss: 0.001218354911543429
Test Loss:  0.0008249929524026811
Valid Loss:  0.0013027751119807363
Epoch:  117  	Training Loss: 0.0012085889466106892
Test Loss:  0.0008169654756784439
Valid Loss:  0.0012935480335727334
Epoch:  118  	Training Loss: 0.0011997600086033344
Test Loss:  0.0008104576263576746
Valid Loss:  0.0012870996724814177
Epoch:  119  	Training Loss: 0.0011912004556506872
Test Loss:  0.0008032637415453792
Valid Loss:  0.001279159914702177
Epoch:  120  	Training Loss: 0.0011828570859506726
Test Loss:  0.0007968241116032004
Valid Loss:  0.001272738678380847
Epoch:  121  	Training Loss: 0.0011747542303055525
Test Loss:  0.0007900350028648973
Valid Loss:  0.0012655970640480518
Epoch:  122  	Training Loss: 0.001166897127404809
Test Loss:  0.0007852793205529451
Valid Loss:  0.0012626611860468984
Epoch:  123  	Training Loss: 0.0011587931076064706
Test Loss:  0.0007807460497133434
Valid Loss:  0.0012580391485244036
Epoch:  124  	Training Loss: 0.0011522088898345828
Test Loss:  0.0007762704626657069
Valid Loss:  0.0012525232741609216
Epoch:  125  	Training Loss: 0.0011465201387181878
Test Loss:  0.0007726391777396202
Valid Loss:  0.0012478053104132414
Epoch:  126  	Training Loss: 0.001141298795118928
Test Loss:  0.000769163656514138
Valid Loss:  0.0012432357762008905
Epoch:  127  	Training Loss: 0.0011362751247361302
Test Loss:  0.0007653808570466936
Valid Loss:  0.0012382641434669495
Epoch:  128  	Training Loss: 0.0011316323652863503
Test Loss:  0.0007622087141498923
Valid Loss:  0.0012338978704065084
Epoch:  129  	Training Loss: 0.0011271487455815077
Test Loss:  0.0007590759778395295
Valid Loss:  0.0012297193752601743
Epoch:  130  	Training Loss: 0.001122787594795227
Test Loss:  0.0007560267113149166
Valid Loss:  0.0012257385533303022
Epoch:  131  	Training Loss: 0.0011185002513229847
Test Loss:  0.0007531895535066724
Valid Loss:  0.0012218526098877192
Epoch:  132  	Training Loss: 0.0011144133750349283
Test Loss:  0.0007484505767934024
Valid Loss:  0.0012135185534134507
Epoch:  133  	Training Loss: 0.0011113818036392331
Test Loss:  0.0007444843067787588
Valid Loss:  0.0012076095445081592
Epoch:  134  	Training Loss: 0.001108742319047451
Test Loss:  0.0007408283418044448
Valid Loss:  0.0012017387198284268
Epoch:  135  	Training Loss: 0.0011063686106353998
Test Loss:  0.0007376732537522912
Valid Loss:  0.001196988276205957
Epoch:  136  	Training Loss: 0.0011042578844353557
Test Loss:  0.0007348523940891027
Valid Loss:  0.0011926188599318266
Epoch:  137  	Training Loss: 0.0011023683473467827
Test Loss:  0.000732306856662035
Valid Loss:  0.0011888084700331092
 28%|██▊       | 139/500 [01:42<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:49<06:59,  1.17s/it] 29%|██▊       | 143/500 [01:49<05:00,  1.19it/s] 29%|██▉       | 145/500 [01:49<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:49<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:49<01:56,  3.02it/s] 30%|███       | 151/500 [01:55<06:52,  1.18s/it] 31%|███       | 153/500 [01:56<04:54,  1.18it/s] 31%|███       | 155/500 [01:56<03:32,  1.63it/s] 31%|███▏      | 157/500 [01:56<02:34,  2.22it/s] 32%|███▏      | 159/500 [01:56<01:54,  2.97it/s] 32%|███▏      | 161/500 [02:02<06:39,  1.18s/it] 33%|███▎      | 163/500 [02:02<04:45,  1.18it/s] 33%|███▎      | 165/500 [02:03<03:25,  1.63it/s] 33%|███▎      | 167/500 [02:03<02:29,  2.23it/s] 34%|███▍      | 169/500 [02:03<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:09<06:31,  1.19s/it] 35%|███▍      | 173/500 [02:09<04:40,  1.17it/s] 35%|███▌      | 175/500 [02:10<03:21,  1.61it/s] 35%|███▌      | 177/500 [02:10<02:26,  2.21it/s] 36%|███▌      | 179/500 [02:10<01:48,  2.96it/s] 36%|███▌      | 181/500 [02:16<06:18,  1.19s/it] 37%|███▋      | 183/500 [02:16<04:29,  1.17it/s] 37%|███▋      | 185/500 [02:16<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:17<02:21,  2.22it/s] 38%|███▊      | 189/500 [02:17<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:23<06:11,  1.20s/it] 39%|███▊      | 193/500 [02:23<04:25,  1.16it/s] 39%|███▉      | 195/500 [02:23<03:10,  1.60it/s] 39%|███▉      | 197/500 [02:24<02:18,  2.19it/s] 40%|███▉      | 199/500 [02:24<01:42,  2.94it/s] 40%|████      | 201/500 [02:30<05:56,  1.19s/it] 41%|████      | 203/500 [02:30<04:14,  1.17it/s] 41%|████      | 205/500 [02:30<03:03,  1.61it/s]Epoch:  138  	Training Loss: 0.0011007137363776565
Test Loss:  0.0007300503202714026
Valid Loss:  0.001185412984341383
Epoch:  139  	Training Loss: 0.0010992293246090412
Test Loss:  0.0007281103753484786
Valid Loss:  0.0011824091197922826
Epoch:  140  	Training Loss: 0.0010978311765938997
Test Loss:  0.0007263491861522198
Valid Loss:  0.0011797163169831038
Epoch:  141  	Training Loss: 0.001096491701900959
Test Loss:  0.0007246980676427484
Valid Loss:  0.0011772625148296356
Epoch:  142  	Training Loss: 0.0010952362790703773
Test Loss:  0.000722158991266042
Valid Loss:  0.0011745519004762173
Epoch:  143  	Training Loss: 0.0010931063443422318
Test Loss:  0.0007199426181614399
Valid Loss:  0.0011725863441824913
Epoch:  144  	Training Loss: 0.0010910665150731802
Test Loss:  0.0007178176310844719
Valid Loss:  0.0011704866774380207
Epoch:  145  	Training Loss: 0.001089123310521245
Test Loss:  0.0007160075474530458
Valid Loss:  0.0011686887592077255
Epoch:  146  	Training Loss: 0.0010873437859117985
Test Loss:  0.0007143458351492882
Valid Loss:  0.0011669902596622705
Epoch:  147  	Training Loss: 0.0010856635635718703
Test Loss:  0.0007127351127564907
Valid Loss:  0.001165479188784957
Epoch:  148  	Training Loss: 0.0010840296745300293
Test Loss:  0.0007111986051313579
Valid Loss:  0.0011641555465757847
Epoch:  149  	Training Loss: 0.0010824736673384905
Test Loss:  0.0007097066263668239
Valid Loss:  0.001162935164757073
Epoch:  150  	Training Loss: 0.0010809757513925433
Test Loss:  0.0007084067910909653
Valid Loss:  0.0011617987183853984
Epoch:  151  	Training Loss: 0.0010795617708936334
Test Loss:  0.0007071917643770576
Valid Loss:  0.0011607279302552342
Epoch:  152  	Training Loss: 0.0010782303288578987
Test Loss:  0.0007066577672958374
Valid Loss:  0.0011652105022221804
Epoch:  153  	Training Loss: 0.0010671773925423622
Test Loss:  0.0007024809019640088
Valid Loss:  0.0011584449093788862
Epoch:  154  	Training Loss: 0.001061637420207262
Test Loss:  0.0007027881219983101
Valid Loss:  0.0011587110348045826
Epoch:  155  	Training Loss: 0.001058181282132864
Test Loss:  0.0007021435885690153
Valid Loss:  0.0011567982146516442
Epoch:  156  	Training Loss: 0.0010557074565440416
Test Loss:  0.0007021487690508366
Valid Loss:  0.001155351521447301
Epoch:  157  	Training Loss: 0.0010540683288127184
Test Loss:  0.0007018556352704763
Valid Loss:  0.0011536156525835395
Epoch:  158  	Training Loss: 0.00105282012373209
Test Loss:  0.00070173479616642
Valid Loss:  0.0011522680288180709
Epoch:  159  	Training Loss: 0.0010516837937757373
Test Loss:  0.000701533688697964
Valid Loss:  0.0011506854789331555
Epoch:  160  	Training Loss: 0.0010506821563467383
Test Loss:  0.0007010875269770622
Valid Loss:  0.0011486755684018135
Epoch:  161  	Training Loss: 0.0010498898336663842
Test Loss:  0.0007006534724496305
Valid Loss:  0.0011467302683740854
Epoch:  162  	Training Loss: 0.0010492282453924417
Test Loss:  0.0006941855535842478
Valid Loss:  0.0011392629239708185
Epoch:  163  	Training Loss: 0.0010443020146340132
Test Loss:  0.0006894737016409636
Valid Loss:  0.0011337061878293753
Epoch:  164  	Training Loss: 0.0010398951126262546
Test Loss:  0.00068514613667503
Valid Loss:  0.0011284260544925928
Epoch:  165  	Training Loss: 0.0010356471175327897
Test Loss:  0.0006809160113334656
Valid Loss:  0.0011232965625822544
Epoch:  166  	Training Loss: 0.0010315300896763802
Test Loss:  0.0006768851890228689
Valid Loss:  0.0011184434406459332
Epoch:  167  	Training Loss: 0.0010274855885654688
Test Loss:  0.0006733595510013402
Valid Loss:  0.001114091370254755
Epoch:  168  	Training Loss: 0.0010235277004539967
Test Loss:  0.0006700698286294937
Valid Loss:  0.0011099136900156736
Epoch:  169  	Training Loss: 0.0010196297662332654
Test Loss:  0.0006668446585536003
Valid Loss:  0.001105806790292263
Epoch:  170  	Training Loss: 0.001015763496980071
Test Loss:  0.0006636347388848662
Valid Loss:  0.0011016916250810027
Epoch:  171  	Training Loss: 0.001011966960504651
Test Loss:  0.0006605017697438598
Valid Loss:  0.0010976879857480526
Epoch:  172  	Training Loss: 0.0010081890504807234
Test Loss:  0.000651757582090795
Valid Loss:  0.0010890121338889003
Epoch:  173  	Training Loss: 0.0009988355450332165
Test Loss:  0.0006446182960644364
Valid Loss:  0.0010823539923876524
Epoch:  174  	Training Loss: 0.0009906410705298185
Test Loss:  0.0006395425298251212
Valid Loss:  0.0010773591930046678
Epoch:  175  	Training Loss: 0.0009846265893429518
Test Loss:  0.0006351651973091066
Valid Loss:  0.0010729958303272724
Epoch:  176  	Training Loss: 0.0009792428463697433
Test Loss:  0.0006315932841971517
Valid Loss:  0.0010687786852940917
Epoch:  177  	Training Loss: 0.000974318478256464
Test Loss:  0.0006283135153353214
Valid Loss:  0.0010646800510585308
Epoch:  178  	Training Loss: 0.0009698010399006307
Test Loss:  0.0006251417798921466
Valid Loss:  0.0010605358984321356
Epoch:  179  	Training Loss: 0.0009657239424996078
Test Loss:  0.0006221665535122156
Valid Loss:  0.0010567950084805489
Epoch:  180  	Training Loss: 0.0009617311879992485
Test Loss:  0.0006191007560119033
Valid Loss:  0.0010531574953347445
Epoch:  181  	Training Loss: 0.000957801821641624
Test Loss:  0.0006161988712847233
Valid Loss:  0.0010497192852199078
Epoch:  182  	Training Loss: 0.0009540549363009632
Test Loss:  0.0006149126566015184
Valid Loss:  0.0010484919184818864
Epoch:  183  	Training Loss: 0.0009511152748018503
Test Loss:  0.0006135601433925331
Valid Loss:  0.0010462633799761534
Epoch:  184  	Training Loss: 0.0009489869116805494
Test Loss:  0.0006123437196947634
Valid Loss:  0.0010443616192787886
Epoch:  185  	Training Loss: 0.0009469684446230531
Test Loss:  0.0006110035465098917
Valid Loss:  0.0010423449566587806
Epoch:  186  	Training Loss: 0.0009450727957300842
Test Loss:  0.0006097268778830767
Valid Loss:  0.0010403861524537206
Epoch:  187  	Training Loss: 0.0009432247024960816
Test Loss:  0.0006086020148359239
Valid Loss:  0.001038429094478488
Epoch:  188  	Training Loss: 0.000941408216021955
Test Loss:  0.0006074337870813906
Valid Loss:  0.0010363952023908496
Epoch:  189  	Training Loss: 0.0009396864334121346
Test Loss:  0.0006062864558771253
Valid Loss:  0.0010343962348997593
Epoch:  190  	Training Loss: 0.0009380163392052054
Test Loss:  0.0006052349926903844
Valid Loss:  0.0010325198527425528
Epoch:  191  	Training Loss: 0.0009363773860968649
Test Loss:  0.0006041841697879136
Valid Loss:  0.00103057234082371
Epoch:  192  	Training Loss: 0.0009347557788714767
Test Loss:  0.000602572865318507
Valid Loss:  0.0010285533498972654
Epoch:  193  	Training Loss: 0.0009312909096479416
Test Loss:  0.0006004357128404081
Valid Loss:  0.0010257537942379713
Epoch:  194  	Training Loss: 0.0009279879741370678
Test Loss:  0.0005982823204249144
Valid Loss:  0.0010230103507637978
Epoch:  195  	Training Loss: 0.0009247621055692434
Test Loss:  0.0005959884729236364
Valid Loss:  0.0010201436234638095
Epoch:  196  	Training Loss: 0.0009215633617714047
Test Loss:  0.0005937140667811036
Valid Loss:  0.0010173728223890066
Epoch:  197  	Training Loss: 0.0009183865040540695
Test Loss:  0.000591547111980617
Valid Loss:  0.0010146970162168145
Epoch:  198  	Training Loss: 0.0009152355487458408
Test Loss:  0.00058920425362885
Valid Loss:  0.0010117797646671534
Epoch:  199  	Training Loss: 0.0009121082257479429
Test Loss:  0.0005869067390449345
Valid Loss:  0.001008944003842771
Epoch:  200  	Training Loss: 0.0009090015664696693
Test Loss:  0.0005847084103152156
Valid Loss:  0.0010061925277113914
Epoch:  201  	Training Loss: 0.0009059104486368597
Test Loss:  0.0005824352847412229
Valid Loss:  0.0010033039143308997
Epoch:  202  	Training Loss: 0.0009028363856486976
Test Loss:  0.0005803919630125165
Valid Loss:  0.0009989977115765214
Epoch:  203  	Training Loss: 0.0009020328288897872
Test Loss:  0.0005788190755993128
Valid Loss:  0.0009959719609469175
Epoch:  204  	Training Loss: 0.0009013727540150285
Test Loss:  0.0005773875745944679
Valid Loss:  0.0009930114028975368
Epoch:  205  	Training Loss: 0.0009008116903714836
Test Loss:  0.0005761184729635715
Valid Loss:  0.0009903728496283293
Epoch:  206  	Training Loss: 0.0009003357845358551
Test Loss:   41%|████▏     | 207/500 [02:30<02:13,  2.20it/s] 42%|████▏     | 209/500 [02:31<01:39,  2.92it/s] 42%|████▏     | 211/500 [02:37<05:44,  1.19s/it] 43%|████▎     | 213/500 [02:37<04:05,  1.17it/s] 43%|████▎     | 215/500 [02:37<02:56,  1.61it/s] 43%|████▎     | 217/500 [02:37<02:08,  2.20it/s] 44%|████▍     | 219/500 [02:37<01:34,  2.97it/s] 44%|████▍     | 221/500 [02:44<05:29,  1.18s/it] 45%|████▍     | 223/500 [02:44<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:44<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:44<02:02,  2.22it/s] 46%|████▌     | 229/500 [02:44<01:31,  2.98it/s] 46%|████▌     | 231/500 [02:51<05:18,  1.18s/it] 47%|████▋     | 233/500 [02:51<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:51<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:51<01:58,  2.22it/s] 48%|████▊     | 239/500 [02:51<01:27,  2.98it/s] 48%|████▊     | 241/500 [02:58<05:08,  1.19s/it] 49%|████▊     | 243/500 [02:58<03:40,  1.17it/s] 49%|████▉     | 245/500 [02:58<02:37,  1.61it/s] 49%|████▉     | 247/500 [02:58<01:54,  2.20it/s] 50%|████▉     | 249/500 [02:58<01:24,  2.96it/s] 50%|█████     | 251/500 [03:05<04:59,  1.20s/it] 51%|█████     | 253/500 [03:05<03:33,  1.16it/s] 51%|█████     | 255/500 [03:05<02:33,  1.60it/s] 51%|█████▏    | 257/500 [03:05<01:51,  2.18it/s] 52%|█████▏    | 259/500 [03:05<01:21,  2.94it/s] 52%|█████▏    | 261/500 [03:11<04:40,  1.17s/it] 53%|█████▎    | 263/500 [03:11<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:12<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:12<01:44,  2.24it/s] 54%|█████▍    | 269/500 [03:12<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:18<04:33,  1.20s/it] 55%|█████▍    | 273/500 [03:18<03:14,  1.16it/s]0.0005749332485720515
Valid Loss:  0.0009879085700958967
Epoch:  207  	Training Loss: 0.0008999289711937308
Test Loss:  0.0005739133921451867
Valid Loss:  0.0009857355616986752
Epoch:  208  	Training Loss: 0.0008995822281576693
Test Loss:  0.0005729839904233813
Valid Loss:  0.000983722973614931
Epoch:  209  	Training Loss: 0.0008992876973934472
Test Loss:  0.000572161516174674
Valid Loss:  0.0009819144615903497
Epoch:  210  	Training Loss: 0.0008990351343527436
Test Loss:  0.0005714119179174304
Valid Loss:  0.0009802441345527768
Epoch:  211  	Training Loss: 0.0008988211629912257
Test Loss:  0.0005707468371838331
Valid Loss:  0.00097873923368752
Epoch:  212  	Training Loss: 0.0008986378088593483
Test Loss:  0.0005722330533899367
Valid Loss:  0.0009819476399570704
Epoch:  213  	Training Loss: 0.0008952239877544343
Test Loss:  0.0005702001508325338
Valid Loss:  0.0009785142028704286
Epoch:  214  	Training Loss: 0.0008926371810957789
Test Loss:  0.0005704322829842567
Valid Loss:  0.000978629570454359
Epoch:  215  	Training Loss: 0.0008904077694751322
Test Loss:  0.0005694972933270037
Valid Loss:  0.000976617680862546
Epoch:  216  	Training Loss: 0.0008884246926754713
Test Loss:  0.0005693173152394593
Valid Loss:  0.0009757517254911363
Epoch:  217  	Training Loss: 0.0008865628624334931
Test Loss:  0.0005689231911674142
Valid Loss:  0.0009740649256855249
Epoch:  218  	Training Loss: 0.0008849835721775889
Test Loss:  0.0005683990311808884
Valid Loss:  0.0009723061230033636
Epoch:  219  	Training Loss: 0.0008835463668219745
Test Loss:  0.0005680110771209002
Valid Loss:  0.0009708974394015968
Epoch:  220  	Training Loss: 0.0008821453666314483
Test Loss:  0.0005675272550433874
Valid Loss:  0.0009693332831375301
Epoch:  221  	Training Loss: 0.0008807826088741422
Test Loss:  0.0005671318504028022
Valid Loss:  0.0009678190108388662
Epoch:  222  	Training Loss: 0.0008794857421889901
Test Loss:  0.0005603070603683591
Valid Loss:  0.0009610803099349141
Epoch:  223  	Training Loss: 0.0008725473890081048
Test Loss:  0.0005539783742278814
Valid Loss:  0.0009546233923174441
Epoch:  224  	Training Loss: 0.0008665495552122593
Test Loss:  0.0005482182605192065
Valid Loss:  0.0009484529728069901
Epoch:  225  	Training Loss: 0.0008611538214609027
Test Loss:  0.000543072703294456
Valid Loss:  0.0009424989111721516
Epoch:  226  	Training Loss: 0.0008562675211578608
Test Loss:  0.0005384660908021033
Valid Loss:  0.0009372146450914443
Epoch:  227  	Training Loss: 0.0008517538080923259
Test Loss:  0.0005346043617464602
Valid Loss:  0.0009325812570750713
Epoch:  228  	Training Loss: 0.0008476192015223205
Test Loss:  0.0005310934502631426
Valid Loss:  0.0009281327947974205
Epoch:  229  	Training Loss: 0.0008438201621174812
Test Loss:  0.0005277065793052316
Valid Loss:  0.0009238249622285366
Epoch:  230  	Training Loss: 0.0008403339306823909
Test Loss:  0.0005245971260592341
Valid Loss:  0.0009198440820910037
Epoch:  231  	Training Loss: 0.000837077503092587
Test Loss:  0.0005217257421463728
Valid Loss:  0.0009161555208265781
Epoch:  232  	Training Loss: 0.0008339486084878445
Test Loss:  0.0005201729945838451
Valid Loss:  0.0009140708134509623
Epoch:  233  	Training Loss: 0.0008307113312184811
Test Loss:  0.0005186673370189965
Valid Loss:  0.0009117075242102146
Epoch:  234  	Training Loss: 0.0008278905879706144
Test Loss:  0.0005172800738364458
Valid Loss:  0.0009094687411561608
Epoch:  235  	Training Loss: 0.0008252433035522699
Test Loss:  0.0005157252307981253
Valid Loss:  0.0009067103965207934
Epoch:  236  	Training Loss: 0.0008227850776165724
Test Loss:  0.0005142688751220703
Valid Loss:  0.0009041964076459408
Epoch:  237  	Training Loss: 0.0008203824982047081
Test Loss:  0.0005127093172632158
Valid Loss:  0.0009014267707243562
Epoch:  238  	Training Loss: 0.0008180111763067544
Test Loss:  0.0005111743230372667
Valid Loss:  0.0008987178443931043
Epoch:  239  	Training Loss: 0.0008156992844305933
Test Loss:  0.0005095278611406684
Valid Loss:  0.0008958721882663667
Epoch:  240  	Training Loss: 0.0008134188828989863
Test Loss:  0.0005079310503788292
Valid Loss:  0.0008931608754210174
Epoch:  241  	Training Loss: 0.0008111489587463439
Test Loss:  0.0005063131684437394
Valid Loss:  0.0008903976995497942
Epoch:  242  	Training Loss: 0.0008088897448033094
Test Loss:  0.0005056003574281931
Valid Loss:  0.0008887042058631778
Epoch:  243  	Training Loss: 0.0008078229147940874
Test Loss:  0.0005047537852078676
Valid Loss:  0.0008866162970662117
Epoch:  244  	Training Loss: 0.0008067822200246155
Test Loss:  0.000503993418533355
Valid Loss:  0.0008847232675179839
Epoch:  245  	Training Loss: 0.0008057588129304349
Test Loss:  0.0005032553453929722
Valid Loss:  0.0008828667923808098
Epoch:  246  	Training Loss: 0.0008047528681345284
Test Loss:  0.00050262053264305
Valid Loss:  0.0008809875580482185
Epoch:  247  	Training Loss: 0.0008038999512791634
Test Loss:  0.0005021457327529788
Valid Loss:  0.000879199244081974
Epoch:  248  	Training Loss: 0.0008032307378016412
Test Loss:  0.0005019038217142224
Valid Loss:  0.0008782739168964326
Epoch:  249  	Training Loss: 0.0008023936534300447
Test Loss:  0.0005011666798964143
Valid Loss:  0.000876142643392086
Epoch:  250  	Training Loss: 0.0008016297942958772
Test Loss:  0.0005006438586860895
Valid Loss:  0.0008744607912376523
Epoch:  251  	Training Loss: 0.0008008840959519148
Test Loss:  0.000500126276165247
Valid Loss:  0.0008727762033231556
Epoch:  252  	Training Loss: 0.0008001511450856924
Test Loss:  0.0004960242658853531
Valid Loss:  0.0008680189494043589
Epoch:  253  	Training Loss: 0.0007959713693708181
Test Loss:  0.0004926926922053099
Valid Loss:  0.0008644773624837399
Epoch:  254  	Training Loss: 0.0007918458431959152
Test Loss:  0.0004890463314950466
Valid Loss:  0.0008603162132203579
Epoch:  255  	Training Loss: 0.0007877631578594446
Test Loss:  0.00048578844871371984
Valid Loss:  0.0008567770710214972
Epoch:  256  	Training Loss: 0.0007837247103452682
Test Loss:  0.0004824278876185417
Valid Loss:  0.0008530258201062679
Epoch:  257  	Training Loss: 0.0007797587313689291
Test Loss:  0.00047936555347405374
Valid Loss:  0.0008496587979607284
Epoch:  258  	Training Loss: 0.0007758805295452476
Test Loss:  0.00047631963388994336
Valid Loss:  0.0008461823454126716
Epoch:  259  	Training Loss: 0.0007720412686467171
Test Loss:  0.0004733686218969524
Valid Loss:  0.0008428267319686711
Epoch:  260  	Training Loss: 0.0007682314608246088
Test Loss:  0.00047039982746355236
Valid Loss:  0.0008394090691581368
Epoch:  261  	Training Loss: 0.0007644589059054852
Test Loss:  0.0004675181407947093
Valid Loss:  0.0008361006621271372
Epoch:  262  	Training Loss: 0.0007607336156070232
Test Loss:  0.0004660944687202573
Valid Loss:  0.0008338094921782613
Epoch:  263  	Training Loss: 0.0007589879678562284
Test Loss:  0.00046474667033180594
Valid Loss:  0.0008315985323861241
Epoch:  264  	Training Loss: 0.0007572674658149481
Test Loss:  0.00046364424633793533
Valid Loss:  0.0008295108564198017
Epoch:  265  	Training Loss: 0.0007557030185125768
Test Loss:  0.0004625642905011773
Valid Loss:  0.0008274393621832132
Epoch:  266  	Training Loss: 0.0007541468366980553
Test Loss:  0.00046151780406944454
Valid Loss:  0.0008254055865108967
Epoch:  267  	Training Loss: 0.0007526191766373813
Test Loss:  0.0004605748108588159
Valid Loss:  0.0008234260603785515
Epoch:  268  	Training Loss: 0.0007511278381571174
Test Loss:  0.00045967570622451603
Valid Loss:  0.0008214447880163789
Epoch:  269  	Training Loss: 0.0007496883627027273
Test Loss:  0.00045883283019065857
Valid Loss:  0.0008195939008146524
Epoch:  270  	Training Loss: 0.0007482921937480569
Test Loss:  0.00045796812628395855
Valid Loss:  0.0008176807314157486
Epoch:  271  	Training Loss: 0.0007469682022929192
Test Loss:  0.00045715278247371316
Valid Loss:  0.0008158644195646048
Epoch:  272  	Training Loss: 0.0007456644088961184
Test Loss:  0.0004578764201141894
Valid Loss:  0.0008171687368303537
Epoch:  273  	Training Loss: 0.0007425830699503422
Test Loss:  0.00045579345896840096
Valid Loss:  0.0008138807606883347
Epoch:  274  	Training Loss: 0.0007399069145321846
Test Loss:  0.0004551179299596697
Valid Loss:  55%|█████▌    | 275/500 [03:19<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:19<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:19<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:25<04:19,  1.19s/it] 57%|█████▋    | 283/500 [03:25<03:04,  1.17it/s] 57%|█████▋    | 285/500 [03:25<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:26<01:36,  2.22it/s] 58%|█████▊    | 289/500 [03:26<01:10,  2.98it/s] 58%|█████▊    | 291/500 [03:32<04:07,  1.18s/it] 59%|█████▊    | 293/500 [03:32<02:56,  1.18it/s] 59%|█████▉    | 295/500 [03:32<02:06,  1.63it/s] 59%|█████▉    | 297/500 [03:32<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:33<01:07,  2.99it/s] 60%|██████    | 301/500 [03:39<03:57,  1.19s/it] 61%|██████    | 303/500 [03:39<02:48,  1.17it/s] 61%|██████    | 305/500 [03:39<02:00,  1.61it/s] 61%|██████▏   | 307/500 [03:39<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:40<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:46<03:46,  1.20s/it] 63%|██████▎   | 313/500 [03:46<02:40,  1.16it/s] 63%|██████▎   | 315/500 [03:46<01:55,  1.61it/s] 63%|██████▎   | 317/500 [03:46<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:46<01:01,  2.95it/s] 64%|██████▍   | 321/500 [03:53<03:30,  1.17s/it] 65%|██████▍   | 323/500 [03:53<02:29,  1.19it/s] 65%|██████▌   | 325/500 [03:53<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:53<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:53<00:56,  3.00it/s] 66%|██████▌   | 331/500 [04:00<03:19,  1.18s/it] 67%|██████▋   | 333/500 [04:00<02:21,  1.18it/s] 67%|██████▋   | 335/500 [04:00<01:41,  1.63it/s] 67%|██████▋   | 337/500 [04:00<01:13,  2.22it/s] 68%|██████▊   | 339/500 [04:00<00:53,  2.99it/s] 68%|██████▊   | 341/500 [04:07<03:09,  1.19s/it] 0.0008126202737912536
Epoch:  275  	Training Loss: 0.0007373730186372995
Test Loss:  0.000453561166068539
Valid Loss:  0.0008099631522782147
Epoch:  276  	Training Loss: 0.0007349586812779307
Test Loss:  0.0004523738462012261
Valid Loss:  0.0008078846731223166
Epoch:  277  	Training Loss: 0.0007325836922973394
Test Loss:  0.0004508464189711958
Valid Loss:  0.0008053143974393606
Epoch:  278  	Training Loss: 0.0007302461890503764
Test Loss:  0.00044947484275326133
Valid Loss:  0.0008029536693356931
Epoch:  279  	Training Loss: 0.0007279464625753462
Test Loss:  0.0004480251809582114
Valid Loss:  0.0008004680275917053
Epoch:  280  	Training Loss: 0.0007256799144670367
Test Loss:  0.00044649504707194865
Valid Loss:  0.000797922199126333
Epoch:  281  	Training Loss: 0.0007234415970742702
Test Loss:  0.0004450171545613557
Valid Loss:  0.0007954469183459878
Epoch:  282  	Training Loss: 0.0007212272612378001
Test Loss:  0.0004438867617864162
Valid Loss:  0.0007926071411930025
Epoch:  283  	Training Loss: 0.0007205032743513584
Test Loss:  0.0004435516311787069
Valid Loss:  0.0007910680724307895
Epoch:  284  	Training Loss: 0.000719841627869755
Test Loss:  0.0004428414104040712
Valid Loss:  0.0007889661937952042
Epoch:  285  	Training Loss: 0.0007192139164544642
Test Loss:  0.0004424733342602849
Valid Loss:  0.0007874066359363496
Epoch:  286  	Training Loss: 0.0007186017464846373
Test Loss:  0.00044201771379448473
Valid Loss:  0.0007857234450057149
Epoch:  287  	Training Loss: 0.0007180065149441361
Test Loss:  0.0004417108721099794
Valid Loss:  0.0007842683698982
Epoch:  288  	Training Loss: 0.0007174313650466502
Test Loss:  0.00044132929178886116
Valid Loss:  0.0007827202789485455
Epoch:  289  	Training Loss: 0.0007168917218223214
Test Loss:  0.0004411045229062438
Valid Loss:  0.0007813877891749144
Epoch:  290  	Training Loss: 0.0007163785048760474
Test Loss:  0.0004408360691741109
Valid Loss:  0.0007800167659297585
Epoch:  291  	Training Loss: 0.0007158889784477651
Test Loss:  0.0004405616200529039
Valid Loss:  0.0007786686182953417
Epoch:  292  	Training Loss: 0.0007154217455536127
Test Loss:  0.0004401254700496793
Valid Loss:  0.0007774967234581709
Epoch:  293  	Training Loss: 0.0007139642257243395
Test Loss:  0.0004389354435261339
Valid Loss:  0.0007753450772725046
Epoch:  294  	Training Loss: 0.000712632667273283
Test Loss:  0.00043805077439174056
Valid Loss:  0.0007736435509286821
Epoch:  295  	Training Loss: 0.0007114093750715256
Test Loss:  0.0004373000410851091
Valid Loss:  0.000771936378441751
Epoch:  296  	Training Loss: 0.000710258143953979
Test Loss:  0.0004365562053862959
Valid Loss:  0.0007702211150899529
Epoch:  297  	Training Loss: 0.0007091725710779428
Test Loss:  0.00043600471690297127
Valid Loss:  0.0007685342570766807
Epoch:  298  	Training Loss: 0.0007082264637574553
Test Loss:  0.00043534947326406837
Valid Loss:  0.0007666780147701502
Epoch:  299  	Training Loss: 0.0007073826855048537
Test Loss:  0.0004349231021478772
Valid Loss:  0.0007651344640180469
Epoch:  300  	Training Loss: 0.0007065802346915007
Test Loss:  0.00043448436190374196
Valid Loss:  0.0007635752554051578
Epoch:  301  	Training Loss: 0.0007058306946419179
Test Loss:  0.0004340835730545223
Valid Loss:  0.0007620920659974217
Epoch:  302  	Training Loss: 0.0007051236461848021
Test Loss:  0.0004337095015216619
Valid Loss:  0.000761020346544683
Epoch:  303  	Training Loss: 0.0007047739927656949
Test Loss:  0.00043340108823031187
Valid Loss:  0.0007600574754178524
Epoch:  304  	Training Loss: 0.0007044303347356617
Test Loss:  0.0004331275122240186
Valid Loss:  0.0007591627072542906
Epoch:  305  	Training Loss: 0.0007040912751108408
Test Loss:  0.0004328798677306622
Valid Loss:  0.0007583213737234473
Epoch:  306  	Training Loss: 0.0007037560571916401
Test Loss:  0.00043265288695693016
Valid Loss:  0.0007575268973596394
Epoch:  307  	Training Loss: 0.000703423167578876
Test Loss:  0.0004324432520661503
Valid Loss:  0.0007567682769149542
Epoch:  308  	Training Loss: 0.0007030930719338357
Test Loss:  0.00043224781984463334
Valid Loss:  0.0007560438825748861
Epoch:  309  	Training Loss: 0.0007027651881799102
Test Loss:  0.0004320638836361468
Valid Loss:  0.0007553457980975509
Epoch:  310  	Training Loss: 0.0007024399237707257
Test Loss:  0.00043189022107981145
Valid Loss:  0.00075466965790838
Epoch:  311  	Training Loss: 0.0007021151832304895
Test Loss:  0.0004317230195738375
Valid Loss:  0.0007540117367170751
Epoch:  312  	Training Loss: 0.0007017931202426553
Test Loss:  0.0004277457483112812
Valid Loss:  0.0007500853971578181
Epoch:  313  	Training Loss: 0.0006975266733206809
Test Loss:  0.00042465608566999435
Valid Loss:  0.0007477961480617523
Epoch:  314  	Training Loss: 0.0006936760619282722
Test Loss:  0.000421402306528762
Valid Loss:  0.000744604563806206
Epoch:  315  	Training Loss: 0.0006901624728925526
Test Loss:  0.000418592884670943
Valid Loss:  0.0007421561749652028
Epoch:  316  	Training Loss: 0.0006868659984320402
Test Loss:  0.0004157517687417567
Valid Loss:  0.0007395861903205514
Epoch:  317  	Training Loss: 0.0006837637629359961
Test Loss:  0.00041329668601974845
Valid Loss:  0.0007373372209258378
Epoch:  318  	Training Loss: 0.0006808509351685643
Test Loss:  0.000410924811149016
Valid Loss:  0.0007349323714151978
Epoch:  319  	Training Loss: 0.0006781405536457896
Test Loss:  0.0004087032575625926
Valid Loss:  0.0007327358471229672
Epoch:  320  	Training Loss: 0.0006755795329809189
Test Loss:  0.00040650408482179046
Valid Loss:  0.0007305459002964199
Epoch:  321  	Training Loss: 0.0006730641471222043
Test Loss:  0.0004043683875352144
Valid Loss:  0.0007285246392711997
Epoch:  322  	Training Loss: 0.0006705850828438997
Test Loss:  0.00040170649299398065
Valid Loss:  0.0007246541790664196
Epoch:  323  	Training Loss: 0.0006675474578514695
Test Loss:  0.000402080244384706
Valid Loss:  0.0007271446520462632
Epoch:  324  	Training Loss: 0.0006649489514529705
Test Loss:  0.0003981706977356225
Valid Loss:  0.0007212721975520253
Epoch:  325  	Training Loss: 0.0006623975932598114
Test Loss:  0.0003983152855653316
Valid Loss:  0.0007230476476252079
Epoch:  326  	Training Loss: 0.0006599546759389341
Test Loss:  0.00039473638753406703
Valid Loss:  0.0007176439394243062
Epoch:  327  	Training Loss: 0.0006575746810995042
Test Loss:  0.0003946335054934025
Valid Loss:  0.0007188993040472269
Epoch:  328  	Training Loss: 0.0006552627310156822
Test Loss:  0.00039141433080658317
Valid Loss:  0.0007140205707401037
Epoch:  329  	Training Loss: 0.0006529843085445464
Test Loss:  0.0003911477397195995
Valid Loss:  0.0007147729629650712
Epoch:  330  	Training Loss: 0.0006507368525490165
Test Loss:  0.00038822629721835256
Valid Loss:  0.0007103849202394485
Epoch:  331  	Training Loss: 0.000648517394438386
Test Loss:  0.00038785580545663834
Valid Loss:  0.0007108324207365513
Epoch:  332  	Training Loss: 0.0006463141180574894
Test Loss:  0.0003870274522341788
Valid Loss:  0.0007088972488418221
Epoch:  333  	Training Loss: 0.0006451669614762068
Test Loss:  0.0003870711661875248
Valid Loss:  0.0007084333337843418
Epoch:  334  	Training Loss: 0.0006440958823077381
Test Loss:  0.00038641400169581175
Valid Loss:  0.0007069042767398059
Epoch:  335  	Training Loss: 0.0006430991343222558
Test Loss:  0.0003862217126879841
Valid Loss:  0.0007061354117468
Epoch:  336  	Training Loss: 0.0006421328289434314
Test Loss:  0.00038572592893615365
Valid Loss:  0.0007048681727610528
Epoch:  337  	Training Loss: 0.000641179271042347
Test Loss:  0.0003854253445751965
Valid Loss:  0.0007039071060717106
Epoch:  338  	Training Loss: 0.0006402432336471975
Test Loss:  0.00038492633029818535
Valid Loss:  0.0007026383536867797
Epoch:  339  	Training Loss: 0.0006393295479938388
Test Loss:  0.0003845588071271777
Valid Loss:  0.0007015856681391597
Epoch:  340  	Training Loss: 0.0006384446169249713
Test Loss:  0.000384138198569417
Valid Loss:  0.000700446660630405
Epoch:  341  	Training Loss: 0.0006375873927026987
Test Loss:  0.00038377835880964994
Valid Loss:  0.000699392578098923
Epoch:  342  	Training Loss: 0.0006367617752403021
Test Loss:  0.0003814312512986362
Valid Loss:  0.0006967710214667022
 69%|██████▊   | 343/500 [04:07<02:14,  1.17it/s] 69%|██████▉   | 345/500 [04:07<01:36,  1.61it/s] 69%|██████▉   | 347/500 [04:07<01:09,  2.20it/s] 70%|██████▉   | 349/500 [04:07<00:51,  2.95it/s] 70%|███████   | 351/500 [04:13<02:54,  1.17s/it] 71%|███████   | 353/500 [04:13<02:03,  1.19it/s] 71%|███████   | 355/500 [04:14<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:14<01:04,  2.23it/s] 72%|███████▏  | 359/500 [04:14<00:47,  3.00it/s] 72%|███████▏  | 361/500 [04:20<02:46,  1.19s/it] 73%|███████▎  | 363/500 [04:20<01:57,  1.17it/s] 73%|███████▎  | 365/500 [04:21<01:23,  1.61it/s] 73%|███████▎  | 367/500 [04:21<01:00,  2.20it/s] 74%|███████▍  | 369/500 [04:21<00:44,  2.95it/s] 74%|███████▍  | 371/500 [04:27<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:27<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:28<01:18,  1.59it/s] 75%|███████▌  | 377/500 [04:28<00:56,  2.17it/s] 76%|███████▌  | 379/500 [04:28<00:41,  2.90it/s] 76%|███████▌  | 381/500 [04:34<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:34<01:40,  1.17it/s] 77%|███████▋  | 385/500 [04:34<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:35<00:51,  2.20it/s] 78%|███████▊  | 389/500 [04:35<00:37,  2.95it/s] 78%|███████▊  | 391/500 [04:41<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:41<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:41<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:41<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:42<00:33,  2.98it/s] 80%|████████  | 401/500 [04:48<01:56,  1.18s/it] 81%|████████  | 403/500 [04:48<01:22,  1.18it/s] 81%|████████  | 405/500 [04:48<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:48<00:42,  2.21it/s] 82%|████████▏ | 409/500 [04:49<00:30,  2.94it/s]Epoch:  343  	Training Loss: 0.000633691786788404
Test Loss:  0.0003793718060478568
Valid Loss:  0.000694402726367116
Epoch:  344  	Training Loss: 0.0006309907184913754
Test Loss:  0.0003773594507947564
Valid Loss:  0.0006920698215253651
Epoch:  345  	Training Loss: 0.0006284661358222365
Test Loss:  0.0003753842320293188
Valid Loss:  0.0006897719576954842
Epoch:  346  	Training Loss: 0.0006260518566705287
Test Loss:  0.0003734773490577936
Valid Loss:  0.0006874917889945209
Epoch:  347  	Training Loss: 0.0006238238420337439
Test Loss:  0.0003716644423548132
Valid Loss:  0.0006853311788290739
Epoch:  348  	Training Loss: 0.0006216620095074177
Test Loss:  0.0003698649234138429
Valid Loss:  0.0006831681821495295
Epoch:  349  	Training Loss: 0.0006195283494889736
Test Loss:  0.0003681406087707728
Valid Loss:  0.0006809788756072521
Epoch:  350  	Training Loss: 0.000617500685621053
Test Loss:  0.0003665407421067357
Valid Loss:  0.0006788793252781034
Epoch:  351  	Training Loss: 0.0006155477021820843
Test Loss:  0.00036493971128948033
Valid Loss:  0.0006767850136384368
Epoch:  352  	Training Loss: 0.0006136293523013592
Test Loss:  0.00036360888043418527
Valid Loss:  0.0006747790612280369
Epoch:  353  	Training Loss: 0.0006124878418631852
Test Loss:  0.00036254164297133684
Valid Loss:  0.0006731897592544556
Epoch:  354  	Training Loss: 0.0006114725256338716
Test Loss:  0.0003614964080043137
Valid Loss:  0.0006717183860018849
Epoch:  355  	Training Loss: 0.0006104893982410431
Test Loss:  0.00036052786163054407
Valid Loss:  0.000670380424708128
Epoch:  356  	Training Loss: 0.0006095395656302571
Test Loss:  0.0003595856251195073
Valid Loss:  0.0006691120215691626
Epoch:  357  	Training Loss: 0.000608604634180665
Test Loss:  0.0003587526734918356
Valid Loss:  0.0006679970538243651
Epoch:  358  	Training Loss: 0.000607722788117826
Test Loss:  0.0003579802578315139
Valid Loss:  0.000667195301502943
Epoch:  359  	Training Loss: 0.0006068432703614235
Test Loss:  0.0003572351997718215
Valid Loss:  0.0006661849329248071
Epoch:  360  	Training Loss: 0.0006059589795768261
Test Loss:  0.0003564789949450642
Valid Loss:  0.0006651880103163421
Epoch:  361  	Training Loss: 0.0006050808588042855
Test Loss:  0.0003557237214408815
Valid Loss:  0.0006642109947279096
Epoch:  362  	Training Loss: 0.000604206055868417
Test Loss:  0.0003505068307276815
Valid Loss:  0.0006587296375073493
Epoch:  363  	Training Loss: 0.0005992500809952617
Test Loss:  0.0003471088712103665
Valid Loss:  0.0006564451032318175
Epoch:  364  	Training Loss: 0.0005945551092736423
Test Loss:  0.00034285325091332197
Valid Loss:  0.0006522042094729841
Epoch:  365  	Training Loss: 0.0005900614778511226
Test Loss:  0.0003393431252334267
Valid Loss:  0.0006491428939625621
Epoch:  366  	Training Loss: 0.0005857431679032743
Test Loss:  0.0003356363740749657
Valid Loss:  0.0006456696428358555
Epoch:  367  	Training Loss: 0.0005815549520775676
Test Loss:  0.00033247211831621826
Valid Loss:  0.0006428493070416152
Epoch:  368  	Training Loss: 0.0005774763412773609
Test Loss:  0.00032896341872401536
Valid Loss:  0.0006391594070009887
Epoch:  369  	Training Loss: 0.0005735073937103152
Test Loss:  0.00032612780341878533
Valid Loss:  0.0006366022862493992
Epoch:  370  	Training Loss: 0.0005697544547729194
Test Loss:  0.0003231340670026839
Valid Loss:  0.000633467745501548
Epoch:  371  	Training Loss: 0.0005660403403453529
Test Loss:  0.00032025628024712205
Valid Loss:  0.0006303707486949861
Epoch:  372  	Training Loss: 0.000562431407161057
Test Loss:  0.00031906302319839597
Valid Loss:  0.0006291593890637159
Epoch:  373  	Training Loss: 0.0005611456581391394
Test Loss:  0.00031809622305445373
Valid Loss:  0.0006278167711570859
Epoch:  374  	Training Loss: 0.0005601684679277241
Test Loss:  0.00031725410372018814
Valid Loss:  0.0006265427800826728
Epoch:  375  	Training Loss: 0.0005593443056568503
Test Loss:  0.000316469871904701
Valid Loss:  0.0006253517349250615
Epoch:  376  	Training Loss: 0.000558595173060894
Test Loss:  0.00031576762557961047
Valid Loss:  0.000624282518401742
Epoch:  377  	Training Loss: 0.0005578802665695548
Test Loss:  0.0003151396522298455
Valid Loss:  0.0006232509040273726
Epoch:  378  	Training Loss: 0.0005572402151301503
Test Loss:  0.0003145855152979493
Valid Loss:  0.0006223192904144526
Epoch:  379  	Training Loss: 0.0005566595937125385
Test Loss:  0.0003140712797176093
Valid Loss:  0.0006214338354766369
Epoch:  380  	Training Loss: 0.0005560992867685854
Test Loss:  0.0003135839360766113
Valid Loss:  0.0006205709651112556
Epoch:  381  	Training Loss: 0.0005555691896006465
Test Loss:  0.0003131345147266984
Valid Loss:  0.0006197566981427372
Epoch:  382  	Training Loss: 0.0005550694186240435
Test Loss:  0.0003129391116090119
Valid Loss:  0.0006204924429766834
Epoch:  383  	Training Loss: 0.0005529180052690208
Test Loss:  0.00031227903673425317
Valid Loss:  0.0006198404007591307
Epoch:  384  	Training Loss: 0.0005513008800335228
Test Loss:  0.000311581592541188
Valid Loss:  0.0006190040148794651
Epoch:  385  	Training Loss: 0.000549917109310627
Test Loss:  0.00031088211107999086
Valid Loss:  0.000617902260273695
Epoch:  386  	Training Loss: 0.0005487099406309426
Test Loss:  0.00031026999931782484
Valid Loss:  0.000616674602497369
Epoch:  387  	Training Loss: 0.0005475763464346528
Test Loss:  0.00030963923200033605
Valid Loss:  0.0006153315771371126
Epoch:  388  	Training Loss: 0.0005465520080178976
Test Loss:  0.0003090527025051415
Valid Loss:  0.000614113116171211
Epoch:  389  	Training Loss: 0.0005455822683870792
Test Loss:  0.00030843386775813997
Valid Loss:  0.000612750998698175
Epoch:  390  	Training Loss: 0.0005446411669254303
Test Loss:  0.00030785781564190984
Valid Loss:  0.0006116902804933488
Epoch:  391  	Training Loss: 0.0005437459331005812
Test Loss:  0.0003072909894399345
Valid Loss:  0.0006103923660703003
Epoch:  392  	Training Loss: 0.0005428395816124976
Test Loss:  0.0003064335905946791
Valid Loss:  0.0006085316999815404
Epoch:  393  	Training Loss: 0.0005420935340225697
Test Loss:  0.0003062398172914982
Valid Loss:  0.0006080518942326307
Epoch:  394  	Training Loss: 0.0005415124469436705
Test Loss:  0.00030596519354730844
Valid Loss:  0.0006072559044696391
Epoch:  395  	Training Loss: 0.0005409090081229806
Test Loss:  0.0003058084985241294
Valid Loss:  0.0006066291825845838
Epoch:  396  	Training Loss: 0.0005404191324487329
Test Loss:  0.00030555384000763297
Valid Loss:  0.0006057005957700312
Epoch:  397  	Training Loss: 0.0005399292567744851
Test Loss:  0.0003053785767406225
Valid Loss:  0.0006050236988812685
Epoch:  398  	Training Loss: 0.0005395081825554371
Test Loss:  0.00030522880842909217
Valid Loss:  0.0006042079767212272
Epoch:  399  	Training Loss: 0.0005390672013163567
Test Loss:  0.00030505593167617917
Valid Loss:  0.0006034901016391814
Epoch:  400  	Training Loss: 0.000538689608220011
Test Loss:  0.00030490278732031584
Valid Loss:  0.0006026878254488111
Epoch:  401  	Training Loss: 0.0005382929230108857
Test Loss:  0.0003047696372959763
Valid Loss:  0.0006020368309691548
Epoch:  402  	Training Loss: 0.0005379291833378375
Test Loss:  0.00030241385684348643
Valid Loss:  0.0005994444945827127
Epoch:  403  	Training Loss: 0.0005352448206394911
Test Loss:  0.0003000986762344837
Valid Loss:  0.0005968456389382482
Epoch:  404  	Training Loss: 0.0005326982354745269
Test Loss:  0.00029796562739647925
Valid Loss:  0.000594395212829113
Epoch:  405  	Training Loss: 0.0005302672507241368
Test Loss:  0.0002960378769785166
Valid Loss:  0.0005921154515817761
Epoch:  406  	Training Loss: 0.0005279994802549481
Test Loss:  0.00029416035977192223
Valid Loss:  0.0005898962263017893
Epoch:  407  	Training Loss: 0.0005257995799183846
Test Loss:  0.0002923633437603712
Valid Loss:  0.0005877942312508821
Epoch:  408  	Training Loss: 0.0005236591678112745
Test Loss:  0.0002905994188040495
Valid Loss:  0.0005857286741957068
Epoch:  409  	Training Loss: 0.0005215932615101337
Test Loss:  0.00028890586690977216
Valid Loss:  0.0005836658529005945
Epoch:  410  	Training Loss: 0.000519650406204164
Test Loss:  0.00028730585472658277
Valid Loss:  0.0005816948832944036
 82%|████████▏ | 411/500 [04:55<01:45,  1.19s/it] 83%|████████▎ | 413/500 [04:55<01:14,  1.17it/s] 83%|████████▎ | 415/500 [04:55<00:52,  1.62it/s] 83%|████████▎ | 417/500 [04:55<00:37,  2.21it/s] 84%|████████▍ | 419/500 [04:55<00:27,  2.97it/s] 84%|████████▍ | 421/500 [05:02<01:34,  1.19s/it] 85%|████████▍ | 423/500 [05:02<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:02<00:46,  1.62it/s] 85%|████████▌ | 427/500 [05:02<00:33,  2.21it/s] 86%|████████▌ | 429/500 [05:02<00:24,  2.96it/s] 86%|████████▌ | 431/500 [05:09<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:09<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:09<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:09<00:28,  2.21it/s] 88%|████████▊ | 439/500 [05:09<00:20,  2.97it/s] 88%|████████▊ | 441/500 [05:16<01:10,  1.19s/it] 89%|████████▊ | 443/500 [05:16<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:16<00:34,  1.62it/s] 89%|████████▉ | 447/500 [05:16<00:24,  2.21it/s] 90%|████████▉ | 449/500 [05:16<00:17,  2.97it/s] 90%|█████████ | 451/500 [05:23<00:59,  1.21s/it] 91%|█████████ | 453/500 [05:23<00:40,  1.15it/s] 91%|█████████ | 455/500 [05:23<00:28,  1.60it/s] 91%|█████████▏| 457/500 [05:23<00:19,  2.18it/s] 92%|█████████▏| 459/500 [05:23<00:13,  2.94it/s] 92%|█████████▏| 461/500 [05:30<00:47,  1.22s/it] 93%|█████████▎| 463/500 [05:30<00:32,  1.14it/s] 93%|█████████▎| 465/500 [05:30<00:22,  1.58it/s] 93%|█████████▎| 467/500 [05:30<00:15,  2.16it/s] 94%|█████████▍| 469/500 [05:30<00:10,  2.91it/s] 94%|█████████▍| 471/500 [05:37<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:37<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:37<00:15,  1.61it/s] 95%|█████████▌| 477/500 [05:37<00:10,  2.20it/s]Epoch:  411  	Training Loss: 0.0005177774000912905
Test Loss:  0.0002857348008546978
Valid Loss:  0.000579775485675782
Epoch:  412  	Training Loss: 0.0005159751744940877
Test Loss:  0.00028499835752882063
Valid Loss:  0.0005788510898128152
Epoch:  413  	Training Loss: 0.0005142293521203101
Test Loss:  0.00028392759850248694
Valid Loss:  0.0005772822769358754
Epoch:  414  	Training Loss: 0.0005126164760440588
Test Loss:  0.0002829277655109763
Valid Loss:  0.0005757755716331303
Epoch:  415  	Training Loss: 0.0005110583151690662
Test Loss:  0.000281933113001287
Valid Loss:  0.0005742379580624402
Epoch:  416  	Training Loss: 0.0005095255328342319
Test Loss:  0.0002809677680488676
Valid Loss:  0.0005726666422560811
Epoch:  417  	Training Loss: 0.0005080290138721466
Test Loss:  0.00028001522878184915
Valid Loss:  0.0005710624391213059
Epoch:  418  	Training Loss: 0.0005065668374300003
Test Loss:  0.00027907034382224083
Valid Loss:  0.0005694606225006282
Epoch:  419  	Training Loss: 0.000505125499330461
Test Loss:  0.00027812569169327617
Valid Loss:  0.0005678596207872033
Epoch:  420  	Training Loss: 0.0005036980146542192
Test Loss:  0.00027719209901988506
Valid Loss:  0.0005662671755999327
Epoch:  421  	Training Loss: 0.0005022907862439752
Test Loss:  0.0002762617659755051
Valid Loss:  0.0005646659410558641
Epoch:  422  	Training Loss: 0.0005009071319364011
Test Loss:  0.000276519131148234
Valid Loss:  0.0005646629142574966
Epoch:  423  	Training Loss: 0.000500079826451838
Test Loss:  0.00027625737129710615
Valid Loss:  0.0005637963186018169
Epoch:  424  	Training Loss: 0.0004993424518033862
Test Loss:  0.0002761518117040396
Valid Loss:  0.0005629260558634996
Epoch:  425  	Training Loss: 0.0004986259154975414
Test Loss:  0.00027590844547376037
Valid Loss:  0.0005617904243990779
Epoch:  426  	Training Loss: 0.0004979816731065512
Test Loss:  0.00027573262923397124
Valid Loss:  0.0005609106738120317
Epoch:  427  	Training Loss: 0.000497336033731699
Test Loss:  0.00027556385612115264
Valid Loss:  0.0005598171264864504
Epoch:  428  	Training Loss: 0.0004966974374838173
Test Loss:  0.00027528416831046343
Valid Loss:  0.0005585587350651622
Epoch:  429  	Training Loss: 0.0004961022641509771
Test Loss:  0.0002750878338702023
Valid Loss:  0.0005575997638516128
Epoch:  430  	Training Loss: 0.0004955133772455156
Test Loss:  0.0002749391132965684
Valid Loss:  0.0005564347957260907
Epoch:  431  	Training Loss: 0.0004949551657773554
Test Loss:  0.00027464175946079195
Valid Loss:  0.0005550420028157532
Epoch:  432  	Training Loss: 0.0004944614483974874
Test Loss:  0.00027224107179790735
Valid Loss:  0.0005516081000678241
Epoch:  433  	Training Loss: 0.0004922241787426174
Test Loss:  0.00027098978171125054
Valid Loss:  0.0005503040738403797
Epoch:  434  	Training Loss: 0.0004900583880953491
Test Loss:  0.00026936165522783995
Valid Loss:  0.000548218609765172
Epoch:  435  	Training Loss: 0.00048791812150739133
Test Loss:  0.0002679081808310002
Valid Loss:  0.0005464685382321477
Epoch:  436  	Training Loss: 0.000485796423163265
Test Loss:  0.0002664139319676906
Valid Loss:  0.0005446275463327765
Epoch:  437  	Training Loss: 0.00048369180876761675
Test Loss:  0.0002649699745234102
Valid Loss:  0.0005428927252069116
Epoch:  438  	Training Loss: 0.0004816059081349522
Test Loss:  0.000263524882029742
Valid Loss:  0.000541130022611469
Epoch:  439  	Training Loss: 0.00047953694593161345
Test Loss:  0.0002621000458020717
Valid Loss:  0.0005393879255279899
Epoch:  440  	Training Loss: 0.00047748343786224723
Test Loss:  0.0002606861526146531
Valid Loss:  0.0005376474000513554
Epoch:  441  	Training Loss: 0.0004754530091304332
Test Loss:  0.00025929161347448826
Valid Loss:  0.0005359192728064954
Epoch:  442  	Training Loss: 0.00047344580525532365
Test Loss:  0.00025866678333841264
Valid Loss:  0.0005345502286218107
Epoch:  443  	Training Loss: 0.00047240726416930556
Test Loss:  0.00025800836738198996
Valid Loss:  0.0005330994608812034
Epoch:  444  	Training Loss: 0.00047140143578872085
Test Loss:  0.0002574196259956807
Valid Loss:  0.0005317835602909327
Epoch:  445  	Training Loss: 0.0004704330349341035
Test Loss:  0.0002568357449490577
Valid Loss:  0.0005304597434587777
Epoch:  446  	Training Loss: 0.0004694787203334272
Test Loss:  0.00025632348842918873
Valid Loss:  0.0005291842389851809
Epoch:  447  	Training Loss: 0.00046854856191203
Test Loss:  0.0002558221749495715
Valid Loss:  0.0005279298638924956
Epoch:  448  	Training Loss: 0.00046763435238972306
Test Loss:  0.0002553258091211319
Valid Loss:  0.0005266969092190266
Epoch:  449  	Training Loss: 0.0004667408356908709
Test Loss:  0.0002548544143792242
Valid Loss:  0.000525519484654069
Epoch:  450  	Training Loss: 0.00046586093958467245
Test Loss:  0.0002543855516705662
Valid Loss:  0.0005243446212261915
Epoch:  451  	Training Loss: 0.00046499710879288614
Test Loss:  0.0002539377601351589
Valid Loss:  0.0005232224357314408
Epoch:  452  	Training Loss: 0.0004641499253921211
Test Loss:  0.00025303461006842554
Valid Loss:  0.0005218160804361105
Epoch:  453  	Training Loss: 0.00046323915012180805
Test Loss:  0.00025216539506800473
Valid Loss:  0.0005204899935051799
Epoch:  454  	Training Loss: 0.0004623545682989061
Test Loss:  0.00025132979499176145
Valid Loss:  0.000519243476446718
Epoch:  455  	Training Loss: 0.00046149559784680605
Test Loss:  0.00025051936972886324
Valid Loss:  0.0005180534208193421
Epoch:  456  	Training Loss: 0.0004606663133017719
Test Loss:  0.00024974870029836893
Valid Loss:  0.0005169456708244979
Epoch:  457  	Training Loss: 0.00045986910117790103
Test Loss:  0.0002490149927325547
Valid Loss:  0.000515898922458291
Epoch:  458  	Training Loss: 0.0004590904572978616
Test Loss:  0.0002483227290213108
Valid Loss:  0.0005149127682670951
Epoch:  459  	Training Loss: 0.0004583397530950606
Test Loss:  0.00024764338741078973
Valid Loss:  0.0005139674758538604
Epoch:  460  	Training Loss: 0.0004576041828840971
Test Loss:  0.00024698313791304827
Valid Loss:  0.0005130679928697646
Epoch:  461  	Training Loss: 0.00045688258251175284
Test Loss:  0.0002463322598487139
Valid Loss:  0.000512191210873425
Epoch:  462  	Training Loss: 0.00045617506839334965
Test Loss:  0.0002458126691635698
Valid Loss:  0.0005116089596413076
Epoch:  463  	Training Loss: 0.00045528318150900304
Test Loss:  0.0002452238113619387
Valid Loss:  0.0005108647746965289
Epoch:  464  	Training Loss: 0.0004544149851426482
Test Loss:  0.00024464691523462534
Valid Loss:  0.0005101325805298984
Epoch:  465  	Training Loss: 0.00045355019392445683
Test Loss:  0.00024407097953371704
Valid Loss:  0.0005093906074762344
Epoch:  466  	Training Loss: 0.0004526894190348685
Test Loss:  0.0002434952330077067
Valid Loss:  0.0005086433957330883
Epoch:  467  	Training Loss: 0.00045184241025708616
Test Loss:  0.0002428960578981787
Valid Loss:  0.0005078418180346489
Epoch:  468  	Training Loss: 0.0004510314902290702
Test Loss:  0.00024231888528447598
Valid Loss:  0.0005070770857855678
Epoch:  469  	Training Loss: 0.00045022444101050496
Test Loss:  0.00024174452119041234
Valid Loss:  0.0005063122371211648
Epoch:  470  	Training Loss: 0.0004494281893130392
Test Loss:  0.0002411715395282954
Valid Loss:  0.0005055494839325547
Epoch:  471  	Training Loss: 0.0004486442485358566
Test Loss:  0.00024062953889369965
Valid Loss:  0.00050482212100178
Epoch:  472  	Training Loss: 0.00044788734521716833
Test Loss:  0.00024107639910653234
Valid Loss:  0.0005056254449300468
Epoch:  473  	Training Loss: 0.0004472852451726794
Test Loss:  0.00024125778872985393
Valid Loss:  0.00050589838065207
Epoch:  474  	Training Loss: 0.0004468347178772092
Test Loss:  0.00024130623205564916
Valid Loss:  0.0005059135146439075
Epoch:  475  	Training Loss: 0.0004464297089725733
Test Loss:  0.00024131813552230597
Valid Loss:  0.0005057974485680461
Epoch:  476  	Training Loss: 0.00044605578295886517
Test Loss:  0.00024128839140757918
Valid Loss:  0.0005055750370956957
Epoch:  477  	Training Loss: 0.00044571259059011936
Test Loss:  0.0002412297180853784
Valid Loss:  0.0005052863853052258
Epoch:  478  	Training Loss: 0.00044538872316479683
Test Loss:  0.00024117567227222025
Valid Loss:   96%|█████████▌| 479/500 [05:37<00:07,  2.96it/s] 96%|█████████▌| 481/500 [05:44<00:23,  1.21s/it] 97%|█████████▋| 483/500 [05:44<00:14,  1.15it/s] 97%|█████████▋| 485/500 [05:44<00:09,  1.59it/s] 97%|█████████▋| 487/500 [05:44<00:05,  2.17it/s] 98%|█████████▊| 489/500 [05:44<00:03,  2.93it/s] 98%|█████████▊| 491/500 [05:51<00:10,  1.20s/it] 99%|█████████▊| 493/500 [05:51<00:06,  1.16it/s] 99%|█████████▉| 495/500 [05:51<00:03,  1.61it/s] 99%|█████████▉| 497/500 [05:51<00:01,  2.19it/s]100%|█████████▉| 499/500 [05:51<00:00,  2.94it/s]100%|██████████| 500/500 [05:51<00:00,  1.42it/s]
0.000504988303873688
Epoch:  479  	Training Loss: 0.0004450730048120022
Test Loss:  0.00024112086975947022
Valid Loss:  0.0005046758451499045
Epoch:  480  	Training Loss: 0.00044476494076661766
Test Loss:  0.0002410628367215395
Valid Loss:  0.0005043450510129333
Epoch:  481  	Training Loss: 0.00044446325046010315
Test Loss:  0.00024099901202134788
Valid Loss:  0.0005039948737248778
Epoch:  482  	Training Loss: 0.00044416639138944447
Test Loss:  0.00023966276785358787
Valid Loss:  0.000501763541251421
Epoch:  483  	Training Loss: 0.00044333713594824076
Test Loss:  0.0002389613218838349
Valid Loss:  0.0005006790161132812
Epoch:  484  	Training Loss: 0.0004426657687872648
Test Loss:  0.00023834442254155874
Valid Loss:  0.0004997663199901581
Epoch:  485  	Training Loss: 0.0004420139011926949
Test Loss:  0.00023775469162501395
Valid Loss:  0.0004989081062376499
Epoch:  486  	Training Loss: 0.00044137786608189344
Test Loss:  0.00023717631120234728
Valid Loss:  0.000498078006785363
Epoch:  487  	Training Loss: 0.00044075719779357314
Test Loss:  0.0002366058324696496
Valid Loss:  0.0004972621100023389
Epoch:  488  	Training Loss: 0.0004401515470817685
Test Loss:  0.0002360545622650534
Valid Loss:  0.0004964825930073857
Epoch:  489  	Training Loss: 0.00043955849832855165
Test Loss:  0.0002355216711293906
Valid Loss:  0.0004957395722158253
Epoch:  490  	Training Loss: 0.00043897604336962104
Test Loss:  0.0002350036520510912
Valid Loss:  0.0004950249567627907
Epoch:  491  	Training Loss: 0.0004384043859317899
Test Loss:  0.00023449970467481762
Valid Loss:  0.0004943356616422534
Epoch:  492  	Training Loss: 0.0004378421581350267
Test Loss:  0.000233471451792866
Valid Loss:  0.0004936682526022196
Epoch:  493  	Training Loss: 0.0004357615252956748
Test Loss:  0.00023223727475851774
Valid Loss:  0.0004925902467221022
Epoch:  494  	Training Loss: 0.0004338122671470046
Test Loss:  0.00023093661002349108
Valid Loss:  0.0004913785960525274
Epoch:  495  	Training Loss: 0.00043191309669055045
Test Loss:  0.00022964044183027
Valid Loss:  0.0004901178181171417
Epoch:  496  	Training Loss: 0.00043005734914913774
Test Loss:  0.00022838640143163502
Valid Loss:  0.0004888414987362921
Epoch:  497  	Training Loss: 0.0004282563750166446
Test Loss:  0.00022717055981047451
Valid Loss:  0.00048755036550574005
Epoch:  498  	Training Loss: 0.0004264935851097107
Test Loss:  0.00022597494535148144
Valid Loss:  0.00048625189810991287
Epoch:  499  	Training Loss: 0.0004247730830684304
Test Loss:  0.00022481683117803186
Valid Loss:  0.00048494222573935986
Epoch:  500  	Training Loss: 0.0004230925696901977
Test Loss:  0.00022366357734426856
Valid Loss:  0.00048358182539232075
seed is  7
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.19it/s]  1%|          | 4/500 [00:00<00:30, 16.18it/s]  1%|          | 6/500 [00:00<00:30, 16.05it/s]  2%|▏         | 8/500 [00:00<00:30, 16.12it/s]  2%|▏         | 10/500 [00:00<00:32, 15.30it/s]  2%|▏         | 12/500 [00:00<00:32, 15.05it/s]  3%|▎         | 14/500 [00:00<00:31, 15.48it/s]  3%|▎         | 16/500 [00:01<00:31, 15.13it/s]  4%|▎         | 18/500 [00:01<00:34, 14.13it/s]  4%|▍         | 20/500 [00:01<00:35, 13.68it/s]  4%|▍         | 22/500 [00:01<00:33, 14.29it/s]  5%|▍         | 24/500 [00:01<00:33, 14.06it/s]  5%|▌         | 26/500 [00:01<00:34, 13.54it/s]  6%|▌         | 28/500 [00:01<00:33, 14.28it/s]  6%|▌         | 30/500 [00:02<00:31, 14.89it/s]  6%|▋         | 32/500 [00:02<00:30, 15.35it/s]  7%|▋         | 34/500 [00:02<00:29, 15.69it/s]  7%|▋         | 36/500 [00:02<00:28, 16.02it/s]  8%|▊         | 38/500 [00:02<00:28, 16.17it/s]  8%|▊         | 40/500 [00:02<00:28, 16.29it/s]  8%|▊         | 42/500 [00:02<00:27, 16.36it/s]  9%|▉         | 44/500 [00:02<00:27, 16.34it/s]  9%|▉         | 46/500 [00:02<00:27, 16.37it/s] 10%|▉         | 48/500 [00:03<00:29, 15.37it/s] 10%|█         | 50/500 [00:03<00:31, 14.29it/s] 10%|█         | 52/500 [00:03<00:31, 14.41it/s] 11%|█         | 54/500 [00:03<00:30, 14.86it/s] 11%|█         | 56/500 [00:03<00:29, 15.22it/s] 12%|█▏        | 58/500 [00:03<00:28, 15.41it/s] 12%|█▏        | 60/500 [00:03<00:28, 15.68it/s] 12%|█▏        | 62/500 [00:04<00:27, 15.71it/s] 13%|█▎        | 64/500 [00:04<00:27, 15.99it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.16it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.24it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.30it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.39it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.36it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.26it/s] 16%|█▌        | 78/500 [00:05<00:25, 16.32it/s] 16%|█▌        | 80/500 [00:05<00:25, 16.45it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.53it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.60it/s] 17%|█▋        | 86/500 [00:05<00:24, 16.58it/s] 18%|█▊        | 88/500 [00:05<00:24, 16.62it/s] 18%|█▊        | 90/500 [00:05<00:25, 15.95it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.02it/s] 19%|█▉        | 94/500 [00:06<00:25, 16.02it/s] 19%|█▉        | 96/500 [00:06<00:25, 16.04it/s] 20%|█▉        | 98/500 [00:06<00:26, 15.14it/s] 20%|██        | 100/500 [00:06<00:26, 14.92it/s] 20%|██        | 102/500 [00:06<00:25, 15.35it/s] 21%|██        | 104/500 [00:06<00:25, 15.70it/s] 21%|██        | 106/500 [00:06<00:24, 15.88it/s] 22%|██▏       | 108/500 [00:06<00:24, 15.83it/s] 22%|██▏       | 110/500 [00:07<00:24, 15.83it/s] 22%|██▏       | 112/500 [00:07<00:24, 15.73it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.90it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.01it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.06it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.21it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.19it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.23it/s]Epoch:  1  	Training Loss: 0.21847409009933472
Test Loss:  4700.88134765625
Valid Loss:  4706.1591796875
Epoch:  2  	Training Loss: 4664.6171875
Test Loss:  1.3888124643966976e+16
Valid Loss:  1.3891839790678016e+16
Epoch:  3  	Training Loss: 1.3946551231578112e+16
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:23, 16.08it/s] 26%|██▌       | 128/500 [00:08<00:23, 16.17it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.33it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.36it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.18it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.08it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.15it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.30it/s] 28%|██▊       | 142/500 [00:09<00:21, 16.30it/s] 29%|██▉       | 144/500 [00:09<00:21, 16.36it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.45it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.48it/s] 30%|███       | 150/500 [00:09<00:21, 16.38it/s] 30%|███       | 152/500 [00:09<00:21, 16.41it/s] 31%|███       | 154/500 [00:09<00:21, 16.42it/s] 31%|███       | 156/500 [00:09<00:20, 16.44it/s] 32%|███▏      | 158/500 [00:10<00:20, 16.34it/s] 32%|███▏      | 160/500 [00:10<00:20, 16.34it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.23it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.25it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.37it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.23it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.29it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.35it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.37it/s] 35%|███▌      | 176/500 [00:11<00:19, 16.44it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.48it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.42it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.31it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.34it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.38it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.30it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.35it/s] 38%|███▊      | 192/500 [00:12<00:18, 16.41it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.42it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.44it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.35it/s] 40%|████      | 200/500 [00:12<00:20, 14.64it/s] 40%|████      | 202/500 [00:12<00:21, 14.09it/s] 41%|████      | 204/500 [00:12<00:20, 14.72it/s] 41%|████      | 206/500 [00:13<00:19, 15.19it/s] 42%|████▏     | 208/500 [00:13<00:19, 15.36it/s] 42%|████▏     | 210/500 [00:13<00:18, 15.50it/s] 42%|████▏     | 212/500 [00:13<00:18, 15.64it/s] 43%|████▎     | 214/500 [00:13<00:18, 15.82it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.03it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.14it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.27it/s] 44%|████▍     | 222/500 [00:14<00:17, 16.22it/s] 45%|████▍     | 224/500 [00:14<00:17, 16.19it/s] 45%|████▌     | 226/500 [00:14<00:17, 16.06it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.18it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.01it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.03it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.14it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.29it/s] 48%|████▊     | 238/500 [00:15<00:16, 16.17it/s] 48%|████▊     | 240/500 [00:15<00:15, 16.31it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.20it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.19it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.29it/s] 50%|████▉     | 248/500 [00:15<00:16, 15.36it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:16, 15.60it/s] 50%|█████     | 252/500 [00:15<00:15, 15.72it/s] 51%|█████     | 254/500 [00:16<00:15, 15.91it/s] 51%|█████     | 256/500 [00:16<00:15, 16.11it/s] 52%|█████▏    | 258/500 [00:16<00:15, 16.03it/s] 52%|█████▏    | 260/500 [00:16<00:16, 14.80it/s] 52%|█████▏    | 262/500 [00:16<00:15, 15.20it/s] 53%|█████▎    | 264/500 [00:16<00:15, 15.44it/s] 53%|█████▎    | 266/500 [00:16<00:14, 15.61it/s] 54%|█████▎    | 268/500 [00:16<00:14, 15.80it/s] 54%|█████▍    | 270/500 [00:17<00:14, 15.97it/s] 54%|█████▍    | 272/500 [00:17<00:14, 15.97it/s] 55%|█████▍    | 274/500 [00:17<00:14, 16.11it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.19it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.29it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.30it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.21it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.27it/s] 57%|█████▋    | 286/500 [00:18<00:13, 16.21it/s] 58%|█████▊    | 288/500 [00:18<00:13, 16.17it/s] 58%|█████▊    | 290/500 [00:18<00:12, 16.25it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.31it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.11it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.23it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.18it/s] 60%|██████    | 300/500 [00:18<00:12, 16.27it/s] 60%|██████    | 302/500 [00:19<00:12, 16.34it/s] 61%|██████    | 304/500 [00:19<00:12, 16.28it/s] 61%|██████    | 306/500 [00:19<00:11, 16.24it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.02it/s] 62%|██████▏   | 310/500 [00:19<00:11, 15.88it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.06it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.13it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.22it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.26it/s] 64%|██████▍   | 320/500 [00:20<00:11, 16.30it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.21it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.11it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.15it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.31it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.44it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.39it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.40it/s] 67%|██████▋   | 336/500 [00:21<00:10, 16.18it/s] 68%|██████▊   | 338/500 [00:21<00:09, 16.29it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.37it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.30it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.02it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.13it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.23it/s] 70%|███████   | 350/500 [00:21<00:09, 16.27it/s] 70%|███████   | 352/500 [00:22<00:09, 16.34it/s] 71%|███████   | 354/500 [00:22<00:08, 16.39it/s] 71%|███████   | 356/500 [00:22<00:08, 16.40it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.49it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.29it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.23it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.27it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.33it/s] 74%|███████▎  | 368/500 [00:23<00:08, 15.97it/s] 74%|███████▍  | 370/500 [00:23<00:08, 14.50it/s] 74%|███████▍  | 372/500 [00:23<00:09, 13.61it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:09, 13.82it/s] 75%|███████▌  | 376/500 [00:23<00:08, 14.49it/s] 76%|███████▌  | 378/500 [00:23<00:08, 14.98it/s] 76%|███████▌  | 380/500 [00:23<00:07, 15.37it/s] 76%|███████▋  | 382/500 [00:24<00:07, 15.64it/s] 77%|███████▋  | 384/500 [00:24<00:07, 15.89it/s] 77%|███████▋  | 386/500 [00:24<00:07, 15.96it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.04it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.08it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.18it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.18it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.23it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.25it/s] 80%|████████  | 400/500 [00:25<00:06, 16.25it/s] 80%|████████  | 402/500 [00:25<00:06, 16.26it/s] 81%|████████  | 404/500 [00:25<00:05, 16.28it/s] 81%|████████  | 406/500 [00:25<00:06, 15.55it/s] 82%|████████▏ | 408/500 [00:25<00:05, 15.77it/s] 82%|████████▏ | 410/500 [00:25<00:05, 15.99it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.03it/s] 83%|████████▎ | 414/500 [00:26<00:05, 16.06it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.19it/s] 84%|████████▎ | 418/500 [00:26<00:05, 16.26it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.21it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.37it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.36it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.34it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.26it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.36it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.44it/s] 87%|████████▋ | 434/500 [00:27<00:04, 16.41it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.08it/s] 88%|████████▊ | 438/500 [00:27<00:03, 15.92it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.01it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.16it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.19it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.27it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.32it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.39it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.42it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.32it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.24it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.27it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.24it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.26it/s] 93%|█████████▎| 464/500 [00:29<00:02, 16.26it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.27it/s] 94%|█████████▎| 468/500 [00:29<00:01, 16.27it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.32it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.32it/s] 95%|█████████▍| 474/500 [00:29<00:01, 15.98it/s] 95%|█████████▌| 476/500 [00:29<00:01, 15.79it/s] 96%|█████████▌| 478/500 [00:29<00:01, 15.98it/s] 96%|█████████▌| 480/500 [00:30<00:01, 16.09it/s] 96%|█████████▋| 482/500 [00:30<00:01, 14.71it/s] 97%|█████████▋| 484/500 [00:30<00:01, 13.95it/s] 97%|█████████▋| 486/500 [00:30<00:00, 14.56it/s] 98%|█████████▊| 488/500 [00:30<00:00, 15.10it/s] 98%|█████████▊| 490/500 [00:30<00:00, 15.46it/s] 98%|█████████▊| 492/500 [00:30<00:00, 15.64it/s] 99%|█████████▉| 494/500 [00:31<00:00, 15.77it/s] 99%|█████████▉| 496/500 [00:31<00:00, 15.91it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 16.06it/s]100%|██████████| 500/500 [00:31<00:00, 16.24it/s]100%|██████████| 500/500 [00:31<00:00, 15.93it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  7
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:42,  6.34s/it]  1%|          | 3/500 [00:06<14:05,  1.70s/it]  1%|          | 5/500 [00:06<07:07,  1.16it/s]  1%|▏         | 7/500 [00:06<04:19,  1.90it/s]  2%|▏         | 9/500 [00:06<02:53,  2.84it/s]  2%|▏         | 11/500 [00:13<10:53,  1.34s/it]  3%|▎         | 13/500 [00:13<07:27,  1.09it/s]  3%|▎         | 15/500 [00:13<05:12,  1.55it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:42,  2.96it/s]  4%|▍         | 21/500 [00:20<09:43,  1.22s/it]  5%|▍         | 23/500 [00:20<06:54,  1.15it/s]  5%|▌         | 25/500 [00:20<04:57,  1.60it/s]  5%|▌         | 27/500 [00:20<03:38,  2.16it/s]  6%|▌         | 29/500 [00:20<02:44,  2.86it/s]  6%|▌         | 31/500 [00:27<09:26,  1.21s/it]  7%|▋         | 33/500 [00:27<06:46,  1.15it/s]  7%|▋         | 35/500 [00:27<04:53,  1.58it/s]  7%|▋         | 37/500 [00:27<03:36,  2.14it/s]  8%|▊         | 39/500 [00:27<02:42,  2.83it/s]  8%|▊         | 41/500 [00:34<09:15,  1.21s/it]  9%|▊         | 43/500 [00:34<06:36,  1.15it/s]  9%|▉         | 45/500 [00:34<04:45,  1.59it/s]  9%|▉         | 47/500 [00:34<03:28,  2.18it/s] 10%|▉         | 49/500 [00:34<02:33,  2.93it/s] 10%|█         | 51/500 [00:41<09:04,  1.21s/it] 11%|█         | 53/500 [00:41<06:28,  1.15it/s] 11%|█         | 55/500 [00:41<04:39,  1.59it/s] 11%|█▏        | 57/500 [00:41<03:23,  2.18it/s] 12%|█▏        | 59/500 [00:41<02:30,  2.93it/s] 12%|█▏        | 61/500 [00:48<08:54,  1.22s/it] 13%|█▎        | 63/500 [00:48<06:21,  1.14it/s] 13%|█▎        | 65/500 [00:48<04:34,  1.58it/s] 13%|█▎        | 67/500 [00:48<03:20,  2.16it/s] 14%|█▍        | 69/500 [00:48<02:28,  2.90it/s] 14%|█▍        | 71/500 [00:55<08:38,  1.21s/it] 15%|█▍        | 73/500 [00:55<06:10,  1.15it/s]Epoch:  1  	Training Loss: 0.2184741050004959
Test Loss:  5.948108673095703
Valid Loss:  5.933862686157227
Epoch:  2  	Training Loss: 6.097996711730957
Test Loss:  0.28149861097335815
Valid Loss:  0.2859741449356079
Epoch:  3  	Training Loss: 0.2473103255033493
Test Loss:  0.28121501207351685
Valid Loss:  0.2856866121292114
Epoch:  4  	Training Loss: 0.24704815447330475
Test Loss:  0.2809317111968994
Valid Loss:  0.2853993773460388
Epoch:  5  	Training Loss: 0.24678629636764526
Test Loss:  0.28064870834350586
Valid Loss:  0.28511250019073486
Epoch:  6  	Training Loss: 0.24652475118637085
Test Loss:  0.28036603331565857
Valid Loss:  0.28482586145401
Epoch:  7  	Training Loss: 0.2462635040283203
Test Loss:  0.28008365631103516
Valid Loss:  0.2845396399497986
Epoch:  8  	Training Loss: 0.24600258469581604
Test Loss:  0.2799994945526123
Valid Loss:  0.2844547629356384
Epoch:  9  	Training Loss: 0.24591389298439026
Test Loss:  0.2799994945526123
Valid Loss:  0.2844547629356384
Epoch:  10  	Training Loss: 0.24591387808322906
Test Loss:  0.2799994647502899
Valid Loss:  0.28445470333099365
Epoch:  11  	Training Loss: 0.24591386318206787
Test Loss:  0.2799994647502899
Valid Loss:  0.28445470333099365
Epoch:  12  	Training Loss: 0.24591384828090668
Test Loss:  0.27999937534332275
Valid Loss:  0.2844546437263489
Epoch:  13  	Training Loss: 0.2459137737751007
Test Loss:  0.2799992561340332
Valid Loss:  0.2844545245170593
Epoch:  14  	Training Loss: 0.24591371417045593
Test Loss:  0.2799991965293884
Valid Loss:  0.28445446491241455
Epoch:  15  	Training Loss: 0.24591365456581116
Test Loss:  0.27999913692474365
Valid Loss:  0.2844544053077698
Epoch:  16  	Training Loss: 0.245913565158844
Test Loss:  0.2799990177154541
Valid Loss:  0.2844542860984802
Epoch:  17  	Training Loss: 0.24591349065303802
Test Loss:  0.2799989581108093
Valid Loss:  0.28445419669151306
Epoch:  18  	Training Loss: 0.24591341614723206
Test Loss:  0.2799988389015198
Valid Loss:  0.2844541072845459
Epoch:  19  	Training Loss: 0.24591335654258728
Test Loss:  0.279998779296875
Valid Loss:  0.28445401787757874
Epoch:  20  	Training Loss: 0.2459132969379425
Test Loss:  0.27999868988990784
Valid Loss:  0.2844539284706116
Epoch:  21  	Training Loss: 0.24591320753097534
Test Loss:  0.2799986004829407
Valid Loss:  0.2844538688659668
Epoch:  22  	Training Loss: 0.24591311812400818
Test Loss:  0.2799985408782959
Valid Loss:  0.28445377945899963
Epoch:  23  	Training Loss: 0.2459130734205246
Test Loss:  0.27999842166900635
Valid Loss:  0.2844536602497101
Epoch:  24  	Training Loss: 0.24591296911239624
Test Loss:  0.2799983620643616
Valid Loss:  0.2844536006450653
Epoch:  25  	Training Loss: 0.24591290950775146
Test Loss:  0.2799982726573944
Valid Loss:  0.28445351123809814
Epoch:  26  	Training Loss: 0.2459128499031067
Test Loss:  0.27999818325042725
Valid Loss:  0.284453421831131
Epoch:  27  	Training Loss: 0.24591279029846191
Test Loss:  0.2799980640411377
Valid Loss:  0.2844533324241638
Epoch:  28  	Training Loss: 0.24591271579265594
Test Loss:  0.2799980044364929
Valid Loss:  0.28445324301719666
Epoch:  29  	Training Loss: 0.24591264128684998
Test Loss:  0.27999791502952576
Valid Loss:  0.2844531536102295
Epoch:  30  	Training Loss: 0.2459125518798828
Test Loss:  0.2799978256225586
Valid Loss:  0.2844530940055847
Epoch:  31  	Training Loss: 0.24591249227523804
Test Loss:  0.2799977660179138
Valid Loss:  0.28445297479629517
Epoch:  32  	Training Loss: 0.24591243267059326
Test Loss:  0.27999764680862427
Valid Loss:  0.2844529151916504
Epoch:  33  	Training Loss: 0.2459123432636261
Test Loss:  0.2799975872039795
Valid Loss:  0.28445279598236084
Epoch:  34  	Training Loss: 0.24591228365898132
Test Loss:  0.27999746799468994
Valid Loss:  0.28445273637771606
Epoch:  35  	Training Loss: 0.24591220915317535
Test Loss:  0.27999740839004517
Valid Loss:  0.2844526171684265
Epoch:  36  	Training Loss: 0.24591213464736938
Test Loss:  0.279997318983078
Valid Loss:  0.28445255756378174
Epoch:  37  	Training Loss: 0.24591204524040222
Test Loss:  0.27999722957611084
Valid Loss:  0.2844524383544922
Epoch:  38  	Training Loss: 0.24591198563575745
Test Loss:  0.27999716997146606
Valid Loss:  0.2844523787498474
Epoch:  39  	Training Loss: 0.24591191112995148
Test Loss:  0.2799970507621765
Valid Loss:  0.28445228934288025
Epoch:  40  	Training Loss: 0.2459118366241455
Test Loss:  0.27999699115753174
Valid Loss:  0.2844521701335907
Epoch:  41  	Training Loss: 0.24591177701950073
Test Loss:  0.2799968719482422
Valid Loss:  0.28445208072662354
Epoch:  42  	Training Loss: 0.24591170251369476
Test Loss:  0.2799968123435974
Valid Loss:  0.28445205092430115
Epoch:  43  	Training Loss: 0.2459116280078888
Test Loss:  0.27999669313430786
Valid Loss:  0.2844519317150116
Epoch:  44  	Training Loss: 0.24591155350208282
Test Loss:  0.2799966335296631
Valid Loss:  0.28445184230804443
Epoch:  45  	Training Loss: 0.24591147899627686
Test Loss:  0.27999651432037354
Valid Loss:  0.28445175290107727
Epoch:  46  	Training Loss: 0.24591141939163208
Test Loss:  0.27999645471572876
Valid Loss:  0.2844516634941101
Epoch:  47  	Training Loss: 0.24591132998466492
Test Loss:  0.2799963653087616
Valid Loss:  0.28445160388946533
Epoch:  48  	Training Loss: 0.24591127038002014
Test Loss:  0.27999627590179443
Valid Loss:  0.2844514846801758
Epoch:  49  	Training Loss: 0.24591121077537537
Test Loss:  0.27999621629714966
Valid Loss:  0.284451425075531
Epoch:  50  	Training Loss: 0.2459111511707306
Test Loss:  0.2799960970878601
Valid Loss:  0.28445130586624146
Epoch:  51  	Training Loss: 0.24591106176376343
Test Loss:  0.27999603748321533
Valid Loss:  0.2844512462615967
Epoch:  52  	Training Loss: 0.24591097235679626
Test Loss:  0.2799959182739258
Valid Loss:  0.28445112705230713
Epoch:  53  	Training Loss: 0.24591092765331268
Test Loss:  0.279995858669281
Valid Loss:  0.28445106744766235
Epoch:  54  	Training Loss: 0.24591083824634552
Test Loss:  0.27999579906463623
Valid Loss:  0.2844509780406952
Epoch:  55  	Training Loss: 0.24591076374053955
Test Loss:  0.2799956798553467
Valid Loss:  0.284450888633728
Epoch:  56  	Training Loss: 0.24591070413589478
Test Loss:  0.2799956202507019
Valid Loss:  0.28445079922676086
Epoch:  57  	Training Loss: 0.2459106296300888
Test Loss:  0.27999550104141235
Valid Loss:  0.2844507098197937
Epoch:  58  	Training Loss: 0.24591055512428284
Test Loss:  0.2799954414367676
Valid Loss:  0.28445062041282654
Epoch:  59  	Training Loss: 0.24591046571731567
Test Loss:  0.2799953520298004
Valid Loss:  0.2844505310058594
Epoch:  60  	Training Loss: 0.2459104061126709
Test Loss:  0.27999526262283325
Valid Loss:  0.2844504714012146
Epoch:  61  	Training Loss: 0.24591034650802612
Test Loss:  0.2799952030181885
Valid Loss:  0.28445038199424744
Epoch:  62  	Training Loss: 0.24591025710105896
Test Loss:  0.2799950838088989
Valid Loss:  0.2844502627849579
Epoch:  63  	Training Loss: 0.24591019749641418
Test Loss:  0.27999499440193176
Valid Loss:  0.2844502031803131
Epoch:  64  	Training Loss: 0.2459101378917694
Test Loss:  0.2799949049949646
Valid Loss:  0.28445011377334595
Epoch:  65  	Training Loss: 0.24591004848480225
Test Loss:  0.27999481558799744
Valid Loss:  0.28445005416870117
Epoch:  66  	Training Loss: 0.24590998888015747
Test Loss:  0.2799947261810303
Valid Loss:  0.2844499349594116
Epoch:  67  	Training Loss: 0.2459098994731903
Test Loss:  0.2799946665763855
Valid Loss:  0.28444984555244446
Epoch:  68  	Training Loss: 0.24590983986854553
Test Loss:  0.27999454736709595
Valid Loss:  0.2844497561454773
Epoch:  69  	Training Loss: 0.24590978026390076
Test Loss:  0.27999448776245117
Valid Loss:  0.2844496965408325
Epoch:  70  	Training Loss: 0.2459096908569336
Test Loss:  0.279994398355484
Valid Loss:  0.28444957733154297
Epoch:  71  	Training Loss: 0.24590963125228882
Test Loss:  0.27999430894851685
Valid Loss:  0.2844495177268982
Epoch:  72  	Training Loss: 0.24590955674648285
Test Loss:  0.27999424934387207
Valid Loss:  0.28444942831993103
Epoch:  73  	Training Loss: 0.24590948224067688
Test Loss:  0.2799941301345825
Valid Loss:  0.2844493091106415
Epoch:  74  	Training Loss: 0.24590939283370972
Test Loss:   15%|█▌        | 75/500 [00:55<04:26,  1.60it/s] 15%|█▌        | 77/500 [00:55<03:13,  2.18it/s] 16%|█▌        | 79/500 [00:55<02:24,  2.91it/s] 16%|█▌        | 81/500 [01:02<08:19,  1.19s/it] 17%|█▋        | 83/500 [01:02<05:57,  1.17it/s] 17%|█▋        | 85/500 [01:02<04:17,  1.61it/s] 17%|█▋        | 87/500 [01:02<03:07,  2.20it/s] 18%|█▊        | 89/500 [01:02<02:19,  2.95it/s] 18%|█▊        | 91/500 [01:09<08:14,  1.21s/it] 19%|█▊        | 93/500 [01:09<05:53,  1.15it/s] 19%|█▉        | 95/500 [01:09<04:14,  1.59it/s] 19%|█▉        | 97/500 [01:09<03:04,  2.18it/s] 20%|█▉        | 99/500 [01:09<02:16,  2.94it/s] 20%|██        | 101/500 [01:16<07:59,  1.20s/it] 21%|██        | 103/500 [01:16<05:42,  1.16it/s] 21%|██        | 105/500 [01:16<04:06,  1.60it/s] 21%|██▏       | 107/500 [01:16<03:00,  2.18it/s] 22%|██▏       | 109/500 [01:16<02:13,  2.93it/s] 22%|██▏       | 111/500 [01:23<07:40,  1.18s/it] 23%|██▎       | 113/500 [01:23<05:29,  1.17it/s] 23%|██▎       | 115/500 [01:23<03:56,  1.62it/s] 23%|██▎       | 117/500 [01:23<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:23<02:08,  2.97it/s] 24%|██▍       | 121/500 [01:30<07:28,  1.18s/it] 25%|██▍       | 123/500 [01:30<05:22,  1.17it/s] 25%|██▌       | 125/500 [01:30<03:52,  1.62it/s] 25%|██▌       | 127/500 [01:30<02:49,  2.21it/s] 26%|██▌       | 129/500 [01:30<02:04,  2.97it/s] 26%|██▌       | 131/500 [01:37<07:25,  1.21s/it] 27%|██▋       | 133/500 [01:37<05:19,  1.15it/s] 27%|██▋       | 135/500 [01:37<03:52,  1.57it/s] 27%|██▋       | 137/500 [01:37<02:51,  2.12it/s] 28%|██▊       | 139/500 [01:37<02:08,  2.81it/s] 28%|██▊       | 141/500 [01:44<07:09,  1.20s/it] 29%|██▊       | 143/500 [01:44<05:06,  1.16it/s] 29%|██▉       | 145/500 [01:44<03:41,  1.60it/s]0.27999407052993774
Valid Loss:  0.2844492197036743
Epoch:  75  	Training Loss: 0.24590933322906494
Test Loss:  0.2799939513206482
Valid Loss:  0.28444916009902954
Epoch:  76  	Training Loss: 0.24590925872325897
Test Loss:  0.2799938917160034
Valid Loss:  0.2844490706920624
Epoch:  77  	Training Loss: 0.2459091991186142
Test Loss:  0.27999380230903625
Valid Loss:  0.2844489812850952
Epoch:  78  	Training Loss: 0.24590912461280823
Test Loss:  0.2799937129020691
Valid Loss:  0.28444886207580566
Epoch:  79  	Training Loss: 0.24590905010700226
Test Loss:  0.27999362349510193
Valid Loss:  0.2844488024711609
Epoch:  80  	Training Loss: 0.24590899050235748
Test Loss:  0.27999353408813477
Valid Loss:  0.2844487130641937
Epoch:  81  	Training Loss: 0.2459089159965515
Test Loss:  0.2799934446811676
Valid Loss:  0.28444862365722656
Epoch:  82  	Training Loss: 0.24590884149074554
Test Loss:  0.27999335527420044
Valid Loss:  0.2844485342502594
Epoch:  83  	Training Loss: 0.24590875208377838
Test Loss:  0.27999329566955566
Valid Loss:  0.28444844484329224
Epoch:  84  	Training Loss: 0.2459086924791336
Test Loss:  0.2799932062625885
Valid Loss:  0.2844483554363251
Epoch:  85  	Training Loss: 0.24590861797332764
Test Loss:  0.27999311685562134
Valid Loss:  0.2844482660293579
Epoch:  86  	Training Loss: 0.24590854346752167
Test Loss:  0.2799929976463318
Valid Loss:  0.28444817662239075
Epoch:  87  	Training Loss: 0.2459084689617157
Test Loss:  0.279992938041687
Valid Loss:  0.2844480872154236
Epoch:  88  	Training Loss: 0.24590840935707092
Test Loss:  0.27999284863471985
Valid Loss:  0.2844479978084564
Epoch:  89  	Training Loss: 0.24590833485126495
Test Loss:  0.2799927592277527
Valid Loss:  0.28444793820381165
Epoch:  90  	Training Loss: 0.24590826034545898
Test Loss:  0.2799926996231079
Valid Loss:  0.2844478487968445
Epoch:  91  	Training Loss: 0.2459082007408142
Test Loss:  0.27999261021614075
Valid Loss:  0.28444772958755493
Epoch:  92  	Training Loss: 0.24590811133384705
Test Loss:  0.2799925208091736
Valid Loss:  0.28444766998291016
Epoch:  93  	Training Loss: 0.24590805172920227
Test Loss:  0.2799924314022064
Valid Loss:  0.2844475507736206
Epoch:  94  	Training Loss: 0.2459079623222351
Test Loss:  0.27999234199523926
Valid Loss:  0.28444749116897583
Epoch:  95  	Training Loss: 0.24590790271759033
Test Loss:  0.2799922823905945
Valid Loss:  0.28444743156433105
Epoch:  96  	Training Loss: 0.24590784311294556
Test Loss:  0.27999216318130493
Valid Loss:  0.2844473123550415
Epoch:  97  	Training Loss: 0.2459077686071396
Test Loss:  0.27999210357666016
Valid Loss:  0.28444722294807434
Epoch:  98  	Training Loss: 0.24590769410133362
Test Loss:  0.279992014169693
Valid Loss:  0.2844471335411072
Epoch:  99  	Training Loss: 0.24590760469436646
Test Loss:  0.27999192476272583
Valid Loss:  0.28444704413414
Epoch:  100  	Training Loss: 0.24590754508972168
Test Loss:  0.27999186515808105
Valid Loss:  0.28444695472717285
Epoch:  101  	Training Loss: 0.2459074705839157
Test Loss:  0.2799917459487915
Valid Loss:  0.2844468951225281
Epoch:  102  	Training Loss: 0.24590739607810974
Test Loss:  0.27999165654182434
Valid Loss:  0.2844467759132385
Epoch:  103  	Training Loss: 0.24590733647346497
Test Loss:  0.2799915671348572
Valid Loss:  0.28444671630859375
Epoch:  104  	Training Loss: 0.245907261967659
Test Loss:  0.27999147772789
Valid Loss:  0.2844465970993042
Epoch:  105  	Training Loss: 0.24590718746185303
Test Loss:  0.27999138832092285
Valid Loss:  0.2844465374946594
Epoch:  106  	Training Loss: 0.24590711295604706
Test Loss:  0.2799913287162781
Valid Loss:  0.28444644808769226
Epoch:  107  	Training Loss: 0.2459070384502411
Test Loss:  0.2799912393093109
Valid Loss:  0.2844463586807251
Epoch:  108  	Training Loss: 0.24590696394443512
Test Loss:  0.27999114990234375
Valid Loss:  0.2844462990760803
Epoch:  109  	Training Loss: 0.24590690433979034
Test Loss:  0.2799910604953766
Valid Loss:  0.28444617986679077
Epoch:  110  	Training Loss: 0.24590682983398438
Test Loss:  0.2799909710884094
Valid Loss:  0.2844460904598236
Epoch:  111  	Training Loss: 0.2459067553281784
Test Loss:  0.27999091148376465
Valid Loss:  0.28444600105285645
Epoch:  112  	Training Loss: 0.24590668082237244
Test Loss:  0.2799908220767975
Valid Loss:  0.28444594144821167
Epoch:  113  	Training Loss: 0.24590662121772766
Test Loss:  0.2799907326698303
Valid Loss:  0.2844458222389221
Epoch:  114  	Training Loss: 0.2459065318107605
Test Loss:  0.27999064326286316
Valid Loss:  0.28444576263427734
Epoch:  115  	Training Loss: 0.24590647220611572
Test Loss:  0.279990553855896
Valid Loss:  0.2844456434249878
Epoch:  116  	Training Loss: 0.24590639770030975
Test Loss:  0.27999046444892883
Valid Loss:  0.284445583820343
Epoch:  117  	Training Loss: 0.24590632319450378
Test Loss:  0.27999037504196167
Valid Loss:  0.28444546461105347
Epoch:  118  	Training Loss: 0.24590624868869781
Test Loss:  0.2799902856349945
Valid Loss:  0.2844454050064087
Epoch:  119  	Training Loss: 0.24590618908405304
Test Loss:  0.27999019622802734
Valid Loss:  0.28444528579711914
Epoch:  120  	Training Loss: 0.24590611457824707
Test Loss:  0.27999013662338257
Valid Loss:  0.28444522619247437
Epoch:  121  	Training Loss: 0.2459060549736023
Test Loss:  0.279990017414093
Valid Loss:  0.2844451367855072
Epoch:  122  	Training Loss: 0.24590596556663513
Test Loss:  0.27998995780944824
Valid Loss:  0.28444504737854004
Epoch:  123  	Training Loss: 0.24590589106082916
Test Loss:  0.2799898386001587
Valid Loss:  0.28444498777389526
Epoch:  124  	Training Loss: 0.2459058314561844
Test Loss:  0.2799897789955139
Valid Loss:  0.2844448685646057
Epoch:  125  	Training Loss: 0.24590575695037842
Test Loss:  0.27998968958854675
Valid Loss:  0.28444477915763855
Epoch:  126  	Training Loss: 0.24590566754341125
Test Loss:  0.2799896001815796
Valid Loss:  0.2844446897506714
Epoch:  127  	Training Loss: 0.24590560793876648
Test Loss:  0.2799895405769348
Valid Loss:  0.2844446003437042
Epoch:  128  	Training Loss: 0.2459055483341217
Test Loss:  0.27998942136764526
Valid Loss:  0.28444451093673706
Epoch:  129  	Training Loss: 0.24590545892715454
Test Loss:  0.2799893617630005
Valid Loss:  0.2844444215297699
Epoch:  130  	Training Loss: 0.24590538442134857
Test Loss:  0.27998924255371094
Valid Loss:  0.28444433212280273
Epoch:  131  	Training Loss: 0.2459053248167038
Test Loss:  0.27998918294906616
Valid Loss:  0.28444427251815796
Epoch:  132  	Training Loss: 0.24590525031089783
Test Loss:  0.279989093542099
Valid Loss:  0.2844441533088684
Epoch:  133  	Training Loss: 0.24590517580509186
Test Loss:  0.27998900413513184
Valid Loss:  0.28444409370422363
Epoch:  134  	Training Loss: 0.2459051012992859
Test Loss:  0.27998894453048706
Valid Loss:  0.28444400429725647
Epoch:  135  	Training Loss: 0.2459050416946411
Test Loss:  0.2799888253211975
Valid Loss:  0.2844439148902893
Epoch:  136  	Training Loss: 0.24590496718883514
Test Loss:  0.27998873591423035
Valid Loss:  0.28444382548332214
Epoch:  137  	Training Loss: 0.24590487778186798
Test Loss:  0.2799886465072632
Valid Loss:  0.2844437062740326
Epoch:  138  	Training Loss: 0.2459048330783844
Test Loss:  0.2799885869026184
Valid Loss:  0.2844436466693878
Epoch:  139  	Training Loss: 0.24590474367141724
Test Loss:  0.27998849749565125
Valid Loss:  0.28444355726242065
Epoch:  140  	Training Loss: 0.24590468406677246
Test Loss:  0.2799884080886841
Valid Loss:  0.2844434976577759
Epoch:  141  	Training Loss: 0.24590462446212769
Test Loss:  0.2799883186817169
Valid Loss:  0.28444337844848633
Epoch:  142  	Training Loss: 0.24590453505516052
Test Loss:  0.27998822927474976
Valid Loss:  0.28444328904151917
Epoch:  143  	Training Loss: 0.24590446054935455
Test Loss:  0.279988169670105
Valid Loss:  0.284443199634552
Epoch:  144  	Training Loss: 0.24590438604354858
Test Loss:  0.27998805046081543
Valid Loss:  0.28444311022758484
Epoch:  145  	Training Loss: 0.2459043264389038
Test Loss:  0.27998799085617065
Valid Loss:  0.28444305062294006
Epoch:  146  	Training Loss: 0.24590425193309784
Test Loss:  0.2799878716468811
Valid Loss:  0.2844429612159729
Epoch:  147  	Training Loss: 0.24590417742729187
Test Loss:   29%|██▉       | 147/500 [01:44<02:41,  2.19it/s] 30%|██▉       | 149/500 [01:44<01:59,  2.94it/s] 30%|███       | 151/500 [01:50<06:51,  1.18s/it] 30%|███       | 152/500 [01:51<05:43,  1.01it/s] 31%|███       | 154/500 [01:51<03:57,  1.46it/s] 31%|███       | 156/500 [01:51<02:46,  2.06it/s] 32%|███▏      | 158/500 [01:51<02:00,  2.84it/s] 32%|███▏      | 160/500 [01:51<01:29,  3.80it/s] 32%|███▏      | 162/500 [01:57<06:25,  1.14s/it] 33%|███▎      | 164/500 [01:57<04:33,  1.23it/s] 33%|███▎      | 166/500 [01:58<03:15,  1.71it/s] 34%|███▎      | 168/500 [01:58<02:22,  2.33it/s] 34%|███▍      | 170/500 [01:58<01:45,  3.13it/s] 34%|███▍      | 172/500 [02:04<06:23,  1.17s/it] 35%|███▍      | 174/500 [02:04<04:32,  1.20it/s] 35%|███▌      | 176/500 [02:04<03:15,  1.65it/s] 36%|███▌      | 178/500 [02:05<02:22,  2.26it/s] 36%|███▌      | 180/500 [02:05<01:45,  3.03it/s] 36%|███▋      | 182/500 [02:11<06:16,  1.18s/it] 37%|███▋      | 184/500 [02:11<04:28,  1.18it/s] 37%|███▋      | 186/500 [02:11<03:12,  1.63it/s] 38%|███▊      | 188/500 [02:11<02:20,  2.22it/s] 38%|███▊      | 190/500 [02:12<01:43,  2.99it/s] 38%|███▊      | 192/500 [02:18<06:05,  1.19s/it] 39%|███▉      | 194/500 [02:18<04:20,  1.18it/s] 39%|███▉      | 196/500 [02:18<03:07,  1.62it/s] 40%|███▉      | 198/500 [02:18<02:16,  2.22it/s] 40%|████      | 200/500 [02:18<01:40,  2.99it/s] 40%|████      | 202/500 [02:25<06:05,  1.22s/it] 41%|████      | 204/500 [02:25<04:19,  1.14it/s] 41%|████      | 206/500 [02:25<03:06,  1.58it/s] 42%|████▏     | 208/500 [02:25<02:15,  2.16it/s] 42%|████▏     | 210/500 [02:26<01:39,  2.91it/s] 42%|████▏     | 212/500 [02:32<05:42,  1.19s/it] 43%|████▎     | 214/500 [02:32<04:03,  1.17it/s] 43%|████▎     | 216/500 [02:32<02:54,  1.62it/s] 44%|████▎     | 218/500 [02:32<02:07,  2.22it/s]0.27998781204223633
Valid Loss:  0.28444287180900574
Epoch:  148  	Training Loss: 0.2459041029214859
Test Loss:  0.27998772263526917
Valid Loss:  0.2844427824020386
Epoch:  149  	Training Loss: 0.24590402841567993
Test Loss:  0.279987633228302
Valid Loss:  0.2844426929950714
Epoch:  150  	Training Loss: 0.24590396881103516
Test Loss:  0.27998754382133484
Valid Loss:  0.28444260358810425
Epoch:  151  	Training Loss: 0.245903879404068
Test Loss:  0.2799874544143677
Valid Loss:  0.2844425141811371
Epoch:  152  	Training Loss: 0.24590381979942322
Test Loss:  0.2799873650074005
Valid Loss:  0.2844424247741699
Epoch:  153  	Training Loss: 0.24590376019477844
Test Loss:  0.27998730540275574
Valid Loss:  0.28444233536720276
Epoch:  154  	Training Loss: 0.24590367078781128
Test Loss:  0.2799872159957886
Valid Loss:  0.284442275762558
Epoch:  155  	Training Loss: 0.2459036111831665
Test Loss:  0.279987096786499
Valid Loss:  0.2844421863555908
Epoch:  156  	Training Loss: 0.24590352177619934
Test Loss:  0.27998703718185425
Valid Loss:  0.28444209694862366
Epoch:  157  	Training Loss: 0.24590346217155457
Test Loss:  0.2799869477748871
Valid Loss:  0.2844419777393341
Epoch:  158  	Training Loss: 0.2459033876657486
Test Loss:  0.2799868583679199
Valid Loss:  0.28444188833236694
Epoch:  159  	Training Loss: 0.24590331315994263
Test Loss:  0.27998679876327515
Valid Loss:  0.28444182872772217
Epoch:  160  	Training Loss: 0.24590325355529785
Test Loss:  0.2799866795539856
Valid Loss:  0.284441739320755
Epoch:  161  	Training Loss: 0.24590317904949188
Test Loss:  0.2799866199493408
Valid Loss:  0.28444164991378784
Epoch:  162  	Training Loss: 0.2459031045436859
Test Loss:  0.27998650074005127
Valid Loss:  0.2844415605068207
Epoch:  163  	Training Loss: 0.24590301513671875
Test Loss:  0.2799864411354065
Valid Loss:  0.2844414710998535
Epoch:  164  	Training Loss: 0.24590295553207397
Test Loss:  0.27998635172843933
Valid Loss:  0.28444138169288635
Epoch:  165  	Training Loss: 0.2459028661251068
Test Loss:  0.27998629212379456
Valid Loss:  0.2844412922859192
Epoch:  166  	Training Loss: 0.24590282142162323
Test Loss:  0.279986172914505
Valid Loss:  0.284441202878952
Epoch:  167  	Training Loss: 0.24590274691581726
Test Loss:  0.27998608350753784
Valid Loss:  0.28444111347198486
Epoch:  168  	Training Loss: 0.2459026724100113
Test Loss:  0.2799859941005707
Valid Loss:  0.2844410538673401
Epoch:  169  	Training Loss: 0.24590259790420532
Test Loss:  0.2799859344959259
Valid Loss:  0.28444093465805054
Epoch:  170  	Training Loss: 0.24590253829956055
Test Loss:  0.27998581528663635
Valid Loss:  0.28444087505340576
Epoch:  171  	Training Loss: 0.24590246379375458
Test Loss:  0.2799857556819916
Valid Loss:  0.2844407856464386
Epoch:  172  	Training Loss: 0.2459023892879486
Test Loss:  0.2799856662750244
Valid Loss:  0.28444069623947144
Epoch:  173  	Training Loss: 0.24590229988098145
Test Loss:  0.27998557686805725
Valid Loss:  0.2844406068325043
Epoch:  174  	Training Loss: 0.24590224027633667
Test Loss:  0.2799854874610901
Valid Loss:  0.2844405174255371
Epoch:  175  	Training Loss: 0.2459021657705307
Test Loss:  0.2799853980541229
Valid Loss:  0.28444042801856995
Epoch:  176  	Training Loss: 0.24590210616588593
Test Loss:  0.27998530864715576
Valid Loss:  0.2844403386116028
Epoch:  177  	Training Loss: 0.24590203166007996
Test Loss:  0.279985249042511
Valid Loss:  0.2844402492046356
Epoch:  178  	Training Loss: 0.2459019422531128
Test Loss:  0.2799851596355438
Valid Loss:  0.28444015979766846
Epoch:  179  	Training Loss: 0.24590186774730682
Test Loss:  0.27998507022857666
Valid Loss:  0.2844401001930237
Epoch:  180  	Training Loss: 0.24590180814266205
Test Loss:  0.2799849808216095
Valid Loss:  0.28443998098373413
Epoch:  181  	Training Loss: 0.24590173363685608
Test Loss:  0.27998489141464233
Valid Loss:  0.28443992137908936
Epoch:  182  	Training Loss: 0.2459016740322113
Test Loss:  0.27998483180999756
Valid Loss:  0.2844398021697998
Epoch:  183  	Training Loss: 0.24590161442756653
Test Loss:  0.279984712600708
Valid Loss:  0.28443974256515503
Epoch:  184  	Training Loss: 0.24590152502059937
Test Loss:  0.27998462319374084
Valid Loss:  0.2844396233558655
Epoch:  185  	Training Loss: 0.2459014505147934
Test Loss:  0.2799845337867737
Valid Loss:  0.2844395637512207
Epoch:  186  	Training Loss: 0.24590137600898743
Test Loss:  0.2799844741821289
Valid Loss:  0.28443944454193115
Epoch:  187  	Training Loss: 0.24590131640434265
Test Loss:  0.27998438477516174
Valid Loss:  0.2844393849372864
Epoch:  188  	Training Loss: 0.24590125679969788
Test Loss:  0.2799842953681946
Valid Loss:  0.2844392955303192
Epoch:  189  	Training Loss: 0.24590115249156952
Test Loss:  0.2799842059612274
Valid Loss:  0.28443920612335205
Epoch:  190  	Training Loss: 0.24590107798576355
Test Loss:  0.27998411655426025
Valid Loss:  0.2844391465187073
Epoch:  191  	Training Loss: 0.24590101838111877
Test Loss:  0.2799840271472931
Valid Loss:  0.2844390273094177
Epoch:  192  	Training Loss: 0.2459009438753128
Test Loss:  0.2799839377403259
Valid Loss:  0.28443893790245056
Epoch:  193  	Training Loss: 0.24590089917182922
Test Loss:  0.27998387813568115
Valid Loss:  0.2844388484954834
Epoch:  194  	Training Loss: 0.24590080976486206
Test Loss:  0.279983788728714
Valid Loss:  0.28443875908851624
Epoch:  195  	Training Loss: 0.2459007352590561
Test Loss:  0.27998366951942444
Valid Loss:  0.2844386696815491
Epoch:  196  	Training Loss: 0.24590066075325012
Test Loss:  0.27998363971710205
Valid Loss:  0.2844386100769043
Epoch:  197  	Training Loss: 0.24590060114860535
Test Loss:  0.2799835205078125
Valid Loss:  0.28443849086761475
Epoch:  198  	Training Loss: 0.24590051174163818
Test Loss:  0.27998343110084534
Valid Loss:  0.28443843126296997
Epoch:  199  	Training Loss: 0.2459004521369934
Test Loss:  0.2799833416938782
Valid Loss:  0.2844383120536804
Epoch:  200  	Training Loss: 0.24590036273002625
Test Loss:  0.2799832820892334
Valid Loss:  0.28443825244903564
Epoch:  201  	Training Loss: 0.24590033292770386
Test Loss:  0.27998316287994385
Valid Loss:  0.2844381630420685
Epoch:  202  	Training Loss: 0.2459002286195755
Test Loss:  0.2799831032752991
Valid Loss:  0.2844380736351013
Epoch:  203  	Training Loss: 0.24590018391609192
Test Loss:  0.2799829840660095
Valid Loss:  0.28443801403045654
Epoch:  204  	Training Loss: 0.24590009450912476
Test Loss:  0.27998292446136475
Valid Loss:  0.284437894821167
Epoch:  205  	Training Loss: 0.2459000200033188
Test Loss:  0.27998286485671997
Valid Loss:  0.2844378352165222
Epoch:  206  	Training Loss: 0.24589994549751282
Test Loss:  0.2799827456474304
Valid Loss:  0.28443771600723267
Epoch:  207  	Training Loss: 0.24589988589286804
Test Loss:  0.27998265624046326
Valid Loss:  0.2844376266002655
Epoch:  208  	Training Loss: 0.24589979648590088
Test Loss:  0.2799825668334961
Valid Loss:  0.28443753719329834
Epoch:  209  	Training Loss: 0.2458997368812561
Test Loss:  0.2799825072288513
Valid Loss:  0.28443747758865356
Epoch:  210  	Training Loss: 0.24589966237545013
Test Loss:  0.27998241782188416
Valid Loss:  0.2844373881816864
Epoch:  211  	Training Loss: 0.24589958786964417
Test Loss:  0.279982328414917
Valid Loss:  0.28443729877471924
Epoch:  212  	Training Loss: 0.2458995282649994
Test Loss:  0.27998223900794983
Valid Loss:  0.2844372093677521
Epoch:  213  	Training Loss: 0.24589943885803223
Test Loss:  0.27998214960098267
Valid Loss:  0.2844371199607849
Epoch:  214  	Training Loss: 0.24589937925338745
Test Loss:  0.2799820601940155
Valid Loss:  0.28443703055381775
Epoch:  215  	Training Loss: 0.24589930474758148
Test Loss:  0.27998197078704834
Valid Loss:  0.2844369411468506
Epoch:  216  	Training Loss: 0.2458992302417755
Test Loss:  0.27998191118240356
Valid Loss:  0.2844368517398834
Epoch:  217  	Training Loss: 0.24589915573596954
Test Loss:  0.279981791973114
Valid Loss:  0.28443676233291626
Epoch:  218  	Training Loss: 0.24589908123016357
Test Loss:  0.27998173236846924
Valid Loss:  0.2844366729259491
Epoch:  219  	Training Loss: 0.2458990067243576
Test Loss:  0.2799816131591797
Valid Loss:  0.28443658351898193
 44%|████▍     | 220/500 [02:32<01:34,  2.98it/s] 44%|████▍     | 222/500 [02:39<05:29,  1.19s/it] 45%|████▍     | 224/500 [02:39<03:54,  1.18it/s] 45%|████▌     | 226/500 [02:39<02:48,  1.63it/s] 46%|████▌     | 228/500 [02:39<02:02,  2.22it/s] 46%|████▌     | 230/500 [02:39<01:30,  2.97it/s] 46%|████▋     | 232/500 [02:46<05:18,  1.19s/it] 47%|████▋     | 234/500 [02:46<03:46,  1.17it/s] 47%|████▋     | 236/500 [02:46<02:42,  1.62it/s] 48%|████▊     | 238/500 [02:46<01:58,  2.21it/s] 48%|████▊     | 240/500 [02:46<01:27,  2.98it/s] 48%|████▊     | 242/500 [02:52<05:01,  1.17s/it] 49%|████▉     | 244/500 [02:53<03:34,  1.19it/s] 49%|████▉     | 246/500 [02:53<02:34,  1.65it/s] 50%|████▉     | 248/500 [02:53<01:52,  2.24it/s] 50%|█████     | 250/500 [02:53<01:23,  3.00it/s] 50%|█████     | 252/500 [02:59<04:57,  1.20s/it] 51%|█████     | 254/500 [02:59<03:31,  1.16it/s] 51%|█████     | 256/500 [03:00<02:31,  1.61it/s] 52%|█████▏    | 258/500 [03:00<01:50,  2.19it/s] 52%|█████▏    | 260/500 [03:00<01:21,  2.95it/s] 52%|█████▏    | 262/500 [03:06<04:43,  1.19s/it] 53%|█████▎    | 264/500 [03:06<03:21,  1.17it/s] 53%|█████▎    | 266/500 [03:07<02:24,  1.62it/s] 54%|█████▎    | 268/500 [03:07<01:45,  2.21it/s] 54%|█████▍    | 270/500 [03:07<01:17,  2.97it/s] 54%|█████▍    | 272/500 [03:13<04:31,  1.19s/it] 55%|█████▍    | 274/500 [03:13<03:12,  1.17it/s] 55%|█████▌    | 276/500 [03:13<02:17,  1.62it/s] 56%|█████▌    | 278/500 [03:14<01:40,  2.22it/s] 56%|█████▌    | 280/500 [03:14<01:13,  2.97it/s] 56%|█████▋    | 282/500 [03:20<04:16,  1.18s/it] 57%|█████▋    | 284/500 [03:20<03:02,  1.19it/s] 57%|█████▋    | 286/500 [03:20<02:10,  1.64it/s] 58%|█████▊    | 288/500 [03:20<01:34,  2.24it/s] 58%|█████▊    | 290/500 [03:20<01:10,  3.00it/s]Epoch:  220  	Training Loss: 0.24589894711971283
Test Loss:  0.2799815535545349
Valid Loss:  0.28443652391433716
Epoch:  221  	Training Loss: 0.24589887261390686
Test Loss:  0.27998146414756775
Valid Loss:  0.2844364047050476
Epoch:  222  	Training Loss: 0.24589881300926208
Test Loss:  0.2799813747406006
Valid Loss:  0.28443634510040283
Epoch:  223  	Training Loss: 0.24589870870113373
Test Loss:  0.2799812853336334
Valid Loss:  0.28443625569343567
Epoch:  224  	Training Loss: 0.24589866399765015
Test Loss:  0.27998119592666626
Valid Loss:  0.2844361364841461
Epoch:  225  	Training Loss: 0.24589857459068298
Test Loss:  0.2799811363220215
Valid Loss:  0.28443604707717896
Epoch:  226  	Training Loss: 0.2458985149860382
Test Loss:  0.27998101711273193
Valid Loss:  0.2844359874725342
Epoch:  227  	Training Loss: 0.24589844048023224
Test Loss:  0.27998095750808716
Valid Loss:  0.284435898065567
Epoch:  228  	Training Loss: 0.24589836597442627
Test Loss:  0.27998086810112
Valid Loss:  0.28443580865859985
Epoch:  229  	Training Loss: 0.2458982914686203
Test Loss:  0.27998077869415283
Valid Loss:  0.2844357192516327
Epoch:  230  	Training Loss: 0.24589823186397552
Test Loss:  0.27998068928718567
Valid Loss:  0.2844356298446655
Epoch:  231  	Training Loss: 0.24589815735816956
Test Loss:  0.2799806296825409
Valid Loss:  0.28443557024002075
Epoch:  232  	Training Loss: 0.2458980828523636
Test Loss:  0.27998054027557373
Valid Loss:  0.2844354510307312
Epoch:  233  	Training Loss: 0.24589800834655762
Test Loss:  0.2799804210662842
Valid Loss:  0.2844353914260864
Epoch:  234  	Training Loss: 0.24589794874191284
Test Loss:  0.2799803614616394
Valid Loss:  0.2844352722167969
Epoch:  235  	Training Loss: 0.24589785933494568
Test Loss:  0.27998027205467224
Valid Loss:  0.2844352126121521
Epoch:  236  	Training Loss: 0.2458977997303009
Test Loss:  0.2799801826477051
Valid Loss:  0.28443509340286255
Epoch:  237  	Training Loss: 0.24589774012565613
Test Loss:  0.2799801230430603
Valid Loss:  0.2844350337982178
Epoch:  238  	Training Loss: 0.24589765071868896
Test Loss:  0.27998000383377075
Valid Loss:  0.2844349145889282
Epoch:  239  	Training Loss: 0.2458975613117218
Test Loss:  0.2799799144268036
Valid Loss:  0.28443485498428345
Epoch:  240  	Training Loss: 0.24589750170707703
Test Loss:  0.2799798250198364
Valid Loss:  0.2844347655773163
Epoch:  241  	Training Loss: 0.24589742720127106
Test Loss:  0.27997973561286926
Valid Loss:  0.2844346761703491
Epoch:  242  	Training Loss: 0.24589736759662628
Test Loss:  0.2799796462059021
Valid Loss:  0.28443458676338196
Epoch:  243  	Training Loss: 0.2458972930908203
Test Loss:  0.2799795866012573
Valid Loss:  0.2844344973564148
Epoch:  244  	Training Loss: 0.24589721858501434
Test Loss:  0.2799794673919678
Valid Loss:  0.28443443775177
Epoch:  245  	Training Loss: 0.24589714407920837
Test Loss:  0.279979407787323
Valid Loss:  0.28443431854248047
Epoch:  246  	Training Loss: 0.2458970844745636
Test Loss:  0.27997931838035583
Valid Loss:  0.2844342291355133
Epoch:  247  	Training Loss: 0.24589699506759644
Test Loss:  0.27997922897338867
Valid Loss:  0.28443413972854614
Epoch:  248  	Training Loss: 0.24589695036411285
Test Loss:  0.2799791693687439
Valid Loss:  0.28443408012390137
Epoch:  249  	Training Loss: 0.2458968609571457
Test Loss:  0.27997905015945435
Valid Loss:  0.2844339609146118
Epoch:  250  	Training Loss: 0.24589680135250092
Test Loss:  0.27997899055480957
Valid Loss:  0.28443387150764465
Epoch:  251  	Training Loss: 0.24589672684669495
Test Loss:  0.2799789011478424
Valid Loss:  0.2844337821006775
Epoch:  252  	Training Loss: 0.24589665234088898
Test Loss:  0.27997881174087524
Valid Loss:  0.2844337224960327
Epoch:  253  	Training Loss: 0.245896577835083
Test Loss:  0.27997875213623047
Valid Loss:  0.28443360328674316
Epoch:  254  	Training Loss: 0.24589651823043823
Test Loss:  0.2799786329269409
Valid Loss:  0.2844335436820984
Epoch:  255  	Training Loss: 0.24589642882347107
Test Loss:  0.27997854351997375
Valid Loss:  0.2844334840774536
Epoch:  256  	Training Loss: 0.2458963692188263
Test Loss:  0.2799784541130066
Valid Loss:  0.28443336486816406
Epoch:  257  	Training Loss: 0.24589629471302032
Test Loss:  0.2799783945083618
Valid Loss:  0.2844332456588745
Epoch:  258  	Training Loss: 0.24589622020721436
Test Loss:  0.27997827529907227
Valid Loss:  0.28443318605422974
Epoch:  259  	Training Loss: 0.2458961457014084
Test Loss:  0.2799782156944275
Valid Loss:  0.2844330966472626
Epoch:  260  	Training Loss: 0.24589607119560242
Test Loss:  0.27997809648513794
Valid Loss:  0.2844330072402954
Epoch:  261  	Training Loss: 0.24589601159095764
Test Loss:  0.27997803688049316
Valid Loss:  0.28443294763565063
Epoch:  262  	Training Loss: 0.24589592218399048
Test Loss:  0.279977947473526
Valid Loss:  0.28443285822868347
Epoch:  263  	Training Loss: 0.2458958625793457
Test Loss:  0.27997785806655884
Valid Loss:  0.2844327390193939
Epoch:  264  	Training Loss: 0.24589578807353973
Test Loss:  0.27997779846191406
Valid Loss:  0.28443264961242676
Epoch:  265  	Training Loss: 0.24589571356773376
Test Loss:  0.2799776792526245
Valid Loss:  0.284432590007782
Epoch:  266  	Training Loss: 0.245895653963089
Test Loss:  0.27997761964797974
Valid Loss:  0.28443247079849243
Epoch:  267  	Training Loss: 0.24589556455612183
Test Loss:  0.2799775302410126
Valid Loss:  0.28443238139152527
Epoch:  268  	Training Loss: 0.24589550495147705
Test Loss:  0.2799774408340454
Valid Loss:  0.2844322919845581
Epoch:  269  	Training Loss: 0.24589544534683228
Test Loss:  0.27997732162475586
Valid Loss:  0.28443223237991333
Epoch:  270  	Training Loss: 0.2458953559398651
Test Loss:  0.2799772620201111
Valid Loss:  0.2844321131706238
Epoch:  271  	Training Loss: 0.24589528143405914
Test Loss:  0.2799772024154663
Valid Loss:  0.284432053565979
Epoch:  272  	Training Loss: 0.24589520692825317
Test Loss:  0.27997708320617676
Valid Loss:  0.28443196415901184
Epoch:  273  	Training Loss: 0.2458951324224472
Test Loss:  0.279977023601532
Valid Loss:  0.2844318747520447
Epoch:  274  	Training Loss: 0.24589507281780243
Test Loss:  0.27997690439224243
Valid Loss:  0.2844317853450775
Epoch:  275  	Training Loss: 0.24589499831199646
Test Loss:  0.27997684478759766
Valid Loss:  0.28443169593811035
Epoch:  276  	Training Loss: 0.2458949238061905
Test Loss:  0.2799767553806305
Valid Loss:  0.2844316363334656
Epoch:  277  	Training Loss: 0.24589484930038452
Test Loss:  0.27997666597366333
Valid Loss:  0.2844315469264984
Epoch:  278  	Training Loss: 0.24589478969573975
Test Loss:  0.27997657656669617
Valid Loss:  0.28443145751953125
Epoch:  279  	Training Loss: 0.24589471518993378
Test Loss:  0.279976487159729
Valid Loss:  0.2844313383102417
Epoch:  280  	Training Loss: 0.2458946406841278
Test Loss:  0.27997639775276184
Valid Loss:  0.2844312787055969
Epoch:  281  	Training Loss: 0.24589456617832184
Test Loss:  0.27997633814811707
Valid Loss:  0.28443118929862976
Epoch:  282  	Training Loss: 0.24589449167251587
Test Loss:  0.2799762487411499
Valid Loss:  0.2844310998916626
Epoch:  283  	Training Loss: 0.2458944171667099
Test Loss:  0.27997615933418274
Valid Loss:  0.2844310402870178
Epoch:  284  	Training Loss: 0.24589435756206512
Test Loss:  0.2799760699272156
Valid Loss:  0.28443092107772827
Epoch:  285  	Training Loss: 0.24589428305625916
Test Loss:  0.2799760103225708
Valid Loss:  0.2844308614730835
Epoch:  286  	Training Loss: 0.24589420855045319
Test Loss:  0.27997589111328125
Valid Loss:  0.28443074226379395
Epoch:  287  	Training Loss: 0.24589413404464722
Test Loss:  0.2799758017063141
Valid Loss:  0.2844306528568268
Epoch:  288  	Training Loss: 0.24589407444000244
Test Loss:  0.2799757122993469
Valid Loss:  0.2844305634498596
Epoch:  289  	Training Loss: 0.24589398503303528
Test Loss:  0.27997565269470215
Valid Loss:  0.28443047404289246
Epoch:  290  	Training Loss: 0.2458939254283905
Test Loss:  0.2799755334854126
Valid Loss:  0.2844303846359253
Epoch:  291  	Training Loss: 0.24589385092258453
Test Loss:  0.2799754738807678
Valid Loss:  0.2844303250312805
Epoch:  292  	Training Loss: 0.24589377641677856
Test Loss:  0.27997538447380066
Valid Loss:   58%|█████▊    | 292/500 [03:27<04:07,  1.19s/it] 59%|█████▉    | 294/500 [03:27<02:56,  1.17it/s] 59%|█████▉    | 296/500 [03:27<02:07,  1.60it/s] 60%|█████▉    | 298/500 [03:27<01:33,  2.15it/s] 60%|██████    | 300/500 [03:28<01:09,  2.90it/s] 60%|██████    | 302/500 [03:34<03:55,  1.19s/it] 61%|██████    | 304/500 [03:34<02:47,  1.17it/s] 61%|██████    | 306/500 [03:34<02:00,  1.62it/s] 62%|██████▏   | 308/500 [03:34<01:27,  2.19it/s] 62%|██████▏   | 310/500 [03:34<01:04,  2.94it/s] 62%|██████▏   | 312/500 [03:41<03:44,  1.20s/it] 63%|██████▎   | 314/500 [03:41<02:39,  1.16it/s] 63%|██████▎   | 316/500 [03:41<01:54,  1.61it/s] 64%|██████▎   | 318/500 [03:41<01:22,  2.20it/s] 64%|██████▍   | 320/500 [03:41<01:00,  2.96it/s] 64%|██████▍   | 322/500 [03:48<03:32,  1.19s/it] 65%|██████▍   | 324/500 [03:48<02:30,  1.17it/s] 65%|██████▌   | 326/500 [03:48<01:47,  1.62it/s] 66%|██████▌   | 328/500 [03:48<01:17,  2.21it/s] 66%|██████▌   | 330/500 [03:48<00:57,  2.97it/s] 66%|██████▋   | 332/500 [03:55<03:18,  1.18s/it] 67%|██████▋   | 334/500 [03:55<02:20,  1.18it/s] 67%|██████▋   | 336/500 [03:55<01:40,  1.64it/s] 68%|██████▊   | 338/500 [03:55<01:12,  2.24it/s] 68%|██████▊   | 340/500 [03:55<00:53,  3.01it/s] 68%|██████▊   | 342/500 [04:01<03:08,  1.19s/it] 69%|██████▉   | 344/500 [04:02<02:13,  1.17it/s] 69%|██████▉   | 346/500 [04:02<01:35,  1.62it/s] 70%|██████▉   | 348/500 [04:02<01:08,  2.21it/s] 70%|███████   | 350/500 [04:02<00:50,  2.97it/s] 70%|███████   | 352/500 [04:08<02:52,  1.17s/it] 71%|███████   | 354/500 [04:08<02:02,  1.19it/s] 71%|███████   | 356/500 [04:08<01:27,  1.65it/s] 72%|███████▏  | 358/500 [04:09<01:03,  2.25it/s] 72%|███████▏  | 360/500 [04:09<00:46,  3.02it/s] 72%|███████▏  | 362/500 [04:15<02:45,  1.20s/it] 73%|███████▎  | 364/500 [04:15<01:56,  1.16it/s]0.28443020582199097
Epoch:  293  	Training Loss: 0.2458937168121338
Test Loss:  0.2799752950668335
Valid Loss:  0.2844301462173462
Epoch:  294  	Training Loss: 0.24589362740516663
Test Loss:  0.27997520565986633
Valid Loss:  0.28443005681037903
Epoch:  295  	Training Loss: 0.24589356780052185
Test Loss:  0.27997511625289917
Valid Loss:  0.28442996740341187
Epoch:  296  	Training Loss: 0.24589350819587708
Test Loss:  0.2799750566482544
Valid Loss:  0.2844298481941223
Epoch:  297  	Training Loss: 0.2458934336900711
Test Loss:  0.27997493743896484
Valid Loss:  0.28442978858947754
Epoch:  298  	Training Loss: 0.24589335918426514
Test Loss:  0.27997487783432007
Valid Loss:  0.2844296991825104
Epoch:  299  	Training Loss: 0.24589328467845917
Test Loss:  0.2799747884273529
Valid Loss:  0.2844296097755432
Epoch:  300  	Training Loss: 0.245893195271492
Test Loss:  0.27997469902038574
Valid Loss:  0.28442952036857605
Epoch:  301  	Training Loss: 0.24589312076568604
Test Loss:  0.2799746096134186
Valid Loss:  0.2844294309616089
Epoch:  302  	Training Loss: 0.24589306116104126
Test Loss:  0.2799745202064514
Valid Loss:  0.2844293415546417
Epoch:  303  	Training Loss: 0.24589300155639648
Test Loss:  0.27997446060180664
Valid Loss:  0.28442928194999695
Epoch:  304  	Training Loss: 0.24589291214942932
Test Loss:  0.2799743711948395
Valid Loss:  0.2844291925430298
Epoch:  305  	Training Loss: 0.24589283764362335
Test Loss:  0.2799742817878723
Valid Loss:  0.28442907333374023
Epoch:  306  	Training Loss: 0.24589276313781738
Test Loss:  0.27997419238090515
Valid Loss:  0.28442901372909546
Epoch:  307  	Training Loss: 0.2458927035331726
Test Loss:  0.279974102973938
Valid Loss:  0.2844289243221283
Epoch:  308  	Training Loss: 0.24589264392852783
Test Loss:  0.27997398376464844
Valid Loss:  0.28442883491516113
Epoch:  309  	Training Loss: 0.24589256942272186
Test Loss:  0.27997392416000366
Valid Loss:  0.28442874550819397
Epoch:  310  	Training Loss: 0.2458924949169159
Test Loss:  0.2799738645553589
Valid Loss:  0.2844286561012268
Epoch:  311  	Training Loss: 0.24589242041110992
Test Loss:  0.2799737751483917
Valid Loss:  0.28442853689193726
Epoch:  312  	Training Loss: 0.24589236080646515
Test Loss:  0.27997368574142456
Valid Loss:  0.2844284772872925
Epoch:  313  	Training Loss: 0.24589228630065918
Test Loss:  0.279973566532135
Valid Loss:  0.28442835807800293
Epoch:  314  	Training Loss: 0.24589219689369202
Test Loss:  0.27997347712516785
Valid Loss:  0.28442829847335815
Epoch:  315  	Training Loss: 0.24589213728904724
Test Loss:  0.27997341752052307
Valid Loss:  0.2844282388687134
Epoch:  316  	Training Loss: 0.24589204788208008
Test Loss:  0.2799733281135559
Valid Loss:  0.28442811965942383
Epoch:  317  	Training Loss: 0.2458919882774353
Test Loss:  0.27997323870658875
Valid Loss:  0.28442806005477905
Epoch:  318  	Training Loss: 0.24589192867279053
Test Loss:  0.2799731492996216
Valid Loss:  0.2844279408454895
Epoch:  319  	Training Loss: 0.24589183926582336
Test Loss:  0.2799730598926544
Valid Loss:  0.2844278812408447
Epoch:  320  	Training Loss: 0.2458917796611786
Test Loss:  0.27997297048568726
Valid Loss:  0.2844277620315552
Epoch:  321  	Training Loss: 0.2458917200565338
Test Loss:  0.2799728810787201
Valid Loss:  0.2844277024269104
Epoch:  322  	Training Loss: 0.24589163064956665
Test Loss:  0.27997279167175293
Valid Loss:  0.28442758321762085
Epoch:  323  	Training Loss: 0.2458915412425995
Test Loss:  0.27997270226478577
Valid Loss:  0.2844275236129761
Epoch:  324  	Training Loss: 0.2458914816379547
Test Loss:  0.2799726128578186
Valid Loss:  0.2844274342060089
Epoch:  325  	Training Loss: 0.24589142203330994
Test Loss:  0.27997255325317383
Valid Loss:  0.28442734479904175
Epoch:  326  	Training Loss: 0.24589134752750397
Test Loss:  0.27997249364852905
Valid Loss:  0.2844272553920746
Epoch:  327  	Training Loss: 0.245891273021698
Test Loss:  0.2799723744392395
Valid Loss:  0.2844271659851074
Epoch:  328  	Training Loss: 0.24589119851589203
Test Loss:  0.2799723148345947
Valid Loss:  0.28442707657814026
Epoch:  329  	Training Loss: 0.24589112401008606
Test Loss:  0.2799721956253052
Valid Loss:  0.2844269871711731
Epoch:  330  	Training Loss: 0.24589106440544128
Test Loss:  0.2799721360206604
Valid Loss:  0.2844269275665283
Epoch:  331  	Training Loss: 0.24589097499847412
Test Loss:  0.27997201681137085
Valid Loss:  0.28442680835723877
Epoch:  332  	Training Loss: 0.24589091539382935
Test Loss:  0.2799719572067261
Valid Loss:  0.284426748752594
Epoch:  333  	Training Loss: 0.24589082598686218
Test Loss:  0.2799718677997589
Valid Loss:  0.28442665934562683
Epoch:  334  	Training Loss: 0.2458907663822174
Test Loss:  0.27997177839279175
Valid Loss:  0.28442656993865967
Epoch:  335  	Training Loss: 0.24589070677757263
Test Loss:  0.279971718788147
Valid Loss:  0.2844264507293701
Epoch:  336  	Training Loss: 0.24589064717292786
Test Loss:  0.2799715995788574
Valid Loss:  0.28442639112472534
Epoch:  337  	Training Loss: 0.2458905577659607
Test Loss:  0.27997153997421265
Valid Loss:  0.2844263017177582
Epoch:  338  	Training Loss: 0.24589048326015472
Test Loss:  0.2799714207649231
Valid Loss:  0.284426212310791
Epoch:  339  	Training Loss: 0.24589040875434875
Test Loss:  0.2799713611602783
Valid Loss:  0.28442612290382385
Epoch:  340  	Training Loss: 0.24589033424854279
Test Loss:  0.27997127175331116
Valid Loss:  0.2844260334968567
Epoch:  341  	Training Loss: 0.24589025974273682
Test Loss:  0.279971182346344
Valid Loss:  0.2844259738922119
Epoch:  342  	Training Loss: 0.24589020013809204
Test Loss:  0.2799711227416992
Valid Loss:  0.28442585468292236
Epoch:  343  	Training Loss: 0.24589014053344727
Test Loss:  0.27997100353240967
Valid Loss:  0.2844257652759552
Epoch:  344  	Training Loss: 0.2458900511264801
Test Loss:  0.2799709141254425
Valid Loss:  0.2844257056713104
Epoch:  345  	Training Loss: 0.24588999152183533
Test Loss:  0.27997085452079773
Valid Loss:  0.28442561626434326
Epoch:  346  	Training Loss: 0.24588990211486816
Test Loss:  0.27997076511383057
Valid Loss:  0.2844254970550537
Epoch:  347  	Training Loss: 0.2458898425102234
Test Loss:  0.279970645904541
Valid Loss:  0.28442543745040894
Epoch:  348  	Training Loss: 0.24588975310325623
Test Loss:  0.27997058629989624
Valid Loss:  0.2844253480434418
Epoch:  349  	Training Loss: 0.24588969349861145
Test Loss:  0.2799704968929291
Valid Loss:  0.2844252586364746
Epoch:  350  	Training Loss: 0.24588963389396667
Test Loss:  0.2799704074859619
Valid Loss:  0.28442516922950745
Epoch:  351  	Training Loss: 0.2458895593881607
Test Loss:  0.27997031807899475
Valid Loss:  0.2844250798225403
Epoch:  352  	Training Loss: 0.24588946998119354
Test Loss:  0.27997025847435
Valid Loss:  0.2844249904155731
Epoch:  353  	Training Loss: 0.24588941037654877
Test Loss:  0.2799701392650604
Valid Loss:  0.28442490100860596
Epoch:  354  	Training Loss: 0.2458893358707428
Test Loss:  0.27997007966041565
Valid Loss:  0.2844248414039612
Epoch:  355  	Training Loss: 0.24588926136493683
Test Loss:  0.2799699902534485
Valid Loss:  0.28442472219467163
Epoch:  356  	Training Loss: 0.24588918685913086
Test Loss:  0.2799699008464813
Valid Loss:  0.28442463278770447
Epoch:  357  	Training Loss: 0.2458891123533249
Test Loss:  0.27996981143951416
Valid Loss:  0.2844245433807373
Epoch:  358  	Training Loss: 0.24588905274868011
Test Loss:  0.279969722032547
Valid Loss:  0.28442448377609253
Epoch:  359  	Training Loss: 0.24588897824287415
Test Loss:  0.27996963262557983
Valid Loss:  0.284424364566803
Epoch:  360  	Training Loss: 0.24588890373706818
Test Loss:  0.27996957302093506
Valid Loss:  0.2844243049621582
Epoch:  361  	Training Loss: 0.2458888292312622
Test Loss:  0.2799694538116455
Valid Loss:  0.28442421555519104
Epoch:  362  	Training Loss: 0.24588876962661743
Test Loss:  0.27996936440467834
Valid Loss:  0.2844241261482239
Epoch:  363  	Training Loss: 0.24588868021965027
Test Loss:  0.2799692749977112
Valid Loss:  0.2844240367412567
Epoch:  364  	Training Loss: 0.2458886206150055
Test Loss:  0.2799692153930664
Valid Loss:  0.28442394733428955
Epoch:  365  	Training Loss: 0.24588853120803833
Test Loss:   73%|███████▎  | 366/500 [04:15<01:23,  1.61it/s] 74%|███████▎  | 368/500 [04:16<00:59,  2.20it/s] 74%|███████▍  | 370/500 [04:16<00:43,  2.96it/s] 74%|███████▍  | 372/500 [04:22<02:31,  1.18s/it] 75%|███████▍  | 374/500 [04:22<01:46,  1.18it/s] 75%|███████▌  | 376/500 [04:22<01:16,  1.63it/s] 76%|███████▌  | 378/500 [04:22<00:54,  2.23it/s] 76%|███████▌  | 380/500 [04:23<00:40,  3.00it/s] 76%|███████▋  | 382/500 [04:29<02:20,  1.19s/it] 77%|███████▋  | 384/500 [04:29<01:39,  1.17it/s] 77%|███████▋  | 386/500 [04:29<01:10,  1.62it/s] 78%|███████▊  | 388/500 [04:29<00:50,  2.22it/s] 78%|███████▊  | 390/500 [04:29<00:36,  2.98it/s] 78%|███████▊  | 392/500 [04:36<02:09,  1.19s/it] 79%|███████▉  | 394/500 [04:36<01:30,  1.17it/s] 79%|███████▉  | 396/500 [04:36<01:04,  1.62it/s] 80%|███████▉  | 398/500 [04:36<00:46,  2.21it/s] 80%|████████  | 400/500 [04:36<00:33,  2.96it/s] 80%|████████  | 402/500 [04:43<01:55,  1.18s/it] 81%|████████  | 404/500 [04:43<01:20,  1.19it/s] 81%|████████  | 406/500 [04:43<00:57,  1.64it/s] 82%|████████▏ | 408/500 [04:43<00:41,  2.24it/s] 82%|████████▏ | 410/500 [04:43<00:29,  3.01it/s] 82%|████████▏ | 412/500 [04:49<01:43,  1.18s/it] 83%|████████▎ | 414/500 [04:50<01:12,  1.18it/s] 83%|████████▎ | 416/500 [04:50<00:51,  1.64it/s] 84%|████████▎ | 418/500 [04:50<00:36,  2.24it/s] 84%|████████▍ | 420/500 [04:50<00:26,  3.01it/s] 84%|████████▍ | 422/500 [04:56<01:31,  1.17s/it] 85%|████████▍ | 424/500 [04:56<01:03,  1.19it/s] 85%|████████▌ | 426/500 [04:57<00:44,  1.65it/s] 86%|████████▌ | 428/500 [04:57<00:31,  2.25it/s] 86%|████████▌ | 430/500 [04:57<00:23,  3.03it/s] 86%|████████▋ | 432/500 [05:03<01:19,  1.17s/it] 87%|████████▋ | 434/500 [05:03<00:55,  1.19it/s] 87%|████████▋ | 436/500 [05:03<00:38,  1.64it/s]0.27996912598609924
Valid Loss:  0.2844238579273224
Epoch:  366  	Training Loss: 0.24588848650455475
Test Loss:  0.2799690365791321
Valid Loss:  0.2844237685203552
Epoch:  367  	Training Loss: 0.24588839709758759
Test Loss:  0.2799689769744873
Valid Loss:  0.28442370891571045
Epoch:  368  	Training Loss: 0.245888352394104
Test Loss:  0.27996885776519775
Valid Loss:  0.2844235897064209
Epoch:  369  	Training Loss: 0.24588826298713684
Test Loss:  0.279968798160553
Valid Loss:  0.2844235301017761
Epoch:  370  	Training Loss: 0.24588818848133087
Test Loss:  0.2799687087535858
Valid Loss:  0.2844234108924866
Epoch:  371  	Training Loss: 0.2458881139755249
Test Loss:  0.27996861934661865
Valid Loss:  0.2844233512878418
Epoch:  372  	Training Loss: 0.24588803946971893
Test Loss:  0.2799685001373291
Valid Loss:  0.28442326188087463
Epoch:  373  	Training Loss: 0.24588797986507416
Test Loss:  0.2799684405326843
Valid Loss:  0.2844231426715851
Epoch:  374  	Training Loss: 0.2458879053592682
Test Loss:  0.27996835112571716
Valid Loss:  0.2844230532646179
Epoch:  375  	Training Loss: 0.24588783085346222
Test Loss:  0.27996826171875
Valid Loss:  0.28442299365997314
Epoch:  376  	Training Loss: 0.24588777124881744
Test Loss:  0.2799682021141052
Valid Loss:  0.284422904253006
Epoch:  377  	Training Loss: 0.24588769674301147
Test Loss:  0.2799680829048157
Valid Loss:  0.2844228148460388
Epoch:  378  	Training Loss: 0.2458876073360443
Test Loss:  0.2799680233001709
Valid Loss:  0.28442272543907166
Epoch:  379  	Training Loss: 0.24588754773139954
Test Loss:  0.27996790409088135
Valid Loss:  0.2844226360321045
Epoch:  380  	Training Loss: 0.24588747322559357
Test Loss:  0.2799678444862366
Valid Loss:  0.28442254662513733
Epoch:  381  	Training Loss: 0.2458873987197876
Test Loss:  0.2799677550792694
Valid Loss:  0.28442248702049255
Epoch:  382  	Training Loss: 0.24588733911514282
Test Loss:  0.27996766567230225
Valid Loss:  0.284422367811203
Epoch:  383  	Training Loss: 0.24588724970817566
Test Loss:  0.27996760606765747
Valid Loss:  0.2844223082065582
Epoch:  384  	Training Loss: 0.24588719010353088
Test Loss:  0.2799674868583679
Valid Loss:  0.28442221879959106
Epoch:  385  	Training Loss: 0.24588711559772491
Test Loss:  0.27996739745140076
Valid Loss:  0.2844221293926239
Epoch:  386  	Training Loss: 0.24588705599308014
Test Loss:  0.279967337846756
Valid Loss:  0.28442203998565674
Epoch:  387  	Training Loss: 0.24588695168495178
Test Loss:  0.2799672484397888
Valid Loss:  0.2844219207763672
Epoch:  388  	Training Loss: 0.2458869069814682
Test Loss:  0.27996718883514404
Valid Loss:  0.2844218611717224
Epoch:  389  	Training Loss: 0.24588683247566223
Test Loss:  0.2799670696258545
Valid Loss:  0.28442174196243286
Epoch:  390  	Training Loss: 0.24588677287101746
Test Loss:  0.2799670100212097
Valid Loss:  0.2844216823577881
Epoch:  391  	Training Loss: 0.2458866834640503
Test Loss:  0.27996689081192017
Valid Loss:  0.2844215929508209
Epoch:  392  	Training Loss: 0.24588660895824432
Test Loss:  0.279966801404953
Valid Loss:  0.28442150354385376
Epoch:  393  	Training Loss: 0.24588653445243835
Test Loss:  0.27996671199798584
Valid Loss:  0.284421443939209
Epoch:  394  	Training Loss: 0.24588645994663239
Test Loss:  0.27996665239334106
Valid Loss:  0.2844213545322418
Epoch:  395  	Training Loss: 0.2458864152431488
Test Loss:  0.2799665331840515
Valid Loss:  0.28442123532295227
Epoch:  396  	Training Loss: 0.24588632583618164
Test Loss:  0.27996647357940674
Valid Loss:  0.2844211459159851
Epoch:  397  	Training Loss: 0.24588625133037567
Test Loss:  0.2799663543701172
Valid Loss:  0.28442108631134033
Epoch:  398  	Training Loss: 0.2458861768245697
Test Loss:  0.2799662947654724
Valid Loss:  0.28442099690437317
Epoch:  399  	Training Loss: 0.24588610231876373
Test Loss:  0.27996623516082764
Valid Loss:  0.284420907497406
Epoch:  400  	Training Loss: 0.24588602781295776
Test Loss:  0.2799661159515381
Valid Loss:  0.28442081809043884
Epoch:  401  	Training Loss: 0.245885968208313
Test Loss:  0.2799660265445709
Valid Loss:  0.2844207286834717
Epoch:  402  	Training Loss: 0.24588589370250702
Test Loss:  0.27996593713760376
Valid Loss:  0.28442060947418213
Epoch:  403  	Training Loss: 0.24588583409786224
Test Loss:  0.279965877532959
Valid Loss:  0.28442054986953735
Epoch:  404  	Training Loss: 0.24588575959205627
Test Loss:  0.27996575832366943
Valid Loss:  0.2844204604625702
Epoch:  405  	Training Loss: 0.2458856701850891
Test Loss:  0.27996569871902466
Valid Loss:  0.284420371055603
Epoch:  406  	Training Loss: 0.24588561058044434
Test Loss:  0.2799656391143799
Valid Loss:  0.28442031145095825
Epoch:  407  	Training Loss: 0.24588553607463837
Test Loss:  0.27996551990509033
Valid Loss:  0.2844201922416687
Epoch:  408  	Training Loss: 0.2458854615688324
Test Loss:  0.27996546030044556
Valid Loss:  0.28442007303237915
Epoch:  409  	Training Loss: 0.24588540196418762
Test Loss:  0.279965341091156
Valid Loss:  0.2844200134277344
Epoch:  410  	Training Loss: 0.24588534235954285
Test Loss:  0.27996525168418884
Valid Loss:  0.2844199538230896
Epoch:  411  	Training Loss: 0.24588525295257568
Test Loss:  0.27996522188186646
Valid Loss:  0.28441983461380005
Epoch:  412  	Training Loss: 0.2458851933479309
Test Loss:  0.2799651026725769
Valid Loss:  0.2844197750091553
Epoch:  413  	Training Loss: 0.24588510394096375
Test Loss:  0.27996501326560974
Valid Loss:  0.2844196557998657
Epoch:  414  	Training Loss: 0.24588502943515778
Test Loss:  0.2799649238586426
Valid Loss:  0.28441959619522095
Epoch:  415  	Training Loss: 0.245884969830513
Test Loss:  0.2799648344516754
Valid Loss:  0.2844194769859314
Epoch:  416  	Training Loss: 0.24588489532470703
Test Loss:  0.27996477484703064
Valid Loss:  0.2844194173812866
Epoch:  417  	Training Loss: 0.24588483572006226
Test Loss:  0.2799646556377411
Valid Loss:  0.28441932797431946
Epoch:  418  	Training Loss: 0.2458847463130951
Test Loss:  0.2799645960330963
Valid Loss:  0.2844192385673523
Epoch:  419  	Training Loss: 0.24588468670845032
Test Loss:  0.27996450662612915
Valid Loss:  0.28441914916038513
Epoch:  420  	Training Loss: 0.24588461220264435
Test Loss:  0.2799643874168396
Valid Loss:  0.28441905975341797
Epoch:  421  	Training Loss: 0.24588453769683838
Test Loss:  0.2799643278121948
Valid Loss:  0.2844190001487732
Epoch:  422  	Training Loss: 0.2458844780921936
Test Loss:  0.27996423840522766
Valid Loss:  0.28441888093948364
Epoch:  423  	Training Loss: 0.24588440358638763
Test Loss:  0.2799641489982605
Valid Loss:  0.2844187915325165
Epoch:  424  	Training Loss: 0.24588431417942047
Test Loss:  0.2799640893936157
Valid Loss:  0.2844187021255493
Epoch:  425  	Training Loss: 0.2458842396736145
Test Loss:  0.27996397018432617
Valid Loss:  0.28441861271858215
Epoch:  426  	Training Loss: 0.24588416516780853
Test Loss:  0.2799639105796814
Valid Loss:  0.284418523311615
Epoch:  427  	Training Loss: 0.24588412046432495
Test Loss:  0.27996382117271423
Valid Loss:  0.2844184637069702
Epoch:  428  	Training Loss: 0.2458840310573578
Test Loss:  0.27996373176574707
Valid Loss:  0.28441840410232544
Epoch:  429  	Training Loss: 0.24588394165039062
Test Loss:  0.2799636423587799
Valid Loss:  0.2844182848930359
Epoch:  430  	Training Loss: 0.24588388204574585
Test Loss:  0.27996355295181274
Valid Loss:  0.2844181954860687
Epoch:  431  	Training Loss: 0.24588382244110107
Test Loss:  0.2799634635448456
Valid Loss:  0.28441810607910156
Epoch:  432  	Training Loss: 0.2458837628364563
Test Loss:  0.2799633741378784
Valid Loss:  0.284417986869812
Epoch:  433  	Training Loss: 0.24588367342948914
Test Loss:  0.27996331453323364
Valid Loss:  0.28441792726516724
Epoch:  434  	Training Loss: 0.24588358402252197
Test Loss:  0.2799631953239441
Valid Loss:  0.2844178378582001
Epoch:  435  	Training Loss: 0.2458835393190384
Test Loss:  0.2799631357192993
Valid Loss:  0.2844177484512329
Epoch:  436  	Training Loss: 0.24588346481323242
Test Loss:  0.27996304631233215
Valid Loss:  0.28441768884658813
Epoch:  437  	Training Loss: 0.24588337540626526
Test Loss:  0.279962956905365
Valid Loss:  0.2844175696372986
Epoch:  438  	Training Loss: 0.24588331580162048
 88%|████████▊ | 438/500 [05:03<00:27,  2.24it/s] 88%|████████▊ | 440/500 [05:04<00:19,  3.01it/s] 88%|████████▊ | 442/500 [05:10<01:07,  1.16s/it] 89%|████████▉ | 444/500 [05:10<00:46,  1.20it/s] 89%|████████▉ | 446/500 [05:10<00:32,  1.66it/s] 90%|████████▉ | 448/500 [05:10<00:22,  2.26it/s] 90%|█████████ | 450/500 [05:10<00:16,  3.03it/s] 90%|█████████ | 452/500 [05:17<00:57,  1.20s/it] 91%|█████████ | 454/500 [05:17<00:39,  1.16it/s] 91%|█████████ | 456/500 [05:17<00:27,  1.60it/s] 92%|█████████▏| 458/500 [05:17<00:19,  2.19it/s] 92%|█████████▏| 460/500 [05:17<00:13,  2.94it/s] 92%|█████████▏| 462/500 [05:24<00:44,  1.18s/it] 93%|█████████▎| 464/500 [05:24<00:30,  1.18it/s] 93%|█████████▎| 466/500 [05:24<00:20,  1.63it/s] 94%|█████████▎| 468/500 [05:24<00:14,  2.22it/s] 94%|█████████▍| 470/500 [05:24<00:10,  2.98it/s] 94%|█████████▍| 472/500 [05:31<00:34,  1.22s/it] 95%|█████████▍| 474/500 [05:31<00:22,  1.14it/s] 95%|█████████▌| 476/500 [05:31<00:15,  1.58it/s] 96%|█████████▌| 478/500 [05:31<00:10,  2.17it/s] 96%|█████████▌| 480/500 [05:31<00:06,  2.92it/s] 96%|█████████▋| 482/500 [05:38<00:21,  1.21s/it] 97%|█████████▋| 484/500 [05:38<00:13,  1.15it/s] 97%|█████████▋| 486/500 [05:38<00:08,  1.59it/s] 98%|█████████▊| 488/500 [05:38<00:05,  2.18it/s] 98%|█████████▊| 490/500 [05:38<00:03,  2.93it/s] 98%|█████████▊| 492/500 [05:45<00:09,  1.20s/it] 99%|█████████▉| 494/500 [05:45<00:05,  1.16it/s] 99%|█████████▉| 496/500 [05:45<00:02,  1.60it/s]100%|█████████▉| 498/500 [05:45<00:00,  2.19it/s]100%|██████████| 500/500 [05:45<00:00,  2.95it/s]100%|██████████| 500/500 [05:45<00:00,  1.45it/s]
Test Loss:  0.2799628674983978
Valid Loss:  0.2844175100326538
Epoch:  439  	Training Loss: 0.2458832561969757
Test Loss:  0.27996280789375305
Valid Loss:  0.28441739082336426
Epoch:  440  	Training Loss: 0.24588318169116974
Test Loss:  0.2799627184867859
Valid Loss:  0.2844173312187195
Epoch:  441  	Training Loss: 0.24588310718536377
Test Loss:  0.27996259927749634
Valid Loss:  0.2844172418117523
Epoch:  442  	Training Loss: 0.2458830177783966
Test Loss:  0.27996253967285156
Valid Loss:  0.28441715240478516
Epoch:  443  	Training Loss: 0.24588295817375183
Test Loss:  0.279962420463562
Valid Loss:  0.2844170331954956
Epoch:  444  	Training Loss: 0.24588286876678467
Test Loss:  0.27996233105659485
Valid Loss:  0.28441697359085083
Epoch:  445  	Training Loss: 0.2458828091621399
Test Loss:  0.2799622714519501
Valid Loss:  0.28441688418388367
Epoch:  446  	Training Loss: 0.24588274955749512
Test Loss:  0.2799621820449829
Valid Loss:  0.2844167947769165
Epoch:  447  	Training Loss: 0.24588267505168915
Test Loss:  0.27996209263801575
Valid Loss:  0.28441673517227173
Epoch:  448  	Training Loss: 0.24588258564472198
Test Loss:  0.2799620032310486
Valid Loss:  0.2844166159629822
Epoch:  449  	Training Loss: 0.2458825260400772
Test Loss:  0.2799619138240814
Valid Loss:  0.284416526556015
Epoch:  450  	Training Loss: 0.24588245153427124
Test Loss:  0.27996185421943665
Valid Loss:  0.28441643714904785
Epoch:  451  	Training Loss: 0.24588239192962646
Test Loss:  0.2799617648124695
Valid Loss:  0.2844163775444031
Epoch:  452  	Training Loss: 0.2458823025226593
Test Loss:  0.27996164560317993
Valid Loss:  0.2844162583351135
Epoch:  453  	Training Loss: 0.24588224291801453
Test Loss:  0.27996158599853516
Valid Loss:  0.28441619873046875
Epoch:  454  	Training Loss: 0.24588218331336975
Test Loss:  0.279961496591568
Valid Loss:  0.2844160795211792
Epoch:  455  	Training Loss: 0.24588210880756378
Test Loss:  0.27996140718460083
Valid Loss:  0.2844160199165344
Epoch:  456  	Training Loss: 0.2458820343017578
Test Loss:  0.27996134757995605
Valid Loss:  0.2844159007072449
Epoch:  457  	Training Loss: 0.24588195979595184
Test Loss:  0.2799612283706665
Valid Loss:  0.2844158411026001
Epoch:  458  	Training Loss: 0.24588188529014587
Test Loss:  0.27996116876602173
Valid Loss:  0.28441575169563293
Epoch:  459  	Training Loss: 0.2458818107843399
Test Loss:  0.2799610495567322
Valid Loss:  0.28441566228866577
Epoch:  460  	Training Loss: 0.24588173627853394
Test Loss:  0.2799609899520874
Valid Loss:  0.2844155728816986
Epoch:  461  	Training Loss: 0.24588167667388916
Test Loss:  0.27996087074279785
Valid Loss:  0.28441548347473145
Epoch:  462  	Training Loss: 0.2458816021680832
Test Loss:  0.2799608111381531
Valid Loss:  0.28441542387008667
Epoch:  463  	Training Loss: 0.24588152766227722
Test Loss:  0.2799607515335083
Valid Loss:  0.2844153046607971
Epoch:  464  	Training Loss: 0.24588146805763245
Test Loss:  0.27996063232421875
Valid Loss:  0.28441524505615234
Epoch:  465  	Training Loss: 0.24588139355182648
Test Loss:  0.279960572719574
Valid Loss:  0.2844151556491852
Epoch:  466  	Training Loss: 0.24588130414485931
Test Loss:  0.2799604833126068
Valid Loss:  0.284415066242218
Epoch:  467  	Training Loss: 0.24588122963905334
Test Loss:  0.27996039390563965
Valid Loss:  0.28441494703292847
Epoch:  468  	Training Loss: 0.24588117003440857
Test Loss:  0.2799602746963501
Valid Loss:  0.2844148874282837
Epoch:  469  	Training Loss: 0.2458810955286026
Test Loss:  0.2799602150917053
Valid Loss:  0.2844148278236389
Epoch:  470  	Training Loss: 0.24588102102279663
Test Loss:  0.27996012568473816
Valid Loss:  0.28441470861434937
Epoch:  471  	Training Loss: 0.24588094651699066
Test Loss:  0.279960036277771
Valid Loss:  0.2844146192073822
Epoch:  472  	Training Loss: 0.2458808720111847
Test Loss:  0.27995994687080383
Valid Loss:  0.28441452980041504
Epoch:  473  	Training Loss: 0.24588081240653992
Test Loss:  0.27995985746383667
Valid Loss:  0.2844144403934479
Epoch:  474  	Training Loss: 0.24588073790073395
Test Loss:  0.2799597680568695
Valid Loss:  0.2844143509864807
Epoch:  475  	Training Loss: 0.24588066339492798
Test Loss:  0.27995967864990234
Valid Loss:  0.28441429138183594
Epoch:  476  	Training Loss: 0.245880588889122
Test Loss:  0.27995961904525757
Valid Loss:  0.2844141721725464
Epoch:  477  	Training Loss: 0.24588052928447723
Test Loss:  0.2799595296382904
Valid Loss:  0.2844140827655792
Epoch:  478  	Training Loss: 0.24588045477867126
Test Loss:  0.27995944023132324
Valid Loss:  0.28441402316093445
Epoch:  479  	Training Loss: 0.2458803653717041
Test Loss:  0.27995938062667847
Valid Loss:  0.2844139337539673
Epoch:  480  	Training Loss: 0.24588030576705933
Test Loss:  0.2799592614173889
Valid Loss:  0.28441381454467773
Epoch:  481  	Training Loss: 0.24588023126125336
Test Loss:  0.27995920181274414
Valid Loss:  0.28441375494003296
Epoch:  482  	Training Loss: 0.2458801567554474
Test Loss:  0.2799590826034546
Valid Loss:  0.2844136953353882
Epoch:  483  	Training Loss: 0.2458800971508026
Test Loss:  0.2799590229988098
Valid Loss:  0.28441357612609863
Epoch:  484  	Training Loss: 0.24588002264499664
Test Loss:  0.27995893359184265
Valid Loss:  0.28441351652145386
Epoch:  485  	Training Loss: 0.24587994813919067
Test Loss:  0.2799588441848755
Valid Loss:  0.2844133973121643
Epoch:  486  	Training Loss: 0.2458798736333847
Test Loss:  0.2799587845802307
Valid Loss:  0.28441333770751953
Epoch:  487  	Training Loss: 0.24587979912757874
Test Loss:  0.27995866537094116
Valid Loss:  0.28441321849823
Epoch:  488  	Training Loss: 0.24587973952293396
Test Loss:  0.279958575963974
Valid Loss:  0.2844131290912628
Epoch:  489  	Training Loss: 0.245879665017128
Test Loss:  0.27995848655700684
Valid Loss:  0.28441303968429565
Epoch:  490  	Training Loss: 0.24587959051132202
Test Loss:  0.27995842695236206
Valid Loss:  0.2844129502773285
Epoch:  491  	Training Loss: 0.24587953090667725
Test Loss:  0.2799583375453949
Valid Loss:  0.28441286087036133
Epoch:  492  	Training Loss: 0.24587944149971008
Test Loss:  0.27995824813842773
Valid Loss:  0.28441280126571655
Epoch:  493  	Training Loss: 0.2458793818950653
Test Loss:  0.27995815873146057
Valid Loss:  0.2844127118587494
Epoch:  494  	Training Loss: 0.24587929248809814
Test Loss:  0.2799580693244934
Valid Loss:  0.2844126224517822
Epoch:  495  	Training Loss: 0.24587923288345337
Test Loss:  0.27995795011520386
Valid Loss:  0.28441253304481506
Epoch:  496  	Training Loss: 0.2458791434764862
Test Loss:  0.2799578905105591
Valid Loss:  0.2844124436378479
Epoch:  497  	Training Loss: 0.24587908387184143
Test Loss:  0.2799578309059143
Valid Loss:  0.28441235423088074
Epoch:  498  	Training Loss: 0.24587900936603546
Test Loss:  0.27995771169662476
Valid Loss:  0.2844122648239136
Epoch:  499  	Training Loss: 0.2458789348602295
Test Loss:  0.27995765209198
Valid Loss:  0.2844122052192688
Epoch:  500  	Training Loss: 0.24587887525558472
Test Loss:  0.2799575626850128
Valid Loss:  0.28441208600997925
seed is  7
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:47,  6.23s/it]  1%|          | 3/500 [00:06<13:48,  1.67s/it]  1%|          | 5/500 [00:06<06:57,  1.19it/s]  1%|▏         | 7/500 [00:06<04:13,  1.95it/s]  2%|▏         | 9/500 [00:06<02:49,  2.90it/s]  2%|▏         | 11/500 [00:13<10:49,  1.33s/it]  3%|▎         | 13/500 [00:13<07:22,  1.10it/s]  3%|▎         | 15/500 [00:13<05:08,  1.57it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.97it/s]  4%|▍         | 21/500 [00:19<09:32,  1.19s/it]  5%|▍         | 23/500 [00:20<06:46,  1.17it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:32,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.01it/s]  6%|▌         | 31/500 [00:26<09:14,  1.18s/it]  7%|▋         | 33/500 [00:26<06:36,  1.18it/s]  7%|▋         | 35/500 [00:26<04:45,  1.63it/s]  7%|▋         | 37/500 [00:27<03:27,  2.23it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:33<09:04,  1.19s/it]  9%|▊         | 43/500 [00:33<06:29,  1.17it/s]  9%|▉         | 45/500 [00:33<04:40,  1.62it/s]  9%|▉         | 47/500 [00:34<03:24,  2.22it/s] 10%|▉         | 49/500 [00:34<02:31,  2.98it/s] 10%|█         | 51/500 [00:40<08:56,  1.19s/it] 11%|█         | 53/500 [00:40<06:23,  1.17it/s] 11%|█         | 55/500 [00:40<04:35,  1.61it/s] 11%|█▏        | 57/500 [00:40<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:41<02:28,  2.96it/s] 12%|█▏        | 61/500 [00:47<08:37,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:10,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:26,  1.63it/s] 13%|█▎        | 67/500 [00:47<03:14,  2.23it/s]Epoch:  1  	Training Loss: 0.2184741050004959
Test Loss:  0.35832643508911133
Valid Loss:  0.352261483669281
Epoch:  2  	Training Loss: 0.3933212161064148
Test Loss:  0.038091812282800674
Valid Loss:  0.037221573293209076
Epoch:  3  	Training Loss: 0.033761173486709595
Test Loss:  0.020228620618581772
Valid Loss:  0.01866735890507698
Epoch:  4  	Training Loss: 0.021798301488161087
Test Loss:  0.013931972905993462
Valid Loss:  0.013372920453548431
Epoch:  5  	Training Loss: 0.01430405955761671
Test Loss:  0.008558970876038074
Valid Loss:  0.007931159809231758
Epoch:  6  	Training Loss: 0.009881287813186646
Test Loss:  0.006059478502720594
Valid Loss:  0.005724871531128883
Epoch:  7  	Training Loss: 0.007063395343720913
Test Loss:  0.004384621046483517
Valid Loss:  0.004126444458961487
Epoch:  8  	Training Loss: 0.005326916463673115
Test Loss:  0.0033889985643327236
Valid Loss:  0.0032338006421923637
Epoch:  9  	Training Loss: 0.004167599603533745
Test Loss:  0.0025886748917400837
Valid Loss:  0.0024729017168283463
Epoch:  10  	Training Loss: 0.0033374817576259375
Test Loss:  0.0020853797905147076
Valid Loss:  0.0020230328664183617
Epoch:  11  	Training Loss: 0.0027376385405659676
Test Loss:  0.0017027901485562325
Valid Loss:  0.0016654847422614694
Epoch:  12  	Training Loss: 0.002301578177139163
Test Loss:  0.001408371957950294
Valid Loss:  0.0013708046171814203
Epoch:  13  	Training Loss: 0.0019646042492240667
Test Loss:  0.0012610796838998795
Valid Loss:  0.0012440853752195835
Epoch:  14  	Training Loss: 0.0017468687146902084
Test Loss:  0.0011011399328708649
Valid Loss:  0.0010877485619857907
Epoch:  15  	Training Loss: 0.0015450511127710342
Test Loss:  0.0010096419136971235
Valid Loss:  0.001011525746434927
Epoch:  16  	Training Loss: 0.0014034274499863386
Test Loss:  0.000920619408134371
Valid Loss:  0.0009185574017465115
Epoch:  17  	Training Loss: 0.0012984253698959947
Test Loss:  0.000853279372677207
Valid Loss:  0.0008713481947779655
Epoch:  18  	Training Loss: 0.0011796129401773214
Test Loss:  0.0007917510811239481
Valid Loss:  0.0008119286503642797
Epoch:  19  	Training Loss: 0.0010957851773127913
Test Loss:  0.0007397967856377363
Valid Loss:  0.0007628471357747912
Epoch:  20  	Training Loss: 0.0010266853496432304
Test Loss:  0.0006946803769096732
Valid Loss:  0.0007266057655215263
Epoch:  21  	Training Loss: 0.0009554191492497921
Test Loss:  0.0006586940144188702
Valid Loss:  0.0006945871282368898
Epoch:  22  	Training Loss: 0.000903594889678061
Test Loss:  0.000627541565336287
Valid Loss:  0.0006787594174966216
Epoch:  23  	Training Loss: 0.0008371182484552264
Test Loss:  0.0005907529266551137
Valid Loss:  0.0006489568622782826
Epoch:  24  	Training Loss: 0.0007880317280068994
Test Loss:  0.0005723320646211505
Valid Loss:  0.0006385206361301243
Epoch:  25  	Training Loss: 0.0007492180448025465
Test Loss:  0.0005457403603941202
Valid Loss:  0.0006165181985124946
Epoch:  26  	Training Loss: 0.0007162546389736235
Test Loss:  0.0005296840099617839
Valid Loss:  0.000604507396928966
Epoch:  27  	Training Loss: 0.0006869516801089048
Test Loss:  0.0005060007679276168
Valid Loss:  0.0005827564164064825
Epoch:  28  	Training Loss: 0.0006598844774998724
Test Loss:  0.0004900010535493493
Valid Loss:  0.0005678050802089274
Epoch:  29  	Training Loss: 0.0006343554123304784
Test Loss:  0.00046819966519251466
Valid Loss:  0.000546138035133481
Epoch:  30  	Training Loss: 0.0006101959152147174
Test Loss:  0.0004550910380203277
Valid Loss:  0.0005329565610736609
Epoch:  31  	Training Loss: 0.0005894961068406701
Test Loss:  0.00043736546649597585
Valid Loss:  0.0005157815758138895
Epoch:  32  	Training Loss: 0.0005707226227968931
Test Loss:  0.00041790487011894584
Valid Loss:  0.000499675574246794
Epoch:  33  	Training Loss: 0.0005442274850793183
Test Loss:  0.00039767043199390173
Valid Loss:  0.00048082531429827213
Epoch:  34  	Training Loss: 0.0005210777744650841
Test Loss:  0.00038246280746534467
Valid Loss:  0.00046758545795455575
Epoch:  35  	Training Loss: 0.00050115748308599
Test Loss:  0.00036566468770615757
Valid Loss:  0.0004507367266342044
Epoch:  36  	Training Loss: 0.00048362353118136525
Test Loss:  0.00035293790278956294
Valid Loss:  0.00043936731526628137
Epoch:  37  	Training Loss: 0.00046727582230232656
Test Loss:  0.00033744072425179183
Valid Loss:  0.0004239841364324093
Epoch:  38  	Training Loss: 0.00045251386472955346
Test Loss:  0.0003262219252064824
Valid Loss:  0.00041310302913188934
Epoch:  39  	Training Loss: 0.00043877906864508986
Test Loss:  0.0003128177486360073
Valid Loss:  0.0003991629055235535
Epoch:  40  	Training Loss: 0.00042620243038982153
Test Loss:  0.00030287561821751297
Valid Loss:  0.00038908925489522517
Epoch:  41  	Training Loss: 0.00041414977749809623
Test Loss:  0.00029051024466753006
Valid Loss:  0.00037659119698219
Epoch:  42  	Training Loss: 0.0004028167459182441
Test Loss:  0.0002819403598550707
Valid Loss:  0.0003683573449961841
Epoch:  43  	Training Loss: 0.00039345648838207126
Test Loss:  0.00027395293000154197
Valid Loss:  0.00036081118742004037
Epoch:  44  	Training Loss: 0.0003849237400572747
Test Loss:  0.00026643736055120826
Valid Loss:  0.0003538444871082902
Epoch:  45  	Training Loss: 0.00037706136936321855
Test Loss:  0.000259398075286299
Valid Loss:  0.0003473954275250435
Epoch:  46  	Training Loss: 0.00036972484667785466
Test Loss:  0.0002529185148887336
Valid Loss:  0.00034130114363506436
Epoch:  47  	Training Loss: 0.000362923601642251
Test Loss:  0.0002469584287609905
Valid Loss:  0.0003354512155056
Epoch:  48  	Training Loss: 0.0003564964863471687
Test Loss:  0.00024140349705703557
Valid Loss:  0.0003298348456155509
Epoch:  49  	Training Loss: 0.00035039009526371956
Test Loss:  0.00023609265917912126
Valid Loss:  0.00032444827957078815
Epoch:  50  	Training Loss: 0.0003445990150794387
Test Loss:  0.00023101965780369937
Valid Loss:  0.0003193072625435889
Epoch:  51  	Training Loss: 0.0003391298232600093
Test Loss:  0.00022623380937147886
Valid Loss:  0.0003144844085909426
Epoch:  52  	Training Loss: 0.0003340175608173013
Test Loss:  0.00021443850710056722
Valid Loss:  0.00029886022093705833
Epoch:  53  	Training Loss: 0.00032100133830681443
Test Loss:  0.00020299284369684756
Valid Loss:  0.00028341574943624437
Epoch:  54  	Training Loss: 0.0003081030154135078
Test Loss:  0.00019716830865945667
Valid Loss:  0.0002769005950540304
Epoch:  55  	Training Loss: 0.00030105284531600773
Test Loss:  0.00019214744679629803
Valid Loss:  0.0002722050412558019
Epoch:  56  	Training Loss: 0.00029458891367539763
Test Loss:  0.00018656264001037925
Valid Loss:  0.00026795073063112795
Epoch:  57  	Training Loss: 0.0002882123226299882
Test Loss:  0.00018136194557882845
Valid Loss:  0.00026347400853410363
Epoch:  58  	Training Loss: 0.00028198209474794567
Test Loss:  0.00017618411220610142
Valid Loss:  0.0002587570052128285
Epoch:  59  	Training Loss: 0.00027473451336845756
Test Loss:  0.00016999336367007345
Valid Loss:  0.0002535053645260632
Epoch:  60  	Training Loss: 0.00026608468033373356
Test Loss:  0.00016407118528150022
Valid Loss:  0.00024771696189418435
Epoch:  61  	Training Loss: 0.00025587313575670123
Test Loss:  0.00015763365081511438
Valid Loss:  0.0002414205519016832
Epoch:  62  	Training Loss: 0.0002450050669722259
Test Loss:  0.00014181810547597706
Valid Loss:  0.0002249153912998736
Epoch:  63  	Training Loss: 0.00022300718410406262
Test Loss:  0.0001287968480028212
Valid Loss:  0.00021549388475250453
Epoch:  64  	Training Loss: 0.0002080830163322389
Test Loss:  0.00012107510701753199
Valid Loss:  0.00021000335982535034
Epoch:  65  	Training Loss: 0.0001995850761886686
Test Loss:  0.00011496458319015801
Valid Loss:  0.00020535173825919628
Epoch:  66  	Training Loss: 0.0001940060465130955
Test Loss:  0.00011139950947836041
Valid Loss:  0.00020184704044368118
Epoch:  67  	Training Loss: 0.00019004318164661527
Test Loss:  0.00010783676407299936
Valid Loss:  0.00019783314201049507
Epoch:  68  	Training Loss: 0.00018674352031666785
Test Loss:  0.00010574795305728912
Valid Loss:  0.0001954088656930253
Epoch:  69  	Training Loss: 0.00018379052926320583
Test Loss:  0.00010237064270768315
 14%|█▍        | 69/500 [00:47<02:24,  2.98it/s] 14%|█▍        | 71/500 [00:54<08:42,  1.22s/it] 15%|█▍        | 73/500 [00:54<06:13,  1.14it/s] 15%|█▌        | 75/500 [00:54<04:31,  1.57it/s] 15%|█▌        | 77/500 [00:54<03:20,  2.11it/s] 16%|█▌        | 79/500 [00:55<02:30,  2.80it/s] 16%|█▌        | 81/500 [01:07<14:53,  2.13s/it] 17%|█▋        | 83/500 [01:07<10:31,  1.52s/it] 17%|█▋        | 85/500 [01:07<07:28,  1.08s/it] 17%|█▋        | 87/500 [01:08<05:20,  1.29it/s] 18%|█▊        | 89/500 [01:08<03:51,  1.77it/s] 18%|█▊        | 91/500 [01:14<09:12,  1.35s/it] 19%|█▊        | 93/500 [01:14<06:33,  1.03it/s] 19%|█▉        | 95/500 [01:14<04:42,  1.44it/s] 19%|█▉        | 97/500 [01:15<03:24,  1.97it/s] 20%|█▉        | 99/500 [01:15<02:30,  2.66it/s] 20%|██        | 101/500 [01:21<08:15,  1.24s/it] 21%|██        | 103/500 [01:21<05:53,  1.12it/s] 21%|██        | 105/500 [01:21<04:14,  1.55it/s] 21%|██▏       | 107/500 [01:22<03:04,  2.13it/s] 22%|██▏       | 109/500 [01:22<02:17,  2.85it/s] 22%|██▏       | 111/500 [01:28<07:51,  1.21s/it] 23%|██▎       | 113/500 [01:28<05:36,  1.15it/s] 23%|██▎       | 115/500 [01:28<04:01,  1.59it/s] 23%|██▎       | 117/500 [01:29<02:56,  2.17it/s] 24%|██▍       | 119/500 [01:29<02:10,  2.91it/s] 24%|██▍       | 121/500 [01:35<07:35,  1.20s/it] 25%|██▍       | 123/500 [01:35<05:25,  1.16it/s] 25%|██▌       | 125/500 [01:35<03:54,  1.60it/s] 25%|██▌       | 127/500 [01:36<02:50,  2.18it/s] 26%|██▌       | 129/500 [01:36<02:06,  2.93it/s] 26%|██▌       | 131/500 [01:42<07:31,  1.22s/it] 27%|██▋       | 133/500 [01:42<05:22,  1.14it/s] 27%|██▋       | 135/500 [01:43<03:51,  1.58it/s]Valid Loss:  0.00019155247719027102
Epoch:  70  	Training Loss: 0.00018104308401234448
Test Loss:  0.00010123000538442284
Valid Loss:  0.0001901306677609682
Epoch:  71  	Training Loss: 0.00017853343160822988
Test Loss:  9.771055192686617e-05
Valid Loss:  0.00018612419080454856
Epoch:  72  	Training Loss: 0.0001761543971952051
Test Loss:  9.937282447936013e-05
Valid Loss:  0.00018636719323694706
Epoch:  73  	Training Loss: 0.00017511131591163576
Test Loss:  9.549525566399097e-05
Valid Loss:  0.00018148464732803404
Epoch:  74  	Training Loss: 0.00017721450421959162
Test Loss:  0.00012753721966873854
Valid Loss:  0.00021249213023111224
Epoch:  75  	Training Loss: 0.00019592254830058664
Test Loss:  0.00021451959037221968
Valid Loss:  0.0002982483129017055
Epoch:  76  	Training Loss: 0.0003233897150494158
Test Loss:  0.0007411317201331258
Valid Loss:  0.0008106276509352028
Epoch:  77  	Training Loss: 0.0007632816559635103
Test Loss:  0.0006086942739784718
Valid Loss:  0.0006813656073063612
Epoch:  78  	Training Loss: 0.0007867672247812152
Test Loss:  0.0007774258265271783
Valid Loss:  0.0008430255693383515
Epoch:  79  	Training Loss: 0.0008006572024896741
Test Loss:  0.00040754969813860953
Valid Loss:  0.00046918162843212485
Epoch:  80  	Training Loss: 0.0005691675469279289
Test Loss:  0.000377973890863359
Valid Loss:  0.00044910432188771665
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.0004207601014059037
Test Loss:  0.00013614713679999113
Valid Loss:  0.00021167052909731865
Epoch:  82  	Training Loss: 0.000200801674509421
Test Loss:  0.00010198337258771062
Valid Loss:  0.00017768614634405822
Epoch:  83  	Training Loss: 0.0001748597132973373
Test Loss:  9.719636000227183e-05
Valid Loss:  0.00017292994016315788
Epoch:  84  	Training Loss: 0.00017202978779096156
Test Loss:  9.571645932737738e-05
Valid Loss:  0.00017152591317426413
Epoch:  85  	Training Loss: 0.0001708079216768965
Test Loss:  9.477955609327182e-05
Valid Loss:  0.0001706768525764346
Epoch:  86  	Training Loss: 0.00016970328579191118
Test Loss:  9.399000555276871e-05
Valid Loss:  0.0001699735876172781
Epoch:  87  	Training Loss: 0.00016862503252923489
Test Loss:  9.325904829893261e-05
Valid Loss:  0.00016933263395912945
Epoch:  88  	Training Loss: 0.00016757778939791024
Test Loss:  9.25505519262515e-05
Valid Loss:  0.00016869381943251938
Epoch:  89  	Training Loss: 0.0001665565650910139
Test Loss:  9.189290722133592e-05
Valid Loss:  0.00016810398665256798
Epoch:  90  	Training Loss: 0.00016557180788367987
Test Loss:  9.123860945692286e-05
Valid Loss:  0.00016751454677432775
Epoch:  91  	Training Loss: 0.00016461368068121374
Test Loss:  9.059676085598767e-05
Valid Loss:  0.00016693701036274433
Epoch:  92  	Training Loss: 0.00016369204968214035
Test Loss:  8.975000673672184e-05
Valid Loss:  0.00016612345643807203
Epoch:  93  	Training Loss: 0.00016274102381430566
Test Loss:  8.902160334400833e-05
Valid Loss:  0.00016542388766538352
Epoch:  94  	Training Loss: 0.00016182870604097843
Test Loss:  8.83503962540999e-05
Valid Loss:  0.00016479362966492772
Epoch:  95  	Training Loss: 0.0001609349565114826
Test Loss:  8.77125930855982e-05
Valid Loss:  0.00016420127940364182
Epoch:  96  	Training Loss: 0.00016005572979338467
Test Loss:  8.710070687811822e-05
Valid Loss:  0.00016362631868105382
Epoch:  97  	Training Loss: 0.00015919169527478516
Test Loss:  8.650640666019171e-05
Valid Loss:  0.0001630637707421556
Epoch:  98  	Training Loss: 0.00015834193618502468
Test Loss:  8.592659287387505e-05
Valid Loss:  0.00016252344357781112
Epoch:  99  	Training Loss: 0.0001575064961798489
Test Loss:  8.536058885511011e-05
Valid Loss:  0.0001620116672711447
Epoch:  100  	Training Loss: 0.000156684429384768
Test Loss:  8.48069685162045e-05
Valid Loss:  0.00016150801093317568
Epoch:  101  	Training Loss: 0.00015587653615511954
Test Loss:  8.42639128677547e-05
Valid Loss:  0.0001610143226571381
Epoch:  102  	Training Loss: 0.0001550825109006837
Test Loss:  8.323256042785943e-05
Valid Loss:  0.0001604155550012365
Epoch:  103  	Training Loss: 0.000154200941324234
Test Loss:  8.256972068920732e-05
Valid Loss:  0.00015990951214917004
Epoch:  104  	Training Loss: 0.00015347145381383598
Test Loss:  8.200827869586647e-05
Valid Loss:  0.000159460527356714
Epoch:  105  	Training Loss: 0.00015280296793207526
Test Loss:  8.151735528372228e-05
Valid Loss:  0.00015903449093457311
Epoch:  106  	Training Loss: 0.00015216671454254538
Test Loss:  8.106314635369927e-05
Valid Loss:  0.00015863298904150724
Epoch:  107  	Training Loss: 0.0001515596522949636
Test Loss:  8.061643166001886e-05
Valid Loss:  0.00015825813170522451
Epoch:  108  	Training Loss: 0.00015096302377060056
Test Loss:  8.01951828179881e-05
Valid Loss:  0.00015789562894497067
Epoch:  109  	Training Loss: 0.00015038475976325572
Test Loss:  7.978786015883088e-05
Valid Loss:  0.0001575360947754234
Epoch:  110  	Training Loss: 0.0001498210767749697
Test Loss:  7.939685019664466e-05
Valid Loss:  0.00015718594659119844
Epoch:  111  	Training Loss: 0.00014927379379514605
Test Loss:  7.901902426965535e-05
Valid Loss:  0.0001568434963701293
Epoch:  112  	Training Loss: 0.0001487411791458726
Test Loss:  7.891012501204386e-05
Valid Loss:  0.0001566268183523789
Epoch:  113  	Training Loss: 0.00014810243737883866
Test Loss:  7.858436583774164e-05
Valid Loss:  0.00015624903608113527
Epoch:  114  	Training Loss: 0.00014751142589375377
Test Loss:  7.821655162842944e-05
Valid Loss:  0.0001558554795337841
Epoch:  115  	Training Loss: 0.00014694200945086777
Test Loss:  7.783135515637696e-05
Valid Loss:  0.0001554540212964639
Epoch:  116  	Training Loss: 0.00014638752327300608
Test Loss:  7.746288611087948e-05
Valid Loss:  0.00015508323849644512
Epoch:  117  	Training Loss: 0.00014584764721803367
Test Loss:  7.709245255682617e-05
Valid Loss:  0.00015472574159502983
Epoch:  118  	Training Loss: 0.00014531370834447443
Test Loss:  7.671922503504902e-05
Valid Loss:  0.00015437521506100893
Epoch:  119  	Training Loss: 0.00014478673983830959
Test Loss:  7.634752546437085e-05
Valid Loss:  0.0001540333905722946
Epoch:  120  	Training Loss: 0.00014426949201151729
Test Loss:  7.598016236443073e-05
Valid Loss:  0.00015370083565358073
Epoch:  121  	Training Loss: 0.00014376331819221377
Test Loss:  7.56231092964299e-05
Valid Loss:  0.00015337549848482013
Epoch:  122  	Training Loss: 0.0001432646531611681
Test Loss:  7.532720337621868e-05
Valid Loss:  0.00015314831398427486
Epoch:  123  	Training Loss: 0.00014296456356532872
Test Loss:  7.506758265662938e-05
Valid Loss:  0.00015293055912479758
Epoch:  124  	Training Loss: 0.00014267614460550249
Test Loss:  7.483231456717476e-05
Valid Loss:  0.00015271510346792638
Epoch:  125  	Training Loss: 0.0001423927751602605
Test Loss:  7.461587665602565e-05
Valid Loss:  0.00015250081196427345
Epoch:  126  	Training Loss: 0.00014211265079211444
Test Loss:  7.44150165701285e-05
Valid Loss:  0.00015228762640617788
Epoch:  127  	Training Loss: 0.000141835305839777
Test Loss:  7.422652561217546e-05
Valid Loss:  0.00015207630349323153
Epoch:  128  	Training Loss: 0.00014156484394334257
Test Loss:  7.40503819542937e-05
Valid Loss:  0.0001518693461548537
Epoch:  129  	Training Loss: 0.00014130315685179085
Test Loss:  7.388408266706392e-05
Valid Loss:  0.0001516666088718921
Epoch:  130  	Training Loss: 0.00014104798901826143
Test Loss:  7.372327672783285e-05
Valid Loss:  0.00015146442456170917
Epoch:  131  	Training Loss: 0.00014079490210860968
Test Loss:  7.356636342592537e-05
Valid Loss:  0.000151264073792845
Epoch:  132  	Training Loss: 0.00014054306666366756
Test Loss:  7.259717676788568e-05
Valid Loss:  0.00015068365610204637
Epoch:  133  	Training Loss: 0.00013822870096191764
Test Loss:  7.115190965123475e-05
Valid Loss:  0.00014961180568207055
Epoch:  134  	Training Loss: 0.00013605205458588898
Test Loss:  6.970789399929345e-05
Valid Loss:  0.00014843838289380074
Epoch:  135  	Training Loss: 0.00013396231224760413
Test Loss:  6.83135149301961e-05
Valid Loss:  0.00014720926992595196
Epoch:  136  	Training Loss: 0.00013182163820602
Test Loss:   27%|██▋       | 137/500 [01:43<02:48,  2.16it/s] 28%|██▊       | 139/500 [01:43<02:04,  2.90it/s] 28%|██▊       | 141/500 [01:49<07:16,  1.22s/it] 29%|██▊       | 143/500 [01:49<05:11,  1.14it/s] 29%|██▉       | 145/500 [01:50<03:43,  1.59it/s] 29%|██▉       | 147/500 [01:50<02:42,  2.17it/s] 30%|██▉       | 149/500 [01:50<02:00,  2.92it/s] 30%|███       | 151/500 [01:56<06:57,  1.20s/it] 31%|███       | 153/500 [01:56<04:58,  1.16it/s] 31%|███       | 155/500 [01:57<03:34,  1.61it/s] 31%|███▏      | 157/500 [01:57<02:36,  2.20it/s] 32%|███▏      | 159/500 [01:57<01:55,  2.95it/s] 32%|███▏      | 161/500 [02:03<06:40,  1.18s/it] 33%|███▎      | 163/500 [02:03<04:46,  1.18it/s] 33%|███▎      | 165/500 [02:03<03:25,  1.63it/s] 33%|███▎      | 167/500 [02:03<02:29,  2.22it/s] 34%|███▍      | 169/500 [02:04<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:10<06:31,  1.19s/it] 35%|███▍      | 173/500 [02:10<04:39,  1.17it/s] 35%|███▌      | 175/500 [02:10<03:20,  1.62it/s] 35%|███▌      | 177/500 [02:10<02:26,  2.20it/s] 36%|███▌      | 179/500 [02:11<01:49,  2.94it/s] 36%|███▌      | 181/500 [02:17<06:18,  1.19s/it] 37%|███▋      | 183/500 [02:17<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:17<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:17<02:21,  2.22it/s] 38%|███▊      | 189/500 [02:17<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:24<06:11,  1.20s/it] 39%|███▊      | 193/500 [02:24<04:25,  1.16it/s] 39%|███▉      | 195/500 [02:24<03:10,  1.60it/s] 39%|███▉      | 197/500 [02:24<02:18,  2.19it/s] 40%|███▉      | 199/500 [02:24<01:42,  2.94it/s] 40%|████      | 201/500 [02:31<05:55,  1.19s/it] 41%|████      | 203/500 [02:31<04:13,  1.17it/s]6.692441093036905e-05
Valid Loss:  0.0001459132181480527
Epoch:  137  	Training Loss: 0.00012959199375472963
Test Loss:  6.561553163919598e-05
Valid Loss:  0.0001446022797608748
Epoch:  138  	Training Loss: 0.0001275122194783762
Test Loss:  6.437476258724928e-05
Valid Loss:  0.00014316674787551165
Epoch:  139  	Training Loss: 0.00012548222730401903
Test Loss:  6.319934618659317e-05
Valid Loss:  0.0001416965969838202
Epoch:  140  	Training Loss: 0.0001234857481904328
Test Loss:  6.207695696502924e-05
Valid Loss:  0.00014023807307239622
Epoch:  141  	Training Loss: 0.00012151585542596877
Test Loss:  6.100631435401738e-05
Valid Loss:  0.00013878541358280927
Epoch:  142  	Training Loss: 0.00011956935486523435
Test Loss:  5.937698369962163e-05
Valid Loss:  0.00013778917491436005
Epoch:  143  	Training Loss: 0.00011851353337988257
Test Loss:  5.917028829571791e-05
Valid Loss:  0.00013742771989200264
Epoch:  144  	Training Loss: 0.0001182142150355503
Test Loss:  5.913688801229e-05
Valid Loss:  0.00013712448708247393
Epoch:  145  	Training Loss: 0.00011799215280916542
Test Loss:  5.9107813285663724e-05
Valid Loss:  0.0001368372468277812
Epoch:  146  	Training Loss: 0.00011779867054428905
Test Loss:  5.90615309192799e-05
Valid Loss:  0.00013654249778483063
Epoch:  147  	Training Loss: 0.00011761244240915403
Test Loss:  5.902758857700974e-05
Valid Loss:  0.00013625842984765768
Epoch:  148  	Training Loss: 0.0001174408316728659
Test Loss:  5.899248571950011e-05
Valid Loss:  0.00013598264195024967
Epoch:  149  	Training Loss: 0.00011727535456884652
Test Loss:  5.8949161029886454e-05
Valid Loss:  0.000135719747049734
Epoch:  150  	Training Loss: 0.00011711366096278653
Test Loss:  5.891058754059486e-05
Valid Loss:  0.00013546955597121269
Epoch:  151  	Training Loss: 0.00011695957800839096
Test Loss:  5.8888603234663606e-05
Valid Loss:  0.00013522824156098068
Epoch:  152  	Training Loss: 0.00011681213800329715
Test Loss:  5.799950668006204e-05
Valid Loss:  0.00013348730863071978
Epoch:  153  	Training Loss: 0.00011446228018030524
Test Loss:  5.682791379513219e-05
Valid Loss:  0.00013168234727345407
Epoch:  154  	Training Loss: 0.00011226088099647313
Test Loss:  5.567041807807982e-05
Valid Loss:  0.00012994556163903326
Epoch:  155  	Training Loss: 0.00011018546501873061
Test Loss:  5.453410267364234e-05
Valid Loss:  0.00012827242608182132
Epoch:  156  	Training Loss: 0.00010821403702721
Test Loss:  5.340395000530407e-05
Valid Loss:  0.00012669485295191407
Epoch:  157  	Training Loss: 0.00010634743375703692
Test Loss:  5.2356488595250994e-05
Valid Loss:  0.00012520450400188565
Epoch:  158  	Training Loss: 0.00010458467295393348
Test Loss:  5.136734034749679e-05
Valid Loss:  0.00012379612599033862
Epoch:  159  	Training Loss: 0.00010291385115124285
Test Loss:  5.039932148065418e-05
Valid Loss:  0.0001224604930030182
Epoch:  160  	Training Loss: 0.00010132253373740241
Test Loss:  4.9449918151367456e-05
Valid Loss:  0.00012119644816266373
Epoch:  161  	Training Loss: 9.983287600334734e-05
Test Loss:  4.8526941100135446e-05
Valid Loss:  0.00012000201968476176
Epoch:  162  	Training Loss: 9.84125945251435e-05
Test Loss:  4.8231802793452516e-05
Valid Loss:  0.00011942631681449711
Epoch:  163  	Training Loss: 9.806340676732361e-05
Test Loss:  4.8063084250316024e-05
Valid Loss:  0.00011894443014170974
Epoch:  164  	Training Loss: 9.777019295142964e-05
Test Loss:  4.797131987288594e-05
Valid Loss:  0.000118535608635284
Epoch:  165  	Training Loss: 9.75104485405609e-05
Test Loss:  4.7917928895913064e-05
Valid Loss:  0.0001181771294795908
Epoch:  166  	Training Loss: 9.726825373945758e-05
Test Loss:  4.788364822161384e-05
Valid Loss:  0.00011785801325459033
Epoch:  167  	Training Loss: 9.704205149319023e-05
Test Loss:  4.7853005526121706e-05
Valid Loss:  0.0001175650249933824
Epoch:  168  	Training Loss: 9.682633390184492e-05
Test Loss:  4.783598706126213e-05
Valid Loss:  0.00011729739344445989
Epoch:  169  	Training Loss: 9.661982767283916e-05
Test Loss:  4.781998723046854e-05
Valid Loss:  0.00011705120414262637
Epoch:  170  	Training Loss: 9.642394434195012e-05
Test Loss:  4.7806475777179e-05
Valid Loss:  0.00011681967589538544
Epoch:  171  	Training Loss: 9.623574442230165e-05
Test Loss:  4.779579830938019e-05
Valid Loss:  0.00011660141171887517
Epoch:  172  	Training Loss: 9.605497325537726e-05
Test Loss:  4.7456007450819016e-05
Valid Loss:  0.00011616594565566629
Epoch:  173  	Training Loss: 9.563638013787568e-05
Test Loss:  4.728188650915399e-05
Valid Loss:  0.0001158241939265281
Epoch:  174  	Training Loss: 9.530245006317273e-05
Test Loss:  4.718773561762646e-05
Valid Loss:  0.00011556111712707207
Epoch:  175  	Training Loss: 9.503799810772762e-05
Test Loss:  4.716384501080029e-05
Valid Loss:  0.000115357936010696
Epoch:  176  	Training Loss: 9.483195026405156e-05
Test Loss:  4.71594394184649e-05
Valid Loss:  0.00011519539111759514
Epoch:  177  	Training Loss: 9.464986942475662e-05
Test Loss:  4.714602982858196e-05
Valid Loss:  0.00011503528367029503
Epoch:  178  	Training Loss: 9.447547199670225e-05
Test Loss:  4.714114766102284e-05
Valid Loss:  0.00011488846212159842
Epoch:  179  	Training Loss: 9.431418584426865e-05
Test Loss:  4.714392707683146e-05
Valid Loss:  0.00011476044164737687
Epoch:  180  	Training Loss: 9.416336251888424e-05
Test Loss:  4.71534876851365e-05
Valid Loss:  0.00011465064744697884
Epoch:  181  	Training Loss: 9.402030264027417e-05
Test Loss:  4.7149038437055424e-05
Valid Loss:  0.00011453998740762472
Epoch:  182  	Training Loss: 9.388141916133463e-05
Test Loss:  4.725878534372896e-05
Valid Loss:  0.00011442417599027976
Epoch:  183  	Training Loss: 9.372508066007867e-05
Test Loss:  4.7275891120079905e-05
Valid Loss:  0.00011427683057263494
Epoch:  184  	Training Loss: 9.357826638733968e-05
Test Loss:  4.727284249383956e-05
Valid Loss:  0.00011413674656068906
Epoch:  185  	Training Loss: 9.343825513496995e-05
Test Loss:  4.7263194574043155e-05
Valid Loss:  0.00011400473158573732
Epoch:  186  	Training Loss: 9.330266038887203e-05
Test Loss:  4.7248595365090296e-05
Valid Loss:  0.0001138844236265868
Epoch:  187  	Training Loss: 9.317093645222485e-05
Test Loss:  4.7233235818566754e-05
Valid Loss:  0.00011377382179489359
Epoch:  188  	Training Loss: 9.304401464760303e-05
Test Loss:  4.7214471123879775e-05
Valid Loss:  0.00011367120896466076
Epoch:  189  	Training Loss: 9.29211382754147e-05
Test Loss:  4.71921703137923e-05
Valid Loss:  0.00011357589391991496
Epoch:  190  	Training Loss: 9.28025838220492e-05
Test Loss:  4.716242983704433e-05
Valid Loss:  0.00011349152191542089
Epoch:  191  	Training Loss: 9.268773283110932e-05
Test Loss:  4.713519956567325e-05
Valid Loss:  0.00011341259960317984
Epoch:  192  	Training Loss: 9.257548663299531e-05
Test Loss:  4.6871587983332574e-05
Valid Loss:  0.00011324465594952926
Epoch:  193  	Training Loss: 9.226188558386639e-05
Test Loss:  4.664355219574645e-05
Valid Loss:  0.00011308144894428551
Epoch:  194  	Training Loss: 9.2006113845855e-05
Test Loss:  4.644841101253405e-05
Valid Loss:  0.00011292641283944249
Epoch:  195  	Training Loss: 9.178603795589879e-05
Test Loss:  4.626734516932629e-05
Valid Loss:  0.00011278192687314004
Epoch:  196  	Training Loss: 9.158157627098262e-05
Test Loss:  4.610307587427087e-05
Valid Loss:  0.00011264600470894948
Epoch:  197  	Training Loss: 9.13911426323466e-05
Test Loss:  4.595691279973835e-05
Valid Loss:  0.00011251158139202744
Epoch:  198  	Training Loss: 9.122336632572114e-05
Test Loss:  4.583603367791511e-05
Valid Loss:  0.0001123802867368795
Epoch:  199  	Training Loss: 9.10691378521733e-05
Test Loss:  4.573477053781971e-05
Valid Loss:  0.00011224734043935314
Epoch:  200  	Training Loss: 9.092236723517999e-05
Test Loss:  4.564583286992274e-05
Valid Loss:  0.00011211416858714074
Epoch:  201  	Training Loss: 9.078008588403463e-05
Test Loss:  4.5562806917587295e-05
Valid Loss:  0.0001119814915000461
Epoch:  202  	Training Loss: 9.064144978765398e-05
Test Loss:  4.5522090658778325e-05
Valid Loss:  0.00011188253847649321
Epoch:  203  	Training Loss: 9.054620750248432e-05
Test Loss:  4.549628647509962e-05
Valid Loss:  0.00011179836292285472
 41%|████      | 205/500 [02:31<03:02,  1.62it/s] 41%|████▏     | 207/500 [02:31<02:12,  2.21it/s] 42%|████▏     | 209/500 [02:31<01:37,  2.97it/s] 42%|████▏     | 211/500 [02:38<05:42,  1.19s/it] 43%|████▎     | 213/500 [02:38<04:04,  1.18it/s] 43%|████▎     | 215/500 [02:38<02:55,  1.62it/s] 43%|████▎     | 217/500 [02:38<02:07,  2.22it/s] 44%|████▍     | 219/500 [02:38<01:34,  2.99it/s] 44%|████▍     | 221/500 [02:45<05:37,  1.21s/it] 45%|████▍     | 223/500 [02:45<04:00,  1.15it/s] 45%|████▌     | 225/500 [02:45<02:52,  1.60it/s] 45%|████▌     | 227/500 [02:45<02:05,  2.18it/s] 46%|████▌     | 229/500 [02:45<01:32,  2.93it/s] 46%|████▌     | 231/500 [02:52<05:20,  1.19s/it] 47%|████▋     | 233/500 [02:52<03:48,  1.17it/s] 47%|████▋     | 235/500 [02:52<02:43,  1.62it/s] 47%|████▋     | 237/500 [02:52<01:59,  2.21it/s] 48%|████▊     | 239/500 [02:52<01:28,  2.96it/s] 48%|████▊     | 241/500 [02:58<05:06,  1.18s/it] 49%|████▊     | 243/500 [02:59<03:38,  1.17it/s] 49%|████▉     | 245/500 [02:59<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:59<01:54,  2.22it/s] 50%|████▉     | 249/500 [02:59<01:24,  2.98it/s] 50%|█████     | 251/500 [03:05<04:56,  1.19s/it] 51%|█████     | 253/500 [03:05<03:31,  1.17it/s] 51%|█████     | 255/500 [03:06<02:31,  1.61it/s] 51%|█████▏    | 257/500 [03:06<01:50,  2.21it/s] 52%|█████▏    | 259/500 [03:06<01:21,  2.96it/s] 52%|█████▏    | 261/500 [03:13<04:59,  1.25s/it] 53%|█████▎    | 263/500 [03:13<03:33,  1.11it/s] 53%|█████▎    | 265/500 [03:13<02:32,  1.54it/s] 53%|█████▎    | 267/500 [03:13<01:51,  2.10it/s] 54%|█████▍    | 269/500 [03:13<01:21,  2.82it/s]Epoch:  204  	Training Loss: 9.045340993907303e-05
Test Loss:  4.547749267658219e-05
Valid Loss:  0.00011172423546668142
Epoch:  205  	Training Loss: 9.036448318511248e-05
Test Loss:  4.5455253712134436e-05
Valid Loss:  0.00011165426985826343
Epoch:  206  	Training Loss: 9.027602209243923e-05
Test Loss:  4.543205432128161e-05
Valid Loss:  0.00011158573761349544
Epoch:  207  	Training Loss: 9.01871026144363e-05
Test Loss:  4.5408407459035516e-05
Valid Loss:  0.00011151890794280916
Epoch:  208  	Training Loss: 9.009911445900798e-05
Test Loss:  4.538540088105947e-05
Valid Loss:  0.00011145360622322187
Epoch:  209  	Training Loss: 9.001257421914488e-05
Test Loss:  4.5360960939433426e-05
Valid Loss:  0.00011139118578284979
Epoch:  210  	Training Loss: 8.992713264888152e-05
Test Loss:  4.533695027930662e-05
Valid Loss:  0.0001113296821131371
Epoch:  211  	Training Loss: 8.984289888758212e-05
Test Loss:  4.53118555014953e-05
Valid Loss:  0.00011127040488645434
Epoch:  212  	Training Loss: 8.975980017567053e-05
Test Loss:  4.455559974303469e-05
Valid Loss:  0.00011079529213020578
Epoch:  213  	Training Loss: 8.875460480339825e-05
Test Loss:  4.369969246909022e-05
Valid Loss:  0.00011018841178156435
Epoch:  214  	Training Loss: 8.785213867668062e-05
Test Loss:  4.290123615646735e-05
Valid Loss:  0.0001096076812245883
Epoch:  215  	Training Loss: 8.701824845047668e-05
Test Loss:  4.2164436308667064e-05
Valid Loss:  0.00010907875548582524
Epoch:  216  	Training Loss: 8.624542533652857e-05
Test Loss:  4.1478964703856036e-05
Valid Loss:  0.00010857536108233035
Epoch:  217  	Training Loss: 8.552439248887822e-05
Test Loss:  4.084013926330954e-05
Valid Loss:  0.00010809334344230592
Epoch:  218  	Training Loss: 8.483840792905539e-05
Test Loss:  4.025349335279316e-05
Valid Loss:  0.000107640924397856
Epoch:  219  	Training Loss: 8.420392987318337e-05
Test Loss:  3.9719285268802196e-05
Valid Loss:  0.00010721702710725367
Epoch:  220  	Training Loss: 8.361341315321624e-05
Test Loss:  3.922792529920116e-05
Valid Loss:  0.00010680139530450106
Epoch:  221  	Training Loss: 8.305866504088044e-05
Test Loss:  3.8777696317993104e-05
Valid Loss:  0.00010640444816090167
Epoch:  222  	Training Loss: 8.254165732068941e-05
Test Loss:  3.87308064091485e-05
Valid Loss:  0.00010594321793178096
Epoch:  223  	Training Loss: 8.198955038096756e-05
Test Loss:  3.855405520880595e-05
Valid Loss:  0.00010547557758400217
Epoch:  224  	Training Loss: 8.147803600877523e-05
Test Loss:  3.833473601844162e-05
Valid Loss:  0.00010500645294087008
Epoch:  225  	Training Loss: 8.098265971057117e-05
Test Loss:  3.810734051512554e-05
Valid Loss:  0.00010454459697939456
Epoch:  226  	Training Loss: 8.050129690673202e-05
Test Loss:  3.7883015465922654e-05
Valid Loss:  0.00010409188689664006
Epoch:  227  	Training Loss: 8.003411494428292e-05
Test Loss:  3.766436202568002e-05
Valid Loss:  0.00010364987247157842
Epoch:  228  	Training Loss: 7.957991329021752e-05
Test Loss:  3.746044239960611e-05
Valid Loss:  0.00010321623994968832
Epoch:  229  	Training Loss: 7.913931040093303e-05
Test Loss:  3.726482464116998e-05
Valid Loss:  0.00010278831177856773
Epoch:  230  	Training Loss: 7.871012348914519e-05
Test Loss:  3.70808265870437e-05
Valid Loss:  0.00010236675734631717
Epoch:  231  	Training Loss: 7.829087553545833e-05
Test Loss:  3.6889148759655654e-05
Valid Loss:  0.00010194502829108387
Epoch:  232  	Training Loss: 7.787581853335723e-05
Test Loss:  3.658786590676755e-05
Valid Loss:  0.00010165659477934241
Epoch:  233  	Training Loss: 7.772496610414237e-05
Test Loss:  3.657209890661761e-05
Valid Loss:  0.00010148718138225377
Epoch:  234  	Training Loss: 7.762745372019708e-05
Test Loss:  3.6628509406000376e-05
Valid Loss:  0.00010134930198546499
Epoch:  235  	Training Loss: 7.75393345975317e-05
Test Loss:  3.670337900985032e-05
Valid Loss:  0.00010122614912688732
Epoch:  236  	Training Loss: 7.745742186671123e-05
Test Loss:  3.67821630788967e-05
Valid Loss:  0.00010111289157066494
Epoch:  237  	Training Loss: 7.738049316685647e-05
Test Loss:  3.686057243612595e-05
Valid Loss:  0.00010100658255396411
Epoch:  238  	Training Loss: 7.73086940171197e-05
Test Loss:  3.693741746246815e-05
Valid Loss:  0.00010090743307955563
Epoch:  239  	Training Loss: 7.724078022874892e-05
Test Loss:  3.70119814760983e-05
Valid Loss:  0.0001008133840514347
Epoch:  240  	Training Loss: 7.717634434811771e-05
Test Loss:  3.708405347424559e-05
Valid Loss:  0.00010072605073219165
Epoch:  241  	Training Loss: 7.711552461842075e-05
Test Loss:  3.715440834639594e-05
Valid Loss:  0.00010064311936730519
Epoch:  242  	Training Loss: 7.705792086198926e-05
Test Loss:  3.71387941413559e-05
Valid Loss:  0.00010056493192678317
Epoch:  243  	Training Loss: 7.69638063502498e-05
Test Loss:  3.710265445988625e-05
Valid Loss:  0.00010047887190012261
Epoch:  244  	Training Loss: 7.687130710110068e-05
Test Loss:  3.705808921949938e-05
Valid Loss:  0.00010039043263532221
Epoch:  245  	Training Loss: 7.6779440860264e-05
Test Loss:  3.701019159052521e-05
Valid Loss:  0.00010029944678535685
Epoch:  246  	Training Loss: 7.668810576433316e-05
Test Loss:  3.6961224395781755e-05
Valid Loss:  0.00010020912304753438
Epoch:  247  	Training Loss: 7.659739640075713e-05
Test Loss:  3.691243182402104e-05
Valid Loss:  0.00010011790436692536
Epoch:  248  	Training Loss: 7.65071454225108e-05
Test Loss:  3.686421041493304e-05
Valid Loss:  0.00010002844646805897
Epoch:  249  	Training Loss: 7.6418393291533e-05
Test Loss:  3.6816247302340344e-05
Valid Loss:  9.993876301450655e-05
Epoch:  250  	Training Loss: 7.632989581907168e-05
Test Loss:  3.676861524581909e-05
Valid Loss:  9.985128417611122e-05
Epoch:  251  	Training Loss: 7.624183490406722e-05
Test Loss:  3.6721350625157356e-05
Valid Loss:  9.976445289794356e-05
Epoch:  252  	Training Loss: 7.615452341269702e-05
Test Loss:  3.6478377296589315e-05
Valid Loss:  9.941415919456631e-05
Epoch:  253  	Training Loss: 7.558662036899477e-05
Test Loss:  3.6177334550302476e-05
Valid Loss:  9.909812069963664e-05
Epoch:  254  	Training Loss: 7.517981430282816e-05
Test Loss:  3.587988976505585e-05
Valid Loss:  9.879267599899322e-05
Epoch:  255  	Training Loss: 7.4825766205322e-05
Test Loss:  3.562293932191096e-05
Valid Loss:  9.849452908383682e-05
Epoch:  256  	Training Loss: 7.451232522726059e-05
Test Loss:  3.541016485542059e-05
Valid Loss:  9.820732520893216e-05
Epoch:  257  	Training Loss: 7.421971531584859e-05
Test Loss:  3.523546547512524e-05
Valid Loss:  9.793274512048811e-05
Epoch:  258  	Training Loss: 7.394119165837765e-05
Test Loss:  3.50851914845407e-05
Valid Loss:  9.766555740498006e-05
Epoch:  259  	Training Loss: 7.367560465354472e-05
Test Loss:  3.496095450827852e-05
Valid Loss:  9.740886889630929e-05
Epoch:  260  	Training Loss: 7.34196582925506e-05
Test Loss:  3.485115303192288e-05
Valid Loss:  9.715782653074712e-05
Epoch:  261  	Training Loss: 7.317197741940618e-05
Test Loss:  3.475627090665512e-05
Valid Loss:  9.691446030046791e-05
Epoch:  262  	Training Loss: 7.293251110240817e-05
Test Loss:  3.484001354081556e-05
Valid Loss:  9.670232248026878e-05
Epoch:  263  	Training Loss: 7.280905992956832e-05
Test Loss:  3.495968849165365e-05
Valid Loss:  9.651997970649973e-05
Epoch:  264  	Training Loss: 7.270195055752993e-05
Test Loss:  3.509021189529449e-05
Valid Loss:  9.635814058128744e-05
Epoch:  265  	Training Loss: 7.260793790919706e-05
Test Loss:  3.522128099575639e-05
Valid Loss:  9.621313074603677e-05
Epoch:  266  	Training Loss: 7.2523980634287e-05
Test Loss:  3.5348577512195334e-05
Valid Loss:  9.608235995983705e-05
Epoch:  267  	Training Loss: 7.244890730362386e-05
Test Loss:  3.5467601264826953e-05
Valid Loss:  9.596218296792358e-05
Epoch:  268  	Training Loss: 7.23812700016424e-05
Test Loss:  3.557946183718741e-05
Valid Loss:  9.58515374804847e-05
Epoch:  269  	Training Loss: 7.231951167341322e-05
Test Loss:  3.5683740861713886e-05
Valid Loss:  9.575019794283435e-05
Epoch:  270  	Training Loss: 7.226282468764111e-05
Test Loss:  3.578083124011755e-05
Valid Loss:  9.565523942001164e-05
Epoch:  271  	Training Loss: 7.221067062346265e-05
Test Loss:  3.587107494240627e-05
Valid Loss:   54%|█████▍    | 271/500 [03:20<04:32,  1.19s/it] 55%|█████▍    | 273/500 [03:20<03:14,  1.17it/s] 55%|█████▌    | 275/500 [03:20<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:20<01:42,  2.18it/s] 56%|█████▌    | 279/500 [03:20<01:16,  2.91it/s] 56%|█████▌    | 281/500 [03:26<04:16,  1.17s/it] 57%|█████▋    | 283/500 [03:27<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:27<02:11,  1.63it/s] 57%|█████▋    | 287/500 [03:27<01:35,  2.23it/s] 58%|█████▊    | 289/500 [03:27<01:10,  3.00it/s] 58%|█████▊    | 291/500 [03:33<04:05,  1.18s/it] 59%|█████▊    | 293/500 [03:33<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:33<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:34<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:34<01:07,  2.98it/s] 60%|██████    | 301/500 [03:40<03:53,  1.17s/it] 61%|██████    | 303/500 [03:40<02:45,  1.19it/s] 61%|██████    | 305/500 [03:40<01:58,  1.64it/s] 61%|██████▏   | 307/500 [03:40<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:41<01:03,  3.00it/s] 62%|██████▏   | 311/500 [03:47<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:47<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:47<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:47<01:22,  2.21it/s] 64%|██████▍   | 319/500 [03:47<01:00,  2.97it/s] 64%|██████▍   | 321/500 [03:54<03:31,  1.18s/it] 65%|██████▍   | 323/500 [03:54<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:54<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:54<01:17,  2.22it/s] 66%|██████▌   | 329/500 [03:54<00:57,  2.97it/s] 66%|██████▌   | 331/500 [04:01<03:25,  1.21s/it] 67%|██████▋   | 333/500 [04:01<02:25,  1.15it/s] 67%|██████▋   | 335/500 [04:01<01:43,  1.59it/s] 67%|██████▋   | 337/500 [04:01<01:15,  2.17it/s] 68%|██████▊   | 339/500 [04:01<00:55,  2.92it/s]9.556562872603536e-05
Epoch:  272  	Training Loss: 7.216224912554026e-05
Test Loss:  3.58958677679766e-05
Valid Loss:  9.55334835452959e-05
Epoch:  273  	Training Loss: 7.21416508895345e-05
Test Loss:  3.592209759517573e-05
Valid Loss:  9.550032700644806e-05
Epoch:  274  	Training Loss: 7.211806951090693e-05
Test Loss:  3.5951474274042994e-05
Valid Loss:  9.546530054649338e-05
Epoch:  275  	Training Loss: 7.209162868093699e-05
Test Loss:  3.5979919630335644e-05
Valid Loss:  9.543115447741002e-05
Epoch:  276  	Training Loss: 7.206421287264675e-05
Test Loss:  3.601080970838666e-05
Valid Loss:  9.539496386423707e-05
Epoch:  277  	Training Loss: 7.203353015938774e-05
Test Loss:  3.6045228625880554e-05
Valid Loss:  9.53507114900276e-05
Epoch:  278  	Training Loss: 7.199749234132469e-05
Test Loss:  3.607049802667461e-05
Valid Loss:  9.529574163025245e-05
Epoch:  279  	Training Loss: 7.195831858552992e-05
Test Loss:  3.608811675803736e-05
Valid Loss:  9.523607877781615e-05
Epoch:  280  	Training Loss: 7.191825716290623e-05
Test Loss:  3.609590567066334e-05
Valid Loss:  9.517134458292276e-05
Epoch:  281  	Training Loss: 7.187393930507824e-05
Test Loss:  3.609778650570661e-05
Valid Loss:  9.509181109024212e-05
Epoch:  282  	Training Loss: 7.182690023910254e-05
Test Loss:  3.6155070120003074e-05
Valid Loss:  9.505888738203794e-05
Epoch:  283  	Training Loss: 7.180764805525541e-05
Test Loss:  3.6206445656716824e-05
Valid Loss:  9.502559259999543e-05
Epoch:  284  	Training Loss: 7.178975647548214e-05
Test Loss:  3.625294630182907e-05
Valid Loss:  9.499267616774887e-05
Epoch:  285  	Training Loss: 7.177222869358957e-05
Test Loss:  3.629518687375821e-05
Valid Loss:  9.495999984210357e-05
Epoch:  286  	Training Loss: 7.175529754022136e-05
Test Loss:  3.633436426753178e-05
Valid Loss:  9.492773097008467e-05
Epoch:  287  	Training Loss: 7.173870835686103e-05
Test Loss:  3.637041663751006e-05
Valid Loss:  9.489603689871728e-05
Epoch:  288  	Training Loss: 7.172240293584764e-05
Test Loss:  3.640383874881081e-05
Valid Loss:  9.48648521443829e-05
Epoch:  289  	Training Loss: 7.170657772803679e-05
Test Loss:  3.64360494131688e-05
Valid Loss:  9.48336673900485e-05
Epoch:  290  	Training Loss: 7.169111631810665e-05
Test Loss:  3.646582626970485e-05
Valid Loss:  9.480343578616157e-05
Epoch:  291  	Training Loss: 7.167674630181864e-05
Test Loss:  3.649407881312072e-05
Valid Loss:  9.47736480156891e-05
Epoch:  292  	Training Loss: 7.166239811340347e-05
Test Loss:  3.635754546849057e-05
Valid Loss:  9.460565343033522e-05
Epoch:  293  	Training Loss: 7.15263158781454e-05
Test Loss:  3.616003232309595e-05
Valid Loss:  9.440869325771928e-05
Epoch:  294  	Training Loss: 7.140439993236214e-05
Test Loss:  3.60137528332416e-05
Valid Loss:  9.42300830502063e-05
Epoch:  295  	Training Loss: 7.129307778086513e-05
Test Loss:  3.5896482586394995e-05
Valid Loss:  9.40583850024268e-05
Epoch:  296  	Training Loss: 7.11854372639209e-05
Test Loss:  3.579446638468653e-05
Valid Loss:  9.389006299898028e-05
Epoch:  297  	Training Loss: 7.108261343091726e-05
Test Loss:  3.570917760953307e-05
Valid Loss:  9.372641216032207e-05
Epoch:  298  	Training Loss: 7.098002970451489e-05
Test Loss:  3.563566497177817e-05
Valid Loss:  9.356536611448973e-05
Epoch:  299  	Training Loss: 7.087687845341861e-05
Test Loss:  3.556159936124459e-05
Valid Loss:  9.340204269392416e-05
Epoch:  300  	Training Loss: 7.077501504682004e-05
Test Loss:  3.549770190147683e-05
Valid Loss:  9.324203711003065e-05
Epoch:  301  	Training Loss: 7.067530532367527e-05
Test Loss:  3.544117498677224e-05
Valid Loss:  9.308336302638054e-05
Epoch:  302  	Training Loss: 7.057670154608786e-05
Test Loss:  3.5513556213118136e-05
Valid Loss:  9.283862891606987e-05
Epoch:  303  	Training Loss: 7.038918556645513e-05
Test Loss:  3.551900590537116e-05
Valid Loss:  9.256500925403088e-05
Epoch:  304  	Training Loss: 7.020235352683812e-05
Test Loss:  3.548553286236711e-05
Valid Loss:  9.225015674019232e-05
Epoch:  305  	Training Loss: 6.999907054705545e-05
Test Loss:  3.5418903280515224e-05
Valid Loss:  9.193710138788447e-05
Epoch:  306  	Training Loss: 6.979142926866189e-05
Test Loss:  3.533339622663334e-05
Valid Loss:  9.16090066311881e-05
Epoch:  307  	Training Loss: 6.95706985425204e-05
Test Loss:  3.522943734424189e-05
Valid Loss:  9.127550583798438e-05
Epoch:  308  	Training Loss: 6.934642442502081e-05
Test Loss:  3.51249982486479e-05
Valid Loss:  9.094059350900352e-05
Epoch:  309  	Training Loss: 6.911805394338444e-05
Test Loss:  3.504436244838871e-05
Valid Loss:  9.061981836566702e-05
Epoch:  310  	Training Loss: 6.889697397127748e-05
Test Loss:  3.4970114938914776e-05
Valid Loss:  9.032838715938851e-05
Epoch:  311  	Training Loss: 6.869515345897526e-05
Test Loss:  3.4899854654213414e-05
Valid Loss:  9.006720210891217e-05
Epoch:  312  	Training Loss: 6.851179205114022e-05
Test Loss:  3.467323404038325e-05
Valid Loss:  8.987071487354115e-05
Epoch:  313  	Training Loss: 6.841553113190457e-05
Test Loss:  3.4563010558485985e-05
Valid Loss:  8.970723138190806e-05
Epoch:  314  	Training Loss: 6.831914652138948e-05
Test Loss:  3.448543429840356e-05
Valid Loss:  8.955005614552647e-05
Epoch:  315  	Training Loss: 6.821479473728687e-05
Test Loss:  3.4432792745064944e-05
Valid Loss:  8.939828694565222e-05
Epoch:  316  	Training Loss: 6.811148341512308e-05
Test Loss:  3.438989369897172e-05
Valid Loss:  8.925152360461652e-05
Epoch:  317  	Training Loss: 6.800923438277096e-05
Test Loss:  3.435132384765893e-05
Valid Loss:  8.910971519071609e-05
Epoch:  318  	Training Loss: 6.790841143811122e-05
Test Loss:  3.431808727327734e-05
Valid Loss:  8.897701627574861e-05
Epoch:  319  	Training Loss: 6.781183765269816e-05
Test Loss:  3.428501804592088e-05
Valid Loss:  8.884690760169178e-05
Epoch:  320  	Training Loss: 6.771988410037011e-05
Test Loss:  3.4265634894836694e-05
Valid Loss:  8.872597391018644e-05
Epoch:  321  	Training Loss: 6.76394411129877e-05
Test Loss:  3.425654722377658e-05
Valid Loss:  8.860703383106738e-05
Epoch:  322  	Training Loss: 6.756133370799944e-05
Test Loss:  3.433845631661825e-05
Valid Loss:  8.856794738676399e-05
Epoch:  323  	Training Loss: 6.753514753654599e-05
Test Loss:  3.4390661312500015e-05
Valid Loss:  8.852173777995631e-05
Epoch:  324  	Training Loss: 6.751026376150548e-05
Test Loss:  3.4434830013196915e-05
Valid Loss:  8.847584103932604e-05
Epoch:  325  	Training Loss: 6.748626765329391e-05
Test Loss:  3.4474709536880255e-05
Valid Loss:  8.842895476846024e-05
Epoch:  326  	Training Loss: 6.746310100425035e-05
Test Loss:  3.45109510817565e-05
Valid Loss:  8.838413486955687e-05
Epoch:  327  	Training Loss: 6.74401453579776e-05
Test Loss:  3.454360557952896e-05
Valid Loss:  8.833980245981365e-05
Epoch:  328  	Training Loss: 6.741779361618683e-05
Test Loss:  3.457397542661056e-05
Valid Loss:  8.829709986457601e-05
Epoch:  329  	Training Loss: 6.739575474057347e-05
Test Loss:  3.4602311643538997e-05
Valid Loss:  8.825479744700715e-05
Epoch:  330  	Training Loss: 6.737372314091772e-05
Test Loss:  3.4628283174242824e-05
Valid Loss:  8.821404480841011e-05
Epoch:  331  	Training Loss: 6.735271017532796e-05
Test Loss:  3.465230474830605e-05
Valid Loss:  8.817357593216002e-05
Epoch:  332  	Training Loss: 6.733136979164556e-05
Test Loss:  3.3972795790759847e-05
Valid Loss:  8.763754885876551e-05
Epoch:  333  	Training Loss: 6.666680565103889e-05
Test Loss:  3.3407213777536526e-05
Valid Loss:  8.720508049009368e-05
Epoch:  334  	Training Loss: 6.617981125600636e-05
Test Loss:  3.296525028417818e-05
Valid Loss:  8.684119529789314e-05
Epoch:  335  	Training Loss: 6.578498869203031e-05
Test Loss:  3.263652615714818e-05
Valid Loss:  8.651960524730384e-05
Epoch:  336  	Training Loss: 6.545653013745323e-05
Test Loss:  3.2424257369711995e-05
Valid Loss:  8.623486064607278e-05
Epoch:  337  	Training Loss: 6.517318252008408e-05
Test Loss:  3.22511259582825e-05
Valid Loss:  8.595662075094879e-05
Epoch:  338  	Training Loss: 6.491312524303794e-05
Test Loss:  3.212792944395915e-05
Valid Loss:  8.569117198931053e-05
Epoch:  339  	Training Loss: 6.466934428317472e-05
Test Loss:  3.202437437721528e-05
Valid Loss:  8.543182775611058e-05
 68%|██████▊   | 341/500 [04:08<03:08,  1.18s/it] 69%|██████▊   | 343/500 [04:08<02:13,  1.18it/s] 69%|██████▉   | 345/500 [04:08<01:35,  1.63it/s] 69%|██████▉   | 347/500 [04:08<01:08,  2.22it/s] 70%|██████▉   | 349/500 [04:08<00:50,  2.97it/s] 70%|███████   | 351/500 [04:15<02:56,  1.19s/it] 71%|███████   | 353/500 [04:15<02:05,  1.17it/s] 71%|███████   | 355/500 [04:15<01:30,  1.60it/s] 71%|███████▏  | 357/500 [04:15<01:05,  2.18it/s] 72%|███████▏  | 359/500 [04:15<00:47,  2.94it/s] 72%|███████▏  | 361/500 [04:22<02:44,  1.18s/it] 73%|███████▎  | 363/500 [04:22<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:22<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:22<01:00,  2.22it/s] 74%|███████▍  | 369/500 [04:22<00:43,  2.98it/s] 74%|███████▍  | 371/500 [04:28<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:29<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:29<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:29<00:55,  2.20it/s] 76%|███████▌  | 379/500 [04:29<00:40,  2.96it/s] 76%|███████▌  | 381/500 [04:35<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:36<01:40,  1.17it/s] 77%|███████▋  | 385/500 [04:36<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:36<00:51,  2.21it/s] 78%|███████▊  | 389/500 [04:36<00:37,  2.97it/s] 78%|███████▊  | 391/500 [04:42<02:11,  1.21s/it] 79%|███████▊  | 393/500 [04:43<01:32,  1.15it/s] 79%|███████▉  | 395/500 [04:43<01:05,  1.59it/s] 79%|███████▉  | 397/500 [04:43<00:47,  2.18it/s] 80%|███████▉  | 399/500 [04:43<00:34,  2.93it/s] 80%|████████  | 401/500 [04:49<01:57,  1.18s/it] 81%|████████  | 403/500 [04:49<01:22,  1.18it/s] 81%|████████  | 405/500 [04:50<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:50<00:41,  2.22it/s]Epoch:  340  	Training Loss: 6.443465827032924e-05
Test Loss:  3.193949305568822e-05
Valid Loss:  8.51786753628403e-05
Epoch:  341  	Training Loss: 6.420854333555326e-05
Test Loss:  3.186685353284702e-05
Valid Loss:  8.493085624650121e-05
Epoch:  342  	Training Loss: 6.398912955773994e-05
Test Loss:  3.182928776368499e-05
Valid Loss:  8.477928349748254e-05
Epoch:  343  	Training Loss: 6.391628994606435e-05
Test Loss:  3.186133108101785e-05
Valid Loss:  8.465889550279826e-05
Epoch:  344  	Training Loss: 6.385507003869861e-05
Test Loss:  3.192546864738688e-05
Valid Loss:  8.455677016172558e-05
Epoch:  345  	Training Loss: 6.37995544821024e-05
Test Loss:  3.2004791137296706e-05
Valid Loss:  8.446647552773356e-05
Epoch:  346  	Training Loss: 6.374854274326935e-05
Test Loss:  3.2090167223941535e-05
Valid Loss:  8.438414079137146e-05
Epoch:  347  	Training Loss: 6.370146002154797e-05
Test Loss:  3.217736229998991e-05
Valid Loss:  8.430794696323574e-05
Epoch:  348  	Training Loss: 6.365809531416744e-05
Test Loss:  3.226421176805161e-05
Valid Loss:  8.423815597780049e-05
Epoch:  349  	Training Loss: 6.361793202813715e-05
Test Loss:  3.234980977140367e-05
Valid Loss:  8.417220669798553e-05
Epoch:  350  	Training Loss: 6.35808683000505e-05
Test Loss:  3.243375977035612e-05
Valid Loss:  8.41111468616873e-05
Epoch:  351  	Training Loss: 6.35460892226547e-05
Test Loss:  3.2515112252440304e-05
Valid Loss:  8.405296830460429e-05
Epoch:  352  	Training Loss: 6.351435877149925e-05
Test Loss:  3.267755528213456e-05
Valid Loss:  8.388266724068671e-05
Epoch:  353  	Training Loss: 6.32952869636938e-05
Test Loss:  3.265085615566932e-05
Valid Loss:  8.366200927412137e-05
Epoch:  354  	Training Loss: 6.309331365628168e-05
Test Loss:  3.261358506279066e-05
Valid Loss:  8.344161324203014e-05
Epoch:  355  	Training Loss: 6.289986777119339e-05
Test Loss:  3.258186188759282e-05
Valid Loss:  8.322435314767063e-05
Epoch:  356  	Training Loss: 6.27122717560269e-05
Test Loss:  3.255721821915358e-05
Valid Loss:  8.300978515762836e-05
Epoch:  357  	Training Loss: 6.252997263800353e-05
Test Loss:  3.2541131076868623e-05
Valid Loss:  8.280085603473708e-05
Epoch:  358  	Training Loss: 6.235310866031796e-05
Test Loss:  3.252970418543555e-05
Valid Loss:  8.259540481958538e-05
Epoch:  359  	Training Loss: 6.218058115337044e-05
Test Loss:  3.252154419897124e-05
Valid Loss:  8.239317685365677e-05
Epoch:  360  	Training Loss: 6.20128121227026e-05
Test Loss:  3.251595262554474e-05
Valid Loss:  8.219452865887433e-05
Epoch:  361  	Training Loss: 6.184860831126571e-05
Test Loss:  3.2514548365725204e-05
Valid Loss:  8.199868898373097e-05
Epoch:  362  	Training Loss: 6.168845720821992e-05
Test Loss:  3.2525618735235184e-05
Valid Loss:  8.187988714780658e-05
Epoch:  363  	Training Loss: 6.161582132335752e-05
Test Loss:  3.2543157431064174e-05
Valid Loss:  8.176745905075222e-05
Epoch:  364  	Training Loss: 6.154461152618751e-05
Test Loss:  3.255987758166157e-05
Valid Loss:  8.165708277374506e-05
Epoch:  365  	Training Loss: 6.147423846414313e-05
Test Loss:  3.257383650634438e-05
Valid Loss:  8.154923852998763e-05
Epoch:  366  	Training Loss: 6.140556797618046e-05
Test Loss:  3.258424476371147e-05
Valid Loss:  8.144222374539822e-05
Epoch:  367  	Training Loss: 6.133566057542339e-05
Test Loss:  3.259228833485395e-05
Valid Loss:  8.133793016895652e-05
Epoch:  368  	Training Loss: 6.126288644736633e-05
Test Loss:  3.25874934787862e-05
Valid Loss:  8.123121369862929e-05
Epoch:  369  	Training Loss: 6.119059980846941e-05
Test Loss:  3.256954732933082e-05
Valid Loss:  8.112438081298023e-05
Epoch:  370  	Training Loss: 6.111950642662123e-05
Test Loss:  3.2550022297073156e-05
Valid Loss:  8.101873390842229e-05
Epoch:  371  	Training Loss: 6.104792555561289e-05
Test Loss:  3.2528208976145834e-05
Valid Loss:  8.09148041298613e-05
Epoch:  372  	Training Loss: 6.0972193750785664e-05
Test Loss:  3.2357871532440186e-05
Valid Loss:  8.076171070570126e-05
Epoch:  373  	Training Loss: 6.08842856308911e-05
Test Loss:  3.2235271646641195e-05
Valid Loss:  8.0626763519831e-05
Epoch:  374  	Training Loss: 6.079926970414817e-05
Test Loss:  3.213260060874745e-05
Valid Loss:  8.049761527217925e-05
Epoch:  375  	Training Loss: 6.071727693779394e-05
Test Loss:  3.2043633837020025e-05
Valid Loss:  8.037210500333458e-05
Epoch:  376  	Training Loss: 6.063705586711876e-05
Test Loss:  3.1962787033990026e-05
Valid Loss:  8.024748967727646e-05
Epoch:  377  	Training Loss: 6.055801350157708e-05
Test Loss:  3.18880302074831e-05
Valid Loss:  8.012447506189346e-05
Epoch:  378  	Training Loss: 6.0480186220956966e-05
Test Loss:  3.182283398928121e-05
Valid Loss:  8.000282832654193e-05
Epoch:  379  	Training Loss: 6.040340304025449e-05
Test Loss:  3.176491009071469e-05
Valid Loss:  7.988212746568024e-05
Epoch:  380  	Training Loss: 6.0328442486934364e-05
Test Loss:  3.1713447242509574e-05
Valid Loss:  7.976359484018758e-05
Epoch:  381  	Training Loss: 6.0254125855863094e-05
Test Loss:  3.166648457408883e-05
Valid Loss:  7.964641554281116e-05
Epoch:  382  	Training Loss: 6.018118801875971e-05
Test Loss:  3.1571093131788075e-05
Valid Loss:  7.955217733979225e-05
Epoch:  383  	Training Loss: 6.013881284161471e-05
Test Loss:  3.1528474210062996e-05
Valid Loss:  7.948388520162553e-05
Epoch:  384  	Training Loss: 6.010055585647933e-05
Test Loss:  3.151036435156129e-05
Valid Loss:  7.942689262563363e-05
Epoch:  385  	Training Loss: 6.0063626733608544e-05
Test Loss:  3.1504358048550785e-05
Valid Loss:  7.937718328321353e-05
Epoch:  386  	Training Loss: 6.002744703437202e-05
Test Loss:  3.150355405523442e-05
Valid Loss:  7.933034066809341e-05
Epoch:  387  	Training Loss: 5.999152563163079e-05
Test Loss:  3.150483826175332e-05
Valid Loss:  7.928418926894665e-05
Epoch:  388  	Training Loss: 5.995598257868551e-05
Test Loss:  3.150785050820559e-05
Valid Loss:  7.923987868707627e-05
Epoch:  389  	Training Loss: 5.99205814069137e-05
Test Loss:  3.1510637199971825e-05
Valid Loss:  7.919624476926401e-05
Epoch:  390  	Training Loss: 5.988548218738288e-05
Test Loss:  3.151315831928514e-05
Valid Loss:  7.915266178315505e-05
Epoch:  391  	Training Loss: 5.985096504446119e-05
Test Loss:  3.151545024593361e-05
Valid Loss:  7.910963904578239e-05
Epoch:  392  	Training Loss: 5.981664435239509e-05
Test Loss:  3.164439840475097e-05
Valid Loss:  7.888533582445234e-05
Epoch:  393  	Training Loss: 5.9526439144974574e-05
Test Loss:  3.149045733152889e-05
Valid Loss:  7.855745207052678e-05
Epoch:  394  	Training Loss: 5.9251528000459075e-05
Test Loss:  3.138460670015775e-05
Valid Loss:  7.82476708991453e-05
Epoch:  395  	Training Loss: 5.8981422625947744e-05
Test Loss:  3.127973104710691e-05
Valid Loss:  7.793988334015012e-05
Epoch:  396  	Training Loss: 5.8717731008073315e-05
Test Loss:  3.11870317091234e-05
Valid Loss:  7.764159818179905e-05
Epoch:  397  	Training Loss: 5.845933628734201e-05
Test Loss:  3.1094474252313375e-05
Valid Loss:  7.734876999165863e-05
Epoch:  398  	Training Loss: 5.820413207402453e-05
Test Loss:  3.100280446233228e-05
Valid Loss:  7.706269389018416e-05
Epoch:  399  	Training Loss: 5.795791366836056e-05
Test Loss:  3.094104613410309e-05
Valid Loss:  7.679250848013908e-05
Epoch:  400  	Training Loss: 5.772109579993412e-05
Test Loss:  3.086941069341265e-05
Valid Loss:  7.652172644156963e-05
Epoch:  401  	Training Loss: 5.74894183955621e-05
Test Loss:  3.08144444716163e-05
Valid Loss:  7.625874422956258e-05
Epoch:  402  	Training Loss: 5.726773088099435e-05
Test Loss:  3.0781222449149936e-05
Valid Loss:  7.609391468577087e-05
Epoch:  403  	Training Loss: 5.7131088396999985e-05
Test Loss:  3.0709183192811906e-05
Valid Loss:  7.591365283587947e-05
Epoch:  404  	Training Loss: 5.6999379012268037e-05
Test Loss:  3.06441324937623e-05
Valid Loss:  7.573938637506217e-05
Epoch:  405  	Training Loss: 5.6873264838941395e-05
Test Loss:  3.058954462176189e-05
Valid Loss:  7.557624485343695e-05
Epoch:  406  	Training Loss: 5.675060674548149e-05
Test Loss:  3.0520161089953035e-05
Valid Loss:  7.541399099864066e-05
Epoch:  407  	Training Loss: 5.663005504175089e-05
Test Loss:  3.0456423701252788e-05
Valid Loss:  7.525698310928419e-05
 82%|████████▏ | 409/500 [04:50<00:30,  2.98it/s] 82%|████████▏ | 411/500 [04:56<01:44,  1.17s/it] 83%|████████▎ | 413/500 [04:56<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:56<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:56<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:57<00:27,  3.00it/s] 84%|████████▍ | 421/500 [05:03<01:34,  1.19s/it] 85%|████████▍ | 423/500 [05:03<01:06,  1.16it/s] 85%|████████▌ | 425/500 [05:03<00:46,  1.60it/s] 85%|████████▌ | 427/500 [05:03<00:33,  2.19it/s] 86%|████████▌ | 429/500 [05:04<00:24,  2.95it/s] 86%|████████▌ | 431/500 [05:10<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:10<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:10<00:39,  1.65it/s] 87%|████████▋ | 437/500 [05:10<00:28,  2.23it/s] 88%|████████▊ | 439/500 [05:10<00:20,  2.93it/s] 88%|████████▊ | 441/500 [05:17<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:17<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:17<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:17<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:17<00:16,  3.00it/s] 90%|█████████ | 451/500 [05:24<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:24<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:24<00:27,  1.61it/s] 91%|█████████▏| 457/500 [05:24<00:19,  2.20it/s] 92%|█████████▏| 459/500 [05:24<00:13,  2.96it/s] 92%|█████████▏| 461/500 [05:30<00:45,  1.18s/it] 93%|█████████▎| 463/500 [05:31<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:31<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:31<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:31<00:10,  3.00it/s] 94%|█████████▍| 471/500 [05:37<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:37<00:22,  1.18it/s]Epoch:  408  	Training Loss: 5.651375249726698e-05
Test Loss:  3.038844806724228e-05
Valid Loss:  7.510118302889168e-05
Epoch:  409  	Training Loss: 5.639922164846212e-05
Test Loss:  3.032935092051048e-05
Valid Loss:  7.495048339478672e-05
Epoch:  410  	Training Loss: 5.62888162676245e-05
Test Loss:  3.0276882171165198e-05
Valid Loss:  7.480485510313883e-05
Epoch:  411  	Training Loss: 5.618207069346681e-05
Test Loss:  3.0231291020754725e-05
Valid Loss:  7.466526585631073e-05
Epoch:  412  	Training Loss: 5.607908315141685e-05
Test Loss:  3.0157090805005282e-05
Valid Loss:  7.456521416315809e-05
Epoch:  413  	Training Loss: 5.598399002337828e-05
Test Loss:  3.0058530683163553e-05
Valid Loss:  7.445245137205347e-05
Epoch:  414  	Training Loss: 5.589110514847562e-05
Test Loss:  2.9958602681290358e-05
Valid Loss:  7.433975406456739e-05
Epoch:  415  	Training Loss: 5.579939534072764e-05
Test Loss:  2.9863485906389542e-05
Valid Loss:  7.422677299473435e-05
Epoch:  416  	Training Loss: 5.57088314963039e-05
Test Loss:  2.977433177875355e-05
Valid Loss:  7.411498518195003e-05
Epoch:  417  	Training Loss: 5.5619326303713024e-05
Test Loss:  2.969057641166728e-05
Valid Loss:  7.400353206321597e-05
Epoch:  418  	Training Loss: 5.553050141315907e-05
Test Loss:  2.961146310553886e-05
Valid Loss:  7.38929957151413e-05
Epoch:  419  	Training Loss: 5.544240411836654e-05
Test Loss:  2.9536517104133964e-05
Valid Loss:  7.377941801678389e-05
Epoch:  420  	Training Loss: 5.5354834330501035e-05
Test Loss:  2.946583117591217e-05
Valid Loss:  7.366185309365392e-05
Epoch:  421  	Training Loss: 5.526786844711751e-05
Test Loss:  2.9398446713457815e-05
Valid Loss:  7.354528497671708e-05
Epoch:  422  	Training Loss: 5.518405669135973e-05
Test Loss:  2.9238213755888864e-05
Valid Loss:  7.334963447647169e-05
Epoch:  423  	Training Loss: 5.5112883273977786e-05
Test Loss:  2.9271013772813603e-05
Valid Loss:  7.325358456000686e-05
Epoch:  424  	Training Loss: 5.505851731868461e-05
Test Loss:  2.9339884349610656e-05
Valid Loss:  7.318016287172213e-05
Epoch:  425  	Training Loss: 5.5008422350510955e-05
Test Loss:  2.9413522497634403e-05
Valid Loss:  7.311365334317088e-05
Epoch:  426  	Training Loss: 5.4960662964731455e-05
Test Loss:  2.9483551770681515e-05
Valid Loss:  7.305089093279094e-05
Epoch:  427  	Training Loss: 5.4915544751565903e-05
Test Loss:  2.954880073957611e-05
Valid Loss:  7.299098069779575e-05
Epoch:  428  	Training Loss: 5.487278394866735e-05
Test Loss:  2.960797428386286e-05
Valid Loss:  7.293398084584624e-05
Epoch:  429  	Training Loss: 5.483246059156954e-05
Test Loss:  2.9664452085853554e-05
Valid Loss:  7.287795597221702e-05
Epoch:  430  	Training Loss: 5.4794028983451426e-05
Test Loss:  2.9715567507082596e-05
Valid Loss:  7.282513979589567e-05
Epoch:  431  	Training Loss: 5.475801299326122e-05
Test Loss:  2.976523137476761e-05
Valid Loss:  7.277366239577532e-05
Epoch:  432  	Training Loss: 5.472321936395019e-05
Test Loss:  2.9652339435415342e-05
Valid Loss:  7.258048572111875e-05
Epoch:  433  	Training Loss: 5.454863276099786e-05
Test Loss:  2.9493225156329572e-05
Valid Loss:  7.240897684823722e-05
Epoch:  434  	Training Loss: 5.4409891163231805e-05
Test Loss:  2.9346338124014437e-05
Valid Loss:  7.227447349578142e-05
Epoch:  435  	Training Loss: 5.429470184026286e-05
Test Loss:  2.9220454962342046e-05
Valid Loss:  7.215034565888345e-05
Epoch:  436  	Training Loss: 5.421171590569429e-05
Test Loss:  2.911533010774292e-05
Valid Loss:  7.2030998126138e-05
Epoch:  437  	Training Loss: 5.4135129175847396e-05
Test Loss:  2.902939922933001e-05
Valid Loss:  7.191827171482146e-05
Epoch:  438  	Training Loss: 5.4062889830674976e-05
Test Loss:  2.8953207220183685e-05
Valid Loss:  7.180655666161329e-05
Epoch:  439  	Training Loss: 5.399279325501993e-05
Test Loss:  2.888824383262545e-05
Valid Loss:  7.169669697759673e-05
Epoch:  440  	Training Loss: 5.392483581090346e-05
Test Loss:  2.8832562747993506e-05
Valid Loss:  7.158856897149235e-05
Epoch:  441  	Training Loss: 5.385853728512302e-05
Test Loss:  2.8788665076717734e-05
Valid Loss:  7.148389704525471e-05
Epoch:  442  	Training Loss: 5.3794195991940796e-05
Test Loss:  2.8980530260014348e-05
Valid Loss:  7.142650429159403e-05
Epoch:  443  	Training Loss: 5.371967563405633e-05
Test Loss:  2.9117389203747734e-05
Valid Loss:  7.136780914152041e-05
Epoch:  444  	Training Loss: 5.3653810027753934e-05
Test Loss:  2.9214364985818975e-05
Valid Loss:  7.130611629690975e-05
Epoch:  445  	Training Loss: 5.359224815038033e-05
Test Loss:  2.928246249211952e-05
Valid Loss:  7.12397086317651e-05
Epoch:  446  	Training Loss: 5.35329309059307e-05
Test Loss:  2.9329818062251434e-05
Valid Loss:  7.117042696336284e-05
Epoch:  447  	Training Loss: 5.347477417672053e-05
Test Loss:  2.936533564934507e-05
Valid Loss:  7.109946454875171e-05
Epoch:  448  	Training Loss: 5.341749420040287e-05
Test Loss:  2.938965189969167e-05
Valid Loss:  7.102773088263348e-05
Epoch:  449  	Training Loss: 5.336096364771947e-05
Test Loss:  2.940589183708653e-05
Valid Loss:  7.095378532540053e-05
Epoch:  450  	Training Loss: 5.330480053089559e-05
Test Loss:  2.9416216420941055e-05
Valid Loss:  7.088075653882697e-05
Epoch:  451  	Training Loss: 5.32493504579179e-05
Test Loss:  2.9422782972687855e-05
Valid Loss:  7.080670184222981e-05
Epoch:  452  	Training Loss: 5.319368210621178e-05
Test Loss:  2.9130056645954028e-05
Valid Loss:  7.060520874802023e-05
Epoch:  453  	Training Loss: 5.311912173056044e-05
Test Loss:  2.9056431230856106e-05
Valid Loss:  7.048896077321842e-05
Epoch:  454  	Training Loss: 5.305857484927401e-05
Test Loss:  2.902924461523071e-05
Valid Loss:  7.03899931977503e-05
Epoch:  455  	Training Loss: 5.2999399485997856e-05
Test Loss:  2.9011232982156798e-05
Valid Loss:  7.029612606856972e-05
Epoch:  456  	Training Loss: 5.2941169997211546e-05
Test Loss:  2.8994611056987196e-05
Valid Loss:  7.020409975666553e-05
Epoch:  457  	Training Loss: 5.2882001909893006e-05
Test Loss:  2.8977297915844247e-05
Valid Loss:  7.01139506418258e-05
Epoch:  458  	Training Loss: 5.2819897973677143e-05
Test Loss:  2.8952166758244857e-05
Valid Loss:  7.002189522609115e-05
Epoch:  459  	Training Loss: 5.275809235172346e-05
Test Loss:  2.8924592697876506e-05
Valid Loss:  6.99295342201367e-05
Epoch:  460  	Training Loss: 5.269716348266229e-05
Test Loss:  2.8897584343212657e-05
Valid Loss:  6.983822822803631e-05
Epoch:  461  	Training Loss: 5.263693310553208e-05
Test Loss:  2.887124355765991e-05
Valid Loss:  6.97480863891542e-05
Epoch:  462  	Training Loss: 5.2577510359697044e-05
Test Loss:  2.869048148568254e-05
Valid Loss:  6.959251186344773e-05
Epoch:  463  	Training Loss: 5.24050192325376e-05
Test Loss:  2.8525260859169066e-05
Valid Loss:  6.943315383978188e-05
Epoch:  464  	Training Loss: 5.2240440709283575e-05
Test Loss:  2.8389298677211627e-05
Valid Loss:  6.927813228685409e-05
Epoch:  465  	Training Loss: 5.2081952162552625e-05
Test Loss:  2.8273614589124918e-05
Valid Loss:  6.912482785992324e-05
Epoch:  466  	Training Loss: 5.192823664401658e-05
Test Loss:  2.8175394618301652e-05
Valid Loss:  6.897313141962513e-05
Epoch:  467  	Training Loss: 5.177913772058673e-05
Test Loss:  2.80930835288018e-05
Valid Loss:  6.882525485707447e-05
Epoch:  468  	Training Loss: 5.163418245501816e-05
Test Loss:  2.8018024750053883e-05
Valid Loss:  6.867767660878599e-05
Epoch:  469  	Training Loss: 5.149252319824882e-05
Test Loss:  2.7951080483035184e-05
Valid Loss:  6.853046943433583e-05
Epoch:  470  	Training Loss: 5.135391256771982e-05
Test Loss:  2.7893953301827423e-05
Valid Loss:  6.838599074399099e-05
Epoch:  471  	Training Loss: 5.121819776832126e-05
Test Loss:  2.7841977498610504e-05
Valid Loss:  6.824270531069487e-05
Epoch:  472  	Training Loss: 5.108548793941736e-05
Test Loss:  2.7947337002842687e-05
Valid Loss:  6.821540591772646e-05
Epoch:  473  	Training Loss: 5.1040100515820086e-05
Test Loss:  2.801537084451411e-05
Valid Loss:  6.818168913014233e-05
Epoch:  474  	Training Loss: 5.099718691781163e-05
Test Loss:  2.8054524591425434e-05
Valid Loss:  6.813988875364885e-05
Epoch:  475  	Training Loss: 5.0956492486875504e-05
Test Loss:  2.8075599402654916e-05
Valid Loss:   95%|█████████▌| 475/500 [05:38<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:38<00:10,  2.22it/s] 96%|█████████▌| 479/500 [05:38<00:07,  2.99it/s] 96%|█████████▌| 481/500 [05:44<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:44<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:44<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:44<00:05,  2.23it/s] 98%|█████████▊| 489/500 [05:45<00:03,  2.98it/s] 98%|█████████▊| 491/500 [05:51<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:51<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:51<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:51<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:51<00:00,  3.00it/s]100%|██████████| 500/500 [05:52<00:00,  1.42it/s]
6.809381011407822e-05
Epoch:  476  	Training Loss: 5.0916511099785566e-05
Test Loss:  2.808587669278495e-05
Valid Loss:  6.804372242186219e-05
Epoch:  477  	Training Loss: 5.0877148169092834e-05
Test Loss:  2.808834324241616e-05
Valid Loss:  6.799305992899463e-05
Epoch:  478  	Training Loss: 5.0838218157878146e-05
Test Loss:  2.8086429665563628e-05
Valid Loss:  6.79396471241489e-05
Epoch:  479  	Training Loss: 5.079943366581574e-05
Test Loss:  2.80811309494311e-05
Valid Loss:  6.788695463910699e-05
Epoch:  480  	Training Loss: 5.076044544694014e-05
Test Loss:  2.8073845896869898e-05
Valid Loss:  6.783310527680442e-05
Epoch:  481  	Training Loss: 5.072199564892799e-05
Test Loss:  2.8065507649444044e-05
Valid Loss:  6.777973612770438e-05
Epoch:  482  	Training Loss: 5.0683818699326366e-05
Test Loss:  2.7602251066127792e-05
Valid Loss:  6.747771840309724e-05
Epoch:  483  	Training Loss: 5.060191688244231e-05
Test Loss:  2.7612481062533334e-05
Valid Loss:  6.741692050127313e-05
Epoch:  484  	Training Loss: 5.0552123866509646e-05
Test Loss:  2.7598693122854456e-05
Valid Loss:  6.734470662195235e-05
Epoch:  485  	Training Loss: 5.050298204878345e-05
Test Loss:  2.7590782337938435e-05
Valid Loss:  6.727469008183107e-05
Epoch:  486  	Training Loss: 5.045655416324735e-05
Test Loss:  2.7584148483583704e-05
Valid Loss:  6.720599776599556e-05
Epoch:  487  	Training Loss: 5.041280383011326e-05
Test Loss:  2.7577927539823577e-05
Valid Loss:  6.71379966661334e-05
Epoch:  488  	Training Loss: 5.037051596445963e-05
Test Loss:  2.7575089916354045e-05
Valid Loss:  6.707233842462301e-05
Epoch:  489  	Training Loss: 5.0328388169873506e-05
Test Loss:  2.7572381441132165e-05
Valid Loss:  6.70079025439918e-05
Epoch:  490  	Training Loss: 5.028684972785413e-05
Test Loss:  2.7567861252464354e-05
Valid Loss:  6.694425246678293e-05
Epoch:  491  	Training Loss: 5.024510028306395e-05
Test Loss:  2.7562189643504098e-05
Valid Loss:  6.687965651508421e-05
Epoch:  492  	Training Loss: 5.020389653509483e-05
Test Loss:  2.7580943424254656e-05
Valid Loss:  6.680596561636776e-05
Epoch:  493  	Training Loss: 5.012023029848933e-05
Test Loss:  2.7534733817446977e-05
Valid Loss:  6.6707085352391e-05
Epoch:  494  	Training Loss: 5.0037378969136626e-05
Test Loss:  2.7469028282212093e-05
Valid Loss:  6.659942300757393e-05
Epoch:  495  	Training Loss: 4.995622657588683e-05
Test Loss:  2.741334174061194e-05
Valid Loss:  6.649349961662665e-05
Epoch:  496  	Training Loss: 4.987665670341812e-05
Test Loss:  2.736239184741862e-05
Valid Loss:  6.63885657559149e-05
Epoch:  497  	Training Loss: 4.979833465768024e-05
Test Loss:  2.7316065825289115e-05
Valid Loss:  6.628471601288766e-05
Epoch:  498  	Training Loss: 4.9721391405910254e-05
Test Loss:  2.727233004407026e-05
Valid Loss:  6.618109182454646e-05
Epoch:  499  	Training Loss: 4.964484105585143e-05
Test Loss:  2.723198849707842e-05
Valid Loss:  6.607852265005931e-05
Epoch:  500  	Training Loss: 4.956963311997242e-05
Test Loss:  2.720360498642549e-05
Valid Loss:  6.597934407182038e-05
seed is  8
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.10it/s]  1%|          | 4/500 [00:00<00:30, 16.27it/s]  1%|          | 6/500 [00:00<00:30, 16.39it/s]  2%|▏         | 8/500 [00:00<00:29, 16.48it/s]  2%|▏         | 10/500 [00:00<00:30, 16.31it/s]  2%|▏         | 12/500 [00:00<00:29, 16.40it/s]  3%|▎         | 14/500 [00:00<00:29, 16.43it/s]  3%|▎         | 16/500 [00:00<00:29, 16.32it/s]  4%|▎         | 18/500 [00:01<00:29, 16.39it/s]  4%|▍         | 20/500 [00:01<00:29, 16.24it/s]  4%|▍         | 22/500 [00:01<00:29, 16.16it/s]  5%|▍         | 24/500 [00:01<00:29, 16.09it/s]  5%|▌         | 26/500 [00:01<00:29, 16.16it/s]  6%|▌         | 28/500 [00:01<00:28, 16.29it/s]  6%|▌         | 30/500 [00:01<00:28, 16.36it/s]  6%|▋         | 32/500 [00:01<00:28, 16.33it/s]  7%|▋         | 34/500 [00:02<00:28, 16.37it/s]  7%|▋         | 36/500 [00:02<00:28, 16.39it/s]  8%|▊         | 38/500 [00:02<00:28, 16.39it/s]  8%|▊         | 40/500 [00:02<00:28, 16.31it/s]  8%|▊         | 42/500 [00:02<00:28, 16.20it/s]  9%|▉         | 44/500 [00:02<00:28, 16.19it/s]  9%|▉         | 46/500 [00:02<00:28, 16.18it/s] 10%|▉         | 48/500 [00:02<00:27, 16.31it/s] 10%|█         | 50/500 [00:03<00:27, 16.28it/s] 10%|█         | 52/500 [00:03<00:27, 16.20it/s] 11%|█         | 54/500 [00:03<00:27, 16.26it/s] 11%|█         | 56/500 [00:03<00:28, 15.70it/s] 12%|█▏        | 58/500 [00:03<00:30, 14.68it/s] 12%|█▏        | 60/500 [00:03<00:29, 15.06it/s] 12%|█▏        | 62/500 [00:03<00:28, 15.51it/s] 13%|█▎        | 64/500 [00:03<00:27, 15.79it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.93it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.05it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.16it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.23it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.34it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.27it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.23it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.29it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.33it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.31it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.41it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.43it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.32it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.37it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.42it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.30it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.23it/s] 20%|██        | 100/500 [00:06<00:24, 16.25it/s] 20%|██        | 102/500 [00:06<00:24, 16.04it/s] 21%|██        | 104/500 [00:06<00:24, 16.16it/s] 21%|██        | 106/500 [00:06<00:24, 16.30it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.32it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.43it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.17it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.48it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.66it/s] 24%|██▎       | 118/500 [00:07<00:24, 15.85it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.04it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.15it/s]Epoch:  1  	Training Loss: 0.029495008289813995
Test Loss:  0.11088533699512482
Valid Loss:  0.10492980480194092
Epoch:  2  	Training Loss: 0.13629138469696045
Test Loss:  1275.679443359375
Valid Loss:  1276.2320556640625
Epoch:  3  	Training Loss: 1269.27978515625
Test Loss:  2402232116969472.0
Valid Loss:  2403393905623040.0
Epoch:  4  	Training Loss: 2408292852695040.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  5  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▍       | 124/500 [00:07<00:23, 16.28it/s] 25%|██▌       | 126/500 [00:07<00:22, 16.35it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.29it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.13it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.20it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.26it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.37it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.40it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.44it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.43it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.41it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.44it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.32it/s] 30%|███       | 150/500 [00:09<00:21, 16.28it/s] 30%|███       | 152/500 [00:09<00:21, 16.39it/s] 31%|███       | 154/500 [00:09<00:21, 16.43it/s] 31%|███       | 156/500 [00:09<00:20, 16.47it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.42it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.36it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.38it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.19it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.17it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.19it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.26it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.29it/s] 35%|███▍      | 174/500 [00:10<00:20, 16.22it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.23it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.28it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.33it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.34it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.35it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.38it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.42it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.38it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.22it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.14it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.29it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.25it/s] 40%|████      | 200/500 [00:12<00:18, 16.38it/s] 40%|████      | 202/500 [00:12<00:18, 16.43it/s] 41%|████      | 204/500 [00:12<00:18, 16.37it/s] 41%|████      | 206/500 [00:12<00:17, 16.45it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.26it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.22it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.21it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.33it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.37it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.40it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.43it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.42it/s] 45%|████▍     | 224/500 [00:13<00:18, 15.25it/s] 45%|████▌     | 226/500 [00:13<00:18, 14.97it/s] 46%|████▌     | 228/500 [00:14<00:17, 15.28it/s] 46%|████▌     | 230/500 [00:14<00:17, 15.58it/s] 46%|████▋     | 232/500 [00:14<00:16, 15.78it/s] 47%|████▋     | 234/500 [00:14<00:16, 15.98it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.05it/s] 48%|████▊     | 238/500 [00:14<00:17, 15.19it/s] 48%|████▊     | 240/500 [00:14<00:16, 15.49it/s] 48%|████▊     | 242/500 [00:14<00:16, 15.69it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.94it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.01it/s]Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|████▉     | 248/500 [00:15<00:15, 16.22it/s] 50%|█████     | 250/500 [00:15<00:15, 16.28it/s] 50%|█████     | 252/500 [00:15<00:15, 16.44it/s] 51%|█████     | 254/500 [00:15<00:15, 16.39it/s] 51%|█████     | 256/500 [00:15<00:14, 16.29it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.40it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.49it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.55it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.60it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.53it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.52it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.23it/s] 54%|█████▍    | 272/500 [00:16<00:14, 15.99it/s] 55%|█████▍    | 274/500 [00:16<00:14, 15.80it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.38it/s] 56%|█████▌    | 278/500 [00:17<00:14, 15.66it/s] 56%|█████▌    | 280/500 [00:17<00:13, 15.91it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.04it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.21it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.30it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.34it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.44it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.49it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.50it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.47it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.42it/s] 60%|██████    | 300/500 [00:18<00:12, 16.37it/s] 60%|██████    | 302/500 [00:18<00:12, 16.36it/s] 61%|██████    | 304/500 [00:18<00:12, 15.41it/s] 61%|██████    | 306/500 [00:18<00:12, 15.65it/s] 62%|██████▏   | 308/500 [00:19<00:12, 15.79it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.00it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.17it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.06it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.16it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.21it/s] 64%|██████▍   | 320/500 [00:19<00:11, 16.26it/s] 64%|██████▍   | 322/500 [00:19<00:11, 16.14it/s] 65%|██████▍   | 324/500 [00:20<00:11, 15.89it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.06it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.12it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.22it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.32it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.30it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.29it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.21it/s] 68%|██████▊   | 340/500 [00:21<00:10, 15.99it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.02it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.08it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.18it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.20it/s] 70%|███████   | 350/500 [00:21<00:09, 16.25it/s] 70%|███████   | 352/500 [00:21<00:09, 16.24it/s] 71%|███████   | 354/500 [00:21<00:09, 16.22it/s] 71%|███████   | 356/500 [00:22<00:08, 16.15it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.12it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.11it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.18it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.20it/s] 73%|███████▎  | 366/500 [00:22<00:08, 15.45it/s] 74%|███████▎  | 368/500 [00:22<00:08, 15.07it/s] 74%|███████▍  | 370/500 [00:22<00:08, 15.53it/s]Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 74%|███████▍  | 372/500 [00:23<00:08, 15.81it/s] 75%|███████▍  | 374/500 [00:23<00:07, 15.99it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.02it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.09it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.18it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.24it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.23it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.31it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.23it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.20it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.25it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.28it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.33it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.41it/s] 80%|████████  | 400/500 [00:24<00:06, 16.39it/s] 80%|████████  | 402/500 [00:24<00:06, 16.21it/s] 81%|████████  | 404/500 [00:25<00:05, 16.14it/s] 81%|████████  | 406/500 [00:25<00:05, 16.19it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.26it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.36it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.38it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.38it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.23it/s] 84%|████████▎ | 418/500 [00:25<00:05, 16.19it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.11it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.07it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.24it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.39it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.43it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.54it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.43it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.42it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.41it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.44it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.41it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.42it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.39it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.28it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.21it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.26it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.33it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.22it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.26it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.30it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.13it/s] 92%|█████████▏| 462/500 [00:28<00:02, 15.47it/s] 93%|█████████▎| 464/500 [00:28<00:02, 15.14it/s] 93%|█████████▎| 466/500 [00:28<00:02, 14.43it/s] 94%|█████████▎| 468/500 [00:29<00:02, 13.58it/s] 94%|█████████▍| 470/500 [00:29<00:02, 13.15it/s] 94%|█████████▍| 472/500 [00:29<00:02, 13.83it/s] 95%|█████████▍| 474/500 [00:29<00:01, 14.56it/s] 95%|█████████▌| 476/500 [00:29<00:01, 15.10it/s] 96%|█████████▌| 478/500 [00:29<00:01, 15.46it/s] 96%|█████████▌| 480/500 [00:29<00:01, 15.78it/s] 96%|█████████▋| 482/500 [00:29<00:01, 15.97it/s] 97%|█████████▋| 484/500 [00:30<00:00, 16.01it/s] 97%|█████████▋| 486/500 [00:30<00:00, 16.12it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.20it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.27it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.21it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.28it/s]Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 99%|█████████▉| 496/500 [00:30<00:00, 16.39it/s]100%|█████████▉| 498/500 [00:30<00:00, 16.43it/s]100%|██████████| 500/500 [00:31<00:00, 16.47it/s]100%|██████████| 500/500 [00:31<00:00, 16.11it/s]
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  8
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:50,  6.23s/it]  1%|          | 3/500 [00:06<13:49,  1.67s/it]  1%|          | 5/500 [00:06<06:57,  1.18it/s]  1%|▏         | 7/500 [00:06<04:13,  1.95it/s]  2%|▏         | 9/500 [00:06<02:49,  2.89it/s]  2%|▏         | 11/500 [00:13<10:49,  1.33s/it]  3%|▎         | 13/500 [00:13<07:22,  1.10it/s]  3%|▎         | 15/500 [00:13<05:08,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:41,  2.99it/s]  4%|▍         | 21/500 [00:19<09:40,  1.21s/it]  5%|▍         | 23/500 [00:20<06:51,  1.16it/s]  5%|▌         | 25/500 [00:20<04:54,  1.61it/s]  5%|▌         | 27/500 [00:20<03:34,  2.21it/s]  6%|▌         | 29/500 [00:20<02:38,  2.97it/s]  6%|▌         | 31/500 [00:26<09:18,  1.19s/it]  7%|▋         | 33/500 [00:27<06:39,  1.17it/s]  7%|▋         | 35/500 [00:27<04:47,  1.62it/s]  7%|▋         | 37/500 [00:27<03:29,  2.21it/s]  8%|▊         | 39/500 [00:27<02:34,  2.98it/s]  8%|▊         | 41/500 [00:33<09:02,  1.18s/it]  9%|▊         | 43/500 [00:33<06:27,  1.18it/s]  9%|▉         | 45/500 [00:33<04:39,  1.63it/s]  9%|▉         | 47/500 [00:34<03:23,  2.23it/s] 10%|▉         | 49/500 [00:34<02:30,  2.99it/s] 10%|█         | 51/500 [00:40<08:52,  1.19s/it] 11%|█         | 53/500 [00:40<06:20,  1.17it/s] 11%|█         | 55/500 [00:40<04:33,  1.62it/s] 11%|█▏        | 57/500 [00:40<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:41<02:27,  2.98it/s] 12%|█▏        | 61/500 [00:47<08:46,  1.20s/it] 13%|█▎        | 63/500 [00:47<06:16,  1.16it/s] 13%|█▎        | 65/500 [00:47<04:30,  1.61it/s] 13%|█▎        | 67/500 [00:47<03:17,  2.20it/s] 14%|█▍        | 69/500 [00:48<02:25,  2.95it/s] 14%|█▍        | 71/500 [00:54<08:28,  1.18s/it]Epoch:  1  	Training Loss: 0.029495006427168846
Test Loss:  0.026446029543876648
Valid Loss:  0.028038984164595604
Epoch:  2  	Training Loss: 0.021292567253112793
Test Loss:  1.078507900238037
Valid Loss:  1.0835239887237549
Epoch:  3  	Training Loss: 1.087083339691162
Test Loss:  0.02967064455151558
Valid Loss:  0.02637188509106636
Epoch:  4  	Training Loss: 0.03879257291555405
Test Loss:  0.028754111379384995
Valid Loss:  0.02555553987622261
Epoch:  5  	Training Loss: 0.03739592432975769
Test Loss:  0.027934525161981583
Valid Loss:  0.024831678718328476
Epoch:  6  	Training Loss: 0.03613031655550003
Test Loss:  0.027231337502598763
Valid Loss:  0.02421104907989502
Epoch:  7  	Training Loss: 0.03503870964050293
Test Loss:  0.02703896537423134
Valid Loss:  0.02403413876891136
Epoch:  8  	Training Loss: 0.034798212349414825
Test Loss:  0.02689850516617298
Valid Loss:  0.02390565164387226
Epoch:  9  	Training Loss: 0.03464856743812561
Test Loss:  0.026767343282699585
Valid Loss:  0.023783816024661064
Epoch:  10  	Training Loss: 0.03450653702020645
Test Loss:  0.02664477378129959
Valid Loss:  0.023677323013544083
Epoch:  11  	Training Loss: 0.034376293420791626
Test Loss:  0.02653932198882103
Valid Loss:  0.023580577224493027
Epoch:  12  	Training Loss: 0.03425974398851395
Test Loss:  0.026220712810754776
Valid Loss:  0.023286346346139908
Epoch:  13  	Training Loss: 0.03398900851607323
Test Loss:  0.02593740075826645
Valid Loss:  0.02302124910056591
Epoch:  14  	Training Loss: 0.03375522047281265
Test Loss:  0.02567112445831299
Valid Loss:  0.02277061715722084
Epoch:  15  	Training Loss: 0.033530786633491516
Test Loss:  0.025428272783756256
Valid Loss:  0.02253636159002781
Epoch:  16  	Training Loss: 0.03332392871379852
Test Loss:  0.025196626782417297
Valid Loss:  0.02231670171022415
Epoch:  17  	Training Loss: 0.03313218802213669
Test Loss:  0.02497478574514389
Valid Loss:  0.022111115977168083
Epoch:  18  	Training Loss: 0.03295452520251274
Test Loss:  0.024781808257102966
Valid Loss:  0.021921999752521515
Epoch:  19  	Training Loss: 0.03279571235179901
Test Loss:  0.024597853422164917
Valid Loss:  0.021742282435297966
Epoch:  20  	Training Loss: 0.03264397382736206
Test Loss:  0.024422045797109604
Valid Loss:  0.021571088582277298
Epoch:  21  	Training Loss: 0.03249834477901459
Test Loss:  0.02425893023610115
Valid Loss:  0.021406713873147964
Epoch:  22  	Training Loss: 0.03235812485218048
Test Loss:  0.024085476994514465
Valid Loss:  0.021234221756458282
Epoch:  23  	Training Loss: 0.03220370411872864
Test Loss:  0.023909876123070717
Valid Loss:  0.021073676645755768
Epoch:  24  	Training Loss: 0.032058004289865494
Test Loss:  0.023768439888954163
Valid Loss:  0.020937718451023102
Epoch:  25  	Training Loss: 0.03195305913686752
Test Loss:  0.023649070411920547
Valid Loss:  0.020817600190639496
Epoch:  26  	Training Loss: 0.031869590282440186
Test Loss:  0.02354223094880581
Valid Loss:  0.020704086869955063
Epoch:  27  	Training Loss: 0.031792521476745605
Test Loss:  0.023444946855306625
Valid Loss:  0.020595677196979523
Epoch:  28  	Training Loss: 0.031719982624053955
Test Loss:  0.023352179676294327
Valid Loss:  0.020494990050792694
Epoch:  29  	Training Loss: 0.03165159374475479
Test Loss:  0.02326664887368679
Valid Loss:  0.020399712026119232
Epoch:  30  	Training Loss: 0.031586796045303345
Test Loss:  0.023181147873401642
Valid Loss:  0.020310278981924057
Epoch:  31  	Training Loss: 0.03152644261717796
Test Loss:  0.023099808022379875
Valid Loss:  0.02022583968937397
Epoch:  32  	Training Loss: 0.031469665467739105
Test Loss:  0.023032022640109062
Valid Loss:  0.020149540156126022
Epoch:  33  	Training Loss: 0.03141911327838898
Test Loss:  0.022968489676713943
Valid Loss:  0.02007686346769333
Epoch:  34  	Training Loss: 0.03137031942605972
Test Loss:  0.022906271740794182
Valid Loss:  0.020009558647871017
Epoch:  35  	Training Loss: 0.031324077397584915
Test Loss:  0.022847699001431465
Valid Loss:  0.019947759807109833
Epoch:  36  	Training Loss: 0.031279440969228745
Test Loss:  0.02279030904173851
Valid Loss:  0.019891316071152687
Epoch:  37  	Training Loss: 0.031237464398145676
Test Loss:  0.02273426577448845
Valid Loss:  0.019837014377117157
Epoch:  38  	Training Loss: 0.03119748830795288
Test Loss:  0.022679835557937622
Valid Loss:  0.019784394651651382
Epoch:  39  	Training Loss: 0.031159741804003716
Test Loss:  0.02262553945183754
Valid Loss:  0.019732099026441574
Epoch:  40  	Training Loss: 0.031124116852879524
Test Loss:  0.022575322538614273
Valid Loss:  0.0196837130934
Epoch:  41  	Training Loss: 0.031090348958969116
Test Loss:  0.022528985515236855
Valid Loss:  0.019638564437627792
Epoch:  42  	Training Loss: 0.031058061867952347
Test Loss:  0.022480692714452744
Valid Loss:  0.019591212272644043
Epoch:  43  	Training Loss: 0.031024346128106117
Test Loss:  0.02243397943675518
Valid Loss:  0.019545812159776688
Epoch:  44  	Training Loss: 0.03099244087934494
Test Loss:  0.022390764206647873
Valid Loss:  0.019503476098179817
Epoch:  45  	Training Loss: 0.030961938202381134
Test Loss:  0.022350385785102844
Valid Loss:  0.019464945420622826
Epoch:  46  	Training Loss: 0.03093278780579567
Test Loss:  0.022310884669423103
Valid Loss:  0.019427377730607986
Epoch:  47  	Training Loss: 0.030905108898878098
Test Loss:  0.022273916751146317
Valid Loss:  0.019392235204577446
Epoch:  48  	Training Loss: 0.030878469347953796
Test Loss:  0.02223907597362995
Valid Loss:  0.019359122961759567
Epoch:  49  	Training Loss: 0.030852828174829483
Test Loss:  0.02220473624765873
Valid Loss:  0.019326556473970413
Epoch:  50  	Training Loss: 0.030828483402729034
Test Loss:  0.022172654047608376
Valid Loss:  0.01929686963558197
Epoch:  51  	Training Loss: 0.0308049526065588
Test Loss:  0.022143326699733734
Valid Loss:  0.019269153475761414
Epoch:  52  	Training Loss: 0.030782096087932587
Test Loss:  0.0221183430403471
Valid Loss:  0.019245518371462822
Epoch:  53  	Training Loss: 0.030761361122131348
Test Loss:  0.022092845290899277
Valid Loss:  0.01922149583697319
Epoch:  54  	Training Loss: 0.030741576105356216
Test Loss:  0.022068530321121216
Valid Loss:  0.01919861137866974
Epoch:  55  	Training Loss: 0.030722271651029587
Test Loss:  0.022045303136110306
Valid Loss:  0.01917675882577896
Epoch:  56  	Training Loss: 0.03070356324315071
Test Loss:  0.02202168107032776
Valid Loss:  0.019154619425535202
Epoch:  57  	Training Loss: 0.030685696750879288
Test Loss:  0.02199920080602169
Valid Loss:  0.0191335529088974
Epoch:  58  	Training Loss: 0.030668264254927635
Test Loss:  0.021977731958031654
Valid Loss:  0.019113454967737198
Epoch:  59  	Training Loss: 0.03065134957432747
Test Loss:  0.021954743191599846
Valid Loss:  0.0190925020724535
Epoch:  60  	Training Loss: 0.03063560090959072
Test Loss:  0.021933145821094513
Valid Loss:  0.019073057919740677
Epoch:  61  	Training Loss: 0.030620358884334564
Test Loss:  0.021912716329097748
Valid Loss:  0.019054867327213287
Epoch:  62  	Training Loss: 0.03060554899275303
Test Loss:  0.02189505286514759
Valid Loss:  0.019039414823055267
Epoch:  63  	Training Loss: 0.030592236667871475
Test Loss:  0.02187710627913475
Valid Loss:  0.019023464992642403
Epoch:  64  	Training Loss: 0.03057939000427723
Test Loss:  0.02185996249318123
Valid Loss:  0.01900835894048214
Epoch:  65  	Training Loss: 0.030566856265068054
Test Loss:  0.021843478083610535
Valid Loss:  0.018993955105543137
Epoch:  66  	Training Loss: 0.030554600059986115
Test Loss:  0.02182762697339058
Valid Loss:  0.01898021623492241
Epoch:  67  	Training Loss: 0.030542707070708275
Test Loss:  0.02181151881814003
Valid Loss:  0.018966026604175568
Epoch:  68  	Training Loss: 0.03053130954504013
Test Loss:  0.02179609425365925
Valid Loss:  0.018952563405036926
Epoch:  69  	Training Loss: 0.030520232394337654
Test Loss:  0.02178054489195347
Valid Loss:  0.018938928842544556
Epoch:  70  	Training Loss: 0.030509650707244873
Test Loss:  0.02176569402217865
Valid Loss:  0.018926415592432022
Epoch:  71  	Training Loss: 0.030499354004859924
Test Loss:  0.021751467138528824
Valid Loss:  0.018914666026830673
Epoch:  72  	Training Loss: 0.03048943355679512
Test Loss:   15%|█▍        | 73/500 [00:54<06:03,  1.18it/s] 15%|█▌        | 75/500 [00:54<04:21,  1.63it/s] 15%|█▌        | 77/500 [00:54<03:10,  2.22it/s] 16%|█▌        | 79/500 [00:54<02:20,  2.99it/s] 16%|█▌        | 81/500 [01:01<08:10,  1.17s/it] 17%|█▋        | 83/500 [01:01<05:50,  1.19it/s] 17%|█▋        | 85/500 [01:01<04:12,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.00it/s] 18%|█▊        | 91/500 [01:07<07:57,  1.17s/it] 19%|█▊        | 93/500 [01:08<05:41,  1.19it/s] 19%|█▉        | 95/500 [01:08<04:06,  1.64it/s] 19%|█▉        | 97/500 [01:08<02:59,  2.24it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.01it/s] 20%|██        | 101/500 [01:14<07:50,  1.18s/it] 21%|██        | 103/500 [01:14<05:36,  1.18it/s] 21%|██        | 105/500 [01:15<04:01,  1.63it/s] 21%|██▏       | 107/500 [01:15<02:56,  2.23it/s] 22%|██▏       | 109/500 [01:15<02:10,  3.00it/s] 22%|██▏       | 111/500 [01:21<07:34,  1.17s/it] 23%|██▎       | 113/500 [01:21<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:21<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:22<02:50,  2.25it/s] 24%|██▍       | 119/500 [01:22<02:06,  3.02it/s] 24%|██▍       | 121/500 [01:28<07:22,  1.17s/it] 25%|██▍       | 123/500 [01:28<05:16,  1.19it/s] 25%|██▌       | 125/500 [01:28<03:47,  1.65it/s] 25%|██▌       | 127/500 [01:28<02:45,  2.25it/s] 26%|██▌       | 129/500 [01:28<02:02,  3.02it/s] 26%|██▌       | 131/500 [01:35<07:19,  1.19s/it] 27%|██▋       | 133/500 [01:35<05:13,  1.17it/s] 27%|██▋       | 135/500 [01:35<03:45,  1.62it/s] 27%|██▋       | 137/500 [01:35<02:44,  2.21it/s] 28%|██▊       | 139/500 [01:35<02:01,  2.97it/s] 28%|██▊       | 141/500 [01:42<07:10,  1.20s/it]0.021738048642873764
Valid Loss:  0.018903300166130066
Epoch:  73  	Training Loss: 0.030480334535241127
Test Loss:  0.021725177764892578
Valid Loss:  0.01889261044561863
Epoch:  74  	Training Loss: 0.0304714385420084
Test Loss:  0.02171279676258564
Valid Loss:  0.018882516771554947
Epoch:  75  	Training Loss: 0.030462751165032387
Test Loss:  0.021700801327824593
Valid Loss:  0.018872899934649467
Epoch:  76  	Training Loss: 0.030454255640506744
Test Loss:  0.02168918028473854
Valid Loss:  0.018863726407289505
Epoch:  77  	Training Loss: 0.03044590726494789
Test Loss:  0.021677907556295395
Valid Loss:  0.018854966387152672
Epoch:  78  	Training Loss: 0.03043770045042038
Test Loss:  0.021666914224624634
Valid Loss:  0.018846526741981506
Epoch:  79  	Training Loss: 0.03042963519692421
Test Loss:  0.021656755357980728
Valid Loss:  0.01883840560913086
Epoch:  80  	Training Loss: 0.030421853065490723
Test Loss:  0.021646298468112946
Valid Loss:  0.018829643726348877
Epoch:  81  	Training Loss: 0.030414346605539322
Test Loss:  0.0216362401843071
Valid Loss:  0.01882130652666092
Epoch:  82  	Training Loss: 0.030406981706619263
Test Loss:  0.021626930683851242
Valid Loss:  0.01881372556090355
Epoch:  83  	Training Loss: 0.030399899929761887
Test Loss:  0.021617896854877472
Valid Loss:  0.018806587904691696
Epoch:  84  	Training Loss: 0.030393090099096298
Test Loss:  0.021607834845781326
Valid Loss:  0.018798034638166428
Epoch:  85  	Training Loss: 0.03038662299513817
Test Loss:  0.02159825712442398
Valid Loss:  0.01879008673131466
Epoch:  86  	Training Loss: 0.03038034588098526
Test Loss:  0.021589122712612152
Valid Loss:  0.018782952800393105
Epoch:  87  	Training Loss: 0.030374225229024887
Test Loss:  0.021580377593636513
Valid Loss:  0.018776345998048782
Epoch:  88  	Training Loss: 0.030368246138095856
Test Loss:  0.021571936085820198
Valid Loss:  0.018770180642604828
Epoch:  89  	Training Loss: 0.030362391844391823
Test Loss:  0.021564148366451263
Valid Loss:  0.01876441389322281
Epoch:  90  	Training Loss: 0.030356643721461296
Test Loss:  0.021556710824370384
Valid Loss:  0.0187589880079031
Epoch:  91  	Training Loss: 0.03035108745098114
Test Loss:  0.021548807621002197
Valid Loss:  0.018752722069621086
Epoch:  92  	Training Loss: 0.03034573420882225
Test Loss:  0.021540481597185135
Valid Loss:  0.01874568872153759
Epoch:  93  	Training Loss: 0.03034057281911373
Test Loss:  0.02153264917433262
Valid Loss:  0.01873927190899849
Epoch:  94  	Training Loss: 0.030335571616888046
Test Loss:  0.02152523398399353
Valid Loss:  0.018733371049165726
Epoch:  95  	Training Loss: 0.030330702662467957
Test Loss:  0.02151818946003914
Valid Loss:  0.018727924674749374
Epoch:  96  	Training Loss: 0.03032594732940197
Test Loss:  0.021511457860469818
Valid Loss:  0.01872286945581436
Epoch:  97  	Training Loss: 0.030321290716528893
Test Loss:  0.021505005657672882
Valid Loss:  0.018718142062425613
Epoch:  98  	Training Loss: 0.030316725373268127
Test Loss:  0.0214987862855196
Valid Loss:  0.0187136959284544
Epoch:  99  	Training Loss: 0.03031228296458721
Test Loss:  0.021492205560207367
Valid Loss:  0.01870853267610073
Epoch:  100  	Training Loss: 0.030308015644550323
Test Loss:  0.02148594707250595
Valid Loss:  0.01870376244187355
Epoch:  101  	Training Loss: 0.03030386008322239
Test Loss:  0.021479390561580658
Valid Loss:  0.01869833469390869
Epoch:  102  	Training Loss: 0.030299875885248184
Test Loss:  0.021473046392202377
Valid Loss:  0.018693236634135246
Epoch:  103  	Training Loss: 0.030295874923467636
Test Loss:  0.021467048674821854
Valid Loss:  0.018688539043068886
Epoch:  104  	Training Loss: 0.03029199317097664
Test Loss:  0.021460779011249542
Valid Loss:  0.018683290109038353
Epoch:  105  	Training Loss: 0.030288245528936386
Test Loss:  0.021454917266964912
Valid Loss:  0.01867849752306938
Epoch:  106  	Training Loss: 0.03028462827205658
Test Loss:  0.021449407562613487
Valid Loss:  0.0186740942299366
Epoch:  107  	Training Loss: 0.03028111718595028
Test Loss:  0.021444212645292282
Valid Loss:  0.01867004670202732
Epoch:  108  	Training Loss: 0.030277695506811142
Test Loss:  0.021439295262098312
Valid Loss:  0.018666300922632217
Epoch:  109  	Training Loss: 0.030274348333477974
Test Loss:  0.02143462747335434
Valid Loss:  0.01866280473768711
Epoch:  110  	Training Loss: 0.030271070078015327
Test Loss:  0.02143014222383499
Valid Loss:  0.018659494817256927
Epoch:  111  	Training Loss: 0.030267849564552307
Test Loss:  0.021425850689411163
Valid Loss:  0.018656400963664055
Epoch:  112  	Training Loss: 0.030264709144830704
Test Loss:  0.02142098918557167
Valid Loss:  0.01865256205201149
Epoch:  113  	Training Loss: 0.03026171773672104
Test Loss:  0.02141641452908516
Valid Loss:  0.018649045377969742
Epoch:  114  	Training Loss: 0.03025880828499794
Test Loss:  0.021412093192338943
Valid Loss:  0.01864580065011978
Epoch:  115  	Training Loss: 0.030255965888500214
Test Loss:  0.021407976746559143
Valid Loss:  0.018642781302332878
Epoch:  116  	Training Loss: 0.030253184959292412
Test Loss:  0.021404042840003967
Valid Loss:  0.01863996312022209
Epoch:  117  	Training Loss: 0.03025044873356819
Test Loss:  0.02140026167035103
Valid Loss:  0.018637295812368393
Epoch:  118  	Training Loss: 0.03024776093661785
Test Loss:  0.021396618336439133
Valid Loss:  0.01863478124141693
Epoch:  119  	Training Loss: 0.03024512156844139
Test Loss:  0.021393071860074997
Valid Loss:  0.018632348626852036
Epoch:  120  	Training Loss: 0.030242519453167915
Test Loss:  0.021389639005064964
Valid Loss:  0.01863003894686699
Epoch:  121  	Training Loss: 0.030239956453442574
Test Loss:  0.021386317908763885
Valid Loss:  0.018627844750881195
Epoch:  122  	Training Loss: 0.030237426981329918
Test Loss:  0.021383125334978104
Valid Loss:  0.01862577721476555
Epoch:  123  	Training Loss: 0.0302349291741848
Test Loss:  0.021380014717578888
Valid Loss:  0.01862379163503647
Epoch:  124  	Training Loss: 0.030232548713684082
Test Loss:  0.021376488730311394
Valid Loss:  0.018621232360601425
Epoch:  125  	Training Loss: 0.03023025020956993
Test Loss:  0.021373119205236435
Valid Loss:  0.01861884444952011
Epoch:  126  	Training Loss: 0.030228037387132645
Test Loss:  0.02136942557990551
Valid Loss:  0.018615972250699997
Epoch:  127  	Training Loss: 0.03022589534521103
Test Loss:  0.021365944296121597
Valid Loss:  0.018613334745168686
Epoch:  128  	Training Loss: 0.030223803594708443
Test Loss:  0.02136264741420746
Valid Loss:  0.01861090585589409
Epoch:  129  	Training Loss: 0.03022177144885063
Test Loss:  0.021359503269195557
Valid Loss:  0.018608644604682922
Epoch:  130  	Training Loss: 0.030219772830605507
Test Loss:  0.021356506273150444
Valid Loss:  0.01860653981566429
Epoch:  131  	Training Loss: 0.030217822641134262
Test Loss:  0.021353622898459435
Valid Loss:  0.018604567274451256
Epoch:  132  	Training Loss: 0.030215900391340256
Test Loss:  0.02135087363421917
Valid Loss:  0.018602728843688965
Epoch:  133  	Training Loss: 0.03021402284502983
Test Loss:  0.021348215639591217
Valid Loss:  0.018600990995764732
Epoch:  134  	Training Loss: 0.030212173238396645
Test Loss:  0.02134562097489834
Valid Loss:  0.018599316477775574
Epoch:  135  	Training Loss: 0.030210349708795547
Test Loss:  0.02134309895336628
Valid Loss:  0.018597720190882683
Epoch:  136  	Training Loss: 0.03020855039358139
Test Loss:  0.021340640261769295
Valid Loss:  0.018596187233924866
Epoch:  137  	Training Loss: 0.030206764116883278
Test Loss:  0.021338246762752533
Valid Loss:  0.01859471946954727
Epoch:  138  	Training Loss: 0.030205003917217255
Test Loss:  0.0213359072804451
Valid Loss:  0.018593307584524155
Epoch:  139  	Training Loss: 0.03020326979458332
Test Loss:  0.021333621814846992
Valid Loss:  0.018591949716210365
Epoch:  140  	Training Loss: 0.03020155057311058
Test Loss:  0.02133137360215187
Valid Loss:  0.01859063282608986
Epoch:  141  	Training Loss: 0.030199864879250526
Test Loss:  0.021328814327716827
Valid Loss:  0.018588852137327194
Epoch:  142  	Training Loss: 0.030198276042938232
Test Loss:  0.021326284855604172
Valid Loss:  0.018587123602628708
Epoch:  143  	Training Loss: 0.030196676030755043
Test Loss:  29%|██▊       | 143/500 [01:42<05:08,  1.16it/s] 29%|██▉       | 145/500 [01:42<03:41,  1.60it/s] 29%|██▉       | 147/500 [01:42<02:41,  2.19it/s] 30%|██▉       | 149/500 [01:42<01:59,  2.95it/s] 30%|███       | 151/500 [01:49<06:49,  1.17s/it] 31%|███       | 153/500 [01:49<04:52,  1.19it/s] 31%|███       | 155/500 [01:49<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:49<02:32,  2.24it/s] 32%|███▏      | 159/500 [01:49<01:53,  3.00it/s] 32%|███▏      | 161/500 [01:55<06:36,  1.17s/it] 33%|███▎      | 163/500 [01:55<04:43,  1.19it/s] 33%|███▎      | 165/500 [01:56<03:23,  1.65it/s] 33%|███▎      | 167/500 [01:56<02:28,  2.25it/s] 34%|███▍      | 169/500 [01:56<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:02<06:28,  1.18s/it] 35%|███▍      | 173/500 [02:02<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:02<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:03<02:25,  2.23it/s] 36%|███▌      | 179/500 [02:03<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:09<06:15,  1.18s/it] 37%|███▋      | 183/500 [02:09<04:27,  1.18it/s] 37%|███▋      | 185/500 [02:09<03:12,  1.63it/s] 37%|███▋      | 187/500 [02:09<02:20,  2.22it/s] 38%|███▊      | 189/500 [02:10<01:44,  2.99it/s] 38%|███▊      | 191/500 [02:16<06:05,  1.18s/it] 39%|███▊      | 193/500 [02:16<04:20,  1.18it/s] 39%|███▉      | 195/500 [02:16<03:07,  1.63it/s] 39%|███▉      | 197/500 [02:16<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:16<01:40,  2.98it/s] 40%|████      | 201/500 [02:23<05:57,  1.19s/it] 41%|████      | 203/500 [02:23<04:14,  1.17it/s] 41%|████      | 205/500 [02:23<03:02,  1.61it/s] 41%|████▏     | 207/500 [02:23<02:12,  2.20it/s] 42%|████▏     | 209/500 [02:23<01:38,  2.96it/s] 42%|████▏     | 211/500 [02:30<05:44,  1.19s/it] 43%|████▎     | 213/500 [02:30<04:05,  1.17it/s] 0.02132384479045868
Valid Loss:  0.01858549937605858
Epoch:  144  	Training Loss: 0.030195096507668495
Test Loss:  0.021321499720215797
Valid Loss:  0.018583979457616806
Epoch:  145  	Training Loss: 0.030193548649549484
Test Loss:  0.021319231018424034
Valid Loss:  0.0185825377702713
Epoch:  146  	Training Loss: 0.030192021280527115
Test Loss:  0.021317023783922195
Valid Loss:  0.018581166863441467
Epoch:  147  	Training Loss: 0.03019050695002079
Test Loss:  0.02131488174200058
Valid Loss:  0.018579866737127304
Epoch:  148  	Training Loss: 0.030189018696546555
Test Loss:  0.02131280116736889
Valid Loss:  0.018578611314296722
Epoch:  149  	Training Loss: 0.030187545344233513
Test Loss:  0.021310750395059586
Valid Loss:  0.01857740245759487
Epoch:  150  	Training Loss: 0.030186085030436516
Test Loss:  0.021308740600943565
Valid Loss:  0.01857622340321541
Epoch:  151  	Training Loss: 0.030184641480445862
Test Loss:  0.02130676805973053
Valid Loss:  0.018575090914964676
Epoch:  152  	Training Loss: 0.030183222144842148
Test Loss:  0.021304816007614136
Valid Loss:  0.018573958426713943
Epoch:  153  	Training Loss: 0.030181804671883583
Test Loss:  0.021302901208400726
Valid Loss:  0.01857287436723709
Epoch:  154  	Training Loss: 0.030180415138602257
Test Loss:  0.021301018074154854
Valid Loss:  0.01857181452214718
Epoch:  155  	Training Loss: 0.03017902374267578
Test Loss:  0.021299168467521667
Valid Loss:  0.01857079565525055
Epoch:  156  	Training Loss: 0.030177652835845947
Test Loss:  0.021297350525856018
Valid Loss:  0.018569795414805412
Epoch:  157  	Training Loss: 0.03017629310488701
Test Loss:  0.02129555493593216
Valid Loss:  0.018568821251392365
Epoch:  158  	Training Loss: 0.03017503395676613
Test Loss:  0.02129322662949562
Valid Loss:  0.018567034974694252
Epoch:  159  	Training Loss: 0.03017379716038704
Test Loss:  0.021291032433509827
Valid Loss:  0.018565405160188675
Epoch:  160  	Training Loss: 0.03017260506749153
Test Loss:  0.021288955584168434
Valid Loss:  0.018563900142908096
Epoch:  161  	Training Loss: 0.03017144463956356
Test Loss:  0.0212869830429554
Valid Loss:  0.018562521785497665
Epoch:  162  	Training Loss: 0.030170317739248276
Test Loss:  0.02128509432077408
Valid Loss:  0.01856124773621559
Epoch:  163  	Training Loss: 0.030169211328029633
Test Loss:  0.021283283829689026
Valid Loss:  0.018560057505965233
Epoch:  164  	Training Loss: 0.03016812354326248
Test Loss:  0.021281536668539047
Valid Loss:  0.018558938056230545
Epoch:  165  	Training Loss: 0.030167056247591972
Test Loss:  0.021279845386743546
Valid Loss:  0.01855788193643093
Epoch:  166  	Training Loss: 0.030166001990437508
Test Loss:  0.021278202533721924
Valid Loss:  0.018556872382760048
Epoch:  167  	Training Loss: 0.030164964497089386
Test Loss:  0.021276604384183884
Valid Loss:  0.018555914983153343
Epoch:  168  	Training Loss: 0.03016393817961216
Test Loss:  0.02127503976225853
Valid Loss:  0.01855500042438507
Epoch:  169  	Training Loss: 0.030162952840328217
Test Loss:  0.021273300051689148
Valid Loss:  0.01855376362800598
Epoch:  170  	Training Loss: 0.030161980539560318
Test Loss:  0.021271631121635437
Valid Loss:  0.018552612513303757
Epoch:  171  	Training Loss: 0.03016103059053421
Test Loss:  0.021270032972097397
Valid Loss:  0.018551547080278397
Epoch:  172  	Training Loss: 0.030160102993249893
Test Loss:  0.021268486976623535
Valid Loss:  0.018550539389252663
Epoch:  173  	Training Loss: 0.03015919029712677
Test Loss:  0.021266799420118332
Valid Loss:  0.018549257889389992
Epoch:  174  	Training Loss: 0.030158283188939095
Test Loss:  0.021265368908643723
Valid Loss:  0.018548399209976196
Epoch:  175  	Training Loss: 0.030157404020428658
Test Loss:  0.02126379683613777
Valid Loss:  0.01854725554585457
Epoch:  176  	Training Loss: 0.030156543478369713
Test Loss:  0.02126229926943779
Valid Loss:  0.018546197563409805
Epoch:  177  	Training Loss: 0.03015570156276226
Test Loss:  0.021261032670736313
Valid Loss:  0.018545519560575485
Epoch:  178  	Training Loss: 0.0301548782736063
Test Loss:  0.0212596096098423
Valid Loss:  0.018544549122452736
Epoch:  179  	Training Loss: 0.03015405870974064
Test Loss:  0.021258242428302765
Valid Loss:  0.01854364201426506
Epoch:  180  	Training Loss: 0.03015325777232647
Test Loss:  0.02125691995024681
Valid Loss:  0.018542783334851265
Epoch:  181  	Training Loss: 0.030152466148138046
Test Loss:  0.021255629137158394
Valid Loss:  0.0185419712215662
Epoch:  182  	Training Loss: 0.030151687562465668
Test Loss:  0.021254388615489006
Valid Loss:  0.018541205674409866
Epoch:  183  	Training Loss: 0.030150918290019035
Test Loss:  0.02125316858291626
Valid Loss:  0.018540475517511368
Epoch:  184  	Training Loss: 0.03015015833079815
Test Loss:  0.02125198021531105
Valid Loss:  0.01853976771235466
Epoch:  185  	Training Loss: 0.03014940209686756
Test Loss:  0.021250814199447632
Valid Loss:  0.01853908598423004
Epoch:  186  	Training Loss: 0.03014865517616272
Test Loss:  0.021249666810035706
Valid Loss:  0.018538426607847214
Epoch:  187  	Training Loss: 0.030147934332489967
Test Loss:  0.02124839462339878
Valid Loss:  0.018537508323788643
Epoch:  188  	Training Loss: 0.03014722466468811
Test Loss:  0.021247176453471184
Valid Loss:  0.018536653369665146
Epoch:  189  	Training Loss: 0.030146524310112
Test Loss:  0.02124600112438202
Valid Loss:  0.018535848706960678
Epoch:  190  	Training Loss: 0.030145840719342232
Test Loss:  0.021244866773486137
Valid Loss:  0.01853509433567524
Epoch:  191  	Training Loss: 0.030145172029733658
Test Loss:  0.021243762224912643
Valid Loss:  0.018534377217292786
Epoch:  192  	Training Loss: 0.03014451265335083
Test Loss:  0.021242698654532433
Valid Loss:  0.018533699214458466
Epoch:  193  	Training Loss: 0.030143868178129196
Test Loss:  0.021241646260023117
Valid Loss:  0.018533043563365936
Epoch:  194  	Training Loss: 0.03014323115348816
Test Loss:  0.02124061807990074
Valid Loss:  0.018532413989305496
Epoch:  195  	Training Loss: 0.03014260157942772
Test Loss:  0.021239615976810455
Valid Loss:  0.018531808629631996
Epoch:  196  	Training Loss: 0.030141977593302727
Test Loss:  0.021238625049591064
Valid Loss:  0.018531225621700287
Epoch:  197  	Training Loss: 0.030141353607177734
Test Loss:  0.02123766392469406
Valid Loss:  0.018530655652284622
Epoch:  198  	Training Loss: 0.030140740796923637
Test Loss:  0.02123679593205452
Valid Loss:  0.018530109897255898
Epoch:  199  	Training Loss: 0.030140135437250137
Test Loss:  0.021235942840576172
Valid Loss:  0.01852957159280777
Epoch:  200  	Training Loss: 0.030139531940221786
Test Loss:  0.021235106512904167
Valid Loss:  0.018529042601585388
Epoch:  201  	Training Loss: 0.030138930305838585
Test Loss:  0.021234285086393356
Valid Loss:  0.018528524786233902
Epoch:  202  	Training Loss: 0.030138328671455383
Test Loss:  0.02123347669839859
Valid Loss:  0.01852801814675331
Epoch:  203  	Training Loss: 0.03013773448765278
Test Loss:  0.02123267948627472
Valid Loss:  0.018527524545788765
Epoch:  204  	Training Loss: 0.030137140303850174
Test Loss:  0.021231891587376595
Valid Loss:  0.018527036532759666
Epoch:  205  	Training Loss: 0.030136555433273315
Test Loss:  0.021231122314929962
Valid Loss:  0.018526555970311165
Epoch:  206  	Training Loss: 0.030135976150631905
Test Loss:  0.02123035117983818
Valid Loss:  0.018526075407862663
Epoch:  207  	Training Loss: 0.030135391280055046
Test Loss:  0.021229591220617294
Valid Loss:  0.018525604158639908
Epoch:  208  	Training Loss: 0.030134836211800575
Test Loss:  0.021228617057204247
Valid Loss:  0.018524937331676483
Epoch:  209  	Training Loss: 0.030134277418255806
Test Loss:  0.02122768759727478
Valid Loss:  0.018524307757616043
Epoch:  210  	Training Loss: 0.030133727937936783
Test Loss:  0.021226799115538597
Valid Loss:  0.01852370798587799
Epoch:  211  	Training Loss: 0.030133189633488655
Test Loss:  0.021225953474640846
Valid Loss:  0.018523145467042923
Epoch:  212  	Training Loss: 0.030132681131362915
Test Loss:  0.021225135773420334
Valid Loss:  0.018522605299949646
Epoch:  213  	Training Loss: 0.030132174491882324
Test Loss:  0.02122434601187706
Valid Loss:  0.018522093072533607
 43%|████▎     | 215/500 [02:30<02:56,  1.62it/s] 43%|████▎     | 217/500 [02:30<02:08,  2.21it/s] 44%|████▍     | 219/500 [02:30<01:34,  2.97it/s] 44%|████▍     | 221/500 [02:37<05:27,  1.17s/it] 45%|████▍     | 223/500 [02:37<03:53,  1.19it/s] 45%|████▌     | 225/500 [02:37<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:37<02:01,  2.24it/s] 46%|████▌     | 229/500 [02:37<01:29,  3.02it/s] 46%|████▌     | 231/500 [02:44<05:22,  1.20s/it] 47%|████▋     | 233/500 [02:44<03:49,  1.16it/s] 47%|████▋     | 235/500 [02:44<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:44<01:59,  2.20it/s] 48%|████▊     | 239/500 [02:44<01:28,  2.95it/s] 48%|████▊     | 241/500 [02:50<05:07,  1.19s/it] 49%|████▊     | 243/500 [02:51<03:38,  1.17it/s] 49%|████▉     | 245/500 [02:51<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:51<01:54,  2.22it/s] 50%|████▉     | 249/500 [02:51<01:24,  2.98it/s] 50%|█████     | 251/500 [02:57<04:54,  1.18s/it] 51%|█████     | 253/500 [02:57<03:29,  1.18it/s] 51%|█████     | 255/500 [02:58<02:30,  1.63it/s] 51%|█████▏    | 257/500 [02:58<01:48,  2.23it/s] 52%|█████▏    | 259/500 [02:58<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:04<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:04<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:04<02:23,  1.63it/s] 53%|█████▎    | 267/500 [03:04<01:44,  2.23it/s] 54%|█████▍    | 269/500 [03:05<01:17,  2.99it/s] 54%|█████▍    | 271/500 [03:11<04:33,  1.19s/it] 55%|█████▍    | 273/500 [03:11<03:14,  1.17it/s] 55%|█████▌    | 275/500 [03:11<02:19,  1.62it/s] 55%|█████▌    | 277/500 [03:11<01:41,  2.19it/s] 56%|█████▌    | 279/500 [03:12<01:16,  2.90it/s] 56%|█████▌    | 281/500 [03:18<04:23,  1.20s/it] 57%|█████▋    | 283/500 [03:18<03:07,  1.16it/s]Epoch:  214  	Training Loss: 0.03013167716562748
Test Loss:  0.02122357487678528
Valid Loss:  0.018521590158343315
Epoch:  215  	Training Loss: 0.030131187289953232
Test Loss:  0.021222826093435287
Valid Loss:  0.018521104007959366
Epoch:  216  	Training Loss: 0.03013070672750473
Test Loss:  0.02122209593653679
Valid Loss:  0.01852063275873661
Epoch:  217  	Training Loss: 0.030130233615636826
Test Loss:  0.02122138999402523
Valid Loss:  0.018520193174481392
Epoch:  218  	Training Loss: 0.03012976609170437
Test Loss:  0.021220695227384567
Valid Loss:  0.01851976476609707
Epoch:  219  	Training Loss: 0.030129309743642807
Test Loss:  0.02122000977396965
Valid Loss:  0.018519341945648193
Epoch:  220  	Training Loss: 0.030128847807645798
Test Loss:  0.02121933549642563
Valid Loss:  0.018518932163715363
Epoch:  221  	Training Loss: 0.030128391459584236
Test Loss:  0.021218672394752502
Valid Loss:  0.018518541008234024
Epoch:  222  	Training Loss: 0.030127931386232376
Test Loss:  0.02121802046895027
Valid Loss:  0.018518153578042984
Epoch:  223  	Training Loss: 0.030127476900815964
Test Loss:  0.021217375993728638
Valid Loss:  0.018517769873142242
Epoch:  224  	Training Loss: 0.030127018690109253
Test Loss:  0.0212167389690876
Valid Loss:  0.018517397344112396
Epoch:  225  	Training Loss: 0.03012656792998314
Test Loss:  0.02121611125767231
Valid Loss:  0.01851702854037285
Epoch:  226  	Training Loss: 0.030126120895147324
Test Loss:  0.021215489134192467
Valid Loss:  0.01851666532456875
Epoch:  227  	Training Loss: 0.030125677585601807
Test Loss:  0.021214865148067474
Valid Loss:  0.0185163002461195
Epoch:  228  	Training Loss: 0.030125226825475693
Test Loss:  0.021214254200458527
Valid Loss:  0.018515948206186295
Epoch:  229  	Training Loss: 0.030124785378575325
Test Loss:  0.021213645115494728
Valid Loss:  0.018515607342123985
Epoch:  230  	Training Loss: 0.030124347656965256
Test Loss:  0.021213041618466377
Valid Loss:  0.018515268340706825
Epoch:  231  	Training Loss: 0.030123911798000336
Test Loss:  0.021212445572018623
Valid Loss:  0.018514934927225113
Epoch:  232  	Training Loss: 0.030123472213745117
Test Loss:  0.021211840212345123
Valid Loss:  0.018514588475227356
Epoch:  233  	Training Loss: 0.030123021453619003
Test Loss:  0.021211236715316772
Valid Loss:  0.018514245748519897
Epoch:  234  	Training Loss: 0.03012257069349289
Test Loss:  0.02121064066886902
Valid Loss:  0.018513981252908707
Epoch:  235  	Training Loss: 0.030122121796011925
Test Loss:  0.021210044622421265
Valid Loss:  0.01851372793316841
Epoch:  236  	Training Loss: 0.030121680349111557
Test Loss:  0.02120945230126381
Valid Loss:  0.018513480201363564
Epoch:  237  	Training Loss: 0.030121242627501488
Test Loss:  0.02120887115597725
Valid Loss:  0.018513236194849014
Epoch:  238  	Training Loss: 0.030120814219117165
Test Loss:  0.021208301186561584
Valid Loss:  0.01851300150156021
Epoch:  239  	Training Loss: 0.03012038767337799
Test Loss:  0.021207738667726517
Valid Loss:  0.01851276494562626
Epoch:  240  	Training Loss: 0.030119962990283966
Test Loss:  0.0212071742862463
Valid Loss:  0.018512537702918053
Epoch:  241  	Training Loss: 0.03011954575777054
Test Loss:  0.02120661363005638
Valid Loss:  0.018512312322854996
Epoch:  242  	Training Loss: 0.03011912666261196
Test Loss:  0.021206069737672806
Valid Loss:  0.01851210556924343
Epoch:  243  	Training Loss: 0.030118728056550026
Test Loss:  0.021205533295869827
Valid Loss:  0.018511904403567314
Epoch:  244  	Training Loss: 0.03011833131313324
Test Loss:  0.0212049912661314
Valid Loss:  0.018511701375246048
Epoch:  245  	Training Loss: 0.030117936432361603
Test Loss:  0.02120445854961872
Valid Loss:  0.01851150393486023
Epoch:  246  	Training Loss: 0.030117550864815712
Test Loss:  0.02120393142104149
Valid Loss:  0.01851131021976471
Epoch:  247  	Training Loss: 0.030117161571979523
Test Loss:  0.02120339870452881
Valid Loss:  0.01851111277937889
Epoch:  248  	Training Loss: 0.030116774141788483
Test Loss:  0.021202875301241875
Valid Loss:  0.01851091906428337
Epoch:  249  	Training Loss: 0.030116386711597443
Test Loss:  0.02120235189795494
Valid Loss:  0.01851072534918785
Epoch:  250  	Training Loss: 0.030115999281406403
Test Loss:  0.021201832219958305
Valid Loss:  0.01851053163409233
Epoch:  251  	Training Loss: 0.03011561557650566
Test Loss:  0.02120130881667137
Valid Loss:  0.01851033605635166
Epoch:  252  	Training Loss: 0.03011522814631462
Test Loss:  0.021200764924287796
Valid Loss:  0.0185101255774498
Epoch:  253  	Training Loss: 0.03011482208967209
Test Loss:  0.021200230345129967
Valid Loss:  0.018509922549128532
Epoch:  254  	Training Loss: 0.030114419758319855
Test Loss:  0.021199699491262436
Valid Loss:  0.01850971393287182
Epoch:  255  	Training Loss: 0.03011401742696762
Test Loss:  0.021199170500040054
Valid Loss:  0.018509509041905403
Epoch:  256  	Training Loss: 0.030113615095615387
Test Loss:  0.02119864523410797
Valid Loss:  0.018509304150938988
Epoch:  257  	Training Loss: 0.03011321648955345
Test Loss:  0.02119811624288559
Valid Loss:  0.018509097397327423
Epoch:  258  	Training Loss: 0.030112821608781815
Test Loss:  0.021197590976953506
Valid Loss:  0.018508894369006157
Epoch:  259  	Training Loss: 0.03011242486536503
Test Loss:  0.021197067573666573
Valid Loss:  0.01850869134068489
Epoch:  260  	Training Loss: 0.03011203184723854
Test Loss:  0.021196551620960236
Valid Loss:  0.018508490175008774
Epoch:  261  	Training Loss: 0.030111636966466904
Test Loss:  0.0211960319429636
Valid Loss:  0.018508289009332657
Epoch:  262  	Training Loss: 0.030111249536275864
Test Loss:  0.021195515990257263
Valid Loss:  0.01850808411836624
Epoch:  263  	Training Loss: 0.030110850930213928
Test Loss:  0.02119498699903488
Valid Loss:  0.018507875502109528
Epoch:  264  	Training Loss: 0.03011045977473259
Test Loss:  0.021194472908973694
Valid Loss:  0.01850767992436886
Epoch:  265  	Training Loss: 0.0301100742071867
Test Loss:  0.021193962544202805
Valid Loss:  0.018507488071918488
Epoch:  266  	Training Loss: 0.030109688639640808
Test Loss:  0.021193448454141617
Valid Loss:  0.01850729063153267
Epoch:  267  	Training Loss: 0.030109304934740067
Test Loss:  0.021192945539951324
Valid Loss:  0.01850709691643715
Epoch:  268  	Training Loss: 0.030108923092484474
Test Loss:  0.021192438900470734
Valid Loss:  0.018506908789277077
Epoch:  269  	Training Loss: 0.03010854497551918
Test Loss:  0.021191932260990143
Valid Loss:  0.018506713211536407
Epoch:  270  	Training Loss: 0.030108166858553886
Test Loss:  0.02119143307209015
Valid Loss:  0.018506521359086037
Epoch:  271  	Training Loss: 0.030107790604233742
Test Loss:  0.021190937608480453
Valid Loss:  0.018506333231925964
Epoch:  272  	Training Loss: 0.030107419937849045
Test Loss:  0.02119043841958046
Valid Loss:  0.018506145104765892
Epoch:  273  	Training Loss: 0.030107036232948303
Test Loss:  0.02118992805480957
Valid Loss:  0.018505949527025223
Epoch:  274  	Training Loss: 0.03010665997862816
Test Loss:  0.021189432591199875
Valid Loss:  0.01850575953722
Epoch:  275  	Training Loss: 0.030106281861662865
Test Loss:  0.02118893899023533
Valid Loss:  0.01850556954741478
Epoch:  276  	Training Loss: 0.03010590374469757
Test Loss:  0.021188441663980484
Valid Loss:  0.01850537583231926
Epoch:  277  	Training Loss: 0.030105527490377426
Test Loss:  0.021187959238886833
Valid Loss:  0.018505189567804337
Epoch:  278  	Training Loss: 0.03010515309870243
Test Loss:  0.02118747867643833
Valid Loss:  0.018505003303289413
Epoch:  279  	Training Loss: 0.030104782432317734
Test Loss:  0.021186990663409233
Valid Loss:  0.01850481890141964
Epoch:  280  	Training Loss: 0.030104411765933037
Test Loss:  0.021186506375670433
Valid Loss:  0.018504632636904716
Epoch:  281  	Training Loss: 0.03010404296219349
Test Loss:  0.02118603326380253
Valid Loss:  0.018504450097680092
Epoch:  282  	Training Loss: 0.03010367602109909
Test Loss:  0.02118554338812828
Valid Loss:  0.018504254519939423
Epoch:  283  	Training Loss: 0.03010329231619835
Test Loss:  0.021185051649808884
Valid Loss:  0.018504060804843903
Epoch:  284  	Training Loss: 0.030102908611297607
Test Loss:  0.021184565499424934
 57%|█████▋    | 285/500 [03:18<02:14,  1.60it/s] 57%|█████▋    | 287/500 [03:18<01:37,  2.19it/s] 58%|█████▊    | 289/500 [03:19<01:11,  2.95it/s] 58%|█████▊    | 291/500 [03:25<04:07,  1.18s/it] 59%|█████▊    | 293/500 [03:25<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:25<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:25<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:25<01:07,  2.98it/s] 60%|██████    | 301/500 [03:32<03:55,  1.18s/it] 61%|██████    | 303/500 [03:32<02:47,  1.18it/s] 61%|██████    | 305/500 [03:32<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:32<01:26,  2.22it/s] 62%|██████▏   | 309/500 [03:32<01:03,  2.99it/s] 62%|██████▏   | 311/500 [03:39<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:39<02:40,  1.16it/s] 63%|██████▎   | 315/500 [03:39<01:55,  1.61it/s] 63%|██████▎   | 317/500 [03:39<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:39<01:01,  2.96it/s] 64%|██████▍   | 321/500 [03:46<03:32,  1.19s/it] 65%|██████▍   | 323/500 [03:46<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:46<01:48,  1.62it/s] 65%|██████▌   | 327/500 [03:46<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:46<00:57,  2.98it/s] 66%|██████▌   | 331/500 [03:52<03:21,  1.19s/it] 67%|██████▋   | 333/500 [03:53<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:53<01:42,  1.62it/s] 67%|██████▋   | 337/500 [03:53<01:13,  2.21it/s] 68%|██████▊   | 339/500 [03:53<00:54,  2.98it/s] 68%|██████▊   | 341/500 [03:59<03:11,  1.20s/it] 69%|██████▊   | 343/500 [04:00<02:15,  1.15it/s] 69%|██████▉   | 345/500 [04:00<01:36,  1.60it/s] 69%|██████▉   | 347/500 [04:00<01:09,  2.19it/s] 70%|██████▉   | 349/500 [04:00<00:51,  2.94it/s] 70%|███████   | 351/500 [04:06<02:56,  1.19s/it] 71%|███████   | 353/500 [04:06<02:05,  1.17it/s]Valid Loss:  0.018503867089748383
Epoch:  285  	Training Loss: 0.030102532356977463
Test Loss:  0.021184086799621582
Valid Loss:  0.01850368082523346
Epoch:  286  	Training Loss: 0.03010215237736702
Test Loss:  0.02118360437452793
Valid Loss:  0.018503490835428238
Epoch:  287  	Training Loss: 0.030101772397756577
Test Loss:  0.02118312194943428
Valid Loss:  0.018503297120332718
Epoch:  288  	Training Loss: 0.03010139800608158
Test Loss:  0.021182648837566376
Valid Loss:  0.018503107130527496
Epoch:  289  	Training Loss: 0.030101019889116287
Test Loss:  0.021182172000408173
Valid Loss:  0.018502917140722275
Epoch:  290  	Training Loss: 0.030100645497441292
Test Loss:  0.021181698888540268
Valid Loss:  0.018502723425626755
Epoch:  291  	Training Loss: 0.030100274831056595
Test Loss:  0.021181229501962662
Valid Loss:  0.01850253716111183
Epoch:  292  	Training Loss: 0.03009989857673645
Test Loss:  0.02118074521422386
Valid Loss:  0.018502335995435715
Epoch:  293  	Training Loss: 0.03009951300919056
Test Loss:  0.02118026092648506
Valid Loss:  0.018502142280340195
Epoch:  294  	Training Loss: 0.030099131166934967
Test Loss:  0.021179772913455963
Valid Loss:  0.01850193366408348
Epoch:  295  	Training Loss: 0.030098749324679375
Test Loss:  0.021179145202040672
Valid Loss:  0.01850147731602192
Epoch:  296  	Training Loss: 0.030098378658294678
Test Loss:  0.02117869257926941
Valid Loss:  0.018501315265893936
Epoch:  297  	Training Loss: 0.030097998678684235
Test Loss:  0.02117808535695076
Valid Loss:  0.018500883132219315
Epoch:  298  	Training Loss: 0.030097633600234985
Test Loss:  0.02117765136063099
Valid Loss:  0.01850074715912342
Epoch:  299  	Training Loss: 0.03009726107120514
Test Loss:  0.021177073940634727
Valid Loss:  0.018500346690416336
Epoch:  300  	Training Loss: 0.03009689413011074
Test Loss:  0.02117650955915451
Valid Loss:  0.01849997229874134
Epoch:  301  	Training Loss: 0.03009653463959694
Test Loss:  0.021176109090447426
Valid Loss:  0.018499866127967834
Epoch:  302  	Training Loss: 0.03009616956114769
Test Loss:  0.021175552159547806
Valid Loss:  0.018499506637454033
Epoch:  303  	Training Loss: 0.030095800757408142
Test Loss:  0.021175015717744827
Valid Loss:  0.018499163910746574
Epoch:  304  	Training Loss: 0.030095435678958893
Test Loss:  0.02117450162768364
Valid Loss:  0.018498841673135757
Epoch:  305  	Training Loss: 0.030095074325799942
Test Loss:  0.021173987537622452
Valid Loss:  0.018498538061976433
Epoch:  306  	Training Loss: 0.03009471297264099
Test Loss:  0.021173492074012756
Valid Loss:  0.018498238176107407
Epoch:  307  	Training Loss: 0.03009435534477234
Test Loss:  0.02117300219833851
Valid Loss:  0.018497955054044724
Epoch:  308  	Training Loss: 0.030093997716903687
Test Loss:  0.021172523498535156
Valid Loss:  0.018497684970498085
Epoch:  309  	Training Loss: 0.030093640089035034
Test Loss:  0.0211720522493124
Valid Loss:  0.018497424200177193
Epoch:  310  	Training Loss: 0.03009328432381153
Test Loss:  0.021171586588025093
Valid Loss:  0.01849716529250145
Epoch:  311  	Training Loss: 0.030092932283878326
Test Loss:  0.021171126514673233
Valid Loss:  0.01849692314863205
Epoch:  312  	Training Loss: 0.030092580243945122
Test Loss:  0.02117067202925682
Valid Loss:  0.018496673554182053
Epoch:  313  	Training Loss: 0.03009221702814102
Test Loss:  0.021170224994421005
Valid Loss:  0.01849643513560295
Epoch:  314  	Training Loss: 0.03009185940027237
Test Loss:  0.02116977423429489
Valid Loss:  0.018496191129088402
Epoch:  315  	Training Loss: 0.03009149432182312
Test Loss:  0.021169332787394524
Valid Loss:  0.018495962023735046
Epoch:  316  	Training Loss: 0.030091136693954468
Test Loss:  0.021168889477849007
Valid Loss:  0.01849573291838169
Epoch:  317  	Training Loss: 0.030090777203440666
Test Loss:  0.021168449893593788
Valid Loss:  0.018495509400963783
Epoch:  318  	Training Loss: 0.030090421438217163
Test Loss:  0.02116800844669342
Valid Loss:  0.018495280295610428
Epoch:  319  	Training Loss: 0.03009006567299366
Test Loss:  0.0211675763130188
Valid Loss:  0.01849506050348282
Epoch:  320  	Training Loss: 0.03008970618247986
Test Loss:  0.021167142316699028
Valid Loss:  0.01849484071135521
Epoch:  321  	Training Loss: 0.030089344829320908
Test Loss:  0.021166712045669556
Valid Loss:  0.01849462278187275
Epoch:  322  	Training Loss: 0.030088990926742554
Test Loss:  0.02116626687347889
Valid Loss:  0.018494391813874245
Epoch:  323  	Training Loss: 0.030088607221841812
Test Loss:  0.021165821701288223
Valid Loss:  0.01849416270852089
Epoch:  324  	Training Loss: 0.03008822724223137
Test Loss:  0.021165363490581512
Valid Loss:  0.018493931740522385
Epoch:  325  	Training Loss: 0.030087852850556374
Test Loss:  0.021164918318390846
Valid Loss:  0.018493706360459328
Epoch:  326  	Training Loss: 0.03008747100830078
Test Loss:  0.02116446942090988
Valid Loss:  0.018493477255105972
Epoch:  327  	Training Loss: 0.030087094753980637
Test Loss:  0.021164026111364365
Valid Loss:  0.018493251875042915
Epoch:  328  	Training Loss: 0.030086711049079895
Test Loss:  0.0211635809391737
Valid Loss:  0.01849302276968956
Epoch:  329  	Training Loss: 0.0300863366574049
Test Loss:  0.02116313949227333
Valid Loss:  0.018492799252271652
Epoch:  330  	Training Loss: 0.030085960403084755
Test Loss:  0.021162696182727814
Valid Loss:  0.018492570146918297
Epoch:  331  	Training Loss: 0.03008558228611946
Test Loss:  0.021162249147892
Valid Loss:  0.01849234849214554
Epoch:  332  	Training Loss: 0.030085204169154167
Test Loss:  0.021161796525120735
Valid Loss:  0.018492113798856735
Epoch:  333  	Training Loss: 0.030084818601608276
Test Loss:  0.021161342039704323
Valid Loss:  0.01849188283085823
Epoch:  334  	Training Loss: 0.030084429308772087
Test Loss:  0.02116088569164276
Valid Loss:  0.01849164068698883
Epoch:  335  	Training Loss: 0.0300840362906456
Test Loss:  0.021160433068871498
Valid Loss:  0.01849140226840973
Epoch:  336  	Training Loss: 0.03008364513516426
Test Loss:  0.021159982308745384
Valid Loss:  0.01849116012454033
Epoch:  337  	Training Loss: 0.03008325584232807
Test Loss:  0.02115952968597412
Valid Loss:  0.01849091425538063
Epoch:  338  	Training Loss: 0.030082864686846733
Test Loss:  0.021159078925848007
Valid Loss:  0.018490659072995186
Epoch:  339  	Training Loss: 0.030082467943429947
Test Loss:  0.021158631891012192
Valid Loss:  0.01849040575325489
Epoch:  340  	Training Loss: 0.03008207678794861
Test Loss:  0.021158181130886078
Valid Loss:  0.018490150570869446
Epoch:  341  	Training Loss: 0.030081678181886673
Test Loss:  0.021157726645469666
Valid Loss:  0.018489893525838852
Epoch:  342  	Training Loss: 0.030081287026405334
Test Loss:  0.02115727588534355
Valid Loss:  0.01848963461816311
Epoch:  343  	Training Loss: 0.0300808846950531
Test Loss:  0.021156825125217438
Valid Loss:  0.018489375710487366
Epoch:  344  	Training Loss: 0.030080486088991165
Test Loss:  0.021156368777155876
Valid Loss:  0.018489116802811623
Epoch:  345  	Training Loss: 0.03008008375763893
Test Loss:  0.021155916154384613
Valid Loss:  0.01848885416984558
Epoch:  346  	Training Loss: 0.030079688876867294
Test Loss:  0.0211554616689682
Valid Loss:  0.018488597124814987
Epoch:  347  	Training Loss: 0.03007928654551506
Test Loss:  0.021155010908842087
Valid Loss:  0.018488332629203796
Epoch:  348  	Training Loss: 0.030078884214162827
Test Loss:  0.021154558286070824
Valid Loss:  0.018488075584173203
Epoch:  349  	Training Loss: 0.030078481882810593
Test Loss:  0.02115410566329956
Valid Loss:  0.018487807363271713
Epoch:  350  	Training Loss: 0.030078072100877762
Test Loss:  0.021153653040528297
Valid Loss:  0.01848754659295082
Epoch:  351  	Training Loss: 0.03007766418159008
Test Loss:  0.021153206005692482
Valid Loss:  0.018487276509404182
Epoch:  352  	Training Loss: 0.0300772562623024
Test Loss:  0.021152742207050323
Valid Loss:  0.018487000837922096
Epoch:  353  	Training Loss: 0.03007684275507927
Test Loss:  0.021152276545763016
Valid Loss:  0.018486715853214264
Epoch:  354  	Training Loss: 0.03007642924785614
Test Loss:  0.021151812747120857
Valid Loss:  0.018486429005861282
Epoch:  355  	Training Loss: 0.03007601574063301
 71%|███████   | 355/500 [04:07<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:07<01:05,  2.19it/s] 72%|███████▏  | 359/500 [04:07<00:47,  2.95it/s] 72%|███████▏  | 361/500 [04:13<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:13<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:14<01:23,  1.61it/s] 73%|███████▎  | 367/500 [04:14<01:00,  2.19it/s] 74%|███████▍  | 369/500 [04:14<00:44,  2.95it/s] 74%|███████▍  | 371/500 [04:20<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:20<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:20<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:21<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:21<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:27<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:27<01:38,  1.18it/s] 77%|███████▋  | 385/500 [04:27<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:27<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:27<00:37,  3.00it/s] 78%|███████▊  | 391/500 [04:34<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:34<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:34<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:34<00:46,  2.23it/s] 80%|███████▉  | 399/500 [04:34<00:33,  2.99it/s] 80%|████████  | 401/500 [04:41<01:56,  1.17s/it] 81%|████████  | 403/500 [04:41<01:21,  1.18it/s] 81%|████████  | 405/500 [04:41<00:57,  1.64it/s] 81%|████████▏ | 407/500 [04:41<00:41,  2.24it/s] 82%|████████▏ | 409/500 [04:41<00:30,  2.99it/s] 82%|████████▏ | 411/500 [04:47<01:45,  1.18s/it] 83%|████████▎ | 413/500 [04:48<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:48<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:48<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:48<00:27,  3.00it/s] 84%|████████▍ | 421/500 [04:54<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:54<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:54<00:45,  1.65it/s]Test Loss:  0.0211513489484787
Valid Loss:  0.0184861421585083
Epoch:  356  	Training Loss: 0.03007560223340988
Test Loss:  0.021150879561901093
Valid Loss:  0.01848585531115532
Epoch:  357  	Training Loss: 0.030075185000896454
Test Loss:  0.02115040458738804
Valid Loss:  0.018485568463802338
Epoch:  358  	Training Loss: 0.030074771493673325
Test Loss:  0.021149925887584686
Valid Loss:  0.018485281616449356
Epoch:  359  	Training Loss: 0.0300743505358696
Test Loss:  0.021149445325136185
Valid Loss:  0.018484991043806076
Epoch:  360  	Training Loss: 0.03007393144071102
Test Loss:  0.021148961037397385
Valid Loss:  0.018484704196453094
Epoch:  361  	Training Loss: 0.030073512345552444
Test Loss:  0.021148482337594032
Valid Loss:  0.018484413623809814
Epoch:  362  	Training Loss: 0.030073091387748718
Test Loss:  0.021147992461919785
Valid Loss:  0.018484100699424744
Epoch:  363  	Training Loss: 0.030072662979364395
Test Loss:  0.02114749699831009
Valid Loss:  0.018483787775039673
Epoch:  364  	Training Loss: 0.03007224202156067
Test Loss:  0.021146997809410095
Valid Loss:  0.018483469262719154
Epoch:  365  	Training Loss: 0.030071813613176346
Test Loss:  0.021146491169929504
Valid Loss:  0.018483154475688934
Epoch:  366  	Training Loss: 0.030071383342146873
Test Loss:  0.021145988255739212
Valid Loss:  0.018482839688658714
Epoch:  367  	Training Loss: 0.0300709530711174
Test Loss:  0.02114548161625862
Valid Loss:  0.018482515588402748
Epoch:  368  	Training Loss: 0.03007052093744278
Test Loss:  0.02114497497677803
Valid Loss:  0.018482189625501633
Epoch:  369  	Training Loss: 0.030070088803768158
Test Loss:  0.021144472062587738
Valid Loss:  0.01848185807466507
Epoch:  370  	Training Loss: 0.030069652944803238
Test Loss:  0.021143965423107147
Valid Loss:  0.018481526523828506
Epoch:  371  	Training Loss: 0.03006921522319317
Test Loss:  0.021143455058336258
Valid Loss:  0.018481194972991943
Epoch:  372  	Training Loss: 0.030068770051002502
Test Loss:  0.021142959594726562
Valid Loss:  0.018480870872735977
Epoch:  373  	Training Loss: 0.03006833791732788
Test Loss:  0.021142464131116867
Valid Loss:  0.01848054677248001
Epoch:  374  	Training Loss: 0.03006790764629841
Test Loss:  0.02114197239279747
Valid Loss:  0.018480222672224045
Epoch:  375  	Training Loss: 0.030067484825849533
Test Loss:  0.021141476929187775
Valid Loss:  0.018479902297258377
Epoch:  376  	Training Loss: 0.03006705269217491
Test Loss:  0.02114097587764263
Valid Loss:  0.018479574471712112
Epoch:  377  	Training Loss: 0.030066626146435738
Test Loss:  0.02114047110080719
Valid Loss:  0.018479252234101295
Epoch:  378  	Training Loss: 0.030066192150115967
Test Loss:  0.0211399607360363
Valid Loss:  0.01847892254590988
Epoch:  379  	Training Loss: 0.03006575256586075
Test Loss:  0.02113945595920086
Valid Loss:  0.018478594720363617
Epoch:  380  	Training Loss: 0.03006531111896038
Test Loss:  0.02113894559442997
Valid Loss:  0.018478255718946457
Epoch:  381  	Training Loss: 0.030064867809414864
Test Loss:  0.02113843709230423
Valid Loss:  0.018477898091077805
Epoch:  382  	Training Loss: 0.030064422637224197
Test Loss:  0.02113792859017849
Valid Loss:  0.01847754418849945
Epoch:  383  	Training Loss: 0.030063975602388382
Test Loss:  0.0211374219506979
Valid Loss:  0.018477195873856544
Epoch:  384  	Training Loss: 0.030063528567552567
Test Loss:  0.021136917173862457
Valid Loss:  0.018476836383342743
Epoch:  385  	Training Loss: 0.030063079670071602
Test Loss:  0.021136410534381866
Valid Loss:  0.018476473167538643
Epoch:  386  	Training Loss: 0.030062634497880936
Test Loss:  0.021135907620191574
Valid Loss:  0.018476106226444244
Epoch:  387  	Training Loss: 0.03006218746304512
Test Loss:  0.021135400980710983
Valid Loss:  0.018475744873285294
Epoch:  388  	Training Loss: 0.030061740428209305
Test Loss:  0.02113489620387554
Valid Loss:  0.018475379794836044
Epoch:  389  	Training Loss: 0.03006129339337349
Test Loss:  0.02113439328968525
Valid Loss:  0.018475014716386795
Epoch:  390  	Training Loss: 0.030060842633247375
Test Loss:  0.021133892238140106
Valid Loss:  0.018474644050002098
Epoch:  391  	Training Loss: 0.03006039187312126
Test Loss:  0.021133383736014366
Valid Loss:  0.0184742771089077
Epoch:  392  	Training Loss: 0.03005993366241455
Test Loss:  0.021132882684469223
Valid Loss:  0.01847391203045845
Epoch:  393  	Training Loss: 0.030059482902288437
Test Loss:  0.021132389083504677
Valid Loss:  0.0184735506772995
Epoch:  394  	Training Loss: 0.030059032142162323
Test Loss:  0.02113189734518528
Valid Loss:  0.0184731874614954
Epoch:  395  	Training Loss: 0.030058585107326508
Test Loss:  0.021131400018930435
Valid Loss:  0.018472831696271896
Epoch:  396  	Training Loss: 0.030058138072490692
Test Loss:  0.02113090455532074
Valid Loss:  0.018472464755177498
Epoch:  397  	Training Loss: 0.03005768544971943
Test Loss:  0.021130410954356194
Valid Loss:  0.018472101539373398
Epoch:  398  	Training Loss: 0.030057230964303017
Test Loss:  0.02112991362810135
Valid Loss:  0.01847173646092415
Epoch:  399  	Training Loss: 0.030056769028306007
Test Loss:  0.021129412576556206
Valid Loss:  0.018471362069249153
Epoch:  400  	Training Loss: 0.03005630150437355
Test Loss:  0.021128911525011063
Valid Loss:  0.01847097836434841
Epoch:  401  	Training Loss: 0.030055830255150795
Test Loss:  0.02112840861082077
Valid Loss:  0.01847059652209282
Epoch:  402  	Training Loss: 0.030055353417992592
Test Loss:  0.021127911284565926
Valid Loss:  0.018470216542482376
Epoch:  403  	Training Loss: 0.030054882168769836
Test Loss:  0.02112741582095623
Valid Loss:  0.018469838425517082
Epoch:  404  	Training Loss: 0.030054409056901932
Test Loss:  0.021126914769411087
Valid Loss:  0.018469462171196938
Epoch:  405  	Training Loss: 0.03005393035709858
Test Loss:  0.02112641930580139
Valid Loss:  0.018469076603651047
Epoch:  406  	Training Loss: 0.030053449794650078
Test Loss:  0.021125923842191696
Valid Loss:  0.018468700349330902
Epoch:  407  	Training Loss: 0.030052974820137024
Test Loss:  0.02112542651593685
Valid Loss:  0.018468307331204414
Epoch:  408  	Training Loss: 0.030052490532398224
Test Loss:  0.021124929189682007
Valid Loss:  0.01846792921423912
Epoch:  409  	Training Loss: 0.030052009969949722
Test Loss:  0.021124430000782013
Valid Loss:  0.018467552959918976
Epoch:  410  	Training Loss: 0.03005152754485607
Test Loss:  0.02112393081188202
Valid Loss:  0.018467169255018234
Epoch:  411  	Training Loss: 0.030051041394472122
Test Loss:  0.021123435348272324
Valid Loss:  0.018466796725988388
Epoch:  412  	Training Loss: 0.03005055896937847
Test Loss:  0.021122947335243225
Valid Loss:  0.018466420471668243
Epoch:  413  	Training Loss: 0.030050072818994522
Test Loss:  0.021122455596923828
Valid Loss:  0.01846604235470295
Epoch:  414  	Training Loss: 0.030049588531255722
Test Loss:  0.021121960133314133
Valid Loss:  0.018465667963027954
Epoch:  415  	Training Loss: 0.030049096792936325
Test Loss:  0.021121466532349586
Valid Loss:  0.01846528798341751
Epoch:  416  	Training Loss: 0.03004860319197178
Test Loss:  0.02112097665667534
Valid Loss:  0.018464911729097366
Epoch:  417  	Training Loss: 0.030048109591007233
Test Loss:  0.021120481193065643
Valid Loss:  0.018464529886841774
Epoch:  418  	Training Loss: 0.030047617852687836
Test Loss:  0.021119989454746246
Valid Loss:  0.01846414990723133
Epoch:  419  	Training Loss: 0.03004712425172329
Test Loss:  0.0211194921284914
Valid Loss:  0.01846376620233059
Epoch:  420  	Training Loss: 0.030046623200178146
Test Loss:  0.02111898362636566
Valid Loss:  0.0184633769094944
Epoch:  421  	Training Loss: 0.030046116560697556
Test Loss:  0.021118473261594772
Valid Loss:  0.018462995067238808
Epoch:  422  	Training Loss: 0.030045609921216965
Test Loss:  0.02111797407269478
Valid Loss:  0.018462611362338066
Epoch:  423  	Training Loss: 0.030045107007026672
Test Loss:  0.021117469295859337
Valid Loss:  0.018462229520082474
Epoch:  424  	Training Loss: 0.03004460036754608
Test Loss:  0.021116970106959343
Valid Loss:  0.018461843952536583
Epoch:  425  	Training Loss: 0.03004409745335579
Test Loss:  0.0211164690554142
Valid Loss:  0.018461458384990692
 85%|████████▌ | 427/500 [04:55<00:32,  2.26it/s] 86%|████████▌ | 429/500 [04:55<00:23,  3.03it/s] 86%|████████▌ | 431/500 [05:01<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:01<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:01<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:01<00:28,  2.23it/s] 88%|████████▊ | 439/500 [05:02<00:20,  2.99it/s] 88%|████████▊ | 441/500 [05:08<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:08<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:08<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:08<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:08<00:17,  2.99it/s] 90%|█████████ | 451/500 [05:15<00:58,  1.20s/it] 91%|█████████ | 453/500 [05:15<00:40,  1.16it/s] 91%|█████████ | 455/500 [05:15<00:28,  1.61it/s] 91%|█████████▏| 457/500 [05:15<00:19,  2.19it/s] 92%|█████████▏| 459/500 [05:15<00:13,  2.95it/s] 92%|█████████▏| 461/500 [05:22<00:46,  1.20s/it] 93%|█████████▎| 463/500 [05:22<00:31,  1.16it/s] 93%|█████████▎| 465/500 [05:22<00:21,  1.60it/s] 93%|█████████▎| 467/500 [05:22<00:15,  2.19it/s] 94%|█████████▍| 469/500 [05:22<00:10,  2.95it/s] 94%|█████████▍| 471/500 [05:29<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:29<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:29<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:29<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:29<00:06,  3.00it/s] 96%|█████████▌| 481/500 [05:36<00:22,  1.21s/it] 97%|█████████▋| 483/500 [05:36<00:14,  1.15it/s] 97%|█████████▋| 485/500 [05:36<00:09,  1.59it/s] 97%|█████████▋| 487/500 [05:36<00:05,  2.18it/s] 98%|█████████▊| 489/500 [05:36<00:03,  2.93it/s] 98%|█████████▊| 491/500 [05:43<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:43<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:43<00:03,  1.62it/s]Epoch:  426  	Training Loss: 0.030043594539165497
Test Loss:  0.021115968003869057
Valid Loss:  0.018461070954799652
Epoch:  427  	Training Loss: 0.030043095350265503
Test Loss:  0.02111547440290451
Valid Loss:  0.018460676074028015
Epoch:  428  	Training Loss: 0.03004259057343006
Test Loss:  0.02111496403813362
Valid Loss:  0.01846027933061123
Epoch:  429  	Training Loss: 0.030042074620723724
Test Loss:  0.021114462986588478
Valid Loss:  0.018459878861904144
Epoch:  430  	Training Loss: 0.030041558668017387
Test Loss:  0.021113958209753036
Valid Loss:  0.01845947653055191
Epoch:  431  	Training Loss: 0.0300410408526659
Test Loss:  0.021113451570272446
Valid Loss:  0.018459072336554527
Epoch:  432  	Training Loss: 0.030040523037314415
Test Loss:  0.021112944930791855
Valid Loss:  0.018458668142557144
Epoch:  433  	Training Loss: 0.03003999963402748
Test Loss:  0.021112442016601562
Valid Loss:  0.01845826394855976
Epoch:  434  	Training Loss: 0.030039481818675995
Test Loss:  0.02111193910241127
Valid Loss:  0.01845785416662693
Epoch:  435  	Training Loss: 0.03003896027803421
Test Loss:  0.02111143060028553
Valid Loss:  0.018457435071468353
Epoch:  436  	Training Loss: 0.030038440600037575
Test Loss:  0.021110929548740387
Valid Loss:  0.018457021564245224
Epoch:  437  	Training Loss: 0.03003791905939579
Test Loss:  0.021110426634550095
Valid Loss:  0.018456608057022095
Epoch:  438  	Training Loss: 0.030037399381399155
Test Loss:  0.021109919995069504
Valid Loss:  0.018456190824508667
Epoch:  439  	Training Loss: 0.030036872252821922
Test Loss:  0.021109415218234062
Valid Loss:  0.01845577359199524
Epoch:  440  	Training Loss: 0.03003634884953499
Test Loss:  0.02110891416668892
Valid Loss:  0.01845535635948181
Epoch:  441  	Training Loss: 0.030035825446248055
Test Loss:  0.021108411252498627
Valid Loss:  0.018454939126968384
Epoch:  442  	Training Loss: 0.03003530204296112
Test Loss:  0.02110791578888893
Valid Loss:  0.018454521894454956
Epoch:  443  	Training Loss: 0.030034784227609634
Test Loss:  0.02110741287469864
Valid Loss:  0.018454108387231827
Epoch:  444  	Training Loss: 0.03003426268696785
Test Loss:  0.021106909960508347
Valid Loss:  0.018453696742653847
Epoch:  445  	Training Loss: 0.030033744871616364
Test Loss:  0.02110639214515686
Valid Loss:  0.018453281372785568
Epoch:  446  	Training Loss: 0.030033225193619728
Test Loss:  0.021105878055095673
Valid Loss:  0.01845286414027214
Epoch:  447  	Training Loss: 0.030032703652977943
Test Loss:  0.021105362102389336
Valid Loss:  0.01845245063304901
Epoch:  448  	Training Loss: 0.030032187700271606
Test Loss:  0.021104846149683
Valid Loss:  0.018452029675245285
Epoch:  449  	Training Loss: 0.03003166802227497
Test Loss:  0.02110433205962181
Valid Loss:  0.018451612442731857
Epoch:  450  	Training Loss: 0.030031144618988037
Test Loss:  0.021103814244270325
Valid Loss:  0.01845119707286358
Epoch:  451  	Training Loss: 0.030030615627765656
Test Loss:  0.02110329270362854
Valid Loss:  0.018450774252414703
Epoch:  452  	Training Loss: 0.030030082911252975
Test Loss:  0.021102774888277054
Valid Loss:  0.01845034956932068
Epoch:  453  	Training Loss: 0.030029546469449997
Test Loss:  0.02110225334763527
Valid Loss:  0.018449921160936356
Epoch:  454  	Training Loss: 0.03002901002764702
Test Loss:  0.021101729944348335
Valid Loss:  0.01844949461519718
Epoch:  455  	Training Loss: 0.030028466135263443
Test Loss:  0.02110120840370655
Valid Loss:  0.018449071794748306
Epoch:  456  	Training Loss: 0.030027925968170166
Test Loss:  0.021100688725709915
Valid Loss:  0.018448643386363983
Epoch:  457  	Training Loss: 0.03002738580107689
Test Loss:  0.02110016532242298
Valid Loss:  0.01844821497797966
Epoch:  458  	Training Loss: 0.030026841908693314
Test Loss:  0.021099645644426346
Valid Loss:  0.01844778284430504
Epoch:  459  	Training Loss: 0.030026298016309738
Test Loss:  0.02109912410378456
Valid Loss:  0.018447354435920715
Epoch:  460  	Training Loss: 0.030025754123926163
Test Loss:  0.021098598837852478
Valid Loss:  0.018446914851665497
Epoch:  461  	Training Loss: 0.03002520278096199
Test Loss:  0.021098077297210693
Valid Loss:  0.01844646781682968
Epoch:  462  	Training Loss: 0.030024658888578415
Test Loss:  0.021097559481859207
Valid Loss:  0.018446017056703568
Epoch:  463  	Training Loss: 0.030024105682969093
Test Loss:  0.021097032353281975
Valid Loss:  0.018445562571287155
Epoch:  464  	Training Loss: 0.030023548752069473
Test Loss:  0.021096501499414444
Valid Loss:  0.018445104360580444
Epoch:  465  	Training Loss: 0.030022986233234406
Test Loss:  0.02109597623348236
Valid Loss:  0.018444648012518883
Epoch:  466  	Training Loss: 0.030022429302334785
Test Loss:  0.02109544537961483
Valid Loss:  0.018444184213876724
Epoch:  467  	Training Loss: 0.030021868646144867
Test Loss:  0.021094925701618195
Valid Loss:  0.018443722277879715
Epoch:  468  	Training Loss: 0.030021309852600098
Test Loss:  0.02109440043568611
Valid Loss:  0.018443260341882706
Epoch:  469  	Training Loss: 0.03002075105905533
Test Loss:  0.02109387516975403
Valid Loss:  0.0184427909553051
Epoch:  470  	Training Loss: 0.03002018854022026
Test Loss:  0.021093349903821945
Valid Loss:  0.01844232715666294
Epoch:  471  	Training Loss: 0.030019626021385193
Test Loss:  0.02109282650053501
Valid Loss:  0.018441857770085335
Epoch:  472  	Training Loss: 0.030019067227840424
Test Loss:  0.021092291921377182
Valid Loss:  0.01844138652086258
Epoch:  473  	Training Loss: 0.03001849539577961
Test Loss:  0.021091755479574203
Valid Loss:  0.018440913408994675
Epoch:  474  	Training Loss: 0.030017921701073647
Test Loss:  0.021091217175126076
Valid Loss:  0.01844044029712677
Epoch:  475  	Training Loss: 0.030017351731657982
Test Loss:  0.021090680733323097
Valid Loss:  0.018439967185258865
Epoch:  476  	Training Loss: 0.030016781762242317
Test Loss:  0.021090146154165268
Valid Loss:  0.018439490348100662
Epoch:  477  	Training Loss: 0.030016209930181503
Test Loss:  0.021089604124426842
Valid Loss:  0.018439006060361862
Epoch:  478  	Training Loss: 0.03001563996076584
Test Loss:  0.021089065819978714
Valid Loss:  0.01843852549791336
Epoch:  479  	Training Loss: 0.030015068128705025
Test Loss:  0.021088529378175735
Valid Loss:  0.018438037484884262
Epoch:  480  	Training Loss: 0.03001449629664421
Test Loss:  0.021087996661663055
Valid Loss:  0.01843756064772606
Epoch:  481  	Training Loss: 0.030013926327228546
Test Loss:  0.021087460219860077
Valid Loss:  0.018437080085277557
Epoch:  482  	Training Loss: 0.03001335635781288
Test Loss:  0.0210869200527668
Valid Loss:  0.018436593934893608
Epoch:  483  	Training Loss: 0.030012790113687515
Test Loss:  0.021086379885673523
Valid Loss:  0.018436111509799957
Epoch:  484  	Training Loss: 0.03001222386956215
Test Loss:  0.021085839718580246
Valid Loss:  0.018435627222061157
Epoch:  485  	Training Loss: 0.030011648312211037
Test Loss:  0.021085292100906372
Valid Loss:  0.018435131758451462
Epoch:  486  	Training Loss: 0.030011069029569626
Test Loss:  0.0210847407579422
Valid Loss:  0.018434634432196617
Epoch:  487  	Training Loss: 0.030010487884283066
Test Loss:  0.021084193140268326
Valid Loss:  0.018434137105941772
Epoch:  488  	Training Loss: 0.030009906738996506
Test Loss:  0.021083645522594452
Valid Loss:  0.01843363046646118
Epoch:  489  	Training Loss: 0.030009320005774498
Test Loss:  0.021083097904920578
Valid Loss:  0.01843312755227089
Epoch:  490  	Training Loss: 0.03000873140990734
Test Loss:  0.021082546561956406
Valid Loss:  0.018432628363370895
Epoch:  491  	Training Loss: 0.030008144676685333
Test Loss:  0.02108200080692768
Valid Loss:  0.0184321291744709
Epoch:  492  	Training Loss: 0.030007554218173027
Test Loss:  0.02108144760131836
Valid Loss:  0.018431615084409714
Epoch:  493  	Training Loss: 0.030006954446434975
Test Loss:  0.02108089253306389
Valid Loss:  0.018431102856993675
Epoch:  494  	Training Loss: 0.03000635839998722
Test Loss:  0.021080337464809418
Valid Loss:  0.018430586904287338
Epoch:  495  	Training Loss: 0.03000575862824917
Test Loss:  0.021079782396554947
Valid Loss:  0.018430070951581
Epoch:  496  	Training Loss: 0.030005155131220818
Test Loss:  0.021079227328300476 99%|█████████▉| 497/500 [05:43<00:01,  2.20it/s]100%|█████████▉| 499/500 [05:43<00:00,  2.95it/s]100%|██████████| 500/500 [05:43<00:00,  1.45it/s]

Valid Loss:  0.018429554998874664
Epoch:  497  	Training Loss: 0.030004551634192467
Test Loss:  0.021078668534755707
Valid Loss:  0.018429037183523178
Epoch:  498  	Training Loss: 0.030003944411873817
Test Loss:  0.02107810042798519
Valid Loss:  0.018428511917591095
Epoch:  499  	Training Loss: 0.03000333160161972
Test Loss:  0.021077536046504974
Valid Loss:  0.01842799410223961
Epoch:  500  	Training Loss: 0.030002715066075325
Test Loss:  0.021076878532767296
Valid Loss:  0.018427181988954544
seed is  8
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:03,  6.26s/it]  1%|          | 3/500 [00:06<13:56,  1.68s/it]  1%|          | 5/500 [00:06<07:01,  1.18it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:50,  1.33s/it]  3%|▎         | 13/500 [00:13<07:23,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:20<09:40,  1.21s/it]  5%|▍         | 23/500 [00:20<06:52,  1.16it/s]  5%|▌         | 25/500 [00:20<04:56,  1.60it/s]  5%|▌         | 27/500 [00:20<03:35,  2.20it/s]  6%|▌         | 29/500 [00:20<02:38,  2.96it/s]  6%|▌         | 31/500 [00:27<09:26,  1.21s/it]  7%|▋         | 33/500 [00:27<06:46,  1.15it/s]  7%|▋         | 35/500 [00:33<12:09,  1.57s/it]  7%|▋         | 37/500 [00:33<08:37,  1.12s/it]  8%|▊         | 39/500 [00:33<06:09,  1.25it/s]  8%|▊         | 41/500 [00:40<11:35,  1.52s/it]  9%|▊         | 43/500 [00:40<08:14,  1.08s/it]  9%|▉         | 45/500 [00:40<05:53,  1.29it/s]  9%|▉         | 47/500 [00:40<04:15,  1.78it/s] 10%|▉         | 49/500 [00:40<03:06,  2.42it/s] 10%|█         | 51/500 [00:47<09:22,  1.25s/it] 11%|█         | 53/500 [00:47<06:42,  1.11it/s] 11%|█         | 55/500 [00:47<04:52,  1.52it/s] 11%|█▏        | 57/500 [00:47<03:32,  2.08it/s] 12%|█▏        | 59/500 [00:47<02:36,  2.81it/s] 12%|█▏        | 61/500 [00:54<08:46,  1.20s/it] 13%|█▎        | 63/500 [00:54<06:18,  1.15it/s] 13%|█▎        | 65/500 [00:54<04:35,  1.58it/s] 13%|█▎        | 67/500 [00:54<03:22,  2.13it/s] 14%|█▍        | 69/500 [00:54<02:30,  2.86it/s]Epoch:  1  	Training Loss: 0.029495006427168846
Test Loss:  0.012943556532263756
Valid Loss:  0.01166597381234169
Epoch:  2  	Training Loss: 0.015811119228601456
Test Loss:  0.02683275192975998
Valid Loss:  0.027414469048380852
Epoch:  3  	Training Loss: 0.024353235960006714
Test Loss:  0.05879752337932587
Valid Loss:  0.055718183517456055
Epoch:  4  	Training Loss: 0.07241848856210709
Test Loss:  0.017563853412866592
Valid Loss:  0.015840571373701096
Epoch:  5  	Training Loss: 0.02068071998655796
Test Loss:  0.016513075679540634
Valid Loss:  0.01480959914624691
Epoch:  6  	Training Loss: 0.01992202363908291
Test Loss:  0.015702206641435623
Valid Loss:  0.014017398469150066
Epoch:  7  	Training Loss: 0.019350171089172363
Test Loss:  0.015163644216954708
Valid Loss:  0.013496562838554382
Epoch:  8  	Training Loss: 0.018986590206623077
Test Loss:  0.014676425606012344
Valid Loss:  0.013020077720284462
Epoch:  9  	Training Loss: 0.01868658885359764
Test Loss:  0.014306843280792236
Valid Loss:  0.012676871381700039
Epoch:  10  	Training Loss: 0.01846463419497013
Test Loss:  0.013922544196248055
Valid Loss:  0.01230041217058897
Epoch:  11  	Training Loss: 0.01817898452281952
Test Loss:  0.01376333273947239
Valid Loss:  0.012153888121247292
Epoch:  12  	Training Loss: 0.018061455339193344
Test Loss:  0.009202130138874054
Valid Loss:  0.00871993601322174
Epoch:  13  	Training Loss: 0.010089369490742683
Test Loss:  0.007120535708963871
Valid Loss:  0.006570098921656609
Epoch:  14  	Training Loss: 0.008599013090133667
Test Loss:  0.007188132964074612
Valid Loss:  0.006996640935540199
Epoch:  15  	Training Loss: 0.008028823882341385
Test Loss:  0.005858640652149916
Valid Loss:  0.005390988662838936
Epoch:  16  	Training Loss: 0.007602027617394924
Test Loss:  0.006644797511398792
Valid Loss:  0.006611543241888285
Epoch:  17  	Training Loss: 0.007337768562138081
Test Loss:  0.0051406570710241795
Valid Loss:  0.004698148928582668
Epoch:  18  	Training Loss: 0.00709241209551692
Test Loss:  0.006388617679476738
Valid Loss:  0.0064949579536914825
Epoch:  19  	Training Loss: 0.006937431637197733
Test Loss:  0.004745464771986008
Valid Loss:  0.004324202425777912
Epoch:  20  	Training Loss: 0.006843884475529194
Test Loss:  0.006338835693895817
Valid Loss:  0.006568873301148415
Epoch:  21  	Training Loss: 0.006781931035220623
Test Loss:  0.004633763805031776
Valid Loss:  0.004225556738674641
Epoch:  22  	Training Loss: 0.00684492290019989
Test Loss:  0.006065782159566879
Valid Loss:  0.0064118364825844765
Epoch:  23  	Training Loss: 0.0065144989639520645
Test Loss:  0.00440957210958004
Valid Loss:  0.004044568166136742
Epoch:  24  	Training Loss: 0.006517697125673294
Test Loss:  0.0058321114629507065
Valid Loss:  0.006244688294827938
Epoch:  25  	Training Loss: 0.00624519307166338
Test Loss:  0.004191461484879255
Valid Loss:  0.0038646378088742495
Epoch:  26  	Training Loss: 0.00619973661378026
Test Loss:  0.005468231160193682
Valid Loss:  0.005870912689715624
Epoch:  27  	Training Loss: 0.005910178646445274
Test Loss:  0.003934261854737997
Valid Loss:  0.003651510924100876
Epoch:  28  	Training Loss: 0.005828599911183119
Test Loss:  0.005092978943139315
Valid Loss:  0.005477610044181347
Epoch:  29  	Training Loss: 0.005577347707003355
Test Loss:  0.0037061944603919983
Valid Loss:  0.0034658792428672314
Epoch:  30  	Training Loss: 0.0054915850050747395
Test Loss:  0.004754967056214809
Valid Loss:  0.005118254572153091
Epoch:  31  	Training Loss: 0.005279147531837225
Test Loss:  0.0035061510279774666
Valid Loss:  0.003303362987935543
Epoch:  32  	Training Loss: 0.005186995025724173
Test Loss:  0.008454317227005959
Valid Loss:  0.009190067648887634
Epoch:  33  	Training Loss: 0.008859063498675823
Test Loss:  0.018769223242998123
Valid Loss:  0.017867043614387512
Epoch:  34  	Training Loss: 0.02365713194012642
Test Loss:  0.007953288033604622
Valid Loss:  0.007136229425668716
Epoch:  35  	Training Loss: 0.011042884550988674
Test Loss:  0.006720227189362049
Valid Loss:  0.0060227238573133945
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.009941254742443562
Test Loss:  0.00598046462982893
Valid Loss:  0.0054109180346131325
Epoch:  37  	Training Loss: 0.008788110688328743
Test Loss:  0.004647263325750828
Valid Loss:  0.004407070577144623
Epoch:  38  	Training Loss: 0.00668761134147644
Test Loss:  0.004267082549631596
Valid Loss:  0.004144786857068539
Epoch:  39  	Training Loss: 0.006100818980485201
Test Loss:  0.003924841992557049
Valid Loss:  0.0038735847920179367
Epoch:  40  	Training Loss: 0.005640082526952028
Test Loss:  0.003633522894233465
Valid Loss:  0.003629333572462201
Epoch:  41  	Training Loss: 0.005253695882856846
Test Loss:  0.003388762939721346
Valid Loss:  0.003420570632442832
Epoch:  42  	Training Loss: 0.004925702232867479
Test Loss:  0.0031367777846753597
Valid Loss:  0.003215593285858631
Epoch:  43  	Training Loss: 0.00463138148188591
Test Loss:  0.0029988721944391727
Valid Loss:  0.00321336486376822
Epoch:  44  	Training Loss: 0.004293786361813545
Test Loss:  0.002812011865898967
Valid Loss:  0.002978184260427952
Epoch:  45  	Training Loss: 0.0041463314555585384
Test Loss:  0.002766407560557127
Valid Loss:  0.0030511002987623215
Epoch:  46  	Training Loss: 0.003915012814104557
Test Loss:  0.0026575056836009026
Valid Loss:  0.0029166864696890116
Epoch:  47  	Training Loss: 0.00382022000849247
Test Loss:  0.0026753521524369717
Valid Loss:  0.00299459183588624
Epoch:  48  	Training Loss: 0.003780336119234562
Test Loss:  0.002603133674710989
Valid Loss:  0.0028755050152540207
Epoch:  49  	Training Loss: 0.0037786136381328106
Test Loss:  0.002631891518831253
Valid Loss:  0.0030082929879426956
Epoch:  50  	Training Loss: 0.003681423142552376
Test Loss:  0.002550811506807804
Valid Loss:  0.0029015764594078064
Epoch:  51  	Training Loss: 0.0036263992078602314
Test Loss:  0.0025509181432425976
Valid Loss:  0.002930485177785158
Epoch:  52  	Training Loss: 0.003594107460230589
Test Loss:  0.0024394432548433542
Valid Loss:  0.002760655712336302
Epoch:  53  	Training Loss: 0.0034547599498182535
Test Loss:  0.002315751276910305
Valid Loss:  0.002628097776323557
Epoch:  54  	Training Loss: 0.003291940549388528
Test Loss:  0.0022440594621002674
Valid Loss:  0.0025685722939670086
Epoch:  55  	Training Loss: 0.003171397838741541
Test Loss:  0.002144882222637534
Valid Loss:  0.002446450525894761
Epoch:  56  	Training Loss: 0.0030685877427458763
Test Loss:  0.0020707391668111086
Valid Loss:  0.0023672878742218018
Epoch:  57  	Training Loss: 0.0029700547456741333
Test Loss:  0.00201919162645936
Valid Loss:  0.0023346676025539637
Epoch:  58  	Training Loss: 0.0028592199087142944
Test Loss:  0.0019426251528784633
Valid Loss:  0.0022487109526991844
Epoch:  59  	Training Loss: 0.002772445324808359
Test Loss:  0.001905508222989738
Valid Loss:  0.0022293340880423784
Epoch:  60  	Training Loss: 0.0026957865338772535
Test Loss:  0.0018396731466054916
Valid Loss:  0.002152294386178255
Epoch:  61  	Training Loss: 0.002649245085194707
Test Loss:  0.0018301296513527632
Valid Loss:  0.0021678125485777855
Epoch:  62  	Training Loss: 0.002589114010334015
Test Loss:  0.0017408167477697134
Valid Loss:  0.002081256126984954
Epoch:  63  	Training Loss: 0.0025008819065988064
Test Loss:  0.001721769105643034
Valid Loss:  0.0020911453757435083
Epoch:  64  	Training Loss: 0.0024171844124794006
Test Loss:  0.0016510100103914738
Valid Loss:  0.0020195182878524065
Epoch:  65  	Training Loss: 0.002349334303289652
Test Loss:  0.0016203124541789293
Valid Loss:  0.0020034185145050287
Epoch:  66  	Training Loss: 0.002291882410645485
Test Loss:  0.001566045917570591
Valid Loss:  0.0019450904801487923
Epoch:  67  	Training Loss: 0.0022378647699952126
Test Loss:  0.0015409409534186125
Valid Loss:  0.0019395144190639257
Epoch:  68  	Training Loss: 0.00217175274156034
Test Loss:  0.0014783774968236685
Valid Loss:  0.0018799937097355723
Epoch:  69  	Training Loss: 0.002111334353685379
Test Loss:  0.0014472852926701307
Valid Loss:  0.0018653646111488342
 14%|█▍        | 71/500 [01:01<08:32,  1.20s/it] 15%|█▍        | 73/500 [01:01<06:06,  1.17it/s] 15%|█▌        | 75/500 [01:01<04:23,  1.61it/s] 15%|█▌        | 77/500 [01:01<03:11,  2.20it/s] 16%|█▌        | 79/500 [01:01<02:23,  2.94it/s] 16%|█▌        | 81/500 [01:08<08:27,  1.21s/it] 17%|█▋        | 83/500 [01:08<06:03,  1.15it/s] 17%|█▋        | 85/500 [01:08<04:21,  1.59it/s] 17%|█▋        | 87/500 [01:08<03:10,  2.17it/s] 18%|█▊        | 89/500 [01:08<02:20,  2.93it/s] 18%|█▊        | 91/500 [01:14<08:02,  1.18s/it] 19%|█▊        | 93/500 [01:15<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:15<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:15<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:15<02:13,  3.00it/s] 20%|██        | 101/500 [01:21<07:55,  1.19s/it] 21%|██        | 103/500 [01:22<05:40,  1.17it/s] 21%|██        | 105/500 [01:22<04:06,  1.60it/s] 21%|██▏       | 107/500 [01:22<02:59,  2.19it/s] 22%|██▏       | 109/500 [01:22<02:12,  2.95it/s] 22%|██▏       | 111/500 [01:28<07:47,  1.20s/it] 23%|██▎       | 113/500 [01:29<05:33,  1.16it/s] 23%|██▎       | 115/500 [01:29<04:00,  1.60it/s] 23%|██▎       | 117/500 [01:29<02:54,  2.19it/s] 24%|██▍       | 119/500 [01:29<02:09,  2.94it/s] 24%|██▍       | 121/500 [01:36<07:50,  1.24s/it] 25%|██▍       | 123/500 [01:36<05:35,  1.12it/s] 25%|██▌       | 125/500 [01:36<04:00,  1.56it/s] 25%|██▌       | 127/500 [01:36<02:55,  2.13it/s] 26%|██▌       | 129/500 [01:36<02:09,  2.87it/s] 26%|██▌       | 131/500 [01:43<07:25,  1.21s/it] 27%|██▋       | 133/500 [01:43<05:19,  1.15it/s] 27%|██▋       | 135/500 [01:43<03:49,  1.59it/s] 27%|██▋       | 137/500 [01:43<02:47,  2.17it/s]Epoch:  70  	Training Loss: 0.0020609586499631405
Test Loss:  0.0014039241941645741
Valid Loss:  0.0018241043435409665
Epoch:  71  	Training Loss: 0.0020231776870787144
Test Loss:  0.001394597114995122
Valid Loss:  0.001834482653066516
Epoch:  72  	Training Loss: 0.0019843042828142643
Test Loss:  0.0013563910033553839
Valid Loss:  0.0017926060827448964
Epoch:  73  	Training Loss: 0.001951452810317278
Test Loss:  0.0013377643190324306
Valid Loss:  0.0017793567385524511
Epoch:  74  	Training Loss: 0.0019206749275326729
Test Loss:  0.0013139862567186356
Valid Loss:  0.0017580976709723473
Epoch:  75  	Training Loss: 0.0018916671397164464
Test Loss:  0.0012932026293128729
Valid Loss:  0.0017401132499799132
Epoch:  76  	Training Loss: 0.0018638706533238292
Test Loss:  0.0012725202832370996
Valid Loss:  0.0017215197440236807
Epoch:  77  	Training Loss: 0.0018371103797107935
Test Loss:  0.0012526354985311627
Valid Loss:  0.001703563961200416
Epoch:  78  	Training Loss: 0.0018112764228135347
Test Loss:  0.0012333387276157737
Valid Loss:  0.001686223316937685
Epoch:  79  	Training Loss: 0.0017863676184788346
Test Loss:  0.0012147414963692427
Valid Loss:  0.0016697391401976347
Epoch:  80  	Training Loss: 0.001762370695360005
Test Loss:  0.0011968610342592
Valid Loss:  0.0016541127115488052
Epoch:  81  	Training Loss: 0.0017394652822986245
Test Loss:  0.001180481631308794
Valid Loss:  0.0016406987560912967
Epoch:  82  	Training Loss: 0.0017176957335323095
Test Loss:  0.0011572340736165643
Valid Loss:  0.0016214996576309204
Epoch:  83  	Training Loss: 0.001693380530923605
Test Loss:  0.0011385285761207342
Valid Loss:  0.001606407924555242
Epoch:  84  	Training Loss: 0.0016738874837756157
Test Loss:  0.0011218662839382887
Valid Loss:  0.0015932184178382158
Epoch:  85  	Training Loss: 0.0016565502155572176
Test Loss:  0.0011067504528909922
Valid Loss:  0.0015810581389814615
Epoch:  86  	Training Loss: 0.001640596310608089
Test Loss:  0.0010930937714874744
Valid Loss:  0.001570067135617137
Epoch:  87  	Training Loss: 0.0016259952681139112
Test Loss:  0.0010802332544699311
Valid Loss:  0.0015601017512381077
Epoch:  88  	Training Loss: 0.0016124797984957695
Test Loss:  0.0010677489917725325
Valid Loss:  0.001550422515720129
Epoch:  89  	Training Loss: 0.0015994904097169638
Test Loss:  0.001057315617799759
Valid Loss:  0.001541568897664547
Epoch:  90  	Training Loss: 0.0015878984704613686
Test Loss:  0.0010476773604750633
Valid Loss:  0.0015330975875258446
Epoch:  91  	Training Loss: 0.0015766806900501251
Test Loss:  0.001038293237797916
Valid Loss:  0.0015249549178406596
Epoch:  92  	Training Loss: 0.0015658946940675378
Test Loss:  0.001043718191795051
Valid Loss:  0.0015408089384436607
Epoch:  93  	Training Loss: 0.0015532602556049824
Test Loss:  0.0010343759786337614
Valid Loss:  0.001527498010545969
Epoch:  94  	Training Loss: 0.0015444100135937333
Test Loss:  0.0010403688065707684
Valid Loss:  0.001539111020974815
Epoch:  95  	Training Loss: 0.0015370012260973454
Test Loss:  0.0010357113787904382
Valid Loss:  0.0015338226221501827
Epoch:  96  	Training Loss: 0.0015328316949307919
Test Loss:  0.0010358006693422794
Valid Loss:  0.0015350468456745148
Epoch:  97  	Training Loss: 0.0015294838231056929
Test Loss:  0.0010343329049646854
Valid Loss:  0.0015334299532696605
Epoch:  98  	Training Loss: 0.0015266214031726122
Test Loss:  0.001033226726576686
Valid Loss:  0.0015319704543799162
Epoch:  99  	Training Loss: 0.0015243038069456816
Test Loss:  0.001032328582368791
Valid Loss:  0.0015306194545701146
Epoch:  100  	Training Loss: 0.001522223697975278
Test Loss:  0.0010311136720702052
Valid Loss:  0.0015289618168026209
Epoch:  101  	Training Loss: 0.0015202718786895275
Test Loss:  0.0010300988797098398
Valid Loss:  0.0015276387566700578
Epoch:  102  	Training Loss: 0.001518412958830595
Test Loss:  0.0010008509270846844
Valid Loss:  0.0014935482759028673
Epoch:  103  	Training Loss: 0.001481494982726872
Test Loss:  0.0009829523041844368
Valid Loss:  0.0014776645693928003
Epoch:  104  	Training Loss: 0.0014658800791949034
Test Loss:  0.0009726252174004912
Valid Loss:  0.0014717888552695513
Epoch:  105  	Training Loss: 0.001451260643079877
Test Loss:  0.0009587153326719999
Valid Loss:  0.0014587753685191274
Epoch:  106  	Training Loss: 0.0014375548344105482
Test Loss:  0.0009490595548413694
Valid Loss:  0.0014522672863677144
Epoch:  107  	Training Loss: 0.0014242250472307205
Test Loss:  0.000936437223572284
Valid Loss:  0.001440594089217484
Epoch:  108  	Training Loss: 0.0014112647622823715
Test Loss:  0.0009270907030440867
Valid Loss:  0.0014338328037410975
Epoch:  109  	Training Loss: 0.0013987591955810785
Test Loss:  0.00091595045523718
Valid Loss:  0.0014233298134058714
Epoch:  110  	Training Loss: 0.0013866927474737167
Test Loss:  0.0009077308932319283
Valid Loss:  0.0014169710921123624
Epoch:  111  	Training Loss: 0.0013751694932579994
Test Loss:  0.0008990295464172959
Valid Loss:  0.0014088778989389539
Epoch:  112  	Training Loss: 0.0013640383258461952
Test Loss:  0.0009000040008686483
Valid Loss:  0.0014108829200267792
Epoch:  113  	Training Loss: 0.0013617469230666757
Test Loss:  0.0008992981747724116
Valid Loss:  0.001410397351719439
Epoch:  114  	Training Loss: 0.001360188121907413
Test Loss:  0.0008986853063106537
Valid Loss:  0.001409974996931851
Epoch:  115  	Training Loss: 0.0013588189613074064
Test Loss:  0.0008981433929875493
Valid Loss:  0.001409545773640275
Epoch:  116  	Training Loss: 0.0013576161582022905
Test Loss:  0.0008975045057013631
Valid Loss:  0.0014090822078287601
Epoch:  117  	Training Loss: 0.0013564573600888252
Test Loss:  0.0008967520552687347
Valid Loss:  0.0014084787108004093
Epoch:  118  	Training Loss: 0.001355327432975173
Test Loss:  0.0008960052509792149
Valid Loss:  0.0014078650856390595
Epoch:  119  	Training Loss: 0.001354228239506483
Test Loss:  0.0008952681673690677
Valid Loss:  0.0014072468038648367
Epoch:  120  	Training Loss: 0.0013531947042793036
Test Loss:  0.000894613447599113
Valid Loss:  0.0014066968578845263
Epoch:  121  	Training Loss: 0.001352221122942865
Test Loss:  0.000893892371095717
Valid Loss:  0.001406063325703144
Epoch:  122  	Training Loss: 0.0013512508012354374
Test Loss:  0.000889916904270649
Valid Loss:  0.0014024965930730104
Epoch:  123  	Training Loss: 0.001347013283520937
Test Loss:  0.0008869034936651587
Valid Loss:  0.001399346045218408
Epoch:  124  	Training Loss: 0.0013437946327030659
Test Loss:  0.0008846449200063944
Valid Loss:  0.0013968218117952347
Epoch:  125  	Training Loss: 0.0013412850676104426
Test Loss:  0.0008826422854326665
Valid Loss:  0.00139482447411865
Epoch:  126  	Training Loss: 0.0013390366220846772
Test Loss:  0.000880986568517983
Valid Loss:  0.0013929990818724036
Epoch:  127  	Training Loss: 0.0013370837550610304
Test Loss:  0.0008795126341283321
Valid Loss:  0.0013914272421970963
Epoch:  128  	Training Loss: 0.0013354013208299875
Test Loss:  0.0008781987125985324
Valid Loss:  0.0013899578480049968
Epoch:  129  	Training Loss: 0.0013338732533156872
Test Loss:  0.0008772410219535232
Valid Loss:  0.001388591481372714
Epoch:  130  	Training Loss: 0.0013325666077435017
Test Loss:  0.0008765945676714182
Valid Loss:  0.0013872949639335275
Epoch:  131  	Training Loss: 0.0013314695097506046
Test Loss:  0.0008761105127632618
Valid Loss:  0.0013860899489372969
Epoch:  132  	Training Loss: 0.0013305385364219546
Test Loss:  0.00086946040391922
Valid Loss:  0.001380471745505929
Epoch:  133  	Training Loss: 0.0013231447665020823
Test Loss:  0.0008630495867691934
Valid Loss:  0.0013751151273027062
Epoch:  134  	Training Loss: 0.0013158549554646015
Test Loss:  0.0008568089106120169
Valid Loss:  0.0013698609545826912
Epoch:  135  	Training Loss: 0.001308684004470706
Test Loss:  0.0008507913444191217
Valid Loss:  0.0013646644074469805
Epoch:  136  	Training Loss: 0.0013016510056331754
Test Loss:  0.0008460904937237501
Valid Loss:  0.001360833179205656
Epoch:  137  	Training Loss: 0.001294957590289414
Test Loss:  0.0008415353368036449
Valid Loss:  0.0013569222064688802
Epoch:  138  	Training Loss: 0.0012884318130090833
Test Loss:  0.0008367757545784116
Valid Loss:   28%|██▊       | 139/500 [01:43<02:03,  2.92it/s] 28%|██▊       | 141/500 [01:50<07:17,  1.22s/it] 29%|██▊       | 143/500 [01:50<05:12,  1.14it/s] 29%|██▉       | 145/500 [01:50<03:44,  1.58it/s] 29%|██▉       | 147/500 [01:50<02:43,  2.16it/s] 30%|██▉       | 149/500 [01:50<02:00,  2.90it/s] 30%|███       | 151/500 [01:57<06:58,  1.20s/it] 31%|███       | 153/500 [01:57<04:58,  1.16it/s] 31%|███       | 155/500 [01:57<03:34,  1.61it/s] 31%|███▏      | 157/500 [01:57<02:36,  2.20it/s] 32%|███▏      | 159/500 [01:57<01:55,  2.96it/s] 32%|███▏      | 161/500 [02:03<06:39,  1.18s/it] 33%|███▎      | 163/500 [02:04<04:45,  1.18it/s] 33%|███▎      | 165/500 [02:04<03:25,  1.63it/s] 33%|███▎      | 167/500 [02:04<02:29,  2.22it/s] 34%|███▍      | 169/500 [02:04<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:10<06:33,  1.20s/it] 35%|███▍      | 173/500 [02:11<04:41,  1.16it/s] 35%|███▌      | 175/500 [02:11<03:22,  1.60it/s] 35%|███▌      | 177/500 [02:11<02:27,  2.19it/s] 36%|███▌      | 179/500 [02:11<01:48,  2.95it/s] 36%|███▌      | 181/500 [02:17<06:15,  1.18s/it] 37%|███▋      | 183/500 [02:17<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:17<03:12,  1.63it/s] 37%|███▋      | 187/500 [02:18<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:18<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:24<05:59,  1.16s/it] 39%|███▊      | 193/500 [02:24<04:16,  1.20it/s] 39%|███▉      | 195/500 [02:24<03:04,  1.65it/s] 39%|███▉      | 197/500 [02:24<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:25<01:42,  2.93it/s] 40%|████      | 201/500 [02:31<05:56,  1.19s/it] 41%|████      | 203/500 [02:31<04:14,  1.17it/s] 41%|████      | 205/500 [02:31<03:03,  1.61it/s]0.0013525362592190504
Epoch:  139  	Training Loss: 0.0012820009142160416
Test Loss:  0.0008320565102621913
Valid Loss:  0.0013480497291311622
Epoch:  140  	Training Loss: 0.0012757029617205262
Test Loss:  0.0008273276034742594
Valid Loss:  0.0013434970751404762
Epoch:  141  	Training Loss: 0.0012694712495431304
Test Loss:  0.0008226098725572228
Valid Loss:  0.0013389099622145295
Epoch:  142  	Training Loss: 0.0012633067090064287
Test Loss:  0.0008148452034220099
Valid Loss:  0.0013296555262058973
Epoch:  143  	Training Loss: 0.0012555047869682312
Test Loss:  0.0008093260694295168
Valid Loss:  0.0013241132255643606
Epoch:  144  	Training Loss: 0.0012495091650635004
Test Loss:  0.0008039928507059813
Valid Loss:  0.0013187157455831766
Epoch:  145  	Training Loss: 0.00124368944671005
Test Loss:  0.000799228553660214
Valid Loss:  0.0013136365450918674
Epoch:  146  	Training Loss: 0.0012380309635773301
Test Loss:  0.0007945744437165558
Valid Loss:  0.0013086232356727123
Epoch:  147  	Training Loss: 0.0012324163690209389
Test Loss:  0.0007900213822722435
Valid Loss:  0.0013038362376391888
Epoch:  148  	Training Loss: 0.001226880238391459
Test Loss:  0.000785615760833025
Valid Loss:  0.0012993721757084131
Epoch:  149  	Training Loss: 0.0012214493472129107
Test Loss:  0.000781312701292336
Valid Loss:  0.0012948409421369433
Epoch:  150  	Training Loss: 0.001216202974319458
Test Loss:  0.000777165696490556
Valid Loss:  0.0012906382326036692
Epoch:  151  	Training Loss: 0.0012110217940062284
Test Loss:  0.0007730380166321993
Valid Loss:  0.0012862752191722393
Epoch:  152  	Training Loss: 0.0012058934662491083
Test Loss:  0.0007521150400862098
Valid Loss:  0.0012636241735890508
Epoch:  153  	Training Loss: 0.0011695672292262316
Test Loss:  0.0007355326670221984
Valid Loss:  0.0012450963258743286
Epoch:  154  	Training Loss: 0.0011400351068004966
Test Loss:  0.0007274305680766702
Valid Loss:  0.0012327166041359305
Epoch:  155  	Training Loss: 0.0011288123205304146
Test Loss:  0.0007255132077261806
Valid Loss:  0.0012310976162552834
Epoch:  156  	Training Loss: 0.0011254516430199146
Test Loss:  0.0007214934448711574
Valid Loss:  0.0012234069872647524
Epoch:  157  	Training Loss: 0.0011228497605770826
Test Loss:  0.0007191710756160319
Valid Loss:  0.0012191326823085546
Epoch:  158  	Training Loss: 0.0011204740731045604
Test Loss:  0.0007166112191043794
Valid Loss:  0.0012141014449298382
Epoch:  159  	Training Loss: 0.0011182664893567562
Test Loss:  0.0007145156851038337
Valid Loss:  0.001209854381158948
Epoch:  160  	Training Loss: 0.0011162231676280499
Test Loss:  0.0007127077551558614
Valid Loss:  0.0012058666907250881
Epoch:  161  	Training Loss: 0.0011142417788505554
Test Loss:  0.0007110605947673321
Valid Loss:  0.0012021784204989672
Epoch:  162  	Training Loss: 0.0011123386211693287
Test Loss:  0.0007107483106665313
Valid Loss:  0.0012009842321276665
Epoch:  163  	Training Loss: 0.0011107469908893108
Test Loss:  0.0007102546514943242
Valid Loss:  0.0011990380007773638
Epoch:  164  	Training Loss: 0.001109008677303791
Test Loss:  0.0007097885245457292
Valid Loss:  0.001196858356706798
Epoch:  165  	Training Loss: 0.0011072594206780195
Test Loss:  0.0007093295571394265
Valid Loss:  0.0011946725426241755
Epoch:  166  	Training Loss: 0.0011055043432861567
Test Loss:  0.0007088171551004052
Valid Loss:  0.001192254014313221
Epoch:  167  	Training Loss: 0.001103609218262136
Test Loss:  0.0007083748932927847
Valid Loss:  0.0011895515490323305
Epoch:  168  	Training Loss: 0.0011014740448445082
Test Loss:  0.0007074275054037571
Valid Loss:  0.001186444889754057
Epoch:  169  	Training Loss: 0.0010991502786055207
Test Loss:  0.0007059950148686767
Valid Loss:  0.0011831165757030249
Epoch:  170  	Training Loss: 0.001096709631383419
Test Loss:  0.0007040101336315274
Valid Loss:  0.00117946055252105
Epoch:  171  	Training Loss: 0.0010940085630863905
Test Loss:  0.000701731420122087
Valid Loss:  0.0011754822917282581
Epoch:  172  	Training Loss: 0.0010909046977758408
Test Loss:  0.0006950064562261105
Valid Loss:  0.0011676200665533543
Epoch:  173  	Training Loss: 0.0010835472494363785
Test Loss:  0.0006885885377414525
Valid Loss:  0.0011603108141571283
Epoch:  174  	Training Loss: 0.0010763132013380527
Test Loss:  0.0006823118310421705
Valid Loss:  0.001153293065726757
Epoch:  175  	Training Loss: 0.0010690727503970265
Test Loss:  0.0006761603290215135
Valid Loss:  0.0011464925482869148
Epoch:  176  	Training Loss: 0.0010619073873385787
Test Loss:  0.0006701105739921331
Valid Loss:  0.0011398158967494965
Epoch:  177  	Training Loss: 0.0010548010468482971
Test Loss:  0.0006641585496254265
Valid Loss:  0.0011332440190017223
Epoch:  178  	Training Loss: 0.001047778408974409
Test Loss:  0.0006584868533536792
Valid Loss:  0.0011270479299128056
Epoch:  179  	Training Loss: 0.0010408961679786444
Test Loss:  0.0006529382080771029
Valid Loss:  0.001120932400226593
Epoch:  180  	Training Loss: 0.0010341277811676264
Test Loss:  0.0006476582493633032
Valid Loss:  0.0011149339843541384
Epoch:  181  	Training Loss: 0.0010274791857227683
Test Loss:  0.0006425542524084449
Valid Loss:  0.0011090926127508283
Epoch:  182  	Training Loss: 0.0010209569009020925
Test Loss:  0.0006382213323377073
Valid Loss:  0.0011038072407245636
Epoch:  183  	Training Loss: 0.0010175365023314953
Test Loss:  0.0006346841109916568
Valid Loss:  0.0011000792728736997
Epoch:  184  	Training Loss: 0.001014474779367447
Test Loss:  0.0006315116188488901
Valid Loss:  0.0010968463029712439
Epoch:  185  	Training Loss: 0.0010115595068782568
Test Loss:  0.0006285764975473285
Valid Loss:  0.001093745231628418
Epoch:  186  	Training Loss: 0.0010087679838761687
Test Loss:  0.0006259108777157962
Valid Loss:  0.001090833218768239
Epoch:  187  	Training Loss: 0.0010061729699373245
Test Loss:  0.0006234046304598451
Valid Loss:  0.0010880996705964208
Epoch:  188  	Training Loss: 0.0010037245228886604
Test Loss:  0.0006209915154613554
Valid Loss:  0.0010854798601940274
Epoch:  189  	Training Loss: 0.0010013687424361706
Test Loss:  0.0006186978425830603
Valid Loss:  0.001082980539649725
Epoch:  190  	Training Loss: 0.0009990944527089596
Test Loss:  0.0006165343802422285
Valid Loss:  0.0010805828496813774
Epoch:  191  	Training Loss: 0.0009968969970941544
Test Loss:  0.000614456832408905
Valid Loss:  0.0010782764293253422
Epoch:  192  	Training Loss: 0.0009947678772732615
Test Loss:  0.0006127692759037018
Valid Loss:  0.0010754010872915387
Epoch:  193  	Training Loss: 0.0009930450469255447
Test Loss:  0.000610874209087342
Valid Loss:  0.0010716067627072334
Epoch:  194  	Training Loss: 0.000991624896414578
Test Loss:  0.0006096205324865878
Valid Loss:  0.001069242018274963
Epoch:  195  	Training Loss: 0.0009902962483465672
Test Loss:  0.0006081871688365936
Valid Loss:  0.001066428842023015
Epoch:  196  	Training Loss: 0.0009889390785247087
Test Loss:  0.0006067994982004166
Valid Loss:  0.0010635685175657272
Epoch:  197  	Training Loss: 0.0009876730618998408
Test Loss:  0.0006055321427993476
Valid Loss:  0.0010608334559947252
Epoch:  198  	Training Loss: 0.000986544881016016
Test Loss:  0.0006046140915714204
Valid Loss:  0.0010587354190647602
Epoch:  199  	Training Loss: 0.0009855306707322598
Test Loss:  0.0006036355625838041
Valid Loss:  0.0010564143303781748
Epoch:  200  	Training Loss: 0.0009845595341175795
Test Loss:  0.0006026823539286852
Valid Loss:  0.0010541388764977455
Epoch:  201  	Training Loss: 0.000983639620244503
Test Loss:  0.0006019891588948667
Valid Loss:  0.0010524429380893707
Epoch:  202  	Training Loss: 0.000982768600806594
Test Loss:  0.0006017363630235195
Valid Loss:  0.0010535451583564281
Epoch:  203  	Training Loss: 0.0009791621705517173
Test Loss:  0.0006005406612530351
Valid Loss:  0.001052084844559431
Epoch:  204  	Training Loss: 0.0009760067914612591
Test Loss:  0.0005993202794343233
Valid Loss:  0.0010505127720534801
Epoch:  205  	Training Loss: 0.0009731014724820852
Test Loss:  0.00059812719700858
Valid Loss:  0.0010489469859749079
Epoch:  206  	Training Loss: 0.000970339635387063
Test Loss:  0.0005969766061753035
Valid Loss:  0.0010473437141627073
 41%|████▏     | 207/500 [02:31<02:13,  2.20it/s] 42%|████▏     | 209/500 [02:31<01:38,  2.96it/s] 42%|████▏     | 211/500 [02:38<05:44,  1.19s/it] 43%|████▎     | 213/500 [02:38<04:05,  1.17it/s] 43%|████▎     | 215/500 [02:38<02:56,  1.62it/s] 43%|████▎     | 217/500 [02:38<02:08,  2.21it/s] 44%|████▍     | 219/500 [02:38<01:34,  2.97it/s] 44%|████▍     | 221/500 [02:45<05:32,  1.19s/it] 45%|████▍     | 223/500 [02:45<03:57,  1.17it/s] 45%|████▌     | 225/500 [02:45<02:50,  1.61it/s] 45%|████▌     | 227/500 [02:45<02:03,  2.20it/s] 46%|████▌     | 229/500 [02:45<01:31,  2.96it/s] 46%|████▌     | 231/500 [02:52<05:17,  1.18s/it] 47%|████▋     | 233/500 [02:52<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:52<02:43,  1.62it/s] 47%|████▋     | 237/500 [02:52<01:58,  2.21it/s] 48%|████▊     | 239/500 [02:52<01:27,  2.97it/s] 48%|████▊     | 241/500 [02:59<05:12,  1.21s/it] 49%|████▊     | 243/500 [02:59<03:42,  1.15it/s] 49%|████▉     | 245/500 [02:59<02:39,  1.59it/s] 49%|████▉     | 247/500 [02:59<01:56,  2.18it/s] 50%|████▉     | 249/500 [02:59<01:25,  2.94it/s] 50%|█████     | 251/500 [03:06<05:05,  1.23s/it] 51%|█████     | 253/500 [03:06<03:37,  1.14it/s] 51%|█████     | 255/500 [03:06<02:35,  1.57it/s] 51%|█████▏    | 257/500 [03:06<01:52,  2.15it/s] 52%|█████▏    | 259/500 [03:06<01:23,  2.90it/s] 52%|█████▏    | 261/500 [03:13<04:49,  1.21s/it] 53%|█████▎    | 263/500 [03:13<03:25,  1.15it/s] 53%|█████▎    | 265/500 [03:13<02:27,  1.59it/s] 53%|█████▎    | 267/500 [03:13<01:46,  2.18it/s] 54%|█████▍    | 269/500 [03:13<01:18,  2.94it/s] 54%|█████▍    | 271/500 [03:20<04:34,  1.20s/it] 55%|█████▍    | 273/500 [03:20<03:15,  1.16it/s]Epoch:  207  	Training Loss: 0.0009676872286945581
Test Loss:  0.0005957177490927279
Valid Loss:  0.0010455413721501827
Epoch:  208  	Training Loss: 0.0009651038562878966
Test Loss:  0.0005944404401816428
Valid Loss:  0.0010436445008963346
Epoch:  209  	Training Loss: 0.000962592544965446
Test Loss:  0.0005933414213359356
Valid Loss:  0.0010418748715892434
Epoch:  210  	Training Loss: 0.0009601754136383533
Test Loss:  0.0005920042749494314
Valid Loss:  0.0010395045392215252
Epoch:  211  	Training Loss: 0.0009579518809914589
Test Loss:  0.0005906223668716848
Valid Loss:  0.0010370903182774782
Epoch:  212  	Training Loss: 0.0009558375459164381
Test Loss:  0.0005882654222659767
Valid Loss:  0.0010380834573879838
Epoch:  213  	Training Loss: 0.0009512444958090782
Test Loss:  0.0005875551141798496
Valid Loss:  0.001037531765177846
Epoch:  214  	Training Loss: 0.000949335633777082
Test Loss:  0.000586802838370204
Valid Loss:  0.0010364789050072432
Epoch:  215  	Training Loss: 0.0009479565778747201
Test Loss:  0.0005860957899130881
Valid Loss:  0.0010352979879826307
Epoch:  216  	Training Loss: 0.0009468026692047715
Test Loss:  0.0005854000337421894
Valid Loss:  0.0010340968146920204
Epoch:  217  	Training Loss: 0.0009457900305278599
Test Loss:  0.0005847425200045109
Valid Loss:  0.0010330749209970236
Epoch:  218  	Training Loss: 0.0009448289638385177
Test Loss:  0.0005841863458044827
Valid Loss:  0.0010321233421564102
Epoch:  219  	Training Loss: 0.0009439364075660706
Test Loss:  0.0005836178315803409
Valid Loss:  0.0010310770012438297
Epoch:  220  	Training Loss: 0.0009431018843315542
Test Loss:  0.0005830727168358862
Valid Loss:  0.0010300383437424898
Epoch:  221  	Training Loss: 0.0009423191659152508
Test Loss:  0.0005824873223900795
Valid Loss:  0.0010289750061929226
Epoch:  222  	Training Loss: 0.0009415773674845695
Test Loss:  0.0005736016319133341
Valid Loss:  0.0010174451163038611
Epoch:  223  	Training Loss: 0.0009335417998954654
Test Loss:  0.0005664172931574285
Valid Loss:  0.0010081634391099215
Epoch:  224  	Training Loss: 0.0009262585081160069
Test Loss:  0.0005597799317911267
Valid Loss:  0.0009997233282774687
Epoch:  225  	Training Loss: 0.0009193544392473996
Test Loss:  0.0005534729571081698
Valid Loss:  0.0009917087154462934
Epoch:  226  	Training Loss: 0.000912708230316639
Test Loss:  0.0005476672668009996
Valid Loss:  0.000984366051852703
Epoch:  227  	Training Loss: 0.0009063787292689085
Test Loss:  0.0005421478417702019
Valid Loss:  0.0009774332866072655
Epoch:  228  	Training Loss: 0.0009002904407680035
Test Loss:  0.0005369632854126394
Valid Loss:  0.0009710054728202522
Epoch:  229  	Training Loss: 0.0008945538429543376
Test Loss:  0.0005320858908817172
Valid Loss:  0.0009648996056057513
Epoch:  230  	Training Loss: 0.0008890803437680006
Test Loss:  0.0005275102448649704
Valid Loss:  0.0009591702837496996
Epoch:  231  	Training Loss: 0.0008837689529173076
Test Loss:  0.0005231311661191285
Valid Loss:  0.0009536928264424205
Epoch:  232  	Training Loss: 0.0008786499965935946
Test Loss:  0.0005195193225517869
Valid Loss:  0.0009494497790001333
Epoch:  233  	Training Loss: 0.0008735245792195201
Test Loss:  0.0005155836115591228
Valid Loss:  0.0009441199363209307
Epoch:  234  	Training Loss: 0.0008685708744451404
Test Loss:  0.0005121344001963735
Valid Loss:  0.0009398697875440121
Epoch:  235  	Training Loss: 0.0008636896964162588
Test Loss:  0.000508264871314168
Valid Loss:  0.0009346592705696821
Epoch:  236  	Training Loss: 0.0008588932687416673
Test Loss:  0.000504904892295599
Valid Loss:  0.0009305296116508543
Epoch:  237  	Training Loss: 0.0008542243158444762
Test Loss:  0.0005011410685256124
Valid Loss:  0.0009254516335204244
Epoch:  238  	Training Loss: 0.0008495945949107409
Test Loss:  0.0004978211945854127
Valid Loss:  0.0009214073652401567
Epoch:  239  	Training Loss: 0.0008450035820715129
Test Loss:  0.0004941184888593853
Valid Loss:  0.0009164315997622907
Epoch:  240  	Training Loss: 0.0008404647815041244
Test Loss:  0.0004908778937533498
Valid Loss:  0.0009124455973505974
Epoch:  241  	Training Loss: 0.0008359845960512757
Test Loss:  0.00048740734928287566
Valid Loss:  0.000907567678950727
Epoch:  242  	Training Loss: 0.0008315487066283822
Test Loss:  0.00048016937216743827
Valid Loss:  0.0009020068682730198
Epoch:  243  	Training Loss: 0.0008170662331394851
Test Loss:  0.00047641544369980693
Valid Loss:  0.0008974511874839664
Epoch:  244  	Training Loss: 0.0008124023443087935
Test Loss:  0.00047331530367955565
Valid Loss:  0.0008939231629483402
Epoch:  245  	Training Loss: 0.0008080769330263138
Test Loss:  0.000470273254904896
Valid Loss:  0.0008904330898076296
Epoch:  246  	Training Loss: 0.0008038012310862541
Test Loss:  0.0004672564973589033
Valid Loss:  0.0008869229350239038
Epoch:  247  	Training Loss: 0.0007995806518010795
Test Loss:  0.0004642387793865055
Valid Loss:  0.0008833705214783549
Epoch:  248  	Training Loss: 0.0007954041939228773
Test Loss:  0.0004612529883161187
Valid Loss:  0.0008798241033218801
Epoch:  249  	Training Loss: 0.0007912712171673775
Test Loss:  0.00045828812289983034
Valid Loss:  0.0008762712823227048
Epoch:  250  	Training Loss: 0.0007871738635003567
Test Loss:  0.00045534735545516014
Valid Loss:  0.0008727164240553975
Epoch:  251  	Training Loss: 0.0007831164402887225
Test Loss:  0.00045241013867780566
Valid Loss:  0.000869111914653331
Epoch:  252  	Training Loss: 0.0007791969110257924
Test Loss:  0.00045011285692453384
Valid Loss:  0.0008667260990478098
Epoch:  253  	Training Loss: 0.0007755231345072389
Test Loss:  0.0004478384798858315
Valid Loss:  0.0008643458131700754
Epoch:  254  	Training Loss: 0.0007719227578490973
Test Loss:  0.00044555997010320425
Valid Loss:  0.0008619261789135635
Epoch:  255  	Training Loss: 0.0007683845469728112
Test Loss:  0.00044329100637696683
Valid Loss:  0.0008594984537921846
Epoch:  256  	Training Loss: 0.0007648990722373128
Test Loss:  0.00044103129766881466
Valid Loss:  0.0008570502395741642
Epoch:  257  	Training Loss: 0.0007614655187353492
Test Loss:  0.0004388341912999749
Valid Loss:  0.0008546709432266653
Epoch:  258  	Training Loss: 0.000758082140237093
Test Loss:  0.00043660952360369265
Valid Loss:  0.0008522061398252845
Epoch:  259  	Training Loss: 0.0007547431159764528
Test Loss:  0.0004343859036453068
Valid Loss:  0.0008497172966599464
Epoch:  260  	Training Loss: 0.0007514427998103201
Test Loss:  0.0004321688029449433
Valid Loss:  0.000847241492010653
Epoch:  261  	Training Loss: 0.0007481846259906888
Test Loss:  0.00042995758121833205
Valid Loss:  0.000844760681502521
Epoch:  262  	Training Loss: 0.0007449624827131629
Test Loss:  0.0004274135280866176
Valid Loss:  0.0008408882422372699
Epoch:  263  	Training Loss: 0.0007420702604576945
Test Loss:  0.000424960715463385
Valid Loss:  0.000837148807477206
Epoch:  264  	Training Loss: 0.0007392240222543478
Test Loss:  0.0004226079909130931
Valid Loss:  0.0008335737511515617
Epoch:  265  	Training Loss: 0.0007364117191173136
Test Loss:  0.0004203346325084567
Valid Loss:  0.0008301390334963799
Epoch:  266  	Training Loss: 0.0007336325361393392
Test Loss:  0.00041818327736109495
Valid Loss:  0.000826895353384316
Epoch:  267  	Training Loss: 0.000730882165953517
Test Loss:  0.0004160605603829026
Valid Loss:  0.0008236891590058804
Epoch:  268  	Training Loss: 0.0007281523430719972
Test Loss:  0.0004139789962209761
Valid Loss:  0.0008205578196793795
Epoch:  269  	Training Loss: 0.0007254410302266479
Test Loss:  0.0004119369259569794
Valid Loss:  0.0008174816030077636
Epoch:  270  	Training Loss: 0.0007227526511996984
Test Loss:  0.0004099312354810536
Valid Loss:  0.0008144561434164643
Epoch:  271  	Training Loss: 0.0007200841791927814
Test Loss:  0.0004079527861904353
Valid Loss:  0.000811473117209971
Epoch:  272  	Training Loss: 0.0007174338097684085
Test Loss:  0.00040673709008842707
Valid Loss:  0.0008076701196841896
Epoch:  273  	Training Loss: 0.0007170459721237421
Test Loss:  0.00040776602691039443
Valid Loss:  0.0008111386559903622
Epoch:  274  	Training Loss: 0.0007166588329710066
Test Loss:  0.000406755309086293
Valid Loss:  0.0008081351406872272
 55%|█████▌    | 275/500 [03:20<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:20<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:20<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:27<04:24,  1.21s/it] 57%|█████▋    | 283/500 [03:27<03:08,  1.15it/s] 57%|█████▋    | 285/500 [03:27<02:14,  1.60it/s] 57%|█████▋    | 287/500 [03:27<01:37,  2.18it/s] 58%|█████▊    | 289/500 [03:27<01:11,  2.94it/s] 58%|█████▊    | 291/500 [03:34<04:06,  1.18s/it] 59%|█████▊    | 293/500 [03:34<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:34<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:34<01:31,  2.23it/s] 60%|█████▉    | 299/500 [03:34<01:07,  2.99it/s] 60%|██████    | 301/500 [03:41<04:04,  1.23s/it] 61%|██████    | 303/500 [03:41<02:54,  1.13it/s] 61%|██████    | 305/500 [03:41<02:04,  1.57it/s] 61%|██████▏   | 307/500 [03:41<01:29,  2.14it/s] 62%|██████▏   | 309/500 [03:41<01:06,  2.89it/s] 62%|██████▏   | 311/500 [03:48<03:54,  1.24s/it] 63%|██████▎   | 313/500 [03:48<02:46,  1.12it/s] 63%|██████▎   | 315/500 [03:48<01:59,  1.55it/s] 63%|██████▎   | 317/500 [03:48<01:26,  2.12it/s] 64%|██████▍   | 319/500 [03:49<01:03,  2.85it/s] 64%|██████▍   | 321/500 [03:55<03:40,  1.23s/it] 65%|██████▍   | 323/500 [03:55<02:37,  1.13it/s] 65%|██████▌   | 325/500 [03:55<01:52,  1.55it/s] 65%|██████▌   | 327/500 [03:56<01:21,  2.11it/s] 66%|██████▌   | 329/500 [03:56<00:59,  2.85it/s] 66%|██████▌   | 331/500 [04:02<03:28,  1.23s/it] 67%|██████▋   | 333/500 [04:02<02:27,  1.13it/s] 67%|██████▋   | 335/500 [04:03<01:45,  1.56it/s] 67%|██████▋   | 337/500 [04:03<01:16,  2.14it/s] 68%|██████▊   | 339/500 [04:03<00:55,  2.88it/s] 68%|██████▊   | 341/500 [04:09<03:09,  1.19s/it]Epoch:  275  	Training Loss: 0.0007162978290580213
Test Loss:  0.00040743520366959274
Valid Loss:  0.0008104436565190554
Epoch:  276  	Training Loss: 0.0007159573724493384
Test Loss:  0.0004067584522999823
Valid Loss:  0.0008084236178547144
Epoch:  277  	Training Loss: 0.0007156369974836707
Test Loss:  0.0004071961739100516
Valid Loss:  0.0008099379483610392
Epoch:  278  	Training Loss: 0.0007153324550017715
Test Loss:  0.0004067314730491489
Valid Loss:  0.0008085805457085371
Epoch:  279  	Training Loss: 0.0007150350138545036
Test Loss:  0.00040700670797377825
Valid Loss:  0.0008095751982182264
Epoch:  280  	Training Loss: 0.0007147443247959018
Test Loss:  0.0004066805122420192
Valid Loss:  0.0008086507441475987
Epoch:  281  	Training Loss: 0.0007144578266888857
Test Loss:  0.0004068448324687779
Valid Loss:  0.000809295626822859
Epoch:  282  	Training Loss: 0.0007141754031181335
Test Loss:  0.00040560425259172916
Valid Loss:  0.000808428565505892
Epoch:  283  	Training Loss: 0.0007110704900696874
Test Loss:  0.0004036495229229331
Valid Loss:  0.000806141528300941
Epoch:  284  	Training Loss: 0.000708248931914568
Test Loss:  0.00040155212627723813
Valid Loss:  0.0008035868522711098
Epoch:  285  	Training Loss: 0.0007054690504446626
Test Loss:  0.00039945862954482436
Valid Loss:  0.000801019137725234
Epoch:  286  	Training Loss: 0.0007027218816801906
Test Loss:  0.000397382362280041
Valid Loss:  0.0007984691765159369
Epoch:  287  	Training Loss: 0.0006999997422099113
Test Loss:  0.00039533519884571433
Valid Loss:  0.0007959525100886822
Epoch:  288  	Training Loss: 0.0006973054260015488
Test Loss:  0.0003933041589334607
Valid Loss:  0.0007934611057862639
Epoch:  289  	Training Loss: 0.0006946387002244592
Test Loss:  0.0003913124091923237
Valid Loss:  0.0007910362910479307
Epoch:  290  	Training Loss: 0.0006919943261891603
Test Loss:  0.00038937380304560065
Valid Loss:  0.0007886691018939018
Epoch:  291  	Training Loss: 0.0006893737008795142
Test Loss:  0.00038747431244701147
Valid Loss:  0.0007863397477194667
Epoch:  292  	Training Loss: 0.0006867798510938883
Test Loss:  0.00038387568201869726
Valid Loss:  0.000780286907684058
Epoch:  293  	Training Loss: 0.0006837119581177831
Test Loss:  0.0003812113718595356
Valid Loss:  0.0007760502048768103
Epoch:  294  	Training Loss: 0.0006810493650846183
Test Loss:  0.00037894758861511946
Valid Loss:  0.000772677012719214
Epoch:  295  	Training Loss: 0.000678525713738054
Test Loss:  0.0003765984147321433
Valid Loss:  0.0007689975900575519
Epoch:  296  	Training Loss: 0.0006759492098353803
Test Loss:  0.00037446431815624237
Valid Loss:  0.0007657771930098534
Epoch:  297  	Training Loss: 0.0006735335919074714
Test Loss:  0.0003723700065165758
Valid Loss:  0.0007625345606356859
Epoch:  298  	Training Loss: 0.0006711909081786871
Test Loss:  0.00037052598781883717
Valid Loss:  0.0007599464734084904
Epoch:  299  	Training Loss: 0.0006688849534839392
Test Loss:  0.0003686252748593688
Valid Loss:  0.0007570982561446726
Epoch:  300  	Training Loss: 0.0006665517576038837
Test Loss:  0.0003667371638584882
Valid Loss:  0.0007542083039879799
Epoch:  301  	Training Loss: 0.0006643697270192206
Test Loss:  0.0003651292063295841
Valid Loss:  0.0007520198123529553
Epoch:  302  	Training Loss: 0.0006622320506721735
Test Loss:  0.0003623279626481235
Valid Loss:  0.000747343641705811
Epoch:  303  	Training Loss: 0.000659432087559253
Test Loss:  0.00035999243846163154
Valid Loss:  0.000743615091778338
Epoch:  304  	Training Loss: 0.0006569120450876653
Test Loss:  0.0003578531905077398
Valid Loss:  0.000740226823836565
Epoch:  305  	Training Loss: 0.0006545663927681744
Test Loss:  0.0003559153410606086
Valid Loss:  0.0007371501997113228
Epoch:  306  	Training Loss: 0.0006523557240143418
Test Loss:  0.00035412004217505455
Valid Loss:  0.0007343948818743229
Epoch:  307  	Training Loss: 0.0006502524483948946
Test Loss:  0.0003524371131788939
Valid Loss:  0.000731891777832061
Epoch:  308  	Training Loss: 0.0006482246681116521
Test Loss:  0.000350874790456146
Valid Loss:  0.0007296245312318206
Epoch:  309  	Training Loss: 0.0006462806486524642
Test Loss:  0.0003493735275696963
Valid Loss:  0.000727513455785811
Epoch:  310  	Training Loss: 0.0006443771417252719
Test Loss:  0.0003479314036667347
Valid Loss:  0.0007255318341776729
Epoch:  311  	Training Loss: 0.0006425216561183333
Test Loss:  0.00034656698699109256
Valid Loss:  0.0007236828678287566
Epoch:  312  	Training Loss: 0.0006407260661944747
Test Loss:  0.00034585443791002035
Valid Loss:  0.0007246906170621514
Epoch:  313  	Training Loss: 0.000637267017737031
Test Loss:  0.0003448565839789808
Valid Loss:  0.0007244365988299251
Epoch:  314  	Training Loss: 0.0006345781730487943
Test Loss:  0.0003436858532950282
Valid Loss:  0.0007236168021336198
Epoch:  315  	Training Loss: 0.0006321155233308673
Test Loss:  0.0003424635506235063
Valid Loss:  0.000722552533261478
Epoch:  316  	Training Loss: 0.0006297749932855368
Test Loss:  0.0003412632504478097
Valid Loss:  0.0007213883800432086
Epoch:  317  	Training Loss: 0.0006275317864492536
Test Loss:  0.00034008180955424905
Valid Loss:  0.0007201784756034613
Epoch:  318  	Training Loss: 0.0006253671017475426
Test Loss:  0.00033892152714543045
Valid Loss:  0.0007189452298916876
Epoch:  319  	Training Loss: 0.000623268831986934
Test Loss:  0.00033778208307921886
Valid Loss:  0.0007176954532042146
Epoch:  320  	Training Loss: 0.0006212331354618073
Test Loss:  0.00033665058435872197
Valid Loss:  0.0007164184935390949
Epoch:  321  	Training Loss: 0.000619244237896055
Test Loss:  0.00033552886452525854
Valid Loss:  0.0007151211611926556
Epoch:  322  	Training Loss: 0.0006172973080538213
Test Loss:  0.00033452571369707584
Valid Loss:  0.0007129794685170054
Epoch:  323  	Training Loss: 0.0006164378137327731
Test Loss:  0.0003336041118018329
Valid Loss:  0.0007110083242878318
Epoch:  324  	Training Loss: 0.00061563472263515
Test Loss:  0.00033275672467425466
Valid Loss:  0.0007091841544024646
Epoch:  325  	Training Loss: 0.0006148769753053784
Test Loss:  0.00033197973971255124
Valid Loss:  0.0007074903696775436
Epoch:  326  	Training Loss: 0.0006141565972939134
Test Loss:  0.00033125519985333085
Valid Loss:  0.0007059115450829268
Epoch:  327  	Training Loss: 0.0006134673021733761
Test Loss:  0.0003305771970190108
Valid Loss:  0.0007044401718303561
Epoch:  328  	Training Loss: 0.0006128074019216001
Test Loss:  0.0003299422678537667
Valid Loss:  0.0007030657725408673
Epoch:  329  	Training Loss: 0.0006121702026575804
Test Loss:  0.00032934144837781787
Valid Loss:  0.0007017740863375366
Epoch:  330  	Training Loss: 0.0006115508731454611
Test Loss:  0.00032877171179279685
Valid Loss:  0.0007005722145549953
Epoch:  331  	Training Loss: 0.0006109477253630757
Test Loss:  0.00032823107903823256
Valid Loss:  0.0006994374562054873
Epoch:  332  	Training Loss: 0.0006103568593971431
Test Loss:  0.000327215064316988
Valid Loss:  0.0006986039807088673
Epoch:  333  	Training Loss: 0.0006073356489650905
Test Loss:  0.00032561871921643615
Valid Loss:  0.0006964345229789615
Epoch:  334  	Training Loss: 0.0006045104237273335
Test Loss:  0.000324095890391618
Valid Loss:  0.0006942442269064486
Epoch:  335  	Training Loss: 0.0006017740815877914
Test Loss:  0.0003225306863896549
Valid Loss:  0.0006918717408552766
Epoch:  336  	Training Loss: 0.0005991053767502308
Test Loss:  0.00032096030190587044
Valid Loss:  0.000689392676576972
Epoch:  337  	Training Loss: 0.0005964752053841949
Test Loss:  0.0003193699521943927
Valid Loss:  0.0006868071504868567
Epoch:  338  	Training Loss: 0.0005938832182437181
Test Loss:  0.000317758705932647
Valid Loss:  0.0006841516587883234
Epoch:  339  	Training Loss: 0.0005913187633268535
Test Loss:  0.00031616914202459157
Valid Loss:  0.0006814749212935567
Epoch:  340  	Training Loss: 0.000588785158470273
Test Loss:  0.0003145574009977281
Valid Loss:  0.0006787056336179376
Epoch:  341  	Training Loss: 0.0005862953839823604
Test Loss:  0.0003129746182821691
Valid Loss:  0.0006759821553714573
Epoch:  342  	Training Loss: 0.0005838206270709634
Test Loss:  0.00031235761707648635
Valid Loss:  0.0006744499551132321
 69%|██████▊   | 343/500 [04:09<02:14,  1.17it/s] 69%|██████▉   | 345/500 [04:09<01:36,  1.61it/s] 69%|██████▉   | 347/500 [04:10<01:09,  2.21it/s] 70%|██████▉   | 349/500 [04:10<00:50,  2.97it/s] 70%|███████   | 351/500 [04:16<02:57,  1.19s/it] 71%|███████   | 353/500 [04:16<02:06,  1.17it/s] 71%|███████   | 355/500 [04:16<01:29,  1.61it/s] 71%|███████▏  | 357/500 [04:16<01:04,  2.20it/s] 72%|███████▏  | 359/500 [04:17<00:47,  2.96it/s] 72%|███████▏  | 361/500 [04:23<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:23<01:57,  1.17it/s] 73%|███████▎  | 365/500 [04:23<01:23,  1.61it/s] 73%|███████▎  | 367/500 [04:23<01:00,  2.21it/s] 74%|███████▍  | 369/500 [04:24<00:44,  2.97it/s] 74%|███████▍  | 371/500 [04:30<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:30<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:30<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:30<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:30<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:37<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:37<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:37<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:37<00:51,  2.20it/s] 78%|███████▊  | 389/500 [04:37<00:37,  2.96it/s] 78%|███████▊  | 391/500 [04:44<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:44<01:31,  1.16it/s] 79%|███████▉  | 395/500 [04:44<01:05,  1.61it/s] 79%|███████▉  | 397/500 [04:44<00:47,  2.19it/s] 80%|███████▉  | 399/500 [04:44<00:34,  2.95it/s] 80%|████████  | 401/500 [04:51<01:57,  1.19s/it] 81%|████████  | 403/500 [04:51<01:23,  1.17it/s] 81%|████████  | 405/500 [04:51<00:59,  1.60it/s] 81%|████████▏ | 407/500 [04:51<00:42,  2.18it/s] 82%|████████▏ | 409/500 [04:51<00:31,  2.93it/s]Epoch:  343  	Training Loss: 0.00058250583242625
Test Loss:  0.00031155088800005615
Valid Loss:  0.0006725586717948318
Epoch:  344  	Training Loss: 0.0005812256131321192
Test Loss:  0.00031074631260707974
Valid Loss:  0.0006706705316901207
Epoch:  345  	Training Loss: 0.000579965824726969
Test Loss:  0.0003099533496424556
Valid Loss:  0.0006687999120913446
Epoch:  346  	Training Loss: 0.0005787255358882248
Test Loss:  0.0003091716207563877
Valid Loss:  0.0006669322028756142
Epoch:  347  	Training Loss: 0.0005775063182227314
Test Loss:  0.00030840077670291066
Valid Loss:  0.0006650788127444685
Epoch:  348  	Training Loss: 0.000576306483708322
Test Loss:  0.00030764195253141224
Valid Loss:  0.0006632390432059765
Epoch:  349  	Training Loss: 0.0005751262651756406
Test Loss:  0.00030690114363096654
Valid Loss:  0.0006614209851250052
Epoch:  350  	Training Loss: 0.0005739690968766809
Test Loss:  0.00030618131859228015
Valid Loss:  0.0006596171879209578
Epoch:  351  	Training Loss: 0.0005728324176743627
Test Loss:  0.00030547782080248
Valid Loss:  0.0006578364409506321
Epoch:  352  	Training Loss: 0.000571716227568686
Test Loss:  0.00030329026049003005
Valid Loss:  0.0006546346703544259
Epoch:  353  	Training Loss: 0.0005694726714864373
Test Loss:  0.00030154926935210824
Valid Loss:  0.0006521299947053194
Epoch:  354  	Training Loss: 0.0005674355197697878
Test Loss:  0.00029997804085724056
Valid Loss:  0.0006499189184978604
Epoch:  355  	Training Loss: 0.0005654827691614628
Test Loss:  0.00029851432191208005
Valid Loss:  0.0006478858995251358
Epoch:  356  	Training Loss: 0.0005635800189338624
Test Loss:  0.00029711658135056496
Valid Loss:  0.0006459606811404228
Epoch:  357  	Training Loss: 0.0005617184215225279
Test Loss:  0.0002957604010589421
Valid Loss:  0.0006440904689952731
Epoch:  358  	Training Loss: 0.0005599349969998002
Test Loss:  0.00029445620020851493
Valid Loss:  0.0006422847509384155
Epoch:  359  	Training Loss: 0.0005582001758739352
Test Loss:  0.0002931940834969282
Valid Loss:  0.0006405487074516714
Epoch:  360  	Training Loss: 0.0005565137835219502
Test Loss:  0.0002919725957326591
Valid Loss:  0.0006389056798070669
Epoch:  361  	Training Loss: 0.0005548584740608931
Test Loss:  0.0002908082096837461
Valid Loss:  0.0006372983334586024
Epoch:  362  	Training Loss: 0.0005532648065127432
Test Loss:  0.0002904935390688479
Valid Loss:  0.0006368664908222854
Epoch:  363  	Training Loss: 0.0005517170066013932
Test Loss:  0.00028964466764591634
Valid Loss:  0.0006352447671815753
Epoch:  364  	Training Loss: 0.0005502734566107392
Test Loss:  0.0002888772578444332
Valid Loss:  0.0006337161175906658
Epoch:  365  	Training Loss: 0.0005488669266924262
Test Loss:  0.0002881150576286018
Valid Loss:  0.0006321222172118723
Epoch:  366  	Training Loss: 0.0005474931676872075
Test Loss:  0.00028736385866068304
Valid Loss:  0.0006304948474280536
Epoch:  367  	Training Loss: 0.0005461532273329794
Test Loss:  0.00028660940006375313
Valid Loss:  0.0006288352888077497
Epoch:  368  	Training Loss: 0.0005448319716379046
Test Loss:  0.0002858579973690212
Valid Loss:  0.0006271600723266602
Epoch:  369  	Training Loss: 0.0005435284692794085
Test Loss:  0.0002851130848284811
Valid Loss:  0.0006254726904444396
Epoch:  370  	Training Loss: 0.0005422420799732208
Test Loss:  0.00028436980210244656
Valid Loss:  0.0006237750058062375
Epoch:  371  	Training Loss: 0.0005409714067354798
Test Loss:  0.00028362765442579985
Valid Loss:  0.0006220731884241104
Epoch:  372  	Training Loss: 0.00053971610032022
Test Loss:  0.00028282415587455034
Valid Loss:  0.0006210556020960212
Epoch:  373  	Training Loss: 0.0005379391368478537
Test Loss:  0.0002818556677084416
Valid Loss:  0.0006196050671860576
Epoch:  374  	Training Loss: 0.0005362525698728859
Test Loss:  0.00028085894882678986
Valid Loss:  0.0006180881755426526
Epoch:  375  	Training Loss: 0.0005345962126739323
Test Loss:  0.00027986190980300307
Valid Loss:  0.000616532692220062
Epoch:  376  	Training Loss: 0.0005329682026058435
Test Loss:  0.00027886300813406706
Valid Loss:  0.0006149481050670147
Epoch:  377  	Training Loss: 0.0005313575966283679
Test Loss:  0.0002778744383249432
Valid Loss:  0.0006133533315733075
Epoch:  378  	Training Loss: 0.0005297858733683825
Test Loss:  0.00027695196331478655
Valid Loss:  0.0006120751495473087
Epoch:  379  	Training Loss: 0.0005283113569021225
Test Loss:  0.0002760346105787903
Valid Loss:  0.0006105519714765251
Epoch:  380  	Training Loss: 0.0005268084350973368
Test Loss:  0.0002752004365902394
Valid Loss:  0.0006095584249123931
Epoch:  381  	Training Loss: 0.0005254345014691353
Test Loss:  0.0002743470831774175
Valid Loss:  0.0006080701714381576
Epoch:  382  	Training Loss: 0.0005239196470938623
Test Loss:  0.00027390645118430257
Valid Loss:  0.0006071417592465878
Epoch:  383  	Training Loss: 0.0005232732510194182
Test Loss:  0.0002735189045779407
Valid Loss:  0.0006065444904379547
Epoch:  384  	Training Loss: 0.0005226992652751505
Test Loss:  0.000273084151558578
Valid Loss:  0.0006056408165022731
Epoch:  385  	Training Loss: 0.0005221246974542737
Test Loss:  0.00027278848574496806
Valid Loss:  0.000605529872700572
Epoch:  386  	Training Loss: 0.0005216395948082209
Test Loss:  0.00027237244648858905
Valid Loss:  0.0006046474445611238
Epoch:  387  	Training Loss: 0.0005209877854213119
Test Loss:  0.000271952070761472
Valid Loss:  0.0006037644925527275
Epoch:  388  	Training Loss: 0.0005203532637096941
Test Loss:  0.00027153128758072853
Valid Loss:  0.0006028895732015371
Epoch:  389  	Training Loss: 0.000519762106705457
Test Loss:  0.0002712043351493776
Valid Loss:  0.0006026353221386671
Epoch:  390  	Training Loss: 0.000519280438311398
Test Loss:  0.00027080916333943605
Valid Loss:  0.0006017911364324391
Epoch:  391  	Training Loss: 0.0005186549969948828
Test Loss:  0.000270409625954926
Valid Loss:  0.000600949046202004
Epoch:  392  	Training Loss: 0.0005180412554182112
Test Loss:  0.0002685653744265437
Valid Loss:  0.000597948266658932
Epoch:  393  	Training Loss: 0.0005161082372069359
Test Loss:  0.00026731574325822294
Valid Loss:  0.0005965727614238858
Epoch:  394  	Training Loss: 0.0005143683520145714
Test Loss:  0.0002660952159203589
Valid Loss:  0.0005947881727479398
Epoch:  395  	Training Loss: 0.0005124571616761386
Test Loss:  0.0002648147055879235
Valid Loss:  0.0005928438622504473
Epoch:  396  	Training Loss: 0.000510584912262857
Test Loss:  0.0002635459532029927
Valid Loss:  0.0005909587489441037
Epoch:  397  	Training Loss: 0.0005089252954348922
Test Loss:  0.00026248834910802543
Valid Loss:  0.0005899741081520915
Epoch:  398  	Training Loss: 0.0005072104977443814
Test Loss:  0.0002613906399346888
Valid Loss:  0.0005883638514205813
Epoch:  399  	Training Loss: 0.000505372416228056
Test Loss:  0.00026019924553111196
Valid Loss:  0.0005865234415978193
Epoch:  400  	Training Loss: 0.0005035740323364735
Test Loss:  0.0002590091316960752
Valid Loss:  0.0005846717394888401
Epoch:  401  	Training Loss: 0.0005018943338654935
Test Loss:  0.0002579755091574043
Valid Loss:  0.0005836274940520525
Epoch:  402  	Training Loss: 0.0005002894904464483
Test Loss:  0.0002578883431851864
Valid Loss:  0.0005832327296957374
Epoch:  403  	Training Loss: 0.0005001139361411333
Test Loss:  0.00025780071155168116
Valid Loss:  0.0005828370922245085
Epoch:  404  	Training Loss: 0.0004999521188437939
Test Loss:  0.00025771241053007543
Valid Loss:  0.0005824411637149751
Epoch:  405  	Training Loss: 0.0004997989744879305
Test Loss:  0.0002576233528088778
Valid Loss:  0.00058204639935866
Epoch:  406  	Training Loss: 0.0004996531060896814
Test Loss:  0.000257532432442531
Valid Loss:  0.0005816538468934596
Epoch:  407  	Training Loss: 0.0004995120689272881
Test Loss:  0.0002574402606114745
Valid Loss:  0.0005812649615108967
Epoch:  408  	Training Loss: 0.0004993753391318023
Test Loss:  0.00025734686641953886
Valid Loss:  0.0005808789865113795
Epoch:  409  	Training Loss: 0.000499242334626615
Test Loss:  0.000257253588642925
Valid Loss:  0.0005804953398182988
Epoch:  410  	Training Loss: 0.0004991124151274562
Test Loss:  0.00025715999072417617
Valid Loss:  0.0005801190854981542
 82%|████████▏ | 411/500 [04:58<01:46,  1.20s/it] 83%|████████▎ | 413/500 [04:58<01:14,  1.16it/s] 83%|████████▎ | 415/500 [04:58<00:52,  1.61it/s] 83%|████████▎ | 417/500 [04:58<00:37,  2.20it/s] 84%|████████▍ | 419/500 [04:58<00:27,  2.96it/s] 84%|████████▍ | 421/500 [05:05<01:34,  1.20s/it] 85%|████████▍ | 423/500 [05:05<01:06,  1.16it/s] 85%|████████▌ | 425/500 [05:05<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:05<00:33,  2.20it/s] 86%|████████▌ | 429/500 [05:05<00:24,  2.95it/s] 86%|████████▌ | 431/500 [05:12<01:23,  1.20s/it] 87%|████████▋ | 433/500 [05:12<00:58,  1.15it/s] 87%|████████▋ | 435/500 [05:12<00:40,  1.59it/s] 87%|████████▋ | 437/500 [05:12<00:28,  2.18it/s] 88%|████████▊ | 439/500 [05:12<00:20,  2.93it/s] 88%|████████▊ | 441/500 [05:18<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:18<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:19<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:19<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:19<00:17,  2.99it/s] 90%|█████████ | 451/500 [05:25<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:25<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:26<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:26<00:19,  2.22it/s] 92%|█████████▏| 459/500 [05:26<00:13,  2.98it/s] 92%|█████████▏| 461/500 [05:32<00:45,  1.18s/it] 93%|█████████▎| 463/500 [05:32<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:32<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:32<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:33<00:10,  3.00it/s] 94%|█████████▍| 471/500 [05:39<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:39<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:39<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:39<00:10,  2.25it/s]Epoch:  411  	Training Loss: 0.0004989848821423948
Test Loss:  0.00025706770247779787
Valid Loss:  0.0005797456833533943
Epoch:  412  	Training Loss: 0.0004988596774637699
Test Loss:  0.00025685623404569924
Valid Loss:  0.000579316692892462
Epoch:  413  	Training Loss: 0.0004986575804650784
Test Loss:  0.00025666900910437107
Valid Loss:  0.0005789360729977489
Epoch:  414  	Training Loss: 0.0004984625848010182
Test Loss:  0.00025649904273450375
Valid Loss:  0.000578591600060463
Epoch:  415  	Training Loss: 0.0004982718965038657
Test Loss:  0.0002563424641266465
Valid Loss:  0.000578274775762111
Epoch:  416  	Training Loss: 0.000498084060382098
Test Loss:  0.00025619534426368773
Valid Loss:  0.000577978091314435
Epoch:  417  	Training Loss: 0.000497897737659514
Test Loss:  0.000256054918281734
Valid Loss:  0.0005776971811428666
Epoch:  418  	Training Loss: 0.0004977129865437746
Test Loss:  0.00025592034216970205
Valid Loss:  0.0005774297751486301
Epoch:  419  	Training Loss: 0.0004975283518433571
Test Loss:  0.0002557904226705432
Valid Loss:  0.0005771712167188525
Epoch:  420  	Training Loss: 0.0004973448230884969
Test Loss:  0.00025566379190422595
Valid Loss:  0.0005769199342466891
Epoch:  421  	Training Loss: 0.0004971613525412977
Test Loss:  0.0002555394603405148
Valid Loss:  0.0005766742979176342
Epoch:  422  	Training Loss: 0.0004969785804860294
Test Loss:  0.0002553036028984934
Valid Loss:  0.0005766152171418071
Epoch:  423  	Training Loss: 0.0004954413743689656
Test Loss:  0.0002548100892454386
Valid Loss:  0.0005759894265793264
Epoch:  424  	Training Loss: 0.000494125357363373
Test Loss:  0.0002541623543947935
Valid Loss:  0.0005750710843130946
Epoch:  425  	Training Loss: 0.0004928529961034656
Test Loss:  0.00025344634195789695
Valid Loss:  0.0005740196211263537
Epoch:  426  	Training Loss: 0.0004915931494906545
Test Loss:  0.0002527040778659284
Valid Loss:  0.0005729052936658263
Epoch:  427  	Training Loss: 0.0004903421504423022
Test Loss:  0.0002519515692256391
Valid Loss:  0.0005717576714232564
Epoch:  428  	Training Loss: 0.0004890987765975296
Test Loss:  0.00025119539350271225
Valid Loss:  0.000570590200368315
Epoch:  429  	Training Loss: 0.00048786273691803217
Test Loss:  0.0002504417789168656
Valid Loss:  0.0005694156279787421
Epoch:  430  	Training Loss: 0.0004866322560701519
Test Loss:  0.00024968382786028087
Valid Loss:  0.0005682227201759815
Epoch:  431  	Training Loss: 0.00048540616990067065
Test Loss:  0.00024893187219277024
Valid Loss:  0.0005670328973792493
Epoch:  432  	Training Loss: 0.000484186050016433
Test Loss:  0.0002477538655512035
Valid Loss:  0.0005645857308991253
Epoch:  433  	Training Loss: 0.0004832460545003414
Test Loss:  0.0002472688793204725
Valid Loss:  0.0005634829867631197
Epoch:  434  	Training Loss: 0.00048245314974337816
Test Loss:  0.0002468366001266986
Valid Loss:  0.0005624862387776375
Epoch:  435  	Training Loss: 0.00048166720080189407
Test Loss:  0.0002464253921061754
Valid Loss:  0.000561633612960577
Epoch:  436  	Training Loss: 0.00048094254452735186
Test Loss:  0.0002460703835822642
Valid Loss:  0.0005609869258478284
Epoch:  437  	Training Loss: 0.00048024056013673544
Test Loss:  0.0002457022783346474
Valid Loss:  0.0005600886652246118
Epoch:  438  	Training Loss: 0.0004795653803739697
Test Loss:  0.0002454101631883532
Valid Loss:  0.0005599303403869271
Epoch:  439  	Training Loss: 0.00047898595221340656
Test Loss:  0.0002451321925036609
Valid Loss:  0.0005592057714238763
Epoch:  440  	Training Loss: 0.00047819677274674177
Test Loss:  0.00024469103664159775
Valid Loss:  0.0005580995930358768
Epoch:  441  	Training Loss: 0.0004774301196448505
Test Loss:  0.0002442362892907113
Valid Loss:  0.0005569608183577657
Epoch:  442  	Training Loss: 0.00047674382221885026
Test Loss:  0.0002448632149025798
Valid Loss:  0.0005585417384281754
Epoch:  443  	Training Loss: 0.00047635057126171887
Test Loss:  0.00024513955577276647
Valid Loss:  0.0005587255000136793
Epoch:  444  	Training Loss: 0.00047605205327272415
Test Loss:  0.0002451898471917957
Valid Loss:  0.0005584824830293655
Epoch:  445  	Training Loss: 0.0004758387804031372
Test Loss:  0.00024513405514881015
Valid Loss:  0.000558066472876817
Epoch:  446  	Training Loss: 0.00047566197463311255
Test Loss:  0.0002450380125083029
Valid Loss:  0.0005579815478995442
Epoch:  447  	Training Loss: 0.00047554686898365617
Test Loss:  0.00024498318089172244
Valid Loss:  0.0005575629766099155
Epoch:  448  	Training Loss: 0.0004753548128064722
Test Loss:  0.00024489202769473195
Valid Loss:  0.0005571017973124981
Epoch:  449  	Training Loss: 0.0004751719534397125
Test Loss:  0.00024478707928210497
Valid Loss:  0.0005566338077187538
Epoch:  450  	Training Loss: 0.0004750532389152795
Test Loss:  0.000244657916482538
Valid Loss:  0.0005566563922911882
Epoch:  451  	Training Loss: 0.00047493044985458255
Test Loss:  0.00024462013971060514
Valid Loss:  0.000556282524485141
Epoch:  452  	Training Loss: 0.0004747477360069752
Test Loss:  0.0002422821125946939
Valid Loss:  0.0005525488522835076
Epoch:  453  	Training Loss: 0.0004726775223389268
Test Loss:  0.00024097113055177033
Valid Loss:  0.0005506121669895947
Epoch:  454  	Training Loss: 0.00047094799811020494
Test Loss:  0.00023985013831406832
Valid Loss:  0.0005490383482538164
Epoch:  455  	Training Loss: 0.00046925252536311746
Test Loss:  0.00023878343927208334
Valid Loss:  0.0005475543439388275
Epoch:  456  	Training Loss: 0.0004675760865211487
Test Loss:  0.00023774159490130842
Valid Loss:  0.0005461013643071055
Epoch:  457  	Training Loss: 0.00046591792488470674
Test Loss:  0.00023671600501984358
Valid Loss:  0.000544662238098681
Epoch:  458  	Training Loss: 0.00046427646884694695
Test Loss:  0.00023570533085148782
Valid Loss:  0.0005432370817288756
Epoch:  459  	Training Loss: 0.0004626508161891252
Test Loss:  0.00023470901942346245
Valid Loss:  0.0005418233340606093
Epoch:  460  	Training Loss: 0.00046103974455036223
Test Loss:  0.00023371890711132437
Valid Loss:  0.0005404200637713075
Epoch:  461  	Training Loss: 0.0004594421188812703
Test Loss:  0.00023274215345736593
Valid Loss:  0.0005390289006754756
Epoch:  462  	Training Loss: 0.0004578591324388981
Test Loss:  0.0002315088058821857
Valid Loss:  0.0005369529244489968
Epoch:  463  	Training Loss: 0.0004562968679238111
Test Loss:  0.00023044724366627634
Valid Loss:  0.0005352326552383602
Epoch:  464  	Training Loss: 0.00045478076208382845
Test Loss:  0.00022944672673474997
Valid Loss:  0.0005336352623999119
Epoch:  465  	Training Loss: 0.000453290092991665
Test Loss:  0.0002284772926941514
Valid Loss:  0.000532100850250572
Epoch:  466  	Training Loss: 0.0004518144705798477
Test Loss:  0.00022754110977984965
Valid Loss:  0.0005306150997057557
Epoch:  467  	Training Loss: 0.0004503615782596171
Test Loss:  0.00022663433628622442
Valid Loss:  0.0005291702109389007
Epoch:  468  	Training Loss: 0.000448931532446295
Test Loss:  0.00022575062757823616
Valid Loss:  0.0005277699092403054
Epoch:  469  	Training Loss: 0.0004475270106922835
Test Loss:  0.00022488871763926
Valid Loss:  0.0005264076171442866
Epoch:  470  	Training Loss: 0.0004461485368665308
Test Loss:  0.00022404579794965684
Valid Loss:  0.0005250838585197926
Epoch:  471  	Training Loss: 0.0004447897954378277
Test Loss:  0.00022321574215311557
Valid Loss:  0.0005237932782620192
Epoch:  472  	Training Loss: 0.00044344717753119767
Test Loss:  0.0002225545176770538
Valid Loss:  0.0005224621272645891
Epoch:  473  	Training Loss: 0.000442447024397552
Test Loss:  0.00022191909374669194
Valid Loss:  0.0005211936659179628
Epoch:  474  	Training Loss: 0.00044146605068817735
Test Loss:  0.00022130380966700613
Valid Loss:  0.0005199785809963942
Epoch:  475  	Training Loss: 0.00044050399446859956
Test Loss:  0.00022070515842642635
Valid Loss:  0.0005188063369132578
Epoch:  476  	Training Loss: 0.0004395623109303415
Test Loss:  0.00022012177214492112
Valid Loss:  0.000517670763656497
Epoch:  477  	Training Loss: 0.00043864076724275947
Test Loss:  0.00021955397096462548
Valid Loss:  0.0005165785551071167
Epoch:  478  	Training Loss: 0.0004377320874482393
Test Loss:  0.00021899881539866328
Valid Loss:   96%|█████████▌| 479/500 [05:39<00:06,  3.02it/s] 96%|█████████▌| 481/500 [05:46<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:46<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:46<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:46<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:46<00:03,  2.98it/s] 98%|█████████▊| 491/500 [05:52<00:10,  1.16s/it] 99%|█████████▊| 493/500 [05:53<00:05,  1.20it/s] 99%|█████████▉| 495/500 [05:53<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:53<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:53<00:00,  3.01it/s]100%|██████████| 500/500 [05:53<00:00,  1.41it/s]
0.0005155194085091352
Epoch:  479  	Training Loss: 0.0004368408117443323
Test Loss:  0.0002184568002121523
Valid Loss:  0.0005145077593624592
Epoch:  480  	Training Loss: 0.00043595972238108516
Test Loss:  0.00021792420011479408
Valid Loss:  0.000513520382810384
Epoch:  481  	Training Loss: 0.00043509603710845113
Test Loss:  0.00021741408272646368
Valid Loss:  0.0005125579191371799
Epoch:  482  	Training Loss: 0.0004342535976320505
Test Loss:  0.00021745501726400107
Valid Loss:  0.0005133479135110974
Epoch:  483  	Training Loss: 0.0004331856034696102
Test Loss:  0.00021698599448427558
Valid Loss:  0.000512767001055181
Epoch:  484  	Training Loss: 0.0004323305911384523
Test Loss:  0.00021661666687577963
Valid Loss:  0.0005123101291246712
Epoch:  485  	Training Loss: 0.00043155558523721993
Test Loss:  0.00021628840477205813
Valid Loss:  0.0005118467379361391
Epoch:  486  	Training Loss: 0.000430858664913103
Test Loss:  0.00021600228501483798
Valid Loss:  0.0005114137311466038
Epoch:  487  	Training Loss: 0.000430221640272066
Test Loss:  0.0002157442067982629
Valid Loss:  0.0005109889316372573
Epoch:  488  	Training Loss: 0.00042963327723555267
Test Loss:  0.00021550570090766996
Valid Loss:  0.0005105574964545667
Epoch:  489  	Training Loss: 0.0004290881915949285
Test Loss:  0.0002152883680537343
Valid Loss:  0.0005101050483062863
Epoch:  490  	Training Loss: 0.00042858615051954985
Test Loss:  0.00021508596546482295
Valid Loss:  0.000509661971591413
Epoch:  491  	Training Loss: 0.00042811065213754773
Test Loss:  0.00021489014034159482
Valid Loss:  0.0005092148785479367
Epoch:  492  	Training Loss: 0.00042765779653564095
Test Loss:  0.00021497957641258836
Valid Loss:  0.00050901755457744
Epoch:  493  	Training Loss: 0.00042723253136500716
Test Loss:  0.00021493827807717025
Valid Loss:  0.0005085441516712308
Epoch:  494  	Training Loss: 0.00042688322719186544
Test Loss:  0.00021482512238435447
Valid Loss:  0.0005079397233203053
Epoch:  495  	Training Loss: 0.0004265537718310952
Test Loss:  0.0002146771439583972
Valid Loss:  0.0005072804051451385
Epoch:  496  	Training Loss: 0.0004262334550730884
Test Loss:  0.00021451551583595574
Valid Loss:  0.0005066067678853869
Epoch:  497  	Training Loss: 0.0004259184352122247
Test Loss:  0.00021434955124277622
Valid Loss:  0.0005059341783635318
Epoch:  498  	Training Loss: 0.00042560813017189503
Test Loss:  0.00021418386313598603
Valid Loss:  0.0005052702035754919
Epoch:  499  	Training Loss: 0.00042530178325250745
Test Loss:  0.00021402022684924304
Valid Loss:  0.0005046165315434337
Epoch:  500  	Training Loss: 0.0004249994526617229
Test Loss:  0.00021385955915320665
Valid Loss:  0.0005039762472733855
seed is  9
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.24it/s]  1%|          | 4/500 [00:00<00:30, 16.31it/s]  1%|          | 6/500 [00:00<00:30, 16.30it/s]  2%|▏         | 8/500 [00:00<00:30, 16.36it/s]  2%|▏         | 10/500 [00:00<00:29, 16.37it/s]  2%|▏         | 12/500 [00:00<00:29, 16.34it/s]  3%|▎         | 14/500 [00:00<00:29, 16.26it/s]  3%|▎         | 16/500 [00:00<00:29, 16.26it/s]  4%|▎         | 18/500 [00:01<00:29, 16.34it/s]  4%|▍         | 20/500 [00:01<00:29, 16.39it/s]  4%|▍         | 22/500 [00:01<00:29, 16.46it/s]  5%|▍         | 24/500 [00:01<00:28, 16.48it/s]  5%|▌         | 26/500 [00:01<00:29, 16.32it/s]  6%|▌         | 28/500 [00:01<00:28, 16.31it/s]  6%|▌         | 30/500 [00:01<00:28, 16.42it/s]  6%|▋         | 32/500 [00:01<00:28, 16.47it/s]  7%|▋         | 34/500 [00:02<00:28, 16.50it/s]  7%|▋         | 36/500 [00:02<00:28, 16.50it/s]  8%|▊         | 38/500 [00:02<00:27, 16.51it/s]  8%|▊         | 40/500 [00:02<00:27, 16.51it/s]  8%|▊         | 42/500 [00:02<00:27, 16.50it/s]  9%|▉         | 44/500 [00:02<00:27, 16.39it/s]  9%|▉         | 46/500 [00:02<00:27, 16.44it/s] 10%|▉         | 48/500 [00:02<00:27, 16.45it/s] 10%|█         | 50/500 [00:03<00:27, 16.47it/s] 10%|█         | 52/500 [00:03<00:27, 16.44it/s] 11%|█         | 54/500 [00:03<00:28, 15.91it/s] 11%|█         | 56/500 [00:03<00:27, 16.11it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.28it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.30it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.29it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.20it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.12it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.13it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.20it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.04it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.16it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.16it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.19it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.27it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.34it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.38it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.43it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.39it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.38it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.39it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.40it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.30it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.25it/s] 20%|██        | 100/500 [00:06<00:24, 16.24it/s] 20%|██        | 102/500 [00:06<00:24, 16.36it/s] 21%|██        | 104/500 [00:06<00:24, 16.39it/s] 21%|██        | 106/500 [00:06<00:24, 16.40it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.43it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.41it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.44it/s] 23%|██▎       | 114/500 [00:06<00:24, 15.62it/s] 23%|██▎       | 116/500 [00:07<00:26, 14.51it/s] 24%|██▎       | 118/500 [00:07<00:26, 14.43it/s] 24%|██▍       | 120/500 [00:07<00:25, 15.00it/s] 24%|██▍       | 122/500 [00:07<00:24, 15.37it/s] 25%|██▍       | 124/500 [00:07<00:24, 15.66it/s]Epoch:  1  	Training Loss: 0.06676879525184631
Test Loss:  1211.1583251953125
Valid Loss:  1212.350341796875
Epoch:  2  	Training Loss: 1211.1875
Test Loss:  204530385944576.0
Valid Loss:  204563386728448.0
Epoch:  3  	Training Loss: 205376880377856.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:23, 15.86it/s] 26%|██▌       | 128/500 [00:07<00:23, 15.96it/s] 26%|██▌       | 130/500 [00:08<00:23, 16.06it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.04it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.17it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.20it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.16it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.02it/s] 28%|██▊       | 142/500 [00:08<00:22, 16.15it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.30it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.36it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.36it/s] 30%|███       | 150/500 [00:09<00:21, 16.38it/s] 30%|███       | 152/500 [00:09<00:21, 16.44it/s] 31%|███       | 154/500 [00:09<00:21, 16.35it/s] 31%|███       | 156/500 [00:09<00:20, 16.42it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.44it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.33it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.39it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.37it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.32it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.07it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.21it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.28it/s] 35%|███▍      | 174/500 [00:10<00:20, 16.16it/s] 35%|███▌      | 176/500 [00:10<00:20, 16.16it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.23it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.31it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.37it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.37it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.37it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.38it/s] 38%|███▊      | 190/500 [00:11<00:19, 16.15it/s] 38%|███▊      | 192/500 [00:11<00:19, 15.73it/s] 39%|███▉      | 194/500 [00:11<00:19, 15.54it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.88it/s] 40%|███▉      | 198/500 [00:12<00:18, 15.98it/s] 40%|████      | 200/500 [00:12<00:18, 16.06it/s] 40%|████      | 202/500 [00:12<00:18, 16.04it/s] 41%|████      | 204/500 [00:12<00:18, 16.14it/s] 41%|████      | 206/500 [00:12<00:18, 16.21it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.24it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.18it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.15it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.21it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.34it/s] 44%|████▎     | 218/500 [00:13<00:17, 15.82it/s] 44%|████▍     | 220/500 [00:13<00:17, 15.95it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.07it/s] 45%|████▍     | 224/500 [00:13<00:17, 16.13it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.20it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.17it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.24it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.24it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.30it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.34it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.34it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.38it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.25it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.32it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.38it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.44it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.41it/s] 50%|█████     | 252/500 [00:15<00:15, 16.43it/s] 51%|█████     | 254/500 [00:15<00:15, 16.32it/s] 51%|█████     | 256/500 [00:15<00:15, 16.24it/s] 52%|█████▏    | 258/500 [00:15<00:15, 16.06it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.21it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.26it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.30it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.34it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.35it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.08it/s] 54%|█████▍    | 272/500 [00:16<00:14, 16.03it/s] 55%|█████▍    | 274/500 [00:16<00:14, 15.85it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.38it/s] 56%|█████▌    | 278/500 [00:17<00:14, 15.64it/s] 56%|█████▌    | 280/500 [00:17<00:13, 15.82it/s] 56%|█████▋    | 282/500 [00:17<00:13, 15.97it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.02it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.11it/s] 58%|█████▊    | 288/500 [00:17<00:13, 16.12it/s] 58%|█████▊    | 290/500 [00:17<00:13, 16.15it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.17it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.23it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.28it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.29it/s] 60%|██████    | 300/500 [00:18<00:12, 16.35it/s] 60%|██████    | 302/500 [00:18<00:12, 16.02it/s] 61%|██████    | 304/500 [00:18<00:13, 14.84it/s] 61%|██████    | 306/500 [00:18<00:12, 15.30it/s] 62%|██████▏   | 308/500 [00:19<00:12, 15.60it/s] 62%|██████▏   | 310/500 [00:19<00:11, 15.87it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.05it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.17it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.06it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.15it/s] 64%|██████▍   | 320/500 [00:19<00:11, 16.25it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.24it/s] 65%|██████▍   | 324/500 [00:20<00:11, 15.92it/s] 65%|██████▌   | 326/500 [00:20<00:11, 15.42it/s] 66%|██████▌   | 328/500 [00:20<00:10, 15.77it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.00it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.17it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.27it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.34it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.37it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.35it/s] 68%|██████▊   | 342/500 [00:21<00:09, 15.86it/s] 69%|██████▉   | 344/500 [00:21<00:09, 15.95it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.00it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.08it/s] 70%|███████   | 350/500 [00:21<00:09, 16.00it/s] 70%|███████   | 352/500 [00:21<00:09, 16.12it/s] 71%|███████   | 354/500 [00:21<00:09, 15.93it/s] 71%|███████   | 356/500 [00:22<00:08, 16.00it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.20it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.10it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.20it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.20it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.17it/s] 74%|███████▎  | 368/500 [00:22<00:08, 15.46it/s] 74%|███████▍  | 370/500 [00:22<00:08, 15.69it/s] 74%|███████▍  | 372/500 [00:23<00:08, 15.90it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.11it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.25it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.35it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.42it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.21it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.21it/s] 77%|███████▋  | 386/500 [00:23<00:07, 16.18it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.27it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.25it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.19it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.25it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.28it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.25it/s] 80%|████████  | 400/500 [00:24<00:06, 16.29it/s] 80%|████████  | 402/500 [00:24<00:06, 16.19it/s] 81%|████████  | 404/500 [00:25<00:05, 16.23it/s] 81%|████████  | 406/500 [00:25<00:05, 16.30it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.34it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.36it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.36it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.40it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.04it/s] 84%|████████▎ | 418/500 [00:25<00:05, 16.04it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.16it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.28it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.22it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.30it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.15it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.25it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.36it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.35it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.37it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.23it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.22it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.29it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.30it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.37it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.40it/s] 90%|█████████ | 450/500 [00:27<00:03, 15.02it/s] 90%|█████████ | 452/500 [00:28<00:03, 14.07it/s] 91%|█████████ | 454/500 [00:28<00:03, 13.43it/s] 91%|█████████ | 456/500 [00:28<00:03, 13.08it/s] 92%|█████████▏| 458/500 [00:28<00:03, 13.92it/s] 92%|█████████▏| 460/500 [00:28<00:02, 14.59it/s] 92%|█████████▏| 462/500 [00:28<00:02, 15.13it/s] 93%|█████████▎| 464/500 [00:28<00:02, 15.49it/s] 93%|█████████▎| 466/500 [00:28<00:02, 15.68it/s] 94%|█████████▎| 468/500 [00:29<00:02, 15.91it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.06it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.01it/s] 95%|█████████▍| 474/500 [00:29<00:01, 14.74it/s] 95%|█████████▌| 476/500 [00:29<00:01, 14.03it/s] 96%|█████████▌| 478/500 [00:29<00:01, 14.67it/s] 96%|█████████▌| 480/500 [00:29<00:01, 15.15it/s] 96%|█████████▋| 482/500 [00:30<00:01, 15.48it/s] 97%|█████████▋| 484/500 [00:30<00:01, 15.74it/s] 97%|█████████▋| 486/500 [00:30<00:00, 15.92it/s] 98%|█████████▊| 488/500 [00:30<00:00, 15.93it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.01it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.10it/s] 99%|█████████▉| 494/500 [00:30<00:00, 15.99it/s] 99%|█████████▉| 496/500 [00:30<00:00, 15.99it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 16.14it/s]100%|██████████| 500/500 [00:31<00:00, 16.28it/s]100%|██████████| 500/500 [00:31<00:00, 16.06it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  9
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:45,  6.22s/it]  1%|          | 3/500 [00:06<13:48,  1.67s/it]  1%|          | 5/500 [00:06<06:57,  1.19it/s]  1%|▏         | 7/500 [00:06<04:13,  1.94it/s]  2%|▏         | 9/500 [00:06<02:49,  2.89it/s]  2%|▏         | 11/500 [00:13<10:50,  1.33s/it]  3%|▎         | 13/500 [00:13<07:23,  1.10it/s]  3%|▎         | 15/500 [00:19<13:10,  1.63s/it]  3%|▎         | 17/500 [00:19<09:10,  1.14s/it]  4%|▍         | 19/500 [00:19<06:27,  1.24it/s]  4%|▍         | 21/500 [00:32<19:50,  2.49s/it]  5%|▍         | 23/500 [00:32<13:53,  1.75s/it]  5%|▌         | 25/500 [00:38<17:08,  2.17s/it]  5%|▌         | 27/500 [00:38<12:04,  1.53s/it]  6%|▌         | 29/500 [00:38<08:33,  1.09s/it]  6%|▌         | 29/500 [00:49<08:33,  1.09s/it]  6%|▌         | 31/500 [00:51<20:44,  2.65s/it]  7%|▋         | 33/500 [00:51<14:36,  1.88s/it]  7%|▋         | 35/500 [00:58<17:32,  2.26s/it]  7%|▋         | 37/500 [00:58<12:23,  1.61s/it]  8%|▊         | 39/500 [00:58<08:47,  1.14s/it]  8%|▊         | 39/500 [01:09<08:47,  1.14s/it]  8%|▊         | 41/500 [01:10<20:31,  2.68s/it]  9%|▊         | 43/500 [01:10<14:27,  1.90s/it]  9%|▉         | 45/500 [01:17<17:14,  2.27s/it]  9%|▉         | 47/500 [01:17<12:10,  1.61s/it] 10%|▉         | 49/500 [01:17<08:38,  1.15s/it] 10%|▉         | 49/500 [01:29<08:38,  1.15s/it] 10%|█         | 51/500 [01:30<20:07,  2.69s/it] 11%|█         | 53/500 [01:30<14:10,  1.90s/it] 11%|█         | 55/500 [01:36<16:58,  2.29s/it] 11%|█▏        | 57/500 [01:36<11:59,  1.62s/it] 12%|█▏        | 59/500 [01:36<08:30,  1.16s/it] 12%|█▏        | 59/500 [01:49<08:30,  1.16s/it] 12%|█▏        | 61/500 [01:49<19:44,  2.70s/it] 13%|█▎        | 63/500 [01:49<13:55,  1.91s/it]Epoch:  1  	Training Loss: 0.06676879525184631
Test Loss:  25.09212303161621
Valid Loss:  25.19021224975586
Epoch:  2  	Training Loss: 24.727445602416992
Test Loss:  15.174887657165527
Valid Loss:  15.237527847290039
Epoch:  3  	Training Loss: 14.95083999633789
Test Loss:  1.6277190446853638
Valid Loss:  1.641971230506897
Epoch:  4  	Training Loss: 1.5408241748809814
Test Loss:  0.204624205827713
Valid Loss:  0.20737995207309723
Epoch:  5  	Training Loss: 0.17695370316505432
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  6  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  7  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  8  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  9  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  10  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  11  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  12  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  13  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  14  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  15  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  17  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  18  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  19  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  20  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  22  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  23  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  24  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  25  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  27  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  28  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  29  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  30  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  32  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  33  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  34  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  35  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  37  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  38  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  39  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  40  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  42  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  43  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  44  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  45  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  47  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  48  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  49  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  50  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  52  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  53  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  54  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  55  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  57  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  58  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  59  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  60  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698879480362
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.097869873046875
Epoch:  62  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  63  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  64  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
 13%|█▎        | 65/500 [01:55<16:32,  2.28s/it] 13%|█▎        | 67/500 [01:56<11:41,  1.62s/it] 14%|█▍        | 69/500 [01:56<08:17,  1.15s/it] 14%|█▍        | 71/500 [02:08<19:06,  2.67s/it] 15%|█▍        | 73/500 [02:08<13:28,  1.89s/it] 15%|█▌        | 75/500 [02:15<16:13,  2.29s/it] 15%|█▌        | 77/500 [02:15<11:27,  1.62s/it] 16%|█▌        | 79/500 [02:15<08:07,  1.16s/it] 16%|█▌        | 81/500 [02:28<18:50,  2.70s/it] 17%|█▋        | 83/500 [02:28<13:16,  1.91s/it] 17%|█▋        | 85/500 [02:34<15:49,  2.29s/it] 17%|█▋        | 87/500 [02:34<11:11,  1.63s/it] 18%|█▊        | 89/500 [02:34<07:56,  1.16s/it] 18%|█▊        | 91/500 [02:47<18:24,  2.70s/it] 19%|█▊        | 93/500 [02:47<12:58,  1.91s/it] 19%|█▉        | 95/500 [02:53<15:21,  2.28s/it] 19%|█▉        | 97/500 [02:54<10:50,  1.61s/it] 20%|█▉        | 99/500 [02:54<07:40,  1.15s/it] 20%|██        | 101/500 [03:06<17:50,  2.68s/it] 21%|██        | 103/500 [03:06<12:33,  1.90s/it] 21%|██        | 105/500 [03:13<14:59,  2.28s/it] 21%|██▏       | 107/500 [03:13<10:35,  1.62s/it] 22%|██▏       | 109/500 [03:13<07:30,  1.15s/it] 22%|██▏       | 111/500 [03:26<17:27,  2.69s/it] 23%|██▎       | 113/500 [03:26<12:17,  1.91s/it] 23%|██▎       | 115/500 [03:32<14:37,  2.28s/it] 23%|██▎       | 116/500 [03:32<12:07,  1.90s/it] 24%|██▎       | 118/500 [03:32<08:09,  1.28s/it] 24%|██▍       | 120/500 [03:39<11:58,  1.89s/it] 24%|██▍       | 121/500 [03:45<17:14,  2.73s/it] 25%|██▍       | 123/500 [03:45<11:19,  1.80s/it]Valid Loss:  0.0978698804974556
Epoch:  65  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  67  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  68  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  69  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  70  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  72  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  73  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  74  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  75  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  77  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  78  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  79  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  80  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  82  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  83  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  84  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  85  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  87  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  88  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  89  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  90  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  92  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  93  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  94  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.097869873046875
Epoch:  95  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  97  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  98  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  99  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  100  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  102  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  103  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  104  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  105  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  107  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  108  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  109  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  110  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  112  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  113  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  114  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  115  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  117  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  118  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.097869873046875
Epoch:  119  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  120  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  122  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  123  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  124  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698879480362
Epoch:  125  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:   25%|██▌       | 125/500 [03:51<14:13,  2.28s/it] 25%|██▌       | 127/500 [03:52<09:43,  1.56s/it] 26%|██▌       | 129/500 [03:52<06:45,  1.09s/it] 26%|██▌       | 131/500 [04:04<16:42,  2.72s/it] 27%|██▋       | 133/500 [04:05<11:39,  1.90s/it] 27%|██▋       | 135/500 [04:11<13:58,  2.30s/it] 27%|██▋       | 137/500 [04:11<09:48,  1.62s/it] 28%|██▊       | 139/500 [04:11<06:55,  1.15s/it] 28%|██▊       | 141/500 [04:24<16:11,  2.71s/it] 29%|██▊       | 143/500 [04:24<11:23,  1.92s/it] 29%|██▉       | 145/500 [04:30<13:38,  2.31s/it] 29%|██▉       | 147/500 [04:31<09:36,  1.63s/it] 30%|██▉       | 149/500 [04:31<06:47,  1.16s/it] 30%|███       | 151/500 [04:43<15:35,  2.68s/it] 31%|███       | 153/500 [04:43<10:58,  1.90s/it] 31%|███       | 155/500 [04:50<13:02,  2.27s/it] 31%|███▏      | 157/500 [04:50<09:12,  1.61s/it] 32%|███▏      | 159/500 [04:50<06:31,  1.15s/it] 32%|███▏      | 161/500 [05:02<15:04,  2.67s/it] 33%|███▎      | 163/500 [05:02<10:36,  1.89s/it] 33%|███▎      | 165/500 [05:09<12:35,  2.25s/it] 33%|███▎      | 167/500 [05:09<08:52,  1.60s/it] 34%|███▍      | 169/500 [05:09<06:17,  1.14s/it] 34%|███▍      | 169/500 [05:19<06:17,  1.14s/it] 34%|███▍      | 171/500 [05:21<14:37,  2.67s/it] 35%|███▍      | 173/500 [05:21<10:17,  1.89s/it] 35%|███▌      | 175/500 [05:28<12:11,  2.25s/it] 35%|███▌      | 177/500 [05:28<08:36,  1.60s/it] 36%|███▌      | 179/500 [05:28<06:05,  1.14s/it] 36%|███▌      | 179/500 [05:39<06:05,  1.14s/it] 36%|███▌      | 181/500 [05:41<14:25,  2.71s/it] 37%|███▋      | 183/500 [05:41<10:08,  1.92s/it]0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  127  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  128  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.097869873046875
Epoch:  129  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  130  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  132  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  133  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  134  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  135  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  137  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  138  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  139  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  140  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  142  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  143  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  144  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  145  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  147  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  148  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  149  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  150  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  152  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  153  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  154  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  155  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  157  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  158  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  159  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  160  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  162  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  163  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  164  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  165  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  167  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  168  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  169  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  170  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  172  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  173  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  174  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  175  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  177  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  178  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  179  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  180  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  182  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  183  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  184  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  185  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
 37%|███▋      | 185/500 [05:47<12:06,  2.31s/it] 37%|███▋      | 187/500 [05:47<08:32,  1.64s/it] 38%|███▊      | 189/500 [05:48<06:02,  1.17s/it] 38%|███▊      | 189/500 [05:59<06:02,  1.17s/it] 38%|███▊      | 191/500 [06:00<14:07,  2.74s/it] 39%|███▊      | 193/500 [06:01<09:56,  1.94s/it] 39%|███▉      | 195/500 [06:07<11:48,  2.32s/it] 39%|███▉      | 197/500 [06:07<08:19,  1.65s/it] 40%|███▉      | 199/500 [06:07<05:53,  1.17s/it] 40%|███▉      | 199/500 [06:19<05:53,  1.17s/it] 40%|████      | 201/500 [06:20<13:35,  2.73s/it] 41%|████      | 203/500 [06:20<09:35,  1.94s/it] 41%|████      | 205/500 [06:26<11:20,  2.31s/it] 41%|████▏     | 207/500 [06:27<07:59,  1.64s/it] 42%|████▏     | 209/500 [06:27<05:39,  1.17s/it] 42%|████▏     | 209/500 [06:39<05:39,  1.17s/it] 42%|████▏     | 211/500 [06:39<13:02,  2.71s/it] 43%|████▎     | 213/500 [06:40<09:10,  1.92s/it] 43%|████▎     | 215/500 [06:46<11:00,  2.32s/it] 43%|████▎     | 217/500 [06:46<07:45,  1.64s/it] 44%|████▍     | 219/500 [06:46<05:28,  1.17s/it] 44%|████▍     | 221/500 [06:59<12:33,  2.70s/it] 45%|████▍     | 223/500 [06:59<08:50,  1.91s/it] 45%|████▌     | 225/500 [07:05<10:31,  2.30s/it] 45%|████▌     | 227/500 [07:06<07:24,  1.63s/it] 46%|████▌     | 229/500 [07:06<05:14,  1.16s/it] 46%|████▌     | 231/500 [07:18<12:14,  2.73s/it] 47%|████▋     | 233/500 [07:19<08:36,  1.93s/it] 47%|████▋     | 235/500 [07:25<10:10,  2.30s/it] 47%|████▋     | 237/500 [07:25<07:09,  1.63s/it] 48%|████▊     | 239/500 [07:25<05:03,  1.16s/it] 48%|████▊     | 241/500 [07:38<11:45,  2.72s/it] 49%|████▊     | 243/500 [07:38<08:15,  1.93s/it]**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  187  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  188  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  189  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  190  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  192  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  193  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  194  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  195  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  197  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  198  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  199  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  200  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  202  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  203  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698879480362
Epoch:  204  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  205  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  207  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  208  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  209  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  210  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  212  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  213  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  214  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  215  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  217  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  218  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  219  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  220  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  222  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  223  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  224  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  225  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  227  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  228  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  229  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  230  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  232  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  233  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  234  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  235  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  237  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  238  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  239  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  240  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  242  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  243  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  244  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  245  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
 49%|████▉     | 245/500 [07:44<09:47,  2.30s/it] 49%|████▉     | 247/500 [07:45<06:53,  1.64s/it] 50%|████▉     | 249/500 [07:45<04:52,  1.17s/it] 50%|█████     | 251/500 [07:57<11:09,  2.69s/it] 51%|█████     | 253/500 [07:57<07:50,  1.90s/it] 51%|█████     | 255/500 [08:04<09:20,  2.29s/it] 51%|█████▏    | 257/500 [08:04<06:34,  1.62s/it] 52%|█████▏    | 259/500 [08:04<04:38,  1.16s/it] 52%|█████▏    | 261/500 [08:17<10:41,  2.68s/it] 53%|█████▎    | 263/500 [08:17<07:30,  1.90s/it] 53%|█████▎    | 265/500 [08:23<08:58,  2.29s/it] 53%|█████▎    | 267/500 [08:23<06:18,  1.62s/it] 54%|█████▍    | 269/500 [08:23<04:27,  1.16s/it] 54%|█████▍    | 271/500 [08:36<10:15,  2.69s/it] 55%|█████▍    | 273/500 [08:36<07:11,  1.90s/it] 55%|█████▌    | 275/500 [08:42<08:33,  2.28s/it] 55%|█████▌    | 277/500 [08:42<06:00,  1.62s/it] 56%|█████▌    | 279/500 [08:43<04:14,  1.15s/it] 56%|█████▌    | 281/500 [08:55<09:50,  2.70s/it] 57%|█████▋    | 283/500 [08:55<06:54,  1.91s/it] 57%|█████▋    | 285/500 [09:02<08:11,  2.28s/it] 57%|█████▋    | 287/500 [09:02<05:45,  1.62s/it] 58%|█████▊    | 289/500 [09:02<04:03,  1.16s/it] 58%|█████▊    | 291/500 [09:15<09:27,  2.72s/it] 59%|█████▊    | 293/500 [09:15<06:38,  1.92s/it] 59%|█████▉    | 295/500 [09:21<07:53,  2.31s/it] 59%|█████▉    | 297/500 [09:21<05:32,  1.64s/it] 60%|█████▉    | 299/500 [09:22<03:54,  1.17s/it] 60%|██████    | 301/500 [09:34<09:05,  2.74s/it] 61%|██████    | 303/500 [09:34<06:22,  1.94s/it]**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  247  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  248  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  249  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  250  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  252  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  253  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  254  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  255  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  257  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  258  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  259  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  260  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  262  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  263  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  264  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.097869873046875
Epoch:  265  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  267  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  268  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698879480362
Epoch:  269  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  270  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  272  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  273  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  274  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  275  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  277  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  278  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  279  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  280  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  282  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  283  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  284  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  285  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  287  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  288  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  289  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415398478508
Valid Loss:  0.097869873046875
Epoch:  290  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  292  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  293  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  294  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  295  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  297  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  298  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  299  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  300  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  302  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  303  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  304  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  305  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698879480362
 61%|██████    | 305/500 [09:41<07:35,  2.34s/it] 61%|██████▏   | 307/500 [09:41<05:20,  1.66s/it] 62%|██████▏   | 309/500 [09:41<03:46,  1.18s/it] 62%|██████▏   | 311/500 [09:54<08:41,  2.76s/it] 63%|██████▎   | 313/500 [09:54<06:06,  1.96s/it] 63%|██████▎   | 315/500 [10:01<07:11,  2.33s/it] 63%|██████▎   | 317/500 [10:01<05:02,  1.65s/it] 64%|██████▍   | 319/500 [10:01<03:33,  1.18s/it] 64%|██████▍   | 321/500 [10:14<08:12,  2.75s/it] 65%|██████▍   | 323/500 [10:14<05:44,  1.95s/it] 65%|██████▌   | 325/500 [10:20<06:47,  2.33s/it] 65%|██████▌   | 327/500 [10:21<04:45,  1.65s/it] 66%|██████▌   | 329/500 [10:21<03:21,  1.18s/it] 66%|██████▌   | 331/500 [10:34<07:43,  2.74s/it] 67%|██████▋   | 333/500 [10:34<05:24,  1.94s/it] 67%|██████▋   | 335/500 [10:40<06:29,  2.36s/it] 67%|██████▋   | 337/500 [10:41<04:32,  1.67s/it] 68%|██████▊   | 339/500 [10:41<03:11,  1.19s/it] 68%|██████▊   | 341/500 [10:54<07:21,  2.78s/it] 69%|██████▊   | 343/500 [10:54<05:08,  1.97s/it] 69%|██████▉   | 345/500 [11:01<06:10,  2.39s/it] 69%|██████▉   | 347/500 [11:01<04:19,  1.70s/it] 70%|██████▉   | 349/500 [11:01<03:02,  1.21s/it] 70%|███████   | 351/500 [11:14<06:52,  2.77s/it] 71%|███████   | 353/500 [11:14<04:47,  1.96s/it] 71%|███████   | 355/500 [11:20<05:38,  2.33s/it] 71%|███████▏  | 357/500 [11:20<03:56,  1.66s/it] 72%|███████▏  | 359/500 [11:20<02:46,  1.18s/it] 72%|███████▏  | 361/500 [11:33<06:20,  2.74s/it] 73%|███████▎  | 363/500 [11:33<04:25,  1.94s/it]**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  307  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  308  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  309  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698879480362
Epoch:  310  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  312  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  313  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  314  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  315  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  317  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  318  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  319  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  320  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  322  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  323  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  324  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  325  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698879480362
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  327  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  328  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  329  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  330  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415323972702
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  332  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  333  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  334  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  335  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  337  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  338  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  339  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.097869873046875
Epoch:  340  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  342  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  343  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  344  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  345  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  347  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  348  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  349  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  350  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  352  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  353  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  354  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  355  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  357  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  358  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  359  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  360  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  362  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  363  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  364  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  365  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
 73%|███████▎  | 365/500 [11:40<05:11,  2.31s/it] 73%|███████▎  | 367/500 [11:40<03:37,  1.64s/it] 74%|███████▍  | 369/500 [11:40<02:32,  1.17s/it] 74%|███████▍  | 371/500 [11:53<05:55,  2.76s/it] 75%|███████▍  | 373/500 [11:53<04:07,  1.95s/it] 75%|███████▌  | 375/500 [12:00<04:54,  2.35s/it] 75%|███████▌  | 377/500 [12:00<03:25,  1.67s/it] 76%|███████▌  | 379/500 [12:00<02:23,  1.19s/it] 76%|███████▌  | 381/500 [12:13<05:25,  2.73s/it] 77%|███████▋  | 383/500 [12:13<03:46,  1.94s/it] 77%|███████▋  | 385/500 [12:19<04:26,  2.32s/it] 77%|███████▋  | 387/500 [12:19<03:05,  1.64s/it] 78%|███████▊  | 389/500 [12:19<02:10,  1.17s/it] 78%|███████▊  | 391/500 [12:32<04:56,  2.72s/it] 79%|███████▊  | 393/500 [12:32<03:26,  1.93s/it] 79%|███████▉  | 395/500 [12:39<04:01,  2.30s/it] 79%|███████▉  | 397/500 [12:39<02:48,  1.64s/it] 80%|███████▉  | 399/500 [12:39<01:58,  1.17s/it] 80%|███████▉  | 399/500 [12:49<01:58,  1.17s/it] 80%|████████  | 401/500 [12:52<04:28,  2.71s/it] 81%|████████  | 403/500 [12:52<03:06,  1.92s/it] 81%|████████  | 405/500 [12:58<03:37,  2.29s/it] 81%|████████▏ | 407/500 [12:58<02:31,  1.62s/it] 82%|████████▏ | 409/500 [12:58<01:45,  1.16s/it] 82%|████████▏ | 409/500 [13:09<01:45,  1.16s/it] 82%|████████▏ | 411/500 [13:11<04:02,  2.72s/it] 83%|████████▎ | 413/500 [13:11<02:47,  1.93s/it] 83%|████████▎ | 415/500 [13:18<03:17,  2.32s/it] 83%|████████▎ | 417/500 [13:18<02:16,  1.65s/it] 84%|████████▍ | 419/500 [13:18<01:34,  1.17s/it] 84%|████████▍ | 419/500 [13:29<01:34,  1.17s/it] 84%|████████▍ | 421/500 [13:31<03:36,  2.74s/it] 85%|████████▍ | 423/500 [13:31<02:29,  1.94s/it]**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  367  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  368  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  369  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  370  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  372  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  373  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  374  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  375  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698879480362
Epoch:  377  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  378  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  379  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  380  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  382  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  383  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  384  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  385  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  387  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  388  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.097869873046875
Epoch:  389  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  390  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  392  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  393  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  394  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.097869873046875
Epoch:  395  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  397  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  398  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  399  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  400  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698879480362
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  402  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  403  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  404  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  405  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  407  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  408  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  409  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  410  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  412  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  413  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  414  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  415  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  417  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  418  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  419  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  420  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  422  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698879480362
Epoch:  423  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  424  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698879480362
Epoch:  425  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
 85%|████████▌ | 425/500 [13:37<02:54,  2.33s/it] 85%|████████▌ | 427/500 [13:38<02:00,  1.65s/it] 86%|████████▌ | 429/500 [13:38<01:23,  1.18s/it] 86%|████████▌ | 429/500 [13:49<01:23,  1.18s/it] 86%|████████▌ | 431/500 [13:50<03:07,  2.72s/it] 87%|████████▋ | 433/500 [13:50<02:08,  1.92s/it] 87%|████████▋ | 435/500 [13:57<02:30,  2.31s/it] 87%|████████▋ | 437/500 [13:57<01:43,  1.64s/it] 88%|████████▊ | 439/500 [13:57<01:11,  1.17s/it] 88%|████████▊ | 439/500 [14:09<01:11,  1.17s/it] 88%|████████▊ | 441/500 [14:10<02:41,  2.73s/it] 89%|████████▊ | 443/500 [14:10<01:50,  1.94s/it] 89%|████████▉ | 445/500 [14:16<02:06,  2.30s/it] 89%|████████▉ | 447/500 [14:17<01:26,  1.64s/it] 90%|████████▉ | 449/500 [14:17<00:59,  1.16s/it] 90%|████████▉ | 449/500 [14:29<00:59,  1.16s/it] 90%|█████████ | 451/500 [14:29<02:14,  2.74s/it] 91%|█████████ | 453/500 [14:30<01:31,  1.94s/it] 91%|█████████ | 455/500 [14:36<01:43,  2.31s/it] 91%|█████████▏| 457/500 [14:36<01:10,  1.64s/it] 92%|█████████▏| 459/500 [14:36<00:47,  1.17s/it] 92%|█████████▏| 461/500 [14:49<01:45,  2.70s/it] 93%|█████████▎| 463/500 [14:49<01:10,  1.91s/it] 93%|█████████▎| 465/500 [14:55<01:19,  2.28s/it] 93%|█████████▎| 467/500 [14:55<00:53,  1.62s/it] 94%|█████████▍| 469/500 [14:56<00:35,  1.15s/it] 94%|█████████▍| 471/500 [15:08<01:18,  2.71s/it] 95%|█████████▍| 473/500 [15:08<00:51,  1.92s/it] 95%|█████████▌| 475/500 [15:15<00:57,  2.29s/it] 95%|█████████▌| 477/500 [15:15<00:37,  1.62s/it] 96%|█████████▌| 479/500 [15:15<00:24,  1.16s/it] 96%|█████████▌| 481/500 [15:27<00:51,  2.69s/it] 97%|█████████▋| 483/500 [15:28<00:32,  1.90s/it]**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  427  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  428  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  429  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  430  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  432  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  433  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  434  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  435  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  437  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  438  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  439  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  440  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  442  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  443  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  444  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.097869873046875
Epoch:  445  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  447  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  448  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  449  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  450  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  452  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  453  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  454  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  455  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  457  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  458  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  459  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  460  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  462  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  463  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  464  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  465  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  467  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  468  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  469  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  470  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  472  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  473  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  474  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  475  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.097869873046875
Epoch:  477  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  478  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  479  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  480  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.097869873046875
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  482  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  483  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  484  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  485  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
 97%|█████████▋| 485/500 [15:34<00:34,  2.27s/it] 97%|█████████▋| 487/500 [15:34<00:20,  1.61s/it] 98%|█████████▊| 489/500 [15:34<00:12,  1.15s/it] 98%|█████████▊| 491/500 [15:47<00:24,  2.69s/it] 99%|█████████▊| 493/500 [15:47<00:13,  1.91s/it] 99%|█████████▉| 495/500 [15:53<00:11,  2.29s/it] 99%|█████████▉| 497/500 [15:53<00:04,  1.62s/it]100%|█████████▉| 499/500 [15:53<00:01,  1.16s/it]100%|██████████| 500/500 [16:00<00:00,  1.92s/it]
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415398478508
Valid Loss:  0.097869873046875
Epoch:  487  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  488  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  489  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  490  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  492  	Training Loss: 0.0798705592751503
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  493  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  494  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.097869873046875
Epoch:  495  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  497  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415398478508
Valid Loss:  0.0978698804974556
Epoch:  498  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698879480362
Epoch:  499  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
Epoch:  500  	Training Loss: 0.0798705518245697
Test Loss:  0.0970415472984314
Valid Loss:  0.0978698804974556
**************************************************learning rate decay**************************************************
seed is  9
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:05,  6.26s/it]  1%|          | 3/500 [00:06<13:57,  1.69s/it]  1%|          | 5/500 [00:06<07:01,  1.17it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:51,  2.87it/s]  2%|▏         | 11/500 [00:13<10:54,  1.34s/it]  3%|▎         | 13/500 [00:13<07:25,  1.09it/s]  3%|▎         | 15/500 [00:13<05:11,  1.56it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:42,  2.97it/s]  4%|▍         | 21/500 [00:26<17:23,  2.18s/it]  5%|▍         | 23/500 [00:26<12:12,  1.53s/it]  5%|▌         | 25/500 [00:26<08:37,  1.09s/it]  5%|▌         | 27/500 [00:26<06:08,  1.28it/s]  6%|▌         | 29/500 [00:26<04:25,  1.77it/s]  6%|▌         | 31/500 [00:33<10:30,  1.34s/it]  7%|▋         | 33/500 [00:33<07:28,  1.04it/s]  7%|▋         | 35/500 [00:33<05:21,  1.44it/s]  7%|▋         | 37/500 [00:33<03:54,  1.98it/s]  8%|▊         | 39/500 [00:33<02:55,  2.63it/s]  8%|▊         | 41/500 [00:40<09:26,  1.23s/it]  9%|▊         | 43/500 [00:40<06:44,  1.13it/s]  9%|▉         | 45/500 [00:40<04:50,  1.57it/s]  9%|▉         | 47/500 [00:40<03:31,  2.14it/s] 10%|▉         | 49/500 [00:40<02:36,  2.88it/s] 10%|█         | 51/500 [00:53<16:01,  2.14s/it] 11%|█         | 53/500 [00:53<11:19,  1.52s/it] 11%|█         | 55/500 [00:53<08:01,  1.08s/it] 11%|█▏        | 57/500 [00:53<05:44,  1.29it/s] 12%|█▏        | 59/500 [00:53<04:08,  1.77it/s] 12%|█▏        | 61/500 [01:00<09:54,  1.35s/it] 13%|█▎        | 63/500 [01:00<07:03,  1.03it/s] 13%|█▎        | 65/500 [01:00<05:04,  1.43it/s] 13%|█▎        | 67/500 [01:00<03:40,  1.96it/s]Epoch:  1  	Training Loss: 0.06676879525184631
Test Loss:  0.6958978176116943
Valid Loss:  0.6975758075714111
Epoch:  2  	Training Loss: 0.693463146686554
Test Loss:  0.15126490592956543
Valid Loss:  0.15321627259254456
Epoch:  3  	Training Loss: 0.13810035586357117
Test Loss:  0.01180264726281166
Valid Loss:  0.011412263847887516
Epoch:  4  	Training Loss: 0.010968453250825405
Test Loss:  0.008159980177879333
Valid Loss:  0.007596531882882118
Epoch:  5  	Training Loss: 0.008544804528355598
Test Loss:  0.006907973438501358
Valid Loss:  0.00638604024425149
Epoch:  6  	Training Loss: 0.007527701556682587
Test Loss:  0.006002964451909065
Valid Loss:  0.0055415937677025795
Epoch:  7  	Training Loss: 0.006692088209092617
Test Loss:  0.005259010009467602
Valid Loss:  0.004860906861722469
Epoch:  8  	Training Loss: 0.0059723686426877975
Test Loss:  0.004623377230018377
Valid Loss:  0.0042877523228526115
Epoch:  9  	Training Loss: 0.005347910337150097
Test Loss:  0.004074453376233578
Valid Loss:  0.003797193057835102
Epoch:  10  	Training Loss: 0.004803926683962345
Test Loss:  0.00360663840547204
Valid Loss:  0.0033811768516898155
Epoch:  11  	Training Loss: 0.004332510754466057
Test Loss:  0.0032084009144455194
Valid Loss:  0.0030295890755951405
Epoch:  12  	Training Loss: 0.003925924655050039
Test Loss:  0.001611756975762546
Valid Loss:  0.0017155020032078028
Epoch:  13  	Training Loss: 0.0021872995421290398
Test Loss:  0.0013088739942759275
Valid Loss:  0.0015218532644212246
Epoch:  14  	Training Loss: 0.0019437995506450534
Test Loss:  0.0025733280926942825
Valid Loss:  0.0029064679984003305
Epoch:  15  	Training Loss: 0.002877449616789818
Test Loss:  0.00840314943343401
Valid Loss:  0.00877307541668415
Epoch:  16  	Training Loss: 0.008811324834823608
Test Loss:  0.04280988499522209
Valid Loss:  0.043565534055233
Epoch:  17  	Training Loss: 0.04159513860940933
Test Loss:  0.15338756144046783
Valid Loss:  0.15463820099830627
Epoch:  18  	Training Loss: 0.14974111318588257
Test Loss:  0.2940106987953186
Valid Loss:  0.2964857220649719
Epoch:  19  	Training Loss: 0.2777307629585266
Test Loss:  0.001947399927303195
Valid Loss:  0.0026052850298583508
Epoch:  20  	Training Loss: 0.0021867945324629545
Test Loss:  0.0016453741118311882
Valid Loss:  0.0022482462227344513
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.0019568041898310184
Test Loss:  0.0016398252919316292
Valid Loss:  0.0022301385179162025
Epoch:  22  	Training Loss: 0.001894880086183548
Test Loss:  0.0016716525424271822
Valid Loss:  0.0022357795387506485
Epoch:  23  	Training Loss: 0.0020513292402029037
Test Loss:  0.0025464827194809914
Valid Loss:  0.0030942014418542385
Epoch:  24  	Training Loss: 0.002805716823786497
Test Loss:  0.0016841369215399027
Valid Loss:  0.002181594492867589
Epoch:  25  	Training Loss: 0.0021349098533391953
Test Loss:  0.0014045264106243849
Valid Loss:  0.001921110670082271
Epoch:  26  	Training Loss: 0.0017800452187657356
Test Loss:  0.0013083592057228088
Valid Loss:  0.0017987823812291026
Epoch:  27  	Training Loss: 0.0017261283937841654
Test Loss:  0.0013030222617089748
Valid Loss:  0.0017910606693476439
Epoch:  28  	Training Loss: 0.0017193951644003391
Test Loss:  0.001293841633014381
Valid Loss:  0.0017752556595951319
Epoch:  29  	Training Loss: 0.0017168649937957525
Test Loss:  0.0012885405449196696
Valid Loss:  0.0017656807322055101
Epoch:  30  	Training Loss: 0.0017152561340481043
Test Loss:  0.0012837171088904142
Valid Loss:  0.0017572027863934636
Epoch:  31  	Training Loss: 0.0017141399439424276
Test Loss:  0.0012802601559087634
Valid Loss:  0.0017506678123027086
Epoch:  32  	Training Loss: 0.0017133356304839253
Test Loss:  0.0012681168736889958
Valid Loss:  0.0017341491766273975
Epoch:  33  	Training Loss: 0.0017045399872586131
Test Loss:  0.0012599321780726314
Valid Loss:  0.001723684836179018
Epoch:  34  	Training Loss: 0.0016993735916912556
Test Loss:  0.0012537756701931357
Valid Loss:  0.0017160868737846613
Epoch:  35  	Training Loss: 0.0016952983569353819
Test Loss:  0.0012471886584535241
Valid Loss:  0.0017077329102903605
Epoch:  36  	Training Loss: 0.0016895385924726725
Test Loss:  0.0012453378876671195
Valid Loss:  0.0017046406865119934
Epoch:  37  	Training Loss: 0.0016888694372028112
Test Loss:  0.0012439319398254156
Valid Loss:  0.0017023654654622078
Epoch:  38  	Training Loss: 0.0016883790958672762
Test Loss:  0.0012428893242031336
Valid Loss:  0.0017006431007757783
Epoch:  39  	Training Loss: 0.0016880136681720614
Test Loss:  0.0012420696439221501
Valid Loss:  0.0016993455355986953
Epoch:  40  	Training Loss: 0.0016877399757504463
Test Loss:  0.001241467660292983
Valid Loss:  0.0016983398236334324
Epoch:  41  	Training Loss: 0.0016875264700502157
Test Loss:  0.001241085585206747
Valid Loss:  0.0016975972102954984
Epoch:  42  	Training Loss: 0.001687374315224588
Test Loss:  0.0012049060314893723
Valid Loss:  0.0016566423000767827
Epoch:  43  	Training Loss: 0.001624937867745757
Test Loss:  0.0011819259962067008
Valid Loss:  0.0016383995534852147
Epoch:  44  	Training Loss: 0.0015905499458312988
Test Loss:  0.0011712724808603525
Valid Loss:  0.0016236434457823634
Epoch:  45  	Training Loss: 0.001579056610353291
Test Loss:  0.0011693271808326244
Valid Loss:  0.0016250048065558076
Epoch:  46  	Training Loss: 0.0015741263050585985
Test Loss:  0.001166710862889886
Valid Loss:  0.0016161815728992224
Epoch:  47  	Training Loss: 0.00157446158118546
Test Loss:  0.0011708671227097511
Valid Loss:  0.0016257402021437883
Epoch:  48  	Training Loss: 0.0015746334102004766
Test Loss:  0.0011654157424345613
Valid Loss:  0.001613394357264042
Epoch:  49  	Training Loss: 0.0015745951095595956
Test Loss:  0.0011700454633682966
Valid Loss:  0.001623774180188775
Epoch:  50  	Training Loss: 0.0015743612311780453
Test Loss:  0.0011644157348200679
Valid Loss:  0.0016111718723550439
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.0015747651923447847
Test Loss:  0.0011618330609053373
Valid Loss:  0.0016108546406030655
Epoch:  52  	Training Loss: 0.0015700208023190498
Test Loss:  0.0011621173471212387
Valid Loss:  0.0016121234511956573
Epoch:  53  	Training Loss: 0.0015693485038354993
Test Loss:  0.0011617634445428848
Valid Loss:  0.0016114043537527323
Epoch:  54  	Training Loss: 0.0015693294117227197
Test Loss:  0.0011615925468504429
Valid Loss:  0.0016110468422994018
Epoch:  55  	Training Loss: 0.0015693212626501918
Test Loss:  0.0011614179238677025
Valid Loss:  0.001610680716112256
Epoch:  56  	Training Loss: 0.001569313695654273
Test Loss:  0.001161258202046156
Valid Loss:  0.0016103469533845782
Epoch:  57  	Training Loss: 0.0015693081077188253
Test Loss:  0.0011611098889261484
Valid Loss:  0.0016100374050438404
Epoch:  58  	Training Loss: 0.0015693025197833776
Test Loss:  0.0011609740322455764
Valid Loss:  0.00160975253675133
Epoch:  59  	Training Loss: 0.0015692984452471137
Test Loss:  0.001160847838036716
Valid Loss:  0.0016094883903861046
Epoch:  60  	Training Loss: 0.0015692946035414934
Test Loss:  0.00116073212120682
Valid Loss:  0.0016092433361336589
Epoch:  61  	Training Loss: 0.0015692919259890914
Test Loss:  0.00116062443703413
Valid Loss:  0.001609018538147211
Epoch:  62  	Training Loss: 0.0015692886663600802
Test Loss:  0.0011580635327845812
Valid Loss:  0.0016063605435192585
Epoch:  63  	Training Loss: 0.0015668589621782303
Test Loss:  0.0011563196312636137
Valid Loss:  0.0016047293320298195
Epoch:  64  	Training Loss: 0.0015652156434953213
Test Loss:  0.0011549920309334993
Valid Loss:  0.0016036456217989326
Epoch:  65  	Training Loss: 0.001564103178679943
Test Loss:  0.001154181663878262
Valid Loss:  0.0016030075494199991
Epoch:  66  	Training Loss: 0.0015635236632078886
Test Loss:  0.0011536157689988613
Valid Loss:  0.0016024017240852118
Epoch:  67  	Training Loss: 0.0015630869893357158
Test Loss:  0.001153197605162859
Valid Loss:  0.0016019692411646247
Epoch:  68  	Training Loss: 0.0015627474058419466
Test Loss:  0.001152826240286231
 14%|█▍        | 69/500 [01:00<02:41,  2.66it/s] 14%|█▍        | 71/500 [01:07<08:36,  1.20s/it] 15%|█▍        | 73/500 [01:07<06:08,  1.16it/s] 15%|█▌        | 75/500 [01:07<04:25,  1.60it/s] 15%|█▌        | 77/500 [01:07<03:13,  2.19it/s] 16%|█▌        | 79/500 [01:07<02:22,  2.95it/s] 16%|█▌        | 81/500 [01:14<08:21,  1.20s/it] 17%|█▋        | 83/500 [01:14<05:58,  1.16it/s] 17%|█▋        | 85/500 [01:14<04:17,  1.61it/s] 17%|█▋        | 87/500 [01:14<03:07,  2.20it/s] 18%|█▊        | 89/500 [01:14<02:18,  2.97it/s] 18%|█▊        | 91/500 [01:20<08:03,  1.18s/it] 19%|█▊        | 93/500 [01:21<05:45,  1.18it/s] 19%|█▉        | 95/500 [01:21<04:08,  1.63it/s] 19%|█▉        | 97/500 [01:21<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:21<02:13,  3.00it/s] 20%|██        | 101/500 [01:27<07:51,  1.18s/it] 21%|██        | 103/500 [01:27<05:36,  1.18it/s] 21%|██        | 105/500 [01:28<04:02,  1.63it/s] 21%|██▏       | 107/500 [01:28<02:56,  2.23it/s] 22%|██▏       | 109/500 [01:28<02:10,  3.00it/s] 22%|██▏       | 111/500 [01:34<07:38,  1.18s/it] 23%|██▎       | 113/500 [01:34<05:27,  1.18it/s] 23%|██▎       | 115/500 [01:34<03:55,  1.63it/s] 23%|██▎       | 117/500 [01:35<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:35<02:07,  3.00it/s] 24%|██▍       | 121/500 [01:41<07:21,  1.16s/it] 25%|██▍       | 123/500 [01:41<05:15,  1.19it/s] 25%|██▌       | 125/500 [01:41<03:47,  1.65it/s] 25%|██▌       | 127/500 [01:41<02:45,  2.25it/s] 26%|██▌       | 129/500 [01:41<02:02,  3.03it/s] 26%|██▌       | 131/500 [01:48<07:12,  1.17s/it] 27%|██▋       | 133/500 [01:48<05:08,  1.19it/s] 27%|██▋       | 135/500 [01:48<03:41,  1.64it/s]Valid Loss:  0.0016015996225178242
Epoch:  69  	Training Loss: 0.0015624579973518848
Test Loss:  0.0011525873560458422
Valid Loss:  0.0016013208078220487
Epoch:  70  	Training Loss: 0.0015622405335307121
Test Loss:  0.0011523913126438856
Valid Loss:  0.001601142343133688
Epoch:  71  	Training Loss: 0.001562048215419054
Test Loss:  0.001152215525507927
Valid Loss:  0.001600989024154842
Epoch:  72  	Training Loss: 0.0015618809266015887
Test Loss:  0.0011282567866146564
Valid Loss:  0.0015814317157492042
Epoch:  73  	Training Loss: 0.001525486120954156
Test Loss:  0.0011038596276193857
Valid Loss:  0.0015625448431819677
Epoch:  74  	Training Loss: 0.0014901590766385198
Test Loss:  0.0010844231583178043
Valid Loss:  0.0015487873461097479
Epoch:  75  	Training Loss: 0.0014622787712141871
Test Loss:  0.0010715899989008904
Valid Loss:  0.0015398948453366756
Epoch:  76  	Training Loss: 0.0014452746836468577
Test Loss:  0.0010624814312905073
Valid Loss:  0.0015326477587223053
Epoch:  77  	Training Loss: 0.0014345247764140368
Test Loss:  0.0010575242340564728
Valid Loss:  0.0015255508478730917
Epoch:  78  	Training Loss: 0.001428420888260007
Test Loss:  0.0010534729808568954
Valid Loss:  0.0015192541759461164
Epoch:  79  	Training Loss: 0.001423962414264679
Test Loss:  0.001049999613314867
Valid Loss:  0.001513756113126874
Epoch:  80  	Training Loss: 0.0014204985927790403
Test Loss:  0.0010474806185811758
Valid Loss:  0.0015091703971847892
Epoch:  81  	Training Loss: 0.0014176417607814074
Test Loss:  0.0010453953873366117
Valid Loss:  0.0015046967891976237
Epoch:  82  	Training Loss: 0.0014154438395053148
Test Loss:  0.0010426283115521073
Valid Loss:  0.0014996645040810108
Epoch:  83  	Training Loss: 0.0014143980806693435
Test Loss:  0.0010401741601526737
Valid Loss:  0.0014952020719647408
Epoch:  84  	Training Loss: 0.0014135489473119378
Test Loss:  0.0010380060411989689
Valid Loss:  0.0014912346377968788
Epoch:  85  	Training Loss: 0.0014128378825262189
Test Loss:  0.001036099623888731
Valid Loss:  0.0014876935165375471
Epoch:  86  	Training Loss: 0.0014122423017397523
Test Loss:  0.0010344197507947683
Valid Loss:  0.0014845167752355337
Epoch:  87  	Training Loss: 0.0014117397367954254
Test Loss:  0.0010329537326470017
Valid Loss:  0.0014816850889474154
Epoch:  88  	Training Loss: 0.0014113315846771002
Test Loss:  0.0010316669940948486
Valid Loss:  0.0014791442081332207
Epoch:  89  	Training Loss: 0.0014109925832599401
Test Loss:  0.001030521234497428
Valid Loss:  0.0014768586261197925
Epoch:  90  	Training Loss: 0.001410704804584384
Test Loss:  0.0010295005049556494
Valid Loss:  0.0014748000539839268
Epoch:  91  	Training Loss: 0.001410455908626318
Test Loss:  0.0010285982862114906
Valid Loss:  0.0014729434624314308
Epoch:  92  	Training Loss: 0.0014102475252002478
Test Loss:  0.001027342863380909
Valid Loss:  0.0014721853658556938
Epoch:  93  	Training Loss: 0.0014070116449147463
Test Loss:  0.0010256703244522214
Valid Loss:  0.0014707709196954966
Epoch:  94  	Training Loss: 0.0014039615634828806
Test Loss:  0.001023916876874864
Valid Loss:  0.0014692590339109302
Epoch:  95  	Training Loss: 0.0014009501319378614
Test Loss:  0.001022192183881998
Valid Loss:  0.0014676405116915703
Epoch:  96  	Training Loss: 0.0013979702489450574
Test Loss:  0.0010204637655988336
Valid Loss:  0.0014659451553598046
Epoch:  97  	Training Loss: 0.0013950426364317536
Test Loss:  0.0010184948332607746
Valid Loss:  0.001463927561417222
Epoch:  98  	Training Loss: 0.0013921502977609634
Test Loss:  0.0010165368439629674
Valid Loss:  0.0014619214925915003
Epoch:  99  	Training Loss: 0.001389276934787631
Test Loss:  0.001014564884826541
Valid Loss:  0.001459889579564333
Epoch:  100  	Training Loss: 0.0013864184729754925
Test Loss:  0.0010125760454684496
Valid Loss:  0.0014578206464648247
Epoch:  101  	Training Loss: 0.0013835750287398696
Test Loss:  0.0010105663677677512
Valid Loss:  0.001455714926123619
Epoch:  102  	Training Loss: 0.0013807439245283604
Test Loss:  0.0010082509834319353
Valid Loss:  0.0014513034839183092
Epoch:  103  	Training Loss: 0.0013801787281408906
Test Loss:  0.001006297767162323
Valid Loss:  0.0014475194038823247
Epoch:  104  	Training Loss: 0.001379742519930005
Test Loss:  0.001004620804451406
Valid Loss:  0.001444224501028657
Epoch:  105  	Training Loss: 0.0013794016558676958
Test Loss:  0.0010031734127551317
Valid Loss:  0.0014413477620109916
Epoch:  106  	Training Loss: 0.001379135763272643
Test Loss:  0.0010019224137067795
Valid Loss:  0.0014388327253982425
Epoch:  107  	Training Loss: 0.0013789276126772165
Test Loss:  0.0010008391691371799
Valid Loss:  0.0014366317773237824
Epoch:  108  	Training Loss: 0.0013787647476419806
Test Loss:  0.000999897951260209
Valid Loss:  0.001434702891856432
Epoch:  109  	Training Loss: 0.0013786389026790857
Test Loss:  0.0009990810649469495
Valid Loss:  0.0014330114936456084
Epoch:  110  	Training Loss: 0.0013785392511636019
Test Loss:  0.000998368370346725
Valid Loss:  0.001431525801308453
Epoch:  111  	Training Loss: 0.0013784619513899088
Test Loss:  0.0009977479930967093
Valid Loss:  0.0014302227646112442
Epoch:  112  	Training Loss: 0.0013784011825919151
Test Loss:  0.0009936071000993252
Valid Loss:  0.001426416914910078
Epoch:  113  	Training Loss: 0.0013733446830883622
Test Loss:  0.000990595086477697
Valid Loss:  0.0014234953559935093
Epoch:  114  	Training Loss: 0.0013699147384613752
Test Loss:  0.0009880600264295936
Valid Loss:  0.0014207509811967611
Epoch:  115  	Training Loss: 0.0013669331092387438
Test Loss:  0.0009855760727077723
Valid Loss:  0.0014178181299939752
Epoch:  116  	Training Loss: 0.001363905263133347
Test Loss:  0.0009826477617025375
Valid Loss:  0.0014145034365355968
Epoch:  117  	Training Loss: 0.0013606093125417829
Test Loss:  0.0009795186342671514
Valid Loss:  0.0014109426410868764
Epoch:  118  	Training Loss: 0.0013573466567322612
Test Loss:  0.0009761193650774658
Valid Loss:  0.0014069557655602694
Epoch:  119  	Training Loss: 0.001353816594928503
Test Loss:  0.0009723722469061613
Valid Loss:  0.0014027076540514827
Epoch:  120  	Training Loss: 0.0013499362394213676
Test Loss:  0.0009682795498520136
Valid Loss:  0.001397861517034471
Epoch:  121  	Training Loss: 0.0013454541331157088
Test Loss:  0.0009638149058446288
Valid Loss:  0.0013923286460340023
Epoch:  122  	Training Loss: 0.001340390183031559
Test Loss:  0.0009552811970934272
Valid Loss:  0.0013856792356818914
Epoch:  123  	Training Loss: 0.0013281083665788174
Test Loss:  0.0009507054346613586
Valid Loss:  0.0013798291329294443
Epoch:  124  	Training Loss: 0.0013230612967163324
Test Loss:  0.0009469374199397862
Valid Loss:  0.0013741720467805862
Epoch:  125  	Training Loss: 0.0013190428726375103
Test Loss:  0.0009430181235074997
Valid Loss:  0.0013683141442015767
Epoch:  126  	Training Loss: 0.0013156795175746083
Test Loss:  0.0009394125081598759
Valid Loss:  0.0013627528678625822
Epoch:  127  	Training Loss: 0.001312757027335465
Test Loss:  0.0009365809382870793
Valid Loss:  0.0013577861245721579
Epoch:  128  	Training Loss: 0.0013101182412356138
Test Loss:  0.0009339952375739813
Valid Loss:  0.0013530999422073364
Epoch:  129  	Training Loss: 0.001308049657382071
Test Loss:  0.0009323951089754701
Valid Loss:  0.0013493173755705357
Epoch:  130  	Training Loss: 0.0013064073864370584
Test Loss:  0.0009313909104093909
Valid Loss:  0.0013460065238177776
Epoch:  131  	Training Loss: 0.001304935896769166
Test Loss:  0.0009305832209065557
Valid Loss:  0.0013431152328848839
Epoch:  132  	Training Loss: 0.0013036720920354128
Test Loss:  0.00092860939912498
Valid Loss:  0.0013392940163612366
Epoch:  133  	Training Loss: 0.0012998548336327076
Test Loss:  0.0009268792346119881
Valid Loss:  0.0013361542951315641
Epoch:  134  	Training Loss: 0.0012965421192348003
Test Loss:  0.0009257125784642994
Valid Loss:  0.0013340445002540946
Epoch:  135  	Training Loss: 0.0012941556051373482
Test Loss:  0.0009244820103049278
Valid Loss:  0.0013325285399332643
Epoch:  136  	Training Loss: 0.0012921097222715616
Test Loss:  0.0009232766460627317
Valid Loss:  0.0013315484393388033
Epoch:  137  	Training Loss: 0.001290320185944438
Test Loss:   27%|██▋       | 137/500 [01:48<02:41,  2.25it/s] 28%|██▊       | 139/500 [01:48<01:59,  3.02it/s] 28%|██▊       | 141/500 [01:54<07:00,  1.17s/it] 29%|██▊       | 143/500 [01:55<05:00,  1.19it/s] 29%|██▉       | 145/500 [01:55<03:35,  1.64it/s] 29%|██▉       | 147/500 [01:55<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:55<01:56,  3.01it/s] 30%|███       | 151/500 [02:01<06:56,  1.19s/it] 31%|███       | 153/500 [02:02<04:57,  1.17it/s] 31%|███       | 155/500 [02:02<03:33,  1.61it/s] 31%|███▏      | 157/500 [02:02<02:35,  2.21it/s] 32%|███▏      | 159/500 [02:02<01:55,  2.97it/s] 32%|███▏      | 161/500 [02:08<06:46,  1.20s/it] 33%|███▎      | 163/500 [02:09<04:49,  1.16it/s] 33%|███▎      | 165/500 [02:09<03:28,  1.61it/s] 33%|███▎      | 167/500 [02:09<02:31,  2.20it/s] 34%|███▍      | 169/500 [02:09<01:52,  2.95it/s] 34%|███▍      | 171/500 [02:15<06:32,  1.19s/it] 35%|███▍      | 173/500 [02:15<04:40,  1.17it/s] 35%|███▌      | 175/500 [02:16<03:21,  1.61it/s] 35%|███▌      | 177/500 [02:16<02:27,  2.20it/s] 36%|███▌      | 179/500 [02:16<01:48,  2.95it/s] 36%|███▌      | 181/500 [02:22<06:22,  1.20s/it] 37%|███▋      | 183/500 [02:22<04:33,  1.16it/s] 37%|███▋      | 185/500 [02:23<03:16,  1.60it/s] 37%|███▋      | 187/500 [02:23<02:23,  2.19it/s] 38%|███▊      | 189/500 [02:23<01:45,  2.94it/s] 38%|███▊      | 191/500 [02:29<06:13,  1.21s/it] 39%|███▊      | 193/500 [02:29<04:26,  1.15it/s] 39%|███▉      | 195/500 [02:30<03:11,  1.59it/s] 39%|███▉      | 197/500 [02:30<02:19,  2.18it/s] 40%|███▉      | 199/500 [02:30<01:42,  2.93it/s] 40%|████      | 201/500 [02:36<05:59,  1.20s/it] 41%|████      | 203/500 [02:36<04:17,  1.16it/s] 41%|████      | 205/500 [02:37<03:04,  1.60it/s]0.0009219516068696976
Valid Loss:  0.0013306804466992617
Epoch:  138  	Training Loss: 0.0012888440396636724
Test Loss:  0.000920546124689281
Valid Loss:  0.0013295975513756275
Epoch:  139  	Training Loss: 0.001287628780119121
Test Loss:  0.0009194310987368226
Valid Loss:  0.0013286109315231442
Epoch:  140  	Training Loss: 0.001286564045585692
Test Loss:  0.0009182127541862428
Valid Loss:  0.0013273775111883879
Epoch:  141  	Training Loss: 0.0012855816166847944
Test Loss:  0.000917281024158001
Valid Loss:  0.0013264522422105074
Epoch:  142  	Training Loss: 0.0012846256140619516
Test Loss:  0.0009007578482851386
Valid Loss:  0.0013115599285811186
Epoch:  143  	Training Loss: 0.0012573187705129385
Test Loss:  0.0008871502941474319
Valid Loss:  0.001299227704294026
Epoch:  144  	Training Loss: 0.001234539202414453
Test Loss:  0.000875769299454987
Valid Loss:  0.0012892093509435654
Epoch:  145  	Training Loss: 0.0012171075213700533
Test Loss:  0.0008669747039675713
Valid Loss:  0.0012826756574213505
Epoch:  146  	Training Loss: 0.001204399624839425
Test Loss:  0.0008591421646997333
Valid Loss:  0.0012764543062075973
Epoch:  147  	Training Loss: 0.0011928455205634236
Test Loss:  0.0008528183680027723
Valid Loss:  0.0012715046759694815
Epoch:  148  	Training Loss: 0.0011831056326627731
Test Loss:  0.000846952898427844
Valid Loss:  0.001267080893740058
Epoch:  149  	Training Loss: 0.0011746261734515429
Test Loss:  0.0008413532050326467
Valid Loss:  0.001262910314835608
Epoch:  150  	Training Loss: 0.0011670077219605446
Test Loss:  0.0008363791857846081
Valid Loss:  0.0012591134291142225
Epoch:  151  	Training Loss: 0.0011600705329328775
Test Loss:  0.0008321027271449566
Valid Loss:  0.0012555904686450958
Epoch:  152  	Training Loss: 0.0011542115826159716
Test Loss:  0.000829384196549654
Valid Loss:  0.001250618021003902
Epoch:  153  	Training Loss: 0.0011531584896147251
Test Loss:  0.0008269724785350263
Valid Loss:  0.001246101688593626
Epoch:  154  	Training Loss: 0.0011523088905960321
Test Loss:  0.0008248522644862533
Valid Loss:  0.0012420691782608628
Epoch:  155  	Training Loss: 0.0011516048107296228
Test Loss:  0.0008229855448007584
Valid Loss:  0.0012384572764858603
Epoch:  156  	Training Loss: 0.0011510222684592009
Test Loss:  0.0008213344262912869
Valid Loss:  0.0012352196499705315
Epoch:  157  	Training Loss: 0.0011505379807204008
Test Loss:  0.0008198759751394391
Valid Loss:  0.0012323129922151566
Epoch:  158  	Training Loss: 0.0011501371627673507
Test Loss:  0.0008185815531760454
Valid Loss:  0.0012297029606997967
Epoch:  159  	Training Loss: 0.0011498050298541784
Test Loss:  0.0008174331160262227
Valid Loss:  0.0012273523025214672
Epoch:  160  	Training Loss: 0.001149529474787414
Test Loss:  0.0008164108730852604
Valid Loss:  0.0012252363376319408
Epoch:  161  	Training Loss: 0.0011493006022647023
Test Loss:  0.0008155008545145392
Valid Loss:  0.0012233322486281395
Epoch:  162  	Training Loss: 0.001149111078120768
Test Loss:  0.0008141532307490706
Valid Loss:  0.001221332000568509
Epoch:  163  	Training Loss: 0.0011484709102660418
Test Loss:  0.0008129545021802187
Valid Loss:  0.0012195790186524391
Epoch:  164  	Training Loss: 0.0011479260865598917
Test Loss:  0.0008118916302919388
Valid Loss:  0.0012179932091385126
Epoch:  165  	Training Loss: 0.0011474648490548134
Test Loss:  0.0008109619375318289
Valid Loss:  0.001216540695168078
Epoch:  166  	Training Loss: 0.001147065544500947
Test Loss:  0.0008102128049358726
Valid Loss:  0.0012152530252933502
Epoch:  167  	Training Loss: 0.001146757509559393
Test Loss:  0.000809524382930249
Valid Loss:  0.0012140373000875115
Epoch:  168  	Training Loss: 0.0011464683338999748
Test Loss:  0.0008088978938758373
Valid Loss:  0.001212935894727707
Epoch:  169  	Training Loss: 0.0011462053516879678
Test Loss:  0.0008083147695288062
Valid Loss:  0.0012119191233068705
Epoch:  170  	Training Loss: 0.0011459644883871078
Test Loss:  0.0008077605743892491
Valid Loss:  0.0012109827948734164
Epoch:  171  	Training Loss: 0.0011457354994490743
Test Loss:  0.0008072558557614684
Valid Loss:  0.0012101181782782078
Epoch:  172  	Training Loss: 0.0011455377098172903
Test Loss:  0.0008036685176193714
Valid Loss:  0.0012079768348485231
Epoch:  173  	Training Loss: 0.0011398682836443186
Test Loss:  0.0008000889793038368
Valid Loss:  0.001205328619107604
Epoch:  174  	Training Loss: 0.001135007943958044
Test Loss:  0.0007966118864715099
Valid Loss:  0.001202935236506164
Epoch:  175  	Training Loss: 0.0011304535437375307
Test Loss:  0.0007932551670819521
Valid Loss:  0.0012006263714283705
Epoch:  176  	Training Loss: 0.0011262963525950909
Test Loss:  0.0007900753989815712
Valid Loss:  0.0011985693126916885
Epoch:  177  	Training Loss: 0.0011225915513932705
Test Loss:  0.0007872394635342062
Valid Loss:  0.0011964007280766964
Epoch:  178  	Training Loss: 0.0011195145780220628
Test Loss:  0.000784838804975152
Valid Loss:  0.001194329233840108
Epoch:  179  	Training Loss: 0.0011169288773089647
Test Loss:  0.0007829936221241951
Valid Loss:  0.0011921834666281939
Epoch:  180  	Training Loss: 0.0011147577315568924
Test Loss:  0.0007815441349521279
Valid Loss:  0.0011902587721124291
Epoch:  181  	Training Loss: 0.0011128024198114872
Test Loss:  0.0007801463361829519
Valid Loss:  0.001188135240226984
Epoch:  182  	Training Loss: 0.0011110235936939716
Test Loss:  0.0007782612228766084
Valid Loss:  0.0011852980824187398
Epoch:  183  	Training Loss: 0.0011101029813289642
Test Loss:  0.0007768357172608376
Valid Loss:  0.0011831261217594147
Epoch:  184  	Training Loss: 0.0011094326619058847
Test Loss:  0.0007757780258543789
Valid Loss:  0.0011813805904239416
Epoch:  185  	Training Loss: 0.0011089234612882137
Test Loss:  0.0007749934447929263
Valid Loss:  0.0011800210922956467
Epoch:  186  	Training Loss: 0.0011085303267464042
Test Loss:  0.0007743191672489047
Valid Loss:  0.0011789007112383842
Epoch:  187  	Training Loss: 0.0011081829434260726
Test Loss:  0.0007737200940027833
Valid Loss:  0.0011779709020629525
Epoch:  188  	Training Loss: 0.0011078673414885998
Test Loss:  0.0007732405210845172
Valid Loss:  0.0011772038415074348
Epoch:  189  	Training Loss: 0.0011076126247644424
Test Loss:  0.0007728257915005088
Valid Loss:  0.0011765214148908854
Epoch:  190  	Training Loss: 0.0011073821224272251
Test Loss:  0.000772487954236567
Valid Loss:  0.0011759523767977953
Epoch:  191  	Training Loss: 0.001107183052226901
Test Loss:  0.0007721772417426109
Valid Loss:  0.0011754569131880999
Epoch:  192  	Training Loss: 0.0011069858446717262
Test Loss:  0.0007718916749581695
Valid Loss:  0.0011749900877475739
Epoch:  193  	Training Loss: 0.001106876414269209
Test Loss:  0.0007716388208791614
Valid Loss:  0.0011745428200811148
Epoch:  194  	Training Loss: 0.001106797019019723
Test Loss:  0.0007714066887274384
Valid Loss:  0.0011741071939468384
Epoch:  195  	Training Loss: 0.0011067362502217293
Test Loss:  0.0007711892249062657
Valid Loss:  0.0011736820451915264
Epoch:  196  	Training Loss: 0.0011066871229559183
Test Loss:  0.0007709828205406666
Valid Loss:  0.0011732655111700296
Epoch:  197  	Training Loss: 0.001106645679101348
Test Loss:  0.0007707866607233882
Valid Loss:  0.0011728571262210608
Epoch:  198  	Training Loss: 0.0011066105216741562
Test Loss:  0.0007705977186560631
Valid Loss:  0.0011724609648808837
Epoch:  199  	Training Loss: 0.0011065774597227573
Test Loss:  0.0007704151794314384
Valid Loss:  0.0011720727197825909
Epoch:  200  	Training Loss: 0.0011065483558923006
Test Loss:  0.000770240556448698
Valid Loss:  0.001171695301309228
Epoch:  201  	Training Loss: 0.0011065219296142459
Test Loss:  0.0007700719870626926
Valid Loss:  0.0011713271960616112
Epoch:  202  	Training Loss: 0.001106497598811984
Test Loss:  0.0007695999811403453
Valid Loss:  0.00117041589692235
Epoch:  203  	Training Loss: 0.0011064449790865183
Test Loss:  0.0007694275700487196
Valid Loss:  0.0011699600145220757
Epoch:  204  	Training Loss: 0.0011064172722399235
Test Loss:  0.0007692243088968098
Valid Loss:  0.0011695076245814562
Epoch:  205  	Training Loss: 0.0011063932906836271
Test Loss:  0.0007690436323173344
Valid Loss:  0.001169097376987338
 41%|████▏     | 207/500 [02:37<02:14,  2.18it/s] 42%|████▏     | 209/500 [02:37<01:38,  2.94it/s] 42%|████▏     | 211/500 [02:43<05:54,  1.23s/it] 43%|████▎     | 213/500 [02:44<04:13,  1.13it/s] 43%|████▎     | 215/500 [02:44<03:03,  1.55it/s] 43%|████▎     | 217/500 [02:44<02:13,  2.12it/s] 44%|████▍     | 219/500 [02:44<01:38,  2.86it/s] 44%|████▍     | 221/500 [02:50<05:37,  1.21s/it] 45%|████▍     | 223/500 [02:51<04:00,  1.15it/s] 45%|████▌     | 225/500 [02:51<02:52,  1.60it/s] 45%|████▌     | 227/500 [02:51<02:05,  2.18it/s] 46%|████▌     | 229/500 [02:51<01:32,  2.94it/s] 46%|████▌     | 231/500 [02:57<05:24,  1.20s/it] 47%|████▋     | 233/500 [02:58<03:50,  1.16it/s] 47%|████▋     | 235/500 [02:58<02:45,  1.60it/s] 47%|████▋     | 237/500 [02:58<02:00,  2.19it/s] 48%|████▊     | 239/500 [02:58<01:28,  2.94it/s] 48%|████▊     | 241/500 [03:04<05:08,  1.19s/it] 49%|████▊     | 243/500 [03:04<03:39,  1.17it/s] 49%|████▉     | 245/500 [03:05<02:37,  1.62it/s] 49%|████▉     | 247/500 [03:05<01:54,  2.21it/s] 50%|████▉     | 249/500 [03:05<01:24,  2.98it/s] 50%|█████     | 251/500 [03:11<05:00,  1.20s/it] 51%|█████     | 253/500 [03:11<03:33,  1.16it/s] 51%|█████     | 255/500 [03:12<02:33,  1.60it/s] 51%|█████▏    | 257/500 [03:12<01:51,  2.18it/s] 52%|█████▏    | 259/500 [03:12<01:22,  2.94it/s] 52%|█████▏    | 261/500 [03:18<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:18<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:18<02:25,  1.62it/s] 53%|█████▎    | 267/500 [03:19<01:45,  2.21it/s] 54%|█████▍    | 269/500 [03:19<01:17,  2.97it/s] 54%|█████▍    | 271/500 [03:25<04:39,  1.22s/it] 55%|█████▍    | 273/500 [03:25<03:18,  1.14it/s]Epoch:  206  	Training Loss: 0.0011063716374337673
Test Loss:  0.0007688757032155991
Valid Loss:  0.0011687066871672869
Epoch:  207  	Training Loss: 0.0011063513811677694
Test Loss:  0.0007687179604545236
Valid Loss:  0.0011683355551213026
Epoch:  208  	Training Loss: 0.001106332871131599
Test Loss:  0.0007685681339353323
Valid Loss:  0.0011679839808493853
Epoch:  209  	Training Loss: 0.001106315990909934
Test Loss:  0.0007684280863031745
Valid Loss:  0.0011676459107547998
Epoch:  210  	Training Loss: 0.0011063009733334184
Test Loss:  0.0007682949071750045
Valid Loss:  0.0011673239059746265
Epoch:  211  	Training Loss: 0.00110628642141819
Test Loss:  0.0007681399583816528
Valid Loss:  0.0011669942177832127
Epoch:  212  	Training Loss: 0.0011062732664868236
Test Loss:  0.0007680484559386969
Valid Loss:  0.0011667985236272216
Epoch:  213  	Training Loss: 0.0011062687262892723
Test Loss:  0.000768016092479229
Valid Loss:  0.0011667176149785519
Epoch:  214  	Training Loss: 0.0011062650009989738
Test Loss:  0.0007679673144593835
Valid Loss:  0.0011666067875921726
Epoch:  215  	Training Loss: 0.0011062603443861008
Test Loss:  0.0007679242407903075
Valid Loss:  0.0011665066704154015
Epoch:  216  	Training Loss: 0.0011062562698498368
Test Loss:  0.0007678802940063179
Valid Loss:  0.001166405389085412
Epoch:  217  	Training Loss: 0.0011062524281442165
Test Loss:  0.0007678384426981211
Valid Loss:  0.0011663081822916865
Epoch:  218  	Training Loss: 0.0011062484700232744
Test Loss:  0.0007677971152588725
Valid Loss:  0.0011662098113447428
Epoch:  219  	Training Loss: 0.0011062449775636196
Test Loss:  0.0007677567191421986
Valid Loss:  0.001166114816442132
Epoch:  220  	Training Loss: 0.0011062416015192866
Test Loss:  0.0007677156827412546
Valid Loss:  0.001166020636446774
Epoch:  221  	Training Loss: 0.0011062382254749537
Test Loss:  0.0007676762761548162
Valid Loss:  0.0011659279698505998
Epoch:  222  	Training Loss: 0.0011062349658459425
Test Loss:  0.0007674528751522303
Valid Loss:  0.0011656000278890133
Epoch:  223  	Training Loss: 0.0011060918914154172
Test Loss:  0.0007672283099964261
Valid Loss:  0.001165272668004036
Epoch:  224  	Training Loss: 0.0011059499811381102
Test Loss:  0.0007670071208849549
Valid Loss:  0.0011649575317278504
Epoch:  225  	Training Loss: 0.0011058103991672397
Test Loss:  0.0007667933823540807
Valid Loss:  0.0011646572966128588
Epoch:  226  	Training Loss: 0.001105671632103622
Test Loss:  0.0007665867451578379
Valid Loss:  0.0011643696343526244
Epoch:  227  	Training Loss: 0.00110553705599159
Test Loss:  0.0007663921569474041
Valid Loss:  0.0011641025776043534
Epoch:  228  	Training Loss: 0.0011054144706577063
Test Loss:  0.0007662033895030618
Valid Loss:  0.0011638487922027707
Epoch:  229  	Training Loss: 0.0011052917689085007
Test Loss:  0.0007660215487703681
Valid Loss:  0.0011636061826720834
Epoch:  230  	Training Loss: 0.001105169765651226
Test Loss:  0.0007658435497432947
Valid Loss:  0.0011633762624114752
Epoch:  231  	Training Loss: 0.0011050535831600428
Test Loss:  0.0007656775997020304
Valid Loss:  0.001163162407465279
Epoch:  232  	Training Loss: 0.0011049449676647782
Test Loss:  0.0007656657253392041
Valid Loss:  0.0011631407542154193
Epoch:  233  	Training Loss: 0.0011049396125599742
Test Loss:  0.0007656542584300041
Valid Loss:  0.00116312550380826
Epoch:  234  	Training Loss: 0.0011049349559471011
Test Loss:  0.0007656470406800508
Valid Loss:  0.0011631145607680082
Epoch:  235  	Training Loss: 0.0011049294844269753
Test Loss:  0.0007656400557607412
Valid Loss:  0.001163104665465653
Epoch:  236  	Training Loss: 0.0011049245949834585
Test Loss:  0.0007656324305571616
Valid Loss:  0.0011630963999778032
Epoch:  237  	Training Loss: 0.0011049193562939763
Test Loss:  0.0007656266679987311
Valid Loss:  0.0011630880180746317
Epoch:  238  	Training Loss: 0.0011049140011891723
Test Loss:  0.000765619392041117
Valid Loss:  0.0011630796361714602
Epoch:  239  	Training Loss: 0.0011049078311771154
Test Loss:  0.0007656139205209911
Valid Loss:  0.0011630714870989323
Epoch:  240  	Training Loss: 0.0011049030581489205
Test Loss:  0.0007656071102246642
Valid Loss:  0.0011630631051957607
Epoch:  241  	Training Loss: 0.0011048972373828292
Test Loss:  0.0007656002417206764
Valid Loss:  0.0011630547232925892
Epoch:  242  	Training Loss: 0.001104891300201416
Test Loss:  0.0007655578665435314
Valid Loss:  0.0011629404034465551
Epoch:  243  	Training Loss: 0.0011048887390643358
Test Loss:  0.0007655018707737327
Valid Loss:  0.0011628055945038795
Epoch:  244  	Training Loss: 0.0011048864107578993
Test Loss:  0.0007654475048184395
Valid Loss:  0.0011626755585893989
Epoch:  245  	Training Loss: 0.00110488454811275
Test Loss:  0.0007653952343389392
Valid Loss:  0.0011625508777797222
Epoch:  246  	Training Loss: 0.0011048822198063135
Test Loss:  0.0007653474458493292
Valid Loss:  0.001162431901320815
Epoch:  247  	Training Loss: 0.0011048807064071298
Test Loss:  0.0007653009379282594
Valid Loss:  0.0011623187456279993
Epoch:  248  	Training Loss: 0.001104879193007946
Test Loss:  0.0007652555359527469
Valid Loss:  0.0011622114107012749
Epoch:  249  	Training Loss: 0.0011048773303627968
Test Loss:  0.000765213742852211
Valid Loss:  0.0011621112935245037
Epoch:  250  	Training Loss: 0.0011048767482861876
Test Loss:  0.000765173404943198
Valid Loss:  0.0011620125733315945
Epoch:  251  	Training Loss: 0.001104875234887004
Test Loss:  0.0007651355117559433
Valid Loss:  0.0011619209544733167
Epoch:  252  	Training Loss: 0.0011048744199797511
Test Loss:  0.0007638004026375711
Valid Loss:  0.0011610802030190825
Epoch:  253  	Training Loss: 0.0011022191029042006
Test Loss:  0.0007625228608958423
Valid Loss:  0.0011600932339206338
Epoch:  254  	Training Loss: 0.0010999938240274787
Test Loss:  0.0007613147608935833
Valid Loss:  0.0011592680821195245
Epoch:  255  	Training Loss: 0.0010980996303260326
Test Loss:  0.000760282448027283
Valid Loss:  0.0011584314052015543
Epoch:  256  	Training Loss: 0.0010964225511997938
Test Loss:  0.0007594592170789838
Valid Loss:  0.0011575743556022644
Epoch:  257  	Training Loss: 0.0010949157876893878
Test Loss:  0.0007586790597997606
Valid Loss:  0.001156685408204794
Epoch:  258  	Training Loss: 0.0010936085600405931
Test Loss:  0.0007578981458209455
Valid Loss:  0.0011558625847101212
Epoch:  259  	Training Loss: 0.001092390390112996
Test Loss:  0.0007571204332634807
Valid Loss:  0.0011552677024155855
Epoch:  260  	Training Loss: 0.0010912003926932812
Test Loss:  0.0007565162377431989
Valid Loss:  0.0011547552421689034
Epoch:  261  	Training Loss: 0.0010900702327489853
Test Loss:  0.0007560491794720292
Valid Loss:  0.001154247671365738
Epoch:  262  	Training Loss: 0.0010890758130699396
Test Loss:  0.0007545212865807116
Valid Loss:  0.0011519271647557616
Epoch:  263  	Training Loss: 0.001088232034817338
Test Loss:  0.0007538467179983854
Valid Loss:  0.0011505063157528639
Epoch:  264  	Training Loss: 0.0010875468142330647
Test Loss:  0.000752766034565866
Valid Loss:  0.0011486783623695374
Epoch:  265  	Training Loss: 0.0010869388934224844
Test Loss:  0.0007523418753407896
Valid Loss:  0.0011474289931356907
Epoch:  266  	Training Loss: 0.0010864557698369026
Test Loss:  0.0007515453035011888
Valid Loss:  0.0011458680965006351
Epoch:  267  	Training Loss: 0.001086013508029282
Test Loss:  0.0007511649746447802
Valid Loss:  0.0011447432916611433
Epoch:  268  	Training Loss: 0.001085634808987379
Test Loss:  0.0007504888344556093
Valid Loss:  0.0011434666812419891
Epoch:  269  	Training Loss: 0.0010852873092517257
Test Loss:  0.0007499109487980604
Valid Loss:  0.0011423262767493725
Epoch:  270  	Training Loss: 0.0010849691461771727
Test Loss:  0.0007495597819797695
Valid Loss:  0.001141429878771305
Epoch:  271  	Training Loss: 0.0010846687946468592
Test Loss:  0.0007490837015211582
Valid Loss:  0.0011404823744669557
Epoch:  272  	Training Loss: 0.0010843772906810045
Test Loss:  0.0007480544736608863
Valid Loss:  0.001139998435974121
Epoch:  273  	Training Loss: 0.001080778893083334
Test Loss:  0.0007474346784874797
Valid Loss:  0.001140046981163323
Epoch:  274  	Training Loss: 0.0010784498881548643
Test Loss:   55%|█████▌    | 275/500 [03:26<02:22,  1.58it/s] 55%|█████▌    | 277/500 [03:26<01:42,  2.17it/s] 56%|█████▌    | 279/500 [03:26<01:15,  2.92it/s] 56%|█████▌    | 281/500 [03:32<04:24,  1.21s/it] 57%|█████▋    | 283/500 [03:32<03:07,  1.15it/s] 57%|█████▋    | 285/500 [03:33<02:14,  1.60it/s] 57%|█████▋    | 287/500 [03:33<01:37,  2.19it/s] 58%|█████▊    | 289/500 [03:33<01:11,  2.94it/s] 58%|█████▊    | 291/500 [03:39<04:17,  1.23s/it] 59%|█████▊    | 293/500 [03:40<03:02,  1.13it/s] 59%|█████▉    | 295/500 [03:40<02:10,  1.57it/s] 59%|█████▉    | 297/500 [03:40<01:34,  2.15it/s] 60%|█████▉    | 299/500 [03:40<01:09,  2.90it/s] 60%|██████    | 301/500 [03:46<04:01,  1.21s/it] 61%|██████    | 303/500 [03:47<02:51,  1.15it/s] 61%|██████    | 305/500 [03:47<02:02,  1.59it/s] 61%|██████▏   | 307/500 [03:47<01:29,  2.15it/s] 62%|██████▏   | 309/500 [03:47<01:05,  2.90it/s] 62%|██████▏   | 311/500 [03:53<03:48,  1.21s/it] 63%|██████▎   | 313/500 [03:54<02:41,  1.16it/s] 63%|██████▎   | 315/500 [03:54<01:55,  1.60it/s] 63%|██████▎   | 317/500 [03:54<01:23,  2.18it/s] 64%|██████▍   | 319/500 [03:54<01:01,  2.94it/s] 64%|██████▍   | 321/500 [04:01<03:38,  1.22s/it] 65%|██████▍   | 323/500 [04:01<02:35,  1.14it/s] 65%|██████▌   | 325/500 [04:01<01:51,  1.57it/s] 65%|██████▌   | 327/500 [04:01<01:20,  2.15it/s] 66%|██████▌   | 329/500 [04:01<00:59,  2.89it/s] 66%|██████▌   | 331/500 [04:08<03:29,  1.24s/it] 67%|██████▋   | 333/500 [04:08<02:28,  1.13it/s] 67%|██████▋   | 335/500 [04:08<01:45,  1.56it/s] 67%|██████▋   | 337/500 [04:08<01:16,  2.14it/s] 68%|██████▊   | 339/500 [04:08<00:56,  2.87it/s] 68%|██████▊   | 341/500 [04:15<03:17,  1.24s/it]0.0007474408484995365
Valid Loss:  0.0011407289421185851
Epoch:  275  	Training Loss: 0.0010765672195702791
Test Loss:  0.0007476829923689365
Valid Loss:  0.001141115091741085
Epoch:  276  	Training Loss: 0.001075205858796835
Test Loss:  0.0007478038896806538
Valid Loss:  0.0011411395389586687
Epoch:  277  	Training Loss: 0.0010743013117462397
Test Loss:  0.0007478226907551289
Valid Loss:  0.0011411597952246666
Epoch:  278  	Training Loss: 0.001073509338311851
Test Loss:  0.0007478270563296974
Valid Loss:  0.0011411246377974749
Epoch:  279  	Training Loss: 0.0010727581102401018
Test Loss:  0.0007477372419089079
Valid Loss:  0.001141026965342462
Epoch:  280  	Training Loss: 0.0010721220169216394
Test Loss:  0.0007476798491552472
Valid Loss:  0.001140959095209837
Epoch:  281  	Training Loss: 0.0010715045500546694
Test Loss:  0.000747751328162849
Valid Loss:  0.0011408515274524689
Epoch:  282  	Training Loss: 0.0010709359776228666
Test Loss:  0.000742313452064991
Valid Loss:  0.0011352249421179295
Epoch:  283  	Training Loss: 0.0010670654010027647
Test Loss:  0.000738196074962616
Valid Loss:  0.0011305345688015223
Epoch:  284  	Training Loss: 0.0010643887799233198
Test Loss:  0.0007351295207627118
Valid Loss:  0.0011264983331784606
Epoch:  285  	Training Loss: 0.0010624012211337686
Test Loss:  0.0007324020843952894
Valid Loss:  0.001122953719459474
Epoch:  286  	Training Loss: 0.0010606327559798956
Test Loss:  0.0007300516590476036
Valid Loss:  0.0011198646388947964
Epoch:  287  	Training Loss: 0.001059152651578188
Test Loss:  0.0007282450096681714
Valid Loss:  0.0011172140948474407
Epoch:  288  	Training Loss: 0.0010579663794487715
Test Loss:  0.0007267059991136193
Valid Loss:  0.0011150081409141421
Epoch:  289  	Training Loss: 0.0010569070000201464
Test Loss:  0.0007253065123222768
Valid Loss:  0.0011130640050396323
Epoch:  290  	Training Loss: 0.0010559638030827045
Test Loss:  0.0007241407874971628
Valid Loss:  0.001111347577534616
Epoch:  291  	Training Loss: 0.001055168453603983
Test Loss:  0.0007230617920868099
Valid Loss:  0.0011098370887339115
Epoch:  292  	Training Loss: 0.001054439228028059
Test Loss:  0.0007206901209428906
Valid Loss:  0.0011071753688156605
Epoch:  293  	Training Loss: 0.001052315579727292
Test Loss:  0.0007191337062977254
Valid Loss:  0.0011054131900891662
Epoch:  294  	Training Loss: 0.0010505241807550192
Test Loss:  0.000717693124897778
Valid Loss:  0.0011038321536034346
Epoch:  295  	Training Loss: 0.0010488745756447315
Test Loss:  0.0007164729759097099
Valid Loss:  0.0011024054838344455
Epoch:  296  	Training Loss: 0.0010474291630089283
Test Loss:  0.0007153010228648782
Valid Loss:  0.0011010424932464957
Epoch:  297  	Training Loss: 0.0010461558122187853
Test Loss:  0.0007141665555536747
Valid Loss:  0.0010996961500495672
Epoch:  298  	Training Loss: 0.001044931123033166
Test Loss:  0.0007129968143999577
Valid Loss:  0.0010984980035573244
Epoch:  299  	Training Loss: 0.0010437588207423687
Test Loss:  0.0007118204957805574
Valid Loss:  0.0010973673779517412
Epoch:  300  	Training Loss: 0.0010426496155560017
Test Loss:  0.0007107778219506145
Valid Loss:  0.0010963388485834002
Epoch:  301  	Training Loss: 0.0010417362209409475
Test Loss:  0.0007098022615537047
Valid Loss:  0.0010952999582514167
Epoch:  302  	Training Loss: 0.0010408363305032253
Test Loss:  0.0007086115656420588
Valid Loss:  0.0010948659619316459
Epoch:  303  	Training Loss: 0.0010368733201175928
Test Loss:  0.0007072216249071062
Valid Loss:  0.0010926657123491168
Epoch:  304  	Training Loss: 0.0010346549097448587
Test Loss:  0.000707543920725584
Valid Loss:  0.001092816237360239
Epoch:  305  	Training Loss: 0.0010331913363188505
Test Loss:  0.0007072000880725682
Valid Loss:  0.0010912609286606312
Epoch:  306  	Training Loss: 0.0010322430171072483
Test Loss:  0.0007072804728522897
Valid Loss:  0.0010906026000156999
Epoch:  307  	Training Loss: 0.0010315105319023132
Test Loss:  0.0007065277895890176
Valid Loss:  0.0010890031699091196
Epoch:  308  	Training Loss: 0.0010308929486200213
Test Loss:  0.0007062375661917031
Valid Loss:  0.0010881898924708366
Epoch:  309  	Training Loss: 0.0010303090093657374
Test Loss:  0.0007053851149976254
Valid Loss:  0.0010866218945011497
Epoch:  310  	Training Loss: 0.0010297753615304828
Test Loss:  0.0007045776583254337
Valid Loss:  0.001085328171029687
Epoch:  311  	Training Loss: 0.0010292562656104565
Test Loss:  0.0007038869080133736
Valid Loss:  0.0010841095354408026
Epoch:  312  	Training Loss: 0.001028744736686349
Test Loss:  0.0007031863206066191
Valid Loss:  0.001082572853192687
Epoch:  313  	Training Loss: 0.0010286089964210987
Test Loss:  0.0007028804975561798
Valid Loss:  0.0010817868169397116
Epoch:  314  	Training Loss: 0.0010285116732120514
Test Loss:  0.0007024055812507868
Valid Loss:  0.0010807180078700185
Epoch:  315  	Training Loss: 0.0010284304153174162
Test Loss:  0.0007020647171884775
Valid Loss:  0.0010799020528793335
Epoch:  316  	Training Loss: 0.0010283604497089982
Test Loss:  0.0007018727483227849
Valid Loss:  0.0010793870314955711
Epoch:  317  	Training Loss: 0.0010283270385116339
Test Loss:  0.0007014286820776761
Valid Loss:  0.0010784231126308441
Epoch:  318  	Training Loss: 0.001028299331665039
Test Loss:  0.0007013665162958205
Valid Loss:  0.0010781621094793081
Epoch:  319  	Training Loss: 0.001028271857649088
Test Loss:  0.0007010889239609241
Valid Loss:  0.0010775470873340964
Epoch:  320  	Training Loss: 0.0010282531147822738
Test Loss:  0.0007009669789113104
Valid Loss:  0.0010772414971143007
Epoch:  321  	Training Loss: 0.0010282373987138271
Test Loss:  0.000700801145285368
Valid Loss:  0.0010768359061330557
Epoch:  322  	Training Loss: 0.0010282216826453805
Test Loss:  0.0007005523657426238
Valid Loss:  0.0010765187907963991
Epoch:  323  	Training Loss: 0.001027982565574348
Test Loss:  0.0007003205828368664
Valid Loss:  0.0010762473102658987
Epoch:  324  	Training Loss: 0.0010277442634105682
Test Loss:  0.0007000988116487861
Valid Loss:  0.0010760108707472682
Epoch:  325  	Training Loss: 0.0010275068925693631
Test Loss:  0.0006998806493356824
Valid Loss:  0.001075788401067257
Epoch:  326  	Training Loss: 0.0010272703366354108
Test Loss:  0.0006996672600507736
Valid Loss:  0.0010756058618426323
Epoch:  327  	Training Loss: 0.0010270355269312859
Test Loss:  0.0006994562572799623
Valid Loss:  0.00107542984187603
Epoch:  328  	Training Loss: 0.0010268002515658736
Test Loss:  0.0006992471753619611
Valid Loss:  0.0010752564994618297
Epoch:  329  	Training Loss: 0.0010265667224302888
Test Loss:  0.0006990400142967701
Valid Loss:  0.0010750866495072842
Epoch:  330  	Training Loss: 0.0010263334261253476
Test Loss:  0.0006988358800299466
Valid Loss:  0.0010749190114438534
Epoch:  331  	Training Loss: 0.001026101061142981
Test Loss:  0.0006986328517086804
Valid Loss:  0.0010747569613158703
Epoch:  332  	Training Loss: 0.001025876495987177
Test Loss:  0.0006981994956731796
Valid Loss:  0.0010740678990259767
Epoch:  333  	Training Loss: 0.0010256198002025485
Test Loss:  0.0006978028686717153
Valid Loss:  0.0010734227253124118
Epoch:  334  	Training Loss: 0.001025409554131329
Test Loss:  0.0006974225398153067
Valid Loss:  0.0010728115448728204
Epoch:  335  	Training Loss: 0.001025207107886672
Test Loss:  0.000697094015777111
Valid Loss:  0.0010722542647272348
Epoch:  336  	Training Loss: 0.0010250170016661286
Test Loss:  0.000696779927238822
Valid Loss:  0.0010717518161982298
Epoch:  337  	Training Loss: 0.0010248299222439528
Test Loss:  0.0006964892381802201
Valid Loss:  0.0010713019873946905
Epoch:  338  	Training Loss: 0.0010246565798297524
Test Loss:  0.0006962113548070192
Valid Loss:  0.0010708804475143552
Epoch:  339  	Training Loss: 0.0010244848672300577
Test Loss:  0.0006959441816434264
Valid Loss:  0.0010704940650612116
Epoch:  340  	Training Loss: 0.0010243155993521214
Test Loss:  0.0006956887664273381
Valid Loss:  0.001070145983248949
Epoch:  341  	Training Loss: 0.0010241491254419088
Test Loss:  0.0006954484852030873
Valid Loss:  0.0010698324767872691
Epoch:  342  	Training Loss: 0.001024001045152545
Test Loss:  0.0006951090763323009
Valid Loss:  0.0010696937097236514
 69%|██████▊   | 343/500 [04:15<02:19,  1.12it/s] 69%|██████▉   | 345/500 [04:15<01:39,  1.56it/s] 69%|██████▉   | 347/500 [04:15<01:11,  2.14it/s] 70%|██████▉   | 349/500 [04:15<00:52,  2.88it/s] 70%|███████   | 351/500 [04:22<03:00,  1.21s/it] 71%|███████   | 353/500 [04:22<02:07,  1.15it/s] 71%|███████   | 355/500 [04:22<01:30,  1.59it/s] 71%|███████▏  | 357/500 [04:22<01:05,  2.18it/s] 72%|███████▏  | 359/500 [04:22<00:48,  2.93it/s] 72%|███████▏  | 361/500 [04:29<02:50,  1.23s/it] 73%|███████▎  | 363/500 [04:29<02:00,  1.14it/s] 73%|███████▎  | 365/500 [04:29<01:25,  1.57it/s] 73%|███████▎  | 367/500 [04:29<01:01,  2.15it/s] 74%|███████▍  | 369/500 [04:30<00:45,  2.90it/s] 74%|███████▍  | 371/500 [04:36<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:36<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:36<01:18,  1.60it/s] 75%|███████▌  | 377/500 [04:36<00:56,  2.19it/s] 76%|███████▌  | 379/500 [04:36<00:41,  2.95it/s] 76%|███████▌  | 381/500 [04:43<02:28,  1.25s/it] 77%|███████▋  | 383/500 [04:43<01:45,  1.11it/s] 77%|███████▋  | 385/500 [04:44<01:14,  1.54it/s] 77%|███████▋  | 387/500 [04:44<00:53,  2.11it/s] 78%|███████▊  | 389/500 [04:44<00:39,  2.84it/s] 78%|███████▊  | 391/500 [04:50<02:11,  1.20s/it] 79%|███████▊  | 393/500 [04:50<01:32,  1.15it/s] 79%|███████▉  | 395/500 [04:50<01:06,  1.58it/s] 79%|███████▉  | 397/500 [04:51<00:48,  2.13it/s] 80%|███████▉  | 399/500 [04:51<00:35,  2.82it/s] 80%|████████  | 401/500 [04:57<02:00,  1.22s/it] 81%|████████  | 403/500 [04:57<01:24,  1.14it/s] 81%|████████  | 405/500 [04:58<01:00,  1.58it/s] 81%|████████▏ | 407/500 [04:58<00:43,  2.16it/s] 82%|████████▏ | 409/500 [04:58<00:31,  2.91it/s]Epoch:  343  	Training Loss: 0.001022788230329752
Test Loss:  0.000694671121891588
Valid Loss:  0.0010695114033296704
Epoch:  344  	Training Loss: 0.0010216966038569808
Test Loss:  0.000694244634360075
Valid Loss:  0.0010693820659071207
Epoch:  345  	Training Loss: 0.0010206446750089526
Test Loss:  0.0006939274608157575
Valid Loss:  0.0010693497024476528
Epoch:  346  	Training Loss: 0.0010196645744144917
Test Loss:  0.0006937431171536446
Valid Loss:  0.0010692405048757792
Epoch:  347  	Training Loss: 0.001018830225802958
Test Loss:  0.000693565874826163
Valid Loss:  0.0010691209463402629
Epoch:  348  	Training Loss: 0.001018052687868476
Test Loss:  0.0006935200653970242
Valid Loss:  0.00106896145734936
Epoch:  349  	Training Loss: 0.0010173497721552849
Test Loss:  0.0006934505654498935
Valid Loss:  0.0010687484173104167
Epoch:  350  	Training Loss: 0.0010167922591790557
Test Loss:  0.0006933766417205334
Valid Loss:  0.0010685843881219625
Epoch:  351  	Training Loss: 0.001016290276311338
Test Loss:  0.0006933090044185519
Valid Loss:  0.001068471116013825
Epoch:  352  	Training Loss: 0.001015799818560481
Test Loss:  0.0006927920039743185
Valid Loss:  0.0010674579534679651
Epoch:  353  	Training Loss: 0.0010156966745853424
Test Loss:  0.0006924555636942387
Valid Loss:  0.001066743046976626
Epoch:  354  	Training Loss: 0.0010156191419810057
Test Loss:  0.0006921610329300165
Valid Loss:  0.0010661055566743016
Epoch:  355  	Training Loss: 0.0010155471973121166
Test Loss:  0.0006918907165527344
Valid Loss:  0.001065516727976501
Epoch:  356  	Training Loss: 0.0010154787451028824
Test Loss:  0.0006916176062077284
Valid Loss:  0.0010649602627381682
Epoch:  357  	Training Loss: 0.0010154163464903831
Test Loss:  0.0006913830293342471
Valid Loss:  0.0010644430294632912
Epoch:  358  	Training Loss: 0.0010153582552447915
Test Loss:  0.0006911654490977526
Valid Loss:  0.0010639589745551348
Epoch:  359  	Training Loss: 0.0010153017938137054
Test Loss:  0.0006909634103067219
Valid Loss:  0.0010635071666911244
Epoch:  360  	Training Loss: 0.0010152490576729178
Test Loss:  0.0006907503120601177
Valid Loss:  0.001063077012076974
Epoch:  361  	Training Loss: 0.0010151980677619576
Test Loss:  0.0006905736518092453
Valid Loss:  0.0010626816656440496
Epoch:  362  	Training Loss: 0.0010151525493711233
Test Loss:  0.0006904815672896802
Valid Loss:  0.0010624693240970373
Epoch:  363  	Training Loss: 0.00101514533162117
Test Loss:  0.0006903916946612298
Valid Loss:  0.001062264433130622
Epoch:  364  	Training Loss: 0.0010151395108550787
Test Loss:  0.0006903283065184951
Valid Loss:  0.0010620722314342856
Epoch:  365  	Training Loss: 0.0010151338065043092
Test Loss:  0.0006902462337166071
Valid Loss:  0.0010618842206895351
Epoch:  366  	Training Loss: 0.0010151282185688615
Test Loss:  0.0006901677697896957
Valid Loss:  0.0010617028456181288
Epoch:  367  	Training Loss: 0.0010151234455406666
Test Loss:  0.0006900934386067092
Valid Loss:  0.001061530434526503
Epoch:  368  	Training Loss: 0.0010151194874197245
Test Loss:  0.0006900444277562201
Valid Loss:  0.0010613694321364164
Epoch:  369  	Training Loss: 0.001015115063637495
Test Loss:  0.0006899782456457615
Valid Loss:  0.00106121227145195
Epoch:  370  	Training Loss: 0.0010151118040084839
Test Loss:  0.0006899142754264176
Valid Loss:  0.0010610605822876096
Epoch:  371  	Training Loss: 0.0010151078458875418
Test Loss:  0.0006898537976667285
Valid Loss:  0.0010609161108732224
Epoch:  372  	Training Loss: 0.0010151048190891743
Test Loss:  0.000689733074977994
Valid Loss:  0.0010606455616652966
Epoch:  373  	Training Loss: 0.0010151006281375885
Test Loss:  0.000689663749653846
Valid Loss:  0.0010604665149003267
Epoch:  374  	Training Loss: 0.0010150966700166464
Test Loss:  0.0006895820843055844
Valid Loss:  0.0010602681431919336
Epoch:  375  	Training Loss: 0.0010150938760489225
Test Loss:  0.000689513748511672
Valid Loss:  0.001060099108144641
Epoch:  376  	Training Loss: 0.0010150909656658769
Test Loss:  0.0006894724792800844
Valid Loss:  0.0010599400848150253
Epoch:  377  	Training Loss: 0.0010150884045287967
Test Loss:  0.0006894163670949638
Valid Loss:  0.0010597949149087071
Epoch:  378  	Training Loss: 0.0010150857269763947
Test Loss:  0.0006893592653796077
Valid Loss:  0.0010596502106636763
Epoch:  379  	Training Loss: 0.0010150843299925327
Test Loss:  0.0006893086829222739
Valid Loss:  0.0010595204075798392
Epoch:  380  	Training Loss: 0.0010150823509320617
Test Loss:  0.0006892630481161177
Valid Loss:  0.0010593973565846682
Epoch:  381  	Training Loss: 0.001015080837532878
Test Loss:  0.000689219101332128
Valid Loss:  0.0010592825710773468
Epoch:  382  	Training Loss: 0.0010150793241336942
Test Loss:  0.000689001171849668
Valid Loss:  0.001059339614585042
Epoch:  383  	Training Loss: 0.0010141097009181976
Test Loss:  0.0006887546041980386
Valid Loss:  0.0010593363549560308
Epoch:  384  	Training Loss: 0.001013173721730709
Test Loss:  0.0006884814938530326
Valid Loss:  0.001059279777109623
Epoch:  385  	Training Loss: 0.0010122685926035047
Test Loss:  0.0006881573353894055
Valid Loss:  0.0010591354221105576
Epoch:  386  	Training Loss: 0.0010114064207300544
Test Loss:  0.0006878144340589643
Valid Loss:  0.0010590017773211002
Epoch:  387  	Training Loss: 0.0010105571709573269
Test Loss:  0.0006874559330753982
Valid Loss:  0.0010588476434350014
Epoch:  388  	Training Loss: 0.001009717001579702
Test Loss:  0.0006870838697068393
Valid Loss:  0.0010586660355329514
Epoch:  389  	Training Loss: 0.0010088863782584667
Test Loss:  0.0006866989424452186
Valid Loss:  0.0010584628907963634
Epoch:  390  	Training Loss: 0.0010080637875944376
Test Loss:  0.0006863130838610232
Valid Loss:  0.0010582387913018465
Epoch:  391  	Training Loss: 0.001007247599773109
Test Loss:  0.0006859547575004399
Valid Loss:  0.001057996996678412
Epoch:  392  	Training Loss: 0.0010064380476251245
Test Loss:  0.0006856675026938319
Valid Loss:  0.001057422487065196
Epoch:  393  	Training Loss: 0.0010047327959910035
Test Loss:  0.0006853934610262513
Valid Loss:  0.0010566574055701494
Epoch:  394  	Training Loss: 0.001003460492938757
Test Loss:  0.0006850177887827158
Valid Loss:  0.00105578382499516
Epoch:  395  	Training Loss: 0.0010023122886195779
Test Loss:  0.000684681348502636
Valid Loss:  0.0010551459854468703
Epoch:  396  	Training Loss: 0.0010012640850618482
Test Loss:  0.0006843380397185683
Valid Loss:  0.001054186373949051
Epoch:  397  	Training Loss: 0.0010003113420680165
Test Loss:  0.000683971680700779
Valid Loss:  0.0010530404979363084
Epoch:  398  	Training Loss: 0.0009994744323194027
Test Loss:  0.0006837510736659169
Valid Loss:  0.001051906030625105
Epoch:  399  	Training Loss: 0.0009987178491428494
Test Loss:  0.0006834059022367001
Valid Loss:  0.0010504013625904918
Epoch:  400  	Training Loss: 0.0009982702322304249
Test Loss:  0.000683200138155371
Valid Loss:  0.0010490198619663715
Epoch:  401  	Training Loss: 0.000997826922684908
Test Loss:  0.0006830311613157392
Valid Loss:  0.001047785859555006
Epoch:  402  	Training Loss: 0.0009974009590223432
Test Loss:  0.0006829715566709638
Valid Loss:  0.0010469375411048532
Epoch:  403  	Training Loss: 0.0009966599754989147
Test Loss:  0.0006826515891589224
Valid Loss:  0.0010459762997925282
Epoch:  404  	Training Loss: 0.0009960199240595102
Test Loss:  0.0006823234143666923
Valid Loss:  0.0010450697736814618
Epoch:  405  	Training Loss: 0.0009953842964023352
Test Loss:  0.000681992678437382
Valid Loss:  0.0010441937483847141
Epoch:  406  	Training Loss: 0.000994750764220953
Test Loss:  0.0006816609529778361
Valid Loss:  0.0010433655697852373
Epoch:  407  	Training Loss: 0.0009941193275153637
Test Loss:  0.0006813324289396405
Valid Loss:  0.0010425812797620893
Epoch:  408  	Training Loss: 0.0009934878908097744
Test Loss:  0.0006810061167925596
Valid Loss:  0.0010418039746582508
Epoch:  409  	Training Loss: 0.0009928853251039982
Test Loss:  0.0006805560551583767
Valid Loss:  0.0010409317910671234
Epoch:  410  	Training Loss: 0.0009923211764544249
Test Loss:  0.0006801306735724211
Valid Loss:  0.001040079165250063
Epoch:  411  	Training Loss: 0.0009917794959619641
Test Loss:   82%|████████▏ | 411/500 [05:04<01:44,  1.18s/it] 83%|████████▎ | 413/500 [05:04<01:13,  1.18it/s] 83%|████████▎ | 415/500 [05:04<00:51,  1.63it/s] 83%|████████▎ | 417/500 [05:05<00:37,  2.23it/s] 84%|████████▍ | 419/500 [05:05<00:27,  2.98it/s] 84%|████████▍ | 421/500 [05:11<01:34,  1.19s/it] 85%|████████▍ | 423/500 [05:11<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:11<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:11<00:33,  2.20it/s] 86%|████████▌ | 429/500 [05:12<00:24,  2.95it/s] 86%|████████▌ | 431/500 [05:18<01:21,  1.19s/it] 87%|████████▋ | 433/500 [05:18<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:18<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:18<00:28,  2.21it/s] 88%|████████▊ | 439/500 [05:19<00:20,  2.95it/s] 88%|████████▊ | 441/500 [05:25<01:12,  1.23s/it] 89%|████████▊ | 443/500 [05:25<00:50,  1.13it/s] 89%|████████▉ | 445/500 [05:25<00:35,  1.57it/s] 89%|████████▉ | 447/500 [05:26<00:24,  2.14it/s] 90%|████████▉ | 449/500 [05:26<00:17,  2.89it/s] 90%|█████████ | 451/500 [05:32<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:32<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:32<00:27,  1.61it/s] 91%|█████████▏| 457/500 [05:32<00:19,  2.20it/s] 92%|█████████▏| 459/500 [05:33<00:13,  2.95it/s] 92%|█████████▏| 461/500 [05:39<00:45,  1.18s/it] 93%|█████████▎| 463/500 [05:39<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:39<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:39<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:39<00:10,  3.01it/s] 94%|█████████▍| 471/500 [05:46<00:34,  1.20s/it] 95%|█████████▍| 473/500 [05:46<00:23,  1.16it/s] 95%|█████████▌| 475/500 [05:46<00:15,  1.60it/s] 95%|█████████▌| 477/500 [05:46<00:10,  2.19it/s] 96%|█████████▌| 479/500 [05:46<00:07,  2.94it/s]0.0006794433575123549
Valid Loss:  0.0010390137322247028
Epoch:  412  	Training Loss: 0.000991262262687087
Test Loss:  0.0006761782569810748
Valid Loss:  0.001035864232107997
Epoch:  413  	Training Loss: 0.0009886027546599507
Test Loss:  0.0006738239899277687
Valid Loss:  0.001033357810229063
Epoch:  414  	Training Loss: 0.0009862014558166265
Test Loss:  0.0006714960327371955
Valid Loss:  0.0010309562785550952
Epoch:  415  	Training Loss: 0.000983819947578013
Test Loss:  0.0006692442111670971
Valid Loss:  0.0010286248289048672
Epoch:  416  	Training Loss: 0.0009814699878916144
Test Loss:  0.000667040585540235
Valid Loss:  0.0010263366857543588
Epoch:  417  	Training Loss: 0.0009791506454348564
Test Loss:  0.0006649119313806295
Valid Loss:  0.0010240820702165365
Epoch:  418  	Training Loss: 0.000976920360699296
Test Loss:  0.0006630441639572382
Valid Loss:  0.0010220310650765896
Epoch:  419  	Training Loss: 0.0009747351286932826
Test Loss:  0.0006614000885747373
Valid Loss:  0.0010201463010162115
Epoch:  420  	Training Loss: 0.0009725906420499086
Test Loss:  0.0006597104365937412
Valid Loss:  0.0010182353435084224
Epoch:  421  	Training Loss: 0.0009704689728096128
Test Loss:  0.0006580083863809705
Valid Loss:  0.0010163072729483247
Epoch:  422  	Training Loss: 0.0009683542884886265
Test Loss:  0.0006582839414477348
Valid Loss:  0.0010162070393562317
Epoch:  423  	Training Loss: 0.0009678081842139363
Test Loss:  0.000658684759400785
Valid Loss:  0.0010161002865061164
Epoch:  424  	Training Loss: 0.0009673425811342895
Test Loss:  0.0006588132819160819
Valid Loss:  0.0010157620999962091
Epoch:  425  	Training Loss: 0.0009669631253927946
Test Loss:  0.0006589826662093401
Valid Loss:  0.0010154735064134002
Epoch:  426  	Training Loss: 0.0009665964171290398
Test Loss:  0.0006591599085368216
Valid Loss:  0.0010151916649192572
Epoch:  427  	Training Loss: 0.0009662512456998229
Test Loss:  0.0006593590369448066
Valid Loss:  0.0010149036534130573
Epoch:  428  	Training Loss: 0.0009659210918471217
Test Loss:  0.000659542391076684
Valid Loss:  0.0010145942214876413
Epoch:  429  	Training Loss: 0.0009656050242483616
Test Loss:  0.000659591518342495
Valid Loss:  0.001014180132187903
Epoch:  430  	Training Loss: 0.000965343788266182
Test Loss:  0.000659672194160521
Valid Loss:  0.0010137902572751045
Epoch:  431  	Training Loss: 0.0009651280706748366
Test Loss:  0.0006594941369257867
Valid Loss:  0.0010131875751540065
Epoch:  432  	Training Loss: 0.0009649511775933206
Test Loss:  0.0006590742850676179
Valid Loss:  0.001012345775961876
Epoch:  433  	Training Loss: 0.0009648061823099852
Test Loss:  0.000658719683997333
Valid Loss:  0.0010116510093212128
Epoch:  434  	Training Loss: 0.000964681850746274
Test Loss:  0.0006583661306649446
Valid Loss:  0.0010109047871083021
Epoch:  435  	Training Loss: 0.0009645584505051374
Test Loss:  0.0006580663030035794
Valid Loss:  0.0010102970991283655
Epoch:  436  	Training Loss: 0.000964452454354614
Test Loss:  0.0006577622843906283
Valid Loss:  0.0010096357436850667
Epoch:  437  	Training Loss: 0.0009643491939641535
Test Loss:  0.0006574894650839269
Valid Loss:  0.0010090128052979708
Epoch:  438  	Training Loss: 0.0009642650256864727
Test Loss:  0.0006572977872565389
Valid Loss:  0.0010086089605465531
Epoch:  439  	Training Loss: 0.0009641866781748831
Test Loss:  0.0006570701953023672
Valid Loss:  0.0010080551728606224
Epoch:  440  	Training Loss: 0.000964110775385052
Test Loss:  0.0006568549433723092
Valid Loss:  0.0010075299069285393
Epoch:  441  	Training Loss: 0.0009640424977988005
Test Loss:  0.0006566498777829111
Valid Loss:  0.0010070321150124073
Epoch:  442  	Training Loss: 0.0009639784111641347
Test Loss:  0.0006564764771610498
Valid Loss:  0.001006679143756628
Epoch:  443  	Training Loss: 0.0009639579220674932
Test Loss:  0.000656356627587229
Valid Loss:  0.0010064132511615753
Epoch:  444  	Training Loss: 0.0009639399941079319
Test Loss:  0.0006562555790878832
Valid Loss:  0.001006175996735692
Epoch:  445  	Training Loss: 0.0009639231720939279
Test Loss:  0.0006561623304150999
Valid Loss:  0.0010059557389467955
Epoch:  446  	Training Loss: 0.000963907572440803
Test Loss:  0.0006560742040164769
Valid Loss:  0.0010057439794763923
Epoch:  447  	Training Loss: 0.0009638922056183219
Test Loss:  0.000655989395454526
Valid Loss:  0.0010055386228486896
Epoch:  448  	Training Loss: 0.0009638767223805189
Test Loss:  0.0006559067987836897
Valid Loss:  0.0010053403675556183
Epoch:  449  	Training Loss: 0.0009638626361265779
Test Loss:  0.0006558257155120373
Valid Loss:  0.0010051457211375237
Epoch:  450  	Training Loss: 0.0009638480842113495
Test Loss:  0.0006557493470609188
Valid Loss:  0.001004961202852428
Epoch:  451  	Training Loss: 0.0009638354531489313
Test Loss:  0.0006556749576702714
Valid Loss:  0.0010047799441963434
Epoch:  452  	Training Loss: 0.0009638221235945821
Test Loss:  0.0006555898580700159
Valid Loss:  0.0010045572416856885
Epoch:  453  	Training Loss: 0.0009638131596148014
Test Loss:  0.0006555016152560711
Valid Loss:  0.0010043333750218153
Epoch:  454  	Training Loss: 0.0009638053015805781
Test Loss:  0.0006554157007485628
Valid Loss:  0.0010041160276159644
Epoch:  455  	Training Loss: 0.0009637978509999812
Test Loss:  0.0006553331622853875
Valid Loss:  0.0010039075277745724
Epoch:  456  	Training Loss: 0.0009637918556109071
Test Loss:  0.0006552543491125107
Valid Loss:  0.001003706594929099
Epoch:  457  	Training Loss: 0.0009637851035222411
Test Loss:  0.000655179494060576
Valid Loss:  0.0010035157902166247
Epoch:  458  	Training Loss: 0.0009637797484174371
Test Loss:  0.0006551075493916869
Valid Loss:  0.0010033330181613564
Epoch:  459  	Training Loss: 0.0009637748589739203
Test Loss:  0.0006550385151058435
Valid Loss:  0.001003159093670547
Epoch:  460  	Training Loss: 0.0009637697949074209
Test Loss:  0.0006549728568643332
Valid Loss:  0.0010029925033450127
Epoch:  461  	Training Loss: 0.0009637656039558351
Test Loss:  0.000654909759759903
Valid Loss:  0.0010028313845396042
Epoch:  462  	Training Loss: 0.0009637619368731976
Test Loss:  0.000654371571727097
Valid Loss:  0.001002151402644813
Epoch:  463  	Training Loss: 0.0009634377784095705
Test Loss:  0.0006538296001963317
Valid Loss:  0.00100146874319762
Epoch:  464  	Training Loss: 0.0009631194989196956
Test Loss:  0.0006533299456350505
Valid Loss:  0.0010008069220930338
Epoch:  465  	Training Loss: 0.0009628284024074674
Test Loss:  0.0006528556114062667
Valid Loss:  0.0010001752525568008
Epoch:  466  	Training Loss: 0.0009625514503568411
Test Loss:  0.0006524185300804675
Valid Loss:  0.00099955964833498
Epoch:  467  	Training Loss: 0.0009622907382436097
Test Loss:  0.0006520657916553319
Valid Loss:  0.0009990213438868523
Epoch:  468  	Training Loss: 0.0009620796190574765
Test Loss:  0.0006517220172099769
Valid Loss:  0.0009985003853216767
Epoch:  469  	Training Loss: 0.0009618715266697109
Test Loss:  0.0006513959961012006
Valid Loss:  0.0009979945607483387
Epoch:  470  	Training Loss: 0.0009616708848625422
Test Loss:  0.0006511014071293175
Valid Loss:  0.000997517490759492
Epoch:  471  	Training Loss: 0.0009614789159968495
Test Loss:  0.0006508150254376233
Valid Loss:  0.000997075461782515
Epoch:  472  	Training Loss: 0.0009612911380827427
Test Loss:  0.000647133041638881
Valid Loss:  0.0009938335279002786
Epoch:  473  	Training Loss: 0.0009583007777109742
Test Loss:  0.0006441526347771287
Valid Loss:  0.0009913776302710176
Epoch:  474  	Training Loss: 0.0009559959289617836
Test Loss:  0.0006417265394702554
Valid Loss:  0.0009892877424135804
Epoch:  475  	Training Loss: 0.0009540601167827845
Test Loss:  0.0006398538243956864
Valid Loss:  0.0009874989045783877
Epoch:  476  	Training Loss: 0.0009524659835733473
Test Loss:  0.0006382777355611324
Valid Loss:  0.0009859598940238357
Epoch:  477  	Training Loss: 0.0009510149247944355
Test Loss:  0.000636909855529666
Valid Loss:  0.0009847290348261595
Epoch:  478  	Training Loss: 0.0009497207356616855
Test Loss:  0.0006356311496347189
Valid Loss:  0.0009836675599217415
Epoch:  479  	Training Loss: 0.0009485021000728011
Test Loss:  0.0006345990113914013
Valid Loss:  0.00098277791403234
 96%|█████████▌| 481/500 [05:53<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:53<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:53<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:53<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:53<00:03,  2.99it/s] 98%|█████████▊| 491/500 [06:00<00:10,  1.19s/it] 99%|█████████▊| 493/500 [06:00<00:05,  1.17it/s] 99%|█████████▉| 495/500 [06:00<00:03,  1.61it/s] 99%|█████████▉| 497/500 [06:00<00:01,  2.19it/s]100%|█████████▉| 499/500 [06:00<00:00,  2.95it/s]100%|██████████| 500/500 [06:00<00:00,  1.39it/s]
Epoch:  480  	Training Loss: 0.0009474465623497963
Test Loss:  0.0006337472004815936
Valid Loss:  0.0009820376290008426
Epoch:  481  	Training Loss: 0.0009464945178478956
Test Loss:  0.0006330401520244777
Valid Loss:  0.0009814901277422905
Epoch:  482  	Training Loss: 0.0009456092375330627
Test Loss:  0.0006329866591840982
Valid Loss:  0.0009817987447604537
Epoch:  483  	Training Loss: 0.0009451633086428046
Test Loss:  0.0006330258911475539
Valid Loss:  0.0009820004925131798
Epoch:  484  	Training Loss: 0.0009448170894756913
Test Loss:  0.0006330652395263314
Valid Loss:  0.0009821945568546653
Epoch:  485  	Training Loss: 0.000944543513469398
Test Loss:  0.0006330923642963171
Valid Loss:  0.000982364872470498
Epoch:  486  	Training Loss: 0.0009442887385375798
Test Loss:  0.0006331414915621281
Valid Loss:  0.0009825511369854212
Epoch:  487  	Training Loss: 0.0009440594003535807
Test Loss:  0.0006332044722512364
Valid Loss:  0.0009826543973758817
Epoch:  488  	Training Loss: 0.0009438535198569298
Test Loss:  0.0006333492347039282
Valid Loss:  0.0009827453177422285
Epoch:  489  	Training Loss: 0.0009436962427571416
Test Loss:  0.0006334707140922546
Valid Loss:  0.0009828206384554505
Epoch:  490  	Training Loss: 0.0009435844840481877
Test Loss:  0.000633618445135653
Valid Loss:  0.0009828879265114665
Epoch:  491  	Training Loss: 0.0009434884414076805
Test Loss:  0.0006337456870824099
Valid Loss:  0.000982940779067576
Epoch:  492  	Training Loss: 0.0009434136445634067
Test Loss:  0.0006345543661154807
Valid Loss:  0.0009836101671680808
Epoch:  493  	Training Loss: 0.0009431748185306787
Test Loss:  0.0006352105410769582
Valid Loss:  0.0009841211140155792
Epoch:  494  	Training Loss: 0.000942990998737514
Test Loss:  0.0006357551319524646
Valid Loss:  0.0009845145978033543
Epoch:  495  	Training Loss: 0.0009428627090528607
Test Loss:  0.0006361033301800489
Valid Loss:  0.000984726008027792
Epoch:  496  	Training Loss: 0.0009427661425434053
Test Loss:  0.0006364218425005674
Valid Loss:  0.0009849346242845058
Epoch:  497  	Training Loss: 0.0009426758042536676
Test Loss:  0.0006367145106196404
Valid Loss:  0.000985137652605772
Epoch:  498  	Training Loss: 0.0009425922762602568
Test Loss:  0.0006369841285049915
Valid Loss:  0.0009853038936853409
Epoch:  499  	Training Loss: 0.0009425277239643037
Test Loss:  0.0006371098570525646
Valid Loss:  0.0009853236842900515
Epoch:  500  	Training Loss: 0.0009424836607649922
Test Loss:  0.0006372444913722575
Valid Loss:  0.0009853425435721874
seed is  10
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:31, 15.98it/s]  1%|          | 4/500 [00:00<00:31, 15.96it/s]  1%|          | 6/500 [00:00<00:31, 15.89it/s]  2%|▏         | 8/500 [00:00<00:31, 15.84it/s]  2%|▏         | 10/500 [00:00<00:30, 15.91it/s]  2%|▏         | 12/500 [00:00<00:30, 15.99it/s]  3%|▎         | 14/500 [00:00<00:30, 16.02it/s]  3%|▎         | 16/500 [00:00<00:29, 16.20it/s]  4%|▎         | 18/500 [00:01<00:29, 16.26it/s]  4%|▍         | 20/500 [00:01<00:29, 16.33it/s]  4%|▍         | 22/500 [00:01<00:29, 16.31it/s]  5%|▍         | 24/500 [00:01<00:29, 16.23it/s]  5%|▌         | 26/500 [00:01<00:29, 16.30it/s]  6%|▌         | 28/500 [00:01<00:28, 16.40it/s]  6%|▌         | 30/500 [00:01<00:28, 16.25it/s]  6%|▋         | 32/500 [00:01<00:28, 16.19it/s]  7%|▋         | 34/500 [00:02<00:28, 16.25it/s]  7%|▋         | 36/500 [00:02<00:28, 16.25it/s]  8%|▊         | 38/500 [00:02<00:28, 16.22it/s]  8%|▊         | 40/500 [00:02<00:28, 16.15it/s]  8%|▊         | 42/500 [00:02<00:28, 16.16it/s]  9%|▉         | 44/500 [00:02<00:28, 16.22it/s]  9%|▉         | 46/500 [00:02<00:27, 16.28it/s] 10%|▉         | 48/500 [00:02<00:27, 16.30it/s] 10%|█         | 50/500 [00:03<00:27, 16.36it/s] 10%|█         | 52/500 [00:03<00:27, 16.36it/s] 11%|█         | 54/500 [00:03<00:27, 16.37it/s] 11%|█         | 56/500 [00:03<00:27, 16.37it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.40it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.40it/s] 12%|█▏        | 62/500 [00:03<00:28, 15.21it/s] 13%|█▎        | 64/500 [00:04<00:30, 14.14it/s] 13%|█▎        | 66/500 [00:04<00:30, 14.24it/s] 14%|█▎        | 68/500 [00:04<00:29, 14.84it/s] 14%|█▍        | 70/500 [00:04<00:28, 15.30it/s] 14%|█▍        | 72/500 [00:04<00:27, 15.60it/s] 15%|█▍        | 74/500 [00:04<00:27, 15.72it/s] 15%|█▌        | 76/500 [00:04<00:26, 15.90it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.04it/s] 16%|█▌        | 80/500 [00:05<00:26, 16.13it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.19it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.27it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.29it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.31it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.33it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.35it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.25it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.34it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.23it/s] 20%|██        | 100/500 [00:06<00:24, 16.23it/s] 20%|██        | 102/500 [00:06<00:24, 16.32it/s] 21%|██        | 104/500 [00:06<00:24, 16.26it/s] 21%|██        | 106/500 [00:06<00:24, 15.87it/s] 22%|██▏       | 108/500 [00:06<00:27, 14.44it/s] 22%|██▏       | 110/500 [00:06<00:28, 13.81it/s] 22%|██▏       | 112/500 [00:07<00:27, 14.33it/s] 23%|██▎       | 114/500 [00:07<00:27, 13.84it/s] 23%|██▎       | 116/500 [00:07<00:29, 13.21it/s] 24%|██▎       | 118/500 [00:07<00:29, 12.88it/s] 24%|██▍       | 120/500 [00:07<00:29, 12.68it/s] 24%|██▍       | 122/500 [00:07<00:28, 13.39it/s] 25%|██▍       | 124/500 [00:07<00:26, 14.15it/s]Epoch:  1  	Training Loss: 0.05188731104135513
Test Loss:  362.21539306640625
Valid Loss:  361.93499755859375
Epoch:  2  	Training Loss: 364.5562744140625
Test Loss:  66632630272.0
Valid Loss:  66680545280.0
Epoch:  3  	Training Loss: 66618818560.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:25, 14.76it/s] 26%|██▌       | 128/500 [00:08<00:24, 15.20it/s] 26%|██▌       | 130/500 [00:08<00:25, 14.51it/s] 26%|██▋       | 132/500 [00:08<00:27, 13.62it/s] 27%|██▋       | 134/500 [00:08<00:27, 13.17it/s] 27%|██▋       | 136/500 [00:08<00:28, 12.79it/s] 28%|██▊       | 138/500 [00:09<00:28, 12.55it/s] 28%|██▊       | 140/500 [00:09<00:28, 12.64it/s] 28%|██▊       | 142/500 [00:09<00:26, 13.55it/s] 29%|██▉       | 144/500 [00:09<00:25, 14.19it/s] 29%|██▉       | 146/500 [00:09<00:24, 14.72it/s] 30%|██▉       | 148/500 [00:09<00:23, 15.11it/s] 30%|███       | 150/500 [00:09<00:22, 15.42it/s] 30%|███       | 152/500 [00:09<00:22, 15.66it/s] 31%|███       | 154/500 [00:10<00:21, 15.82it/s] 31%|███       | 156/500 [00:10<00:21, 15.97it/s] 32%|███▏      | 158/500 [00:10<00:21, 16.06it/s] 32%|███▏      | 160/500 [00:10<00:21, 16.05it/s] 32%|███▏      | 162/500 [00:10<00:21, 16.08it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.16it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.21it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.26it/s] 34%|███▍      | 170/500 [00:11<00:20, 16.25it/s] 34%|███▍      | 172/500 [00:11<00:20, 16.33it/s] 35%|███▍      | 174/500 [00:11<00:19, 16.34it/s] 35%|███▌      | 176/500 [00:11<00:19, 16.22it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.25it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.01it/s] 36%|███▋      | 182/500 [00:11<00:20, 15.37it/s] 37%|███▋      | 184/500 [00:11<00:20, 15.11it/s] 37%|███▋      | 186/500 [00:12<00:20, 15.51it/s] 38%|███▊      | 188/500 [00:12<00:19, 15.75it/s] 38%|███▊      | 190/500 [00:12<00:19, 15.96it/s] 38%|███▊      | 192/500 [00:12<00:19, 15.93it/s] 39%|███▉      | 194/500 [00:12<00:19, 16.09it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.16it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.21it/s] 40%|████      | 200/500 [00:12<00:18, 16.28it/s] 40%|████      | 202/500 [00:13<00:18, 16.26it/s] 41%|████      | 204/500 [00:13<00:18, 16.09it/s] 41%|████      | 206/500 [00:13<00:18, 16.16it/s] 42%|████▏     | 208/500 [00:13<00:18, 16.21it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.28it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.34it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.33it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.38it/s] 44%|████▎     | 218/500 [00:14<00:18, 15.57it/s] 44%|████▍     | 220/500 [00:14<00:17, 15.65it/s] 44%|████▍     | 222/500 [00:14<00:17, 15.84it/s] 45%|████▍     | 224/500 [00:14<00:17, 16.02it/s] 45%|████▌     | 226/500 [00:14<00:17, 16.10it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.14it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.11it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.04it/s] 47%|████▋     | 234/500 [00:15<00:16, 16.11it/s] 47%|████▋     | 236/500 [00:15<00:16, 16.21it/s] 48%|████▊     | 238/500 [00:15<00:16, 16.26it/s] 48%|████▊     | 240/500 [00:15<00:16, 16.06it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.95it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.85it/s] 49%|████▉     | 246/500 [00:15<00:17, 14.47it/s] 50%|████▉     | 248/500 [00:15<00:17, 14.24it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:16, 14.71it/s] 50%|█████     | 252/500 [00:16<00:16, 15.16it/s] 51%|█████     | 254/500 [00:16<00:15, 15.44it/s] 51%|█████     | 256/500 [00:16<00:15, 15.68it/s] 52%|█████▏    | 258/500 [00:16<00:15, 15.93it/s] 52%|█████▏    | 260/500 [00:16<00:15, 15.83it/s] 52%|█████▏    | 262/500 [00:16<00:15, 15.75it/s] 53%|█████▎    | 264/500 [00:16<00:14, 15.76it/s] 53%|█████▎    | 266/500 [00:17<00:14, 15.77it/s] 54%|█████▎    | 268/500 [00:17<00:14, 15.98it/s] 54%|█████▍    | 270/500 [00:17<00:14, 16.16it/s] 54%|█████▍    | 272/500 [00:17<00:14, 16.08it/s] 55%|█████▍    | 274/500 [00:17<00:14, 15.97it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.04it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.01it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.09it/s] 56%|█████▋    | 282/500 [00:18<00:13, 16.18it/s] 57%|█████▋    | 284/500 [00:18<00:13, 16.24it/s] 57%|█████▋    | 286/500 [00:18<00:13, 15.52it/s] 58%|█████▊    | 288/500 [00:18<00:13, 15.53it/s] 58%|█████▊    | 290/500 [00:18<00:14, 14.58it/s] 58%|█████▊    | 292/500 [00:18<00:13, 15.06it/s] 59%|█████▉    | 294/500 [00:18<00:13, 15.41it/s] 59%|█████▉    | 296/500 [00:19<00:12, 15.70it/s] 60%|█████▉    | 298/500 [00:19<00:12, 15.96it/s] 60%|██████    | 300/500 [00:19<00:12, 16.09it/s] 60%|██████    | 302/500 [00:19<00:12, 16.18it/s] 61%|██████    | 304/500 [00:19<00:12, 16.27it/s] 61%|██████    | 306/500 [00:19<00:11, 16.32it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.33it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.36it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.44it/s] 63%|██████▎   | 314/500 [00:20<00:11, 16.32it/s] 63%|██████▎   | 316/500 [00:20<00:11, 16.24it/s] 64%|██████▎   | 318/500 [00:20<00:11, 16.15it/s] 64%|██████▍   | 320/500 [00:20<00:11, 16.20it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.24it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.28it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.38it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.39it/s] 66%|██████▌   | 330/500 [00:21<00:10, 16.36it/s] 66%|██████▋   | 332/500 [00:21<00:10, 16.42it/s] 67%|██████▋   | 334/500 [00:21<00:10, 16.37it/s] 67%|██████▋   | 336/500 [00:21<00:10, 16.24it/s] 68%|██████▊   | 338/500 [00:21<00:09, 16.24it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.23it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.18it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.18it/s] 69%|██████▉   | 346/500 [00:22<00:09, 16.20it/s] 70%|██████▉   | 348/500 [00:22<00:09, 16.23it/s] 70%|███████   | 350/500 [00:22<00:09, 16.24it/s] 70%|███████   | 352/500 [00:22<00:09, 16.26it/s] 71%|███████   | 354/500 [00:22<00:09, 16.19it/s] 71%|███████   | 356/500 [00:22<00:08, 16.17it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.25it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.14it/s] 72%|███████▏  | 362/500 [00:23<00:08, 16.06it/s] 73%|███████▎  | 364/500 [00:23<00:08, 16.17it/s] 73%|███████▎  | 366/500 [00:23<00:08, 16.18it/s] 74%|███████▎  | 368/500 [00:23<00:08, 16.22it/s] 74%|███████▍  | 370/500 [00:23<00:08, 16.10it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.10it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.17it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.22it/s] 76%|███████▌  | 378/500 [00:24<00:07, 16.25it/s] 76%|███████▌  | 380/500 [00:24<00:07, 16.19it/s] 76%|███████▋  | 382/500 [00:24<00:07, 16.20it/s] 77%|███████▋  | 384/500 [00:24<00:07, 16.21it/s] 77%|███████▋  | 386/500 [00:24<00:06, 16.30it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.23it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.40it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.41it/s] 79%|███████▉  | 394/500 [00:25<00:06, 16.26it/s] 79%|███████▉  | 396/500 [00:25<00:06, 16.33it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.16it/s] 80%|████████  | 400/500 [00:25<00:06, 16.23it/s] 80%|████████  | 402/500 [00:25<00:06, 16.07it/s] 81%|████████  | 404/500 [00:25<00:05, 16.18it/s] 81%|████████  | 406/500 [00:25<00:05, 16.23it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.26it/s] 82%|████████▏ | 410/500 [00:26<00:05, 16.26it/s] 82%|████████▏ | 412/500 [00:26<00:05, 16.26it/s] 83%|████████▎ | 414/500 [00:26<00:05, 16.15it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.23it/s] 84%|████████▎ | 418/500 [00:26<00:05, 15.44it/s] 84%|████████▍ | 420/500 [00:26<00:05, 15.71it/s] 84%|████████▍ | 422/500 [00:26<00:04, 15.83it/s] 85%|████████▍ | 424/500 [00:26<00:04, 15.77it/s] 85%|████████▌ | 426/500 [00:27<00:04, 15.92it/s] 86%|████████▌ | 428/500 [00:27<00:04, 16.07it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.15it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.13it/s] 87%|████████▋ | 434/500 [00:27<00:04, 16.07it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.13it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.21it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.24it/s] 88%|████████▊ | 442/500 [00:28<00:03, 16.25it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.24it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.16it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.29it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.26it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.12it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.13it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.25it/s] 92%|█████████▏| 458/500 [00:29<00:02, 16.22it/s] 92%|█████████▏| 460/500 [00:29<00:02, 15.99it/s] 92%|█████████▏| 462/500 [00:29<00:02, 16.04it/s] 93%|█████████▎| 464/500 [00:29<00:02, 16.15it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.31it/s] 94%|█████████▎| 468/500 [00:29<00:01, 16.14it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.04it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.02it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.02it/s] 95%|█████████▌| 476/500 [00:30<00:01, 16.08it/s] 96%|█████████▌| 478/500 [00:30<00:01, 16.04it/s] 96%|█████████▌| 480/500 [00:30<00:01, 16.16it/s] 96%|█████████▋| 482/500 [00:30<00:01, 16.17it/s] 97%|█████████▋| 484/500 [00:30<00:00, 16.15it/s] 97%|█████████▋| 486/500 [00:30<00:00, 16.25it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.20it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.17it/s] 98%|█████████▊| 492/500 [00:31<00:00, 16.22it/s] 99%|█████████▉| 494/500 [00:31<00:00, 16.23it/s] 99%|█████████▉| 496/500 [00:31<00:00, 15.94it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 15.91it/s]100%|██████████| 500/500 [00:31<00:00, 16.03it/s]100%|██████████| 500/500 [00:31<00:00, 15.82it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  10
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:02,  6.26s/it]  1%|          | 3/500 [00:06<14:00,  1.69s/it]  1%|          | 5/500 [00:06<07:08,  1.16it/s]  1%|▏         | 7/500 [00:06<04:23,  1.87it/s]  2%|▏         | 9/500 [00:06<02:57,  2.76it/s]  2%|▏         | 11/500 [00:13<11:03,  1.36s/it]  3%|▎         | 13/500 [00:13<07:31,  1.08it/s]  3%|▎         | 15/500 [00:13<05:16,  1.53it/s]  3%|▎         | 17/500 [00:13<03:46,  2.14it/s]  4%|▍         | 19/500 [00:13<02:44,  2.92it/s]  4%|▍         | 21/500 [00:20<09:37,  1.21s/it]  5%|▍         | 23/500 [00:20<06:50,  1.16it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:33,  2.21it/s]  6%|▌         | 29/500 [00:20<02:38,  2.97it/s]  6%|▌         | 31/500 [00:27<09:13,  1.18s/it]  7%|▋         | 33/500 [00:27<06:35,  1.18it/s]  7%|▋         | 35/500 [00:27<04:45,  1.63it/s]  7%|▋         | 37/500 [00:27<03:28,  2.22it/s]  8%|▊         | 39/500 [00:27<02:34,  2.99it/s]  8%|▊         | 41/500 [00:33<09:00,  1.18s/it]  9%|▊         | 43/500 [00:34<06:29,  1.17it/s]  9%|▉         | 45/500 [00:34<04:43,  1.61it/s]  9%|▉         | 47/500 [00:34<03:28,  2.17it/s] 10%|▉         | 49/500 [00:34<02:34,  2.92it/s] 10%|█         | 51/500 [00:40<08:55,  1.19s/it] 11%|█         | 53/500 [00:41<06:25,  1.16it/s] 11%|█         | 55/500 [00:41<04:38,  1.60it/s] 11%|█▏        | 57/500 [00:41<03:23,  2.17it/s] 12%|█▏        | 59/500 [00:41<02:30,  2.93it/s] 12%|█▏        | 61/500 [00:48<09:00,  1.23s/it] 13%|█▎        | 63/500 [00:48<06:25,  1.13it/s] 13%|█▎        | 65/500 [00:48<04:37,  1.57it/s] 13%|█▎        | 67/500 [00:48<03:21,  2.15it/s] 14%|█▍        | 69/500 [00:48<02:29,  2.89it/s] 14%|█▍        | 71/500 [00:54<08:32,  1.19s/it]Epoch:  1  	Training Loss: 0.05188731104135513
Test Loss:  8.53350830078125
Valid Loss:  8.557531356811523
Epoch:  2  	Training Loss: 8.431495666503906
Test Loss:  0.06987506151199341
Valid Loss:  0.07028143107891083
Epoch:  3  	Training Loss: 0.058481864631175995
Test Loss:  0.06916554272174835
Valid Loss:  0.0695544108748436
Epoch:  4  	Training Loss: 0.057904355227947235
Test Loss:  0.0684662014245987
Valid Loss:  0.06883779168128967
Epoch:  5  	Training Loss: 0.05733557790517807
Test Loss:  0.0677768737077713
Valid Loss:  0.06813140958547592
Epoch:  6  	Training Loss: 0.05677538365125656
Test Loss:  0.06709741055965424
Valid Loss:  0.06743508577346802
Epoch:  7  	Training Loss: 0.05622362717986107
Test Loss:  0.06642763316631317
Valid Loss:  0.06674866378307343
Epoch:  8  	Training Loss: 0.05568016692996025
Test Loss:  0.06576739251613617
Valid Loss:  0.06607198715209961
Epoch:  9  	Training Loss: 0.055144861340522766
Test Loss:  0.06511653959751129
Valid Loss:  0.06540490686893463
Epoch:  10  	Training Loss: 0.05461758002638817
Test Loss:  0.064474917948246
Valid Loss:  0.06474725157022476
Epoch:  11  	Training Loss: 0.05409817770123482
Test Loss:  0.06384237855672836
Valid Loss:  0.06409889459609985
Epoch:  12  	Training Loss: 0.053586531430482864
Test Loss:  0.06323762983083725
Valid Loss:  0.06347774714231491
Epoch:  13  	Training Loss: 0.053097568452358246
Test Loss:  0.06264112889766693
Valid Loss:  0.06286504864692688
Epoch:  14  	Training Loss: 0.052615728229284286
Test Loss:  0.062052737921476364
Valid Loss:  0.06226063519716263
Epoch:  15  	Training Loss: 0.052140891551971436
Test Loss:  0.06147234886884689
Valid Loss:  0.0616643987596035
Epoch:  16  	Training Loss: 0.051672954112291336
Test Loss:  0.06104125455021858
Valid Loss:  0.061217598617076874
Epoch:  17  	Training Loss: 0.05131272226572037
Test Loss:  0.06072847172617912
Valid Loss:  0.06089634448289871
Epoch:  18  	Training Loss: 0.05106159299612045
Test Loss:  0.06042250245809555
Valid Loss:  0.06058143079280853
Epoch:  19  	Training Loss: 0.050815507769584656
Test Loss:  0.06012122333049774
Valid Loss:  0.06027548760175705
Epoch:  20  	Training Loss: 0.05057595670223236
Test Loss:  0.05985637381672859
Valid Loss:  0.06000130996108055
Epoch:  21  	Training Loss: 0.0503607839345932
Test Loss:  0.05963151901960373
Valid Loss:  0.05976208671927452
Epoch:  22  	Training Loss: 0.05017038434743881
Test Loss:  0.05942372605204582
Valid Loss:  0.05955344811081886
Epoch:  23  	Training Loss: 0.050004154443740845
Test Loss:  0.059320077300071716
Valid Loss:  0.0594334602355957
Epoch:  24  	Training Loss: 0.04990483820438385
Test Loss:  0.05927703157067299
Valid Loss:  0.05938871204853058
Epoch:  25  	Training Loss: 0.049864254891872406
Test Loss:  0.059257909655570984
Valid Loss:  0.059371985495090485
Epoch:  26  	Training Loss: 0.04984888806939125
Test Loss:  0.05924820899963379
Valid Loss:  0.059363603591918945
Epoch:  27  	Training Loss: 0.04984213784337044
Test Loss:  0.059242695569992065
Valid Loss:  0.059358011931180954
Epoch:  28  	Training Loss: 0.04983796551823616
Test Loss:  0.05923844873905182
Valid Loss:  0.05935381352901459
Epoch:  29  	Training Loss: 0.04983469098806381
Test Loss:  0.059235841035842896
Valid Loss:  0.05935113504528999
Epoch:  30  	Training Loss: 0.04983227699995041
Test Loss:  0.0592336431145668
Valid Loss:  0.05934937298297882
Epoch:  31  	Training Loss: 0.04983021318912506
Test Loss:  0.05923207104206085
Valid Loss:  0.05934787541627884
Epoch:  32  	Training Loss: 0.04982851445674896
Test Loss:  0.059230703860521317
Valid Loss:  0.059346698224544525
Epoch:  33  	Training Loss: 0.04982713982462883
Test Loss:  0.05922951549291611
Valid Loss:  0.05934567749500275
Epoch:  34  	Training Loss: 0.04982592165470123
Test Loss:  0.05922854319214821
Valid Loss:  0.05934479087591171
Epoch:  35  	Training Loss: 0.049824852496385574
Test Loss:  0.05922772362828255
Valid Loss:  0.05934402719140053
Epoch:  36  	Training Loss: 0.04982387647032738
Test Loss:  0.05922706425189972
Valid Loss:  0.05934334173798561
Epoch:  37  	Training Loss: 0.04982297495007515
Test Loss:  0.05922653526067734
Valid Loss:  0.05934276804327965
Epoch:  38  	Training Loss: 0.0498221330344677
Test Loss:  0.05922611430287361
Valid Loss:  0.05934230983257294
Epoch:  39  	Training Loss: 0.049821339547634125
Test Loss:  0.059225693345069885
Valid Loss:  0.059341929852962494
Epoch:  40  	Training Loss: 0.04982056841254234
Test Loss:  0.05922529101371765
Valid Loss:  0.05934160575270653
Epoch:  41  	Training Loss: 0.04981980472803116
Test Loss:  0.059224896132946014
Valid Loss:  0.05934127792716026
Epoch:  42  	Training Loss: 0.04981904476881027
Test Loss:  0.05922451615333557
Valid Loss:  0.059340979903936386
Epoch:  43  	Training Loss: 0.04981831833720207
Test Loss:  0.05922412872314453
Valid Loss:  0.0593407079577446
Epoch:  44  	Training Loss: 0.049817584455013275
Test Loss:  0.05922373756766319
Valid Loss:  0.05934043228626251
Epoch:  45  	Training Loss: 0.049816858023405075
Test Loss:  0.05922335386276245
Valid Loss:  0.05934016406536102
Epoch:  46  	Training Loss: 0.049816131591796875
Test Loss:  0.05922296643257141
Valid Loss:  0.059339892119169235
Epoch:  47  	Training Loss: 0.049815401434898376
Test Loss:  0.05922258272767067
Valid Loss:  0.05933961272239685
Epoch:  48  	Training Loss: 0.04981467127799988
Test Loss:  0.05922219529747963
Valid Loss:  0.059339359402656555
Epoch:  49  	Training Loss: 0.04981394112110138
Test Loss:  0.059221815317869186
Valid Loss:  0.05933911353349686
Epoch:  50  	Training Loss: 0.04981321841478348
Test Loss:  0.05922143906354904
Valid Loss:  0.05933886393904686
Epoch:  51  	Training Loss: 0.049812495708465576
Test Loss:  0.059221051633358
Valid Loss:  0.05933874100446701
Epoch:  52  	Training Loss: 0.04981178045272827
Test Loss:  0.05922064930200577
Valid Loss:  0.059338465332984924
Epoch:  53  	Training Loss: 0.04981103539466858
Test Loss:  0.059220246970653534
Valid Loss:  0.05933823436498642
Epoch:  54  	Training Loss: 0.049810294061899185
Test Loss:  0.059219829738140106
Valid Loss:  0.0593380406498909
Epoch:  55  	Training Loss: 0.04980955645442009
Test Loss:  0.05921943485736847
Valid Loss:  0.05933776870369911
Epoch:  56  	Training Loss: 0.049808815121650696
Test Loss:  0.05921902135014534
Valid Loss:  0.059337615966796875
Epoch:  57  	Training Loss: 0.0498080812394619
Test Loss:  0.059218622744083405
Valid Loss:  0.05933734029531479
Epoch:  58  	Training Loss: 0.049807339906692505
Test Loss:  0.05921822786331177
Valid Loss:  0.0593370646238327
Epoch:  59  	Training Loss: 0.04980660229921341
Test Loss:  0.05921780318021774
Valid Loss:  0.05933690816164017
Epoch:  60  	Training Loss: 0.049805864691734314
Test Loss:  0.059217408299446106
Valid Loss:  0.05933663249015808
Epoch:  61  	Training Loss: 0.04980512708425522
Test Loss:  0.05921699479222298
Valid Loss:  0.059336476027965546
Epoch:  62  	Training Loss: 0.04980438947677612
Test Loss:  0.05921662226319313
Valid Loss:  0.059336233884096146
Epoch:  63  	Training Loss: 0.04980367422103882
Test Loss:  0.059216246008872986
Valid Loss:  0.05933602899312973
Epoch:  64  	Training Loss: 0.049802958965301514
Test Loss:  0.059215862303972244
Valid Loss:  0.059335850179195404
Epoch:  65  	Training Loss: 0.04980224370956421
Test Loss:  0.0592154935002327
Valid Loss:  0.059335604310035706
Epoch:  66  	Training Loss: 0.049801528453826904
Test Loss:  0.05921510234475136
Valid Loss:  0.059335462749004364
Epoch:  67  	Training Loss: 0.0498008131980896
Test Loss:  0.05921473354101181
Valid Loss:  0.05933522433042526
Epoch:  68  	Training Loss: 0.049800097942352295
Test Loss:  0.05921434611082077
Valid Loss:  0.05933505296707153
Epoch:  69  	Training Loss: 0.04979938268661499
Test Loss:  0.05921398103237152
Valid Loss:  0.05933482572436333
Epoch:  70  	Training Loss: 0.049798667430877686
Test Loss:  0.05921359360218048
Valid Loss:  0.05933469533920288
Epoch:  71  	Training Loss: 0.04979795590043068
Test Loss:  0.05921322479844093
Valid Loss:  0.059334442019462585
Epoch:  72  	Training Loss: 0.049797240644693375
Test Loss:  0.05921279639005661
Valid Loss:  0.05933426693081856
 15%|█▍        | 73/500 [00:55<06:06,  1.17it/s] 15%|█▌        | 75/500 [00:55<04:23,  1.61it/s] 15%|█▌        | 77/500 [00:55<03:11,  2.20it/s] 16%|█▌        | 79/500 [00:55<02:21,  2.97it/s] 16%|█▌        | 81/500 [01:01<08:17,  1.19s/it] 17%|█▋        | 83/500 [01:01<05:55,  1.17it/s] 17%|█▋        | 85/500 [01:02<04:15,  1.62it/s] 17%|█▋        | 87/500 [01:02<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:02<02:18,  2.97it/s] 18%|█▊        | 91/500 [01:08<08:10,  1.20s/it] 19%|█▊        | 93/500 [01:08<05:50,  1.16it/s] 19%|█▉        | 95/500 [01:09<04:12,  1.60it/s] 19%|█▉        | 97/500 [01:09<03:04,  2.18it/s] 20%|█▉        | 99/500 [01:09<02:16,  2.93it/s] 20%|██        | 101/500 [01:15<07:56,  1.19s/it] 21%|██        | 103/500 [01:15<05:40,  1.17it/s] 21%|██        | 105/500 [01:16<04:05,  1.61it/s] 21%|██▏       | 107/500 [01:16<02:58,  2.20it/s] 22%|██▏       | 109/500 [01:16<02:11,  2.96it/s] 22%|██▏       | 111/500 [01:22<07:42,  1.19s/it] 23%|██▎       | 113/500 [01:22<05:30,  1.17it/s] 23%|██▎       | 115/500 [01:22<03:57,  1.62it/s] 23%|██▎       | 117/500 [01:23<02:53,  2.21it/s] 24%|██▍       | 119/500 [01:23<02:08,  2.98it/s] 24%|██▍       | 121/500 [01:29<07:29,  1.19s/it] 25%|██▍       | 123/500 [01:29<05:20,  1.17it/s] 25%|██▌       | 125/500 [01:29<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:29<02:48,  2.22it/s] 26%|██▌       | 129/500 [01:30<02:06,  2.94it/s] 26%|██▌       | 131/500 [01:36<07:26,  1.21s/it] 27%|██▋       | 133/500 [01:36<05:20,  1.15it/s] 27%|██▋       | 135/500 [01:36<03:52,  1.57it/s] 27%|██▋       | 137/500 [01:37<02:51,  2.12it/s] 28%|██▊       | 139/500 [01:37<02:08,  2.81it/s] 28%|██▊       | 141/500 [01:43<07:23,  1.23s/it] 29%|██▊       | 143/500 [01:43<05:15,  1.13it/s]Epoch:  73  	Training Loss: 0.04979649931192398
Test Loss:  0.05921238288283348
Valid Loss:  0.05933399870991707
Epoch:  74  	Training Loss: 0.04979574680328369
Test Loss:  0.05921196937561035
Valid Loss:  0.05933374911546707
Epoch:  75  	Training Loss: 0.049795001745224
Test Loss:  0.059211552143096924
Valid Loss:  0.059333525598049164
Epoch:  76  	Training Loss: 0.04979425668716431
Test Loss:  0.059211134910583496
Valid Loss:  0.05933326110243797
Epoch:  77  	Training Loss: 0.04979351535439491
Test Loss:  0.05921071022748947
Valid Loss:  0.059333086013793945
Epoch:  78  	Training Loss: 0.04979276657104492
Test Loss:  0.059210292994976044
Valid Loss:  0.05933281406760216
Epoch:  79  	Training Loss: 0.04979202151298523
Test Loss:  0.05920986831188202
Valid Loss:  0.05933263897895813
Epoch:  80  	Training Loss: 0.049791283905506134
Test Loss:  0.05920945852994919
Valid Loss:  0.05933234095573425
Epoch:  81  	Training Loss: 0.04979053512215614
Test Loss:  0.05920904129743576
Valid Loss:  0.05933214724063873
Epoch:  82  	Training Loss: 0.04978979378938675
Test Loss:  0.059208665043115616
Valid Loss:  0.05933188647031784
Epoch:  83  	Training Loss: 0.049789074808359146
Test Loss:  0.05920825153589249
Valid Loss:  0.059331730008125305
Epoch:  84  	Training Loss: 0.049788348376750946
Test Loss:  0.05920787155628204
Valid Loss:  0.05933148413896561
Epoch:  85  	Training Loss: 0.049787625670433044
Test Loss:  0.05920746549963951
Valid Loss:  0.05933133140206337
Epoch:  86  	Training Loss: 0.04978690296411514
Test Loss:  0.059207089245319366
Valid Loss:  0.05933109298348427
Epoch:  87  	Training Loss: 0.04978618770837784
Test Loss:  0.059206683188676834
Valid Loss:  0.059330932796001434
Epoch:  88  	Training Loss: 0.04978546127676964
Test Loss:  0.05920629948377609
Valid Loss:  0.059330690652132034
Epoch:  89  	Training Loss: 0.049784738570451736
Test Loss:  0.05920589715242386
Valid Loss:  0.0593305304646492
Epoch:  90  	Training Loss: 0.04978401958942413
Test Loss:  0.05920551344752312
Valid Loss:  0.0593302845954895
Epoch:  91  	Training Loss: 0.04978329688310623
Test Loss:  0.05920512601733208
Valid Loss:  0.05933009088039398
Epoch:  92  	Training Loss: 0.04978257417678833
Test Loss:  0.05920475348830223
Valid Loss:  0.059329867362976074
Epoch:  93  	Training Loss: 0.04978186637163162
Test Loss:  0.05920437350869179
Valid Loss:  0.059329718351364136
Epoch:  94  	Training Loss: 0.049781158566474915
Test Loss:  0.05920401215553284
Valid Loss:  0.05932946503162384
Epoch:  95  	Training Loss: 0.049780454486608505
Test Loss:  0.0592036247253418
Valid Loss:  0.059329356998205185
Epoch:  96  	Training Loss: 0.0497797466814518
Test Loss:  0.05920327454805374
Valid Loss:  0.05932909622788429
Epoch:  97  	Training Loss: 0.049779050052165985
Test Loss:  0.0592028871178627
Valid Loss:  0.05932898446917534
Epoch:  98  	Training Loss: 0.04977834224700928
Test Loss:  0.059202518314123154
Valid Loss:  0.059328727424144745
Epoch:  99  	Training Loss: 0.04977763816714287
Test Loss:  0.05920214205980301
Valid Loss:  0.05932861194014549
Epoch:  100  	Training Loss: 0.04977692663669586
Test Loss:  0.05920177698135376
Valid Loss:  0.0593283548951149
Epoch:  101  	Training Loss: 0.04977622628211975
Test Loss:  0.059201404452323914
Valid Loss:  0.05932825058698654
Epoch:  102  	Training Loss: 0.04977552592754364
Test Loss:  0.059201035648584366
Valid Loss:  0.05932801216840744
Epoch:  103  	Training Loss: 0.04977481812238693
Test Loss:  0.05920064076781273
Valid Loss:  0.059327851980924606
Epoch:  104  	Training Loss: 0.049774106591939926
Test Loss:  0.05920027196407318
Valid Loss:  0.0593276172876358
Epoch:  105  	Training Loss: 0.04977339878678322
Test Loss:  0.05919988453388214
Valid Loss:  0.05932746082544327
Epoch:  106  	Training Loss: 0.04977268725633621
Test Loss:  0.059199512004852295
Valid Loss:  0.05932721868157387
Epoch:  107  	Training Loss: 0.049771979451179504
Test Loss:  0.05919912829995155
Valid Loss:  0.05932707339525223
Epoch:  108  	Training Loss: 0.0497712716460228
Test Loss:  0.05919875204563141
Valid Loss:  0.05932682752609253
Epoch:  109  	Training Loss: 0.04977056384086609
Test Loss:  0.059198372066020966
Valid Loss:  0.05932669714093208
Epoch:  110  	Training Loss: 0.04976985603570938
Test Loss:  0.05919799581170082
Valid Loss:  0.05932646617293358
Epoch:  111  	Training Loss: 0.04976914823055267
Test Loss:  0.05919760465621948
Valid Loss:  0.05932634323835373
Epoch:  112  	Training Loss: 0.049768444150686264
Test Loss:  0.05919722840189934
Valid Loss:  0.059326060116291046
Epoch:  113  	Training Loss: 0.04976772516965866
Test Loss:  0.0591968297958374
Valid Loss:  0.0593259260058403
Epoch:  114  	Training Loss: 0.049767013639211655
Test Loss:  0.05919644981622696
Valid Loss:  0.05932566523551941
Epoch:  115  	Training Loss: 0.04976629465818405
Test Loss:  0.05919605493545532
Valid Loss:  0.059325505048036575
Epoch:  116  	Training Loss: 0.049765583127737045
Test Loss:  0.059195682406425476
Valid Loss:  0.05932525545358658
Epoch:  117  	Training Loss: 0.04976487159729004
Test Loss:  0.05919529125094414
Valid Loss:  0.05932511016726494
Epoch:  118  	Training Loss: 0.049764152616262436
Test Loss:  0.0591949038207531
Valid Loss:  0.059324827045202255
Epoch:  119  	Training Loss: 0.04976344108581543
Test Loss:  0.05919451266527176
Valid Loss:  0.05932468920946121
Epoch:  120  	Training Loss: 0.04976272955536842
Test Loss:  0.059194132685661316
Valid Loss:  0.0593244694173336
Epoch:  121  	Training Loss: 0.04976201057434082
Test Loss:  0.05919373035430908
Valid Loss:  0.05932430550456047
Epoch:  122  	Training Loss: 0.04976130276918411
Test Loss:  0.05919336527585983
Valid Loss:  0.05932404845952988
Epoch:  123  	Training Loss: 0.049760594964027405
Test Loss:  0.0591929629445076
Valid Loss:  0.05932391434907913
Epoch:  124  	Training Loss: 0.0497598759829998
Test Loss:  0.05919259786605835
Valid Loss:  0.05932366102933884
Epoch:  125  	Training Loss: 0.04975917190313339
Test Loss:  0.05919221043586731
Valid Loss:  0.059323500841856
Epoch:  126  	Training Loss: 0.04975845664739609
Test Loss:  0.05919183790683746
Valid Loss:  0.05932324379682541
Epoch:  127  	Training Loss: 0.04975775256752968
Test Loss:  0.059191443026065826
Valid Loss:  0.05932311713695526
Epoch:  128  	Training Loss: 0.049757033586502075
Test Loss:  0.05919106304645538
Valid Loss:  0.05932290107011795
Epoch:  129  	Training Loss: 0.04975632578134537
Test Loss:  0.05919068306684494
Valid Loss:  0.05932268127799034
Epoch:  130  	Training Loss: 0.04975561052560806
Test Loss:  0.059190280735492706
Valid Loss:  0.0593225434422493
Epoch:  131  	Training Loss: 0.049754902720451355
Test Loss:  0.059189919382333755
Valid Loss:  0.059322282671928406
Epoch:  132  	Training Loss: 0.049754198640584946
Test Loss:  0.05918954312801361
Valid Loss:  0.059322159737348557
Epoch:  133  	Training Loss: 0.049753498286008835
Test Loss:  0.05918917804956436
Valid Loss:  0.05932189151644707
Epoch:  134  	Training Loss: 0.04975280910730362
Test Loss:  0.059188805520534515
Valid Loss:  0.05932175740599632
Epoch:  135  	Training Loss: 0.04975210502743721
Test Loss:  0.059188440442085266
Valid Loss:  0.05932155251502991
Epoch:  136  	Training Loss: 0.049751412123441696
Test Loss:  0.05918806046247482
Valid Loss:  0.05932142212986946
Epoch:  137  	Training Loss: 0.04975071921944618
Test Loss:  0.05918770283460617
Valid Loss:  0.059321172535419464
Epoch:  138  	Training Loss: 0.04975002259016037
Test Loss:  0.05918733403086662
Valid Loss:  0.05932101979851723
Epoch:  139  	Training Loss: 0.049749329686164856
Test Loss:  0.059186968952417374
Valid Loss:  0.059320807456970215
Epoch:  140  	Training Loss: 0.04974863678216934
Test Loss:  0.05918659269809723
Valid Loss:  0.05932068079710007
Epoch:  141  	Training Loss: 0.04974794387817383
Test Loss:  0.05918623507022858
Valid Loss:  0.05932043120265007
Epoch:  142  	Training Loss: 0.049747250974178314
Test Loss:  0.05918586254119873
Valid Loss:  0.05932031199336052
Epoch:  143  	Training Loss: 0.0497465655207634
Test Loss:  0.05918550863862038
Valid Loss:  0.05932009965181351
Epoch:  144  	Training Loss: 0.04974587634205818
Test Loss:  0.05918513610959053
 29%|██▉       | 145/500 [01:44<03:46,  1.56it/s] 29%|██▉       | 147/500 [01:44<02:44,  2.14it/s] 30%|██▉       | 149/500 [01:44<02:01,  2.88it/s] 30%|███       | 151/500 [01:50<07:00,  1.20s/it] 31%|███       | 153/500 [01:50<05:01,  1.15it/s] 31%|███       | 155/500 [01:51<03:36,  1.59it/s] 31%|███▏      | 157/500 [01:51<02:37,  2.18it/s] 32%|███▏      | 159/500 [01:51<01:56,  2.93it/s] 32%|███▏      | 161/500 [01:57<06:46,  1.20s/it] 33%|███▎      | 163/500 [01:57<04:50,  1.16it/s] 33%|███▎      | 165/500 [01:58<03:28,  1.61it/s] 33%|███▎      | 167/500 [01:58<02:31,  2.20it/s] 34%|███▍      | 169/500 [01:58<01:51,  2.96it/s] 34%|███▍      | 171/500 [02:04<06:35,  1.20s/it] 35%|███▍      | 173/500 [02:04<04:42,  1.16it/s] 35%|███▌      | 175/500 [02:04<03:22,  1.60it/s] 35%|███▌      | 177/500 [02:05<02:27,  2.19it/s] 36%|███▌      | 179/500 [02:05<01:48,  2.95it/s] 36%|███▌      | 181/500 [02:11<06:15,  1.18s/it] 37%|███▋      | 183/500 [02:11<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:11<03:12,  1.63it/s] 37%|███▋      | 187/500 [02:11<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:12<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:18<06:10,  1.20s/it] 39%|███▊      | 193/500 [02:18<04:24,  1.16it/s] 39%|███▉      | 195/500 [02:18<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:18<02:18,  2.18it/s] 40%|███▉      | 199/500 [02:19<01:42,  2.93it/s] 40%|████      | 201/500 [02:25<06:08,  1.23s/it] 41%|████      | 203/500 [02:25<04:23,  1.13it/s] 41%|████      | 205/500 [02:25<03:09,  1.56it/s] 41%|████▏     | 207/500 [02:26<02:17,  2.13it/s] 42%|████▏     | 209/500 [02:26<01:41,  2.87it/s] 42%|████▏     | 211/500 [02:32<05:46,  1.20s/it] 43%|████▎     | 213/500 [02:32<04:07,  1.16it/s] 43%|████▎     | 215/500 [02:32<02:57,  1.61it/s]Valid Loss:  0.05931994691491127
Epoch:  145  	Training Loss: 0.049745187163352966
Test Loss:  0.05918478965759277
Valid Loss:  0.05931970849633217
Epoch:  146  	Training Loss: 0.04974450170993805
Test Loss:  0.059184424579143524
Valid Loss:  0.05931957811117172
Epoch:  147  	Training Loss: 0.04974381625652313
Test Loss:  0.059184059500694275
Valid Loss:  0.05931936949491501
Epoch:  148  	Training Loss: 0.04974312707781792
Test Loss:  0.059183694422245026
Valid Loss:  0.05931924656033516
Epoch:  149  	Training Loss: 0.049742441624403
Test Loss:  0.05918335169553757
Valid Loss:  0.05931899696588516
Epoch:  150  	Training Loss: 0.04974175989627838
Test Loss:  0.05918297916650772
Valid Loss:  0.05931887775659561
Epoch:  151  	Training Loss: 0.04974106699228287
Test Loss:  0.05918261781334877
Valid Loss:  0.05931870639324188
Epoch:  152  	Training Loss: 0.04974038526415825
Test Loss:  0.05918226018548012
Valid Loss:  0.05931853875517845
Epoch:  153  	Training Loss: 0.04973970726132393
Test Loss:  0.05918191373348236
Valid Loss:  0.05931834131479263
Epoch:  154  	Training Loss: 0.049739036709070206
Test Loss:  0.05918155610561371
Valid Loss:  0.059318218380212784
Epoch:  155  	Training Loss: 0.049738362431526184
Test Loss:  0.05918122082948685
Valid Loss:  0.059317976236343384
Epoch:  156  	Training Loss: 0.04973768815398216
Test Loss:  0.059180863201618195
Valid Loss:  0.059317849576473236
Epoch:  157  	Training Loss: 0.04973701015114784
Test Loss:  0.059180498123168945
Valid Loss:  0.059317655861377716
Epoch:  158  	Training Loss: 0.04973633587360382
Test Loss:  0.05918015539646149
Valid Loss:  0.05931748449802399
Epoch:  159  	Training Loss: 0.0497356653213501
Test Loss:  0.05917980894446373
Valid Loss:  0.05931727960705757
Epoch:  160  	Training Loss: 0.049734991043806076
Test Loss:  0.05917944759130478
Valid Loss:  0.05931715667247772
Epoch:  161  	Training Loss: 0.04973432049155235
Test Loss:  0.05917911231517792
Valid Loss:  0.059316910803318024
Epoch:  162  	Training Loss: 0.04973365366458893
Test Loss:  0.05917874723672867
Valid Loss:  0.059316784143447876
Epoch:  163  	Training Loss: 0.04973296821117401
Test Loss:  0.05917838588356972
Valid Loss:  0.05931661278009415
Epoch:  164  	Training Loss: 0.04973228648304939
Test Loss:  0.059178031980991364
Valid Loss:  0.05931644141674042
Epoch:  165  	Training Loss: 0.049731601029634476
Test Loss:  0.059177666902542114
Valid Loss:  0.05931627005338669
Epoch:  166  	Training Loss: 0.049730923026800156
Test Loss:  0.05917730554938316
Valid Loss:  0.05931609869003296
Epoch:  167  	Training Loss: 0.04973024129867554
Test Loss:  0.05917695164680481
Valid Loss:  0.05931592732667923
Epoch:  168  	Training Loss: 0.04972956329584122
Test Loss:  0.059176601469516754
Valid Loss:  0.05931571125984192
Epoch:  169  	Training Loss: 0.0497288852930069
Test Loss:  0.05917622148990631
Valid Loss:  0.059315573424100876
Epoch:  170  	Training Loss: 0.04972819983959198
Test Loss:  0.05917588621377945
Valid Loss:  0.059315361082553864
Epoch:  171  	Training Loss: 0.04972752183675766
Test Loss:  0.0591755174100399
Valid Loss:  0.05931522324681282
Epoch:  172  	Training Loss: 0.04972684383392334
Test Loss:  0.05917515605688095
Valid Loss:  0.059314943850040436
Epoch:  173  	Training Loss: 0.049726150929927826
Test Loss:  0.059174779802560806
Valid Loss:  0.059314802289009094
Epoch:  174  	Training Loss: 0.049725454300642014
Test Loss:  0.05917441099882126
Valid Loss:  0.05931466072797775
Epoch:  175  	Training Loss: 0.049724772572517395
Test Loss:  0.05917404592037201
Valid Loss:  0.059314385056495667
Epoch:  176  	Training Loss: 0.04972407594323158
Test Loss:  0.05917367711663246
Valid Loss:  0.059314243495464325
Epoch:  177  	Training Loss: 0.04972338676452637
Test Loss:  0.059173308312892914
Valid Loss:  0.059314046055078506
Epoch:  178  	Training Loss: 0.04972270131111145
Test Loss:  0.059172943234443665
Valid Loss:  0.05931385979056358
Epoch:  179  	Training Loss: 0.04972201585769653
Test Loss:  0.05917257070541382
Valid Loss:  0.05931366980075836
Epoch:  180  	Training Loss: 0.04972132295370102
Test Loss:  0.05917220562696457
Valid Loss:  0.05931348353624344
Epoch:  181  	Training Loss: 0.0497206412255764
Test Loss:  0.05917184054851532
Valid Loss:  0.05931328982114792
Epoch:  182  	Training Loss: 0.049719952046871185
Test Loss:  0.05917147174477577
Valid Loss:  0.0593130961060524
Epoch:  183  	Training Loss: 0.04971926659345627
Test Loss:  0.05917111039161682
Valid Loss:  0.059312909841537476
Epoch:  184  	Training Loss: 0.04971858114004135
Test Loss:  0.059170737862586975
Valid Loss:  0.05931272357702255
Epoch:  185  	Training Loss: 0.049717891961336136
Test Loss:  0.059170372784137726
Valid Loss:  0.05931252986192703
Epoch:  186  	Training Loss: 0.04971720650792122
Test Loss:  0.05917000770568848
Valid Loss:  0.05931233614683151
Epoch:  187  	Training Loss: 0.0497165247797966
Test Loss:  0.05916963890194893
Valid Loss:  0.05931214243173599
Epoch:  188  	Training Loss: 0.049715835601091385
Test Loss:  0.059169262647628784
Valid Loss:  0.05931198224425316
Epoch:  189  	Training Loss: 0.04971514642238617
Test Loss:  0.05916890501976013
Valid Loss:  0.05931170657277107
Epoch:  190  	Training Loss: 0.04971446096897125
Test Loss:  0.05916852876543999
Valid Loss:  0.05931154638528824
Epoch:  191  	Training Loss: 0.049713775515556335
Test Loss:  0.05916815251111984
Valid Loss:  0.0593113973736763
Epoch:  192  	Training Loss: 0.04971309006214142
Test Loss:  0.05916779115796089
Valid Loss:  0.0593111589550972
Epoch:  193  	Training Loss: 0.0497124046087265
Test Loss:  0.059167418628931046
Valid Loss:  0.059310998767614365
Epoch:  194  	Training Loss: 0.049711719155311584
Test Loss:  0.059167053550481796
Valid Loss:  0.059310801327228546
Epoch:  195  	Training Loss: 0.04971103370189667
Test Loss:  0.05916668474674225
Valid Loss:  0.059310607612133026
Epoch:  196  	Training Loss: 0.04971035197377205
Test Loss:  0.059166319668293
Valid Loss:  0.05931041017174721
Epoch:  197  	Training Loss: 0.04970967024564743
Test Loss:  0.05916595458984375
Valid Loss:  0.05931021273136139
Epoch:  198  	Training Loss: 0.04970898479223251
Test Loss:  0.0591655895113945
Valid Loss:  0.05931001156568527
Epoch:  199  	Training Loss: 0.04970830678939819
Test Loss:  0.05916522443294525
Valid Loss:  0.059309810400009155
Epoch:  200  	Training Loss: 0.049707621335983276
Test Loss:  0.059164851903915405
Valid Loss:  0.05930965393781662
Epoch:  201  	Training Loss: 0.049706943333148956
Test Loss:  0.05916449427604675
Valid Loss:  0.05930941179394722
Epoch:  202  	Training Loss: 0.04970626160502434
Test Loss:  0.0591641440987587
Valid Loss:  0.059309277683496475
Epoch:  203  	Training Loss: 0.04970559850335121
Test Loss:  0.05916379392147064
Valid Loss:  0.05930909886956215
Epoch:  204  	Training Loss: 0.04970493167638779
Test Loss:  0.059163451194763184
Valid Loss:  0.059308912605047226
Epoch:  205  	Training Loss: 0.04970427230000496
Test Loss:  0.05916310474276543
Valid Loss:  0.0593087300658226
Epoch:  206  	Training Loss: 0.04970360919833183
Test Loss:  0.05916276574134827
Valid Loss:  0.05930854752659798
Epoch:  207  	Training Loss: 0.04970294609665871
Test Loss:  0.05916241556406021
Valid Loss:  0.059308409690856934
Epoch:  208  	Training Loss: 0.04970228672027588
Test Loss:  0.05916207283735275
Valid Loss:  0.059308186173439026
Epoch:  209  	Training Loss: 0.04970162734389305
Test Loss:  0.0591617226600647
Valid Loss:  0.059308044612407684
Epoch:  210  	Training Loss: 0.04970096796751022
Test Loss:  0.059161387383937836
Valid Loss:  0.05930785834789276
Epoch:  211  	Training Loss: 0.0497003048658371
Test Loss:  0.05916103720664978
Valid Loss:  0.05930767208337784
Epoch:  212  	Training Loss: 0.04969964548945427
Test Loss:  0.05916067585349083
Valid Loss:  0.05930747091770172
Epoch:  213  	Training Loss: 0.04969897121191025
Test Loss:  0.059160299599170685
Valid Loss:  0.05930729955434799
Epoch:  214  	Training Loss: 0.04969828575849533
Test Loss:  0.05915994197130203
Valid Loss:  0.05930710583925247
Epoch:  215  	Training Loss: 0.04969760775566101
Test Loss:  0.05915958061814308
Valid Loss:  0.05930689722299576
 43%|████▎     | 217/500 [02:33<02:09,  2.18it/s] 44%|████▍     | 219/500 [02:33<01:35,  2.94it/s] 44%|████▍     | 221/500 [02:39<05:36,  1.21s/it] 45%|████▍     | 223/500 [02:39<03:59,  1.16it/s] 45%|████▌     | 225/500 [02:39<02:52,  1.60it/s] 45%|████▌     | 227/500 [02:40<02:04,  2.19it/s] 46%|████▌     | 229/500 [02:40<01:32,  2.94it/s] 46%|████▌     | 231/500 [02:46<05:22,  1.20s/it] 47%|████▋     | 233/500 [02:46<03:50,  1.16it/s] 47%|████▋     | 235/500 [02:46<02:45,  1.60it/s] 47%|████▋     | 237/500 [02:46<01:59,  2.19it/s] 48%|████▊     | 239/500 [02:47<01:28,  2.95it/s] 48%|████▊     | 241/500 [02:53<05:09,  1.20s/it] 49%|████▊     | 243/500 [02:53<03:41,  1.16it/s] 49%|████▉     | 245/500 [02:53<02:40,  1.58it/s] 49%|████▉     | 247/500 [02:54<01:58,  2.14it/s] 50%|████▉     | 249/500 [02:54<01:26,  2.89it/s] 50%|█████     | 251/500 [03:00<05:01,  1.21s/it] 51%|█████     | 253/500 [03:00<03:35,  1.15it/s] 51%|█████     | 255/500 [03:00<02:34,  1.59it/s] 51%|█████▏    | 257/500 [03:01<01:52,  2.17it/s] 52%|█████▏    | 259/500 [03:01<01:23,  2.90it/s] 52%|█████▏    | 261/500 [03:07<04:49,  1.21s/it] 53%|█████▎    | 263/500 [03:07<03:26,  1.15it/s] 53%|█████▎    | 265/500 [03:07<02:28,  1.59it/s] 53%|█████▎    | 267/500 [03:08<01:47,  2.16it/s] 54%|█████▍    | 269/500 [03:08<01:19,  2.91it/s] 54%|█████▍    | 271/500 [03:14<04:35,  1.20s/it] 55%|█████▍    | 273/500 [03:14<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:14<02:20,  1.60it/s] 55%|█████▌    | 277/500 [03:15<01:42,  2.18it/s] 56%|█████▌    | 279/500 [03:15<01:15,  2.91it/s] 56%|█████▌    | 281/500 [03:21<04:22,  1.20s/it] 57%|█████▋    | 283/500 [03:21<03:07,  1.16it/s] 57%|█████▋    | 285/500 [03:21<02:14,  1.60it/s]Epoch:  216  	Training Loss: 0.04969693347811699
Test Loss:  0.05915922299027443
Valid Loss:  0.05930669978260994
Epoch:  217  	Training Loss: 0.04969625920057297
Test Loss:  0.05915885791182518
Valid Loss:  0.05930653214454651
Epoch:  218  	Training Loss: 0.04969558119773865
Test Loss:  0.05915849655866623
Valid Loss:  0.05930628627538681
Epoch:  219  	Training Loss: 0.04969490319490433
Test Loss:  0.05915813148021698
Valid Loss:  0.05930611491203308
Epoch:  220  	Training Loss: 0.04969422146677971
Test Loss:  0.05915777385234833
Valid Loss:  0.059305913746356964
Epoch:  221  	Training Loss: 0.04969354718923569
Test Loss:  0.05915740132331848
Valid Loss:  0.059305738657712936
Epoch:  222  	Training Loss: 0.049692872911691666
Test Loss:  0.059157054871320724
Valid Loss:  0.059305500239133835
Epoch:  223  	Training Loss: 0.049692198634147644
Test Loss:  0.05915668606758118
Valid Loss:  0.059305340051651
Epoch:  224  	Training Loss: 0.04969152808189392
Test Loss:  0.05915633216500282
Valid Loss:  0.059305138885974884
Epoch:  225  	Training Loss: 0.0496908575296402
Test Loss:  0.059155963361263275
Valid Loss:  0.059304967522621155
Epoch:  226  	Training Loss: 0.049690183252096176
Test Loss:  0.05915560573339462
Valid Loss:  0.05930476635694504
Epoch:  227  	Training Loss: 0.049689508974552155
Test Loss:  0.05915525183081627
Valid Loss:  0.059304557740688324
Epoch:  228  	Training Loss: 0.04968884214758873
Test Loss:  0.05915489047765732
Valid Loss:  0.05930439382791519
Epoch:  229  	Training Loss: 0.049688175320625305
Test Loss:  0.05915454402565956
Valid Loss:  0.05930418521165848
Epoch:  230  	Training Loss: 0.04968750476837158
Test Loss:  0.059154193848371506
Valid Loss:  0.05930398404598236
Epoch:  231  	Training Loss: 0.04968683421611786
Test Loss:  0.05915382504463196
Valid Loss:  0.0593038946390152
Epoch:  232  	Training Loss: 0.04968617111444473
Test Loss:  0.059153489768505096
Valid Loss:  0.059303708374500275
Epoch:  233  	Training Loss: 0.049685508012771606
Test Loss:  0.05915314331650734
Valid Loss:  0.059303514659404755
Epoch:  234  	Training Loss: 0.04968485236167908
Test Loss:  0.05915279686450958
Valid Loss:  0.05930336192250252
Epoch:  235  	Training Loss: 0.04968418926000595
Test Loss:  0.059152450412511826
Valid Loss:  0.059303224086761475
Epoch:  236  	Training Loss: 0.04968353360891342
Test Loss:  0.059152115136384964
Valid Loss:  0.059303030371665955
Epoch:  237  	Training Loss: 0.04968287795782089
Test Loss:  0.05915176868438721
Valid Loss:  0.05930287390947342
Epoch:  238  	Training Loss: 0.049682214856147766
Test Loss:  0.059151437133550644
Valid Loss:  0.0593026801943779
Epoch:  239  	Training Loss: 0.04968155920505524
Test Loss:  0.05915107578039169
Valid Loss:  0.05930258333683014
Epoch:  240  	Training Loss: 0.04968090355396271
Test Loss:  0.05915074422955513
Valid Loss:  0.059302378445863724
Epoch:  241  	Training Loss: 0.04968024417757988
Test Loss:  0.05915040522813797
Valid Loss:  0.059302184730768204
Epoch:  242  	Training Loss: 0.04967958852648735
Test Loss:  0.05915004760026932
Valid Loss:  0.05930206924676895
Epoch:  243  	Training Loss: 0.049678921699523926
Test Loss:  0.05914970114827156
Valid Loss:  0.05930186063051224
Epoch:  244  	Training Loss: 0.0496782585978508
Test Loss:  0.05914933979511261
Valid Loss:  0.05930175632238388
Epoch:  245  	Training Loss: 0.04967759549617767
Test Loss:  0.059148985892534256
Valid Loss:  0.05930154770612717
Epoch:  246  	Training Loss: 0.04967692494392395
Test Loss:  0.0591486394405365
Valid Loss:  0.059301335364580154
Epoch:  247  	Training Loss: 0.049676261842250824
Test Loss:  0.059148289263248444
Valid Loss:  0.059301186352968216
Epoch:  248  	Training Loss: 0.0496755950152874
Test Loss:  0.05914793908596039
Valid Loss:  0.0593009777367115
Epoch:  249  	Training Loss: 0.04967493191361427
Test Loss:  0.05914757400751114
Valid Loss:  0.05930086225271225
Epoch:  250  	Training Loss: 0.049674272537231445
Test Loss:  0.05914723128080368
Valid Loss:  0.05930064991116524
Epoch:  251  	Training Loss: 0.04967360943555832
Test Loss:  0.05914687737822533
Valid Loss:  0.05930047482252121
Epoch:  252  	Training Loss: 0.049672942608594894
Test Loss:  0.05914655327796936
Valid Loss:  0.059300344437360764
Epoch:  253  	Training Loss: 0.04967229813337326
Test Loss:  0.059146225452423096
Valid Loss:  0.05930019170045853
Epoch:  254  	Training Loss: 0.049671661108732224
Test Loss:  0.059145890176296234
Valid Loss:  0.05930006504058838
Epoch:  255  	Training Loss: 0.04967100918292999
Test Loss:  0.059145569801330566
Valid Loss:  0.05929991230368614
Epoch:  256  	Training Loss: 0.04967036843299866
Test Loss:  0.0591452494263649
Valid Loss:  0.05929972603917122
Epoch:  257  	Training Loss: 0.04966973140835762
Test Loss:  0.059144917875528336
Valid Loss:  0.059299636632204056
Epoch:  258  	Training Loss: 0.049669090658426285
Test Loss:  0.05914459377527237
Valid Loss:  0.05929943919181824
Epoch:  259  	Training Loss: 0.04966844245791435
Test Loss:  0.0591442734003067
Valid Loss:  0.0592992901802063
Epoch:  260  	Training Loss: 0.049667805433273315
Test Loss:  0.05914394557476044
Valid Loss:  0.05929915979504585
Epoch:  261  	Training Loss: 0.04966716468334198
Test Loss:  0.05914361774921417
Valid Loss:  0.05929902568459511
Epoch:  262  	Training Loss: 0.049666523933410645
Test Loss:  0.0591433010995388
Valid Loss:  0.05929883196949959
Epoch:  263  	Training Loss: 0.04966588318347931
Test Loss:  0.05914296954870224
Valid Loss:  0.059298738837242126
Epoch:  264  	Training Loss: 0.04966524988412857
Test Loss:  0.05914264917373657
Valid Loss:  0.059298545122146606
Epoch:  265  	Training Loss: 0.049664612859487534
Test Loss:  0.059142328798770905
Valid Loss:  0.059298425912857056
Epoch:  266  	Training Loss: 0.049663983285427094
Test Loss:  0.059142015874385834
Valid Loss:  0.05929822847247124
Epoch:  267  	Training Loss: 0.04966335371136665
Test Loss:  0.05914168059825897
Valid Loss:  0.059298135340213776
Epoch:  268  	Training Loss: 0.049662716686725616
Test Loss:  0.0591413639485836
Valid Loss:  0.05929800868034363
Epoch:  269  	Training Loss: 0.04966208338737488
Test Loss:  0.05914103984832764
Valid Loss:  0.0592978335916996
Epoch:  270  	Training Loss: 0.04966145008802414
Test Loss:  0.05914072319865227
Valid Loss:  0.05929769203066826
Epoch:  271  	Training Loss: 0.049660824239254
Test Loss:  0.059140395373106
Valid Loss:  0.05929754674434662
Epoch:  272  	Training Loss: 0.04966019093990326
Test Loss:  0.05914006382226944
Valid Loss:  0.059297382831573486
Epoch:  273  	Training Loss: 0.049659550189971924
Test Loss:  0.05913972109556198
Valid Loss:  0.05929727107286453
Epoch:  274  	Training Loss: 0.04965890944004059
Test Loss:  0.059139400720596313
Valid Loss:  0.059297092258930206
Epoch:  275  	Training Loss: 0.04965826869010925
Test Loss:  0.05913906544446945
Valid Loss:  0.059296924620866776
Epoch:  276  	Training Loss: 0.04965762794017792
Test Loss:  0.05913873016834259
Valid Loss:  0.059296779334545135
Epoch:  277  	Training Loss: 0.04965699464082718
Test Loss:  0.059138406068086624
Valid Loss:  0.059296607971191406
Epoch:  278  	Training Loss: 0.04965634644031525
Test Loss:  0.059138067066669464
Valid Loss:  0.05929649621248245
Epoch:  279  	Training Loss: 0.04965571314096451
Test Loss:  0.0591377355158329
Valid Loss:  0.05929628014564514
Epoch:  280  	Training Loss: 0.049655068665742874
Test Loss:  0.059137411415576935
Valid Loss:  0.059296175837516785
Epoch:  281  	Training Loss: 0.049654439091682434
Test Loss:  0.05913708359003067
Valid Loss:  0.05929600074887276
Epoch:  282  	Training Loss: 0.0496537983417511
Test Loss:  0.05913674086332321
Valid Loss:  0.05929584428668022
Epoch:  283  	Training Loss: 0.04965315759181976
Test Loss:  0.05913641303777695
Valid Loss:  0.05929567664861679
Epoch:  284  	Training Loss: 0.04965251311659813
Test Loss:  0.05913607031106949
Valid Loss:  0.05929556116461754
Epoch:  285  	Training Loss: 0.049651872366666794
Test Loss:  0.05913574621081352
Valid Loss:  0.05929534509778023
Epoch:  286  	Training Loss: 0.04965122789144516
Test Loss:  0.05913540720939636
Valid Loss:  0.059295255690813065
Epoch:  287  	Training Loss: 0.04965059086680412
 57%|█████▋    | 287/500 [03:22<01:37,  2.19it/s] 58%|█████▊    | 289/500 [03:22<01:13,  2.89it/s] 58%|█████▊    | 291/500 [03:28<04:14,  1.22s/it] 59%|█████▊    | 293/500 [03:28<03:00,  1.15it/s] 59%|█████▉    | 295/500 [03:28<02:09,  1.59it/s] 59%|█████▉    | 297/500 [03:29<01:33,  2.17it/s] 60%|█████▉    | 299/500 [03:29<01:08,  2.92it/s] 60%|██████    | 301/500 [03:35<03:55,  1.18s/it] 61%|██████    | 303/500 [03:35<02:48,  1.17it/s] 61%|██████    | 305/500 [03:35<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:35<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:36<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:42<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:42<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:42<01:55,  1.60it/s] 63%|██████▎   | 317/500 [03:42<01:24,  2.16it/s] 64%|██████▍   | 319/500 [03:43<01:03,  2.86it/s] 64%|██████▍   | 321/500 [03:49<03:34,  1.20s/it] 65%|██████▍   | 323/500 [03:49<02:32,  1.16it/s] 65%|██████▌   | 325/500 [03:49<01:48,  1.61it/s] 65%|██████▌   | 327/500 [03:49<01:18,  2.20it/s] 66%|██████▌   | 329/500 [03:50<00:58,  2.94it/s] 66%|██████▌   | 331/500 [03:56<03:22,  1.20s/it] 67%|██████▋   | 333/500 [03:56<02:23,  1.16it/s] 67%|██████▋   | 335/500 [03:56<01:42,  1.60it/s] 67%|██████▋   | 337/500 [03:56<01:14,  2.18it/s] 68%|██████▊   | 339/500 [03:56<00:55,  2.91it/s] 68%|██████▊   | 341/500 [04:03<03:13,  1.22s/it] 69%|██████▊   | 343/500 [04:03<02:16,  1.15it/s] 69%|██████▉   | 345/500 [04:03<01:37,  1.59it/s] 69%|██████▉   | 347/500 [04:03<01:10,  2.17it/s] 70%|██████▉   | 349/500 [04:04<00:51,  2.92it/s] 70%|███████   | 351/500 [04:10<02:58,  1.20s/it] 71%|███████   | 353/500 [04:10<02:07,  1.15it/s] 71%|███████   | 355/500 [04:10<01:31,  1.58it/s] 71%|███████▏  | 357/500 [04:10<01:07,  2.13it/s]Test Loss:  0.0591350793838501
Valid Loss:  0.05929507687687874
Epoch:  288  	Training Loss: 0.04964994639158249
Test Loss:  0.059134747833013535
Valid Loss:  0.059294894337654114
Epoch:  289  	Training Loss: 0.049649305641651154
Test Loss:  0.05913441255688667
Valid Loss:  0.059294745326042175
Epoch:  290  	Training Loss: 0.04964866489171982
Test Loss:  0.05913408100605011
Valid Loss:  0.059294600039720535
Epoch:  291  	Training Loss: 0.04964802414178848
Test Loss:  0.059133756905794144
Valid Loss:  0.059294443577528
Epoch:  292  	Training Loss: 0.049647387117147446
Test Loss:  0.05913341045379639
Valid Loss:  0.059294313192367554
Epoch:  293  	Training Loss: 0.04964674636721611
Test Loss:  0.05913308262825012
Valid Loss:  0.05929413437843323
Epoch:  294  	Training Loss: 0.04964610934257507
Test Loss:  0.05913275480270386
Valid Loss:  0.0592939555644989
Epoch:  295  	Training Loss: 0.049645476043224335
Test Loss:  0.0591324158012867
Valid Loss:  0.05929381027817726
Epoch:  296  	Training Loss: 0.049644835293293
Test Loss:  0.05913209170103073
Valid Loss:  0.05929362773895264
Epoch:  297  	Training Loss: 0.04964419826865196
Test Loss:  0.05913174897432327
Valid Loss:  0.05929351598024368
Epoch:  298  	Training Loss: 0.049643561244010925
Test Loss:  0.059131424874067307
Valid Loss:  0.05929333716630936
Epoch:  299  	Training Loss: 0.04964292794466019
Test Loss:  0.059131085872650146
Valid Loss:  0.05929320305585861
Epoch:  300  	Training Loss: 0.04964229092001915
Test Loss:  0.05913076549768448
Valid Loss:  0.05929300934076309
Epoch:  301  	Training Loss: 0.04964165389537811
Test Loss:  0.05913042649626732
Valid Loss:  0.059292882680892944
Epoch:  302  	Training Loss: 0.049641020596027374
Test Loss:  0.059130094945430756
Valid Loss:  0.05929269641637802
Epoch:  303  	Training Loss: 0.04964038357138634
Test Loss:  0.059129759669303894
Valid Loss:  0.05929257348179817
Epoch:  304  	Training Loss: 0.049639742821455
Test Loss:  0.059129439294338226
Valid Loss:  0.05929236486554146
Epoch:  305  	Training Loss: 0.049639105796813965
Test Loss:  0.059129104018211365
Valid Loss:  0.05929224193096161
Epoch:  306  	Training Loss: 0.04963846877217293
Test Loss:  0.0591287687420845
Valid Loss:  0.059292055666446686
Epoch:  307  	Training Loss: 0.04963783547282219
Test Loss:  0.059128426015377045
Valid Loss:  0.059291958808898926
Epoch:  308  	Training Loss: 0.04963719844818115
Test Loss:  0.05912809446454048
Valid Loss:  0.0592917874455452
Epoch:  309  	Training Loss: 0.049636565148830414
Test Loss:  0.05912776291370392
Valid Loss:  0.05929163098335266
Epoch:  310  	Training Loss: 0.04963592439889908
Test Loss:  0.059127435088157654
Valid Loss:  0.05929143354296684
Epoch:  311  	Training Loss: 0.04963529109954834
Test Loss:  0.05912709981203079
Valid Loss:  0.05929126590490341
Epoch:  312  	Training Loss: 0.0496346540749073
Test Loss:  0.05912677198648453
Valid Loss:  0.059291161596775055
Epoch:  313  	Training Loss: 0.049634017050266266
Test Loss:  0.05912642925977707
Valid Loss:  0.059290967881679535
Epoch:  314  	Training Loss: 0.04963337630033493
Test Loss:  0.05912609398365021
Valid Loss:  0.05929083377122879
Epoch:  315  	Training Loss: 0.04963274300098419
Test Loss:  0.05912576615810394
Valid Loss:  0.05929066240787506
Epoch:  316  	Training Loss: 0.049632102251052856
Test Loss:  0.05912543088197708
Valid Loss:  0.05929048731923103
Epoch:  317  	Training Loss: 0.04963146150112152
Test Loss:  0.05912509933114052
Valid Loss:  0.059290289878845215
Epoch:  318  	Training Loss: 0.04963082820177078
Test Loss:  0.05912475660443306
Valid Loss:  0.05929018557071686
Epoch:  319  	Training Loss: 0.049630194902420044
Test Loss:  0.059124428778886795
Valid Loss:  0.05929001048207283
Epoch:  320  	Training Loss: 0.04962955415248871
Test Loss:  0.059124089777469635
Valid Loss:  0.059289876371622086
Epoch:  321  	Training Loss: 0.04962892085313797
Test Loss:  0.05912376195192337
Valid Loss:  0.05928967520594597
Epoch:  322  	Training Loss: 0.04962828382849693
Test Loss:  0.059123411774635315
Valid Loss:  0.05928955599665642
Epoch:  323  	Training Loss: 0.0496276393532753
Test Loss:  0.059123072773218155
Valid Loss:  0.059289343655109406
Epoch:  324  	Training Loss: 0.049626998603343964
Test Loss:  0.0591227263212204
Valid Loss:  0.059289224445819855
Epoch:  325  	Training Loss: 0.04962635412812233
Test Loss:  0.05912238359451294
Valid Loss:  0.05928902328014374
Epoch:  326  	Training Loss: 0.049625709652900696
Test Loss:  0.05912203714251518
Valid Loss:  0.05928888916969299
Epoch:  327  	Training Loss: 0.04962506890296936
Test Loss:  0.05912169814109802
Valid Loss:  0.0592886358499527
Epoch:  328  	Training Loss: 0.049624428153038025
Test Loss:  0.059121351689100266
Valid Loss:  0.05928848311305046
Epoch:  329  	Training Loss: 0.04962377995252609
Test Loss:  0.05912100523710251
Valid Loss:  0.05928831547498703
Epoch:  330  	Training Loss: 0.04962313175201416
Test Loss:  0.05912066251039505
Valid Loss:  0.059288136661052704
Epoch:  331  	Training Loss: 0.049622491002082825
Test Loss:  0.05912031978368759
Valid Loss:  0.05928798019886017
Epoch:  332  	Training Loss: 0.04962185025215149
Test Loss:  0.05911998450756073
Valid Loss:  0.059287797659635544
Epoch:  333  	Training Loss: 0.04962121695280075
Test Loss:  0.05911964178085327
Valid Loss:  0.05928768217563629
Epoch:  334  	Training Loss: 0.04962058365345001
Test Loss:  0.05911931395530701
Valid Loss:  0.05928747355937958
Epoch:  335  	Training Loss: 0.049619950354099274
Test Loss:  0.059118982404470444
Valid Loss:  0.059287358075380325
Epoch:  336  	Training Loss: 0.04961931332945824
Test Loss:  0.05911865085363388
Valid Loss:  0.059287138283252716
Epoch:  337  	Training Loss: 0.0496186837553978
Test Loss:  0.059118304401636124
Valid Loss:  0.05928702652454376
Epoch:  338  	Training Loss: 0.04961805045604706
Test Loss:  0.05911798030138016
Valid Loss:  0.05928684026002884
Epoch:  339  	Training Loss: 0.04961741715669632
Test Loss:  0.059117645025253296
Valid Loss:  0.0592866875231266
Epoch:  340  	Training Loss: 0.04961678385734558
Test Loss:  0.05911731719970703
Valid Loss:  0.059286508709192276
Epoch:  341  	Training Loss: 0.04961615428328514
Test Loss:  0.05911697819828987
Valid Loss:  0.05928637832403183
Epoch:  342  	Training Loss: 0.0496155247092247
Test Loss:  0.059116654098033905
Valid Loss:  0.05928617715835571
Epoch:  343  	Training Loss: 0.04961489140987396
Test Loss:  0.05911631882190704
Valid Loss:  0.05928605794906616
Epoch:  344  	Training Loss: 0.04961426556110382
Test Loss:  0.05911599099636078
Valid Loss:  0.05928587168455124
Epoch:  345  	Training Loss: 0.04961363971233368
Test Loss:  0.059115663170814514
Valid Loss:  0.0592857263982296
Epoch:  346  	Training Loss: 0.04961301013827324
Test Loss:  0.05911533161997795
Valid Loss:  0.05928557738661766
Epoch:  347  	Training Loss: 0.0496123805642128
Test Loss:  0.059115007519721985
Valid Loss:  0.059285424649715424
Epoch:  348  	Training Loss: 0.04961175471544266
Test Loss:  0.05911467969417572
Valid Loss:  0.05928521975874901
Epoch:  349  	Training Loss: 0.049611128866672516
Test Loss:  0.05911434814333916
Valid Loss:  0.05928512290120125
Epoch:  350  	Training Loss: 0.049610503017902374
Test Loss:  0.05911402404308319
Valid Loss:  0.059284910559654236
Epoch:  351  	Training Loss: 0.04960987716913223
Test Loss:  0.05911369249224663
Valid Loss:  0.05928478389978409
Epoch:  352  	Training Loss: 0.04960925132036209
Test Loss:  0.059113360941410065
Valid Loss:  0.059284597635269165
Epoch:  353  	Training Loss: 0.04960862174630165
Test Loss:  0.0591130256652832
Valid Loss:  0.05928444489836693
Epoch:  354  	Training Loss: 0.04960799589753151
Test Loss:  0.059112705290317535
Valid Loss:  0.059284280985593796
Epoch:  355  	Training Loss: 0.04960736632347107
Test Loss:  0.059112370014190674
Valid Loss:  0.05928412824869156
Epoch:  356  	Training Loss: 0.04960674047470093
Test Loss:  0.05911204591393471
Valid Loss:  0.05928393453359604
Epoch:  357  	Training Loss: 0.04960611090064049
Test Loss:  0.05911169946193695
Valid Loss:  0.05928380787372589
Epoch:  358  	Training Loss: 0.049605485051870346
Test Loss:  0.05911137908697128
Valid Loss:   72%|███████▏  | 359/500 [04:11<00:49,  2.83it/s] 72%|███████▏  | 361/500 [04:17<02:46,  1.20s/it] 73%|███████▎  | 363/500 [04:17<01:57,  1.16it/s] 73%|███████▎  | 365/500 [04:17<01:23,  1.61it/s] 73%|███████▎  | 367/500 [04:17<01:00,  2.20it/s] 74%|███████▍  | 369/500 [04:17<00:44,  2.95it/s] 74%|███████▍  | 371/500 [04:24<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:24<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:24<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:24<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:24<00:40,  2.98it/s] 76%|███████▌  | 381/500 [04:31<02:25,  1.22s/it] 77%|███████▋  | 383/500 [04:31<01:42,  1.14it/s] 77%|███████▋  | 385/500 [04:31<01:12,  1.58it/s] 77%|███████▋  | 387/500 [04:31<00:52,  2.16it/s] 78%|███████▊  | 389/500 [04:31<00:38,  2.88it/s] 78%|███████▊  | 391/500 [04:38<02:11,  1.21s/it] 79%|███████▊  | 393/500 [04:38<01:32,  1.16it/s] 79%|███████▉  | 395/500 [04:38<01:05,  1.60it/s] 79%|███████▉  | 397/500 [04:38<00:47,  2.18it/s] 80%|███████▉  | 399/500 [04:38<00:34,  2.94it/s] 80%|████████  | 401/500 [04:45<01:58,  1.20s/it] 81%|████████  | 403/500 [04:45<01:23,  1.16it/s] 81%|████████  | 405/500 [04:45<00:58,  1.61it/s] 81%|████████▏ | 407/500 [04:45<00:42,  2.20it/s] 82%|████████▏ | 409/500 [04:45<00:30,  2.97it/s] 82%|████████▏ | 411/500 [04:52<01:46,  1.20s/it] 83%|████████▎ | 413/500 [04:52<01:14,  1.16it/s] 83%|████████▎ | 415/500 [04:52<00:52,  1.60it/s] 83%|████████▎ | 417/500 [04:52<00:37,  2.19it/s] 84%|████████▍ | 419/500 [04:52<00:27,  2.95it/s] 84%|████████▍ | 421/500 [04:59<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:59<01:05,  1.17it/s] 85%|████████▌ | 425/500 [04:59<00:46,  1.62it/s] 85%|████████▌ | 427/500 [04:59<00:32,  2.22it/s] 86%|████████▌ | 429/500 [04:59<00:23,  2.98it/s]0.05928358808159828
Epoch:  359  	Training Loss: 0.049604855477809906
Test Loss:  0.05911104008555412
Valid Loss:  0.05928348749876022
Epoch:  360  	Training Loss: 0.049604229629039764
Test Loss:  0.059110723435878754
Valid Loss:  0.059283263981342316
Epoch:  361  	Training Loss: 0.04960360378026962
Test Loss:  0.059110384434461594
Valid Loss:  0.05928315967321396
Epoch:  362  	Training Loss: 0.04960297793149948
Test Loss:  0.059110064059495926
Valid Loss:  0.05928293988108635
Epoch:  363  	Training Loss: 0.049602359533309937
Test Loss:  0.05910974368453026
Valid Loss:  0.059282854199409485
Epoch:  364  	Training Loss: 0.04960174486041069
Test Loss:  0.05910942703485489
Valid Loss:  0.05928263068199158
Epoch:  365  	Training Loss: 0.04960112273693085
Test Loss:  0.05910910665988922
Valid Loss:  0.05928248539566994
Epoch:  366  	Training Loss: 0.0496005043387413
Test Loss:  0.05910877883434296
Valid Loss:  0.05928235873579979
Epoch:  367  	Training Loss: 0.049599889665842056
Test Loss:  0.05910845845937729
Valid Loss:  0.059282176196575165
Epoch:  368  	Training Loss: 0.04959927499294281
Test Loss:  0.05910813808441162
Valid Loss:  0.05928204208612442
Epoch:  369  	Training Loss: 0.049598656594753265
Test Loss:  0.05910781770944595
Valid Loss:  0.0592818558216095
Epoch:  370  	Training Loss: 0.04959803819656372
Test Loss:  0.05910750478506088
Valid Loss:  0.05928172171115875
Epoch:  371  	Training Loss: 0.04959742724895477
Test Loss:  0.05910717695951462
Valid Loss:  0.05928153544664383
Epoch:  372  	Training Loss: 0.04959680885076523
Test Loss:  0.059106845408678055
Valid Loss:  0.0592813678085804
Epoch:  373  	Training Loss: 0.04959617927670479
Test Loss:  0.05910651013255119
Valid Loss:  0.059281185269355774
Epoch:  374  	Training Loss: 0.04959554597735405
Test Loss:  0.05910617113113403
Valid Loss:  0.05928101763129234
Epoch:  375  	Training Loss: 0.04959491640329361
Test Loss:  0.05910583958029747
Valid Loss:  0.05928083881735802
Epoch:  376  	Training Loss: 0.04959429055452347
Test Loss:  0.05910550057888031
Valid Loss:  0.05928066372871399
Epoch:  377  	Training Loss: 0.04959365725517273
Test Loss:  0.05910516530275345
Valid Loss:  0.05928051471710205
Epoch:  378  	Training Loss: 0.04959303140640259
Test Loss:  0.059104833751916885
Valid Loss:  0.05928030610084534
Epoch:  379  	Training Loss: 0.04959239438176155
Test Loss:  0.059104494750499725
Valid Loss:  0.0592801533639431
Epoch:  380  	Training Loss: 0.04959176480770111
Test Loss:  0.05910416692495346
Valid Loss:  0.059279948472976685
Epoch:  381  	Training Loss: 0.04959113895893097
Test Loss:  0.0591038316488266
Valid Loss:  0.05927977338433266
Epoch:  382  	Training Loss: 0.04959050938487053
Test Loss:  0.05910351872444153
Valid Loss:  0.05927965044975281
Epoch:  383  	Training Loss: 0.04958990961313248
Test Loss:  0.059103213250637054
Valid Loss:  0.05927945673465729
Epoch:  384  	Training Loss: 0.04958929494023323
Test Loss:  0.05910289287567139
Valid Loss:  0.05927933007478714
Epoch:  385  	Training Loss: 0.04958868399262428
Test Loss:  0.05910258740186691
Valid Loss:  0.059279151260852814
Epoch:  386  	Training Loss: 0.04958808422088623
Test Loss:  0.059102270752191544
Valid Loss:  0.05927901715040207
Epoch:  387  	Training Loss: 0.04958747327327728
Test Loss:  0.059101954102516174
Valid Loss:  0.059278856962919235
Epoch:  388  	Training Loss: 0.049586862325668335
Test Loss:  0.0591016560792923
Valid Loss:  0.0592786967754364
Epoch:  389  	Training Loss: 0.049586258828639984
Test Loss:  0.05910133570432663
Valid Loss:  0.059278544038534164
Epoch:  390  	Training Loss: 0.04958565533161163
Test Loss:  0.05910101905465126
Valid Loss:  0.05927840992808342
Epoch:  391  	Training Loss: 0.049585044384002686
Test Loss:  0.059100713580846786
Valid Loss:  0.0592782236635685
Epoch:  392  	Training Loss: 0.049584440886974335
Test Loss:  0.05910041183233261
Valid Loss:  0.05927808955311775
Epoch:  393  	Training Loss: 0.04958384111523628
Test Loss:  0.05910010263323784
Valid Loss:  0.05927794426679611
Epoch:  394  	Training Loss: 0.04958323761820793
Test Loss:  0.05909980088472366
Valid Loss:  0.05927778035402298
Epoch:  395  	Training Loss: 0.04958264157176018
Test Loss:  0.05909949541091919
Valid Loss:  0.05927763134241104
Epoch:  396  	Training Loss: 0.04958203434944153
Test Loss:  0.059099189937114716
Valid Loss:  0.059277504682540894
Epoch:  397  	Training Loss: 0.049581438302993774
Test Loss:  0.05909888446331024
Valid Loss:  0.05927734822034836
Epoch:  398  	Training Loss: 0.04958084225654602
Test Loss:  0.059098586440086365
Valid Loss:  0.05927715823054314
Epoch:  399  	Training Loss: 0.04958024248480797
Test Loss:  0.05909828096628189
Valid Loss:  0.05927703157067299
Epoch:  400  	Training Loss: 0.049579642713069916
Test Loss:  0.05909797549247742
Valid Loss:  0.059276875108480453
Epoch:  401  	Training Loss: 0.04957904666662216
Test Loss:  0.05909767374396324
Valid Loss:  0.05927671119570732
Epoch:  402  	Training Loss: 0.04957844316959381
Test Loss:  0.05909736454486847
Valid Loss:  0.05927657335996628
Epoch:  403  	Training Loss: 0.04957784339785576
Test Loss:  0.0590970516204834
Valid Loss:  0.059276409447193146
Epoch:  404  	Training Loss: 0.049577243626117706
Test Loss:  0.05909673497080803
Valid Loss:  0.059276238083839417
Epoch:  405  	Training Loss: 0.04957663267850876
Test Loss:  0.05909642577171326
Valid Loss:  0.059276070445775986
Epoch:  406  	Training Loss: 0.04957602918148041
Test Loss:  0.059096112847328186
Valid Loss:  0.05927594006061554
Epoch:  407  	Training Loss: 0.04957542568445206
Test Loss:  0.05909581109881401
Valid Loss:  0.05927573889493942
Epoch:  408  	Training Loss: 0.0495748296380043
Test Loss:  0.05909550189971924
Valid Loss:  0.05927560105919838
Epoch:  409  	Training Loss: 0.04957422614097595
Test Loss:  0.05909518897533417
Valid Loss:  0.05927547067403793
Epoch:  410  	Training Loss: 0.0495736263692379
Test Loss:  0.05909488722681999
Valid Loss:  0.059275269508361816
Epoch:  411  	Training Loss: 0.04957302659749985
Test Loss:  0.05909457430243492
Valid Loss:  0.05927516147494316
Epoch:  412  	Training Loss: 0.0495724231004715
Test Loss:  0.05909426137804985
Valid Loss:  0.05927491933107376
Epoch:  413  	Training Loss: 0.049571819603443146
Test Loss:  0.059093933552503586
Valid Loss:  0.05927480012178421
Epoch:  414  	Training Loss: 0.0495712086558342
Test Loss:  0.05909361317753792
Valid Loss:  0.059274621307849884
Epoch:  415  	Training Loss: 0.04957060515880585
Test Loss:  0.05909330025315285
Valid Loss:  0.05927446484565735
Epoch:  416  	Training Loss: 0.049570001661777496
Test Loss:  0.05909298360347748
Valid Loss:  0.05927425995469093
Epoch:  417  	Training Loss: 0.04956939071416855
Test Loss:  0.05909266695380211
Valid Loss:  0.059274137020111084
Epoch:  418  	Training Loss: 0.049568794667720795
Test Loss:  0.059092357754707336
Valid Loss:  0.05927392840385437
Epoch:  419  	Training Loss: 0.049568191170692444
Test Loss:  0.05909203737974167
Valid Loss:  0.05927377566695213
Epoch:  420  	Training Loss: 0.049567583948373795
Test Loss:  0.059091717004776
Valid Loss:  0.0592736192047596
Epoch:  421  	Training Loss: 0.049566980451345444
Test Loss:  0.05909140408039093
Valid Loss:  0.05927343666553497
Epoch:  422  	Training Loss: 0.049566373229026794
Test Loss:  0.05909108370542526
Valid Loss:  0.05927328020334244
Epoch:  423  	Training Loss: 0.049565769731998444
Test Loss:  0.05909076705574989
Valid Loss:  0.05927309766411781
Epoch:  424  	Training Loss: 0.04956516623497009
Test Loss:  0.05909046158194542
Valid Loss:  0.05927291512489319
Epoch:  425  	Training Loss: 0.04956456273794174
Test Loss:  0.05909013748168945
Valid Loss:  0.05927277356386185
Epoch:  426  	Training Loss: 0.04956396296620369
Test Loss:  0.05908982455730438
Valid Loss:  0.059272587299346924
Epoch:  427  	Training Loss: 0.04956335946917534
Test Loss:  0.05908951163291931
Valid Loss:  0.059272401034832
Epoch:  428  	Training Loss: 0.04956275224685669
Test Loss:  0.059089191257953644
Valid Loss:  0.059272248297929764
Epoch:  429  	Training Loss: 0.04956215247511864
Test Loss:  0.05908887833356857
Valid Loss:  0.05927206575870514
 86%|████████▌ | 431/500 [05:06<01:22,  1.20s/it] 87%|████████▋ | 433/500 [05:06<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:06<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:06<00:28,  2.19it/s] 88%|████████▊ | 439/500 [05:06<00:20,  2.93it/s] 88%|████████▊ | 441/500 [05:12<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:13<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:13<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:13<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:13<00:17,  2.99it/s] 90%|█████████ | 451/500 [05:19<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:19<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:20<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:20<00:19,  2.22it/s] 92%|█████████▏| 459/500 [05:20<00:13,  2.98it/s] 92%|█████████▏| 461/500 [05:26<00:46,  1.20s/it] 93%|█████████▎| 463/500 [05:26<00:31,  1.16it/s] 93%|█████████▎| 465/500 [05:27<00:21,  1.60it/s] 93%|█████████▎| 467/500 [05:27<00:15,  2.18it/s] 94%|█████████▍| 469/500 [05:27<00:10,  2.93it/s] 94%|█████████▍| 471/500 [05:33<00:34,  1.20s/it] 95%|█████████▍| 473/500 [05:33<00:23,  1.16it/s] 95%|█████████▌| 475/500 [05:34<00:15,  1.61it/s] 95%|█████████▌| 477/500 [05:34<00:10,  2.19it/s] 96%|█████████▌| 479/500 [05:34<00:07,  2.94it/s] 96%|█████████▌| 481/500 [05:40<00:23,  1.22s/it] 97%|█████████▋| 483/500 [05:41<00:14,  1.14it/s] 97%|█████████▋| 485/500 [05:41<00:09,  1.56it/s] 97%|█████████▋| 487/500 [05:41<00:06,  2.14it/s] 98%|█████████▊| 489/500 [05:41<00:03,  2.88it/s] 98%|█████████▊| 491/500 [05:47<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:47<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:48<00:03,  1.61it/s] 99%|█████████▉| 497/500 [05:48<00:01,  2.18it/s]100%|█████████▉| 499/500 [05:48<00:00,  2.88it/s]100%|██████████| 500/500 [05:48<00:00,  1.43it/s]
Epoch:  430  	Training Loss: 0.04956154525279999
Test Loss:  0.059088561683893204
Valid Loss:  0.05927190184593201
Epoch:  431  	Training Loss: 0.049560949206352234
Test Loss:  0.059088245034217834
Valid Loss:  0.05927171930670738
Epoch:  432  	Training Loss: 0.04956034570932388
Test Loss:  0.059087950736284256
Valid Loss:  0.05927157774567604
Epoch:  433  	Training Loss: 0.049559757113456726
Test Loss:  0.05908764898777008
Valid Loss:  0.05927141010761261
Epoch:  434  	Training Loss: 0.04955916851758957
Test Loss:  0.059087347239255905
Valid Loss:  0.05927127227187157
Epoch:  435  	Training Loss: 0.049558572471141815
Test Loss:  0.05908704921603203
Valid Loss:  0.059271104633808136
Epoch:  436  	Training Loss: 0.04955798760056496
Test Loss:  0.05908675491809845
Valid Loss:  0.0592709556221962
Epoch:  437  	Training Loss: 0.0495573952794075
Test Loss:  0.059086449444293976
Valid Loss:  0.05927078425884247
Epoch:  438  	Training Loss: 0.049556806683540344
Test Loss:  0.0590861514210701
Valid Loss:  0.059270646423101425
Epoch:  439  	Training Loss: 0.04955621808767319
Test Loss:  0.05908584967255592
Valid Loss:  0.059270478785037994
Epoch:  440  	Training Loss: 0.04955562949180603
Test Loss:  0.059085555374622345
Valid Loss:  0.059270329773426056
Epoch:  441  	Training Loss: 0.04955504462122917
Test Loss:  0.05908525735139847
Valid Loss:  0.05927015841007233
Epoch:  442  	Training Loss: 0.049554452300071716
Test Loss:  0.059084951877593994
Valid Loss:  0.05927000939846039
Epoch:  443  	Training Loss: 0.04955386370420456
Test Loss:  0.05908465385437012
Valid Loss:  0.05926983430981636
Epoch:  444  	Training Loss: 0.0495532751083374
Test Loss:  0.05908435583114624
Valid Loss:  0.05926969274878502
Epoch:  445  	Training Loss: 0.049552686512470245
Test Loss:  0.05908404663205147
Valid Loss:  0.059269510209560394
Epoch:  446  	Training Loss: 0.04955209791660309
Test Loss:  0.05908374860882759
Valid Loss:  0.059269364923238754
Epoch:  447  	Training Loss: 0.04955151304602623
Test Loss:  0.059083446860313416
Valid Loss:  0.05926918983459473
Epoch:  448  	Training Loss: 0.049550920724868774
Test Loss:  0.05908314883708954
Valid Loss:  0.05926903709769249
Epoch:  449  	Training Loss: 0.04955033212900162
Test Loss:  0.05908285081386566
Valid Loss:  0.05926888436079025
Epoch:  450  	Training Loss: 0.04954975098371506
Test Loss:  0.05908254534006119
Valid Loss:  0.059268705546855927
Epoch:  451  	Training Loss: 0.0495491623878479
Test Loss:  0.05908224731683731
Valid Loss:  0.059268560260534286
Epoch:  452  	Training Loss: 0.04954857751727104
Test Loss:  0.05908194184303284
Valid Loss:  0.05926840752363205
Epoch:  453  	Training Loss: 0.049547985196113586
Test Loss:  0.05908164009451866
Valid Loss:  0.05926821380853653
Epoch:  454  	Training Loss: 0.04954739660024643
Test Loss:  0.05908133089542389
Valid Loss:  0.05926806479692459
Epoch:  455  	Training Loss: 0.04954680800437927
Test Loss:  0.059081025421619415
Valid Loss:  0.05926790460944176
Epoch:  456  	Training Loss: 0.049546219408512115
Test Loss:  0.05908072367310524
Valid Loss:  0.05926772207021713
Epoch:  457  	Training Loss: 0.049545638263225555
Test Loss:  0.059080418199300766
Valid Loss:  0.0592675656080246
Epoch:  458  	Training Loss: 0.0495450422167778
Test Loss:  0.05908011272549629
Valid Loss:  0.059267379343509674
Epoch:  459  	Training Loss: 0.049544453620910645
Test Loss:  0.059079814702272415
Valid Loss:  0.05926721543073654
Epoch:  460  	Training Loss: 0.04954386502504349
Test Loss:  0.059079498052597046
Valid Loss:  0.0592670775949955
Epoch:  461  	Training Loss: 0.04954328015446663
Test Loss:  0.059079188853502274
Valid Loss:  0.059266943484544754
Epoch:  462  	Training Loss: 0.04954269155859947
Test Loss:  0.0590788833796978
Valid Loss:  0.059266798198223114
Epoch:  463  	Training Loss: 0.049542102962732315
Test Loss:  0.059078581631183624
Valid Loss:  0.05926663428544998
Epoch:  464  	Training Loss: 0.04954151809215546
Test Loss:  0.05907827615737915
Valid Loss:  0.05926649272441864
Epoch:  465  	Training Loss: 0.049540936946868896
Test Loss:  0.059077970683574677
Valid Loss:  0.05926637351512909
Epoch:  466  	Training Loss: 0.04954034835100174
Test Loss:  0.0590776726603508
Valid Loss:  0.059266187250614166
Epoch:  467  	Training Loss: 0.04953976348042488
Test Loss:  0.05907735973596573
Valid Loss:  0.059266097843647
Epoch:  468  	Training Loss: 0.049539174884557724
Test Loss:  0.05907706171274185
Valid Loss:  0.05926593393087387
Epoch:  469  	Training Loss: 0.049538590013980865
Test Loss:  0.05907674878835678
Valid Loss:  0.059265777468681335
Epoch:  470  	Training Loss: 0.049538008868694305
Test Loss:  0.059076450765132904
Valid Loss:  0.0592656172811985
Epoch:  471  	Training Loss: 0.04953742027282715
Test Loss:  0.05907614901661873
Valid Loss:  0.05926547199487686
Epoch:  472  	Training Loss: 0.04953683912754059
Test Loss:  0.059075839817523956
Valid Loss:  0.059265341609716415
Epoch:  473  	Training Loss: 0.04953625053167343
Test Loss:  0.059075530618429184
Valid Loss:  0.05926518887281418
Epoch:  474  	Training Loss: 0.049535661935806274
Test Loss:  0.05907522141933441
Valid Loss:  0.059265054762363434
Epoch:  475  	Training Loss: 0.049535077065229416
Test Loss:  0.05907491594552994
Valid Loss:  0.05926485359668732
Epoch:  476  	Training Loss: 0.04953449219465256
Test Loss:  0.059074610471725464
Valid Loss:  0.05926476791501045
Epoch:  477  	Training Loss: 0.0495339073240757
Test Loss:  0.05907430499792099
Valid Loss:  0.059264615178108215
Epoch:  478  	Training Loss: 0.04953332245349884
Test Loss:  0.05907399207353592
Valid Loss:  0.05926443636417389
Epoch:  479  	Training Loss: 0.04953273385763168
Test Loss:  0.059073690325021744
Valid Loss:  0.059264298528432846
Epoch:  480  	Training Loss: 0.04953215271234512
Test Loss:  0.05907337740063667
Valid Loss:  0.05926413834095001
Epoch:  481  	Training Loss: 0.049531564116477966
Test Loss:  0.0590730756521225
Valid Loss:  0.059264007955789566
Epoch:  482  	Training Loss: 0.04953097552061081
Test Loss:  0.05907277762889862
Valid Loss:  0.059263862669467926
Epoch:  483  	Training Loss: 0.049530401825904846
Test Loss:  0.05907246842980385
Valid Loss:  0.059263717383146286
Epoch:  484  	Training Loss: 0.04952981695532799
Test Loss:  0.05907216668128967
Valid Loss:  0.05926358327269554
Epoch:  485  	Training Loss: 0.04952923581004143
Test Loss:  0.0590718649327755
Valid Loss:  0.059263430535793304
Epoch:  486  	Training Loss: 0.04952865466475487
Test Loss:  0.05907156690955162
Valid Loss:  0.059263262897729874
Epoch:  487  	Training Loss: 0.049528080970048904
Test Loss:  0.059071265161037445
Valid Loss:  0.05926314368844032
Epoch:  488  	Training Loss: 0.049527499824762344
Test Loss:  0.05907096341252327
Valid Loss:  0.05926300585269928
Epoch:  489  	Training Loss: 0.049526918679475784
Test Loss:  0.059070661664009094
Valid Loss:  0.05926283448934555
Epoch:  490  	Training Loss: 0.049526337534189224
Test Loss:  0.05907035619020462
Valid Loss:  0.0592627078294754
Epoch:  491  	Training Loss: 0.04952576011419296
Test Loss:  0.05907005816698074
Valid Loss:  0.05926257744431496
Epoch:  492  	Training Loss: 0.049525186419487
Test Loss:  0.05906974524259567
Valid Loss:  0.059262439608573914
Epoch:  493  	Training Loss: 0.04952459782361984
Test Loss:  0.0590694397687912
Valid Loss:  0.05926225334405899
Epoch:  494  	Training Loss: 0.049524012953042984
Test Loss:  0.05906912684440613
Valid Loss:  0.05926211178302765
Epoch:  495  	Training Loss: 0.04952342063188553
Test Loss:  0.05906881019473076
Valid Loss:  0.05926197022199631
Epoch:  496  	Training Loss: 0.04952283948659897
Test Loss:  0.059068500995635986
Valid Loss:  0.059261783957481384
Epoch:  497  	Training Loss: 0.04952225461602211
Test Loss:  0.059068188071250916
Valid Loss:  0.059261634945869446
Epoch:  498  	Training Loss: 0.04952166602015495
Test Loss:  0.05906787887215614
Valid Loss:  0.0592614971101284
Epoch:  499  	Training Loss: 0.049521081149578094
Test Loss:  0.05906756967306137
Valid Loss:  0.05926135182380676
Epoch:  500  	Training Loss: 0.04952049255371094
Test Loss:  0.0590672604739666
Valid Loss:  0.05926118791103363
seed is  10
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:01,  6.38s/it]  1%|          | 3/500 [00:06<14:07,  1.71s/it]  1%|          | 5/500 [00:06<07:06,  1.16it/s]  1%|▏         | 7/500 [00:06<04:18,  1.91it/s]  2%|▏         | 9/500 [00:06<02:52,  2.84it/s]  2%|▏         | 11/500 [00:13<10:57,  1.34s/it]  3%|▎         | 13/500 [00:13<07:28,  1.09it/s]  3%|▎         | 15/500 [00:13<05:12,  1.55it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:42,  2.95it/s]  4%|▍         | 21/500 [00:20<09:44,  1.22s/it]  5%|▍         | 23/500 [00:20<06:57,  1.14it/s]  5%|▌         | 25/500 [00:20<05:00,  1.58it/s]  5%|▌         | 27/500 [00:20<03:38,  2.17it/s]  6%|▌         | 29/500 [00:20<02:41,  2.92it/s]  6%|▌         | 31/500 [00:27<09:26,  1.21s/it]  7%|▋         | 33/500 [00:27<06:45,  1.15it/s]  7%|▋         | 35/500 [00:27<04:51,  1.60it/s]  7%|▋         | 37/500 [00:27<03:31,  2.18it/s]  8%|▊         | 39/500 [00:27<02:36,  2.94it/s]  8%|▊         | 41/500 [00:34<09:08,  1.19s/it]  9%|▊         | 43/500 [00:34<06:32,  1.17it/s]  9%|▉         | 45/500 [00:34<04:42,  1.61it/s]  9%|▉         | 47/500 [00:34<03:25,  2.20it/s] 10%|▉         | 49/500 [00:34<02:32,  2.96it/s] 10%|█         | 51/500 [00:47<15:54,  2.13s/it] 11%|█         | 53/500 [00:47<11:14,  1.51s/it] 11%|█         | 55/500 [00:47<07:58,  1.08s/it] 11%|█▏        | 57/500 [00:47<05:44,  1.29it/s] 12%|█▏        | 59/500 [00:47<04:10,  1.76it/s] 12%|█▏        | 61/500 [00:54<10:06,  1.38s/it] 13%|█▎        | 63/500 [00:54<07:11,  1.01it/s] 13%|█▎        | 65/500 [00:54<05:09,  1.41it/s] 13%|█▎        | 67/500 [00:54<03:44,  1.93it/s] 14%|█▍        | 69/500 [00:55<02:44,  2.62it/s]Epoch:  1  	Training Loss: 0.05188731104135513
Test Loss:  0.3272801637649536
Valid Loss:  0.31890377402305603
Epoch:  2  	Training Loss: 0.37027767300605774
Test Loss:  1.6196644306182861
Valid Loss:  1.6368186473846436
Epoch:  3  	Training Loss: 1.5386899709701538
Test Loss:  0.29060098528862
Valid Loss:  0.282327264547348
Epoch:  4  	Training Loss: 0.3322160840034485
Test Loss:  0.23730483651161194
Valid Loss:  0.2279350757598877
Epoch:  5  	Training Loss: 0.2817785441875458
Test Loss:  0.21827289462089539
Valid Loss:  0.20843732357025146
Epoch:  6  	Training Loss: 0.26311612129211426
Test Loss:  0.20432309806346893
Valid Loss:  0.19364851713180542
Epoch:  7  	Training Loss: 0.24938517808914185
Test Loss:  0.19334819912910461
Valid Loss:  0.1820838898420334
Epoch:  8  	Training Loss: 0.23861736059188843
Test Loss:  0.18805240094661713
Valid Loss:  0.17653006315231323
Epoch:  9  	Training Loss: 0.232908695936203
Test Loss:  0.18532492220401764
Valid Loss:  0.1736864149570465
Epoch:  10  	Training Loss: 0.22998888790607452
Test Loss:  0.1834137737751007
Valid Loss:  0.17151060700416565
Epoch:  11  	Training Loss: 0.227791428565979
Test Loss:  0.18193581700325012
Valid Loss:  0.16984336078166962
Epoch:  12  	Training Loss: 0.22614583373069763
Test Loss:  0.039969511330127716
Valid Loss:  0.03704197704792023
Epoch:  13  	Training Loss: 0.041807692497968674
Test Loss:  0.027627361938357353
Valid Loss:  0.024804551154375076
Epoch:  14  	Training Loss: 0.032313860952854156
Test Loss:  0.022044960409402847
Valid Loss:  0.0201319120824337
Epoch:  15  	Training Loss: 0.025090184062719345
Test Loss:  0.016935179010033607
Valid Loss:  0.01523883268237114
Epoch:  16  	Training Loss: 0.02049865946173668
Test Loss:  0.014194156974554062
Valid Loss:  0.012929817661643028
Epoch:  17  	Training Loss: 0.017189238220453262
Test Loss:  0.01150698121637106
Valid Loss:  0.01042194478213787
Epoch:  18  	Training Loss: 0.01462783757597208
Test Loss:  0.00977710634469986
Valid Loss:  0.008967996574938297
Epoch:  19  	Training Loss: 0.012626901268959045
Test Loss:  0.008261053822934628
Valid Loss:  0.007622971199452877
Epoch:  20  	Training Loss: 0.011059165000915527
Test Loss:  0.007206405512988567
Valid Loss:  0.006760019343346357
Epoch:  21  	Training Loss: 0.009825251065194607
Test Loss:  0.006311398930847645
Valid Loss:  0.005970817990601063
Epoch:  22  	Training Loss: 0.008816342800855637
Test Loss:  0.0032936446368694305
Valid Loss:  0.0035853972658514977
Epoch:  23  	Training Loss: 0.004487959202378988
Test Loss:  0.003152985591441393
Valid Loss:  0.0031622061505913734
Epoch:  24  	Training Loss: 0.004030548967421055
Test Loss:  0.012243546545505524
Valid Loss:  0.01305551640689373
Epoch:  25  	Training Loss: 0.013089592568576336
Test Loss:  0.026911355555057526
Valid Loss:  0.026531320065259933
Epoch:  26  	Training Loss: 0.028839170932769775
Test Loss:  0.007956285029649734
Valid Loss:  0.00850491039454937
Epoch:  27  	Training Loss: 0.00845717266201973
Test Loss:  0.004000240005552769
Valid Loss:  0.003942906390875578
Epoch:  28  	Training Loss: 0.0049290345050394535
Test Loss:  0.002763104857876897
Valid Loss:  0.0029512778855860233
Epoch:  29  	Training Loss: 0.0035124553833156824
Test Loss:  0.0023365009110420942
Valid Loss:  0.0024070758372545242
Epoch:  30  	Training Loss: 0.0030491212382912636
Test Loss:  0.0021633985452353954
Valid Loss:  0.0023010869044810534
Epoch:  31  	Training Loss: 0.0028294394724071026
Test Loss:  0.002062069484964013
Valid Loss:  0.00218707462772727
Epoch:  32  	Training Loss: 0.0026926102582365274
Test Loss:  0.0020562198478728533
Valid Loss:  0.00220982963219285
Epoch:  33  	Training Loss: 0.0026847273111343384
Test Loss:  0.002057597739621997
Valid Loss:  0.002214268781244755
Epoch:  34  	Training Loss: 0.0026820823550224304
Test Loss:  0.0020584799349308014
Valid Loss:  0.0022174385376274586
Epoch:  35  	Training Loss: 0.0026796506717801094
Test Loss:  0.0020591598004102707
Valid Loss:  0.002220070455223322
Epoch:  36  	Training Loss: 0.0026773298159241676
Test Loss:  0.002059774473309517
Valid Loss:  0.0022224807180464268
Epoch:  37  	Training Loss: 0.002675101161003113
Test Loss:  0.002060383791103959
Valid Loss:  0.002224800642579794
Epoch:  38  	Training Loss: 0.002672957954928279
Test Loss:  0.0020610084757208824
Valid Loss:  0.0022270847111940384
Epoch:  39  	Training Loss: 0.002670896239578724
Test Loss:  0.0020616590045392513
Valid Loss:  0.002229350619018078
Epoch:  40  	Training Loss: 0.0026689129881560802
Test Loss:  0.002062335843220353
Valid Loss:  0.0022316095419228077
Epoch:  41  	Training Loss: 0.0026670051738619804
Test Loss:  0.002063038758933544
Valid Loss:  0.002233863342553377
Epoch:  42  	Training Loss: 0.0026651700027287006
Test Loss:  0.0018453591037541628
Valid Loss:  0.002039416925981641
Epoch:  43  	Training Loss: 0.0023735438007861376
Test Loss:  0.0016460958868265152
Valid Loss:  0.0019115189788863063
Epoch:  44  	Training Loss: 0.0020752635318785906
Test Loss:  0.0014582693111151457
Valid Loss:  0.001718519488349557
Epoch:  45  	Training Loss: 0.0018977150321006775
Test Loss:  0.0015386415179818869
Valid Loss:  0.0018640077905729413
Epoch:  46  	Training Loss: 0.0018865984166041017
Test Loss:  0.0017106165178120136
Valid Loss:  0.0019419940654188395
Epoch:  47  	Training Loss: 0.0022449628449976444
Test Loss:  0.00344732403755188
Valid Loss:  0.00378206605091691
Epoch:  48  	Training Loss: 0.00374351954087615
Test Loss:  0.007748838048428297
Valid Loss:  0.007832375355064869
Epoch:  49  	Training Loss: 0.008933737874031067
Test Loss:  0.021177059039473534
Valid Loss:  0.02151085063815117
Epoch:  50  	Training Loss: 0.02211494743824005
Test Loss:  0.053112201392650604
Valid Loss:  0.05225227773189545
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.05743444710969925
Test Loss:  0.0016946143005043268
Valid Loss:  0.002176461275666952
Epoch:  52  	Training Loss: 0.0018590157851576805
Test Loss:  0.0013559021754190326
Valid Loss:  0.0018656863830983639
Epoch:  53  	Training Loss: 0.0015799662796780467
Test Loss:  0.0012716064229607582
Valid Loss:  0.0017607859335839748
Epoch:  54  	Training Loss: 0.0014802798395976424
Test Loss:  0.0011956255184486508
Valid Loss:  0.0016896674642339349
Epoch:  55  	Training Loss: 0.001427261857315898
Test Loss:  0.0011506170267239213
Valid Loss:  0.001636649714782834
Epoch:  56  	Training Loss: 0.0013898657634854317
Test Loss:  0.0011072242632508278
Valid Loss:  0.0015932819806039333
Epoch:  57  	Training Loss: 0.0013593551702797413
Test Loss:  0.0010722256265580654
Valid Loss:  0.0015546412905678153
Epoch:  58  	Training Loss: 0.0013338918797671795
Test Loss:  0.0010417785961180925
Valid Loss:  0.0015220209024846554
Epoch:  59  	Training Loss: 0.001313274260610342
Test Loss:  0.0010154206538572907
Valid Loss:  0.0014931734185665846
Epoch:  60  	Training Loss: 0.0012955632992088795
Test Loss:  0.0009919374715536833
Valid Loss:  0.0014680386520922184
Epoch:  61  	Training Loss: 0.0012806402519345284
Test Loss:  0.0009714666521176696
Valid Loss:  0.001446262584067881
Epoch:  62  	Training Loss: 0.0012680720537900925
Test Loss:  0.0009468335192650557
Valid Loss:  0.001416610088199377
Epoch:  63  	Training Loss: 0.0012508032377809286
Test Loss:  0.0009264540858566761
Valid Loss:  0.0013892726274207234
Epoch:  64  	Training Loss: 0.0012350105680525303
Test Loss:  0.0009052371024154127
Valid Loss:  0.0013623994309455156
Epoch:  65  	Training Loss: 0.0012188006658107042
Test Loss:  0.0008811993757262826
Valid Loss:  0.0013332576490938663
Epoch:  66  	Training Loss: 0.0011994034284725785
Test Loss:  0.0008505273144692183
Valid Loss:  0.0012940821470692754
Epoch:  67  	Training Loss: 0.0011690862011164427
Test Loss:  0.00085061090067029
Valid Loss:  0.0012865301687270403
Epoch:  68  	Training Loss: 0.0011617031414061785
Test Loss:  0.0008341540233232081
Valid Loss:  0.001264021615497768
Epoch:  69  	Training Loss: 0.001152766402810812
Test Loss:  0.0008291769772768021
Valid Loss:  0.0012539566960185766
Epoch:  70  	Training Loss: 0.001149211311712861
Test Loss:   14%|█▍        | 71/500 [01:01<08:50,  1.24s/it] 15%|█▍        | 73/500 [01:01<06:18,  1.13it/s] 15%|█▌        | 75/500 [01:01<04:32,  1.56it/s] 15%|█▌        | 77/500 [01:01<03:17,  2.14it/s] 16%|█▌        | 79/500 [01:02<02:26,  2.88it/s] 16%|█▌        | 81/500 [01:08<08:29,  1.22s/it] 17%|█▋        | 83/500 [01:08<06:03,  1.15it/s] 17%|█▋        | 85/500 [01:08<04:21,  1.58it/s] 17%|█▋        | 87/500 [01:08<03:10,  2.17it/s] 18%|█▊        | 89/500 [01:09<02:21,  2.90it/s] 18%|█▊        | 91/500 [01:15<08:16,  1.21s/it] 19%|█▊        | 93/500 [01:15<05:54,  1.15it/s] 19%|█▉        | 95/500 [01:15<04:14,  1.59it/s] 19%|█▉        | 97/500 [01:15<03:05,  2.17it/s] 20%|█▉        | 99/500 [01:16<02:17,  2.92it/s] 20%|██        | 101/500 [01:22<08:17,  1.25s/it] 21%|██        | 103/500 [01:22<05:57,  1.11it/s] 21%|██        | 105/500 [01:23<04:17,  1.53it/s] 21%|██▏       | 107/500 [01:23<03:07,  2.09it/s] 22%|██▏       | 109/500 [01:23<02:18,  2.82it/s] 22%|██▏       | 111/500 [01:29<07:52,  1.22s/it] 23%|██▎       | 113/500 [01:29<05:37,  1.15it/s] 23%|██▎       | 115/500 [01:30<04:02,  1.59it/s] 23%|██▎       | 117/500 [01:30<02:56,  2.17it/s] 24%|██▍       | 119/500 [01:30<02:10,  2.92it/s] 24%|██▍       | 121/500 [01:36<07:42,  1.22s/it] 25%|██▍       | 123/500 [01:37<05:30,  1.14it/s] 25%|██▌       | 125/500 [01:37<03:57,  1.58it/s] 25%|██▌       | 127/500 [01:37<02:53,  2.16it/s] 26%|██▌       | 129/500 [01:37<02:07,  2.90it/s] 26%|██▌       | 131/500 [01:44<07:32,  1.23s/it] 27%|██▋       | 133/500 [01:44<05:22,  1.14it/s] 27%|██▋       | 135/500 [01:44<03:52,  1.57it/s] 27%|██▋       | 137/500 [01:44<02:48,  2.15it/s]0.0008176870178431273
Valid Loss:  0.001240048441104591
Epoch:  71  	Training Loss: 0.0011456506326794624
Test Loss:  0.0008194925030693412
Valid Loss:  0.001237562159076333
Epoch:  72  	Training Loss: 0.0011442115064710379
Test Loss:  0.0008023769478313625
Valid Loss:  0.0012211489956825972
Epoch:  73  	Training Loss: 0.0011184957111254334
Test Loss:  0.0007925574900582433
Valid Loss:  0.0012109267991036177
Epoch:  74  	Training Loss: 0.0011124885641038418
Test Loss:  0.0007859261822886765
Valid Loss:  0.0012030008947476745
Epoch:  75  	Training Loss: 0.0011089106556028128
Test Loss:  0.0007802537875249982
Valid Loss:  0.001195744494907558
Epoch:  76  	Training Loss: 0.0011059868847951293
Test Loss:  0.0007749666692689061
Valid Loss:  0.0011891094036400318
Epoch:  77  	Training Loss: 0.0011035497300326824
Test Loss:  0.0007703866576775908
Valid Loss:  0.0011834423057734966
Epoch:  78  	Training Loss: 0.0011019555386155844
Test Loss:  0.0007681989227421582
Valid Loss:  0.001180486986413598
Epoch:  79  	Training Loss: 0.001100793480873108
Test Loss:  0.0007642058189958334
Valid Loss:  0.0011755754239857197
Epoch:  80  	Training Loss: 0.001099585322663188
Test Loss:  0.0007627200102433562
Valid Loss:  0.001173445489257574
Epoch:  81  	Training Loss: 0.0010987550485879183
Test Loss:  0.0007594224298372865
Valid Loss:  0.0011691483668982983
Epoch:  82  	Training Loss: 0.0010976603953167796
Test Loss:  0.0007472541183233261
Valid Loss:  0.0011536730453372002
Epoch:  83  	Training Loss: 0.0010885513620451093
Test Loss:  0.0007396925939247012
Valid Loss:  0.0011437791399657726
Epoch:  84  	Training Loss: 0.0010829197708517313
Test Loss:  0.0007354472763836384
Valid Loss:  0.0011366570834070444
Epoch:  85  	Training Loss: 0.0010794473346322775
Test Loss:  0.0007327863713726401
Valid Loss:  0.0011317883618175983
Epoch:  86  	Training Loss: 0.0010774144902825356
Test Loss:  0.000730802770704031
Valid Loss:  0.0011284464271739125
Epoch:  87  	Training Loss: 0.0010759755969047546
Test Loss:  0.0007291754009202123
Valid Loss:  0.0011257334845140576
Epoch:  88  	Training Loss: 0.0010747751221060753
Test Loss:  0.0007277282420545816
Valid Loss:  0.0011233834084123373
Epoch:  89  	Training Loss: 0.001073695020750165
Test Loss:  0.0007264934247359633
Valid Loss:  0.0011214603437110782
Epoch:  90  	Training Loss: 0.0010728134075179696
Test Loss:  0.0007254456868395209
Valid Loss:  0.0011198616120964289
Epoch:  91  	Training Loss: 0.001072071143426001
Test Loss:  0.0007245225133374333
Valid Loss:  0.0011185123585164547
Epoch:  92  	Training Loss: 0.001071430859155953
Test Loss:  0.0007203251007013023
Valid Loss:  0.0011101465206593275
Epoch:  93  	Training Loss: 0.001069581019692123
Test Loss:  0.0007190059404820204
Valid Loss:  0.0011077503440901637
Epoch:  94  	Training Loss: 0.0010690180351957679
Test Loss:  0.000717584160156548
Valid Loss:  0.0011047180742025375
Epoch:  95  	Training Loss: 0.0010686267632991076
Test Loss:  0.0007164948619902134
Valid Loss:  0.0011024447157979012
Epoch:  96  	Training Loss: 0.00106830894947052
Test Loss:  0.0007155447965487838
Valid Loss:  0.0011004144325852394
Epoch:  97  	Training Loss: 0.0010680414270609617
Test Loss:  0.0007147422293201089
Valid Loss:  0.001098686596378684
Epoch:  98  	Training Loss: 0.001067811856046319
Test Loss:  0.0007140507223084569
Valid Loss:  0.0010972105665132403
Epoch:  99  	Training Loss: 0.0010676176752895117
Test Loss:  0.0007134599145501852
Valid Loss:  0.0010959457140415907
Epoch:  100  	Training Loss: 0.0010674420045688748
Test Loss:  0.0007129530422389507
Valid Loss:  0.0010948720155283809
Epoch:  101  	Training Loss: 0.001067287870682776
Test Loss:  0.000712516950443387
Valid Loss:  0.0010939592029899359
Epoch:  102  	Training Loss: 0.001067157369107008
Test Loss:  0.0007083909586071968
Valid Loss:  0.001090344274416566
Epoch:  103  	Training Loss: 0.0010635200887918472
Test Loss:  0.0007046135142445564
Valid Loss:  0.0010875557782128453
Epoch:  104  	Training Loss: 0.0010601067915558815
Test Loss:  0.0007002681959420443
Valid Loss:  0.0010833311825990677
Epoch:  105  	Training Loss: 0.0010567773133516312
Test Loss:  0.0006965157808735967
Valid Loss:  0.0010804065968841314
Epoch:  106  	Training Loss: 0.0010535273468121886
Test Loss:  0.0006926304777152836
Valid Loss:  0.0010770773515105247
Epoch:  107  	Training Loss: 0.0010503437370061874
Test Loss:  0.0006890383083373308
Valid Loss:  0.0010743611492216587
Epoch:  108  	Training Loss: 0.0010472682770341635
Test Loss:  0.0006856669206172228
Valid Loss:  0.0010716216638684273
Epoch:  109  	Training Loss: 0.0010443462524563074
Test Loss:  0.0006826201570220292
Valid Loss:  0.0010693036019802094
Epoch:  110  	Training Loss: 0.0010415620636194944
Test Loss:  0.0006796037196181715
Valid Loss:  0.001066981116309762
Epoch:  111  	Training Loss: 0.0010388240916654468
Test Loss:  0.0006766770384274423
Valid Loss:  0.0010648128809407353
Epoch:  112  	Training Loss: 0.0010361259337514639
Test Loss:  0.0006732435431331396
Valid Loss:  0.0010622558183968067
Epoch:  113  	Training Loss: 0.0010293853702023625
Test Loss:  0.0006687871646136045
Valid Loss:  0.0010600537061691284
Epoch:  114  	Training Loss: 0.0010219098767265677
Test Loss:  0.0006679475773125887
Valid Loss:  0.0010582669638097286
Epoch:  115  	Training Loss: 0.001020926982164383
Test Loss:  0.0006681791273877025
Valid Loss:  0.0010586284333840013
Epoch:  116  	Training Loss: 0.0010205337312072515
Test Loss:  0.0006683398969471455
Valid Loss:  0.0010585349518805742
Epoch:  117  	Training Loss: 0.0010203379206359386
Test Loss:  0.0006685589905828238
Valid Loss:  0.00105864810757339
Epoch:  118  	Training Loss: 0.0010202102130278945
Test Loss:  0.0006686070701107383
Valid Loss:  0.0010585800046101213
Epoch:  119  	Training Loss: 0.0010201339609920979
Test Loss:  0.0006686822162009776
Valid Loss:  0.0010586241260170937
Epoch:  120  	Training Loss: 0.0010200822725892067
Test Loss:  0.0006685464759357274
Valid Loss:  0.0010584229603409767
Epoch:  121  	Training Loss: 0.001020031631924212
Test Loss:  0.0006685482803732157
Valid Loss:  0.0010584897827357054
Epoch:  122  	Training Loss: 0.0010199828539043665
Test Loss:  0.0006666620611213148
Valid Loss:  0.0010573435574769974
Epoch:  123  	Training Loss: 0.0010169417364522815
Test Loss:  0.000664598192088306
Valid Loss:  0.0010558663634583354
Epoch:  124  	Training Loss: 0.0010139482328668237
Test Loss:  0.0006624488160014153
Valid Loss:  0.001054232008755207
Epoch:  125  	Training Loss: 0.0010109831346198916
Test Loss:  0.0006602652720175683
Valid Loss:  0.0010525257093831897
Epoch:  126  	Training Loss: 0.0010080449283123016
Test Loss:  0.0006580684566870332
Valid Loss:  0.0010507829720154405
Epoch:  127  	Training Loss: 0.0010051311692222953
Test Loss:  0.0006558705354109406
Valid Loss:  0.0010490231215953827
Epoch:  128  	Training Loss: 0.0010022424394264817
Test Loss:  0.0006536738947033882
Valid Loss:  0.0010472509311512113
Epoch:  129  	Training Loss: 0.0009993752464652061
Test Loss:  0.000651482492685318
Valid Loss:  0.0010454754810780287
Epoch:  130  	Training Loss: 0.0009965318022295833
Test Loss:  0.0006492969114333391
Valid Loss:  0.0010436959564685822
Epoch:  131  	Training Loss: 0.0009937093127518892
Test Loss:  0.0006471187807619572
Valid Loss:  0.0010419156169518828
Epoch:  132  	Training Loss: 0.000990909757092595
Test Loss:  0.0006468427600339055
Valid Loss:  0.0010405362118035555
Epoch:  133  	Training Loss: 0.0009904562029987574
Test Loss:  0.0006464417092502117
Valid Loss:  0.001038797083310783
Epoch:  134  	Training Loss: 0.000990034081041813
Test Loss:  0.0006462068995460868
Valid Loss:  0.0010374088305979967
Epoch:  135  	Training Loss: 0.0009896255796775222
Test Loss:  0.000646005617454648
Valid Loss:  0.001036077388562262
Epoch:  136  	Training Loss: 0.000989227555692196
Test Loss:  0.0006458622519858181
Valid Loss:  0.0010348624782636762
Epoch:  137  	Training Loss: 0.0009888395434245467
Test Loss:  0.0006457515992224216
Valid Loss:  0.0010337166022509336
Epoch:  138  	Training Loss: 0.000988459913060069
Test Loss:  0.0006456730188801885
Valid Loss:  0.0010326351039111614
 28%|██▊       | 139/500 [01:44<02:04,  2.89it/s] 28%|██▊       | 141/500 [01:51<07:14,  1.21s/it] 29%|██▊       | 143/500 [01:51<05:10,  1.15it/s] 29%|██▉       | 145/500 [01:51<03:43,  1.59it/s] 29%|██▉       | 147/500 [01:51<02:45,  2.13it/s] 30%|██▉       | 149/500 [01:51<02:04,  2.82it/s] 30%|███       | 151/500 [01:58<07:04,  1.22s/it] 31%|███       | 153/500 [01:58<05:05,  1.14it/s] 31%|███       | 155/500 [01:58<03:40,  1.57it/s] 31%|███▏      | 157/500 [01:58<02:40,  2.14it/s] 32%|███▏      | 159/500 [01:58<01:58,  2.88it/s] 32%|███▏      | 161/500 [02:05<06:54,  1.22s/it] 33%|███▎      | 163/500 [02:05<04:55,  1.14it/s] 33%|███▎      | 165/500 [02:05<03:32,  1.58it/s] 33%|███▎      | 167/500 [02:05<02:34,  2.16it/s] 34%|███▍      | 169/500 [02:05<01:53,  2.90it/s] 34%|███▍      | 171/500 [02:12<06:43,  1.23s/it] 35%|███▍      | 173/500 [02:12<04:47,  1.14it/s] 35%|███▌      | 175/500 [02:12<03:26,  1.58it/s] 35%|███▌      | 177/500 [02:12<02:30,  2.15it/s] 36%|███▌      | 179/500 [02:12<01:51,  2.89it/s] 36%|███▌      | 181/500 [02:19<06:22,  1.20s/it] 37%|███▋      | 183/500 [02:19<04:32,  1.16it/s] 37%|███▋      | 185/500 [02:19<03:16,  1.61it/s] 37%|███▋      | 187/500 [02:19<02:22,  2.19it/s] 38%|███▊      | 189/500 [02:19<01:45,  2.95it/s] 38%|███▊      | 191/500 [02:26<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:26<04:22,  1.17it/s] 39%|███▉      | 195/500 [02:26<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:26<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:26<01:41,  2.97it/s] 40%|████      | 201/500 [02:33<05:58,  1.20s/it] 41%|████      | 203/500 [02:33<04:15,  1.16it/s] 41%|████      | 205/500 [02:33<03:03,  1.61it/s]Epoch:  139  	Training Loss: 0.0009880880825221539
Test Loss:  0.0006456159753724933
Valid Loss:  0.001031601568683982
Epoch:  140  	Training Loss: 0.000987724750302732
Test Loss:  0.0006455766852013767
Valid Loss:  0.00103060866240412
Epoch:  141  	Training Loss: 0.0009873679373413324
Test Loss:  0.0006455524126067758
Valid Loss:  0.0010296509135514498
Epoch:  142  	Training Loss: 0.0009870193898677826
Test Loss:  0.0006420134450308979
Valid Loss:  0.0010266137542203069
Epoch:  143  	Training Loss: 0.0009831790812313557
Test Loss:  0.0006385328597389162
Valid Loss:  0.0010237493552267551
Epoch:  144  	Training Loss: 0.0009794760262593627
Test Loss:  0.0006351710762828588
Valid Loss:  0.0010209777392446995
Epoch:  145  	Training Loss: 0.0009758610976859927
Test Loss:  0.0006318248924799263
Valid Loss:  0.0010181572288274765
Epoch:  146  	Training Loss: 0.0009723182301968336
Test Loss:  0.0006285066483542323
Valid Loss:  0.0010153346229344606
Epoch:  147  	Training Loss: 0.0009688368299975991
Test Loss:  0.0006251637823879719
Valid Loss:  0.001012454740703106
Epoch:  148  	Training Loss: 0.000965405604802072
Test Loss:  0.0006218759808689356
Valid Loss:  0.001009632251225412
Epoch:  149  	Training Loss: 0.0009620151249691844
Test Loss:  0.0006187783437781036
Valid Loss:  0.00100686342921108
Epoch:  150  	Training Loss: 0.0009587104432284832
Test Loss:  0.0006160439224913716
Valid Loss:  0.0010042826179414988
Epoch:  151  	Training Loss: 0.0009557469747960567
Test Loss:  0.000613451877143234
Valid Loss:  0.0010018062312155962
Epoch:  152  	Training Loss: 0.0009528922964818776
Test Loss:  0.0006096270517446101
Valid Loss:  0.0009978408925235271
Epoch:  153  	Training Loss: 0.0009495491394773126
Test Loss:  0.0006061644526198506
Valid Loss:  0.0009941118769347668
Epoch:  154  	Training Loss: 0.0009466094197705388
Test Loss:  0.0006030190270394087
Valid Loss:  0.0009906194172799587
Epoch:  155  	Training Loss: 0.0009439042187295854
Test Loss:  0.0006000396097078919
Valid Loss:  0.0009873788803815842
Epoch:  156  	Training Loss: 0.000941347680054605
Test Loss:  0.0005972729995846748
Valid Loss:  0.0009843531297519803
Epoch:  157  	Training Loss: 0.0009389412589371204
Test Loss:  0.0005946906167082489
Valid Loss:  0.0009815865196287632
Epoch:  158  	Training Loss: 0.0009366442682221532
Test Loss:  0.0005922337295487523
Valid Loss:  0.0009789910400286317
Epoch:  159  	Training Loss: 0.0009344440186396241
Test Loss:  0.0005899061798118055
Valid Loss:  0.0009765395661816001
Epoch:  160  	Training Loss: 0.0009323294507339597
Test Loss:  0.0005876827053725719
Valid Loss:  0.0009742383263073862
Epoch:  161  	Training Loss: 0.0009303086553700268
Test Loss:  0.0005856049247086048
Valid Loss:  0.0009720951784402132
Epoch:  162  	Training Loss: 0.0009284355910494924
Test Loss:  0.0005842723185196519
Valid Loss:  0.0009724101983010769
Epoch:  163  	Training Loss: 0.0009236973710358143
Test Loss:  0.0005829916335642338
Valid Loss:  0.000972659036051482
Epoch:  164  	Training Loss: 0.0009196341270580888
Test Loss:  0.000581625965423882
Valid Loss:  0.000972683890722692
Epoch:  165  	Training Loss: 0.0009158840402960777
Test Loss:  0.0005800924845971167
Valid Loss:  0.0009723569382913411
Epoch:  166  	Training Loss: 0.0009123381460085511
Test Loss:  0.000578415347263217
Valid Loss:  0.0009717257344163954
Epoch:  167  	Training Loss: 0.0009089321829378605
Test Loss:  0.0005765858222730458
Valid Loss:  0.00097077083773911
Epoch:  168  	Training Loss: 0.0009056102717295289
Test Loss:  0.0005746192764490843
Valid Loss:  0.0009695579065009952
Epoch:  169  	Training Loss: 0.0009023219463415444
Test Loss:  0.0005725809023715556
Valid Loss:  0.0009681119117885828
Epoch:  170  	Training Loss: 0.0008990528294816613
Test Loss:  0.0005705708754248917
Valid Loss:  0.0009665603865869343
Epoch:  171  	Training Loss: 0.0008958542020991445
Test Loss:  0.0005685067735612392
Valid Loss:  0.0009648908744566143
Epoch:  172  	Training Loss: 0.0008927090675570071
Test Loss:  0.0005637403228320181
Valid Loss:  0.0009534612763673067
Epoch:  173  	Training Loss: 0.0008905711001716554
Test Loss:  0.0005625020712614059
Valid Loss:  0.000955659372266382
Epoch:  174  	Training Loss: 0.0008886134601198137
Test Loss:  0.0005586480256170034
Valid Loss:  0.0009466274059377611
Epoch:  175  	Training Loss: 0.0008867991855368018
Test Loss:  0.0005577086703851819
Valid Loss:  0.0009483203175477684
Epoch:  176  	Training Loss: 0.0008850981248542666
Test Loss:  0.0005544761079363525
Valid Loss:  0.0009411670034751296
Epoch:  177  	Training Loss: 0.0008834890904836357
Test Loss:  0.0005536432145163417
Valid Loss:  0.0009423838928341866
Epoch:  178  	Training Loss: 0.000881952466443181
Test Loss:  0.0005509081529453397
Valid Loss:  0.0009366936283186078
Epoch:  179  	Training Loss: 0.0008804781828075647
Test Loss:  0.0005501049454323947
Valid Loss:  0.0009374956716783345
Epoch:  180  	Training Loss: 0.0008790523861534894
Test Loss:  0.0005477646482177079
Valid Loss:  0.0009329417371191084
Epoch:  181  	Training Loss: 0.0008776688482612371
Test Loss:  0.0005469583556987345
Valid Loss:  0.0009334960486739874
Epoch:  182  	Training Loss: 0.0008763208752498031
Test Loss:  0.0005463915294967592
Valid Loss:  0.0009318647789768875
Epoch:  183  	Training Loss: 0.000876254343893379
Test Loss:  0.0005464529967866838
Valid Loss:  0.0009320728713646531
Epoch:  184  	Training Loss: 0.0008762513753026724
Test Loss:  0.0005464196437969804
Valid Loss:  0.0009319795062765479
Epoch:  185  	Training Loss: 0.0008762497454881668
Test Loss:  0.0005464029964059591
Valid Loss:  0.0009319387609139085
Epoch:  186  	Training Loss: 0.0008762488141655922
Test Loss:  0.0005463836714625359
Valid Loss:  0.0009318902739323676
Epoch:  187  	Training Loss: 0.0008762475335970521
Test Loss:  0.0005463658599182963
Valid Loss:  0.0009318426600657403
Epoch:  188  	Training Loss: 0.0008762461948208511
Test Loss:  0.0005463472916744649
Valid Loss:  0.0009317960939370096
Epoch:  189  	Training Loss: 0.0008762450306676328
Test Loss:  0.0005463305860757828
Valid Loss:  0.0009317516814917326
Epoch:  190  	Training Loss: 0.0008762440411373973
Test Loss:  0.0005463119596242905
Valid Loss:  0.0009317062795162201
Epoch:  191  	Training Loss: 0.0008762425277382135
Test Loss:  0.0005462945555336773
Valid Loss:  0.0009316625073552132
Epoch:  192  	Training Loss: 0.0008762416546232998
Test Loss:  0.0005459105595946312
Valid Loss:  0.000931067974306643
Epoch:  193  	Training Loss: 0.0008760494529269636
Test Loss:  0.0005455913487821817
Valid Loss:  0.0009305781568400562
Epoch:  194  	Training Loss: 0.0008758748299442232
Test Loss:  0.0005453050835058093
Valid Loss:  0.0009301515528932214
Epoch:  195  	Training Loss: 0.0008757082978263497
Test Loss:  0.0005450487951748073
Valid Loss:  0.0009298034128732979
Epoch:  196  	Training Loss: 0.0008755445014685392
Test Loss:  0.0005448241718113422
Valid Loss:  0.0009294815827161074
Epoch:  197  	Training Loss: 0.0008753924630582333
Test Loss:  0.0005446298164315522
Valid Loss:  0.0009291985770687461
Epoch:  198  	Training Loss: 0.0008752577705308795
Test Loss:  0.0005444440757855773
Valid Loss:  0.0009289378067478538
Epoch:  199  	Training Loss: 0.0008751243585720658
Test Loss:  0.0005442669498734176
Valid Loss:  0.0009286962449550629
Epoch:  200  	Training Loss: 0.0008749933913350105
Test Loss:  0.0005441103130578995
Valid Loss:  0.0009284772677347064
Epoch:  201  	Training Loss: 0.0008748668478801847
Test Loss:  0.0005439580418169498
Valid Loss:  0.0009282741812057793
Epoch:  202  	Training Loss: 0.0008747405954636633
Test Loss:  0.0005425597773864865
Valid Loss:  0.0009268363355658948
Epoch:  203  	Training Loss: 0.0008733296999707818
Test Loss:  0.0005412542959675193
Valid Loss:  0.0009255086188204587
Epoch:  204  	Training Loss: 0.0008719717734493315
Test Loss:  0.0005400233203545213
Valid Loss:  0.0009242730448022485
Epoch:  205  	Training Loss: 0.0008706776425242424
Test Loss:  0.0005388563731685281
Valid Loss:  0.0009231261210516095
Epoch:  206  	Training Loss: 0.000869450275786221
Test Loss:  0.000537722953595221
Valid Loss:  0.0009220269275829196
Epoch:  207  	Training Loss: 0.0008682484040036798
 41%|████▏     | 207/500 [02:33<02:13,  2.19it/s] 42%|████▏     | 209/500 [02:33<01:38,  2.94it/s] 42%|████▏     | 211/500 [02:40<05:45,  1.20s/it] 43%|████▎     | 213/500 [02:40<04:06,  1.16it/s] 43%|████▎     | 215/500 [02:40<02:56,  1.61it/s] 43%|████▎     | 217/500 [02:40<02:08,  2.20it/s] 44%|████▍     | 219/500 [02:40<01:34,  2.96it/s] 44%|████▍     | 221/500 [02:53<10:02,  2.16s/it] 45%|████▍     | 223/500 [02:53<07:04,  1.53s/it] 45%|████▌     | 225/500 [02:53<05:00,  1.09s/it] 45%|████▌     | 227/500 [02:53<03:34,  1.27it/s] 46%|████▌     | 229/500 [02:54<02:34,  1.76it/s] 46%|████▌     | 231/500 [03:00<06:15,  1.40s/it] 47%|████▋     | 233/500 [03:00<04:26,  1.00it/s] 47%|████▋     | 235/500 [03:00<03:10,  1.39it/s] 47%|████▋     | 237/500 [03:01<02:17,  1.91it/s] 48%|████▊     | 239/500 [03:01<01:40,  2.59it/s] 48%|████▊     | 241/500 [03:07<05:20,  1.24s/it] 49%|████▊     | 243/500 [03:07<03:48,  1.13it/s] 49%|████▉     | 245/500 [03:07<02:45,  1.54it/s] 49%|████▉     | 247/500 [03:08<02:01,  2.08it/s] 50%|████▉     | 249/500 [03:08<01:30,  2.76it/s] 50%|█████     | 251/500 [03:14<05:07,  1.23s/it] 51%|█████     | 253/500 [03:15<03:40,  1.12it/s] 51%|█████     | 255/500 [03:15<02:39,  1.54it/s] 51%|█████▏    | 257/500 [03:15<01:56,  2.08it/s] 52%|█████▏    | 259/500 [03:15<01:27,  2.76it/s] 52%|█████▏    | 261/500 [03:22<04:55,  1.24s/it] 53%|█████▎    | 263/500 [03:22<03:30,  1.13it/s] 53%|█████▎    | 265/500 [03:22<02:30,  1.56it/s] 53%|█████▎    | 267/500 [03:22<01:49,  2.13it/s] 54%|█████▍    | 269/500 [03:22<01:21,  2.84it/s] 54%|█████▍    | 271/500 [03:29<04:44,  1.24s/it] 55%|█████▍    | 273/500 [03:29<03:22,  1.12it/s]Test Loss:  0.0005366270197555423
Valid Loss:  0.0009209803538396955
Epoch:  208  	Training Loss: 0.000867081806063652
Test Loss:  0.0005355492467060685
Valid Loss:  0.0009199635242111981
Epoch:  209  	Training Loss: 0.0008659333107061684
Test Loss:  0.0005344944074749947
Valid Loss:  0.0009189870324917138
Epoch:  210  	Training Loss: 0.000864813569933176
Test Loss:  0.0005334581364877522
Valid Loss:  0.000918040401302278
Epoch:  211  	Training Loss: 0.0008637123974040151
Test Loss:  0.0005324390949681401
Valid Loss:  0.0009171143174171448
Epoch:  212  	Training Loss: 0.0008626263588666916
Test Loss:  0.0005329593550413847
Valid Loss:  0.0009207533439621329
Epoch:  213  	Training Loss: 0.0008595430990681052
Test Loss:  0.0005299454787746072
Valid Loss:  0.0009139032918028533
Epoch:  214  	Training Loss: 0.0008568145567551255
Test Loss:  0.0005326344980858266
Valid Loss:  0.0009228095877915621
Epoch:  215  	Training Loss: 0.0008546165190637112
Test Loss:  0.000528399832546711
Valid Loss:  0.0009096188587136567
Epoch:  216  	Training Loss: 0.0008533675572834909
Test Loss:  0.0005369886057451367
Valid Loss:  0.0009315569186583161
Epoch:  217  	Training Loss: 0.0008540938142687082
Test Loss:  0.0005333512672223151
Valid Loss:  0.0009078335133381188
Epoch:  218  	Training Loss: 0.0008590834913775325
Test Loss:  0.0005617547431029379
Valid Loss:  0.0009659449569880962
Epoch:  219  	Training Loss: 0.0008744640508666635
Test Loss:  0.0006012450321577489
Valid Loss:  0.0009544324711896479
Epoch:  220  	Training Loss: 0.0009383055148646235
Test Loss:  0.0007530094590038061
Valid Loss:  0.0012039653956890106
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.0010730782523751259
Test Loss:  0.0006785247242078185
Valid Loss:  0.0011273184791207314
Epoch:  222  	Training Loss: 0.0009981257608160377
Test Loss:  0.0005580163560807705
Valid Loss:  0.0009565100772306323
Epoch:  223  	Training Loss: 0.0008618307765573263
Test Loss:  0.0005420094821602106
Valid Loss:  0.0009467937052249908
Epoch:  224  	Training Loss: 0.000846431590616703
Test Loss:  0.0005392103921622038
Valid Loss:  0.0009411679347977042
Epoch:  225  	Training Loss: 0.0008448243024758995
Test Loss:  0.0005368400597944856
Valid Loss:  0.0009366555605083704
Epoch:  226  	Training Loss: 0.0008434213232249022
Test Loss:  0.0005347324768081307
Valid Loss:  0.0009325316059403121
Epoch:  227  	Training Loss: 0.0008421657257713377
Test Loss:  0.0005328546976670623
Valid Loss:  0.0009288102737627923
Epoch:  228  	Training Loss: 0.0008410177542828023
Test Loss:  0.0005311786662787199
Valid Loss:  0.0009254679316654801
Epoch:  229  	Training Loss: 0.0008399483631365001
Test Loss:  0.0005296950112096965
Valid Loss:  0.0009224334498867393
Epoch:  230  	Training Loss: 0.0008389482973143458
Test Loss:  0.0005283657228574157
Valid Loss:  0.0009196215542033315
Epoch:  231  	Training Loss: 0.0008380217477679253
Test Loss:  0.0005271639092825353
Valid Loss:  0.000917025376111269
Epoch:  232  	Training Loss: 0.0008371504954993725
Test Loss:  0.0005214530974626541
Valid Loss:  0.0009127192897722125
Epoch:  233  	Training Loss: 0.0008275230065919459
Test Loss:  0.0005187458009459078
Valid Loss:  0.0009112714906223118
Epoch:  234  	Training Loss: 0.0008230870589613914
Test Loss:  0.0005180876469239593
Valid Loss:  0.0009101961040869355
Epoch:  235  	Training Loss: 0.0008209217921830714
Test Loss:  0.0005175663973204792
Valid Loss:  0.0009092791005969048
Epoch:  236  	Training Loss: 0.000819442211650312
Test Loss:  0.0005171911907382309
Valid Loss:  0.0009083471959456801
Epoch:  237  	Training Loss: 0.0008184757316485047
Test Loss:  0.0005173124372959137
Valid Loss:  0.0009082795586436987
Epoch:  238  	Training Loss: 0.0008176694973371923
Test Loss:  0.000516956381034106
Valid Loss:  0.00090746209025383
Epoch:  239  	Training Loss: 0.0008169287466444075
Test Loss:  0.000517066684551537
Valid Loss:  0.0009072424145415425
Epoch:  240  	Training Loss: 0.000816372805275023
Test Loss:  0.000516657717525959
Valid Loss:  0.0009062854805961251
Epoch:  241  	Training Loss: 0.0008158289128914475
Test Loss:  0.0005166616756469011
Valid Loss:  0.0009059489821083844
Epoch:  242  	Training Loss: 0.0008153790840879083
Test Loss:  0.0005110912024974823
Valid Loss:  0.0008977612596936524
Epoch:  243  	Training Loss: 0.0008116625249385834
Test Loss:  0.000506482261698693
Valid Loss:  0.0008903995621949434
Epoch:  244  	Training Loss: 0.0008086158777587116
Test Loss:  0.0005027840379625559
Valid Loss:  0.0008840757072903216
Epoch:  245  	Training Loss: 0.0008060674299485981
Test Loss:  0.0004997054929845035
Valid Loss:  0.0008787332335487008
Epoch:  246  	Training Loss: 0.0008038569358177483
Test Loss:  0.0004970238078385592
Valid Loss:  0.0008740914636291564
Epoch:  247  	Training Loss: 0.0008018718799576163
Test Loss:  0.0004948095302097499
Valid Loss:  0.0008700768812559545
Epoch:  248  	Training Loss: 0.0008001496316865087
Test Loss:  0.0004928793059661984
Valid Loss:  0.0008664984488859773
Epoch:  249  	Training Loss: 0.0007985524134710431
Test Loss:  0.000491179758682847
Valid Loss:  0.0008633577963337302
Epoch:  250  	Training Loss: 0.0007971505983732641
Test Loss:  0.0004896873724646866
Valid Loss:  0.000860558939166367
Epoch:  251  	Training Loss: 0.0007958424394018948
Test Loss:  0.0004883540677838027
Valid Loss:  0.0008580261492170393
Epoch:  252  	Training Loss: 0.0007946349796839058
Test Loss:  0.00048688691458664834
Valid Loss:  0.0008560387650504708
Epoch:  253  	Training Loss: 0.0007932313601486385
Test Loss:  0.00048545474419370294
Valid Loss:  0.0008541111601516604
Epoch:  254  	Training Loss: 0.0007918417104519904
Test Loss:  0.0004840550245717168
Valid Loss:  0.0008522365242242813
Epoch:  255  	Training Loss: 0.0007904678350314498
Test Loss:  0.000482686999021098
Valid Loss:  0.0008504099096171558
Epoch:  256  	Training Loss: 0.000789117650128901
Test Loss:  0.00048135651741176844
Valid Loss:  0.0008486463339067996
Epoch:  257  	Training Loss: 0.0007877922616899014
Test Loss:  0.0004800541209988296
Valid Loss:  0.0008469331078231335
Epoch:  258  	Training Loss: 0.00078648014459759
Test Loss:  0.0004787736979778856
Valid Loss:  0.0008452641777694225
Epoch:  259  	Training Loss: 0.0007851732661947608
Test Loss:  0.00047750998055562377
Valid Loss:  0.0008436362259089947
Epoch:  260  	Training Loss: 0.000783873547334224
Test Loss:  0.0004762652679346502
Valid Loss:  0.0008420487283729017
Epoch:  261  	Training Loss: 0.0007825822103768587
Test Loss:  0.0004750850494019687
Valid Loss:  0.0008405011030845344
Epoch:  262  	Training Loss: 0.0007813028059899807
Test Loss:  0.0004742489254567772
Valid Loss:  0.0008398672798648477
Epoch:  263  	Training Loss: 0.0007795696146786213
Test Loss:  0.00047339542652480304
Valid Loss:  0.0008391643641516566
Epoch:  264  	Training Loss: 0.0007778622675687075
Test Loss:  0.0004725483013316989
Valid Loss:  0.0008384197717532516
Epoch:  265  	Training Loss: 0.0007761762826703489
Test Loss:  0.00047169794561341405
Valid Loss:  0.0008376595797017217
Epoch:  266  	Training Loss: 0.0007745118346065283
Test Loss:  0.00047084575635381043
Valid Loss:  0.0008368868147954345
Epoch:  267  	Training Loss: 0.0007728672353550792
Test Loss:  0.00046999892219901085
Valid Loss:  0.0008361143991351128
Epoch:  268  	Training Loss: 0.0007712432416155934
Test Loss:  0.00046915747225284576
Valid Loss:  0.0008353433222509921
Epoch:  269  	Training Loss: 0.0007696390966884792
Test Loss:  0.00046832358930259943
Valid Loss:  0.0008345788810402155
Epoch:  270  	Training Loss: 0.0007680540438741446
Test Loss:  0.00046749497414566576
Valid Loss:  0.0008338199113495648
Epoch:  271  	Training Loss: 0.0007664873264729977
Test Loss:  0.00046667910646647215
Valid Loss:  0.0008330718846991658
Epoch:  272  	Training Loss: 0.0007649405742995441
Test Loss:  0.00046621347428299487
Valid Loss:  0.0008326605893671513
Epoch:  273  	Training Loss: 0.0007640179246664047
Test Loss:  0.00046572936116717756
Valid Loss:  0.0008322027279064059
Epoch:  274  	Training Loss: 0.0007631018524989486
Test Loss:  0.0004652310162782669
 55%|█████▌    | 275/500 [03:29<02:25,  1.55it/s] 55%|█████▌    | 277/500 [03:29<01:45,  2.12it/s] 56%|█████▌    | 279/500 [03:29<01:17,  2.84it/s] 56%|█████▌    | 281/500 [03:36<04:29,  1.23s/it] 57%|█████▋    | 283/500 [03:36<03:11,  1.13it/s] 57%|█████▋    | 285/500 [03:36<02:17,  1.57it/s] 57%|█████▋    | 287/500 [03:36<01:39,  2.14it/s] 58%|█████▊    | 289/500 [03:37<01:13,  2.87it/s] 58%|█████▊    | 291/500 [03:43<04:17,  1.23s/it] 59%|█████▊    | 293/500 [03:43<03:04,  1.12it/s] 59%|█████▉    | 295/500 [03:43<02:11,  1.56it/s] 59%|█████▉    | 297/500 [03:44<01:36,  2.11it/s] 60%|█████▉    | 299/500 [03:44<01:11,  2.79it/s] 60%|██████    | 301/500 [03:50<04:08,  1.25s/it] 61%|██████    | 303/500 [03:51<02:56,  1.11it/s] 61%|██████    | 305/500 [03:51<02:06,  1.54it/s] 61%|██████▏   | 307/500 [03:51<01:31,  2.11it/s] 62%|██████▏   | 309/500 [03:51<01:07,  2.84it/s] 62%|██████▏   | 311/500 [03:57<03:46,  1.20s/it] 63%|██████▎   | 313/500 [03:57<02:40,  1.16it/s] 63%|██████▎   | 315/500 [03:58<01:55,  1.61it/s] 63%|██████▎   | 317/500 [03:58<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:58<01:01,  2.95it/s] 64%|██████▍   | 321/500 [04:04<03:33,  1.19s/it] 65%|██████▍   | 323/500 [04:04<02:31,  1.17it/s] 65%|██████▌   | 325/500 [04:04<01:48,  1.62it/s] 65%|██████▌   | 327/500 [04:05<01:18,  2.21it/s] 66%|██████▌   | 329/500 [04:05<00:57,  2.97it/s] 66%|██████▌   | 331/500 [04:11<03:19,  1.18s/it] 67%|██████▋   | 333/500 [04:11<02:21,  1.18it/s] 67%|██████▋   | 335/500 [04:11<01:41,  1.63it/s] 67%|██████▋   | 337/500 [04:11<01:13,  2.23it/s] 68%|██████▊   | 339/500 [04:12<00:53,  2.99it/s] 68%|██████▊   | 341/500 [04:18<03:09,  1.19s/it]Valid Loss:  0.000831709592603147
Epoch:  275  	Training Loss: 0.0007621914846822619
Test Loss:  0.0004647225432563573
Valid Loss:  0.0008311929414048791
Epoch:  276  	Training Loss: 0.0007612864137627184
Test Loss:  0.0004642058629542589
Valid Loss:  0.0008306562667712569
Epoch:  277  	Training Loss: 0.000760385999456048
Test Loss:  0.0004636828089132905
Valid Loss:  0.0008301055640913546
Epoch:  278  	Training Loss: 0.0007594898343086243
Test Loss:  0.00046315506915561855
Valid Loss:  0.0008295422303490341
Epoch:  279  	Training Loss: 0.0007585977436974645
Test Loss:  0.0004626230802386999
Valid Loss:  0.000828969874419272
Epoch:  280  	Training Loss: 0.0007577085052616894
Test Loss:  0.0004620870458893478
Valid Loss:  0.0008283893694169819
Epoch:  281  	Training Loss: 0.0007568236324004829
Test Loss:  0.0004615477519109845
Valid Loss:  0.0008278011227957904
Epoch:  282  	Training Loss: 0.0007559421937912703
Test Loss:  0.00045949523337185383
Valid Loss:  0.0008242879994213581
Epoch:  283  	Training Loss: 0.0007532637100666761
Test Loss:  0.0004576102364808321
Valid Loss:  0.000821153458673507
Epoch:  284  	Training Loss: 0.0007511888397857547
Test Loss:  0.00045612253597937524
Valid Loss:  0.0008186482009477913
Epoch:  285  	Training Loss: 0.0007493128068745136
Test Loss:  0.00045451358892023563
Valid Loss:  0.0008159879362210631
Epoch:  286  	Training Loss: 0.0007474959711544216
Test Loss:  0.00045316421892493963
Valid Loss:  0.0008134684758260846
Epoch:  287  	Training Loss: 0.0007458529435098171
Test Loss:  0.0004519987269304693
Valid Loss:  0.0008112864452414215
Epoch:  288  	Training Loss: 0.0007444053189828992
Test Loss:  0.0004507583798840642
Valid Loss:  0.0008090203627943993
Epoch:  289  	Training Loss: 0.0007429962861351669
Test Loss:  0.00044978782534599304
Valid Loss:  0.0008072414202615619
Epoch:  290  	Training Loss: 0.000741662341170013
Test Loss:  0.00044868135591968894
Valid Loss:  0.0008051050826907158
Epoch:  291  	Training Loss: 0.0007403312483802438
Test Loss:  0.0004476891190279275
Valid Loss:  0.0008030394674278796
Epoch:  292  	Training Loss: 0.0007391517283394933
Test Loss:  0.0004474195302464068
Valid Loss:  0.0008023533737286925
Epoch:  293  	Training Loss: 0.0007390695973299444
Test Loss:  0.00044718716526404023
Valid Loss:  0.0008017743239179254
Epoch:  294  	Training Loss: 0.0007390003884211183
Test Loss:  0.00044697715202346444
Valid Loss:  0.0008012644248083234
Epoch:  295  	Training Loss: 0.0007389385136775672
Test Loss:  0.0004467833787202835
Valid Loss:  0.0008007994620129466
Epoch:  296  	Training Loss: 0.0007388796657323837
Test Loss:  0.0004465992678888142
Valid Loss:  0.0008003645343706012
Epoch:  297  	Training Loss: 0.0007388238445855677
Test Loss:  0.000446423829998821
Valid Loss:  0.0007999524823389947
Epoch:  298  	Training Loss: 0.0007387695368379354
Test Loss:  0.00044625502778217196
Valid Loss:  0.0007995564956218004
Epoch:  299  	Training Loss: 0.0007387188961729407
Test Loss:  0.00044609152246266603
Valid Loss:  0.0007991741294972599
Epoch:  300  	Training Loss: 0.0007386691868305206
Test Loss:  0.0004459343326743692
Valid Loss:  0.0007988043362274766
Epoch:  301  	Training Loss: 0.0007386222714558244
Test Loss:  0.00044578060624189675
Valid Loss:  0.0007984441472217441
Epoch:  302  	Training Loss: 0.00073857675306499
Test Loss:  0.0004452824068721384
Valid Loss:  0.0007973622996360064
Epoch:  303  	Training Loss: 0.0007384110358543694
Test Loss:  0.00044484742102213204
Valid Loss:  0.0007963487878441811
Epoch:  304  	Training Loss: 0.0007382848998531699
Test Loss:  0.0004444531223271042
Valid Loss:  0.0007953971507959068
Epoch:  305  	Training Loss: 0.0007381804753094912
Test Loss:  0.00044409147812984884
Valid Loss:  0.0007945051183924079
Epoch:  306  	Training Loss: 0.0007380899041891098
Test Loss:  0.00044375855941325426
Valid Loss:  0.0007936712354421616
Epoch:  307  	Training Loss: 0.0007380115566775203
Test Loss:  0.00044345168862491846
Valid Loss:  0.0007928946288302541
Epoch:  308  	Training Loss: 0.0007379426970146596
Test Loss:  0.00044316891580820084
Valid Loss:  0.0007921707001514733
Epoch:  309  	Training Loss: 0.0007378826267085969
Test Loss:  0.0004429084074217826
Valid Loss:  0.000791497528553009
Epoch:  310  	Training Loss: 0.0007378299487754703
Test Loss:  0.0004426676023285836
Valid Loss:  0.0007908695843070745
Epoch:  311  	Training Loss: 0.0007377841975539923
Test Loss:  0.0004424455692060292
Valid Loss:  0.000790286110714078
Epoch:  312  	Training Loss: 0.0007377438596449792
Test Loss:  0.00044031161814928055
Valid Loss:  0.0007876499439589679
Epoch:  313  	Training Loss: 0.0007357941358350217
Test Loss:  0.00043846710468642414
Valid Loss:  0.0007851924165152013
Epoch:  314  	Training Loss: 0.0007340260781347752
Test Loss:  0.0004368554800748825
Valid Loss:  0.0007830304675735533
Epoch:  315  	Training Loss: 0.000732436659745872
Test Loss:  0.0004354191478341818
Valid Loss:  0.0007810299284756184
Epoch:  316  	Training Loss: 0.0007309464272111654
Test Loss:  0.0004340885207056999
Valid Loss:  0.0007792040123604238
Epoch:  317  	Training Loss: 0.0007295456016436219
Test Loss:  0.00043286022264510393
Valid Loss:  0.0007775202393531799
Epoch:  318  	Training Loss: 0.0007282259175553918
Test Loss:  0.00043170564458705485
Valid Loss:  0.0007759502623230219
Epoch:  319  	Training Loss: 0.0007269664201885462
Test Loss:  0.00043061425094492733
Valid Loss:  0.0007745031034573913
Epoch:  320  	Training Loss: 0.0007257714169099927
Test Loss:  0.0004296244587749243
Valid Loss:  0.0007731945952400565
Epoch:  321  	Training Loss: 0.0007246749009937048
Test Loss:  0.00042872116318903863
Valid Loss:  0.0007719770073890686
Epoch:  322  	Training Loss: 0.0007236258825287223
Test Loss:  0.0004271503130439669
Valid Loss:  0.0007694447413086891
Epoch:  323  	Training Loss: 0.0007220912375487387
Test Loss:  0.00042629503877833486
Valid Loss:  0.0007683196454308927
Epoch:  324  	Training Loss: 0.0007208280730992556
Test Loss:  0.00042567160562612116
Valid Loss:  0.0007676893728785217
Epoch:  325  	Training Loss: 0.0007196324877440929
Test Loss:  0.00042513624066486955
Valid Loss:  0.00076724385144189
Epoch:  326  	Training Loss: 0.0007184704300016165
Test Loss:  0.00042463853606022894
Valid Loss:  0.0007668657344765961
Epoch:  327  	Training Loss: 0.000717335322406143
Test Loss:  0.0004241594288032502
Valid Loss:  0.0007665123557671905
Epoch:  328  	Training Loss: 0.000716225418727845
Test Loss:  0.0004236937966197729
Valid Loss:  0.0007661643321625888
Epoch:  329  	Training Loss: 0.0007151381578296423
Test Loss:  0.00042326166294515133
Valid Loss:  0.000765815086197108
Epoch:  330  	Training Loss: 0.0007140729576349258
Test Loss:  0.000422831391915679
Valid Loss:  0.0007654606597498059
Epoch:  331  	Training Loss: 0.000713026151061058
Test Loss:  0.0004224024887662381
Valid Loss:  0.0007650998304598033
Epoch:  332  	Training Loss: 0.0007119969232007861
Test Loss:  0.00042161697638221085
Valid Loss:  0.0007640030817128718
Epoch:  333  	Training Loss: 0.0007111886516213417
Test Loss:  0.0004209497128613293
Valid Loss:  0.0007632520864717662
Epoch:  334  	Training Loss: 0.0007103974930942059
Test Loss:  0.0004203617281746119
Valid Loss:  0.0007625974249094725
Epoch:  335  	Training Loss: 0.0007096314802765846
Test Loss:  0.0004198207170702517
Valid Loss:  0.0007619575480930507
Epoch:  336  	Training Loss: 0.000708884559571743
Test Loss:  0.0004192980413790792
Valid Loss:  0.0007613194175064564
Epoch:  337  	Training Loss: 0.0007081636576913297
Test Loss:  0.0004187690210528672
Valid Loss:  0.0007606840808875859
Epoch:  338  	Training Loss: 0.0007074656896293163
Test Loss:  0.000418245792388916
Valid Loss:  0.0007600634125992656
Epoch:  339  	Training Loss: 0.0007067705155350268
Test Loss:  0.00041772174881771207
Valid Loss:  0.0007594588096253574
Epoch:  340  	Training Loss: 0.0007060857024043798
Test Loss:  0.0004172186891082674
Valid Loss:  0.0007588598527945578
Epoch:  341  	Training Loss: 0.0007054044981487095
Test Loss:  0.0004167143488302827
Valid Loss:  0.0007582549587823451
Epoch:  342  	Training Loss: 0.0007047313847579062
Test Loss:  0.0004165355348959565
Valid Loss:   69%|██████▊   | 343/500 [04:18<02:14,  1.16it/s] 69%|██████▉   | 345/500 [04:18<01:37,  1.59it/s] 69%|██████▉   | 347/500 [04:18<01:11,  2.15it/s] 70%|██████▉   | 349/500 [04:19<00:53,  2.84it/s] 70%|███████   | 351/500 [04:25<03:01,  1.22s/it] 71%|███████   | 353/500 [04:25<02:08,  1.14it/s] 71%|███████   | 355/500 [04:25<01:32,  1.57it/s] 71%|███████▏  | 357/500 [04:26<01:06,  2.15it/s] 72%|███████▏  | 359/500 [04:26<00:48,  2.90it/s] 72%|███████▏  | 361/500 [04:32<02:48,  1.21s/it] 73%|███████▎  | 363/500 [04:32<01:59,  1.15it/s] 73%|███████▎  | 365/500 [04:32<01:25,  1.58it/s] 73%|███████▎  | 367/500 [04:33<01:01,  2.17it/s] 74%|███████▍  | 369/500 [04:33<00:44,  2.91it/s] 74%|███████▍  | 371/500 [04:39<02:37,  1.22s/it] 75%|███████▍  | 373/500 [04:39<01:51,  1.14it/s] 75%|███████▌  | 375/500 [04:40<01:19,  1.58it/s] 75%|███████▌  | 377/500 [04:40<00:57,  2.16it/s] 76%|███████▌  | 379/500 [04:40<00:41,  2.91it/s] 76%|███████▌  | 381/500 [04:46<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:46<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:46<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:47<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:47<00:37,  2.98it/s] 78%|███████▊  | 391/500 [04:59<03:53,  2.14s/it] 79%|███████▊  | 393/500 [05:00<02:42,  1.52s/it] 79%|███████▉  | 395/500 [05:00<01:54,  1.09s/it] 79%|███████▉  | 397/500 [05:00<01:20,  1.28it/s] 80%|███████▉  | 399/500 [05:00<00:57,  1.76it/s] 80%|████████  | 401/500 [05:06<02:13,  1.35s/it] 81%|████████  | 403/500 [05:06<01:33,  1.03it/s] 81%|████████  | 405/500 [05:07<01:06,  1.44it/s] 81%|████████▏ | 407/500 [05:07<00:47,  1.97it/s] 82%|████████▏ | 409/500 [05:07<00:34,  2.67it/s]0.0007583140395581722
Epoch:  343  	Training Loss: 0.0007037328323349357
Test Loss:  0.0004162848345004022
Valid Loss:  0.0007581341778859496
Epoch:  344  	Training Loss: 0.0007027853862382472
Test Loss:  0.00041595028596930206
Valid Loss:  0.0007577032083645463
Epoch:  345  	Training Loss: 0.0007018597098067403
Test Loss:  0.00041557621443644166
Valid Loss:  0.0007571537862531841
Epoch:  346  	Training Loss: 0.0007009460823610425
Test Loss:  0.0004152085748501122
Valid Loss:  0.0007565306732431054
Epoch:  347  	Training Loss: 0.0007000488694757223
Test Loss:  0.00041484355460852385
Valid Loss:  0.0007558541838079691
Epoch:  348  	Training Loss: 0.0006991856498643756
Test Loss:  0.00041446887189522386
Valid Loss:  0.000755136483348906
Epoch:  349  	Training Loss: 0.000698350602760911
Test Loss:  0.0004140851378906518
Valid Loss:  0.000754384440369904
Epoch:  350  	Training Loss: 0.0006975367432460189
Test Loss:  0.0004137431678827852
Valid Loss:  0.0007537359488196671
Epoch:  351  	Training Loss: 0.0006967363879084587
Test Loss:  0.0004133354814257473
Valid Loss:  0.000752918072976172
Epoch:  352  	Training Loss: 0.0006959664169698954
Test Loss:  0.00041156410588882864
Valid Loss:  0.0007501880172640085
Epoch:  353  	Training Loss: 0.000694187474437058
Test Loss:  0.0004099361249245703
Valid Loss:  0.0007476242026314139
Epoch:  354  	Training Loss: 0.0006924933404661715
Test Loss:  0.00040846114279702306
Valid Loss:  0.0007452730787917972
Epoch:  355  	Training Loss: 0.0006908499635756016
Test Loss:  0.0004070561262778938
Valid Loss:  0.0007431397098116577
Epoch:  356  	Training Loss: 0.0006892309756949544
Test Loss:  0.00040570873534306884
Valid Loss:  0.0007411600672639906
Epoch:  357  	Training Loss: 0.0006876306142657995
Test Loss:  0.00040442775934934616
Valid Loss:  0.000739305280148983
Epoch:  358  	Training Loss: 0.0006860741996206343
Test Loss:  0.0004031884600408375
Valid Loss:  0.0007375366985797882
Epoch:  359  	Training Loss: 0.0006845480529591441
Test Loss:  0.00040204203105531633
Valid Loss:  0.0007358909351751208
Epoch:  360  	Training Loss: 0.0006830673664808273
Test Loss:  0.0004009501135442406
Valid Loss:  0.0007343058823607862
Epoch:  361  	Training Loss: 0.0006815938977524638
Test Loss:  0.00039988092612475157
Valid Loss:  0.0007327670464292169
Epoch:  362  	Training Loss: 0.0006801294512115419
Test Loss:  0.00039909832412377
Valid Loss:  0.0007315714610740542
Epoch:  363  	Training Loss: 0.000679554243106395
Test Loss:  0.00039847425068728626
Valid Loss:  0.0007307445630431175
Epoch:  364  	Training Loss: 0.0006790319457650185
Test Loss:  0.0003979254688601941
Valid Loss:  0.0007301074801944196
Epoch:  365  	Training Loss: 0.0006785269360989332
Test Loss:  0.0003974140272475779
Valid Loss:  0.0007295696996152401
Epoch:  366  	Training Loss: 0.0006780284456908703
Test Loss:  0.0003969240642618388
Valid Loss:  0.0007290850626304746
Epoch:  367  	Training Loss: 0.0006775348447263241
Test Loss:  0.0003964462666772306
Valid Loss:  0.0007286310428753495
Epoch:  368  	Training Loss: 0.0006770445615984499
Test Loss:  0.0003959775494877249
Valid Loss:  0.0007281953003257513
Epoch:  369  	Training Loss: 0.000676562893204391
Test Loss:  0.00039552111411467195
Valid Loss:  0.0007277786498889327
Epoch:  370  	Training Loss: 0.0006760928081348538
Test Loss:  0.0003950693644583225
Valid Loss:  0.0007273674127645791
Epoch:  371  	Training Loss: 0.0006756259244866669
Test Loss:  0.0003946219221688807
Valid Loss:  0.0007269619381986558
Epoch:  372  	Training Loss: 0.000675161718390882
Test Loss:  0.0003932849795091897
Valid Loss:  0.0007250925409607589
Epoch:  373  	Training Loss: 0.0006730646127834916
Test Loss:  0.00039224320789799094
Valid Loss:  0.0007234807126224041
Epoch:  374  	Training Loss: 0.0006713923066854477
Test Loss:  0.0003913584805559367
Valid Loss:  0.0007222428102977574
Epoch:  375  	Training Loss: 0.0006698789075016975
Test Loss:  0.0003906874917447567
Valid Loss:  0.0007210931507870555
Epoch:  376  	Training Loss: 0.0006685429252684116
Test Loss:  0.0003901035524904728
Valid Loss:  0.000719960720743984
Epoch:  377  	Training Loss: 0.0006673288298770785
Test Loss:  0.00038950180169194937
Valid Loss:  0.0007188954623416066
Epoch:  378  	Training Loss: 0.0006662064115516841
Test Loss:  0.0003888930950779468
Valid Loss:  0.0007178571540862322
Epoch:  379  	Training Loss: 0.000665109371766448
Test Loss:  0.00038832155405543745
Valid Loss:  0.0007168346783146262
Epoch:  380  	Training Loss: 0.000664044520817697
Test Loss:  0.000387760519515723
Valid Loss:  0.000715807662345469
Epoch:  381  	Training Loss: 0.0006630115676671267
Test Loss:  0.0003872858069371432
Valid Loss:  0.0007147825672291219
Epoch:  382  	Training Loss: 0.000662085076328367
Test Loss:  0.00038744325865991414
Valid Loss:  0.0007156566716730595
Epoch:  383  	Training Loss: 0.0006619110936298966
Test Loss:  0.00038754427805542946
Valid Loss:  0.000716042413841933
Epoch:  384  	Training Loss: 0.0006618819897994399
Test Loss:  0.00038755807327106595
Valid Loss:  0.0007161217508837581
Epoch:  385  	Training Loss: 0.0006618844345211983
Test Loss:  0.00038764532655477524
Valid Loss:  0.0007163482368923724
Epoch:  386  	Training Loss: 0.0006618902552872896
Test Loss:  0.000387633393984288
Valid Loss:  0.0007163394475355744
Epoch:  387  	Training Loss: 0.0006618759362027049
Test Loss:  0.00038760044844821095
Valid Loss:  0.0007162586553022265
Epoch:  388  	Training Loss: 0.0006618638872168958
Test Loss:  0.00038755900459364057
Valid Loss:  0.0007161484099924564
Epoch:  389  	Training Loss: 0.0006618526531383395
Test Loss:  0.0003875145339407027
Valid Loss:  0.0007160273962654173
Epoch:  390  	Training Loss: 0.0006618411862291396
Test Loss:  0.0003874691901728511
Valid Loss:  0.0007159042870625854
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.0006618456682190299
Test Loss:  0.00038755658897571266
Valid Loss:  0.0007158128428272903
Epoch:  392  	Training Loss: 0.0006616401951760054
Test Loss:  0.00038758956361562014
Valid Loss:  0.0007159480592235923
Epoch:  393  	Training Loss: 0.0006613822188228369
Test Loss:  0.0003876296104863286
Valid Loss:  0.0007160785607993603
Epoch:  394  	Training Loss: 0.0006611781427636743
Test Loss:  0.0003879013820551336
Valid Loss:  0.0007168037118390203
Epoch:  395  	Training Loss: 0.0006610146956518292
Test Loss:  0.0003879287978634238
Valid Loss:  0.0007168863667175174
Epoch:  396  	Training Loss: 0.000660808989778161
Test Loss:  0.00038795825093984604
Valid Loss:  0.0007169600576162338
Epoch:  397  	Training Loss: 0.0006606209790334105
Test Loss:  0.00038798560854047537
Valid Loss:  0.0007170244352892041
Epoch:  398  	Training Loss: 0.0006604785448871553
Test Loss:  0.00038823331124149263
Valid Loss:  0.0007176735671237111
Epoch:  399  	Training Loss: 0.0006603411165997386
Test Loss:  0.0003882437013089657
Valid Loss:  0.0007176921935752034
Epoch:  400  	Training Loss: 0.0006601734785363078
Test Loss:  0.00038825825322419405
Valid Loss:  0.0007177020306698978
Epoch:  401  	Training Loss: 0.0006600152119062841
Test Loss:  0.0003882796154357493
Valid Loss:  0.0007177041843533516
Epoch:  402  	Training Loss: 0.0006598777254112065
Test Loss:  0.000388165470212698
Valid Loss:  0.0007175630889832973
Epoch:  403  	Training Loss: 0.000659773766528815
Test Loss:  0.0003880519652739167
Valid Loss:  0.0007174225174821913
Epoch:  404  	Training Loss: 0.0006596703315153718
Test Loss:  0.00038793927524238825
Valid Loss:  0.0007172812474891543
Epoch:  405  	Training Loss: 0.0006595669547095895
Test Loss:  0.0003878265852108598
Valid Loss:  0.0007171429460868239
Epoch:  406  	Training Loss: 0.000659464334603399
Test Loss:  0.0003877149720210582
Valid Loss:  0.0007170030730776489
Epoch:  407  	Training Loss: 0.0006593613652512431
Test Loss:  0.0003876023693010211
Valid Loss:  0.000716865761205554
Epoch:  408  	Training Loss: 0.0006592590943910182
Test Loss:  0.0003874913090839982
Valid Loss:  0.000716729904524982
Epoch:  409  	Training Loss: 0.000659158977214247
Test Loss:  0.0003873858950100839
Valid Loss:  0.0007165924762375653
 82%|████████▏ | 411/500 [05:13<01:49,  1.23s/it] 83%|████████▎ | 413/500 [05:13<01:16,  1.13it/s] 83%|████████▎ | 415/500 [05:14<00:54,  1.57it/s] 83%|████████▎ | 417/500 [05:14<00:38,  2.15it/s] 84%|████████▍ | 419/500 [05:14<00:28,  2.89it/s] 84%|████████▍ | 421/500 [05:20<01:34,  1.19s/it] 85%|████████▍ | 423/500 [05:20<01:06,  1.16it/s] 85%|████████▌ | 425/500 [05:20<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:21<00:33,  2.20it/s] 86%|████████▌ | 429/500 [05:21<00:23,  2.97it/s] 86%|████████▌ | 431/500 [05:27<01:22,  1.20s/it] 87%|████████▋ | 433/500 [05:27<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:27<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:28<00:28,  2.20it/s] 88%|████████▊ | 439/500 [05:28<00:20,  2.96it/s] 88%|████████▊ | 441/500 [05:34<01:10,  1.19s/it] 89%|████████▊ | 443/500 [05:34<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:34<00:34,  1.62it/s] 89%|████████▉ | 447/500 [05:34<00:23,  2.21it/s] 90%|████████▉ | 449/500 [05:35<00:17,  2.97it/s] 90%|█████████ | 451/500 [05:41<00:59,  1.21s/it] 91%|█████████ | 453/500 [05:41<00:41,  1.14it/s] 91%|█████████ | 455/500 [05:41<00:28,  1.57it/s] 91%|█████████▏| 457/500 [05:42<00:20,  2.15it/s] 92%|█████████▏| 459/500 [05:42<00:14,  2.88it/s] 92%|█████████▏| 461/500 [05:48<00:47,  1.21s/it] 93%|█████████▎| 463/500 [05:48<00:32,  1.15it/s] 93%|█████████▎| 465/500 [05:48<00:22,  1.58it/s] 93%|█████████▎| 467/500 [05:49<00:15,  2.16it/s] 94%|█████████▍| 469/500 [05:49<00:10,  2.89it/s] 94%|█████████▍| 471/500 [05:55<00:34,  1.20s/it] 95%|█████████▍| 473/500 [05:55<00:23,  1.16it/s] 95%|█████████▌| 475/500 [05:55<00:15,  1.60it/s] 95%|█████████▌| 477/500 [05:56<00:10,  2.18it/s]Epoch:  410  	Training Loss: 0.0006590590928681195
Test Loss:  0.00038727937499061227
Valid Loss:  0.000716456794179976
Epoch:  411  	Training Loss: 0.000658959208521992
Test Loss:  0.00038717410643585026
Valid Loss:  0.0007163214613683522
Epoch:  412  	Training Loss: 0.0006588600808754563
Test Loss:  0.0003867963096126914
Valid Loss:  0.0007157886866480112
Epoch:  413  	Training Loss: 0.0006585462251678109
Test Loss:  0.00038643646985292435
Valid Loss:  0.0007152744219638407
Epoch:  414  	Training Loss: 0.0006582395872101188
Test Loss:  0.00038609019247815013
Valid Loss:  0.0007147769792936742
Epoch:  415  	Training Loss: 0.0006579385371878743
Test Loss:  0.00038575177313759923
Valid Loss:  0.0007142929243855178
Epoch:  416  	Training Loss: 0.0006576431915163994
Test Loss:  0.0003854210954159498
Valid Loss:  0.000713821966201067
Epoch:  417  	Training Loss: 0.0006573512218892574
Test Loss:  0.00038509495789185166
Valid Loss:  0.0007133607286959887
Epoch:  418  	Training Loss: 0.0006570634432137012
Test Loss:  0.00038477545604109764
Valid Loss:  0.0007129110745154321
Epoch:  419  	Training Loss: 0.0006567791569977999
Test Loss:  0.0003844605234917253
Valid Loss:  0.0007124713156372309
Epoch:  420  	Training Loss: 0.0006564973737113178
Test Loss:  0.00038414925802499056
Valid Loss:  0.0007120401132851839
Epoch:  421  	Training Loss: 0.0006562183843925595
Test Loss:  0.0003838429693132639
Valid Loss:  0.0007116179913282394
Epoch:  422  	Training Loss: 0.0006559418980032206
Test Loss:  0.0003836478863377124
Valid Loss:  0.0007113985484465957
Epoch:  423  	Training Loss: 0.0006554843275807798
Test Loss:  0.0003834459057543427
Valid Loss:  0.0007111598970368505
Epoch:  424  	Training Loss: 0.0006550288526341319
Test Loss:  0.000383240170776844
Valid Loss:  0.0007109074504114687
Epoch:  425  	Training Loss: 0.0006545769283547997
Test Loss:  0.000383030332159251
Valid Loss:  0.0007106462144292891
Epoch:  426  	Training Loss: 0.0006541268085129559
Test Loss:  0.00038282183231785893
Valid Loss:  0.0007103723473846912
Epoch:  427  	Training Loss: 0.0006536830333061516
Test Loss:  0.0003826080937869847
Valid Loss:  0.000710090680513531
Epoch:  428  	Training Loss: 0.0006532430998049676
Test Loss:  0.00038239231798797846
Valid Loss:  0.0007098062196746469
Epoch:  429  	Training Loss: 0.0006528047379106283
Test Loss:  0.0003821764839813113
Valid Loss:  0.0007095190812833607
Epoch:  430  	Training Loss: 0.000652369053568691
Test Loss:  0.00038195852539502084
Valid Loss:  0.000709226937033236
Epoch:  431  	Training Loss: 0.0006519343005493283
Test Loss:  0.0003817389369942248
Valid Loss:  0.0007089312421157956
Epoch:  432  	Training Loss: 0.000651502632535994
Test Loss:  0.00038144364953041077
Valid Loss:  0.0007087084813974798
Epoch:  433  	Training Loss: 0.0006509252707473934
Test Loss:  0.0003811435599345714
Valid Loss:  0.0007084694225341082
Epoch:  434  	Training Loss: 0.0006503561744466424
Test Loss:  0.000380840094294399
Valid Loss:  0.0007082155207172036
Epoch:  435  	Training Loss: 0.0006497931317426264
Test Loss:  0.00038053016760386527
Valid Loss:  0.0007079477072693408
Epoch:  436  	Training Loss: 0.0006492345128208399
Test Loss:  0.00038021718501113355
Valid Loss:  0.000707666331436485
Epoch:  437  	Training Loss: 0.0006486805505119264
Test Loss:  0.0003799163969233632
Valid Loss:  0.0007073745946399868
Epoch:  438  	Training Loss: 0.0006481301970779896
Test Loss:  0.00037961400812491775
Valid Loss:  0.0007070712745189667
Epoch:  439  	Training Loss: 0.0006475824629887938
Test Loss:  0.00037930833059363067
Valid Loss:  0.0007067587575875223
Epoch:  440  	Training Loss: 0.0006470371736213565
Test Loss:  0.000379001721739769
Valid Loss:  0.0007064361125230789
Epoch:  441  	Training Loss: 0.0006464947946369648
Test Loss:  0.00037869939114898443
Valid Loss:  0.000706106424331665
Epoch:  442  	Training Loss: 0.0006459536380134523
Test Loss:  0.00037698139203712344
Valid Loss:  0.0007029972039163113
Epoch:  443  	Training Loss: 0.0006447082851082087
Test Loss:  0.00037584081292152405
Valid Loss:  0.0007014715811237693
Epoch:  444  	Training Loss: 0.0006435986724682152
Test Loss:  0.0003747087612282485
Valid Loss:  0.0006999218021519482
Epoch:  445  	Training Loss: 0.0006425064639188349
Test Loss:  0.00037364207673817873
Valid Loss:  0.0006983898347243667
Epoch:  446  	Training Loss: 0.0006414525560103357
Test Loss:  0.0003726392751559615
Valid Loss:  0.000696931907441467
Epoch:  447  	Training Loss: 0.000640444690361619
Test Loss:  0.0003716658102348447
Valid Loss:  0.0006955119897611439
Epoch:  448  	Training Loss: 0.0006394524243660271
Test Loss:  0.00037071717088110745
Valid Loss:  0.0006941275205463171
Epoch:  449  	Training Loss: 0.0006384738953784108
Test Loss:  0.00036979286232963204
Valid Loss:  0.0006927732611075044
Epoch:  450  	Training Loss: 0.0006375097436830401
Test Loss:  0.0003689117729663849
Valid Loss:  0.0006914582336321473
Epoch:  451  	Training Loss: 0.0006365603767335415
Test Loss:  0.00036804977571591735
Valid Loss:  0.0006901709130033851
Epoch:  452  	Training Loss: 0.0006356198573485017
Test Loss:  0.0003677739296108484
Valid Loss:  0.0006898107239976525
Epoch:  453  	Training Loss: 0.0006353071657940745
Test Loss:  0.00036750835715793073
Valid Loss:  0.0006894623511470854
Epoch:  454  	Training Loss: 0.0006349962204694748
Test Loss:  0.0003672559978440404
Valid Loss:  0.00068912364076823
Epoch:  455  	Training Loss: 0.0006346872542053461
Test Loss:  0.0003670054138638079
Valid Loss:  0.0006887897616252303
Epoch:  456  	Training Loss: 0.0006343823042698205
Test Loss:  0.0003667580313049257
Valid Loss:  0.000688462401740253
Epoch:  457  	Training Loss: 0.0006340781692415476
Test Loss:  0.0003665125695988536
Valid Loss:  0.000688140164129436
Epoch:  458  	Training Loss: 0.0006337749655358493
Test Loss:  0.0003662679810076952
Valid Loss:  0.0006878228159621358
Epoch:  459  	Training Loss: 0.0006334721110761166
Test Loss:  0.0003660332877188921
Valid Loss:  0.0006875108228996396
Epoch:  460  	Training Loss: 0.000633174495305866
Test Loss:  0.0003657990600913763
Valid Loss:  0.0006871880614198744
Epoch:  461  	Training Loss: 0.0006328858435153961
Test Loss:  0.00036556634586304426
Valid Loss:  0.0006868699565529823
Epoch:  462  	Training Loss: 0.0006325979484245181
Test Loss:  0.0003650314756669104
Valid Loss:  0.0006863073213025928
Epoch:  463  	Training Loss: 0.0006318059749901295
Test Loss:  0.00036448269383981824
Valid Loss:  0.0006856610998511314
Epoch:  464  	Training Loss: 0.0006310483440756798
Test Loss:  0.00036395847564563155
Valid Loss:  0.0006850470090284944
Epoch:  465  	Training Loss: 0.0006303231930360198
Test Loss:  0.00036345256376080215
Valid Loss:  0.0006844542804174125
Epoch:  466  	Training Loss: 0.0006296210340224206
Test Loss:  0.0003629618149716407
Valid Loss:  0.0006838784320279956
Epoch:  467  	Training Loss: 0.000628939364105463
Test Loss:  0.00036248640390112996
Valid Loss:  0.0006833224906586111
Epoch:  468  	Training Loss: 0.0006282771937549114
Test Loss:  0.00036202179035171866
Valid Loss:  0.0006827819161117077
Epoch:  469  	Training Loss: 0.0006276315543800592
Test Loss:  0.00036156942951492965
Valid Loss:  0.0006822735304012895
Epoch:  470  	Training Loss: 0.0006270016310736537
Test Loss:  0.00036112841917201877
Valid Loss:  0.0006817773100920022
Epoch:  471  	Training Loss: 0.0006263870745897293
Test Loss:  0.0003607005055528134
Valid Loss:  0.0006813030340708792
Epoch:  472  	Training Loss: 0.0006257929489947855
Test Loss:  0.00036026997258886695
Valid Loss:  0.0006807364406995475
Epoch:  473  	Training Loss: 0.0006247993442229927
Test Loss:  0.00035991179174743593
Valid Loss:  0.0006802977877669036
Epoch:  474  	Training Loss: 0.0006239027134142816
Test Loss:  0.000359601981472224
Valid Loss:  0.0006799033144488931
Epoch:  475  	Training Loss: 0.0006230673170648515
Test Loss:  0.00035932741593569517
Valid Loss:  0.0006795441149733961
Epoch:  476  	Training Loss: 0.0006222876836545765
Test Loss:  0.000359079655027017
Valid Loss:  0.0006792361382395029
Epoch:  477  	Training Loss: 0.0006215579924173653
Test Loss:  0.0003588697290979326
Valid Loss:  0.0006789363687857985
 96%|█████████▌| 479/500 [05:56<00:07,  2.91it/s] 96%|█████████▌| 481/500 [06:02<00:22,  1.20s/it] 97%|█████████▋| 483/500 [06:02<00:14,  1.16it/s] 97%|█████████▋| 485/500 [06:02<00:09,  1.60it/s] 97%|█████████▋| 487/500 [06:03<00:05,  2.18it/s] 98%|█████████▊| 489/500 [06:03<00:03,  2.92it/s] 98%|█████████▊| 491/500 [06:09<00:10,  1.20s/it] 98%|█████████▊| 492/500 [06:09<00:08,  1.00s/it] 99%|█████████▉| 494/500 [06:09<00:04,  1.45it/s] 99%|█████████▉| 496/500 [06:09<00:01,  2.04it/s]100%|█████████▉| 498/500 [06:10<00:00,  2.79it/s]100%|██████████| 500/500 [06:10<00:00,  3.73it/s]100%|██████████| 500/500 [06:10<00:00,  1.35it/s]
Epoch:  478  	Training Loss: 0.0006208611885085702
Test Loss:  0.00035867816768586636
Valid Loss:  0.0006786430021747947
Epoch:  479  	Training Loss: 0.0006202033255249262
Test Loss:  0.0003584921360015869
Valid Loss:  0.0006783473072573543
Epoch:  480  	Training Loss: 0.0006195660098455846
Test Loss:  0.0003583281650207937
Valid Loss:  0.0006780494004487991
Epoch:  481  	Training Loss: 0.0006189566338434815
Test Loss:  0.00035819708136841655
Valid Loss:  0.0006777514354325831
Epoch:  482  	Training Loss: 0.0006184104131534696
Test Loss:  0.00035792679409496486
Valid Loss:  0.0006775130750611424
Epoch:  483  	Training Loss: 0.0006179678020998836
Test Loss:  0.000357653945684433
Valid Loss:  0.0006772677879780531
Epoch:  484  	Training Loss: 0.0006175283342599869
Test Loss:  0.00035737943835556507
Valid Loss:  0.0006770167965441942
Epoch:  485  	Training Loss: 0.0006170914275571704
Test Loss:  0.0003571084525901824
Valid Loss:  0.0006767609156668186
Epoch:  486  	Training Loss: 0.000616660516243428
Test Loss:  0.000356842007022351
Valid Loss:  0.000676502997521311
Epoch:  487  	Training Loss: 0.0006162355421110988
Test Loss:  0.0003565731458365917
Valid Loss:  0.0006762396078556776
Epoch:  488  	Training Loss: 0.0006158126052469015
Test Loss:  0.00035630157799459994
Valid Loss:  0.0006759731913916767
Epoch:  489  	Training Loss: 0.0006153906579129398
Test Loss:  0.0003560286422725767
Valid Loss:  0.0006757015362381935
Epoch:  490  	Training Loss: 0.0006149706314317882
Test Loss:  0.00035575314541347325
Valid Loss:  0.0006754250498488545
Epoch:  491  	Training Loss: 0.0006145507795736194
Test Loss:  0.0003554769791662693
Valid Loss:  0.0006751452456228435
Epoch:  492  	Training Loss: 0.0006141324411146343
Test Loss:  0.00035428398405201733
Valid Loss:  0.0006733123445883393
Epoch:  493  	Training Loss: 0.0006131805712357163
Test Loss:  0.00035317675792612135
Valid Loss:  0.0006715970812365413
Epoch:  494  	Training Loss: 0.0006122820195741951
Test Loss:  0.00035217354889027774
Valid Loss:  0.0006700144149363041
Epoch:  495  	Training Loss: 0.0006114529096521437
Test Loss:  0.0003512157709337771
Valid Loss:  0.000668514403514564
Epoch:  496  	Training Loss: 0.0006106526125222445
Test Loss:  0.0003502960898913443
Valid Loss:  0.0006670848233625293
Epoch:  497  	Training Loss: 0.0006098785088397563
Test Loss:  0.00034941534977406263
Valid Loss:  0.0006657170597463846
Epoch:  498  	Training Loss: 0.0006091289105825126
Test Loss:  0.0003485667402856052
Valid Loss:  0.0006644052919000387
Epoch:  499  	Training Loss: 0.0006084040505811572
Test Loss:  0.00034776522079482675
Valid Loss:  0.0006631541182287037
Epoch:  500  	Training Loss: 0.0006077035213820636
Test Loss:  0.0003469930961728096
Valid Loss:  0.0006619521882385015
seed is  11
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:39, 12.58it/s]  1%|          | 4/500 [00:00<00:40, 12.23it/s]  1%|          | 6/500 [00:00<00:40, 12.20it/s]  2%|▏         | 8/500 [00:00<00:40, 12.19it/s]  2%|▏         | 10/500 [00:00<00:37, 12.95it/s]  2%|▏         | 12/500 [00:00<00:35, 13.74it/s]  3%|▎         | 14/500 [00:01<00:33, 14.40it/s]  3%|▎         | 16/500 [00:01<00:32, 14.96it/s]  4%|▎         | 18/500 [00:01<00:31, 15.41it/s]  4%|▍         | 20/500 [00:01<00:30, 15.71it/s]  4%|▍         | 22/500 [00:01<00:29, 15.96it/s]  5%|▍         | 24/500 [00:01<00:29, 16.12it/s]  5%|▌         | 26/500 [00:01<00:29, 16.25it/s]  6%|▌         | 28/500 [00:01<00:28, 16.28it/s]  6%|▌         | 30/500 [00:02<00:29, 16.15it/s]  6%|▋         | 32/500 [00:02<00:28, 16.23it/s]  7%|▋         | 34/500 [00:02<00:30, 15.28it/s]  7%|▋         | 36/500 [00:02<00:30, 15.01it/s]  8%|▊         | 38/500 [00:02<00:30, 15.40it/s]  8%|▊         | 40/500 [00:02<00:29, 15.69it/s]  8%|▊         | 42/500 [00:02<00:29, 15.69it/s]  9%|▉         | 44/500 [00:02<00:28, 15.83it/s]  9%|▉         | 46/500 [00:03<00:28, 15.99it/s] 10%|▉         | 48/500 [00:03<00:28, 16.11it/s] 10%|█         | 50/500 [00:03<00:27, 16.21it/s] 10%|█         | 52/500 [00:03<00:27, 16.29it/s] 11%|█         | 54/500 [00:03<00:27, 16.35it/s] 11%|█         | 56/500 [00:03<00:27, 16.37it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.35it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.29it/s] 12%|█▏        | 62/500 [00:04<00:27, 16.21it/s] 13%|█▎        | 64/500 [00:04<00:26, 16.20it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.22it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.24it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.27it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.15it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.13it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.20it/s] 16%|█▌        | 78/500 [00:05<00:25, 16.29it/s] 16%|█▌        | 80/500 [00:05<00:26, 15.87it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.98it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.93it/s] 17%|█▋        | 86/500 [00:05<00:25, 15.94it/s] 18%|█▊        | 88/500 [00:05<00:25, 15.93it/s] 18%|█▊        | 90/500 [00:05<00:25, 15.90it/s] 18%|█▊        | 92/500 [00:05<00:25, 15.97it/s] 19%|█▉        | 94/500 [00:06<00:25, 16.14it/s] 19%|█▉        | 96/500 [00:06<00:24, 16.25it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.27it/s] 20%|██        | 100/500 [00:06<00:24, 16.28it/s] 20%|██        | 102/500 [00:06<00:24, 16.21it/s] 21%|██        | 104/500 [00:06<00:24, 16.22it/s] 21%|██        | 106/500 [00:06<00:24, 16.29it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.34it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.32it/s] 22%|██▏       | 112/500 [00:07<00:23, 16.22it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.32it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.36it/s] 24%|██▎       | 118/500 [00:07<00:24, 15.74it/s] 24%|██▍       | 120/500 [00:07<00:23, 15.95it/s] 24%|██▍       | 122/500 [00:07<00:23, 15.97it/s]Epoch:  1  	Training Loss: 0.02847922034561634
Test Loss:  29.83582305908203
Valid Loss:  29.775348663330078
Epoch:  2  	Training Loss: 30.174285888671875
Test Loss:  19014984.0
Valid Loss:  19047706.0
Epoch:  3  	Training Loss: 18920540.0
Test Loss:  8.997735433170432e+34
Valid Loss:  8.99681143472511e+34
Epoch:  4  	Training Loss: 9.055291722180951e+34
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan 25%|██▍       | 124/500 [00:07<00:23, 15.96it/s] 25%|██▌       | 126/500 [00:07<00:23, 16.08it/s] 26%|██▌       | 128/500 [00:08<00:22, 16.21it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.31it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.27it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.18it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.31it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.36it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.37it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.40it/s] 29%|██▉       | 144/500 [00:09<00:21, 16.40it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.39it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.37it/s] 30%|███       | 150/500 [00:09<00:21, 16.36it/s] 30%|███       | 152/500 [00:09<00:21, 16.41it/s] 31%|███       | 154/500 [00:09<00:21, 16.30it/s] 31%|███       | 156/500 [00:09<00:21, 16.24it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.30it/s] 32%|███▏      | 160/500 [00:10<00:20, 16.37it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.40it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.33it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.29it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.24it/s] 34%|███▍      | 170/500 [00:10<00:21, 15.19it/s] 34%|███▍      | 172/500 [00:10<00:23, 14.12it/s] 35%|███▍      | 174/500 [00:11<00:23, 13.64it/s] 35%|███▌      | 176/500 [00:11<00:22, 14.32it/s] 36%|███▌      | 178/500 [00:11<00:21, 14.74it/s] 36%|███▌      | 180/500 [00:11<00:21, 15.12it/s] 36%|███▋      | 182/500 [00:11<00:20, 15.36it/s] 37%|███▋      | 184/500 [00:11<00:20, 15.58it/s] 37%|███▋      | 186/500 [00:11<00:19, 15.81it/s] 38%|███▊      | 188/500 [00:11<00:19, 15.75it/s] 38%|███▊      | 190/500 [00:12<00:20, 15.46it/s] 38%|███▊      | 192/500 [00:12<00:21, 14.31it/s] 39%|███▉      | 194/500 [00:12<00:22, 13.76it/s] 39%|███▉      | 196/500 [00:12<00:21, 14.34it/s] 40%|███▉      | 198/500 [00:12<00:20, 14.85it/s] 40%|████      | 200/500 [00:12<00:19, 15.29it/s] 40%|████      | 202/500 [00:12<00:19, 15.57it/s] 41%|████      | 204/500 [00:12<00:18, 15.87it/s] 41%|████      | 206/500 [00:13<00:18, 16.02it/s] 42%|████▏     | 208/500 [00:13<00:18, 16.20it/s] 42%|████▏     | 210/500 [00:13<00:18, 15.97it/s] 42%|████▏     | 212/500 [00:13<00:18, 15.90it/s] 43%|████▎     | 214/500 [00:13<00:19, 14.45it/s] 43%|████▎     | 216/500 [00:13<00:20, 13.79it/s] 44%|████▎     | 218/500 [00:13<00:19, 14.43it/s] 44%|████▍     | 220/500 [00:14<00:18, 14.91it/s] 44%|████▍     | 222/500 [00:14<00:18, 15.27it/s] 45%|████▍     | 224/500 [00:14<00:17, 15.59it/s] 45%|████▌     | 226/500 [00:14<00:17, 15.73it/s] 46%|████▌     | 228/500 [00:14<00:17, 15.85it/s] 46%|████▌     | 230/500 [00:14<00:17, 15.05it/s] 46%|████▋     | 232/500 [00:14<00:18, 14.76it/s] 47%|████▋     | 234/500 [00:14<00:17, 15.26it/s] 47%|████▋     | 236/500 [00:15<00:17, 15.39it/s] 48%|████▊     | 238/500 [00:15<00:17, 15.18it/s] 48%|████▊     | 240/500 [00:15<00:16, 15.59it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.69it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.93it/s] 49%|████▉     | 246/500 [00:15<00:16, 15.81it/s]
Valid Loss:  nan
Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
 50%|████▉     | 248/500 [00:15<00:15, 15.83it/s] 50%|█████     | 250/500 [00:15<00:15, 15.88it/s] 50%|█████     | 252/500 [00:16<00:15, 15.79it/s] 51%|█████     | 254/500 [00:16<00:15, 16.03it/s] 51%|█████     | 256/500 [00:16<00:15, 16.09it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.23it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.03it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.17it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.26it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.26it/s] 54%|█████▎    | 268/500 [00:17<00:14, 16.19it/s] 54%|█████▍    | 270/500 [00:17<00:14, 16.29it/s] 54%|█████▍    | 272/500 [00:17<00:14, 16.04it/s] 55%|█████▍    | 274/500 [00:17<00:14, 15.91it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.99it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.03it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.02it/s] 56%|█████▋    | 282/500 [00:17<00:13, 15.91it/s] 57%|█████▋    | 284/500 [00:18<00:13, 15.97it/s] 57%|█████▋    | 286/500 [00:18<00:13, 15.99it/s] 58%|█████▊    | 288/500 [00:18<00:13, 16.04it/s] 58%|█████▊    | 290/500 [00:18<00:13, 16.14it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.11it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.09it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.09it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.07it/s] 60%|██████    | 300/500 [00:19<00:12, 16.08it/s] 60%|██████    | 302/500 [00:19<00:12, 16.28it/s] 61%|██████    | 304/500 [00:19<00:12, 16.14it/s] 61%|██████    | 306/500 [00:19<00:11, 16.17it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.19it/s] 62%|██████▏   | 310/500 [00:19<00:13, 14.49it/s] 62%|██████▏   | 312/500 [00:19<00:13, 13.74it/s] 63%|██████▎   | 314/500 [00:20<00:14, 13.22it/s] 63%|██████▎   | 316/500 [00:20<00:14, 12.86it/s] 64%|██████▎   | 318/500 [00:20<00:14, 12.59it/s] 64%|██████▍   | 320/500 [00:20<00:14, 12.50it/s] 64%|██████▍   | 322/500 [00:20<00:14, 12.55it/s] 65%|██████▍   | 324/500 [00:20<00:13, 13.54it/s] 65%|██████▌   | 326/500 [00:20<00:12, 14.32it/s] 66%|██████▌   | 328/500 [00:21<00:11, 14.86it/s] 66%|██████▌   | 330/500 [00:21<00:11, 15.28it/s] 66%|██████▋   | 332/500 [00:21<00:10, 15.58it/s] 67%|██████▋   | 334/500 [00:21<00:10, 15.80it/s] 67%|██████▋   | 336/500 [00:21<00:10, 15.98it/s] 68%|██████▊   | 338/500 [00:21<00:10, 16.12it/s] 68%|██████▊   | 340/500 [00:21<00:10, 15.51it/s] 68%|██████▊   | 342/500 [00:22<00:10, 14.36it/s] 69%|██████▉   | 344/500 [00:22<00:10, 14.22it/s] 69%|██████▉   | 346/500 [00:22<00:10, 14.78it/s] 70%|██████▉   | 348/500 [00:22<00:10, 15.13it/s] 70%|███████   | 350/500 [00:22<00:09, 15.40it/s] 70%|███████   | 352/500 [00:22<00:09, 14.98it/s] 71%|███████   | 354/500 [00:22<00:09, 15.46it/s] 71%|███████   | 356/500 [00:22<00:09, 15.73it/s] 72%|███████▏  | 358/500 [00:23<00:08, 15.91it/s] 72%|███████▏  | 360/500 [00:23<00:08, 16.09it/s] 72%|███████▏  | 362/500 [00:23<00:08, 16.16it/s] 73%|███████▎  | 364/500 [00:23<00:08, 16.27it/s] 73%|███████▎  | 366/500 [00:23<00:08, 15.20it/s] 74%|███████▎  | 368/500 [00:23<00:09, 14.10it/s] 74%|███████▍  | 370/500 [00:23<00:09, 13.46it/s]Valid Loss:  nan
Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
 74%|███████▍  | 372/500 [00:24<00:09, 12.96it/s] 75%|███████▍  | 374/500 [00:24<00:09, 12.67it/s] 75%|███████▌  | 376/500 [00:24<00:09, 12.64it/s] 76%|███████▌  | 378/500 [00:24<00:09, 13.52it/s] 76%|███████▌  | 380/500 [00:24<00:08, 14.29it/s] 76%|███████▋  | 382/500 [00:24<00:07, 14.88it/s] 77%|███████▋  | 384/500 [00:24<00:07, 15.33it/s] 77%|███████▋  | 386/500 [00:24<00:07, 15.56it/s] 78%|███████▊  | 388/500 [00:25<00:07, 15.68it/s] 78%|███████▊  | 390/500 [00:25<00:06, 15.77it/s] 78%|███████▊  | 392/500 [00:25<00:06, 15.72it/s] 79%|███████▉  | 394/500 [00:25<00:06, 15.85it/s] 79%|███████▉  | 396/500 [00:25<00:06, 15.92it/s] 80%|███████▉  | 398/500 [00:25<00:06, 15.77it/s] 80%|████████  | 400/500 [00:25<00:06, 15.98it/s] 80%|████████  | 402/500 [00:25<00:06, 16.16it/s] 81%|████████  | 404/500 [00:26<00:05, 16.25it/s] 81%|████████  | 406/500 [00:26<00:05, 16.06it/s] 82%|████████▏ | 408/500 [00:26<00:05, 15.89it/s] 82%|████████▏ | 410/500 [00:26<00:05, 15.71it/s] 82%|████████▏ | 412/500 [00:26<00:05, 15.88it/s] 83%|████████▎ | 414/500 [00:26<00:05, 15.99it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.02it/s] 84%|████████▎ | 418/500 [00:26<00:05, 16.08it/s] 84%|████████▍ | 420/500 [00:27<00:04, 16.20it/s] 84%|████████▍ | 422/500 [00:27<00:04, 16.26it/s] 85%|████████▍ | 424/500 [00:27<00:04, 16.34it/s] 85%|████████▌ | 426/500 [00:27<00:04, 16.38it/s] 86%|████████▌ | 428/500 [00:27<00:04, 15.50it/s] 86%|████████▌ | 430/500 [00:27<00:04, 14.82it/s] 86%|████████▋ | 432/500 [00:27<00:04, 14.85it/s] 87%|████████▋ | 434/500 [00:28<00:04, 15.28it/s] 87%|████████▋ | 436/500 [00:28<00:04, 15.63it/s] 88%|████████▊ | 438/500 [00:28<00:03, 15.93it/s] 88%|████████▊ | 440/500 [00:28<00:03, 16.12it/s] 88%|████████▊ | 442/500 [00:28<00:03, 16.21it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.19it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.18it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.29it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.38it/s] 90%|█████████ | 452/500 [00:29<00:02, 16.41it/s] 91%|█████████ | 454/500 [00:29<00:02, 16.41it/s] 91%|█████████ | 456/500 [00:29<00:02, 16.29it/s] 92%|█████████▏| 458/500 [00:29<00:02, 16.37it/s] 92%|█████████▏| 460/500 [00:29<00:02, 16.42it/s] 92%|█████████▏| 462/500 [00:29<00:02, 16.34it/s] 93%|█████████▎| 464/500 [00:29<00:02, 16.23it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.25it/s] 94%|█████████▎| 468/500 [00:30<00:01, 16.35it/s] 94%|█████████▍| 470/500 [00:30<00:01, 16.37it/s] 94%|█████████▍| 472/500 [00:30<00:01, 16.41it/s] 95%|█████████▍| 474/500 [00:30<00:01, 16.43it/s] 95%|█████████▌| 476/500 [00:30<00:01, 16.48it/s] 96%|█████████▌| 478/500 [00:30<00:01, 16.43it/s] 96%|█████████▌| 480/500 [00:30<00:01, 16.34it/s] 96%|█████████▋| 482/500 [00:30<00:01, 16.26it/s] 97%|█████████▋| 484/500 [00:31<00:00, 16.30it/s] 97%|█████████▋| 486/500 [00:31<00:00, 16.32it/s] 98%|█████████▊| 488/500 [00:31<00:00, 16.37it/s] 98%|█████████▊| 490/500 [00:31<00:00, 16.30it/s] 98%|█████████▊| 492/500 [00:31<00:00, 16.20it/s] 99%|█████████▉| 494/500 [00:31<00:00, 16.25it/s]Valid Loss:  nan
Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
 99%|█████████▉| 496/500 [00:31<00:00, 16.22it/s]100%|█████████▉| 498/500 [00:31<00:00, 16.23it/s]100%|██████████| 500/500 [00:32<00:00, 16.25it/s]100%|██████████| 500/500 [00:32<00:00, 15.60it/s]
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  11
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:08,  6.27s/it]  1%|          | 3/500 [00:06<13:56,  1.68s/it]  1%|          | 5/500 [00:06<07:01,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.87it/s]  2%|▏         | 11/500 [00:13<10:54,  1.34s/it]  3%|▎         | 13/500 [00:13<07:25,  1.09it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.97it/s]  4%|▍         | 21/500 [00:20<09:39,  1.21s/it]  5%|▍         | 23/500 [00:20<06:51,  1.16it/s]  5%|▌         | 25/500 [00:20<04:54,  1.61it/s]  5%|▌         | 27/500 [00:20<03:33,  2.21it/s]  6%|▌         | 29/500 [00:20<02:38,  2.98it/s]  6%|▌         | 31/500 [00:26<09:19,  1.19s/it]  7%|▋         | 33/500 [00:27<06:39,  1.17it/s]  7%|▋         | 35/500 [00:27<04:47,  1.62it/s]  7%|▋         | 37/500 [00:27<03:29,  2.21it/s]  8%|▊         | 39/500 [00:27<02:35,  2.96it/s]  8%|▊         | 41/500 [00:33<09:11,  1.20s/it]  9%|▊         | 43/500 [00:34<06:33,  1.16it/s]  9%|▉         | 45/500 [00:34<04:43,  1.61it/s]  9%|▉         | 47/500 [00:34<03:26,  2.20it/s] 10%|▉         | 49/500 [00:34<02:32,  2.96it/s] 10%|█         | 51/500 [00:40<08:55,  1.19s/it] 11%|█         | 53/500 [00:40<06:22,  1.17it/s] 11%|█         | 55/500 [00:41<04:35,  1.62it/s] 11%|█▏        | 57/500 [00:41<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:41<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:47<08:47,  1.20s/it] 13%|█▎        | 63/500 [00:47<06:16,  1.16it/s] 13%|█▎        | 65/500 [00:48<04:31,  1.60it/s] 13%|█▎        | 67/500 [00:48<03:17,  2.19it/s] 14%|█▍        | 69/500 [00:48<02:26,  2.95it/s] 14%|█▍        | 71/500 [00:54<08:29,  1.19s/it]Epoch:  1  	Training Loss: 0.02847922034561634
Test Loss:  0.36733460426330566
Valid Loss:  0.36829444766044617
Epoch:  2  	Training Loss: 0.362127423286438
Test Loss:  0.7064956426620483
Valid Loss:  0.7149165868759155
Epoch:  3  	Training Loss: 0.6614097356796265
Test Loss:  0.032261915504932404
Valid Loss:  0.03126605600118637
Epoch:  4  	Training Loss: 0.029508434236049652
Test Loss:  0.03225491940975189
Valid Loss:  0.03126026690006256
Epoch:  5  	Training Loss: 0.02949872799217701
Test Loss:  0.03225228190422058
Valid Loss:  0.03125767037272453
Epoch:  6  	Training Loss: 0.02949337661266327
Test Loss:  0.032250866293907166
Valid Loss:  0.031256385147571564
Epoch:  7  	Training Loss: 0.029490802437067032
Test Loss:  0.03224943205714226
Valid Loss:  0.03125534951686859
Epoch:  8  	Training Loss: 0.029488515108823776
Test Loss:  0.032247819006443024
Valid Loss:  0.03125392645597458
Epoch:  9  	Training Loss: 0.02948632836341858
Test Loss:  0.03224620968103409
Valid Loss:  0.031252503395080566
Epoch:  10  	Training Loss: 0.02948414534330368
Test Loss:  0.03224460780620575
Valid Loss:  0.03125108778476715
Epoch:  11  	Training Loss: 0.029481962323188782
Test Loss:  0.03224300593137741
Valid Loss:  0.03124966472387314
Epoch:  12  	Training Loss: 0.029479779303073883
Test Loss:  0.0322396457195282
Valid Loss:  0.031246243044734
Epoch:  13  	Training Loss: 0.029476003721356392
Test Loss:  0.032236311584711075
Valid Loss:  0.031242815777659416
Epoch:  14  	Training Loss: 0.02947225607931614
Test Loss:  0.03223312273621559
Valid Loss:  0.03123943693935871
Epoch:  15  	Training Loss: 0.02946857362985611
Test Loss:  0.03223004192113876
Valid Loss:  0.031236128881573677
Epoch:  16  	Training Loss: 0.029465004801750183
Test Loss:  0.032227180898189545
Valid Loss:  0.031232889741659164
Epoch:  17  	Training Loss: 0.029461506754159927
Test Loss:  0.03222431242465973
Valid Loss:  0.031229646876454353
Epoch:  18  	Training Loss: 0.02945801056921482
Test Loss:  0.03222150355577469
Valid Loss:  0.03122638911008835
Epoch:  19  	Training Loss: 0.029454538598656654
Test Loss:  0.03221878781914711
Valid Loss:  0.031223371624946594
Epoch:  20  	Training Loss: 0.029451148584485054
Test Loss:  0.03221610188484192
Valid Loss:  0.031220529228448868
Epoch:  21  	Training Loss: 0.029447827488183975
Test Loss:  0.03221338242292404
Valid Loss:  0.031217660754919052
Epoch:  22  	Training Loss: 0.029444530606269836
Test Loss:  0.032210707664489746
Valid Loss:  0.03121485374867916
Epoch:  23  	Training Loss: 0.029441237449645996
Test Loss:  0.03220803663134575
Valid Loss:  0.03121204301714897
Epoch:  24  	Training Loss: 0.029437990859150887
Test Loss:  0.03220539540052414
Valid Loss:  0.031209304928779602
Epoch:  25  	Training Loss: 0.02943482995033264
Test Loss:  0.03220287710428238
Valid Loss:  0.031206747516989708
Epoch:  26  	Training Loss: 0.029431672766804695
Test Loss:  0.032200440764427185
Valid Loss:  0.0312042199075222
Epoch:  27  	Training Loss: 0.029428556561470032
Test Loss:  0.032198064029216766
Valid Loss:  0.03120165877044201
Epoch:  28  	Training Loss: 0.02942548133432865
Test Loss:  0.032195769250392914
Valid Loss:  0.031199224293231964
Epoch:  29  	Training Loss: 0.02942240610718727
Test Loss:  0.032193563878536224
Valid Loss:  0.031196877360343933
Epoch:  30  	Training Loss: 0.029419343918561935
Test Loss:  0.032191406935453415
Valid Loss:  0.031194578856229782
Epoch:  31  	Training Loss: 0.029416315257549286
Test Loss:  0.03218922019004822
Valid Loss:  0.031192291527986526
Epoch:  32  	Training Loss: 0.02941332384943962
Test Loss:  0.03218713402748108
Valid Loss:  0.03119012899696827
Epoch:  33  	Training Loss: 0.029410425573587418
Test Loss:  0.032185062766075134
Valid Loss:  0.031187988817691803
Epoch:  34  	Training Loss: 0.029407545924186707
Test Loss:  0.0321829691529274
Valid Loss:  0.03118579089641571
Epoch:  35  	Training Loss: 0.029404666274785995
Test Loss:  0.03218096122145653
Valid Loss:  0.031183648854494095
Epoch:  36  	Training Loss: 0.029401810839772224
Test Loss:  0.03217897564172745
Valid Loss:  0.03118157386779785
Epoch:  37  	Training Loss: 0.029399005696177483
Test Loss:  0.03217700496315956
Valid Loss:  0.031179610639810562
Epoch:  38  	Training Loss: 0.02939622849225998
Test Loss:  0.032175034284591675
Valid Loss:  0.03117765299975872
Epoch:  39  	Training Loss: 0.029393451288342476
Test Loss:  0.03217301145195961
Valid Loss:  0.03117569349706173
Epoch:  40  	Training Loss: 0.029390674084424973
Test Loss:  0.03217103332281113
Valid Loss:  0.031173788011074066
Epoch:  41  	Training Loss: 0.02938789874315262
Test Loss:  0.032169077545404434
Valid Loss:  0.031171899288892746
Epoch:  42  	Training Loss: 0.02938515692949295
Test Loss:  0.03216712921857834
Valid Loss:  0.031170036643743515
Epoch:  43  	Training Loss: 0.02938247099518776
Test Loss:  0.03216519579291344
Valid Loss:  0.03116818144917488
Epoch:  44  	Training Loss: 0.02937980368733406
Test Loss:  0.03216320648789406
Valid Loss:  0.03116627037525177
Epoch:  45  	Training Loss: 0.02937714383006096
Test Loss:  0.03216128051280975
Valid Loss:  0.03116443008184433
Epoch:  46  	Training Loss: 0.029374513775110245
Test Loss:  0.032159365713596344
Valid Loss:  0.03116261586546898
Epoch:  47  	Training Loss: 0.02937190793454647
Test Loss:  0.032157473266124725
Valid Loss:  0.031160855665802956
Epoch:  48  	Training Loss: 0.029369354248046875
Test Loss:  0.032155591994524
Valid Loss:  0.031159119680523872
Epoch:  49  	Training Loss: 0.029366835951805115
Test Loss:  0.032153718173503876
Valid Loss:  0.03115738555788994
Epoch:  50  	Training Loss: 0.02936432510614395
Test Loss:  0.03215178847312927
Valid Loss:  0.031155604869127274
Epoch:  51  	Training Loss: 0.029361829161643982
Test Loss:  0.03214992582798004
Valid Loss:  0.031153889372944832
Epoch:  52  	Training Loss: 0.02935934066772461
Test Loss:  0.03214814141392708
Valid Loss:  0.031152281910181046
Epoch:  53  	Training Loss: 0.029356922954320908
Test Loss:  0.03214636445045471
Valid Loss:  0.0311506986618042
Epoch:  54  	Training Loss: 0.029354512691497803
Test Loss:  0.03214457631111145
Valid Loss:  0.031149104237556458
Epoch:  55  	Training Loss: 0.029352113604545593
Test Loss:  0.03214281052350998
Valid Loss:  0.031147519126534462
Epoch:  56  	Training Loss: 0.029349733144044876
Test Loss:  0.03214103728532791
Valid Loss:  0.031145934015512466
Epoch:  57  	Training Loss: 0.029347356408834457
Test Loss:  0.03213927894830704
Valid Loss:  0.031144361943006516
Epoch:  58  	Training Loss: 0.029345005750656128
Test Loss:  0.03213752061128616
Valid Loss:  0.03114280104637146
Epoch:  59  	Training Loss: 0.029342658817768097
Test Loss:  0.032135769724845886
Valid Loss:  0.031141232699155807
Epoch:  60  	Training Loss: 0.029340313747525215
Test Loss:  0.03213401511311531
Valid Loss:  0.031139664351940155
Epoch:  61  	Training Loss: 0.029337970539927483
Test Loss:  0.032132215797901154
Valid Loss:  0.031138049438595772
Epoch:  62  	Training Loss: 0.029335640370845795
Test Loss:  0.03213050961494446
Valid Loss:  0.031136509031057358
Epoch:  63  	Training Loss: 0.02933335304260254
Test Loss:  0.032128818333148956
Valid Loss:  0.03113497421145439
Epoch:  64  	Training Loss: 0.029331069439649582
Test Loss:  0.03212711960077286
Valid Loss:  0.031133443117141724
Epoch:  65  	Training Loss: 0.029328791424632072
Test Loss:  0.03212542086839676
Valid Loss:  0.031131908297538757
Epoch:  66  	Training Loss: 0.029326513409614563
Test Loss:  0.032123733311891556
Valid Loss:  0.031130380928516388
Epoch:  67  	Training Loss: 0.029324239119887352
Test Loss:  0.03212204575538635
Valid Loss:  0.03112884797155857
Epoch:  68  	Training Loss: 0.02932196483016014
Test Loss:  0.03212035074830055
Valid Loss:  0.031127316877245903
Epoch:  69  	Training Loss: 0.02931968867778778
Test Loss:  0.03211865946650505
Valid Loss:  0.03112579695880413
Epoch:  70  	Training Loss: 0.02931741625070572
Test Loss:  0.03211697190999985
Valid Loss:  0.031124290078878403
Epoch:  71  	Training Loss: 0.029315145686268806
Test Loss:  0.032115280628204346
Valid Loss:  0.03112279437482357
Epoch:  72  	Training Loss: 0.029312897473573685
Test Loss:  0.03211364150047302
 15%|█▍        | 73/500 [00:54<06:04,  1.17it/s] 15%|█▌        | 75/500 [00:54<04:21,  1.62it/s] 15%|█▌        | 77/500 [00:55<03:10,  2.22it/s] 16%|█▌        | 79/500 [00:55<02:21,  2.97it/s] 16%|█▌        | 81/500 [01:01<08:19,  1.19s/it] 17%|█▋        | 83/500 [01:01<05:57,  1.17it/s] 17%|█▋        | 85/500 [01:01<04:17,  1.61it/s] 17%|█▋        | 87/500 [01:02<03:07,  2.20it/s] 18%|█▊        | 89/500 [01:02<02:21,  2.90it/s] 18%|█▊        | 91/500 [01:08<08:15,  1.21s/it] 19%|█▊        | 93/500 [01:08<05:56,  1.14it/s] 19%|█▉        | 95/500 [01:08<04:17,  1.57it/s] 19%|█▉        | 97/500 [01:09<03:08,  2.14it/s] 20%|█▉        | 99/500 [01:09<02:19,  2.88it/s] 20%|██        | 101/500 [01:15<07:53,  1.19s/it] 21%|██        | 103/500 [01:15<05:39,  1.17it/s] 21%|██        | 105/500 [01:15<04:04,  1.62it/s] 21%|██▏       | 107/500 [01:16<02:57,  2.21it/s] 22%|██▏       | 109/500 [01:16<02:13,  2.93it/s] 22%|██▏       | 111/500 [01:22<07:50,  1.21s/it] 23%|██▎       | 113/500 [01:22<05:35,  1.15it/s] 23%|██▎       | 115/500 [01:22<04:01,  1.59it/s] 23%|██▎       | 117/500 [01:23<02:58,  2.14it/s] 24%|██▍       | 119/500 [01:23<02:14,  2.82it/s] 24%|██▍       | 121/500 [01:29<07:36,  1.21s/it] 25%|██▍       | 123/500 [01:29<05:25,  1.16it/s] 25%|██▌       | 125/500 [01:29<03:54,  1.60it/s] 25%|██▌       | 127/500 [01:30<02:51,  2.18it/s] 26%|██▌       | 129/500 [01:30<02:06,  2.93it/s] 26%|██▌       | 131/500 [01:36<07:27,  1.21s/it] 27%|██▋       | 133/500 [01:36<05:19,  1.15it/s] 27%|██▋       | 135/500 [01:36<03:49,  1.59it/s] 27%|██▋       | 137/500 [01:37<02:47,  2.17it/s] 28%|██▊       | 139/500 [01:37<02:03,  2.93it/s] 28%|██▊       | 141/500 [01:43<07:17,  1.22s/it]Valid Loss:  0.03112133778631687
Epoch:  73  	Training Loss: 0.029310695827007294
Test Loss:  0.0321120023727417
Valid Loss:  0.031119879335165024
Epoch:  74  	Training Loss: 0.029308494180440903
Test Loss:  0.03211035579442978
Valid Loss:  0.031118422746658325
Epoch:  75  	Training Loss: 0.029306290671229362
Test Loss:  0.03210871294140816
Valid Loss:  0.031116962432861328
Epoch:  76  	Training Loss: 0.02930409088730812
Test Loss:  0.032107070088386536
Valid Loss:  0.03111550584435463
Epoch:  77  	Training Loss: 0.02930189110338688
Test Loss:  0.032105427235364914
Valid Loss:  0.03111404739320278
Epoch:  78  	Training Loss: 0.029299691319465637
Test Loss:  0.03210378438234329
Valid Loss:  0.031112592667341232
Epoch:  79  	Training Loss: 0.029297493398189545
Test Loss:  0.03210214152932167
Valid Loss:  0.031111156567931175
Epoch:  80  	Training Loss: 0.02929529920220375
Test Loss:  0.032100506126880646
Valid Loss:  0.031109724193811417
Epoch:  81  	Training Loss: 0.029293101280927658
Test Loss:  0.03209886699914932
Valid Loss:  0.031108282506465912
Epoch:  82  	Training Loss: 0.029290907084941864
Test Loss:  0.032097212970256805
Valid Loss:  0.03110683709383011
Epoch:  83  	Training Loss: 0.029288705438375473
Test Loss:  0.03209555894136429
Valid Loss:  0.03110538236796856
Epoch:  84  	Training Loss: 0.02928650565445423
Test Loss:  0.03209390491247177
Valid Loss:  0.031103935092687607
Epoch:  85  	Training Loss: 0.029284309595823288
Test Loss:  0.03209225460886955
Valid Loss:  0.031102485954761505
Epoch:  86  	Training Loss: 0.029282111674547195
Test Loss:  0.032090600579977036
Valid Loss:  0.031101040542125702
Epoch:  87  	Training Loss: 0.02927991934120655
Test Loss:  0.03208896145224571
Valid Loss:  0.0310995951294899
Epoch:  88  	Training Loss: 0.0292777381837368
Test Loss:  0.03208731859922409
Valid Loss:  0.031098153442144394
Epoch:  89  	Training Loss: 0.029275553300976753
Test Loss:  0.03208567202091217
Valid Loss:  0.03109671175479889
Epoch:  90  	Training Loss: 0.029273368418216705
Test Loss:  0.03208402544260025
Valid Loss:  0.031095270067453384
Epoch:  91  	Training Loss: 0.029271189123392105
Test Loss:  0.03208238631486893
Valid Loss:  0.03109382465481758
Epoch:  92  	Training Loss: 0.029269009828567505
Test Loss:  0.03208077698945999
Valid Loss:  0.031092418357729912
Epoch:  93  	Training Loss: 0.029266849160194397
Test Loss:  0.03207916393876076
Valid Loss:  0.031091010197997093
Epoch:  94  	Training Loss: 0.02926468849182129
Test Loss:  0.032077569514513016
Valid Loss:  0.031089607626199722
Epoch:  95  	Training Loss: 0.029262524098157883
Test Loss:  0.03207597881555557
Valid Loss:  0.03108818829059601
Epoch:  96  	Training Loss: 0.029260367155075073
Test Loss:  0.03207439184188843
Valid Loss:  0.031086783856153488
Epoch:  97  	Training Loss: 0.029258208349347115
Test Loss:  0.03207280486822128
Valid Loss:  0.031085364520549774
Epoch:  98  	Training Loss: 0.02925604209303856
Test Loss:  0.03207122161984444
Valid Loss:  0.031083956360816956
Epoch:  99  	Training Loss: 0.029253888875246048
Test Loss:  0.03206964209675789
Valid Loss:  0.031082546338438988
Epoch:  100  	Training Loss: 0.02925173193216324
Test Loss:  0.03206805884838104
Valid Loss:  0.03108113631606102
Epoch:  101  	Training Loss: 0.02924957126379013
Test Loss:  0.032066479325294495
Valid Loss:  0.031079726293683052
Epoch:  102  	Training Loss: 0.02924741804599762
Test Loss:  0.032064929604530334
Valid Loss:  0.03107834793627262
Epoch:  103  	Training Loss: 0.029245294630527496
Test Loss:  0.032063379883766174
Valid Loss:  0.03107697144150734
Epoch:  104  	Training Loss: 0.02924317494034767
Test Loss:  0.032061830163002014
Valid Loss:  0.031075598672032356
Epoch:  105  	Training Loss: 0.029241058975458145
Test Loss:  0.032060276716947556
Valid Loss:  0.031074216589331627
Epoch:  106  	Training Loss: 0.029238946735858917
Test Loss:  0.03205873444676399
Valid Loss:  0.031072843819856644
Epoch:  107  	Training Loss: 0.02923683077096939
Test Loss:  0.032057181000709534
Valid Loss:  0.031071465462446213
Epoch:  108  	Training Loss: 0.029234718531370163
Test Loss:  0.03205563873052597
Valid Loss:  0.031070087105035782
Epoch:  109  	Training Loss: 0.02923261933028698
Test Loss:  0.03205409646034241
Valid Loss:  0.031068723648786545
Epoch:  110  	Training Loss: 0.029230520129203796
Test Loss:  0.032052554190158844
Valid Loss:  0.031067360192537308
Epoch:  111  	Training Loss: 0.02922842651605606
Test Loss:  0.03205101564526558
Valid Loss:  0.031065993010997772
Epoch:  112  	Training Loss: 0.029226336628198624
Test Loss:  0.03204943984746933
Valid Loss:  0.0310645941644907
Epoch:  113  	Training Loss: 0.029224220663309097
Test Loss:  0.032047878950834274
Valid Loss:  0.031063202768564224
Epoch:  114  	Training Loss: 0.02922211028635502
Test Loss:  0.032046303153038025
Valid Loss:  0.031061798334121704
Epoch:  115  	Training Loss: 0.029219992458820343
Test Loss:  0.03204472362995148
Valid Loss:  0.03106040135025978
Epoch:  116  	Training Loss: 0.029217876493930817
Test Loss:  0.032043155282735825
Valid Loss:  0.031059004366397858
Epoch:  117  	Training Loss: 0.02921576425433159
Test Loss:  0.032041583210229874
Valid Loss:  0.031057603657245636
Epoch:  118  	Training Loss: 0.029213648289442062
Test Loss:  0.03203999996185303
Valid Loss:  0.031056197360157967
Epoch:  119  	Training Loss: 0.029211530461907387
Test Loss:  0.032038427889347076
Valid Loss:  0.031054798513650894
Epoch:  120  	Training Loss: 0.02920941822230816
Test Loss:  0.032036859542131424
Valid Loss:  0.03105340339243412
Epoch:  121  	Training Loss: 0.02920731157064438
Test Loss:  0.032035283744335175
Valid Loss:  0.03105200082063675
Epoch:  122  	Training Loss: 0.02920519933104515
Test Loss:  0.03203371539711952
Valid Loss:  0.031050605699419975
Epoch:  123  	Training Loss: 0.029203105717897415
Test Loss:  0.03203214332461357
Valid Loss:  0.031049206852912903
Epoch:  124  	Training Loss: 0.029201006516814232
Test Loss:  0.03203057870268822
Valid Loss:  0.031047813594341278
Epoch:  125  	Training Loss: 0.029198909178376198
Test Loss:  0.032029006630182266
Valid Loss:  0.031046416610479355
Epoch:  126  	Training Loss: 0.029196809977293015
Test Loss:  0.03202744200825691
Valid Loss:  0.03104502521455288
Epoch:  127  	Training Loss: 0.029194721952080727
Test Loss:  0.03202587738633156
Valid Loss:  0.03104364685714245
Epoch:  128  	Training Loss: 0.02919263392686844
Test Loss:  0.0320243164896965
Valid Loss:  0.03104226663708687
Epoch:  129  	Training Loss: 0.0291905477643013
Test Loss:  0.03202275186777115
Valid Loss:  0.03104088269174099
Epoch:  130  	Training Loss: 0.02918846160173416
Test Loss:  0.0320211797952652
Valid Loss:  0.031039506196975708
Epoch:  131  	Training Loss: 0.029186371713876724
Test Loss:  0.032019615173339844
Valid Loss:  0.031038135290145874
Epoch:  132  	Training Loss: 0.029184285551309586
Test Loss:  0.03201805427670479
Valid Loss:  0.03103676438331604
Epoch:  133  	Training Loss: 0.02918219566345215
Test Loss:  0.03201649710536003
Valid Loss:  0.031035402789711952
Epoch:  134  	Training Loss: 0.02918010577559471
Test Loss:  0.032014939934015274
Valid Loss:  0.031034037470817566
Epoch:  135  	Training Loss: 0.029178019613027573
Test Loss:  0.032013386487960815
Valid Loss:  0.03103266842663288
Epoch:  136  	Training Loss: 0.029175929725170135
Test Loss:  0.03201182931661606
Valid Loss:  0.031031301245093346
Epoch:  137  	Training Loss: 0.029173851013183594
Test Loss:  0.0320102833211422
Valid Loss:  0.03102993406355381
Epoch:  138  	Training Loss: 0.029171770438551903
Test Loss:  0.03200872242450714
Valid Loss:  0.031028568744659424
Epoch:  139  	Training Loss: 0.029169688001275063
Test Loss:  0.03200717270374298
Valid Loss:  0.031027203425765038
Epoch:  140  	Training Loss: 0.02916760928928852
Test Loss:  0.03200562298297882
Valid Loss:  0.03102583810687065
Epoch:  141  	Training Loss: 0.02916553243994713
Test Loss:  0.03200407326221466
Valid Loss:  0.031024472787976265
Epoch:  142  	Training Loss: 0.029163450002670288
Test Loss:  0.032002560794353485
Valid Loss:  0.031023137271404266
Epoch:  143  	Training Loss: 0.02916141040623188
Test Loss:  0.032001033425331116
Valid Loss:   29%|██▊       | 143/500 [01:43<05:12,  1.14it/s] 29%|██▉       | 145/500 [01:44<03:44,  1.58it/s] 29%|██▉       | 147/500 [01:44<02:43,  2.16it/s] 30%|██▉       | 149/500 [01:44<02:01,  2.88it/s] 30%|███       | 151/500 [01:50<06:56,  1.19s/it] 31%|███       | 153/500 [01:50<04:57,  1.17it/s] 31%|███       | 155/500 [01:50<03:33,  1.62it/s] 31%|███▏      | 157/500 [01:51<02:35,  2.21it/s] 32%|███▏      | 159/500 [01:51<01:54,  2.97it/s] 32%|███▏      | 161/500 [01:57<06:38,  1.18s/it] 33%|███▎      | 163/500 [01:57<04:44,  1.18it/s] 33%|███▎      | 165/500 [01:57<03:24,  1.64it/s] 33%|███▎      | 167/500 [01:57<02:28,  2.24it/s] 34%|███▍      | 169/500 [01:58<01:50,  3.01it/s] 34%|███▍      | 171/500 [02:04<06:32,  1.19s/it] 35%|███▍      | 173/500 [02:04<04:42,  1.16it/s] 35%|███▌      | 175/500 [02:04<03:24,  1.59it/s] 35%|███▌      | 177/500 [02:04<02:29,  2.16it/s] 36%|███▌      | 179/500 [02:05<01:50,  2.91it/s] 36%|███▌      | 181/500 [02:11<06:21,  1.19s/it] 37%|███▋      | 183/500 [02:11<04:32,  1.16it/s] 37%|███▋      | 185/500 [02:11<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:11<02:22,  2.20it/s] 38%|███▊      | 189/500 [02:11<01:45,  2.96it/s] 38%|███▊      | 191/500 [02:18<06:09,  1.20s/it] 39%|███▊      | 193/500 [02:18<04:23,  1.16it/s] 39%|███▉      | 195/500 [02:18<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:18<02:18,  2.18it/s] 40%|███▉      | 199/500 [02:18<01:44,  2.89it/s] 40%|████      | 201/500 [02:25<06:09,  1.24s/it] 41%|████      | 203/500 [02:25<04:23,  1.13it/s] 41%|████      | 205/500 [02:25<03:10,  1.55it/s] 41%|████▏     | 207/500 [02:26<02:18,  2.11it/s] 42%|████▏     | 209/500 [02:26<01:42,  2.85it/s] 42%|████▏     | 211/500 [02:32<05:49,  1.21s/it] 43%|████▎     | 213/500 [02:32<04:09,  1.15it/s]0.031021805480122566
Epoch:  144  	Training Loss: 0.029159368947148323
Test Loss:  0.03199952095746994
Valid Loss:  0.031020481139421463
Epoch:  145  	Training Loss: 0.029157327488064766
Test Loss:  0.03199800103902817
Valid Loss:  0.031019147485494614
Epoch:  146  	Training Loss: 0.029155291616916656
Test Loss:  0.03199649229645729
Valid Loss:  0.03101782500743866
Epoch:  147  	Training Loss: 0.0291532501578331
Test Loss:  0.03199496865272522
Valid Loss:  0.03101649321615696
Epoch:  148  	Training Loss: 0.02915121242403984
Test Loss:  0.031993452459573746
Valid Loss:  0.031015168875455856
Epoch:  149  	Training Loss: 0.029149172827601433
Test Loss:  0.03199193999171257
Valid Loss:  0.031013837084174156
Epoch:  150  	Training Loss: 0.029147133231163025
Test Loss:  0.031990427523851395
Valid Loss:  0.031012510880827904
Epoch:  151  	Training Loss: 0.029145099222660065
Test Loss:  0.03198891878128052
Valid Loss:  0.031011182814836502
Epoch:  152  	Training Loss: 0.029143065214157104
Test Loss:  0.031987376511096954
Valid Loss:  0.031009821221232414
Epoch:  153  	Training Loss: 0.02914099022746086
Test Loss:  0.03198583424091339
Valid Loss:  0.031008463352918625
Epoch:  154  	Training Loss: 0.029138922691345215
Test Loss:  0.03198428452014923
Valid Loss:  0.03100709617137909
Epoch:  155  	Training Loss: 0.02913685329258442
Test Loss:  0.03198274224996567
Valid Loss:  0.031005730852484703
Epoch:  156  	Training Loss: 0.029134787619113922
Test Loss:  0.031981199979782104
Valid Loss:  0.031004371121525764
Epoch:  157  	Training Loss: 0.029132721945643425
Test Loss:  0.03197965398430824
Valid Loss:  0.031003005802631378
Epoch:  158  	Training Loss: 0.029130656272172928
Test Loss:  0.03197810798883438
Valid Loss:  0.03100164234638214
Epoch:  159  	Training Loss: 0.02912858873605728
Test Loss:  0.03197656571865082
Valid Loss:  0.031000275164842606
Epoch:  160  	Training Loss: 0.029126524925231934
Test Loss:  0.031975019723176956
Valid Loss:  0.03099891170859337
Epoch:  161  	Training Loss: 0.029124457389116287
Test Loss:  0.031973473727703094
Valid Loss:  0.030997540801763535
Epoch:  162  	Training Loss: 0.029122386127710342
Test Loss:  0.03197193518280983
Valid Loss:  0.030996190384030342
Epoch:  163  	Training Loss: 0.029120344668626785
Test Loss:  0.03197041153907776
Valid Loss:  0.030994832515716553
Epoch:  164  	Training Loss: 0.029118303209543228
Test Loss:  0.03196888044476509
Valid Loss:  0.030993476510047913
Epoch:  165  	Training Loss: 0.02911626175045967
Test Loss:  0.03196734935045242
Valid Loss:  0.03099212236702442
Epoch:  166  	Training Loss: 0.029114220291376114
Test Loss:  0.031965821981430054
Valid Loss:  0.030990764498710632
Epoch:  167  	Training Loss: 0.029112180694937706
Test Loss:  0.031964290887117386
Valid Loss:  0.03098941221833229
Epoch:  168  	Training Loss: 0.029110141098499298
Test Loss:  0.03196275234222412
Valid Loss:  0.030988052487373352
Epoch:  169  	Training Loss: 0.029108097776770592
Test Loss:  0.03196122869849205
Valid Loss:  0.030986689031124115
Epoch:  170  	Training Loss: 0.029106058180332184
Test Loss:  0.03195970505475998
Valid Loss:  0.030985336750745773
Epoch:  171  	Training Loss: 0.029104018583893776
Test Loss:  0.03195818513631821
Valid Loss:  0.030983980745077133
Epoch:  172  	Training Loss: 0.029101982712745667
Test Loss:  0.03195670247077942
Valid Loss:  0.030982665717601776
Epoch:  173  	Training Loss: 0.02909996546804905
Test Loss:  0.03195521980524063
Valid Loss:  0.030981354415416718
Epoch:  174  	Training Loss: 0.02909795194864273
Test Loss:  0.031953729689121246
Valid Loss:  0.030980035662651062
Epoch:  175  	Training Loss: 0.029095936566591263
Test Loss:  0.03195224702358246
Valid Loss:  0.030978724360466003
Epoch:  176  	Training Loss: 0.029093926772475243
Test Loss:  0.03195076063275337
Valid Loss:  0.0309774037450552
Epoch:  177  	Training Loss: 0.029091913253068924
Test Loss:  0.03194930776953697
Valid Loss:  0.03097614273428917
Epoch:  178  	Training Loss: 0.029089897871017456
Test Loss:  0.03194785863161087
Valid Loss:  0.030974891036748886
Epoch:  179  	Training Loss: 0.029087889939546585
Test Loss:  0.03194640204310417
Valid Loss:  0.030973628163337708
Epoch:  180  	Training Loss: 0.029085878282785416
Test Loss:  0.031944915652275085
Valid Loss:  0.030972307547926903
Epoch:  181  	Training Loss: 0.029083870351314545
Test Loss:  0.03194345906376839
Valid Loss:  0.030971050262451172
Epoch:  182  	Training Loss: 0.029081858694553375
Test Loss:  0.0319419801235199
Valid Loss:  0.03096977062523365
Epoch:  183  	Training Loss: 0.029079817235469818
Test Loss:  0.03194049373269081
Valid Loss:  0.03096848912537098
Epoch:  184  	Training Loss: 0.029077773913741112
Test Loss:  0.031938984990119934
Valid Loss:  0.030967149883508682
Epoch:  185  	Training Loss: 0.029075728729367256
Test Loss:  0.03193749487400055
Valid Loss:  0.030965866521000862
Epoch:  186  	Training Loss: 0.02907368913292885
Test Loss:  0.03193601220846176
Valid Loss:  0.03096458874642849
Epoch:  187  	Training Loss: 0.029071643948554993
Test Loss:  0.031934525817632675
Valid Loss:  0.03096330165863037
Epoch:  188  	Training Loss: 0.029069602489471436
Test Loss:  0.0319330170750618
Valid Loss:  0.030961964279413223
Epoch:  189  	Training Loss: 0.029067562893033028
Test Loss:  0.03193153068423271
Valid Loss:  0.030960682779550552
Epoch:  190  	Training Loss: 0.02906551957130432
Test Loss:  0.031930048018693924
Valid Loss:  0.030959397554397583
Epoch:  191  	Training Loss: 0.029063479974865913
Test Loss:  0.03192856162786484
Valid Loss:  0.030958114191889763
Epoch:  192  	Training Loss: 0.029061438515782356
Test Loss:  0.03192715346813202
Valid Loss:  0.030956896021962166
Epoch:  193  	Training Loss: 0.029059484601020813
Test Loss:  0.0319257453083992
Valid Loss:  0.030955687165260315
Epoch:  194  	Training Loss: 0.029057536274194717
Test Loss:  0.03192431479692459
Valid Loss:  0.03095441311597824
Epoch:  195  	Training Loss: 0.029055584222078323
Test Loss:  0.03192290663719177
Valid Loss:  0.03095320239663124
Epoch:  196  	Training Loss: 0.029053635895252228
Test Loss:  0.03192150220274925
Valid Loss:  0.03095199167728424
Epoch:  197  	Training Loss: 0.029051683843135834
Test Loss:  0.03192009776830673
Valid Loss:  0.03095078095793724
Epoch:  198  	Training Loss: 0.029049739241600037
Test Loss:  0.03191869705915451
Valid Loss:  0.030949566513299942
Epoch:  199  	Training Loss: 0.02904779277741909
Test Loss:  0.03191729635000229
Valid Loss:  0.030948355793952942
Epoch:  200  	Training Loss: 0.029045848175883293
Test Loss:  0.03191588819026947
Valid Loss:  0.030947145074605942
Epoch:  201  	Training Loss: 0.029043905436992645
Test Loss:  0.03191449120640755
Valid Loss:  0.030945932492613792
Epoch:  202  	Training Loss: 0.029041964560747147
Test Loss:  0.03191300481557846
Valid Loss:  0.03094463422894478
Epoch:  203  	Training Loss: 0.029039952903985977
Test Loss:  0.03191152215003967
Valid Loss:  0.03094334714114666
Epoch:  204  	Training Loss: 0.029037944972515106
Test Loss:  0.03191004693508148
Valid Loss:  0.030942050740122795
Epoch:  205  	Training Loss: 0.029035933315753937
Test Loss:  0.031908564269542694
Valid Loss:  0.03094075433909893
Epoch:  206  	Training Loss: 0.029033925384283066
Test Loss:  0.0319070927798748
Valid Loss:  0.030939463526010513
Epoch:  207  	Training Loss: 0.029031917452812195
Test Loss:  0.03190561383962631
Valid Loss:  0.03093816712498665
Epoch:  208  	Training Loss: 0.029029907658696175
Test Loss:  0.03190413862466812
Valid Loss:  0.03093687817454338
Epoch:  209  	Training Loss: 0.02902790904045105
Test Loss:  0.03190266713500023
Valid Loss:  0.030935583636164665
Epoch:  210  	Training Loss: 0.029025904834270477
Test Loss:  0.031901195645332336
Valid Loss:  0.03093428909778595
Epoch:  211  	Training Loss: 0.029023902490735054
Test Loss:  0.031899720430374146
Valid Loss:  0.030932998284697533
Epoch:  212  	Training Loss: 0.02902190573513508
Test Loss:  0.031898245215415955
Valid Loss:  0.030931711196899414
Epoch:  213  	Training Loss: 0.02901989221572876
Test Loss:  0.03189677372574806
Valid Loss:  0.0309304166585207
Epoch:  214  	Training Loss: 0.029017888009548187
Test Loss:   43%|████▎     | 215/500 [02:32<02:59,  1.59it/s] 43%|████▎     | 217/500 [02:33<02:10,  2.17it/s] 44%|████▍     | 219/500 [02:33<01:36,  2.92it/s] 44%|████▍     | 221/500 [02:39<05:33,  1.20s/it] 45%|████▍     | 223/500 [02:39<03:58,  1.16it/s] 45%|████▌     | 225/500 [02:39<02:50,  1.61it/s] 45%|████▌     | 227/500 [02:39<02:04,  2.20it/s] 46%|████▌     | 229/500 [02:40<01:31,  2.96it/s] 46%|████▌     | 231/500 [02:46<05:30,  1.23s/it] 47%|████▋     | 233/500 [02:46<03:57,  1.13it/s] 47%|████▋     | 235/500 [02:46<02:49,  1.56it/s] 47%|████▋     | 237/500 [02:47<02:03,  2.14it/s] 48%|████▊     | 239/500 [02:47<01:30,  2.88it/s] 48%|████▊     | 241/500 [02:53<05:17,  1.22s/it] 49%|████▊     | 243/500 [02:53<03:45,  1.14it/s] 49%|████▉     | 245/500 [02:54<02:41,  1.57it/s] 49%|████▉     | 247/500 [02:54<01:57,  2.15it/s] 50%|████▉     | 249/500 [02:54<01:27,  2.88it/s] 50%|█████     | 251/500 [03:00<05:00,  1.21s/it] 51%|█████     | 253/500 [03:00<03:34,  1.15it/s] 51%|█████     | 255/500 [03:01<02:33,  1.60it/s] 51%|█████▏    | 257/500 [03:01<01:51,  2.18it/s] 52%|█████▏    | 259/500 [03:01<01:22,  2.93it/s] 52%|█████▏    | 261/500 [03:07<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:07<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:07<02:24,  1.63it/s] 53%|█████▎    | 267/500 [03:08<01:44,  2.22it/s] 54%|█████▍    | 269/500 [03:08<01:17,  2.98it/s] 54%|█████▍    | 271/500 [03:14<04:32,  1.19s/it] 55%|█████▍    | 273/500 [03:14<03:14,  1.17it/s] 55%|█████▌    | 275/500 [03:14<02:19,  1.62it/s] 55%|█████▌    | 277/500 [03:14<01:40,  2.21it/s] 56%|█████▌    | 279/500 [03:15<01:14,  2.97it/s] 56%|█████▌    | 281/500 [03:21<04:24,  1.21s/it] 57%|█████▋    | 283/500 [03:21<03:08,  1.15it/s]0.03189529851078987
Valid Loss:  0.03092912584543228
Epoch:  215  	Training Loss: 0.029015876352787018
Test Loss:  0.03189382702112198
Valid Loss:  0.030927833169698715
Epoch:  216  	Training Loss: 0.029013872146606445
Test Loss:  0.03189235180616379
Valid Loss:  0.030926542356610298
Epoch:  217  	Training Loss: 0.029011866077780724
Test Loss:  0.031890884041786194
Valid Loss:  0.03092525526881218
Epoch:  218  	Training Loss: 0.029009860008955002
Test Loss:  0.031889408826828
Valid Loss:  0.030923962593078613
Epoch:  219  	Training Loss: 0.029007859528064728
Test Loss:  0.03188793733716011
Valid Loss:  0.030922669917345047
Epoch:  220  	Training Loss: 0.029005857184529305
Test Loss:  0.03188646212220192
Valid Loss:  0.03092137537896633
Epoch:  221  	Training Loss: 0.029003847390413284
Test Loss:  0.03188499063253403
Valid Loss:  0.030920078977942467
Epoch:  222  	Training Loss: 0.02900184504687786
Test Loss:  0.03188353776931763
Valid Loss:  0.030918806791305542
Epoch:  223  	Training Loss: 0.02899988368153572
Test Loss:  0.031882088631391525
Valid Loss:  0.030917543917894363
Epoch:  224  	Training Loss: 0.028997914865612984
Test Loss:  0.03188063204288483
Valid Loss:  0.030916262418031693
Epoch:  225  	Training Loss: 0.028995949774980545
Test Loss:  0.031879182904958725
Valid Loss:  0.030914990231394768
Epoch:  226  	Training Loss: 0.028993982821702957
Test Loss:  0.031877726316452026
Valid Loss:  0.030913716182112694
Epoch:  227  	Training Loss: 0.028992019593715668
Test Loss:  0.031876277178525925
Valid Loss:  0.03091244399547577
Epoch:  228  	Training Loss: 0.02899005636572838
Test Loss:  0.03187483176589012
Valid Loss:  0.030911177396774292
Epoch:  229  	Training Loss: 0.028988098725676537
Test Loss:  0.03187338262796402
Valid Loss:  0.030909903347492218
Epoch:  230  	Training Loss: 0.028986137360334396
Test Loss:  0.03187193349003792
Valid Loss:  0.030908629298210144
Epoch:  231  	Training Loss: 0.028984177857637405
Test Loss:  0.031870484352111816
Valid Loss:  0.03090735524892807
Epoch:  232  	Training Loss: 0.028982222080230713
Test Loss:  0.03186902031302452
Valid Loss:  0.0309060700237751
Epoch:  233  	Training Loss: 0.028980232775211334
Test Loss:  0.031867556273937225
Valid Loss:  0.03090479038655758
Epoch:  234  	Training Loss: 0.028978247195482254
Test Loss:  0.03186609596014023
Valid Loss:  0.03090350702404976
Epoch:  235  	Training Loss: 0.028976265341043472
Test Loss:  0.03186463564634323
Valid Loss:  0.030902225524187088
Epoch:  236  	Training Loss: 0.02897428348660469
Test Loss:  0.031863171607255936
Valid Loss:  0.030900944024324417
Epoch:  237  	Training Loss: 0.028972303494811058
Test Loss:  0.03186171501874924
Valid Loss:  0.030899658799171448
Epoch:  238  	Training Loss: 0.028970325365662575
Test Loss:  0.03186025470495224
Valid Loss:  0.030898377299308777
Epoch:  239  	Training Loss: 0.028968343511223793
Test Loss:  0.031858786940574646
Valid Loss:  0.030897095799446106
Epoch:  240  	Training Loss: 0.02896636351943016
Test Loss:  0.03185732662677765
Valid Loss:  0.030895806849002838
Epoch:  241  	Training Loss: 0.028964385390281677
Test Loss:  0.03185586631298065
Valid Loss:  0.030894525349140167
Epoch:  242  	Training Loss: 0.028962405398488045
Test Loss:  0.031854405999183655
Valid Loss:  0.030893240123987198
Epoch:  243  	Training Loss: 0.028960417956113815
Test Loss:  0.03185294196009636
Valid Loss:  0.03089195489883423
Epoch:  244  	Training Loss: 0.028958428651094437
Test Loss:  0.03185148164629936
Valid Loss:  0.03089066967368126
Epoch:  245  	Training Loss: 0.028956444934010506
Test Loss:  0.03185001760721207
Valid Loss:  0.03088938631117344
Epoch:  246  	Training Loss: 0.028954455628991127
Test Loss:  0.03184854984283447
Valid Loss:  0.03088810108602047
Epoch:  247  	Training Loss: 0.028952471911907196
Test Loss:  0.031847089529037476
Valid Loss:  0.03088681399822235
Epoch:  248  	Training Loss: 0.028950482606887817
Test Loss:  0.03184562176465988
Valid Loss:  0.030885521322488785
Epoch:  249  	Training Loss: 0.028948495164513588
Test Loss:  0.031844157725572586
Valid Loss:  0.030884239822626114
Epoch:  250  	Training Loss: 0.028946509584784508
Test Loss:  0.03184270113706589
Valid Loss:  0.030882949009537697
Epoch:  251  	Training Loss: 0.02894452214241028
Test Loss:  0.03184123337268829
Valid Loss:  0.03088166005909443
Epoch:  252  	Training Loss: 0.028942540287971497
Test Loss:  0.0318397656083107
Valid Loss:  0.030880367383360863
Epoch:  253  	Training Loss: 0.028940558433532715
Test Loss:  0.031838297843933105
Valid Loss:  0.030879070982336998
Epoch:  254  	Training Loss: 0.028938576579093933
Test Loss:  0.03183683007955551
Valid Loss:  0.030877774581313133
Epoch:  255  	Training Loss: 0.02893659472465515
Test Loss:  0.03183536231517792
Valid Loss:  0.030876480042934418
Epoch:  256  	Training Loss: 0.02893461287021637
Test Loss:  0.031833890825510025
Valid Loss:  0.030875179916620255
Epoch:  257  	Training Loss: 0.028932631015777588
Test Loss:  0.03183241933584213
Valid Loss:  0.030873887240886688
Epoch:  258  	Training Loss: 0.028930649161338806
Test Loss:  0.03183095157146454
Valid Loss:  0.030872579663991928
Epoch:  259  	Training Loss: 0.028928667306900024
Test Loss:  0.031829480081796646
Valid Loss:  0.030871279537677765
Epoch:  260  	Training Loss: 0.028926685452461243
Test Loss:  0.03182801231741905
Valid Loss:  0.0308699831366539
Epoch:  261  	Training Loss: 0.02892470359802246
Test Loss:  0.03182654082775116
Valid Loss:  0.03086867928504944
Epoch:  262  	Training Loss: 0.028922725468873978
Test Loss:  0.03182510286569595
Valid Loss:  0.03086741268634796
Epoch:  263  	Training Loss: 0.028920775279402733
Test Loss:  0.031823694705963135
Valid Loss:  0.03086620382964611
Epoch:  264  	Training Loss: 0.028918828815221786
Test Loss:  0.03182224929332733
Valid Loss:  0.030864933505654335
Epoch:  265  	Training Loss: 0.02891688048839569
Test Loss:  0.03182084858417511
Valid Loss:  0.03086373209953308
Epoch:  266  	Training Loss: 0.028914937749505043
Test Loss:  0.031819406896829605
Valid Loss:  0.030862461775541306
Epoch:  267  	Training Loss: 0.028912991285324097
Test Loss:  0.031817998737096786
Valid Loss:  0.030861254781484604
Epoch:  268  	Training Loss: 0.028911042958498
Test Loss:  0.03181656077504158
Valid Loss:  0.03085998445749283
Epoch:  269  	Training Loss: 0.028909102082252502
Test Loss:  0.03181515261530876
Valid Loss:  0.03085877001285553
Epoch:  270  	Training Loss: 0.028907157480716705
Test Loss:  0.031813714653253555
Valid Loss:  0.030857499688863754
Epoch:  271  	Training Loss: 0.02890521101653576
Test Loss:  0.031812310218811035
Valid Loss:  0.030856288969516754
Epoch:  272  	Training Loss: 0.02890327200293541
Test Loss:  0.03181082755327225
Valid Loss:  0.030854975804686546
Epoch:  273  	Training Loss: 0.028901303187012672
Test Loss:  0.031809378415346146
Valid Loss:  0.030853718519210815
Epoch:  274  	Training Loss: 0.028899334371089935
Test Loss:  0.03180789574980736
Valid Loss:  0.030852405354380608
Epoch:  275  	Training Loss: 0.028897369280457497
Test Loss:  0.031806450337171555
Valid Loss:  0.030851151794195175
Epoch:  276  	Training Loss: 0.028895407915115356
Test Loss:  0.031804971396923065
Valid Loss:  0.030849836766719818
Epoch:  277  	Training Loss: 0.02889344096183777
Test Loss:  0.03180352598428726
Valid Loss:  0.030848577618598938
Epoch:  278  	Training Loss: 0.028891481459140778
Test Loss:  0.03180208429694176
Valid Loss:  0.030847325921058655
Epoch:  279  	Training Loss: 0.028889518231153488
Test Loss:  0.03180060535669327
Valid Loss:  0.03084600903093815
Epoch:  280  	Training Loss: 0.028887556865811348
Test Loss:  0.031799159944057465
Valid Loss:  0.030844755470752716
Epoch:  281  	Training Loss: 0.028885599225759506
Test Loss:  0.031797681003808975
Valid Loss:  0.03084343858063221
Epoch:  282  	Training Loss: 0.028883639723062515
Test Loss:  0.031796276569366455
Valid Loss:  0.030842222273349762
Epoch:  283  	Training Loss: 0.028881704434752464
Test Loss:  0.031794868409633636
Valid Loss:  0.030841005966067314
Epoch:  284  	Training Loss: 0.028879769146442413
Test Loss:  0.03179342299699783
Valid Loss:  0.03083973005414009
 57%|█████▋    | 285/500 [03:21<02:14,  1.60it/s] 57%|█████▋    | 287/500 [03:21<01:37,  2.18it/s] 58%|█████▊    | 289/500 [03:22<01:11,  2.94it/s] 58%|█████▊    | 291/500 [03:28<04:08,  1.19s/it] 59%|█████▊    | 293/500 [03:28<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:28<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:28<01:31,  2.21it/s] 60%|█████▉    | 299/500 [03:28<01:07,  2.97it/s] 60%|██████    | 301/500 [03:35<03:57,  1.19s/it] 61%|██████    | 303/500 [03:35<02:48,  1.17it/s] 61%|██████    | 305/500 [03:35<02:01,  1.61it/s] 61%|██████▏   | 307/500 [03:35<01:27,  2.20it/s] 62%|██████▏   | 309/500 [03:35<01:04,  2.96it/s] 62%|██████▏   | 311/500 [03:42<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:42<02:40,  1.17it/s] 63%|██████▎   | 315/500 [03:42<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:42<01:22,  2.21it/s] 64%|██████▍   | 319/500 [03:42<01:00,  2.97it/s] 64%|██████▍   | 321/500 [03:49<03:32,  1.19s/it] 65%|██████▍   | 323/500 [03:49<02:30,  1.17it/s] 65%|██████▌   | 325/500 [03:49<01:48,  1.61it/s] 65%|██████▌   | 327/500 [03:49<01:19,  2.17it/s] 66%|██████▌   | 329/500 [03:49<00:59,  2.88it/s] 66%|██████▌   | 331/500 [03:56<03:21,  1.19s/it] 67%|██████▋   | 333/500 [03:56<02:23,  1.17it/s] 67%|██████▋   | 335/500 [03:56<01:42,  1.61it/s] 67%|██████▋   | 337/500 [03:56<01:13,  2.20it/s] 68%|██████▊   | 339/500 [03:56<00:54,  2.97it/s] 68%|██████▊   | 341/500 [04:03<03:13,  1.22s/it] 69%|██████▊   | 343/500 [04:03<02:17,  1.15it/s] 69%|██████▉   | 345/500 [04:03<01:38,  1.57it/s] 69%|██████▉   | 347/500 [04:03<01:12,  2.12it/s] 70%|██████▉   | 349/500 [04:03<00:53,  2.82it/s] 70%|███████   | 351/500 [04:10<03:01,  1.22s/it] 71%|███████   | 353/500 [04:10<02:08,  1.14it/s]Epoch:  285  	Training Loss: 0.028877831995487213
Test Loss:  0.03179201856255531
Valid Loss:  0.030838513746857643
Epoch:  286  	Training Loss: 0.028875896707177162
Test Loss:  0.031790610402822495
Valid Loss:  0.030837297439575195
Epoch:  287  	Training Loss: 0.02887396514415741
Test Loss:  0.03178917616605759
Valid Loss:  0.030836017802357674
Epoch:  288  	Training Loss: 0.02887202985584736
Test Loss:  0.031787771731615067
Valid Loss:  0.030834801495075226
Epoch:  289  	Training Loss: 0.028870096430182457
Test Loss:  0.03178635984659195
Valid Loss:  0.03083358332514763
Epoch:  290  	Training Loss: 0.028868163004517555
Test Loss:  0.031784918159246445
Valid Loss:  0.030832305550575256
Epoch:  291  	Training Loss: 0.028866231441497803
Test Loss:  0.031783513724803925
Valid Loss:  0.03083108738064766
Epoch:  292  	Training Loss: 0.02886429987847805
Test Loss:  0.031782116740942
Valid Loss:  0.03082987666130066
Epoch:  293  	Training Loss: 0.028862368315458298
Test Loss:  0.03178071230649948
Valid Loss:  0.03082866594195366
Epoch:  294  	Training Loss: 0.028860442340373993
Test Loss:  0.03177927806973457
Valid Loss:  0.030827391892671585
Epoch:  295  	Training Loss: 0.02885851263999939
Test Loss:  0.03177788108587265
Valid Loss:  0.030826181173324585
Epoch:  296  	Training Loss: 0.028856582939624786
Test Loss:  0.03177647665143013
Valid Loss:  0.030824963003396988
Epoch:  297  	Training Loss: 0.02885465696454048
Test Loss:  0.03177507966756821
Valid Loss:  0.030823752284049988
Epoch:  298  	Training Loss: 0.028852730989456177
Test Loss:  0.0317736491560936
Valid Loss:  0.03082248568534851
Epoch:  299  	Training Loss: 0.028850805014371872
Test Loss:  0.031772252172231674
Valid Loss:  0.030821263790130615
Epoch:  300  	Training Loss: 0.028848877176642418
Test Loss:  0.03177085146307945
Valid Loss:  0.030820049345493317
Epoch:  301  	Training Loss: 0.028846953064203262
Test Loss:  0.03176945447921753
Valid Loss:  0.030818838626146317
Epoch:  302  	Training Loss: 0.028845030814409256
Test Loss:  0.031768012791872025
Valid Loss:  0.030817575752735138
Epoch:  303  	Training Loss: 0.028843071311712265
Test Loss:  0.031766533851623535
Valid Loss:  0.030816256999969482
Epoch:  304  	Training Loss: 0.028841111809015274
Test Loss:  0.03176509588956833
Valid Loss:  0.030814994126558304
Epoch:  305  	Training Loss: 0.028839150443673134
Test Loss:  0.031763650476932526
Valid Loss:  0.030813734978437424
Epoch:  306  	Training Loss: 0.028837190940976143
Test Loss:  0.03176220506429672
Valid Loss:  0.030812475830316544
Epoch:  307  	Training Loss: 0.028835231438279152
Test Loss:  0.03176076337695122
Valid Loss:  0.030811212956905365
Epoch:  308  	Training Loss: 0.02883327379822731
Test Loss:  0.03175932168960571
Valid Loss:  0.030809950083494186
Epoch:  309  	Training Loss: 0.02883131429553032
Test Loss:  0.03175788000226021
Valid Loss:  0.03080868348479271
Epoch:  310  	Training Loss: 0.028829358518123627
Test Loss:  0.03175640106201172
Valid Loss:  0.030807362869381905
Epoch:  311  	Training Loss: 0.028827404603362083
Test Loss:  0.03175496682524681
Valid Loss:  0.030806107446551323
Epoch:  312  	Training Loss: 0.02882545255124569
Test Loss:  0.0317535474896431
Valid Loss:  0.030804861336946487
Epoch:  313  	Training Loss: 0.028823524713516235
Test Loss:  0.031752120703458786
Valid Loss:  0.030803609639406204
Epoch:  314  	Training Loss: 0.02882159687578678
Test Loss:  0.031750697642564774
Valid Loss:  0.03080236352980137
Epoch:  315  	Training Loss: 0.028819672763347626
Test Loss:  0.03174927458167076
Valid Loss:  0.030801117420196533
Epoch:  316  	Training Loss: 0.02881774678826332
Test Loss:  0.03174785524606705
Valid Loss:  0.030799873173236847
Epoch:  317  	Training Loss: 0.028815824538469315
Test Loss:  0.03174643591046333
Valid Loss:  0.030798623338341713
Epoch:  318  	Training Loss: 0.02881390042603016
Test Loss:  0.03174501284956932
Valid Loss:  0.030797377228736877
Epoch:  319  	Training Loss: 0.028811978176236153
Test Loss:  0.03174358978867531
Valid Loss:  0.030796129256486893
Epoch:  320  	Training Loss: 0.028810055926442146
Test Loss:  0.031742170453071594
Valid Loss:  0.030794883146882057
Epoch:  321  	Training Loss: 0.02880813367664814
Test Loss:  0.03174075111746788
Valid Loss:  0.030793635174632072
Epoch:  322  	Training Loss: 0.028806213289499283
Test Loss:  0.03173932433128357
Valid Loss:  0.03079237788915634
Epoch:  323  	Training Loss: 0.028804291039705276
Test Loss:  0.03173789381980896
Valid Loss:  0.03079112246632576
Epoch:  324  	Training Loss: 0.028802363201975822
Test Loss:  0.03173646330833435
Valid Loss:  0.030789868906140327
Epoch:  325  	Training Loss: 0.028800437226891518
Test Loss:  0.03173503652215004
Valid Loss:  0.030788607895374298
Epoch:  326  	Training Loss: 0.028798513114452362
Test Loss:  0.03173360228538513
Valid Loss:  0.030787348747253418
Epoch:  327  	Training Loss: 0.028796590864658356
Test Loss:  0.03173217922449112
Valid Loss:  0.030786093324422836
Epoch:  328  	Training Loss: 0.0287946667522192
Test Loss:  0.03173074498772621
Valid Loss:  0.030784836038947105
Epoch:  329  	Training Loss: 0.028792744502425194
Test Loss:  0.0317293144762516
Valid Loss:  0.030783575028181076
Epoch:  330  	Training Loss: 0.028790822252631187
Test Loss:  0.03172788769006729
Valid Loss:  0.030782315880060196
Epoch:  331  	Training Loss: 0.02878890186548233
Test Loss:  0.03172645345330238
Valid Loss:  0.030781056731939316
Epoch:  332  	Training Loss: 0.028786979615688324
Test Loss:  0.031725045293569565
Valid Loss:  0.03077981434762478
Epoch:  333  	Training Loss: 0.028785061091184616
Test Loss:  0.031723637133836746
Valid Loss:  0.03077857941389084
Epoch:  334  	Training Loss: 0.028783151879906654
Test Loss:  0.03172222524881363
Valid Loss:  0.030777333304286003
Epoch:  335  	Training Loss: 0.028781235218048096
Test Loss:  0.031720809638500214
Valid Loss:  0.030776087194681168
Epoch:  336  	Training Loss: 0.028779322281479836
Test Loss:  0.0317193940281868
Valid Loss:  0.03077484667301178
Epoch:  337  	Training Loss: 0.028777409344911575
Test Loss:  0.03171798586845398
Valid Loss:  0.030773606151342392
Epoch:  338  	Training Loss: 0.028775494545698166
Test Loss:  0.03171657770872116
Valid Loss:  0.030772369354963303
Epoch:  339  	Training Loss: 0.028773589059710503
Test Loss:  0.031715165823698044
Valid Loss:  0.030771125108003616
Epoch:  340  	Training Loss: 0.028771676123142242
Test Loss:  0.03171375393867493
Valid Loss:  0.03076987713575363
Epoch:  341  	Training Loss: 0.02876976504921913
Test Loss:  0.03171233832836151
Valid Loss:  0.030768631026148796
Epoch:  342  	Training Loss: 0.02876785397529602
Test Loss:  0.03171093016862869
Valid Loss:  0.030767390504479408
Epoch:  343  	Training Loss: 0.0287659652531147
Test Loss:  0.03170952945947647
Valid Loss:  0.03076614998281002
Epoch:  344  	Training Loss: 0.02876407653093338
Test Loss:  0.03170812129974365
Valid Loss:  0.030764903873205185
Epoch:  345  	Training Loss: 0.02876218967139721
Test Loss:  0.03170671686530113
Valid Loss:  0.030763667076826096
Epoch:  346  	Training Loss: 0.028760302811861038
Test Loss:  0.03170531243085861
Valid Loss:  0.03076242469251156
Epoch:  347  	Training Loss: 0.028758417814970016
Test Loss:  0.03170390799641609
Valid Loss:  0.03076118417084217
Epoch:  348  	Training Loss: 0.028756534680724144
Test Loss:  0.03170250728726387
Valid Loss:  0.030759941786527634
Epoch:  349  	Training Loss: 0.02875465154647827
Test Loss:  0.03170110285282135
Valid Loss:  0.030758701264858246
Epoch:  350  	Training Loss: 0.028752770274877548
Test Loss:  0.03169970214366913
Valid Loss:  0.03075745701789856
Epoch:  351  	Training Loss: 0.028750883415341377
Test Loss:  0.03169829398393631
Valid Loss:  0.030756212770938873
Epoch:  352  	Training Loss: 0.028749004006385803
Test Loss:  0.031696874648332596
Valid Loss:  0.03075496107339859
Epoch:  353  	Training Loss: 0.028747089207172394
Test Loss:  0.031695447862148285
Valid Loss:  0.03075370192527771
Epoch:  354  	Training Loss: 0.028745172545313835
Test Loss:  0.031694017350673676
Valid Loss:  0.030752431601285934
Epoch:  355  	Training Loss: 0.028743255883455276
Test Loss:  0.03169259428977966
Valid Loss:   71%|███████   | 355/500 [04:10<01:31,  1.58it/s] 71%|███████▏  | 357/500 [04:10<01:06,  2.16it/s] 72%|███████▏  | 359/500 [04:10<00:48,  2.91it/s] 72%|███████▏  | 361/500 [04:17<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:17<01:57,  1.17it/s] 73%|███████▎  | 365/500 [04:17<01:23,  1.61it/s] 73%|███████▎  | 367/500 [04:17<01:00,  2.20it/s] 74%|███████▍  | 369/500 [04:17<00:44,  2.96it/s] 74%|███████▍  | 371/500 [04:24<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:24<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:24<01:17,  1.62it/s] 75%|███████▌  | 377/500 [04:24<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:24<00:40,  2.97it/s] 76%|███████▌  | 381/500 [04:31<02:22,  1.19s/it] 77%|███████▋  | 383/500 [04:31<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:31<01:11,  1.60it/s] 77%|███████▋  | 387/500 [04:31<00:51,  2.18it/s] 78%|███████▊  | 389/500 [04:31<00:38,  2.92it/s] 78%|███████▊  | 391/500 [04:38<02:11,  1.20s/it] 79%|███████▊  | 393/500 [04:38<01:32,  1.15it/s] 79%|███████▉  | 395/500 [04:38<01:06,  1.58it/s] 79%|███████▉  | 397/500 [04:38<00:47,  2.16it/s] 80%|███████▉  | 399/500 [04:38<00:34,  2.90it/s] 80%|████████  | 401/500 [04:44<01:57,  1.19s/it] 81%|████████  | 403/500 [04:45<01:22,  1.17it/s] 81%|████████  | 405/500 [04:45<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:45<00:41,  2.22it/s] 82%|████████▏ | 409/500 [04:45<00:30,  2.97it/s] 82%|████████▏ | 411/500 [04:51<01:46,  1.20s/it] 83%|████████▎ | 413/500 [04:52<01:14,  1.16it/s] 83%|████████▎ | 415/500 [04:52<00:52,  1.61it/s] 83%|████████▎ | 417/500 [04:52<00:37,  2.19it/s] 84%|████████▍ | 419/500 [04:52<00:27,  2.95it/s] 84%|████████▍ | 421/500 [04:58<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:58<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:59<00:45,  1.63it/s]0.030751176178455353
Epoch:  356  	Training Loss: 0.028741341084241867
Test Loss:  0.03169116750359535
Valid Loss:  0.030749917030334473
Epoch:  357  	Training Loss: 0.028739430010318756
Test Loss:  0.03168974816799164
Valid Loss:  0.030748656019568443
Epoch:  358  	Training Loss: 0.028737517073750496
Test Loss:  0.03168832138180733
Valid Loss:  0.030747395008802414
Epoch:  359  	Training Loss: 0.028735604137182236
Test Loss:  0.03168690204620361
Valid Loss:  0.030746135860681534
Epoch:  360  	Training Loss: 0.028733696788549423
Test Loss:  0.0316854789853096
Valid Loss:  0.030744871124625206
Epoch:  361  	Training Loss: 0.028731783851981163
Test Loss:  0.03168405592441559
Valid Loss:  0.030743615701794624
Epoch:  362  	Training Loss: 0.0287298746407032
Test Loss:  0.03168270364403725
Valid Loss:  0.030742421746253967
Epoch:  363  	Training Loss: 0.028728019446134567
Test Loss:  0.03168134391307831
Valid Loss:  0.03074122779071331
Epoch:  364  	Training Loss: 0.028726164251565933
Test Loss:  0.03167998418211937
Valid Loss:  0.030740024521946907
Epoch:  365  	Training Loss: 0.02872431091964245
Test Loss:  0.03167862817645073
Valid Loss:  0.03073883429169655
Epoch:  366  	Training Loss: 0.028722457587718964
Test Loss:  0.03167726472020149
Valid Loss:  0.030737638473510742
Epoch:  367  	Training Loss: 0.02872060239315033
Test Loss:  0.031675904989242554
Valid Loss:  0.030736438930034637
Epoch:  368  	Training Loss: 0.028718747198581696
Test Loss:  0.031674548983573914
Valid Loss:  0.03073524311184883
Epoch:  369  	Training Loss: 0.02871689386665821
Test Loss:  0.03167319297790527
Valid Loss:  0.030734049156308174
Epoch:  370  	Training Loss: 0.028715042397379875
Test Loss:  0.03167183697223663
Valid Loss:  0.03073284775018692
Epoch:  371  	Training Loss: 0.02871319279074669
Test Loss:  0.03167048096656799
Valid Loss:  0.030731651932001114
Epoch:  372  	Training Loss: 0.028711341321468353
Test Loss:  0.03166906535625458
Valid Loss:  0.03073040023446083
Epoch:  373  	Training Loss: 0.028709448873996735
Test Loss:  0.03166765719652176
Valid Loss:  0.030729155987501144
Epoch:  374  	Training Loss: 0.028707556426525116
Test Loss:  0.03166624531149864
Valid Loss:  0.030727902427315712
Epoch:  375  	Training Loss: 0.028705662116408348
Test Loss:  0.031664833426475525
Valid Loss:  0.030726656317710876
Epoch:  376  	Training Loss: 0.02870377153158188
Test Loss:  0.031663425266742706
Valid Loss:  0.03072540834546089
Epoch:  377  	Training Loss: 0.028701884672045708
Test Loss:  0.03166201710700989
Valid Loss:  0.030724158510565758
Epoch:  378  	Training Loss: 0.028699997812509537
Test Loss:  0.03166060894727707
Valid Loss:  0.030722904950380325
Epoch:  379  	Training Loss: 0.028698105365037918
Test Loss:  0.03165920451283455
Valid Loss:  0.03072165511548519
Epoch:  380  	Training Loss: 0.028696216642856598
Test Loss:  0.03165780007839203
Valid Loss:  0.030720405280590057
Epoch:  381  	Training Loss: 0.028694327920675278
Test Loss:  0.03165638446807861
Valid Loss:  0.030719153583049774
Epoch:  382  	Training Loss: 0.028692439198493958
Test Loss:  0.03165499120950699
Valid Loss:  0.030717924237251282
Epoch:  383  	Training Loss: 0.02869056910276413
Test Loss:  0.03165361285209656
Valid Loss:  0.03071669675409794
Epoch:  384  	Training Loss: 0.028688697144389153
Test Loss:  0.03165222331881523
Valid Loss:  0.030715471133589745
Epoch:  385  	Training Loss: 0.028686828911304474
Test Loss:  0.031650837510824203
Valid Loss:  0.030714239925146103
Epoch:  386  	Training Loss: 0.028684962540864944
Test Loss:  0.03164944797754288
Valid Loss:  0.03071300871670246
Epoch:  387  	Training Loss: 0.028683094307780266
Test Loss:  0.031648099422454834
Valid Loss:  0.030711838975548744
Epoch:  388  	Training Loss: 0.028681227937340736
Test Loss:  0.031646713614463806
Valid Loss:  0.030710607767105103
Epoch:  389  	Training Loss: 0.028679363429546356
Test Loss:  0.031645357608795166
Valid Loss:  0.030709441751241684
Epoch:  390  	Training Loss: 0.028677495196461678
Test Loss:  0.03164397552609444
Valid Loss:  0.030708206817507744
Epoch:  391  	Training Loss: 0.028675630688667297
Test Loss:  0.031642623245716095
Valid Loss:  0.030707038938999176
Epoch:  392  	Training Loss: 0.028673766180872917
Test Loss:  0.031641244888305664
Valid Loss:  0.03070581890642643
Epoch:  393  	Training Loss: 0.028671901673078537
Test Loss:  0.0316399410367012
Valid Loss:  0.030704721808433533
Epoch:  394  	Training Loss: 0.028670039027929306
Test Loss:  0.031638555228710175
Valid Loss:  0.030703501775860786
Epoch:  395  	Training Loss: 0.028668174520134926
Test Loss:  0.03163718432188034
Valid Loss:  0.03070228360593319
Epoch:  396  	Training Loss: 0.028666313737630844
Test Loss:  0.0316358357667923
Valid Loss:  0.03070111945271492
Epoch:  397  	Training Loss: 0.028664443641901016
Test Loss:  0.03163449093699455
Valid Loss:  0.0306999534368515
Epoch:  398  	Training Loss: 0.028662577271461487
Test Loss:  0.03163311257958412
Valid Loss:  0.030698735266923904
Epoch:  399  	Training Loss: 0.028660712763667107
Test Loss:  0.03163176774978638
Valid Loss:  0.030697569251060486
Epoch:  400  	Training Loss: 0.028658851981163025
Test Loss:  0.03163042664527893
Valid Loss:  0.030696406960487366
Epoch:  401  	Training Loss: 0.028656985610723495
Test Loss:  0.0316290408372879
Valid Loss:  0.03069518320262432
Epoch:  402  	Training Loss: 0.028655124828219414
Test Loss:  0.03162764757871628
Valid Loss:  0.030693966895341873
Epoch:  403  	Training Loss: 0.028653230518102646
Test Loss:  0.031626250594854355
Valid Loss:  0.03069274127483368
Epoch:  404  	Training Loss: 0.028651341795921326
Test Loss:  0.03162481635808945
Valid Loss:  0.03069145977497101
Epoch:  405  	Training Loss: 0.028649453073740005
Test Loss:  0.03162342682480812
Valid Loss:  0.03069024719297886
Epoch:  406  	Training Loss: 0.028647562488913536
Test Loss:  0.0316220261156559
Valid Loss:  0.030689023435115814
Epoch:  407  	Training Loss: 0.028645671904087067
Test Loss:  0.03162059187889099
Valid Loss:  0.030687743797898293
Epoch:  408  	Training Loss: 0.028643783181905746
Test Loss:  0.031619228422641754
Valid Loss:  0.03068658336997032
Epoch:  409  	Training Loss: 0.028641896322369576
Test Loss:  0.03161780163645744
Valid Loss:  0.0306853000074625
Epoch:  410  	Training Loss: 0.028640005737543106
Test Loss:  0.03161640465259552
Valid Loss:  0.030684081837534904
Epoch:  411  	Training Loss: 0.028638118878006935
Test Loss:  0.03161497414112091
Valid Loss:  0.030682794749736786
Epoch:  412  	Training Loss: 0.028636233881115913
Test Loss:  0.03161364421248436
Valid Loss:  0.03068166971206665
Epoch:  413  	Training Loss: 0.02863437682390213
Test Loss:  0.031612250953912735
Valid Loss:  0.030680421739816666
Epoch:  414  	Training Loss: 0.028632521629333496
Test Loss:  0.031610891222953796
Valid Loss:  0.030679237097501755
Epoch:  415  	Training Loss: 0.028630666434764862
Test Loss:  0.03160952776670456
Valid Loss:  0.030678045004606247
Epoch:  416  	Training Loss: 0.02862880565226078
Test Loss:  0.03160812705755234
Valid Loss:  0.030676795169711113
Epoch:  417  	Training Loss: 0.028626954182982445
Test Loss:  0.031606804579496384
Valid Loss:  0.030675671994686127
Epoch:  418  	Training Loss: 0.02862510085105896
Test Loss:  0.03160541132092476
Valid Loss:  0.030674420297145844
Epoch:  419  	Training Loss: 0.028623245656490326
Test Loss:  0.03160404413938522
Valid Loss:  0.030673224478960037
Epoch:  420  	Training Loss: 0.028621390461921692
Test Loss:  0.03160268813371658
Valid Loss:  0.030672039836645126
Epoch:  421  	Training Loss: 0.028619538992643356
Test Loss:  0.031601328402757645
Valid Loss:  0.030670853331685066
Epoch:  422  	Training Loss: 0.02861768752336502
Test Loss:  0.031599972397089005
Valid Loss:  0.030669663101434708
Epoch:  423  	Training Loss: 0.028615837916731834
Test Loss:  0.03159857913851738
Valid Loss:  0.030668416991829872
Epoch:  424  	Training Loss: 0.028613992035388947
Test Loss:  0.03159725293517113
Valid Loss:  0.030667288228869438
Epoch:  425  	Training Loss: 0.02861214429140091
Test Loss:  0.0315958634018898
Valid Loss:  0.030666040256619453
Epoch:  426  	Training Loss: 0.028610296547412872
Test Loss:   85%|████████▌ | 427/500 [04:59<00:32,  2.23it/s] 86%|████████▌ | 429/500 [04:59<00:23,  2.98it/s] 86%|████████▌ | 431/500 [05:05<01:22,  1.20s/it] 87%|████████▋ | 433/500 [05:05<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:06<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:06<00:28,  2.20it/s] 88%|████████▊ | 439/500 [05:06<00:20,  2.95it/s] 88%|████████▊ | 441/500 [05:12<01:09,  1.19s/it] 89%|████████▊ | 443/500 [05:12<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:12<00:34,  1.62it/s] 89%|████████▉ | 447/500 [05:13<00:24,  2.21it/s] 90%|████████▉ | 449/500 [05:13<00:17,  2.97it/s] 90%|█████████ | 451/500 [05:19<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:19<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:19<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:19<00:19,  2.25it/s] 92%|█████████▏| 459/500 [05:19<00:13,  3.02it/s] 92%|█████████▏| 461/500 [05:26<00:46,  1.20s/it] 93%|█████████▎| 463/500 [05:26<00:31,  1.16it/s] 93%|█████████▎| 465/500 [05:26<00:21,  1.60it/s] 93%|█████████▎| 467/500 [05:26<00:15,  2.19it/s] 94%|█████████▍| 469/500 [05:26<00:10,  2.95it/s] 94%|█████████▍| 471/500 [05:33<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:33<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:33<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:33<00:10,  2.21it/s] 96%|█████████▌| 479/500 [05:33<00:07,  2.98it/s] 96%|█████████▌| 481/500 [05:40<00:22,  1.21s/it] 97%|█████████▋| 483/500 [05:40<00:14,  1.15it/s] 97%|█████████▋| 485/500 [05:40<00:09,  1.60it/s] 97%|█████████▋| 487/500 [05:40<00:05,  2.18it/s] 98%|█████████▊| 489/500 [05:40<00:03,  2.94it/s] 98%|█████████▊| 491/500 [05:47<00:10,  1.21s/it] 99%|█████████▊| 493/500 [05:47<00:06,  1.15it/s] 99%|█████████▉| 495/500 [05:47<00:03,  1.59it/s]0.03159454092383385
Valid Loss:  0.030664915218949318
Epoch:  427  	Training Loss: 0.028608450666069984
Test Loss:  0.031593143939971924
Valid Loss:  0.030663656070828438
Epoch:  428  	Training Loss: 0.028606601059436798
Test Loss:  0.031591787934303284
Valid Loss:  0.030662473291158676
Epoch:  429  	Training Loss: 0.02860475331544876
Test Loss:  0.03159042447805405
Valid Loss:  0.03066128119826317
Epoch:  430  	Training Loss: 0.02860291115939617
Test Loss:  0.031589068472385406
Valid Loss:  0.030660096555948257
Epoch:  431  	Training Loss: 0.028601067140698433
Test Loss:  0.031587716192007065
Valid Loss:  0.030658908188343048
Epoch:  432  	Training Loss: 0.028599224984645844
Test Loss:  0.03158634901046753
Valid Loss:  0.03065771609544754
Epoch:  433  	Training Loss: 0.028597354888916016
Test Loss:  0.0315849743783474
Valid Loss:  0.030656520277261734
Epoch:  434  	Training Loss: 0.028595486655831337
Test Loss:  0.03158361464738846
Valid Loss:  0.030655324459075928
Epoch:  435  	Training Loss: 0.02859361469745636
Test Loss:  0.03158224746584892
Valid Loss:  0.03065413050353527
Epoch:  436  	Training Loss: 0.02859174832701683
Test Loss:  0.03158087655901909
Valid Loss:  0.030652932822704315
Epoch:  437  	Training Loss: 0.028589880093932152
Test Loss:  0.03157950937747955
Valid Loss:  0.03065173514187336
Epoch:  438  	Training Loss: 0.028588011860847473
Test Loss:  0.03157813847064972
Valid Loss:  0.030650533735752106
Epoch:  439  	Training Loss: 0.028586136177182198
Test Loss:  0.03157677501440048
Valid Loss:  0.03064933605492115
Epoch:  440  	Training Loss: 0.028584271669387817
Test Loss:  0.03157540038228035
Valid Loss:  0.030648138374090195
Epoch:  441  	Training Loss: 0.028582405298948288
Test Loss:  0.03157403692603111
Valid Loss:  0.03064693883061409
Epoch:  442  	Training Loss: 0.02858053892850876
Test Loss:  0.031572796404361725
Valid Loss:  0.030645867809653282
Epoch:  443  	Training Loss: 0.028578784316778183
Test Loss:  0.031571563333272934
Valid Loss:  0.03064480796456337
Epoch:  444  	Training Loss: 0.028577037155628204
Test Loss:  0.031570326536893845
Valid Loss:  0.030643735080957413
Epoch:  445  	Training Loss: 0.02857528254389763
Test Loss:  0.03156912699341774
Valid Loss:  0.030642729252576828
Epoch:  446  	Training Loss: 0.02857353165745735
Test Loss:  0.031567856669425964
Valid Loss:  0.030641602352261543
Epoch:  447  	Training Loss: 0.028571784496307373
Test Loss:  0.03156665340065956
Valid Loss:  0.03064059466123581
Epoch:  448  	Training Loss: 0.028570031747221947
Test Loss:  0.03156537562608719
Valid Loss:  0.030639449134469032
Epoch:  449  	Training Loss: 0.02856828272342682
Test Loss:  0.031564176082611084
Valid Loss:  0.030638447031378746
Epoch:  450  	Training Loss: 0.028566529974341393
Test Loss:  0.031562939286231995
Valid Loss:  0.030637379735708237
Epoch:  451  	Training Loss: 0.028564784675836563
Test Loss:  0.03156169876456261
Valid Loss:  0.030636295676231384
Epoch:  452  	Training Loss: 0.028563030064105988
Test Loss:  0.03156030923128128
Valid Loss:  0.03063507378101349
Epoch:  453  	Training Loss: 0.028561171144247055
Test Loss:  0.031558968126773834
Valid Loss:  0.030633917078375816
Epoch:  454  	Training Loss: 0.028559323400259018
Test Loss:  0.031557537615299225
Valid Loss:  0.0306326262652874
Epoch:  455  	Training Loss: 0.028557464480400085
Test Loss:  0.03155618906021118
Valid Loss:  0.03063146397471428
Epoch:  456  	Training Loss: 0.02855560928583145
Test Loss:  0.03155481070280075
Valid Loss:  0.030630243942141533
Epoch:  457  	Training Loss: 0.028553761541843414
Test Loss:  0.031553421169519424
Valid Loss:  0.03062901645898819
Epoch:  458  	Training Loss: 0.02855190448462963
Test Loss:  0.0315520353615284
Valid Loss:  0.030627787113189697
Epoch:  459  	Training Loss: 0.028550053015351295
Test Loss:  0.03155068680644035
Valid Loss:  0.030626628547906876
Epoch:  460  	Training Loss: 0.02854820340871811
Test Loss:  0.03154930844902992
Valid Loss:  0.03062540292739868
Epoch:  461  	Training Loss: 0.028546351939439774
Test Loss:  0.031547918915748596
Valid Loss:  0.03062417171895504
Epoch:  462  	Training Loss: 0.028544500470161438
Test Loss:  0.03154655918478966
Valid Loss:  0.030622974038124084
Epoch:  463  	Training Loss: 0.028542667627334595
Test Loss:  0.03154522925615311
Valid Loss:  0.030621834099292755
Epoch:  464  	Training Loss: 0.02854083850979805
Test Loss:  0.031543880701065063
Valid Loss:  0.030620630830526352
Epoch:  465  	Training Loss: 0.028539009392261505
Test Loss:  0.031542517244815826
Valid Loss:  0.030619429424405098
Epoch:  466  	Training Loss: 0.02853717841207981
Test Loss:  0.03154115378856659
Valid Loss:  0.030618220567703247
Epoch:  467  	Training Loss: 0.028535349294543266
Test Loss:  0.03153982758522034
Valid Loss:  0.030617082491517067
Epoch:  468  	Training Loss: 0.028533516451716423
Test Loss:  0.0315384678542614
Valid Loss:  0.030615877360105515
Epoch:  469  	Training Loss: 0.028531687334179878
Test Loss:  0.03153710439801216
Valid Loss:  0.03061467409133911
Epoch:  470  	Training Loss: 0.028529860079288483
Test Loss:  0.03153577819466591
Valid Loss:  0.030613532289862633
Epoch:  471  	Training Loss: 0.028528032824397087
Test Loss:  0.03153441473841667
Valid Loss:  0.03061232529580593
Epoch:  472  	Training Loss: 0.028526203706860542
Test Loss:  0.03153304010629654
Valid Loss:  0.030611101537942886
Epoch:  473  	Training Loss: 0.028524354100227356
Test Loss:  0.03153169900178909
Valid Loss:  0.030609946697950363
Epoch:  474  	Training Loss: 0.02852250635623932
Test Loss:  0.03153032064437866
Valid Loss:  0.030608724802732468
Epoch:  475  	Training Loss: 0.028520654886960983
Test Loss:  0.03152894601225853
Valid Loss:  0.03060751035809517
Epoch:  476  	Training Loss: 0.028518807142972946
Test Loss:  0.03152760863304138
Valid Loss:  0.030606355518102646
Epoch:  477  	Training Loss: 0.02851696126163006
Test Loss:  0.03152623027563095
Valid Loss:  0.0306051317602396
Epoch:  478  	Training Loss: 0.028515111654996872
Test Loss:  0.031524889171123505
Valid Loss:  0.030603978782892227
Epoch:  479  	Training Loss: 0.028513267636299133
Test Loss:  0.03152351453900337
Valid Loss:  0.03060275688767433
Epoch:  480  	Training Loss: 0.028511419892311096
Test Loss:  0.03152213990688324
Valid Loss:  0.030601531267166138
Epoch:  481  	Training Loss: 0.02850957214832306
Test Loss:  0.0315207913517952
Valid Loss:  0.030600370839238167
Epoch:  482  	Training Loss: 0.028507722541689873
Test Loss:  0.03151945397257805
Valid Loss:  0.030599188059568405
Epoch:  483  	Training Loss: 0.02850591018795967
Test Loss:  0.031518153846263885
Valid Loss:  0.030598066747188568
Epoch:  484  	Training Loss: 0.02850409969687462
Test Loss:  0.03151681274175644
Valid Loss:  0.03059687465429306
Epoch:  485  	Training Loss: 0.028502287343144417
Test Loss:  0.03151550889015198
Valid Loss:  0.030595751479268074
Epoch:  486  	Training Loss: 0.028500478714704514
Test Loss:  0.03151416778564453
Valid Loss:  0.030594563111662865
Epoch:  487  	Training Loss: 0.028498666360974312
Test Loss:  0.03151286393404007
Valid Loss:  0.03059343993663788
Epoch:  488  	Training Loss: 0.02849685773253441
Test Loss:  0.03151152655482292
Valid Loss:  0.030592255294322968
Epoch:  489  	Training Loss: 0.028495049104094505
Test Loss:  0.03151021897792816
Valid Loss:  0.030591130256652832
Epoch:  490  	Training Loss: 0.028493240475654602
Test Loss:  0.031508881598711014
Valid Loss:  0.030589941889047623
Epoch:  491  	Training Loss: 0.02849142998456955
Test Loss:  0.031507574021816254
Valid Loss:  0.030588818714022636
Epoch:  492  	Training Loss: 0.028489623218774796
Test Loss:  0.03150622919201851
Valid Loss:  0.030587609857320786
Epoch:  493  	Training Loss: 0.02848781645298004
Test Loss:  0.03150491416454315
Valid Loss:  0.030586469918489456
Epoch:  494  	Training Loss: 0.028486013412475586
Test Loss:  0.03150356188416481
Valid Loss:  0.03058527037501335
Epoch:  495  	Training Loss: 0.028484217822551727
Test Loss:  0.03150225058197975
Valid Loss:  0.030584130436182022
Epoch:  496  	Training Loss: 0.02848241664469242
Test Loss:  0.03150089830160141
Valid Loss:  0.03058292344212532
Epoch:  497  	Training Loss: 0.028480615466833115 99%|█████████▉| 497/500 [05:47<00:01,  2.17it/s]100%|█████████▉| 499/500 [05:47<00:00,  2.92it/s]100%|██████████| 500/500 [05:47<00:00,  1.44it/s]

Test Loss:  0.031499579548835754
Valid Loss:  0.030581781640648842
Epoch:  498  	Training Loss: 0.02847881428897381
Test Loss:  0.03149823099374771
Valid Loss:  0.03058057837188244
Epoch:  499  	Training Loss: 0.028477013111114502
Test Loss:  0.03149691969156265
Valid Loss:  0.03057943657040596
Epoch:  500  	Training Loss: 0.028475215658545494
Test Loss:  0.031495600938797
Valid Loss:  0.030578289180994034
seed is  11
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:20,  6.29s/it]  1%|          | 3/500 [00:06<14:02,  1.69s/it]  1%|          | 5/500 [00:06<07:09,  1.15it/s]  1%|▏         | 7/500 [00:06<04:24,  1.87it/s]  2%|▏         | 9/500 [00:06<02:59,  2.73it/s]  2%|▏         | 11/500 [00:13<11:12,  1.37s/it]  3%|▎         | 13/500 [00:13<07:37,  1.06it/s]  3%|▎         | 15/500 [00:20<13:31,  1.67s/it]  3%|▎         | 17/500 [00:20<09:23,  1.17s/it]  4%|▍         | 19/500 [00:20<06:36,  1.21it/s]  4%|▍         | 21/500 [00:26<12:24,  1.55s/it]  5%|▍         | 23/500 [00:26<08:45,  1.10s/it]  5%|▌         | 25/500 [00:26<06:14,  1.27it/s]  5%|▌         | 27/500 [00:27<04:29,  1.76it/s]  6%|▌         | 29/500 [00:27<03:16,  2.39it/s]  6%|▌         | 31/500 [00:33<10:06,  1.29s/it]  7%|▋         | 33/500 [00:34<07:12,  1.08it/s]  7%|▋         | 35/500 [00:34<05:10,  1.50it/s]  7%|▋         | 37/500 [00:34<03:45,  2.05it/s]  8%|▊         | 39/500 [00:34<02:46,  2.77it/s]  8%|▊         | 41/500 [00:40<09:22,  1.23s/it]  9%|▊         | 43/500 [00:41<06:42,  1.14it/s]  9%|▉         | 45/500 [00:41<04:49,  1.57it/s]  9%|▉         | 47/500 [00:41<03:31,  2.14it/s] 10%|▉         | 49/500 [00:41<02:39,  2.83it/s] 10%|█         | 51/500 [00:48<09:08,  1.22s/it] 11%|█         | 53/500 [00:48<06:31,  1.14it/s] 11%|█         | 55/500 [00:48<04:42,  1.58it/s] 11%|█▏        | 57/500 [00:48<03:25,  2.16it/s] 12%|█▏        | 59/500 [00:48<02:31,  2.90it/s] 12%|█▏        | 61/500 [00:54<08:46,  1.20s/it] 13%|█▎        | 63/500 [00:55<06:16,  1.16it/s] 13%|█▎        | 65/500 [00:55<04:31,  1.60it/s] 13%|█▎        | 67/500 [00:55<03:17,  2.19it/s]Epoch:  1  	Training Loss: 0.02847922034561634
Test Loss:  0.02870561182498932
Valid Loss:  0.02685489133000374
Epoch:  2  	Training Loss: 0.03659950569272041
Test Loss:  0.017965370789170265
Valid Loss:  0.017459433525800705
Epoch:  3  	Training Loss: 0.017080165445804596
Test Loss:  0.007003334816545248
Valid Loss:  0.006217620335519314
Epoch:  4  	Training Loss: 0.0092929033562541
Test Loss:  0.005761828273534775
Valid Loss:  0.0057942853309214115
Epoch:  5  	Training Loss: 0.006371393799781799
Test Loss:  0.0031455724965780973
Valid Loss:  0.002811484271660447
Epoch:  6  	Training Loss: 0.004666042514145374
Test Loss:  0.002729646395891905
Valid Loss:  0.0028212545439600945
Epoch:  7  	Training Loss: 0.0034830602817237377
Test Loss:  0.0018496210686862469
Valid Loss:  0.0017773129511624575
Epoch:  8  	Training Loss: 0.0027959365397691727
Test Loss:  0.0016996071208268404
Valid Loss:  0.0017808745615184307
Epoch:  9  	Training Loss: 0.002358984900638461
Test Loss:  0.0014043832197785378
Valid Loss:  0.0014540567062795162
Epoch:  10  	Training Loss: 0.0020736982114613056
Test Loss:  0.0013199703535065055
Valid Loss:  0.001422741450369358
Epoch:  11  	Training Loss: 0.0018706027185544372
Test Loss:  0.0011905173305422068
Valid Loss:  0.0012982434127479792
Epoch:  12  	Training Loss: 0.0017164715100079775
Test Loss:  0.001536682015284896
Valid Loss:  0.0017112214118242264
Epoch:  13  	Training Loss: 0.001897740177810192
Test Loss:  0.0031426751520484686
Valid Loss:  0.0031212347093969584
Epoch:  14  	Training Loss: 0.0042364709079265594
Test Loss:  0.015427791513502598
Valid Loss:  0.01621917076408863
Epoch:  15  	Training Loss: 0.016050927340984344
Test Loss:  0.018578290939331055
Valid Loss:  0.017979826778173447
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.022347524762153625
Test Loss:  0.014759710058569908
Valid Loss:  0.014997061342000961
Epoch:  17  	Training Loss: 0.013602346181869507
Test Loss:  0.003081474220380187
Valid Loss:  0.0028972183354198933
Epoch:  18  	Training Loss: 0.004608922637999058
Test Loss:  0.0018614105647429824
Valid Loss:  0.001951097510755062
Epoch:  19  	Training Loss: 0.002635939745232463
Test Loss:  0.0013043065555393696
Valid Loss:  0.0014765157829970121
Epoch:  20  	Training Loss: 0.0019942233338952065
Test Loss:  0.0011500081745907664
Valid Loss:  0.0013766573974862695
Epoch:  21  	Training Loss: 0.0017109469044953585
Test Loss:  0.001041230745613575
Valid Loss:  0.0012845871970057487
Epoch:  22  	Training Loss: 0.00154683250002563
Test Loss:  0.0010567333083599806
Valid Loss:  0.0013239668915048242
Epoch:  23  	Training Loss: 0.0014997213147580624
Test Loss:  0.0010075161699205637
Valid Loss:  0.001273424830287695
Epoch:  24  	Training Loss: 0.0014768533874303102
Test Loss:  0.0010137574281543493
Valid Loss:  0.0012913106475025415
Epoch:  25  	Training Loss: 0.001456048572435975
Test Loss:  0.0009850022615864873
Valid Loss:  0.0012634501326829195
Epoch:  26  	Training Loss: 0.0014375020982697606
Test Loss:  0.0009803530992940068
Valid Loss:  0.0012645861133933067
Epoch:  27  	Training Loss: 0.001419269246980548
Test Loss:  0.0009570763795636594
Valid Loss:  0.001242387224920094
Epoch:  28  	Training Loss: 0.0014015467604622245
Test Loss:  0.0009482729947194457
Valid Loss:  0.001237162621691823
Epoch:  29  	Training Loss: 0.001384422299452126
Test Loss:  0.000929838337469846
Valid Loss:  0.00122001301497221
Epoch:  30  	Training Loss: 0.0013679283438250422
Test Loss:  0.000919192680157721
Valid Loss:  0.001210781978443265
Epoch:  31  	Training Loss: 0.0013525689719244838
Test Loss:  0.0009068603394553065
Valid Loss:  0.001197870820760727
Epoch:  32  	Training Loss: 0.0013382639735937119
Test Loss:  0.0008398732752539217
Valid Loss:  0.0011285743676126003
Epoch:  33  	Training Loss: 0.0012533020926639438
Test Loss:  0.0008071181364357471
Valid Loss:  0.001089791301637888
Epoch:  34  	Training Loss: 0.0011971195926889777
Test Loss:  0.0007858845638111234
Valid Loss:  0.0010588932782411575
Epoch:  35  	Training Loss: 0.0011542155407369137
Test Loss:  0.0007713122176937759
Valid Loss:  0.0010402884799987078
Epoch:  36  	Training Loss: 0.0011255701538175344
Test Loss:  0.0007584440754726529
Valid Loss:  0.0010199141688644886
Epoch:  37  	Training Loss: 0.0011042013065889478
Test Loss:  0.000753441359847784
Valid Loss:  0.0010103171225637197
Epoch:  38  	Training Loss: 0.0010927871335297823
Test Loss:  0.0007490188581869006
Valid Loss:  0.0010032861027866602
Epoch:  39  	Training Loss: 0.0010844634380191565
Test Loss:  0.00074433081317693
Valid Loss:  0.000997380935586989
Epoch:  40  	Training Loss: 0.0010772017994895577
Test Loss:  0.0007421374320983887
Valid Loss:  0.0009930792730301619
Epoch:  41  	Training Loss: 0.0010715386597439647
Test Loss:  0.0007404960924759507
Valid Loss:  0.0009895773837342858
Epoch:  42  	Training Loss: 0.0010669302428141236
Test Loss:  0.0006687017739750445
Valid Loss:  0.0009301295503973961
Epoch:  43  	Training Loss: 0.0009510577656328678
Test Loss:  0.0006109274108894169
Valid Loss:  0.0008812471060082316
Epoch:  44  	Training Loss: 0.0008834905456751585
Test Loss:  0.0005745065864175558
Valid Loss:  0.0008544537704437971
Epoch:  45  	Training Loss: 0.0008304134244099259
Test Loss:  0.000533341895788908
Valid Loss:  0.0008206512429751456
Epoch:  46  	Training Loss: 0.0007891353452578187
Test Loss:  0.0005115069216117263
Valid Loss:  0.0008062878623604774
Epoch:  47  	Training Loss: 0.0007576232310384512
Test Loss:  0.00048411538591608405
Valid Loss:  0.0007823396008461714
Epoch:  48  	Training Loss: 0.0007326955674216151
Test Loss:  0.00047090003499761224
Valid Loss:  0.000773817184381187
Epoch:  49  	Training Loss: 0.0007126112468540668
Test Loss:  0.00045153722749091685
Valid Loss:  0.0007565460400655866
Epoch:  50  	Training Loss: 0.0006963767809793353
Test Loss:  0.0004427461535669863
Valid Loss:  0.0007516333716921508
Epoch:  51  	Training Loss: 0.0006826085154898465
Test Loss:  0.00042733491864055395
Valid Loss:  0.0007363274344243109
Epoch:  52  	Training Loss: 0.0006710529560223222
Test Loss:  0.00042374152690172195
Valid Loss:  0.0007337782299146056
Epoch:  53  	Training Loss: 0.0006631124997511506
Test Loss:  0.0004151329630985856
Valid Loss:  0.0007246672175824642
Epoch:  54  	Training Loss: 0.0006564623909071088
Test Loss:  0.0004106295818928629
Valid Loss:  0.0007207270245999098
Epoch:  55  	Training Loss: 0.0006507292273454368
Test Loss:  0.0004043368389829993
Valid Loss:  0.00071433384437114
Epoch:  56  	Training Loss: 0.0006455553229898214
Test Loss:  0.0003995586303062737
Valid Loss:  0.0007100875955075026
Epoch:  57  	Training Loss: 0.000640695623587817
Test Loss:  0.0003943777992390096
Valid Loss:  0.0007051214342936873
Epoch:  58  	Training Loss: 0.0006363424472510815
Test Loss:  0.00039008917519822717
Valid Loss:  0.0007009251276031137
Epoch:  59  	Training Loss: 0.0006325054564513266
Test Loss:  0.00038607034366577864
Valid Loss:  0.0006965998327359557
Epoch:  60  	Training Loss: 0.0006290677702054381
Test Loss:  0.00038249732460826635
Valid Loss:  0.0006926916539669037
Epoch:  61  	Training Loss: 0.0006258766516111791
Test Loss:  0.00037931452970951796
Valid Loss:  0.0006889461656101048
Epoch:  62  	Training Loss: 0.0006230123108252883
Test Loss:  0.0003727800794877112
Valid Loss:  0.0006813803920522332
Epoch:  63  	Training Loss: 0.0006173165747895837
Test Loss:  0.0003674355975817889
Valid Loss:  0.0006752665503881872
Epoch:  64  	Training Loss: 0.0006121963961049914
Test Loss:  0.0003627549158409238
Valid Loss:  0.0006698818178847432
Epoch:  65  	Training Loss: 0.0006074863485991955
Test Loss:  0.00035853206645697355
Valid Loss:  0.0006649753195233643
Epoch:  66  	Training Loss: 0.0006030226941220462
Test Loss:  0.0003545583749655634
Valid Loss:  0.0006603087531402707
Epoch:  67  	Training Loss: 0.0005988430930301547
Test Loss:  0.0003507990622892976
Valid Loss:  0.000655913376249373
Epoch:  68  	Training Loss: 0.0005947668105363846
Test Loss:  0.00034714938374236226
Valid Loss:  0.0006516848807223141
 14%|█▍        | 69/500 [00:55<02:26,  2.94it/s] 14%|█▍        | 71/500 [01:01<08:33,  1.20s/it] 15%|█▍        | 73/500 [01:02<06:07,  1.16it/s] 15%|█▌        | 75/500 [01:02<04:24,  1.61it/s] 15%|█▌        | 77/500 [01:02<03:13,  2.19it/s] 16%|█▌        | 79/500 [01:02<02:22,  2.95it/s] 16%|█▌        | 81/500 [01:08<08:18,  1.19s/it] 17%|█▋        | 83/500 [01:08<05:56,  1.17it/s] 17%|█▋        | 85/500 [01:09<04:17,  1.61it/s] 17%|█▋        | 87/500 [01:09<03:08,  2.19it/s] 18%|█▊        | 89/500 [01:09<02:19,  2.95it/s] 18%|█▊        | 91/500 [01:15<08:14,  1.21s/it] 19%|█▊        | 93/500 [01:16<05:53,  1.15it/s] 19%|█▉        | 95/500 [01:16<04:15,  1.59it/s] 19%|█▉        | 97/500 [01:16<03:05,  2.17it/s] 20%|█▉        | 99/500 [01:16<02:16,  2.93it/s] 20%|██        | 101/500 [01:22<08:05,  1.22s/it] 21%|██        | 103/500 [01:23<05:46,  1.15it/s] 21%|██        | 105/500 [01:23<04:08,  1.59it/s] 21%|██▏       | 107/500 [01:23<03:01,  2.17it/s] 22%|██▏       | 109/500 [01:23<02:15,  2.89it/s] 22%|██▏       | 111/500 [01:29<07:51,  1.21s/it] 23%|██▎       | 113/500 [01:30<05:36,  1.15it/s] 23%|██▎       | 115/500 [01:30<04:02,  1.59it/s] 23%|██▎       | 117/500 [01:30<02:56,  2.18it/s] 24%|██▍       | 119/500 [01:30<02:10,  2.93it/s] 24%|██▍       | 121/500 [01:36<07:30,  1.19s/it] 25%|██▍       | 123/500 [01:36<05:22,  1.17it/s] 25%|██▌       | 125/500 [01:37<03:52,  1.62it/s] 25%|██▌       | 127/500 [01:37<02:48,  2.21it/s] 26%|██▌       | 129/500 [01:37<02:04,  2.97it/s] 26%|██▌       | 131/500 [01:43<07:22,  1.20s/it] 27%|██▋       | 133/500 [01:43<05:16,  1.16it/s] 27%|██▋       | 135/500 [01:44<03:47,  1.60it/s]Epoch:  69  	Training Loss: 0.0005907785380259156
Test Loss:  0.00034361385041847825
Valid Loss:  0.0006476377602666616
Epoch:  70  	Training Loss: 0.0005869457381777465
Test Loss:  0.00034023396437987685
Valid Loss:  0.0006437894771806896
Epoch:  71  	Training Loss: 0.0005832753959111869
Test Loss:  0.00033700186759233475
Valid Loss:  0.0006401016726158559
Epoch:  72  	Training Loss: 0.00057967723114416
Test Loss:  0.000332873547449708
Valid Loss:  0.0006348598399199545
Epoch:  73  	Training Loss: 0.0005758512415923178
Test Loss:  0.0003296605427749455
Valid Loss:  0.0006305348360911012
Epoch:  74  	Training Loss: 0.000572304124943912
Test Loss:  0.0003268099098931998
Valid Loss:  0.0006268578581511974
Epoch:  75  	Training Loss: 0.0005691099213436246
Test Loss:  0.00032425616518594325
Valid Loss:  0.0006240493967197835
Epoch:  76  	Training Loss: 0.0005661089671775699
Test Loss:  0.00032182669383473694
Valid Loss:  0.0006210403516888618
Epoch:  77  	Training Loss: 0.000563147128559649
Test Loss:  0.000319422222673893
Valid Loss:  0.0006181130302138627
Epoch:  78  	Training Loss: 0.0005602325545623899
Test Loss:  0.00031714310171082616
Valid Loss:  0.000615360273513943
Epoch:  79  	Training Loss: 0.0005574444076046348
Test Loss:  0.00031500085606239736
Valid Loss:  0.000612847856245935
Epoch:  80  	Training Loss: 0.0005548113840632141
Test Loss:  0.00031297700479626656
Valid Loss:  0.0006104579661041498
Epoch:  81  	Training Loss: 0.0005523146828636527
Test Loss:  0.00031111075077205896
Valid Loss:  0.0006083781481720507
Epoch:  82  	Training Loss: 0.0005499443504959345
Test Loss:  0.00031079794280231
Valid Loss:  0.0006059309234842658
Epoch:  83  	Training Loss: 0.0005458752857521176
Test Loss:  0.00030995492124930024
Valid Loss:  0.0006042640889063478
Epoch:  84  	Training Loss: 0.000542527879588306
Test Loss:  0.00030894146766513586
Valid Loss:  0.0006029325304552913
Epoch:  85  	Training Loss: 0.0005401324015110731
Test Loss:  0.0003079648595303297
Valid Loss:  0.0006017403211444616
Epoch:  86  	Training Loss: 0.0005385825061239302
Test Loss:  0.00030698737828060985
Valid Loss:  0.0006003802409395576
Epoch:  87  	Training Loss: 0.0005370696308091283
Test Loss:  0.0003059571608901024
Valid Loss:  0.0005989017663523555
Epoch:  88  	Training Loss: 0.0005356032634153962
Test Loss:  0.0003049308725167066
Valid Loss:  0.0005974077503196895
Epoch:  89  	Training Loss: 0.0005341846263036132
Test Loss:  0.000304000626783818
Valid Loss:  0.0005962774157524109
Epoch:  90  	Training Loss: 0.0005327952094376087
Test Loss:  0.00030304223764687777
Valid Loss:  0.0005948659963905811
Epoch:  91  	Training Loss: 0.0005313835572451353
Test Loss:  0.0003020194417331368
Valid Loss:  0.0005933865322731435
Epoch:  92  	Training Loss: 0.0005299845361150801
Test Loss:  0.0002995605464093387
Valid Loss:  0.0005898675299249589
Epoch:  93  	Training Loss: 0.000527877826243639
Test Loss:  0.00029836982139386237
Valid Loss:  0.0005885674618184566
Epoch:  94  	Training Loss: 0.000525894807651639
Test Loss:  0.0002968541521113366
Valid Loss:  0.0005866659921593964
Epoch:  95  	Training Loss: 0.0005239360616542399
Test Loss:  0.00029544325661845505
Valid Loss:  0.0005849387380294502
Epoch:  96  	Training Loss: 0.0005220005987212062
Test Loss:  0.00029401981737464666
Valid Loss:  0.0005831574671901762
Epoch:  97  	Training Loss: 0.0005200993618927896
Test Loss:  0.0002925977169070393
Valid Loss:  0.0005813813768327236
Epoch:  98  	Training Loss: 0.000518231128808111
Test Loss:  0.00029119994724169374
Valid Loss:  0.0005796408513560891
Epoch:  99  	Training Loss: 0.0005163809983059764
Test Loss:  0.00028982246294617653
Valid Loss:  0.0005778924096375704
Epoch:  100  	Training Loss: 0.0005145429749973118
Test Loss:  0.00028847053181380033
Valid Loss:  0.0005761480424553156
Epoch:  101  	Training Loss: 0.000512722646817565
Test Loss:  0.0002871139149647206
Valid Loss:  0.0005743797519244254
Epoch:  102  	Training Loss: 0.0005109222838655114
Test Loss:  0.00028490694239735603
Valid Loss:  0.0005710145924240351
Epoch:  103  	Training Loss: 0.0005078800022602081
Test Loss:  0.0002827709831763059
Valid Loss:  0.0005678642774000764
Epoch:  104  	Training Loss: 0.000505132891703397
Test Loss:  0.0002807479177135974
Valid Loss:  0.0005650502862408757
Epoch:  105  	Training Loss: 0.0005026625003665686
Test Loss:  0.0002788333804346621
Valid Loss:  0.0005625118501484394
Epoch:  106  	Training Loss: 0.000500418187584728
Test Loss:  0.00027714265161193907
Valid Loss:  0.0005602162564173341
Epoch:  107  	Training Loss: 0.000498335633892566
Test Loss:  0.0002755391178652644
Valid Loss:  0.000558016006834805
Epoch:  108  	Training Loss: 0.0004963255487382412
Test Loss:  0.00027402842533774674
Valid Loss:  0.000555910577531904
Epoch:  109  	Training Loss: 0.0004943690728396177
Test Loss:  0.0002725498052313924
Valid Loss:  0.0005538610275834799
Epoch:  110  	Training Loss: 0.0004924741224385798
Test Loss:  0.00027117267018184066
Valid Loss:  0.0005519066471606493
Epoch:  111  	Training Loss: 0.0004906386602669954
Test Loss:  0.0002698298776522279
Valid Loss:  0.000550028053112328
Epoch:  112  	Training Loss: 0.0004888421972282231
Test Loss:  0.00026835902826860547
Valid Loss:  0.000547530478797853
Epoch:  113  	Training Loss: 0.00048514443915337324
Test Loss:  0.000267910014372319
Valid Loss:  0.0005475406651385128
Epoch:  114  	Training Loss: 0.00048277241876348853
Test Loss:  0.00026582746068015695
Valid Loss:  0.0005444777198135853
Epoch:  115  	Training Loss: 0.00048057729145511985
Test Loss:  0.0002651651157066226
Valid Loss:  0.0005440987879410386
Epoch:  116  	Training Loss: 0.00047845562221482396
Test Loss:  0.0002633043040987104
Valid Loss:  0.0005413081962615252
Epoch:  117  	Training Loss: 0.00047636928502470255
Test Loss:  0.00026244993205182254
Valid Loss:  0.0005406425334513187
Epoch:  118  	Training Loss: 0.0004743212484754622
Test Loss:  0.00026071889442391694
Valid Loss:  0.0005378923960961401
Epoch:  119  	Training Loss: 0.00047230394557118416
Test Loss:  0.00025981286307796836
Valid Loss:  0.0005371817969717085
Epoch:  120  	Training Loss: 0.00047031184658408165
Test Loss:  0.0002580690779723227
Valid Loss:  0.0005343329976312816
Epoch:  121  	Training Loss: 0.00046833258238621056
Test Loss:  0.0002572287921793759
Valid Loss:  0.000533699057996273
Epoch:  122  	Training Loss: 0.0004663716536015272
Test Loss:  0.00025539990747347474
Valid Loss:  0.0005311497952789068
Epoch:  123  	Training Loss: 0.000464542827103287
Test Loss:  0.0002537053369451314
Valid Loss:  0.0005287923268042505
Epoch:  124  	Training Loss: 0.0004627931339200586
Test Loss:  0.00025214123888872564
Valid Loss:  0.0005266328225843608
Epoch:  125  	Training Loss: 0.00046112725976854563
Test Loss:  0.0002506712917238474
Valid Loss:  0.0005246241926215589
Epoch:  126  	Training Loss: 0.00045952684013172984
Test Loss:  0.00024932637461461127
Valid Loss:  0.0005227632354944944
Epoch:  127  	Training Loss: 0.0004579749656841159
Test Loss:  0.0002480582916177809
Valid Loss:  0.0005210209637880325
Epoch:  128  	Training Loss: 0.0004564584814943373
Test Loss:  0.00024683820083737373
Valid Loss:  0.0005193667602725327
Epoch:  129  	Training Loss: 0.00045497308019548655
Test Loss:  0.00024566418142057955
Valid Loss:  0.0005177888087928295
Epoch:  130  	Training Loss: 0.00045351823791861534
Test Loss:  0.00024452738580293953
Valid Loss:  0.000516272964887321
Epoch:  131  	Training Loss: 0.0004520856309682131
Test Loss:  0.00024342340475413948
Valid Loss:  0.0005148124182596803
Epoch:  132  	Training Loss: 0.00045067330938763916
Test Loss:  0.00024225699598900974
Valid Loss:  0.0005126171745359898
Epoch:  133  	Training Loss: 0.00044971719034947455
Test Loss:  0.0002416442148387432
Valid Loss:  0.0005115164676681161
Epoch:  134  	Training Loss: 0.0004488168633542955
Test Loss:  0.00024095876142382622
Valid Loss:  0.0005102625582367182
Epoch:  135  	Training Loss: 0.00044792695553041995
Test Loss:  0.00024030522035900503
Valid Loss:  0.0005090712802484632
Epoch:  136  	Training Loss: 0.0004470465355552733
Test Loss:  0.00023966330627445132
Valid Loss:  0.0005079080583527684
 27%|██▋       | 137/500 [01:44<02:45,  2.19it/s] 28%|██▊       | 139/500 [01:44<02:02,  2.95it/s] 28%|██▊       | 141/500 [01:50<07:14,  1.21s/it] 29%|██▊       | 143/500 [01:50<05:09,  1.15it/s] 29%|██▉       | 145/500 [01:51<03:42,  1.60it/s] 29%|██▉       | 147/500 [01:51<02:41,  2.18it/s] 30%|██▉       | 149/500 [01:51<01:59,  2.93it/s] 30%|███       | 151/500 [01:57<06:58,  1.20s/it] 31%|███       | 153/500 [01:57<04:59,  1.16it/s] 31%|███       | 155/500 [01:58<03:35,  1.60it/s] 31%|███▏      | 157/500 [01:58<02:36,  2.19it/s] 32%|███▏      | 159/500 [01:58<01:55,  2.95it/s] 32%|███▏      | 161/500 [02:04<06:43,  1.19s/it] 33%|███▎      | 163/500 [02:04<04:48,  1.17it/s] 33%|███▎      | 165/500 [02:04<03:27,  1.61it/s] 33%|███▎      | 167/500 [02:05<02:31,  2.20it/s] 34%|███▍      | 169/500 [02:05<01:53,  2.92it/s] 34%|███▍      | 171/500 [02:11<06:37,  1.21s/it] 35%|███▍      | 173/500 [02:11<04:43,  1.15it/s] 35%|███▌      | 175/500 [02:11<03:23,  1.60it/s] 35%|███▌      | 177/500 [02:12<02:28,  2.18it/s] 36%|███▌      | 179/500 [02:12<01:49,  2.93it/s] 36%|███▌      | 181/500 [02:18<06:29,  1.22s/it] 37%|███▋      | 183/500 [02:18<04:37,  1.14it/s] 37%|███▋      | 185/500 [02:19<03:19,  1.58it/s] 37%|███▋      | 187/500 [02:19<02:25,  2.15it/s] 38%|███▊      | 189/500 [02:19<01:47,  2.89it/s] 38%|███▊      | 191/500 [02:25<06:10,  1.20s/it] 39%|███▊      | 193/500 [02:25<04:24,  1.16it/s] 39%|███▉      | 195/500 [02:26<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:26<02:18,  2.19it/s] 40%|███▉      | 199/500 [02:26<01:42,  2.94it/s] 40%|████      | 201/500 [02:32<06:01,  1.21s/it] 41%|████      | 203/500 [02:32<04:18,  1.15it/s]Epoch:  137  	Training Loss: 0.0004461709759198129
Test Loss:  0.00023903361579868942
Valid Loss:  0.0005067732417955995
Epoch:  138  	Training Loss: 0.0004453008295968175
Test Loss:  0.0002384110412094742
Valid Loss:  0.0005056430818513036
Epoch:  139  	Training Loss: 0.00044443938531912863
Test Loss:  0.00023780418268870562
Valid Loss:  0.0005045464495196939
Epoch:  140  	Training Loss: 0.0004435845767147839
Test Loss:  0.00023720023455098271
Valid Loss:  0.0005034530768170953
Epoch:  141  	Training Loss: 0.0004427410603966564
Test Loss:  0.0002366270637139678
Valid Loss:  0.0005024006823077798
Epoch:  142  	Training Loss: 0.0004419580800458789
Test Loss:  0.00023519886599387974
Valid Loss:  0.0005043261335231364
Epoch:  143  	Training Loss: 0.0004355967394076288
Test Loss:  0.00023030195734463632
Valid Loss:  0.0004959756042808294
Epoch:  144  	Training Loss: 0.0004324758192524314
Test Loss:  0.00023126986343413591
Valid Loss:  0.0004986762069165707
Epoch:  145  	Training Loss: 0.00042967763147316873
Test Loss:  0.00022712440113537014
Valid Loss:  0.0004914270830340683
Epoch:  146  	Training Loss: 0.0004271318030077964
Test Loss:  0.0002278803294757381
Valid Loss:  0.000493379367981106
Epoch:  147  	Training Loss: 0.00042476330418139696
Test Loss:  0.00022395141422748566
Valid Loss:  0.000486439501401037
Epoch:  148  	Training Loss: 0.00042251156992278993
Test Loss:  0.0002247879165224731
Valid Loss:  0.0004886222304776311
Epoch:  149  	Training Loss: 0.00042028340976685286
Test Loss:  0.00022073235595598817
Valid Loss:  0.00048133396194316447
Epoch:  150  	Training Loss: 0.0004182258853688836
Test Loss:  0.00022212300973478705
Valid Loss:  0.00048451992915943265
Epoch:  151  	Training Loss: 0.00041611751657910645
Test Loss:  0.00021770779858343303
Valid Loss:  0.00047650025226175785
Epoch:  152  	Training Loss: 0.0004140869132243097
Test Loss:  0.00021823184215463698
Valid Loss:  0.0004777058493345976
Epoch:  153  	Training Loss: 0.00041197938844561577
Test Loss:  0.0002157598501071334
Valid Loss:  0.00047333393013104796
Epoch:  154  	Training Loss: 0.00041029497515410185
Test Loss:  0.0002152828819816932
Valid Loss:  0.0004724364262074232
Epoch:  155  	Training Loss: 0.0004087916458956897
Test Loss:  0.00021374650532379746
Valid Loss:  0.00046966972877271473
Epoch:  156  	Training Loss: 0.00040732487104833126
Test Loss:  0.00021314702462404966
Valid Loss:  0.000468592275865376
Epoch:  157  	Training Loss: 0.00040589459240436554
Test Loss:  0.0002118110132869333
Valid Loss:  0.0004662119899876416
Epoch:  158  	Training Loss: 0.0004044781962875277
Test Loss:  0.0002112094807671383
Valid Loss:  0.00046515316353179514
Epoch:  159  	Training Loss: 0.00040308735333383083
Test Loss:  0.00020997310639359057
Valid Loss:  0.00046298038796521723
Epoch:  160  	Training Loss: 0.00040169685962609947
Test Loss:  0.0002093104412779212
Valid Loss:  0.00046183637459762394
Epoch:  161  	Training Loss: 0.0004003478097729385
Test Loss:  0.00020818783377762884
Valid Loss:  0.00045989028876647353
Epoch:  162  	Training Loss: 0.0003990157274529338
Test Loss:  0.00020805757958441973
Valid Loss:  0.00045932098873890936
Epoch:  163  	Training Loss: 0.00039851825567893684
Test Loss:  0.00020809605484828353
Valid Loss:  0.0004590934549923986
Epoch:  164  	Training Loss: 0.00039811659371480346
Test Loss:  0.00020798493642359972
Valid Loss:  0.00045857764780521393
Epoch:  165  	Training Loss: 0.00039774522883817554
Test Loss:  0.00020786977256648242
Valid Loss:  0.0004580350359901786
Epoch:  166  	Training Loss: 0.00039738696068525314
Test Loss:  0.00020775866869371384
Valid Loss:  0.00045748037518933415
Epoch:  167  	Training Loss: 0.00039705305243842304
Test Loss:  0.00020764493092428893
Valid Loss:  0.0004569188749883324
Epoch:  168  	Training Loss: 0.00039673352148383856
Test Loss:  0.0002075391385005787
Valid Loss:  0.0004563680849969387
Epoch:  169  	Training Loss: 0.0003964244097005576
Test Loss:  0.0002074219664791599
Valid Loss:  0.00045579276047647
Epoch:  170  	Training Loss: 0.00039612530963495374
Test Loss:  0.00020730245159938931
Valid Loss:  0.00045520917046815157
Epoch:  171  	Training Loss: 0.0003958398592658341
Test Loss:  0.0002071924536721781
Valid Loss:  0.0004546220588963479
Epoch:  172  	Training Loss: 0.0003955667489208281
Test Loss:  0.00020598237460944802
Valid Loss:  0.00045338706695474684
Epoch:  173  	Training Loss: 0.0003934732230845839
Test Loss:  0.00020475943165365607
Valid Loss:  0.0004519916546996683
Epoch:  174  	Training Loss: 0.00039150516386143863
Test Loss:  0.0002035853685811162
Valid Loss:  0.0004505962715484202
Epoch:  175  	Training Loss: 0.00038962578400969505
Test Loss:  0.0002024391433224082
Valid Loss:  0.00044920522486791015
Epoch:  176  	Training Loss: 0.0003878011484630406
Test Loss:  0.00020130224584136158
Valid Loss:  0.00044779456220567226
Epoch:  177  	Training Loss: 0.00038602013955824077
Test Loss:  0.00020017796487081796
Valid Loss:  0.0004463534860406071
Epoch:  178  	Training Loss: 0.0003842824080493301
Test Loss:  0.00019907901878468692
Valid Loss:  0.00044491590233519673
Epoch:  179  	Training Loss: 0.000382583646569401
Test Loss:  0.00019798640278168023
Valid Loss:  0.00044346164213493466
Epoch:  180  	Training Loss: 0.0003809104673564434
Test Loss:  0.00019690877525135875
Valid Loss:  0.00044201238779351115
Epoch:  181  	Training Loss: 0.00037925911601632833
Test Loss:  0.0001958390057552606
Valid Loss:  0.000440559204434976
Epoch:  182  	Training Loss: 0.00037763387081213295
Test Loss:  0.0001930962025653571
Valid Loss:  0.00043627372360788286
Epoch:  183  	Training Loss: 0.0003738885570783168
Test Loss:  0.00019088067347183824
Valid Loss:  0.00043272346374578774
Epoch:  184  	Training Loss: 0.0003708678996190429
Test Loss:  0.0001889617706183344
Valid Loss:  0.0004296702682040632
Epoch:  185  	Training Loss: 0.0003681358357425779
Test Loss:  0.00018725132395047694
Valid Loss:  0.00042701142956502736
Epoch:  186  	Training Loss: 0.00036562932655215263
Test Loss:  0.00018579108291305602
Valid Loss:  0.0004246125463396311
Epoch:  187  	Training Loss: 0.00036332369199953973
Test Loss:  0.00018444762099534273
Valid Loss:  0.00042249809484928846
Epoch:  188  	Training Loss: 0.00036120536969974637
Test Loss:  0.0001831632835092023
Valid Loss:  0.0004206049779895693
Epoch:  189  	Training Loss: 0.00035918416688218713
Test Loss:  0.00018191606795880944
Valid Loss:  0.00041881215292960405
Epoch:  190  	Training Loss: 0.0003572130517568439
Test Loss:  0.00018070181249640882
Valid Loss:  0.0004170896718278527
Epoch:  191  	Training Loss: 0.000355282798409462
Test Loss:  0.00017952236521523446
Valid Loss:  0.0004154237103648484
Epoch:  192  	Training Loss: 0.0003533924464136362
Test Loss:  0.00017796650354284793
Valid Loss:  0.0004130184534005821
Epoch:  193  	Training Loss: 0.0003518028534017503
Test Loss:  0.00017752118583302945
Valid Loss:  0.0004124114057049155
Epoch:  194  	Training Loss: 0.00035059743095189333
Test Loss:  0.0001768731017364189
Valid Loss:  0.00041128206066787243
Epoch:  195  	Training Loss: 0.00034948292886838317
Test Loss:  0.0001763186592143029
Valid Loss:  0.00041025274549610913
Epoch:  196  	Training Loss: 0.0003484073677100241
Test Loss:  0.00017574461526237428
Valid Loss:  0.0004091563168913126
Epoch:  197  	Training Loss: 0.0003473560500424355
Test Loss:  0.00017519482935313135
Valid Loss:  0.00040804268792271614
Epoch:  198  	Training Loss: 0.00034634361509233713
Test Loss:  0.0001746699563227594
Valid Loss:  0.00040694541530683637
Epoch:  199  	Training Loss: 0.00034535874146968126
Test Loss:  0.000174152766703628
Valid Loss:  0.00040584016824141145
Epoch:  200  	Training Loss: 0.0003444025060161948
Test Loss:  0.00017366436077281833
Valid Loss:  0.0004047564580105245
Epoch:  201  	Training Loss: 0.00034347487962804735
Test Loss:  0.0001731892698444426
Valid Loss:  0.0004036928294226527
Epoch:  202  	Training Loss: 0.0003425889299251139
Test Loss:  0.00017323125211987644
Valid Loss:  0.0004035362508147955
Epoch:  203  	Training Loss: 0.00034201869857497513
Test Loss:  0.00017298336024396122
Valid Loss:  0.00040279875975102186
Epoch:  204  	Training Loss: 0.0003414914244785905
 41%|████      | 205/500 [02:33<03:05,  1.59it/s] 41%|████▏     | 207/500 [02:33<02:15,  2.17it/s] 42%|████▏     | 209/500 [02:33<01:40,  2.91it/s] 42%|████▏     | 211/500 [02:39<05:48,  1.21s/it] 43%|████▎     | 213/500 [02:39<04:08,  1.15it/s] 43%|████▎     | 215/500 [02:40<02:58,  1.60it/s] 43%|████▎     | 217/500 [02:40<02:09,  2.18it/s] 44%|████▍     | 219/500 [02:40<01:35,  2.93it/s] 44%|████▍     | 221/500 [02:46<05:35,  1.20s/it] 45%|████▍     | 223/500 [02:46<03:59,  1.16it/s] 45%|████▌     | 225/500 [02:47<02:52,  1.59it/s] 45%|████▌     | 227/500 [02:47<02:05,  2.18it/s] 46%|████▌     | 229/500 [02:47<01:32,  2.94it/s] 46%|████▌     | 231/500 [02:53<05:25,  1.21s/it] 47%|████▋     | 233/500 [02:53<03:51,  1.15it/s] 47%|████▋     | 235/500 [02:54<02:46,  1.60it/s] 47%|████▋     | 237/500 [02:54<02:00,  2.18it/s] 48%|████▊     | 239/500 [02:54<01:28,  2.94it/s] 48%|████▊     | 241/500 [03:00<05:20,  1.24s/it] 49%|████▊     | 243/500 [03:01<03:49,  1.12it/s] 49%|████▉     | 245/500 [03:01<02:46,  1.53it/s] 49%|████▉     | 247/500 [03:01<02:01,  2.08it/s] 50%|████▉     | 249/500 [03:01<01:31,  2.75it/s] 50%|█████     | 251/500 [03:08<05:02,  1.21s/it] 51%|█████     | 253/500 [03:08<03:35,  1.15it/s] 51%|█████     | 255/500 [03:08<02:34,  1.58it/s] 51%|█████▏    | 257/500 [03:08<01:52,  2.16it/s] 52%|█████▏    | 259/500 [03:08<01:22,  2.91it/s] 52%|█████▏    | 261/500 [03:14<04:43,  1.19s/it] 53%|█████▎    | 263/500 [03:15<03:21,  1.17it/s] 53%|█████▎    | 265/500 [03:15<02:24,  1.62it/s] 53%|█████▎    | 267/500 [03:15<01:45,  2.22it/s] 54%|█████▍    | 269/500 [03:15<01:17,  2.98it/s]Test Loss:  0.0001727566123008728
Valid Loss:  0.0004020696796942502
Epoch:  205  	Training Loss: 0.0003409828641451895
Test Loss:  0.00017252723046112806
Valid Loss:  0.0004013141442555934
Epoch:  206  	Training Loss: 0.00034048984525725245
Test Loss:  0.00017230222874786705
Valid Loss:  0.0004005466471426189
Epoch:  207  	Training Loss: 0.0003400086425244808
Test Loss:  0.00017207842029165477
Valid Loss:  0.00039977754931896925
Epoch:  208  	Training Loss: 0.0003395386738702655
Test Loss:  0.00017185263277497143
Valid Loss:  0.00039899488911032677
Epoch:  209  	Training Loss: 0.00033907912438735366
Test Loss:  0.00017163286975119263
Valid Loss:  0.00039821205427870154
Epoch:  210  	Training Loss: 0.0003386284806765616
Test Loss:  0.0001714156096568331
Valid Loss:  0.0003974340215791017
Epoch:  211  	Training Loss: 0.00033818691736087203
Test Loss:  0.00017119702533818781
Valid Loss:  0.00039665051735937595
Epoch:  212  	Training Loss: 0.00033775344491004944
Test Loss:  0.0001704694441286847
Valid Loss:  0.00039524747990071774
Epoch:  213  	Training Loss: 0.0003359952534083277
Test Loss:  0.00016926124226301908
Valid Loss:  0.0003930171951651573
Epoch:  214  	Training Loss: 0.0003343970747664571
Test Loss:  0.00016828213119879365
Valid Loss:  0.00039115894469432533
Epoch:  215  	Training Loss: 0.000332891009747982
Test Loss:  0.00016732380026951432
Valid Loss:  0.0003893638786394149
Epoch:  216  	Training Loss: 0.00033142921165563166
Test Loss:  0.0001664150331635028
Valid Loss:  0.00038765749195590615
Epoch:  217  	Training Loss: 0.00032999817631207407
Test Loss:  0.00016554734611418098
Valid Loss:  0.00038601868436671793
Epoch:  218  	Training Loss: 0.00032859283965080976
Test Loss:  0.00016468935064040124
Valid Loss:  0.0003844183520413935
Epoch:  219  	Training Loss: 0.00032721232855692506
Test Loss:  0.00016386441711802036
Valid Loss:  0.0003828968037851155
Epoch:  220  	Training Loss: 0.0003258547221776098
Test Loss:  0.00016305086319334805
Valid Loss:  0.00038141250843182206
Epoch:  221  	Training Loss: 0.0003245137631893158
Test Loss:  0.0001622441632207483
Valid Loss:  0.00037994631566107273
Epoch:  222  	Training Loss: 0.0003231865121051669
Test Loss:  0.0001611721090739593
Valid Loss:  0.0003782017738558352
Epoch:  223  	Training Loss: 0.0003219656937289983
Test Loss:  0.0001604113494977355
Valid Loss:  0.00037695426726713777
Epoch:  224  	Training Loss: 0.0003207947011105716
Test Loss:  0.00015969866944942623
Valid Loss:  0.0003757845261134207
Epoch:  225  	Training Loss: 0.00031964073423296213
Test Loss:  0.00015900582366157323
Valid Loss:  0.0003746423462871462
Epoch:  226  	Training Loss: 0.0003184994566254318
Test Loss:  0.00015832444478292018
Valid Loss:  0.00037351224455051124
Epoch:  227  	Training Loss: 0.00031737005338072777
Test Loss:  0.0001576556678628549
Valid Loss:  0.00037240536767058074
Epoch:  228  	Training Loss: 0.00031625013798475266
Test Loss:  0.00015699348296038806
Valid Loss:  0.00037130562122911215
Epoch:  229  	Training Loss: 0.0003151416894979775
Test Loss:  0.0001563355908729136
Valid Loss:  0.0003702130343299359
Epoch:  230  	Training Loss: 0.0003140438930131495
Test Loss:  0.00015568602248094976
Valid Loss:  0.00036913342773914337
Epoch:  231  	Training Loss: 0.0003129560500383377
Test Loss:  0.00015504375915043056
Valid Loss:  0.0003680622612591833
Epoch:  232  	Training Loss: 0.0003118784516118467
Test Loss:  0.00015429439372383058
Valid Loss:  0.0003665513650048524
Epoch:  233  	Training Loss: 0.00031112931901589036
Test Loss:  0.00015398795949295163
Valid Loss:  0.0003659027861431241
Epoch:  234  	Training Loss: 0.0003104035567957908
Test Loss:  0.00015356281073763967
Valid Loss:  0.00036501127760857344
Epoch:  235  	Training Loss: 0.0003096837899647653
Test Loss:  0.00015317442012019455
Valid Loss:  0.0003641866205725819
Epoch:  236  	Training Loss: 0.00030896809767000377
Test Loss:  0.0001527770364191383
Valid Loss:  0.0003633419401012361
Epoch:  237  	Training Loss: 0.00030825621797703207
Test Loss:  0.00015238363994285464
Valid Loss:  0.0003625024401117116
Epoch:  238  	Training Loss: 0.0003075473941862583
Test Loss:  0.00015199114568531513
Valid Loss:  0.0003616614267230034
Epoch:  239  	Training Loss: 0.00030684180092066526
Test Loss:  0.00015159860777202994
Valid Loss:  0.00036082020960748196
Epoch:  240  	Training Loss: 0.0003061399911530316
Test Loss:  0.00015120679745450616
Valid Loss:  0.0003599826304707676
Epoch:  241  	Training Loss: 0.0003054414119105786
Test Loss:  0.00015081667515914887
Valid Loss:  0.00035914458567276597
Epoch:  242  	Training Loss: 0.00030474772211164236
Test Loss:  0.0001492566370870918
Valid Loss:  0.0003568102838471532
Epoch:  243  	Training Loss: 0.00030250902636907995
Test Loss:  0.00014899417874403298
Valid Loss:  0.00035538425436243415
Epoch:  244  	Training Loss: 0.0003015380061697215
Test Loss:  0.00014865369303151965
Valid Loss:  0.0003539537137839943
Epoch:  245  	Training Loss: 0.0003007110790349543
Test Loss:  0.00014826924598310143
Valid Loss:  0.0003525042557157576
Epoch:  246  	Training Loss: 0.00029989745235070586
Test Loss:  0.00014783110236749053
Valid Loss:  0.00035106486757285893
Epoch:  247  	Training Loss: 0.0002990715438500047
Test Loss:  0.00014738409663550556
Valid Loss:  0.0003496554563753307
Epoch:  248  	Training Loss: 0.0002982598962262273
Test Loss:  0.00014704473142046481
Valid Loss:  0.0003484180197119713
Epoch:  249  	Training Loss: 0.00029762860503979027
Test Loss:  0.00014679666492156684
Valid Loss:  0.00034731783671304584
Epoch:  250  	Training Loss: 0.00029710543458350003
Test Loss:  0.00014655239647254348
Valid Loss:  0.0003462953318376094
Epoch:  251  	Training Loss: 0.00029663066379725933
Test Loss:  0.00014632230158895254
Valid Loss:  0.0003454118559602648
Epoch:  252  	Training Loss: 0.0002962159924209118
Test Loss:  0.0001456259924452752
Valid Loss:  0.00034366833278909326
Epoch:  253  	Training Loss: 0.00029530792380683124
Test Loss:  0.0001451763091608882
Valid Loss:  0.0003424315946176648
Epoch:  254  	Training Loss: 0.0002944123116321862
Test Loss:  0.00014389767602551728
Valid Loss:  0.00034015969140455127
Epoch:  255  	Training Loss: 0.0002926407032646239
Test Loss:  0.00013919029152020812
Valid Loss:  0.00033432579948566854
Epoch:  256  	Training Loss: 0.00028580392245203257
Test Loss:  0.00013938227493781596
Valid Loss:  0.0003338016686029732
Epoch:  257  	Training Loss: 0.00028402521274983883
Test Loss:  0.00013854954158887267
Valid Loss:  0.0003319418174214661
Epoch:  258  	Training Loss: 0.0002828135038726032
Test Loss:  0.00013791194942314178
Valid Loss:  0.00033035792876034975
Epoch:  259  	Training Loss: 0.000281583983451128
Test Loss:  0.00013719379785470665
Valid Loss:  0.0003287318686489016
Epoch:  260  	Training Loss: 0.00028038426535204053
Test Loss:  0.000136721006128937
Valid Loss:  0.0003273524343967438
Epoch:  261  	Training Loss: 0.000279443571344018
Test Loss:  0.0001362228358630091
Valid Loss:  0.0003260860685259104
Epoch:  262  	Training Loss: 0.0002785830874927342
Test Loss:  0.00013611374015454203
Valid Loss:  0.0003257251810282469
Epoch:  263  	Training Loss: 0.0002780132053885609
Test Loss:  0.00013588933506980538
Valid Loss:  0.00032522084075026214
Epoch:  264  	Training Loss: 0.0002774641034193337
Test Loss:  0.00013561962987296283
Valid Loss:  0.00032466219272464514
Epoch:  265  	Training Loss: 0.0002769191632978618
Test Loss:  0.0001353338302578777
Valid Loss:  0.00032408631523139775
Epoch:  266  	Training Loss: 0.0002763764059636742
Test Loss:  0.00013504318485502154
Valid Loss:  0.00032350607216358185
Epoch:  267  	Training Loss: 0.0002758360933512449
Test Loss:  0.00013475179730448872
Valid Loss:  0.00032292617834173143
Epoch:  268  	Training Loss: 0.00027529761428013444
Test Loss:  0.00013446115190163255
Valid Loss:  0.0003223480307497084
Epoch:  269  	Training Loss: 0.00027476123068481684
Test Loss:  0.0001341713941656053
Valid Loss:  0.0003217721823602915
Epoch:  270  	Training Loss: 0.00027422665152698755
Test Loss:  0.00013388287334237248
Valid Loss:  0.0003211992734577507
Epoch:  271  	Training Loss: 0.0002736939350143075
Test Loss:  0.00013359569129534066
Valid Loss:   54%|█████▍    | 271/500 [03:21<04:34,  1.20s/it] 55%|█████▍    | 273/500 [03:22<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:22<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:22<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:22<01:14,  2.95it/s] 56%|█████▌    | 281/500 [03:28<04:20,  1.19s/it] 57%|█████▋    | 283/500 [03:28<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:29<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:29<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:29<01:11,  2.97it/s] 58%|█████▊    | 291/500 [03:35<04:09,  1.20s/it] 59%|█████▊    | 293/500 [03:35<02:57,  1.16it/s] 59%|█████▉    | 295/500 [03:36<02:07,  1.61it/s] 59%|█████▉    | 297/500 [03:36<01:32,  2.20it/s] 60%|█████▉    | 299/500 [03:36<01:07,  2.96it/s] 60%|██████    | 301/500 [03:42<03:56,  1.19s/it] 61%|██████    | 303/500 [03:42<02:49,  1.16it/s] 61%|██████    | 305/500 [03:42<02:02,  1.60it/s] 61%|██████▏   | 307/500 [03:43<01:28,  2.18it/s] 62%|██████▏   | 309/500 [03:43<01:05,  2.93it/s] 62%|██████▏   | 311/500 [03:49<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:49<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:49<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:49<01:22,  2.21it/s] 64%|██████▍   | 319/500 [03:50<01:01,  2.96it/s] 64%|██████▍   | 321/500 [03:56<03:33,  1.19s/it] 65%|██████▍   | 323/500 [03:56<02:32,  1.16it/s] 65%|██████▌   | 325/500 [03:56<01:50,  1.59it/s] 65%|██████▌   | 327/500 [03:57<01:20,  2.14it/s] 66%|██████▌   | 329/500 [03:57<01:00,  2.83it/s] 66%|██████▌   | 331/500 [04:03<03:25,  1.22s/it] 67%|██████▋   | 333/500 [04:03<02:26,  1.14it/s] 67%|██████▋   | 335/500 [04:03<01:44,  1.58it/s] 67%|██████▋   | 337/500 [04:04<01:15,  2.15it/s]0.0003206290421076119
Epoch:  272  	Training Loss: 0.00027316337218508124
Test Loss:  0.00013268085604067892
Valid Loss:  0.00031931832199916244
Epoch:  273  	Training Loss: 0.00027180270990356803
Test Loss:  0.00013195935753174126
Valid Loss:  0.000318275997415185
Epoch:  274  	Training Loss: 0.0002704776998143643
Test Loss:  0.00013120481162331998
Valid Loss:  0.00031712703639641404
Epoch:  275  	Training Loss: 0.0002691820845939219
Test Loss:  0.00013050349662080407
Valid Loss:  0.0003160386113449931
Epoch:  276  	Training Loss: 0.00026790605625137687
Test Loss:  0.0001298151328228414
Valid Loss:  0.00031494771246798337
Epoch:  277  	Training Loss: 0.00026664877077564597
Test Loss:  0.00012914245598949492
Valid Loss:  0.00031386493355967104
Epoch:  278  	Training Loss: 0.00026540952967479825
Test Loss:  0.00012848457845393568
Valid Loss:  0.00031278858659788966
Epoch:  279  	Training Loss: 0.0002641890023369342
Test Loss:  0.00012782956764567643
Valid Loss:  0.00031170088914223015
Epoch:  280  	Training Loss: 0.0002629862283356488
Test Loss:  0.0001271981600439176
Valid Loss:  0.0003106424701400101
Epoch:  281  	Training Loss: 0.0002618000435177237
Test Loss:  0.00012657884508371353
Valid Loss:  0.0003095939173363149
Epoch:  282  	Training Loss: 0.00026063056429848075
Test Loss:  0.00012608530232682824
Valid Loss:  0.00030772120226174593
Epoch:  283  	Training Loss: 0.0002591258380562067
Test Loss:  0.00012557054287754
Valid Loss:  0.0003060061717405915
Epoch:  284  	Training Loss: 0.0002578981511760503
Test Loss:  0.0001251525100087747
Valid Loss:  0.00030467583565041423
Epoch:  285  	Training Loss: 0.00025684532010927796
Test Loss:  0.00012473610695451498
Valid Loss:  0.00030338740907609463
Epoch:  286  	Training Loss: 0.0002558069536462426
Test Loss:  0.00012428121408447623
Valid Loss:  0.0003020920557901263
Epoch:  287  	Training Loss: 0.0002547357580624521
Test Loss:  0.0001238005788763985
Valid Loss:  0.00030074920505285263
Epoch:  288  	Training Loss: 0.00025365527835674584
Test Loss:  0.00012330309255048633
Valid Loss:  0.0002994039678014815
Epoch:  289  	Training Loss: 0.0002525594609323889
Test Loss:  0.00012276681081857532
Valid Loss:  0.00029804775840602815
Epoch:  290  	Training Loss: 0.00025146317784674466
Test Loss:  0.00012223220255691558
Valid Loss:  0.0002967117470689118
Epoch:  291  	Training Loss: 0.0002503815048839897
Test Loss:  0.00012169704132247716
Valid Loss:  0.00029541458934545517
Epoch:  292  	Training Loss: 0.00024932637461461127
Test Loss:  0.00012022633745800704
Valid Loss:  0.0002924767031800002
Epoch:  293  	Training Loss: 0.00024753258912824094
Test Loss:  0.00011967353930231184
Valid Loss:  0.0002906376321334392
Epoch:  294  	Training Loss: 0.0002458833623677492
Test Loss:  0.00011893085320480168
Valid Loss:  0.00028871066751889884
Epoch:  295  	Training Loss: 0.00024429248878732324
Test Loss:  0.00011824032117146999
Valid Loss:  0.0002869407180696726
Epoch:  296  	Training Loss: 0.00024273607414215803
Test Loss:  0.00011749770783353597
Valid Loss:  0.00028522423235699534
Epoch:  297  	Training Loss: 0.00024118668807204813
Test Loss:  0.0001167204900411889
Valid Loss:  0.00028351874789223075
Epoch:  298  	Training Loss: 0.00023962673731148243
Test Loss:  0.00011587711196625605
Valid Loss:  0.0002818360226228833
Epoch:  299  	Training Loss: 0.00023804453667253256
Test Loss:  0.00011492762132547796
Valid Loss:  0.00028014357667416334
Epoch:  300  	Training Loss: 0.00023641651205252856
Test Loss:  0.00011398339120205492
Valid Loss:  0.00027847083401866257
Epoch:  301  	Training Loss: 0.00023478118237107992
Test Loss:  0.00011312538117635995
Valid Loss:  0.0002768371195998043
Epoch:  302  	Training Loss: 0.00023321060871239752
Test Loss:  0.00011328588880132884
Valid Loss:  0.00027755287010222673
Epoch:  303  	Training Loss: 0.00023266741482075304
Test Loss:  0.00011271136463619769
Valid Loss:  0.00027687527472153306
Epoch:  304  	Training Loss: 0.0002322155487490818
Test Loss:  0.00011244888446526602
Valid Loss:  0.00027660775231197476
Epoch:  305  	Training Loss: 0.0002318022307008505
Test Loss:  0.00011214699770789593
Valid Loss:  0.0002761869691312313
Epoch:  306  	Training Loss: 0.00023141011479310691
Test Loss:  0.00011189937504241243
Valid Loss:  0.00027577695436775684
Epoch:  307  	Training Loss: 0.00023103661078494042
Test Loss:  0.00011166273179696873
Valid Loss:  0.0002753349835984409
Epoch:  308  	Training Loss: 0.0002306761161889881
Test Loss:  0.0001114455662900582
Valid Loss:  0.0002748814004007727
Epoch:  309  	Training Loss: 0.00023032606986816972
Test Loss:  0.00011123851436423138
Valid Loss:  0.0002744019730016589
Epoch:  310  	Training Loss: 0.0002299865591339767
Test Loss:  0.00011104746226919815
Valid Loss:  0.00027392481570132077
Epoch:  311  	Training Loss: 0.0002296528546139598
Test Loss:  0.00011086453741881996
Valid Loss:  0.00027344602858647704
Epoch:  312  	Training Loss: 0.000229322089580819
Test Loss:  0.000110447290353477
Valid Loss:  0.00027282704832032323
Epoch:  313  	Training Loss: 0.00022888617240823805
Test Loss:  0.00011016652570106089
Valid Loss:  0.00027244299417361617
Epoch:  314  	Training Loss: 0.000228455028263852
Test Loss:  0.00010989971633534878
Valid Loss:  0.00027207500534132123
Epoch:  315  	Training Loss: 0.00022802766761742532
Test Loss:  0.00010963778186123818
Valid Loss:  0.00027170561952516437
Epoch:  316  	Training Loss: 0.00022760350839234889
Test Loss:  0.00010938054037978873
Valid Loss:  0.0002713344874791801
Epoch:  317  	Training Loss: 0.00022718269610777497
Test Loss:  0.00010912187281064689
Valid Loss:  0.00027095709810964763
Epoch:  318  	Training Loss: 0.00022676307708024979
Test Loss:  0.00010885885421885177
Valid Loss:  0.00027057903935201466
Epoch:  319  	Training Loss: 0.0002263464848510921
Test Loss:  0.00010859906615223736
Valid Loss:  0.00027019967092201114
Epoch:  320  	Training Loss: 0.00022593257017433643
Test Loss:  0.0001083413080777973
Valid Loss:  0.0002698190219234675
Epoch:  321  	Training Loss: 0.00022552188602276146
Test Loss:  0.00010808689694385976
Valid Loss:  0.0002694328723009676
Epoch:  322  	Training Loss: 0.0002251140249427408
Test Loss:  0.00010792115062940866
Valid Loss:  0.00026917841751128435
Epoch:  323  	Training Loss: 0.00022460863692685962
Test Loss:  0.0001076398475561291
Valid Loss:  0.00026870184228755534
Epoch:  324  	Training Loss: 0.00022411116515286267
Test Loss:  0.00010736162948887795
Valid Loss:  0.00026822072686627507
Epoch:  325  	Training Loss: 0.00022361634182743728
Test Loss:  0.0001070866419468075
Valid Loss:  0.0002677376032806933
Epoch:  326  	Training Loss: 0.0002231238759122789
Test Loss:  0.00010681449202820659
Valid Loss:  0.00026725122006610036
Epoch:  327  	Training Loss: 0.00022263391292653978
Test Loss:  0.00010654491779860109
Valid Loss:  0.00026676314882934093
Epoch:  328  	Training Loss: 0.00022214613272808492
Test Loss:  0.00010627780284266919
Valid Loss:  0.0002662728074938059
Epoch:  329  	Training Loss: 0.0002216602733824402
Test Loss:  0.00010601260146358982
Valid Loss:  0.00026578246615827084
Epoch:  330  	Training Loss: 0.0002211765677202493
Test Loss:  0.00010574935004115105
Valid Loss:  0.0002652911061886698
Epoch:  331  	Training Loss: 0.00022069519036449492
Test Loss:  0.00010548456339165568
Valid Loss:  0.0002647904912009835
Epoch:  332  	Training Loss: 0.00022021529730409384
Test Loss:  0.00010553786705713719
Valid Loss:  0.0002632434479892254
Epoch:  333  	Training Loss: 0.00021924759494140744
Test Loss:  0.0001053492451319471
Valid Loss:  0.00026174262166023254
Epoch:  334  	Training Loss: 0.00021847077005077153
Test Loss:  0.00010522388765821233
Valid Loss:  0.0002605026529636234
Epoch:  335  	Training Loss: 0.00021778099471703172
Test Loss:  0.00010510104766581208
Valid Loss:  0.00025943072978407145
Epoch:  336  	Training Loss: 0.00021712957823183388
Test Loss:  0.0001049614220391959
Valid Loss:  0.0002584821486379951
Epoch:  337  	Training Loss: 0.00021650487906299531
Test Loss:  0.00010479714546818286
Valid Loss:  0.00025761721190065145
Epoch:  338  	Training Loss: 0.0002158867719117552
Test Loss:  0.00010458959877723828
Valid Loss:  0.0002568206691648811
 68%|██████▊   | 339/500 [04:04<00:55,  2.89it/s] 68%|██████▊   | 341/500 [04:10<03:11,  1.20s/it] 69%|██████▊   | 343/500 [04:10<02:16,  1.15it/s] 69%|██████▉   | 345/500 [04:10<01:38,  1.58it/s] 69%|██████▉   | 347/500 [04:11<01:10,  2.16it/s] 70%|██████▉   | 349/500 [04:11<00:52,  2.89it/s] 70%|███████   | 351/500 [04:17<02:57,  1.19s/it] 71%|███████   | 353/500 [04:17<02:06,  1.16it/s] 71%|███████   | 355/500 [04:17<01:30,  1.60it/s] 71%|███████▏  | 357/500 [04:18<01:05,  2.18it/s] 72%|███████▏  | 359/500 [04:18<00:48,  2.91it/s] 72%|███████▏  | 361/500 [04:24<02:51,  1.23s/it] 73%|███████▎  | 363/500 [04:24<02:01,  1.13it/s] 73%|███████▎  | 365/500 [04:25<01:26,  1.56it/s] 73%|███████▎  | 367/500 [04:25<01:02,  2.12it/s] 74%|███████▍  | 369/500 [04:25<00:46,  2.82it/s] 74%|███████▍  | 371/500 [04:32<02:40,  1.25s/it] 75%|███████▍  | 373/500 [04:32<01:54,  1.11it/s] 75%|███████▌  | 375/500 [04:32<01:21,  1.53it/s] 75%|███████▌  | 377/500 [04:32<00:58,  2.10it/s] 76%|███████▌  | 379/500 [04:32<00:42,  2.83it/s] 76%|███████▌  | 381/500 [04:39<02:25,  1.23s/it] 77%|███████▋  | 383/500 [04:39<01:43,  1.13it/s] 77%|███████▋  | 385/500 [04:39<01:13,  1.57it/s] 77%|███████▋  | 387/500 [04:39<00:52,  2.15it/s] 78%|███████▊  | 389/500 [04:39<00:38,  2.89it/s] 78%|███████▊  | 391/500 [04:46<02:10,  1.20s/it] 79%|███████▊  | 393/500 [04:46<01:32,  1.16it/s] 79%|███████▉  | 395/500 [04:46<01:05,  1.61it/s] 79%|███████▉  | 397/500 [04:46<00:46,  2.20it/s] 80%|███████▉  | 399/500 [04:46<00:34,  2.96it/s] 80%|████████  | 401/500 [04:53<01:59,  1.21s/it] 81%|████████  | 403/500 [04:53<01:24,  1.15it/s] 81%|████████  | 405/500 [04:53<01:00,  1.57it/s]Epoch:  339  	Training Loss: 0.0002152770757675171
Test Loss:  0.00010440163168823346
Valid Loss:  0.000256045488640666
Epoch:  340  	Training Loss: 0.000214667699765414
Test Loss:  0.00010415214637760073
Valid Loss:  0.0002552892838139087
Epoch:  341  	Training Loss: 0.00021404634753707796
Test Loss:  0.00010389652743469924
Valid Loss:  0.000254565296927467
Epoch:  342  	Training Loss: 0.00021341680258046836
Test Loss:  0.00010321295849280432
Valid Loss:  0.0002535871462896466
Epoch:  343  	Training Loss: 0.00021298749197740108
Test Loss:  0.00010302222653990611
Valid Loss:  0.0002533766091801226
Epoch:  344  	Training Loss: 0.00021259798086248338
Test Loss:  0.00010281098366249353
Valid Loss:  0.00025313341757282615
Epoch:  345  	Training Loss: 0.0002122069417964667
Test Loss:  0.00010259952250635251
Valid Loss:  0.00025288175675086677
Epoch:  346  	Training Loss: 0.0002118202392011881
Test Loss:  0.00010238963295705616
Valid Loss:  0.00025262965937145054
Epoch:  347  	Training Loss: 0.00021143378398846835
Test Loss:  0.00010218006354989484
Valid Loss:  0.0002523732837289572
Epoch:  348  	Training Loss: 0.00021104574261698872
Test Loss:  0.00010196947550866753
Valid Loss:  0.0002521093701943755
Epoch:  349  	Training Loss: 0.00021065885084681213
Test Loss:  0.00010176043724641204
Valid Loss:  0.00025184228434227407
Epoch:  350  	Training Loss: 0.00021027348702773452
Test Loss:  0.00010155462950933725
Valid Loss:  0.00025157202617265284
Epoch:  351  	Training Loss: 0.00020989190670661628
Test Loss:  0.00010134962940355763
Valid Loss:  0.00025129460846073925
Epoch:  352  	Training Loss: 0.00020951451733708382
Test Loss:  0.00010091801959788427
Valid Loss:  0.0002508140751160681
Epoch:  353  	Training Loss: 0.00020893651526421309
Test Loss:  0.00010055944585474208
Valid Loss:  0.0002504295844119042
Epoch:  354  	Training Loss: 0.00020837297779507935
Test Loss:  0.00010029586701421067
Valid Loss:  0.0002501830749679357
Epoch:  355  	Training Loss: 0.00020786048844456673
Test Loss:  9.998284804169089e-05
Valid Loss:  0.00024983391631394625
Epoch:  356  	Training Loss: 0.00020736506849061698
Test Loss:  9.965068602468818e-05
Valid Loss:  0.00024943414609879255
Epoch:  357  	Training Loss: 0.00020687669166363776
Test Loss:  9.933608816936612e-05
Valid Loss:  0.00024904636666178703
Epoch:  358  	Training Loss: 0.00020639401918742806
Test Loss:  9.902710735332221e-05
Valid Loss:  0.0002486499724909663
Epoch:  359  	Training Loss: 0.0002059143444057554
Test Loss:  9.872189548332244e-05
Valid Loss:  0.00024824446882121265
Epoch:  360  	Training Loss: 0.00020543581922538579
Test Loss:  9.842678264249116e-05
Valid Loss:  0.00024784269044175744
Epoch:  361  	Training Loss: 0.00020496190700214356
Test Loss:  9.813611541176215e-05
Valid Loss:  0.00024743680842220783
Epoch:  362  	Training Loss: 0.00020449268049560487
Test Loss:  9.807021706365049e-05
Valid Loss:  0.0002471907646395266
Epoch:  363  	Training Loss: 0.00020395239698700607
Test Loss:  9.786214650375769e-05
Valid Loss:  0.00024674442829564214
Epoch:  364  	Training Loss: 0.0002034334174823016
Test Loss:  9.765238064574078e-05
Valid Loss:  0.00024627638049423695
Epoch:  365  	Training Loss: 0.00020292231056373566
Test Loss:  9.744829731062055e-05
Valid Loss:  0.0002458045491948724
Epoch:  366  	Training Loss: 0.00020242018217686564
Test Loss:  9.725806739879772e-05
Valid Loss:  0.0002453317283652723
Epoch:  367  	Training Loss: 0.0002019262610701844
Test Loss:  9.70727123785764e-05
Valid Loss:  0.00024488105555064976
Epoch:  368  	Training Loss: 0.0002014356286963448
Test Loss:  9.689025318948552e-05
Valid Loss:  0.00024442237918265164
Epoch:  369  	Training Loss: 0.00020095356740057468
Test Loss:  9.670255531091243e-05
Valid Loss:  0.0002439609816065058
Epoch:  370  	Training Loss: 0.00020047687576152384
Test Loss:  9.652592416387051e-05
Valid Loss:  0.00024350278545171022
Epoch:  371  	Training Loss: 0.0002000055683311075
Test Loss:  9.63433412835002e-05
Valid Loss:  0.0002430485765216872
Epoch:  372  	Training Loss: 0.0001995398197323084
Test Loss:  9.605361992726102e-05
Valid Loss:  0.00024237591424025595
Epoch:  373  	Training Loss: 0.0001991614990402013
Test Loss:  9.593412687536329e-05
Valid Loss:  0.00024196377489715815
Epoch:  374  	Training Loss: 0.0001987951691262424
Test Loss:  9.582156053511426e-05
Valid Loss:  0.00024157132429536432
Epoch:  375  	Training Loss: 0.00019843291374854743
Test Loss:  9.570896509103477e-05
Valid Loss:  0.00024118871078826487
Epoch:  376  	Training Loss: 0.00019807287026196718
Test Loss:  9.55941213760525e-05
Valid Loss:  0.00024080942966975272
Epoch:  377  	Training Loss: 0.00019771067309193313
Test Loss:  9.548035450279713e-05
Valid Loss:  0.00024043821031227708
Epoch:  378  	Training Loss: 0.00019735173555091023
Test Loss:  9.536659490549937e-05
Valid Loss:  0.00024007429601624608
Epoch:  379  	Training Loss: 0.00019699618860613555
Test Loss:  9.525333007331938e-05
Valid Loss:  0.00023971548944246024
Epoch:  380  	Training Loss: 0.00019664381397888064
Test Loss:  9.514034900348634e-05
Valid Loss:  0.0002393621252849698
Epoch:  381  	Training Loss: 0.00019629432063084096
Test Loss:  9.502770262770355e-05
Valid Loss:  0.00023901429085526615
Epoch:  382  	Training Loss: 0.00019594762125052512
Test Loss:  9.518175647826865e-05
Valid Loss:  0.00023939323727972806
Epoch:  383  	Training Loss: 0.00019579095533117652
Test Loss:  9.526676876703277e-05
Valid Loss:  0.0002395697811152786
Epoch:  384  	Training Loss: 0.00019569951109588146
Test Loss:  9.530357783660293e-05
Valid Loss:  0.0002396358031546697
Epoch:  385  	Training Loss: 0.00019562733359634876
Test Loss:  9.531083924230188e-05
Valid Loss:  0.00023963945568539202
Epoch:  386  	Training Loss: 0.00019556173356249928
Test Loss:  9.529900853522122e-05
Valid Loss:  0.00023960554972290993
Epoch:  387  	Training Loss: 0.00019549825810827315
Test Loss:  9.527067595627159e-05
Valid Loss:  0.0002395377232460305
Epoch:  388  	Training Loss: 0.00019543690723367035
Test Loss:  9.523687913315371e-05
Valid Loss:  0.00023945767316035926
Epoch:  389  	Training Loss: 0.00019537561456672847
Test Loss:  9.51999390963465e-05
Valid Loss:  0.00023937059449963272
Epoch:  390  	Training Loss: 0.00019531497673597187
Test Loss:  9.515820420347154e-05
Valid Loss:  0.0002392703026998788
Epoch:  391  	Training Loss: 0.00019525438256096095
Test Loss:  9.51168840401806e-05
Valid Loss:  0.00023917076759971678
Epoch:  392  	Training Loss: 0.00019519435591064394
Test Loss:  9.386984311277047e-05
Valid Loss:  0.00023723908816464245
Epoch:  393  	Training Loss: 0.00019461338524706662
Test Loss:  9.39017190830782e-05
Valid Loss:  0.00023753021378070116
Epoch:  394  	Training Loss: 0.00019410914683248848
Test Loss:  9.342924022348598e-05
Valid Loss:  0.00023688348301220685
Epoch:  395  	Training Loss: 0.00019362621242180467
Test Loss:  9.320135723100975e-05
Valid Loss:  0.00023665631306357682
Epoch:  396  	Training Loss: 0.00019315547251608223
Test Loss:  9.289069566875696e-05
Valid Loss:  0.0002362482773605734
Epoch:  397  	Training Loss: 0.00019269605400040746
Test Loss:  9.26386856008321e-05
Valid Loss:  0.00023592360957991332
Epoch:  398  	Training Loss: 0.0001922491646837443
Test Loss:  9.237771155312657e-05
Valid Loss:  0.00023556177620775998
Epoch:  399  	Training Loss: 0.00019181141396984458
Test Loss:  9.213194425683469e-05
Valid Loss:  0.0002352171577513218
Epoch:  400  	Training Loss: 0.0001913829182740301
Test Loss:  9.188996773445979e-05
Valid Loss:  0.00023486674763262272
Epoch:  401  	Training Loss: 0.00019096209143754095
Test Loss:  9.16663120733574e-05
Valid Loss:  0.0002345275424886495
Epoch:  402  	Training Loss: 0.00019055907614529133
Test Loss:  9.193246660288423e-05
Valid Loss:  0.00023445958504453301
Epoch:  403  	Training Loss: 0.00019009914831258357
Test Loss:  9.209625568473712e-05
Valid Loss:  0.00023430053261108696
Epoch:  404  	Training Loss: 0.00018974830163642764
Test Loss:  9.217956539941952e-05
Valid Loss:  0.0002340828941669315
Epoch:  405  	Training Loss: 0.0001894347369670868
Test Loss:  9.221109212376177e-05
Valid Loss:  0.0002338402991881594
Epoch:  406  	Training Loss: 0.00018913784879259765
 81%|████████▏ | 407/500 [04:53<00:43,  2.13it/s] 82%|████████▏ | 409/500 [04:53<00:32,  2.81it/s] 82%|████████▏ | 411/500 [05:00<01:49,  1.23s/it] 83%|████████▎ | 413/500 [05:00<01:17,  1.13it/s] 83%|████████▎ | 415/500 [05:00<00:54,  1.56it/s] 83%|████████▎ | 417/500 [05:00<00:38,  2.14it/s] 84%|████████▍ | 419/500 [05:00<00:28,  2.89it/s] 84%|████████▍ | 421/500 [05:07<01:33,  1.19s/it] 85%|████████▍ | 423/500 [05:07<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:07<00:46,  1.62it/s] 85%|████████▌ | 427/500 [05:07<00:33,  2.21it/s] 86%|████████▌ | 429/500 [05:07<00:23,  2.97it/s] 86%|████████▌ | 431/500 [05:14<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:14<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:14<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:14<00:28,  2.23it/s] 88%|████████▊ | 439/500 [05:14<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:21<01:11,  1.21s/it] 89%|████████▊ | 443/500 [05:21<00:49,  1.15it/s] 89%|████████▉ | 445/500 [05:21<00:34,  1.58it/s] 89%|████████▉ | 447/500 [05:21<00:24,  2.16it/s] 90%|████████▉ | 449/500 [05:21<00:17,  2.91it/s] 90%|█████████ | 451/500 [05:28<00:58,  1.20s/it] 91%|█████████ | 453/500 [05:28<00:40,  1.16it/s] 91%|█████████ | 455/500 [05:28<00:28,  1.60it/s] 91%|█████████▏| 457/500 [05:28<00:19,  2.18it/s] 92%|█████████▏| 459/500 [05:28<00:14,  2.93it/s] 92%|█████████▏| 461/500 [05:35<00:47,  1.21s/it] 93%|█████████▎| 463/500 [05:35<00:32,  1.16it/s] 93%|█████████▎| 465/500 [05:35<00:21,  1.60it/s] 93%|█████████▎| 467/500 [05:35<00:15,  2.18it/s] 94%|█████████▍| 469/500 [05:35<00:10,  2.94it/s] 94%|█████████▍| 471/500 [05:42<00:34,  1.20s/it]Test Loss:  9.221026266459376e-05
Valid Loss:  0.000233592523727566
Epoch:  407  	Training Loss: 0.0001888514234451577
Test Loss:  9.218892955686897e-05
Valid Loss:  0.00023334837169386446
Epoch:  408  	Training Loss: 0.00018857218674384058
Test Loss:  9.215415047947317e-05
Valid Loss:  0.00023311178665608168
Epoch:  409  	Training Loss: 0.00018829776672646403
Test Loss:  9.211043652612716e-05
Valid Loss:  0.00023288390366360545
Epoch:  410  	Training Loss: 0.00018802814884111285
Test Loss:  9.206005779560655e-05
Valid Loss:  0.0002326636458747089
Epoch:  411  	Training Loss: 0.00018776231445372105
Test Loss:  9.200749627780169e-05
Valid Loss:  0.0002324516826774925
Epoch:  412  	Training Loss: 0.00018750027811620384
Test Loss:  9.139507892541587e-05
Valid Loss:  0.00023142798454500735
Epoch:  413  	Training Loss: 0.00018716361955739558
Test Loss:  9.118845628108829e-05
Valid Loss:  0.00023088636226020753
Epoch:  414  	Training Loss: 0.00018688017735257745
Test Loss:  9.103609045268968e-05
Valid Loss:  0.0002304186491528526
Epoch:  415  	Training Loss: 0.00018660066416487098
Test Loss:  9.089089871849865e-05
Valid Loss:  0.00022996753978077322
Epoch:  416  	Training Loss: 0.00018632455612532794
Test Loss:  9.074686386156827e-05
Valid Loss:  0.0002295268641319126
Epoch:  417  	Training Loss: 0.00018605138757266104
Test Loss:  9.060141746886075e-05
Valid Loss:  0.00022908876417204738
Epoch:  418  	Training Loss: 0.00018578325398266315
Test Loss:  9.046043851412833e-05
Valid Loss:  0.0002286576054757461
Epoch:  419  	Training Loss: 0.00018551808898337185
Test Loss:  9.031999798025936e-05
Valid Loss:  0.00022823482868261635
Epoch:  420  	Training Loss: 0.00018525478662922978
Test Loss:  9.017939737532288e-05
Valid Loss:  0.00022781672305427492
Epoch:  421  	Training Loss: 0.00018499344878364354
Test Loss:  9.003789455164224e-05
Valid Loss:  0.0002274060097988695
Epoch:  422  	Training Loss: 0.00018473516684025526
Test Loss:  8.96422570804134e-05
Valid Loss:  0.0002267313830088824
Epoch:  423  	Training Loss: 0.00018419732805341482
Test Loss:  8.936374797485769e-05
Valid Loss:  0.00022619082301389426
Epoch:  424  	Training Loss: 0.0001836648298194632
Test Loss:  8.907537267077714e-05
Valid Loss:  0.00022561498917639256
Epoch:  425  	Training Loss: 0.00018312648171558976
Test Loss:  8.858579531079158e-05
Valid Loss:  0.0002247951051685959
Epoch:  426  	Training Loss: 0.0001823879429139197
Test Loss:  8.707348752068356e-05
Valid Loss:  0.0002227399090770632
Epoch:  427  	Training Loss: 0.00018040961003862321
Test Loss:  8.626126509625465e-05
Valid Loss:  0.00022163509856909513
Epoch:  428  	Training Loss: 0.0001787349465303123
Test Loss:  8.640897431178018e-05
Valid Loss:  0.00022144420654512942
Epoch:  429  	Training Loss: 0.00017814835882745683
Test Loss:  8.627819624962285e-05
Valid Loss:  0.00022081143106333911
Epoch:  430  	Training Loss: 0.00017764416406862438
Test Loss:  8.612157398601994e-05
Valid Loss:  0.0002201729512307793
Epoch:  431  	Training Loss: 0.00017714223940856755
Test Loss:  8.592839003540576e-05
Valid Loss:  0.00021952544921077788
Epoch:  432  	Training Loss: 0.00017663161270320415
Test Loss:  8.526515011908486e-05
Valid Loss:  0.00021811369515489787
Epoch:  433  	Training Loss: 0.00017605470202397555
Test Loss:  8.527704630978405e-05
Valid Loss:  0.00021773968182969838
Epoch:  434  	Training Loss: 0.00017548749747220427
Test Loss:  8.470869215670973e-05
Valid Loss:  0.00021647951507475227
Epoch:  435  	Training Loss: 0.00017492545885033906
Test Loss:  8.461817924398929e-05
Valid Loss:  0.0002159935684176162
Epoch:  436  	Training Loss: 0.00017436646157875657
Test Loss:  8.410281589021906e-05
Valid Loss:  0.0002148672501789406
Epoch:  437  	Training Loss: 0.00017381133511662483
Test Loss:  8.396004704991356e-05
Valid Loss:  0.00021430493507068604
Epoch:  438  	Training Loss: 0.00017326064698863775
Test Loss:  8.350519055966288e-05
Valid Loss:  0.00021326202841009945
Epoch:  439  	Training Loss: 0.0001727171038510278
Test Loss:  8.334332960657775e-05
Valid Loss:  0.00021263402595650405
Epoch:  440  	Training Loss: 0.00017218453285750002
Test Loss:  8.29571217764169e-05
Valid Loss:  0.00021164698409847915
Epoch:  441  	Training Loss: 0.00017166297766380012
Test Loss:  8.280436304630712e-05
Valid Loss:  0.00021099703735671937
Epoch:  442  	Training Loss: 0.00017114984802901745
Test Loss:  8.279191388282925e-05
Valid Loss:  0.00021056656260043383
Epoch:  443  	Training Loss: 0.00017082229896914214
Test Loss:  8.270485704997554e-05
Valid Loss:  0.000210079102544114
Epoch:  444  	Training Loss: 0.0001704994065221399
Test Loss:  8.260340837296098e-05
Valid Loss:  0.0002096024836646393
Epoch:  445  	Training Loss: 0.000170182524016127
Test Loss:  8.249490201706067e-05
Valid Loss:  0.00020914328342769295
Epoch:  446  	Training Loss: 0.00016986999253276736
Test Loss:  8.238024020101875e-05
Valid Loss:  0.00020869958098046482
Epoch:  447  	Training Loss: 0.0001695615064818412
Test Loss:  8.226052159443498e-05
Valid Loss:  0.00020826971740461886
Epoch:  448  	Training Loss: 0.000169256585650146
Test Loss:  8.213764522224665e-05
Valid Loss:  0.00020785181550309062
Epoch:  449  	Training Loss: 0.00016895390581339598
Test Loss:  8.201364107662812e-05
Valid Loss:  0.0002074437798000872
Epoch:  450  	Training Loss: 0.0001686540199443698
Test Loss:  8.18847693153657e-05
Valid Loss:  0.00020704473718069494
Epoch:  451  	Training Loss: 0.0001683553564362228
Test Loss:  8.175225229933858e-05
Valid Loss:  0.0002066560264211148
Epoch:  452  	Training Loss: 0.00016805835184641182
Test Loss:  8.14771992736496e-05
Valid Loss:  0.00020606655743904412
Epoch:  453  	Training Loss: 0.00016766437329351902
Test Loss:  8.132199582178146e-05
Valid Loss:  0.00020564207807183266
Epoch:  454  	Training Loss: 0.0001672795624472201
Test Loss:  8.117759716697037e-05
Valid Loss:  0.0002052435593213886
Epoch:  455  	Training Loss: 0.00016689894255250692
Test Loss:  8.103220898192376e-05
Valid Loss:  0.0002048541500698775
Epoch:  456  	Training Loss: 0.00016652181511744857
Test Loss:  8.088573667919263e-05
Valid Loss:  0.00020446849521249533
Epoch:  457  	Training Loss: 0.00016615146887488663
Test Loss:  8.074035577010363e-05
Valid Loss:  0.00020409336138982326
Epoch:  458  	Training Loss: 0.00016578460054006428
Test Loss:  8.059405081439763e-05
Valid Loss:  0.00020372406288515776
Epoch:  459  	Training Loss: 0.00016542142839170992
Test Loss:  8.044712740229443e-05
Valid Loss:  0.00020336156012490392
Epoch:  460  	Training Loss: 0.00016506097745150328
Test Loss:  8.030033495742828e-05
Valid Loss:  0.00020301190670579672
Epoch:  461  	Training Loss: 0.00016470416449010372
Test Loss:  8.014976629056036e-05
Valid Loss:  0.00020266653154976666
Epoch:  462  	Training Loss: 0.00016435046563856304
Test Loss:  7.971920422278345e-05
Valid Loss:  0.00020205997861921787
Epoch:  463  	Training Loss: 0.00016402354231104255
Test Loss:  7.962064410094172e-05
Valid Loss:  0.00020175514509901404
Epoch:  464  	Training Loss: 0.00016375925042666495
Test Loss:  7.952288433443755e-05
Valid Loss:  0.00020143187430221587
Epoch:  465  	Training Loss: 0.00016352444072254002
Test Loss:  7.946938421810046e-05
Valid Loss:  0.00020111844060011208
Epoch:  466  	Training Loss: 0.0001633047650102526
Test Loss:  7.939778151921928e-05
Valid Loss:  0.00020080056856386364
Epoch:  467  	Training Loss: 0.0001630878250580281
Test Loss:  7.935407484183088e-05
Valid Loss:  0.0002005018905038014
Epoch:  468  	Training Loss: 0.00016287420294247568
Test Loss:  7.927873230073601e-05
Valid Loss:  0.00020019870135001838
Epoch:  469  	Training Loss: 0.0001626614248380065
Test Loss:  7.9218196333386e-05
Valid Loss:  0.0001999126106966287
Epoch:  470  	Training Loss: 0.0001624509459361434
Test Loss:  7.913258741609752e-05
Valid Loss:  0.00019962387159466743
Epoch:  471  	Training Loss: 0.0001622413838049397
Test Loss:  7.906502287369221e-05
Valid Loss:  0.000199352580239065
Epoch:  472  	Training Loss: 0.00016203266568481922
Test Loss:  7.917215407360345e-05
Valid Loss:  0.00019965411047451198
Epoch:  473  	Training Loss: 0.00016178080113604665
Test Loss:  7.895602902863175e-05
Valid Loss:   95%|█████████▍| 473/500 [05:42<00:23,  1.16it/s] 95%|█████████▌| 475/500 [05:42<00:15,  1.60it/s] 95%|█████████▌| 477/500 [05:42<00:10,  2.19it/s] 96%|█████████▌| 479/500 [05:42<00:07,  2.94it/s] 96%|█████████▌| 481/500 [05:49<00:22,  1.21s/it] 97%|█████████▋| 483/500 [05:49<00:14,  1.15it/s] 97%|█████████▋| 485/500 [05:49<00:09,  1.59it/s] 97%|█████████▋| 487/500 [05:49<00:05,  2.18it/s] 98%|█████████▊| 489/500 [05:49<00:03,  2.94it/s] 98%|█████████▊| 491/500 [05:56<00:10,  1.20s/it] 99%|█████████▊| 493/500 [05:56<00:06,  1.15it/s] 99%|█████████▉| 495/500 [05:56<00:03,  1.59it/s] 99%|█████████▉| 497/500 [05:56<00:01,  2.17it/s]100%|█████████▉| 499/500 [05:56<00:00,  2.92it/s]100%|██████████| 500/500 [05:56<00:00,  1.40it/s]
0.00019945960957556963
Epoch:  474  	Training Loss: 0.00016158793005160987
Test Loss:  7.874873699620366e-05
Valid Loss:  0.00019921507919207215
Epoch:  475  	Training Loss: 0.0001614091161172837
Test Loss:  7.858400203986093e-05
Valid Loss:  0.00019897377933375537
Epoch:  476  	Training Loss: 0.00016123824752867222
Test Loss:  7.843581261113286e-05
Valid Loss:  0.00019872438861057162
Epoch:  477  	Training Loss: 0.00016107194824144244
Test Loss:  7.830183312762529e-05
Valid Loss:  0.00019846876966767013
Epoch:  478  	Training Loss: 0.00016090940334834158
Test Loss:  7.817935693310574e-05
Valid Loss:  0.00019821403839159757
Epoch:  479  	Training Loss: 0.0001607501762919128
Test Loss:  7.806648500263691e-05
Valid Loss:  0.00019795533444266766
Epoch:  480  	Training Loss: 0.00016059321933425963
Test Loss:  7.796184945618734e-05
Valid Loss:  0.00019769417122006416
Epoch:  481  	Training Loss: 0.00016043893992900848
Test Loss:  7.78639514464885e-05
Valid Loss:  0.0001974364131456241
Epoch:  482  	Training Loss: 0.00016028658137656748
Test Loss:  7.738736167084426e-05
Valid Loss:  0.00019655836513265967
Epoch:  483  	Training Loss: 0.00016004660574253649
Test Loss:  7.73835345171392e-05
Valid Loss:  0.00019625872664619237
Epoch:  484  	Training Loss: 0.0001598490634933114
Test Loss:  7.737208215985447e-05
Valid Loss:  0.00019596811034716666
Epoch:  485  	Training Loss: 0.0001596567453816533
Test Loss:  7.735814870102331e-05
Valid Loss:  0.000195689732208848
Epoch:  486  	Training Loss: 0.00015946938947308809
Test Loss:  7.73407518863678e-05
Valid Loss:  0.00019542120571713895
Epoch:  487  	Training Loss: 0.00015928599168546498
Test Loss:  7.732109224889427e-05
Valid Loss:  0.00019516239990480244
Epoch:  488  	Training Loss: 0.00015910515503492206
Test Loss:  7.729890057817101e-05
Valid Loss:  0.00019491268903948367
Epoch:  489  	Training Loss: 0.0001589269086252898
Test Loss:  7.72743223933503e-05
Valid Loss:  0.00019467157835606486
Epoch:  490  	Training Loss: 0.00015875097597017884
Test Loss:  7.724572787992656e-05
Valid Loss:  0.00019443484779912978
Epoch:  491  	Training Loss: 0.0001585767895448953
Test Loss:  7.721720612607896e-05
Valid Loss:  0.00019420782336965203
Epoch:  492  	Training Loss: 0.00015840445121284574
Test Loss:  7.746565097477287e-05
Valid Loss:  0.00019397902360651642
Epoch:  493  	Training Loss: 0.00015815807273611426
Test Loss:  7.738414569757879e-05
Valid Loss:  0.00019349504145793617
Epoch:  494  	Training Loss: 0.00015792023623362184
Test Loss:  7.743434980511665e-05
Valid Loss:  0.00019318262638989836
Epoch:  495  	Training Loss: 0.00015768330194987357
Test Loss:  7.740050932625309e-05
Valid Loss:  0.00019282233552075922
Epoch:  496  	Training Loss: 0.00015744879783596843
Test Loss:  7.739193097222596e-05
Valid Loss:  0.00019251115736551583
Epoch:  497  	Training Loss: 0.00015721676754765213
Test Loss:  7.736129919067025e-05
Valid Loss:  0.00019219961541239172
Epoch:  498  	Training Loss: 0.00015698633797001094
Test Loss:  7.733437087154016e-05
Valid Loss:  0.0001919130008900538
Epoch:  499  	Training Loss: 0.00015675237227696925
Test Loss:  7.727790216449648e-05
Valid Loss:  0.0001916217734105885
Epoch:  500  	Training Loss: 0.00015651964349672198
Test Loss:  7.722468581050634e-05
Valid Loss:  0.00019134333706460893
seed is  12
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.28it/s]  1%|          | 4/500 [00:00<00:30, 16.33it/s]  1%|          | 6/500 [00:00<00:30, 16.34it/s]  2%|▏         | 8/500 [00:00<00:30, 16.35it/s]  2%|▏         | 10/500 [00:00<00:30, 16.19it/s]  2%|▏         | 12/500 [00:00<00:29, 16.27it/s]  3%|▎         | 14/500 [00:00<00:29, 16.39it/s]  3%|▎         | 16/500 [00:00<00:29, 16.40it/s]  4%|▎         | 18/500 [00:01<00:29, 16.45it/s]  4%|▍         | 20/500 [00:01<00:29, 16.41it/s]  4%|▍         | 22/500 [00:01<00:29, 16.37it/s]  5%|▍         | 24/500 [00:01<00:29, 16.38it/s]  5%|▌         | 26/500 [00:01<00:28, 16.52it/s]  6%|▌         | 28/500 [00:01<00:28, 16.47it/s]  6%|▌         | 30/500 [00:01<00:28, 16.44it/s]  6%|▋         | 32/500 [00:01<00:28, 16.48it/s]  7%|▋         | 34/500 [00:02<00:28, 16.38it/s]  7%|▋         | 36/500 [00:02<00:28, 16.50it/s]  8%|▊         | 38/500 [00:02<00:28, 16.28it/s]  8%|▊         | 40/500 [00:02<00:28, 16.17it/s]  8%|▊         | 42/500 [00:02<00:28, 16.09it/s]  9%|▉         | 44/500 [00:02<00:28, 16.13it/s]  9%|▉         | 46/500 [00:02<00:27, 16.26it/s] 10%|▉         | 48/500 [00:02<00:27, 16.17it/s] 10%|█         | 50/500 [00:03<00:27, 16.29it/s] 10%|█         | 52/500 [00:03<00:27, 16.22it/s] 11%|█         | 54/500 [00:03<00:27, 16.18it/s] 11%|█         | 56/500 [00:03<00:27, 16.18it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.20it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.18it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.29it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.32it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.35it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.37it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.38it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.30it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.21it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.21it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.25it/s] 16%|█▌        | 80/500 [00:04<00:26, 16.10it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.13it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.20it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.19it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.21it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.24it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.24it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.26it/s] 19%|█▉        | 96/500 [00:05<00:25, 16.10it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.16it/s] 20%|██        | 100/500 [00:06<00:24, 16.22it/s] 20%|██        | 102/500 [00:06<00:24, 16.32it/s] 21%|██        | 104/500 [00:06<00:24, 16.36it/s] 21%|██        | 106/500 [00:06<00:24, 16.38it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.47it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.47it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.49it/s] 23%|██▎       | 114/500 [00:06<00:23, 16.28it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.33it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.31it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.38it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.41it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.26it/s]Epoch:  1  	Training Loss: 0.15179064869880676
Test Loss:  3992.54248046875
Valid Loss:  3984.0146484375
Epoch:  2  	Training Loss: 4055.254638671875
Test Loss:  1.5628050255314944e+16
Valid Loss:  1.5634682758561792e+16
Epoch:  3  	Training Loss: 1.5679452423913472e+16
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.29it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.38it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.37it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.32it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.35it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.31it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.23it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.20it/s] 28%|██▊       | 142/500 [00:08<00:22, 16.23it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.33it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.39it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.31it/s] 30%|███       | 150/500 [00:09<00:21, 15.95it/s] 30%|███       | 152/500 [00:09<00:22, 15.58it/s] 31%|███       | 154/500 [00:09<00:21, 15.84it/s] 31%|███       | 156/500 [00:09<00:21, 15.89it/s] 32%|███▏      | 158/500 [00:09<00:21, 15.79it/s] 32%|███▏      | 160/500 [00:09<00:21, 15.71it/s] 32%|███▏      | 162/500 [00:09<00:21, 15.44it/s] 33%|███▎      | 164/500 [00:10<00:21, 15.56it/s] 33%|███▎      | 166/500 [00:10<00:21, 15.61it/s] 34%|███▎      | 168/500 [00:10<00:21, 15.78it/s] 34%|███▍      | 170/500 [00:10<00:20, 15.97it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.15it/s] 35%|███▍      | 174/500 [00:10<00:20, 16.22it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.27it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.32it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.37it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.37it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.24it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.15it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.08it/s] 38%|███▊      | 190/500 [00:11<00:19, 16.21it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.22it/s] 39%|███▉      | 194/500 [00:11<00:19, 16.10it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.05it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.19it/s] 40%|████      | 200/500 [00:12<00:18, 16.27it/s] 40%|████      | 202/500 [00:12<00:18, 16.35it/s] 41%|████      | 204/500 [00:12<00:18, 16.27it/s] 41%|████      | 206/500 [00:12<00:17, 16.33it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.34it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.29it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.07it/s] 43%|████▎     | 214/500 [00:13<00:19, 14.72it/s] 43%|████▎     | 216/500 [00:13<00:20, 13.90it/s] 44%|████▎     | 218/500 [00:13<00:21, 13.39it/s] 44%|████▍     | 220/500 [00:13<00:21, 13.03it/s] 44%|████▍     | 222/500 [00:13<00:21, 12.79it/s] 45%|████▍     | 224/500 [00:14<00:20, 13.32it/s] 45%|████▌     | 226/500 [00:14<00:19, 14.17it/s] 46%|████▌     | 228/500 [00:14<00:18, 14.79it/s] 46%|████▌     | 230/500 [00:14<00:17, 15.18it/s] 46%|████▋     | 232/500 [00:14<00:17, 15.58it/s] 47%|████▋     | 234/500 [00:14<00:16, 15.82it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.00it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.18it/s] 48%|████▊     | 240/500 [00:14<00:16, 16.24it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.31it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.34it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.38it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.40it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.33it/s] 50%|█████     | 252/500 [00:15<00:15, 16.17it/s] 51%|█████     | 254/500 [00:15<00:15, 16.23it/s] 51%|█████     | 256/500 [00:15<00:14, 16.34it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.43it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.34it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.20it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.24it/s] 53%|█████▎    | 266/500 [00:16<00:14, 15.99it/s] 54%|█████▎    | 268/500 [00:16<00:14, 15.86it/s] 54%|█████▍    | 270/500 [00:16<00:15, 14.90it/s] 54%|█████▍    | 272/500 [00:17<00:16, 13.95it/s] 55%|█████▍    | 274/500 [00:17<00:16, 13.45it/s] 55%|█████▌    | 276/500 [00:17<00:15, 14.03it/s] 56%|█████▌    | 278/500 [00:17<00:15, 14.69it/s] 56%|█████▌    | 280/500 [00:17<00:14, 15.19it/s] 56%|█████▋    | 282/500 [00:17<00:14, 15.18it/s] 57%|█████▋    | 284/500 [00:17<00:14, 15.39it/s] 57%|█████▋    | 286/500 [00:17<00:13, 15.60it/s] 58%|█████▊    | 288/500 [00:18<00:13, 15.85it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.96it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.07it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.23it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.36it/s] 60%|█████▉    | 298/500 [00:18<00:12, 15.97it/s] 60%|██████    | 300/500 [00:18<00:13, 14.87it/s] 60%|██████    | 302/500 [00:18<00:13, 15.20it/s] 61%|██████    | 304/500 [00:19<00:12, 15.56it/s] 61%|██████    | 306/500 [00:19<00:12, 15.84it/s] 62%|██████▏   | 308/500 [00:19<00:12, 16.00it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.10it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.25it/s] 63%|██████▎   | 314/500 [00:19<00:12, 15.22it/s] 63%|██████▎   | 316/500 [00:19<00:12, 14.16it/s] 64%|██████▎   | 318/500 [00:20<00:13, 13.55it/s] 64%|██████▍   | 320/500 [00:20<00:13, 13.74it/s] 64%|██████▍   | 322/500 [00:20<00:12, 14.41it/s] 65%|██████▍   | 324/500 [00:20<00:11, 15.02it/s] 65%|██████▌   | 326/500 [00:20<00:11, 15.45it/s] 66%|██████▌   | 328/500 [00:20<00:10, 15.73it/s] 66%|██████▌   | 330/500 [00:20<00:10, 15.84it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.06it/s] 67%|██████▋   | 334/500 [00:21<00:10, 16.10it/s] 67%|██████▋   | 336/500 [00:21<00:10, 16.25it/s] 68%|██████▊   | 338/500 [00:21<00:09, 16.35it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.26it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.34it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.23it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.29it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.36it/s] 70%|███████   | 350/500 [00:22<00:09, 16.32it/s] 70%|███████   | 352/500 [00:22<00:09, 16.23it/s] 71%|███████   | 354/500 [00:22<00:08, 16.31it/s] 71%|███████   | 356/500 [00:22<00:08, 16.35it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.08it/s] 72%|███████▏  | 360/500 [00:22<00:08, 15.68it/s] 72%|███████▏  | 362/500 [00:22<00:08, 15.81it/s] 73%|███████▎  | 364/500 [00:22<00:08, 15.85it/s] 73%|███████▎  | 366/500 [00:23<00:08, 16.02it/s] 74%|███████▎  | 368/500 [00:23<00:08, 15.77it/s] 74%|███████▍  | 370/500 [00:23<00:09, 14.44it/s] 74%|███████▍  | 372/500 [00:23<00:09, 13.68it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:09, 13.21it/s] 75%|███████▌  | 376/500 [00:23<00:09, 12.89it/s] 76%|███████▌  | 378/500 [00:23<00:09, 12.57it/s] 76%|███████▌  | 380/500 [00:24<00:09, 12.36it/s] 76%|███████▋  | 382/500 [00:24<00:09, 12.32it/s] 77%|███████▋  | 384/500 [00:24<00:09, 12.30it/s] 77%|███████▋  | 386/500 [00:24<00:09, 12.29it/s] 78%|███████▊  | 388/500 [00:24<00:09, 12.17it/s] 78%|███████▊  | 390/500 [00:24<00:09, 12.18it/s] 78%|███████▊  | 392/500 [00:25<00:08, 12.19it/s] 79%|███████▉  | 394/500 [00:25<00:08, 12.18it/s] 79%|███████▉  | 396/500 [00:25<00:08, 12.15it/s] 80%|███████▉  | 398/500 [00:25<00:08, 12.12it/s] 80%|████████  | 400/500 [00:25<00:08, 12.17it/s] 80%|████████  | 402/500 [00:25<00:07, 12.38it/s] 81%|████████  | 404/500 [00:26<00:07, 12.85it/s] 81%|████████  | 406/500 [00:26<00:06, 13.76it/s] 82%|████████▏ | 408/500 [00:26<00:06, 14.47it/s] 82%|████████▏ | 410/500 [00:26<00:06, 14.98it/s] 82%|████████▏ | 412/500 [00:26<00:05, 15.42it/s] 83%|████████▎ | 414/500 [00:26<00:05, 15.70it/s] 83%|████████▎ | 416/500 [00:26<00:05, 15.52it/s] 84%|████████▎ | 418/500 [00:26<00:05, 15.76it/s] 84%|████████▍ | 420/500 [00:27<00:05, 15.47it/s] 84%|████████▍ | 422/500 [00:27<00:05, 14.37it/s] 85%|████████▍ | 424/500 [00:27<00:05, 13.71it/s] 85%|████████▌ | 426/500 [00:27<00:05, 13.25it/s] 86%|████████▌ | 428/500 [00:27<00:05, 13.12it/s] 86%|████████▌ | 430/500 [00:27<00:05, 13.98it/s] 86%|████████▋ | 432/500 [00:27<00:04, 14.62it/s] 87%|████████▋ | 434/500 [00:28<00:04, 14.24it/s] 87%|████████▋ | 436/500 [00:28<00:04, 14.23it/s] 88%|████████▊ | 438/500 [00:28<00:04, 14.50it/s] 88%|████████▊ | 440/500 [00:28<00:04, 14.96it/s] 88%|████████▊ | 442/500 [00:28<00:03, 15.25it/s] 89%|████████▉ | 444/500 [00:28<00:03, 15.57it/s] 89%|████████▉ | 446/500 [00:28<00:03, 15.82it/s] 90%|████████▉ | 448/500 [00:29<00:03, 15.77it/s] 90%|█████████ | 450/500 [00:29<00:03, 15.37it/s] 90%|█████████ | 452/500 [00:29<00:03, 15.30it/s] 91%|█████████ | 454/500 [00:29<00:03, 14.44it/s] 91%|█████████ | 456/500 [00:29<00:02, 14.94it/s] 92%|█████████▏| 458/500 [00:29<00:02, 15.23it/s] 92%|█████████▏| 460/500 [00:29<00:02, 15.47it/s] 92%|█████████▏| 462/500 [00:29<00:02, 15.76it/s] 93%|█████████▎| 464/500 [00:30<00:02, 15.98it/s] 93%|█████████▎| 466/500 [00:30<00:02, 15.94it/s] 94%|█████████▎| 468/500 [00:30<00:01, 16.01it/s] 94%|█████████▍| 470/500 [00:30<00:01, 15.92it/s] 94%|█████████▍| 472/500 [00:30<00:01, 16.09it/s] 95%|█████████▍| 474/500 [00:30<00:01, 16.15it/s] 95%|█████████▌| 476/500 [00:30<00:01, 16.04it/s] 96%|█████████▌| 478/500 [00:30<00:01, 16.08it/s] 96%|█████████▌| 480/500 [00:31<00:01, 16.11it/s] 96%|█████████▋| 482/500 [00:31<00:01, 16.21it/s] 97%|█████████▋| 484/500 [00:31<00:00, 16.19it/s] 97%|█████████▋| 486/500 [00:31<00:00, 16.18it/s] 98%|█████████▊| 488/500 [00:31<00:00, 16.12it/s] 98%|█████████▊| 490/500 [00:31<00:00, 16.28it/s] 98%|█████████▊| 492/500 [00:31<00:00, 16.32it/s] 99%|█████████▉| 494/500 [00:31<00:00, 16.28it/s] 99%|█████████▉| 496/500 [00:32<00:00, 16.24it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:32<00:00, 15.82it/s]100%|██████████| 500/500 [00:32<00:00, 16.10it/s]100%|██████████| 500/500 [00:32<00:00, 15.48it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  12
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:08,  6.27s/it]  1%|          | 3/500 [00:06<13:54,  1.68s/it]  1%|          | 5/500 [00:06<07:00,  1.18it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:57,  1.34s/it]  3%|▎         | 13/500 [00:13<07:27,  1.09it/s]  3%|▎         | 15/500 [00:13<05:12,  1.55it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:42,  2.96it/s]  4%|▍         | 21/500 [00:20<09:45,  1.22s/it]  5%|▍         | 23/500 [00:20<06:55,  1.15it/s]  5%|▌         | 25/500 [00:20<04:57,  1.60it/s]  5%|▌         | 27/500 [00:20<03:35,  2.19it/s]  6%|▌         | 29/500 [00:20<02:39,  2.95it/s]  6%|▌         | 31/500 [00:26<09:12,  1.18s/it]  7%|▋         | 33/500 [00:27<06:36,  1.18it/s]  7%|▋         | 35/500 [00:27<04:45,  1.63it/s]  7%|▋         | 37/500 [00:27<03:28,  2.23it/s]  8%|▊         | 39/500 [00:27<02:34,  2.98it/s]  8%|▊         | 41/500 [00:33<09:11,  1.20s/it]  9%|▊         | 43/500 [00:34<06:33,  1.16it/s]  9%|▉         | 45/500 [00:34<04:43,  1.61it/s]  9%|▉         | 47/500 [00:34<03:26,  2.20it/s] 10%|▉         | 49/500 [00:34<02:32,  2.95it/s] 10%|█         | 51/500 [00:40<09:04,  1.21s/it] 11%|█         | 53/500 [00:41<06:30,  1.14it/s] 11%|█         | 55/500 [00:41<04:41,  1.58it/s] 11%|█▏        | 57/500 [00:41<03:24,  2.16it/s] 12%|█▏        | 59/500 [00:41<02:31,  2.91it/s] 12%|█▏        | 61/500 [00:48<09:06,  1.24s/it] 13%|█▎        | 63/500 [00:48<06:29,  1.12it/s] 13%|█▎        | 65/500 [00:48<04:40,  1.55it/s] 13%|█▎        | 67/500 [00:48<03:24,  2.12it/s] 14%|█▍        | 69/500 [00:48<02:31,  2.85it/s] 14%|█▍        | 71/500 [00:55<08:45,  1.22s/it] 15%|█▍        | 73/500 [00:55<06:14,  1.14it/s]Epoch:  1  	Training Loss: 0.15179064869880676
Test Loss:  6.79960298538208
Valid Loss:  6.790787696838379
Epoch:  2  	Training Loss: 6.92677640914917
Test Loss:  0.1780795305967331
Valid Loss:  0.18086546659469604
Epoch:  3  	Training Loss: 0.15116509795188904
Test Loss:  0.17804963886737823
Valid Loss:  0.1808350682258606
Epoch:  4  	Training Loss: 0.15113955736160278
Test Loss:  0.17801973223686218
Valid Loss:  0.18080466985702515
Epoch:  5  	Training Loss: 0.15111404657363892
Test Loss:  0.17798982560634613
Valid Loss:  0.1807742565870285
Epoch:  6  	Training Loss: 0.15108850598335266
Test Loss:  0.17795991897583008
Valid Loss:  0.18074384331703186
Epoch:  7  	Training Loss: 0.1510629653930664
Test Loss:  0.17792999744415283
Valid Loss:  0.18071341514587402
Epoch:  8  	Training Loss: 0.15103742480278015
Test Loss:  0.17790007591247559
Valid Loss:  0.1806829869747162
Epoch:  9  	Training Loss: 0.1510118693113327
Test Loss:  0.17787013947963715
Valid Loss:  0.18065254390239716
Epoch:  10  	Training Loss: 0.15098631381988525
Test Loss:  0.17784032225608826
Valid Loss:  0.18062275648117065
Epoch:  11  	Training Loss: 0.15096122026443481
Test Loss:  0.17781464755535126
Valid Loss:  0.18059617280960083
Epoch:  12  	Training Loss: 0.15093865990638733
Test Loss:  0.17780719697475433
Valid Loss:  0.18058806657791138
Epoch:  13  	Training Loss: 0.15093061327934265
Test Loss:  0.17780135571956635
Valid Loss:  0.18058225512504578
Epoch:  14  	Training Loss: 0.15092487633228302
Test Loss:  0.17779672145843506
Valid Loss:  0.1805778443813324
Epoch:  15  	Training Loss: 0.15092048048973083
Test Loss:  0.1777932345867157
Valid Loss:  0.18057432770729065
Epoch:  16  	Training Loss: 0.15091712772846222
Test Loss:  0.17779013514518738
Valid Loss:  0.18057124316692352
Epoch:  17  	Training Loss: 0.15091413259506226
Test Loss:  0.17778754234313965
Valid Loss:  0.1805683970451355
Epoch:  18  	Training Loss: 0.15091156959533691
Test Loss:  0.17778506875038147
Valid Loss:  0.18056580424308777
Epoch:  19  	Training Loss: 0.15090927481651306
Test Loss:  0.17778274416923523
Valid Loss:  0.1805633306503296
Epoch:  20  	Training Loss: 0.15090715885162354
Test Loss:  0.17778055369853973
Valid Loss:  0.18056103587150574
Epoch:  21  	Training Loss: 0.15090519189834595
Test Loss:  0.17777839303016663
Valid Loss:  0.18055883049964905
Epoch:  22  	Training Loss: 0.15090329945087433
Test Loss:  0.17777469754219055
Valid Loss:  0.180555060505867
Epoch:  23  	Training Loss: 0.15090005099773407
Test Loss:  0.17777101695537567
Valid Loss:  0.18055137991905212
Epoch:  24  	Training Loss: 0.1508968472480774
Test Loss:  0.17776735126972198
Valid Loss:  0.18054772913455963
Epoch:  25  	Training Loss: 0.1508936583995819
Test Loss:  0.1777636855840683
Valid Loss:  0.18054409325122833
Epoch:  26  	Training Loss: 0.15089051425457
Test Loss:  0.1777600795030594
Valid Loss:  0.18054044246673584
Epoch:  27  	Training Loss: 0.1508873701095581
Test Loss:  0.17775648832321167
Valid Loss:  0.18053680658340454
Epoch:  28  	Training Loss: 0.1508842259645462
Test Loss:  0.17775291204452515
Valid Loss:  0.18053318560123444
Epoch:  29  	Training Loss: 0.1508811116218567
Test Loss:  0.17774935066699982
Valid Loss:  0.18052956461906433
Epoch:  30  	Training Loss: 0.15087799727916718
Test Loss:  0.17774580419063568
Valid Loss:  0.18052595853805542
Epoch:  31  	Training Loss: 0.15087491273880005
Test Loss:  0.17774224281311035
Valid Loss:  0.1805223524570465
Epoch:  32  	Training Loss: 0.15087181329727173
Test Loss:  0.1777382791042328
Valid Loss:  0.18051831424236298
Epoch:  33  	Training Loss: 0.15086844563484192
Test Loss:  0.17773431539535522
Valid Loss:  0.18051427602767944
Epoch:  34  	Training Loss: 0.15086506307125092
Test Loss:  0.17773032188415527
Valid Loss:  0.18051022291183472
Epoch:  35  	Training Loss: 0.1508617103099823
Test Loss:  0.1777263581752777
Valid Loss:  0.18050619959831238
Epoch:  36  	Training Loss: 0.15085835754871368
Test Loss:  0.17772239446640015
Valid Loss:  0.18050217628479004
Epoch:  37  	Training Loss: 0.15085501968860626
Test Loss:  0.17771844565868378
Valid Loss:  0.1804981529712677
Epoch:  38  	Training Loss: 0.15085166692733765
Test Loss:  0.17771446704864502
Valid Loss:  0.18049412965774536
Epoch:  39  	Training Loss: 0.15084832906723022
Test Loss:  0.17771051824092865
Valid Loss:  0.18049009144306183
Epoch:  40  	Training Loss: 0.1508449763059616
Test Loss:  0.1777065545320511
Valid Loss:  0.1804860681295395
Epoch:  41  	Training Loss: 0.150841623544693
Test Loss:  0.17770257592201233
Valid Loss:  0.18048202991485596
Epoch:  42  	Training Loss: 0.15083828568458557
Test Loss:  0.1776985228061676
Valid Loss:  0.18047791719436646
Epoch:  43  	Training Loss: 0.150834858417511
Test Loss:  0.17769445478916168
Valid Loss:  0.18047377467155457
Epoch:  44  	Training Loss: 0.1508314609527588
Test Loss:  0.17769041657447815
Valid Loss:  0.18046966195106506
Epoch:  45  	Training Loss: 0.1508280634880066
Test Loss:  0.17768634855747223
Valid Loss:  0.18046551942825317
Epoch:  46  	Training Loss: 0.150824636220932
Test Loss:  0.1776822805404663
Valid Loss:  0.18046137690544128
Epoch:  47  	Training Loss: 0.15082122385501862
Test Loss:  0.17767822742462158
Valid Loss:  0.18045726418495178
Epoch:  48  	Training Loss: 0.15081781148910522
Test Loss:  0.17767414450645447
Valid Loss:  0.1804531216621399
Epoch:  49  	Training Loss: 0.15081441402435303
Test Loss:  0.17767009139060974
Valid Loss:  0.1804489940404892
Epoch:  50  	Training Loss: 0.15081098675727844
Test Loss:  0.17766600847244263
Valid Loss:  0.1804448664188385
Epoch:  51  	Training Loss: 0.15080757439136505
Test Loss:  0.1776619553565979
Valid Loss:  0.1804407238960266
Epoch:  52  	Training Loss: 0.15080416202545166
Test Loss:  0.1776578724384308
Valid Loss:  0.18043658137321472
Epoch:  53  	Training Loss: 0.15080074965953827
Test Loss:  0.17765381932258606
Valid Loss:  0.18043245375156403
Epoch:  54  	Training Loss: 0.15079733729362488
Test Loss:  0.17764975130558014
Valid Loss:  0.18042832612991333
Epoch:  55  	Training Loss: 0.15079393982887268
Test Loss:  0.17764568328857422
Valid Loss:  0.18042418360710144
Epoch:  56  	Training Loss: 0.1507905274629593
Test Loss:  0.1776416152715683
Valid Loss:  0.18042005598545074
Epoch:  57  	Training Loss: 0.1507871150970459
Test Loss:  0.17763756215572357
Valid Loss:  0.18041592836380005
Epoch:  58  	Training Loss: 0.1507837176322937
Test Loss:  0.17763349413871765
Valid Loss:  0.18041178584098816
Epoch:  59  	Training Loss: 0.1507803201675415
Test Loss:  0.17762942612171173
Valid Loss:  0.18040767312049866
Epoch:  60  	Training Loss: 0.1507769227027893
Test Loss:  0.1776253581047058
Valid Loss:  0.18040353059768677
Epoch:  61  	Training Loss: 0.1507735252380371
Test Loss:  0.17762130498886108
Valid Loss:  0.18039941787719727
Epoch:  62  	Training Loss: 0.15077009797096252
Test Loss:  0.17761725187301636
Valid Loss:  0.18039530515670776
Epoch:  63  	Training Loss: 0.15076671540737152
Test Loss:  0.17761319875717163
Valid Loss:  0.18039116263389587
Epoch:  64  	Training Loss: 0.15076330304145813
Test Loss:  0.1776091456413269
Valid Loss:  0.18038704991340637
Epoch:  65  	Training Loss: 0.15075990557670593
Test Loss:  0.17760509252548218
Valid Loss:  0.18038293719291687
Epoch:  66  	Training Loss: 0.15075652301311493
Test Loss:  0.17760105431079865
Valid Loss:  0.18037879467010498
Epoch:  67  	Training Loss: 0.15075312554836273
Test Loss:  0.17759700119495392
Valid Loss:  0.18037471175193787
Epoch:  68  	Training Loss: 0.15074972808361053
Test Loss:  0.177592933177948
Valid Loss:  0.18037058413028717
Epoch:  69  	Training Loss: 0.15074634552001953
Test Loss:  0.17758889496326447
Valid Loss:  0.18036644160747528
Epoch:  70  	Training Loss: 0.15074294805526733
Test Loss:  0.17758482694625854
Valid Loss:  0.18036231398582458
Epoch:  71  	Training Loss: 0.15073953568935394
Test Loss:  0.17758077383041382
Valid Loss:  0.18035820126533508
Epoch:  72  	Training Loss: 0.15073613822460175
Test Loss:  0.17757673561573029
Valid Loss:  0.18035411834716797
Epoch:  73  	Training Loss: 0.15073277056217194
Test Loss:  0.17757271230220795
Valid Loss:  0.18035002052783966
 15%|█▌        | 75/500 [00:55<04:29,  1.58it/s] 15%|█▌        | 77/500 [00:55<03:16,  2.16it/s] 16%|█▌        | 79/500 [00:55<02:25,  2.90it/s] 16%|█▌        | 81/500 [01:02<08:22,  1.20s/it] 17%|█▋        | 83/500 [01:02<05:58,  1.16it/s] 17%|█▋        | 85/500 [01:02<04:18,  1.61it/s] 17%|█▋        | 87/500 [01:02<03:08,  2.19it/s] 18%|█▊        | 89/500 [01:02<02:19,  2.95it/s] 18%|█▊        | 91/500 [01:09<08:10,  1.20s/it] 19%|█▊        | 93/500 [01:09<05:50,  1.16it/s] 19%|█▉        | 95/500 [01:09<04:12,  1.60it/s] 19%|█▉        | 97/500 [01:09<03:04,  2.19it/s] 20%|█▉        | 99/500 [01:09<02:16,  2.94it/s] 20%|██        | 101/500 [01:16<08:03,  1.21s/it] 21%|██        | 103/500 [01:16<05:44,  1.15it/s] 21%|██        | 105/500 [01:16<04:09,  1.58it/s] 21%|██▏       | 107/500 [01:16<03:04,  2.13it/s] 22%|██▏       | 109/500 [01:16<02:18,  2.82it/s] 22%|██▏       | 111/500 [01:23<07:50,  1.21s/it] 23%|██▎       | 113/500 [01:23<05:35,  1.15it/s] 23%|██▎       | 115/500 [01:23<04:01,  1.60it/s] 23%|██▎       | 117/500 [01:23<02:55,  2.18it/s] 24%|██▍       | 119/500 [01:23<02:10,  2.93it/s] 24%|██▍       | 121/500 [01:30<07:34,  1.20s/it] 25%|██▍       | 123/500 [01:30<05:24,  1.16it/s] 25%|██▌       | 125/500 [01:30<03:55,  1.59it/s] 25%|██▌       | 127/500 [01:30<02:51,  2.17it/s] 26%|██▌       | 129/500 [01:30<02:08,  2.89it/s] 26%|██▌       | 131/500 [01:37<07:36,  1.24s/it] 27%|██▋       | 133/500 [01:37<05:27,  1.12it/s] 27%|██▋       | 135/500 [01:37<03:57,  1.53it/s] 27%|██▋       | 137/500 [01:38<02:55,  2.07it/s] 28%|██▊       | 139/500 [01:38<02:11,  2.75it/s] 28%|██▊       | 141/500 [01:44<07:25,  1.24s/it] 29%|██▊       | 143/500 [01:44<05:17,  1.12it/s] 29%|██▉       | 145/500 [01:45<03:48,  1.55it/s]Epoch:  74  	Training Loss: 0.15072938799858093
Test Loss:  0.1775687038898468
Valid Loss:  0.18034592270851135
Epoch:  75  	Training Loss: 0.15072602033615112
Test Loss:  0.17756468057632446
Valid Loss:  0.18034182488918304
Epoch:  76  	Training Loss: 0.1507226675748825
Test Loss:  0.17756065726280212
Valid Loss:  0.18033774197101593
Epoch:  77  	Training Loss: 0.1507192850112915
Test Loss:  0.17755663394927979
Valid Loss:  0.18033364415168762
Epoch:  78  	Training Loss: 0.1507159173488617
Test Loss:  0.17755261063575745
Valid Loss:  0.1803295612335205
Epoch:  79  	Training Loss: 0.15071254968643188
Test Loss:  0.1775485873222351
Valid Loss:  0.1803254783153534
Epoch:  80  	Training Loss: 0.15070918202400208
Test Loss:  0.17754454910755157
Valid Loss:  0.1803213655948639
Epoch:  81  	Training Loss: 0.15070579946041107
Test Loss:  0.17754054069519043
Valid Loss:  0.18031728267669678
Epoch:  82  	Training Loss: 0.15070244669914246
Test Loss:  0.1775365024805069
Valid Loss:  0.18031319975852966
Epoch:  83  	Training Loss: 0.15069907903671265
Test Loss:  0.17753246426582336
Valid Loss:  0.18030910193920135
Epoch:  84  	Training Loss: 0.15069569647312164
Test Loss:  0.17752845585346222
Valid Loss:  0.18030503392219543
Epoch:  85  	Training Loss: 0.15069234371185303
Test Loss:  0.17752444744110107
Valid Loss:  0.18030093610286713
Epoch:  86  	Training Loss: 0.15068897604942322
Test Loss:  0.17752042412757874
Valid Loss:  0.1802968531847
Epoch:  87  	Training Loss: 0.1506856083869934
Test Loss:  0.1775164008140564
Valid Loss:  0.1802927702665329
Epoch:  88  	Training Loss: 0.1506822407245636
Test Loss:  0.17751239240169525
Valid Loss:  0.1802886724472046
Epoch:  89  	Training Loss: 0.1506788730621338
Test Loss:  0.1775083690881729
Valid Loss:  0.18028458952903748
Epoch:  90  	Training Loss: 0.15067550539970398
Test Loss:  0.17750433087348938
Valid Loss:  0.18028050661087036
Epoch:  91  	Training Loss: 0.15067213773727417
Test Loss:  0.17750030755996704
Valid Loss:  0.18027642369270325
Epoch:  92  	Training Loss: 0.15066877007484436
Test Loss:  0.17749632894992828
Valid Loss:  0.18027237057685852
Epoch:  93  	Training Loss: 0.15066543221473694
Test Loss:  0.17749235033988953
Valid Loss:  0.1802683174610138
Epoch:  94  	Training Loss: 0.15066209435462952
Test Loss:  0.17748835682868958
Valid Loss:  0.18026424944400787
Epoch:  95  	Training Loss: 0.1506587564945221
Test Loss:  0.17748436331748962
Valid Loss:  0.18026019632816315
Epoch:  96  	Training Loss: 0.15065541863441467
Test Loss:  0.17748036980628967
Valid Loss:  0.18025615811347961
Epoch:  97  	Training Loss: 0.15065208077430725
Test Loss:  0.17747639119625092
Valid Loss:  0.1802520751953125
Epoch:  98  	Training Loss: 0.15064874291419983
Test Loss:  0.17747241258621216
Valid Loss:  0.18024802207946777
Epoch:  99  	Training Loss: 0.1506454050540924
Test Loss:  0.177468404173851
Valid Loss:  0.18024398386478424
Epoch:  100  	Training Loss: 0.1506420522928238
Test Loss:  0.17746442556381226
Valid Loss:  0.18023993074893951
Epoch:  101  	Training Loss: 0.15063869953155518
Test Loss:  0.1774604320526123
Valid Loss:  0.1802358627319336
Epoch:  102  	Training Loss: 0.15063537657260895
Test Loss:  0.17745645344257355
Valid Loss:  0.18023182451725006
Epoch:  103  	Training Loss: 0.15063203871250153
Test Loss:  0.1774524748325348
Valid Loss:  0.18022777140140533
Epoch:  104  	Training Loss: 0.1506287157535553
Test Loss:  0.17744848132133484
Valid Loss:  0.1802237331867218
Epoch:  105  	Training Loss: 0.15062536299228668
Test Loss:  0.17744451761245728
Valid Loss:  0.18021968007087708
Epoch:  106  	Training Loss: 0.15062202513217926
Test Loss:  0.17744052410125732
Valid Loss:  0.18021562695503235
Epoch:  107  	Training Loss: 0.15061868727207184
Test Loss:  0.17743654549121857
Valid Loss:  0.18021157383918762
Epoch:  108  	Training Loss: 0.1506153643131256
Test Loss:  0.1774325668811798
Valid Loss:  0.1802075356245041
Epoch:  109  	Training Loss: 0.1506120264530182
Test Loss:  0.17742857336997986
Valid Loss:  0.18020349740982056
Epoch:  110  	Training Loss: 0.15060868859291077
Test Loss:  0.1774245947599411
Valid Loss:  0.18019944429397583
Epoch:  111  	Training Loss: 0.15060535073280334
Test Loss:  0.17742061614990234
Valid Loss:  0.1801953911781311
Epoch:  112  	Training Loss: 0.15060201287269592
Test Loss:  0.17741665244102478
Valid Loss:  0.18019135296344757
Epoch:  113  	Training Loss: 0.1505986899137497
Test Loss:  0.17741268873214722
Valid Loss:  0.18018732964992523
Epoch:  114  	Training Loss: 0.15059536695480347
Test Loss:  0.17740869522094727
Valid Loss:  0.1801832914352417
Epoch:  115  	Training Loss: 0.15059204399585724
Test Loss:  0.1774047464132309
Valid Loss:  0.18017926812171936
Epoch:  116  	Training Loss: 0.15058870613574982
Test Loss:  0.17740078270435333
Valid Loss:  0.18017522990703583
Epoch:  117  	Training Loss: 0.1505853831768036
Test Loss:  0.17739680409431458
Valid Loss:  0.1801711916923523
Epoch:  118  	Training Loss: 0.15058207511901855
Test Loss:  0.177392840385437
Valid Loss:  0.18016715347766876
Epoch:  119  	Training Loss: 0.15057873725891113
Test Loss:  0.17738886177539825
Valid Loss:  0.18016311526298523
Epoch:  120  	Training Loss: 0.1505754142999649
Test Loss:  0.1773848980665207
Valid Loss:  0.1801590919494629
Epoch:  121  	Training Loss: 0.15057209134101868
Test Loss:  0.17738091945648193
Valid Loss:  0.18015503883361816
Epoch:  122  	Training Loss: 0.15056876838207245
Test Loss:  0.17737698554992676
Valid Loss:  0.1801510453224182
Epoch:  123  	Training Loss: 0.15056546032428741
Test Loss:  0.17737305164337158
Valid Loss:  0.18014702200889587
Epoch:  124  	Training Loss: 0.1505621373653412
Test Loss:  0.17736908793449402
Valid Loss:  0.18014299869537354
Epoch:  125  	Training Loss: 0.15055885910987854
Test Loss:  0.17736515402793884
Valid Loss:  0.18013900518417358
Epoch:  126  	Training Loss: 0.1505555510520935
Test Loss:  0.17736120522022247
Valid Loss:  0.18013501167297363
Epoch:  127  	Training Loss: 0.15055225789546967
Test Loss:  0.1773572713136673
Valid Loss:  0.1801309883594513
Epoch:  128  	Training Loss: 0.15054894983768463
Test Loss:  0.17735332250595093
Valid Loss:  0.18012697994709015
Epoch:  129  	Training Loss: 0.1505456268787384
Test Loss:  0.17734938859939575
Valid Loss:  0.180122971534729
Epoch:  130  	Training Loss: 0.15054231882095337
Test Loss:  0.17734543979167938
Valid Loss:  0.18011896312236786
Epoch:  131  	Training Loss: 0.15053902566432953
Test Loss:  0.177341490983963
Valid Loss:  0.1801149547100067
Epoch:  132  	Training Loss: 0.1505357176065445
Test Loss:  0.17733757197856903
Valid Loss:  0.18011096119880676
Epoch:  133  	Training Loss: 0.15053242444992065
Test Loss:  0.17733365297317505
Valid Loss:  0.180106982588768
Epoch:  134  	Training Loss: 0.150529146194458
Test Loss:  0.17732973396778107
Valid Loss:  0.18010298907756805
Epoch:  135  	Training Loss: 0.15052586793899536
Test Loss:  0.17732581496238708
Valid Loss:  0.1800990104675293
Epoch:  136  	Training Loss: 0.15052258968353271
Test Loss:  0.1773218810558319
Valid Loss:  0.18009503185749054
Epoch:  137  	Training Loss: 0.15051929652690887
Test Loss:  0.17731797695159912
Valid Loss:  0.1800910234451294
Epoch:  138  	Training Loss: 0.15051601827144623
Test Loss:  0.17731405794620514
Valid Loss:  0.18008704483509064
Epoch:  139  	Training Loss: 0.1505127251148224
Test Loss:  0.17731012403964996
Valid Loss:  0.18008306622505188
Epoch:  140  	Training Loss: 0.15050944685935974
Test Loss:  0.17730620503425598
Valid Loss:  0.18007907271385193
Epoch:  141  	Training Loss: 0.1505061686038971
Test Loss:  0.177302286028862
Valid Loss:  0.18007510900497437
Epoch:  142  	Training Loss: 0.15050289034843445
Test Loss:  0.17729836702346802
Valid Loss:  0.1800711452960968
Epoch:  143  	Training Loss: 0.1504996120929718
Test Loss:  0.17729449272155762
Valid Loss:  0.18006715178489685
Epoch:  144  	Training Loss: 0.15049633383750916
Test Loss:  0.17729057371616364
Valid Loss:  0.1800631880760193
Epoch:  145  	Training Loss: 0.1504930555820465
Test Loss:  0.17728668451309204
Valid Loss:  0.18005922436714172
Epoch:  146  	Training Loss: 0.15048979222774506
Test Loss:  0.17728276550769806
 29%|██▉       | 147/500 [01:45<02:45,  2.13it/s] 30%|██▉       | 149/500 [01:45<02:02,  2.87it/s] 30%|███       | 151/500 [01:51<07:00,  1.20s/it] 31%|███       | 153/500 [01:51<05:00,  1.16it/s] 31%|███       | 155/500 [01:51<03:36,  1.60it/s] 31%|███▏      | 157/500 [01:52<02:37,  2.18it/s] 32%|███▏      | 159/500 [01:52<01:56,  2.94it/s] 32%|███▏      | 161/500 [01:58<06:48,  1.20s/it] 33%|███▎      | 163/500 [01:58<04:51,  1.16it/s] 33%|███▎      | 165/500 [01:58<03:29,  1.60it/s] 33%|███▎      | 167/500 [01:59<02:32,  2.19it/s] 34%|███▍      | 169/500 [01:59<01:52,  2.94it/s] 34%|███▍      | 171/500 [02:05<06:36,  1.20s/it] 35%|███▍      | 173/500 [02:05<04:44,  1.15it/s] 35%|███▌      | 175/500 [02:06<03:26,  1.57it/s] 35%|███▌      | 177/500 [02:06<02:31,  2.13it/s] 36%|███▌      | 179/500 [02:06<01:52,  2.85it/s] 36%|███▌      | 181/500 [02:12<06:22,  1.20s/it] 37%|███▋      | 183/500 [02:12<04:32,  1.16it/s] 37%|███▋      | 185/500 [02:12<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:13<02:22,  2.20it/s] 38%|███▊      | 189/500 [02:13<01:46,  2.93it/s] 38%|███▊      | 191/500 [02:19<06:15,  1.21s/it] 39%|███▊      | 193/500 [02:19<04:28,  1.14it/s] 39%|███▉      | 195/500 [02:20<03:14,  1.57it/s] 39%|███▉      | 197/500 [02:20<02:23,  2.12it/s] 40%|███▉      | 199/500 [02:20<01:47,  2.80it/s] 40%|████      | 201/500 [02:27<06:12,  1.25s/it] 41%|████      | 203/500 [02:27<04:25,  1.12it/s] 41%|████      | 205/500 [02:27<03:10,  1.55it/s] 41%|████▏     | 207/500 [02:27<02:18,  2.12it/s] 42%|████▏     | 209/500 [02:27<01:42,  2.85it/s] 42%|████▏     | 211/500 [02:34<05:51,  1.22s/it] 43%|████▎     | 213/500 [02:34<04:12,  1.14it/s] 43%|████▎     | 215/500 [02:34<03:02,  1.56it/s] 43%|████▎     | 217/500 [02:34<02:12,  2.14it/s]Valid Loss:  0.18005526065826416
Epoch:  147  	Training Loss: 0.1504865288734436
Test Loss:  0.17727887630462646
Valid Loss:  0.1800512969493866
Epoch:  148  	Training Loss: 0.15048325061798096
Test Loss:  0.17727497220039368
Valid Loss:  0.18004730343818665
Epoch:  149  	Training Loss: 0.1504799723625183
Test Loss:  0.1772710680961609
Valid Loss:  0.18004333972930908
Epoch:  150  	Training Loss: 0.15047669410705566
Test Loss:  0.1772671490907669
Valid Loss:  0.18003937602043152
Epoch:  151  	Training Loss: 0.1504734307527542
Test Loss:  0.1772632598876953
Valid Loss:  0.18003541231155396
Epoch:  152  	Training Loss: 0.15047016739845276
Test Loss:  0.1772593855857849
Valid Loss:  0.18003147840499878
Epoch:  153  	Training Loss: 0.1504669189453125
Test Loss:  0.1772555112838745
Valid Loss:  0.1800275444984436
Epoch:  154  	Training Loss: 0.15046367049217224
Test Loss:  0.1772516369819641
Valid Loss:  0.18002361059188843
Epoch:  155  	Training Loss: 0.15046042203903198
Test Loss:  0.1772477626800537
Valid Loss:  0.18001966178417206
Epoch:  156  	Training Loss: 0.15045718848705292
Test Loss:  0.1772438883781433
Valid Loss:  0.18001572787761688
Epoch:  157  	Training Loss: 0.15045392513275146
Test Loss:  0.1772400140762329
Valid Loss:  0.1800117790699005
Epoch:  158  	Training Loss: 0.1504506915807724
Test Loss:  0.1772361397743225
Valid Loss:  0.18000784516334534
Epoch:  159  	Training Loss: 0.15044745802879333
Test Loss:  0.1772322654724121
Valid Loss:  0.18000391125679016
Epoch:  160  	Training Loss: 0.15044420957565308
Test Loss:  0.1772283911705017
Valid Loss:  0.17999997735023499
Epoch:  161  	Training Loss: 0.15044096112251282
Test Loss:  0.1772245168685913
Valid Loss:  0.1799960434436798
Epoch:  162  	Training Loss: 0.15043771266937256
Test Loss:  0.1772206425666809
Valid Loss:  0.17999209463596344
Epoch:  163  	Training Loss: 0.1504344642162323
Test Loss:  0.1772167682647705
Valid Loss:  0.17998817563056946
Epoch:  164  	Training Loss: 0.15043121576309204
Test Loss:  0.1772129237651825
Valid Loss:  0.17998424172401428
Epoch:  165  	Training Loss: 0.15042799711227417
Test Loss:  0.1772090494632721
Valid Loss:  0.1799803078174591
Epoch:  166  	Training Loss: 0.15042473375797272
Test Loss:  0.1772051900625229
Valid Loss:  0.17997638881206512
Epoch:  167  	Training Loss: 0.15042150020599365
Test Loss:  0.1772013008594513
Valid Loss:  0.17997245490550995
Epoch:  168  	Training Loss: 0.1504182517528534
Test Loss:  0.17719745635986328
Valid Loss:  0.17996852099895477
Epoch:  169  	Training Loss: 0.15041501820087433
Test Loss:  0.17719358205795288
Valid Loss:  0.1799645870923996
Epoch:  170  	Training Loss: 0.15041178464889526
Test Loss:  0.17718973755836487
Valid Loss:  0.17996065318584442
Epoch:  171  	Training Loss: 0.150408536195755
Test Loss:  0.17718584835529327
Valid Loss:  0.17995673418045044
Epoch:  172  	Training Loss: 0.15040528774261475
Test Loss:  0.17718201875686646
Valid Loss:  0.17995283007621765
Epoch:  173  	Training Loss: 0.15040208399295807
Test Loss:  0.17717817425727844
Valid Loss:  0.17994892597198486
Epoch:  174  	Training Loss: 0.1503988653421402
Test Loss:  0.17717435956001282
Valid Loss:  0.17994502186775208
Epoch:  175  	Training Loss: 0.15039566159248352
Test Loss:  0.177170529961586
Valid Loss:  0.17994114756584167
Epoch:  176  	Training Loss: 0.15039244294166565
Test Loss:  0.17716670036315918
Valid Loss:  0.1799372434616089
Epoch:  177  	Training Loss: 0.15038923919200897
Test Loss:  0.17716285586357117
Valid Loss:  0.1799333393573761
Epoch:  178  	Training Loss: 0.1503860205411911
Test Loss:  0.17715902626514435
Valid Loss:  0.1799294501543045
Epoch:  179  	Training Loss: 0.15038280189037323
Test Loss:  0.17715518176555634
Valid Loss:  0.17992554605007172
Epoch:  180  	Training Loss: 0.15037958323955536
Test Loss:  0.17715135216712952
Valid Loss:  0.17992165684700012
Epoch:  181  	Training Loss: 0.15037637948989868
Test Loss:  0.1771475225687027
Valid Loss:  0.17991775274276733
Epoch:  182  	Training Loss: 0.150373175740242
Test Loss:  0.17714369297027588
Valid Loss:  0.17991387844085693
Epoch:  183  	Training Loss: 0.15036997199058533
Test Loss:  0.17713987827301025
Valid Loss:  0.17990998923778534
Epoch:  184  	Training Loss: 0.15036676824092865
Test Loss:  0.17713606357574463
Valid Loss:  0.17990610003471375
Epoch:  185  	Training Loss: 0.15036356449127197
Test Loss:  0.177132248878479
Valid Loss:  0.17990222573280334
Epoch:  186  	Training Loss: 0.1503603607416153
Test Loss:  0.17712843418121338
Valid Loss:  0.17989833652973175
Epoch:  187  	Training Loss: 0.15035715699195862
Test Loss:  0.17712458968162537
Valid Loss:  0.17989444732666016
Epoch:  188  	Training Loss: 0.15035393834114075
Test Loss:  0.17712077498435974
Valid Loss:  0.17989057302474976
Epoch:  189  	Training Loss: 0.15035074949264526
Test Loss:  0.17711696028709412
Valid Loss:  0.17988669872283936
Epoch:  190  	Training Loss: 0.15034756064414978
Test Loss:  0.1771131455898285
Valid Loss:  0.17988279461860657
Epoch:  191  	Training Loss: 0.1503443419933319
Test Loss:  0.17710933089256287
Valid Loss:  0.17987892031669617
Epoch:  192  	Training Loss: 0.15034115314483643
Test Loss:  0.17710553109645844
Valid Loss:  0.17987507581710815
Epoch:  193  	Training Loss: 0.15033796429634094
Test Loss:  0.177101731300354
Valid Loss:  0.17987120151519775
Epoch:  194  	Training Loss: 0.15033477544784546
Test Loss:  0.17709793150424957
Valid Loss:  0.17986734211444855
Epoch:  195  	Training Loss: 0.15033160150051117
Test Loss:  0.17709413170814514
Valid Loss:  0.17986349761486053
Epoch:  196  	Training Loss: 0.15032842755317688
Test Loss:  0.1770903468132019
Valid Loss:  0.17985963821411133
Epoch:  197  	Training Loss: 0.1503252387046814
Test Loss:  0.17708653211593628
Valid Loss:  0.17985579371452332
Epoch:  198  	Training Loss: 0.1503220498561859
Test Loss:  0.17708276212215424
Valid Loss:  0.17985191941261292
Epoch:  199  	Training Loss: 0.15031886100769043
Test Loss:  0.1770789623260498
Valid Loss:  0.17984804511070251
Epoch:  200  	Training Loss: 0.15031568706035614
Test Loss:  0.17707517743110657
Valid Loss:  0.1798442006111145
Epoch:  201  	Training Loss: 0.15031251311302185
Test Loss:  0.17707136273384094
Valid Loss:  0.1798403412103653
Epoch:  202  	Training Loss: 0.15030932426452637
Test Loss:  0.1770675778388977
Valid Loss:  0.17983649671077728
Epoch:  203  	Training Loss: 0.15030616521835327
Test Loss:  0.17706380784511566
Valid Loss:  0.17983263731002808
Epoch:  204  	Training Loss: 0.15030299127101898
Test Loss:  0.17706000804901123
Valid Loss:  0.17982879281044006
Epoch:  205  	Training Loss: 0.1502998173236847
Test Loss:  0.177056223154068
Valid Loss:  0.17982494831085205
Epoch:  206  	Training Loss: 0.1502966284751892
Test Loss:  0.17705243825912476
Valid Loss:  0.17982110381126404
Epoch:  207  	Training Loss: 0.1502934694290161
Test Loss:  0.1770486682653427
Valid Loss:  0.17981725931167603
Epoch:  208  	Training Loss: 0.15029028058052063
Test Loss:  0.17704489827156067
Valid Loss:  0.1798134297132492
Epoch:  209  	Training Loss: 0.15028712153434753
Test Loss:  0.17704109847545624
Valid Loss:  0.1798095703125
Epoch:  210  	Training Loss: 0.15028393268585205
Test Loss:  0.177037313580513
Valid Loss:  0.179805725812912
Epoch:  211  	Training Loss: 0.15028077363967896
Test Loss:  0.17703352868556976
Valid Loss:  0.17980188131332397
Epoch:  212  	Training Loss: 0.15027761459350586
Test Loss:  0.1770297884941101
Valid Loss:  0.17979806661605835
Epoch:  213  	Training Loss: 0.15027445554733276
Test Loss:  0.17702603340148926
Valid Loss:  0.17979426681995392
Epoch:  214  	Training Loss: 0.15027131140232086
Test Loss:  0.1770222932100296
Valid Loss:  0.1797904670238495
Epoch:  215  	Training Loss: 0.15026816725730896
Test Loss:  0.17701855301856995
Valid Loss:  0.17978665232658386
Epoch:  216  	Training Loss: 0.15026503801345825
Test Loss:  0.17701482772827148
Valid Loss:  0.17978285253047943
Epoch:  217  	Training Loss: 0.15026190876960754
Test Loss:  0.17701107263565063
Valid Loss:  0.1797790229320526
Epoch:  218  	Training Loss: 0.15025874972343445
Test Loss:  0.17700731754302979
Valid Loss:  0.17977523803710938
 44%|████▍     | 219/500 [02:34<01:37,  2.88it/s] 44%|████▍     | 221/500 [02:41<05:33,  1.20s/it] 45%|████▍     | 223/500 [02:41<03:57,  1.17it/s] 45%|████▌     | 225/500 [02:41<02:50,  1.61it/s] 45%|████▌     | 227/500 [02:41<02:04,  2.20it/s] 46%|████▌     | 229/500 [02:41<01:31,  2.96it/s] 46%|████▌     | 231/500 [02:47<05:17,  1.18s/it] 47%|████▋     | 233/500 [02:48<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:48<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:48<01:58,  2.22it/s] 48%|████▊     | 239/500 [02:48<01:29,  2.92it/s] 48%|████▊     | 241/500 [02:54<05:10,  1.20s/it] 49%|████▊     | 243/500 [02:55<03:41,  1.16it/s] 49%|████▉     | 245/500 [02:55<02:38,  1.61it/s] 49%|████▉     | 247/500 [02:55<01:55,  2.19it/s] 50%|████▉     | 249/500 [02:55<01:24,  2.95it/s] 50%|█████     | 251/500 [03:01<05:00,  1.21s/it] 51%|█████     | 253/500 [03:02<03:34,  1.15it/s] 51%|█████     | 255/500 [03:02<02:33,  1.60it/s] 51%|█████▏    | 257/500 [03:02<01:51,  2.18it/s] 52%|█████▏    | 259/500 [03:02<01:21,  2.94it/s] 52%|█████▏    | 261/500 [03:08<04:42,  1.18s/it] 53%|█████▎    | 263/500 [03:08<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:09<02:24,  1.63it/s] 53%|█████▎    | 267/500 [03:09<01:44,  2.23it/s] 54%|█████▍    | 269/500 [03:09<01:17,  3.00it/s] 54%|█████▍    | 271/500 [03:15<04:34,  1.20s/it] 55%|█████▍    | 273/500 [03:15<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:15<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:16<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:16<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:22<04:19,  1.18s/it] 57%|█████▋    | 283/500 [03:22<03:04,  1.18it/s] 57%|█████▋    | 285/500 [03:22<02:12,  1.63it/s] 57%|█████▋    | 287/500 [03:22<01:35,  2.22it/s] 58%|█████▊    | 289/500 [03:23<01:11,  2.97it/s]Epoch:  219  	Training Loss: 0.15025562047958374
Test Loss:  0.17700357735157013
Valid Loss:  0.17977142333984375
Epoch:  220  	Training Loss: 0.15025247633457184
Test Loss:  0.17699985206127167
Valid Loss:  0.17976762354373932
Epoch:  221  	Training Loss: 0.15024933218955994
Test Loss:  0.176996111869812
Valid Loss:  0.1797638088464737
Epoch:  222  	Training Loss: 0.15024620294570923
Test Loss:  0.17699237167835236
Valid Loss:  0.17976003885269165
Epoch:  223  	Training Loss: 0.15024308860301971
Test Loss:  0.17698867619037628
Valid Loss:  0.1797562688589096
Epoch:  224  	Training Loss: 0.1502399742603302
Test Loss:  0.17698493599891663
Valid Loss:  0.17975249886512756
Epoch:  225  	Training Loss: 0.15023687481880188
Test Loss:  0.17698122560977936
Valid Loss:  0.17974868416786194
Epoch:  226  	Training Loss: 0.15023374557495117
Test Loss:  0.1769775152206421
Valid Loss:  0.17974494397640228
Epoch:  227  	Training Loss: 0.15023063123226166
Test Loss:  0.17697380483150482
Valid Loss:  0.17974114418029785
Epoch:  228  	Training Loss: 0.15022751688957214
Test Loss:  0.17697009444236755
Valid Loss:  0.179737389087677
Epoch:  229  	Training Loss: 0.15022440254688263
Test Loss:  0.17696638405323029
Valid Loss:  0.17973360419273376
Epoch:  230  	Training Loss: 0.15022128820419312
Test Loss:  0.17696267366409302
Valid Loss:  0.17972981929779053
Epoch:  231  	Training Loss: 0.1502181738615036
Test Loss:  0.17695894837379456
Valid Loss:  0.1797260344028473
Epoch:  232  	Training Loss: 0.1502150595188141
Test Loss:  0.17695525288581848
Valid Loss:  0.17972232401371002
Epoch:  233  	Training Loss: 0.15021197497844696
Test Loss:  0.1769515872001648
Valid Loss:  0.17971856892108917
Epoch:  234  	Training Loss: 0.15020887553691864
Test Loss:  0.17694789171218872
Valid Loss:  0.17971482872962952
Epoch:  235  	Training Loss: 0.1502057909965515
Test Loss:  0.17694421112537384
Valid Loss:  0.17971107363700867
Epoch:  236  	Training Loss: 0.1502027064561844
Test Loss:  0.17694053053855896
Valid Loss:  0.17970731854438782
Epoch:  237  	Training Loss: 0.15019960701465607
Test Loss:  0.17693684995174408
Valid Loss:  0.17970359325408936
Epoch:  238  	Training Loss: 0.15019652247428894
Test Loss:  0.1769331693649292
Valid Loss:  0.1796998381614685
Epoch:  239  	Training Loss: 0.15019342303276062
Test Loss:  0.17692948877811432
Valid Loss:  0.17969611287117004
Epoch:  240  	Training Loss: 0.1501903384923935
Test Loss:  0.17692580819129944
Valid Loss:  0.1796923577785492
Epoch:  241  	Training Loss: 0.15018725395202637
Test Loss:  0.17692212760448456
Valid Loss:  0.17968861758708954
Epoch:  242  	Training Loss: 0.15018415451049805
Test Loss:  0.1769184172153473
Valid Loss:  0.1796848475933075
Epoch:  243  	Training Loss: 0.15018105506896973
Test Loss:  0.1769147515296936
Valid Loss:  0.17968112230300903
Epoch:  244  	Training Loss: 0.1501779705286026
Test Loss:  0.17691105604171753
Valid Loss:  0.17967736721038818
Epoch:  245  	Training Loss: 0.15017488598823547
Test Loss:  0.17690736055374146
Valid Loss:  0.17967361211776733
Epoch:  246  	Training Loss: 0.15017178654670715
Test Loss:  0.17690367996692657
Valid Loss:  0.17966985702514648
Epoch:  247  	Training Loss: 0.15016868710517883
Test Loss:  0.1768999993801117
Valid Loss:  0.17966611683368683
Epoch:  248  	Training Loss: 0.1501655876636505
Test Loss:  0.17689630389213562
Valid Loss:  0.17966236174106598
Epoch:  249  	Training Loss: 0.1501625031232834
Test Loss:  0.17689260840415955
Valid Loss:  0.17965860664844513
Epoch:  250  	Training Loss: 0.15015940368175507
Test Loss:  0.17688891291618347
Valid Loss:  0.17965486645698547
Epoch:  251  	Training Loss: 0.15015631914138794
Test Loss:  0.17688524723052979
Valid Loss:  0.17965111136436462
Epoch:  252  	Training Loss: 0.15015321969985962
Test Loss:  0.1768815815448761
Valid Loss:  0.17964740097522736
Epoch:  253  	Training Loss: 0.1501501500606537
Test Loss:  0.1768779158592224
Valid Loss:  0.1796436607837677
Epoch:  254  	Training Loss: 0.15014708042144775
Test Loss:  0.17687425017356873
Valid Loss:  0.17963995039463043
Epoch:  255  	Training Loss: 0.15014399588108063
Test Loss:  0.17687058448791504
Valid Loss:  0.17963624000549316
Epoch:  256  	Training Loss: 0.1501409262418747
Test Loss:  0.17686694860458374
Valid Loss:  0.1796324998140335
Epoch:  257  	Training Loss: 0.15013784170150757
Test Loss:  0.17686326801776886
Valid Loss:  0.17962878942489624
Epoch:  258  	Training Loss: 0.15013480186462402
Test Loss:  0.17685960233211517
Valid Loss:  0.17962506413459778
Epoch:  259  	Training Loss: 0.1501317173242569
Test Loss:  0.1768559366464615
Valid Loss:  0.17962133884429932
Epoch:  260  	Training Loss: 0.15012863278388977
Test Loss:  0.176852285861969
Valid Loss:  0.17961761355400085
Epoch:  261  	Training Loss: 0.15012556314468384
Test Loss:  0.1768486201763153
Valid Loss:  0.1796138882637024
Epoch:  262  	Training Loss: 0.1501224935054779
Test Loss:  0.17684495449066162
Valid Loss:  0.17961019277572632
Epoch:  263  	Training Loss: 0.15011942386627197
Test Loss:  0.17684133350849152
Valid Loss:  0.17960649728775024
Epoch:  264  	Training Loss: 0.15011636912822723
Test Loss:  0.17683768272399902
Valid Loss:  0.17960277199745178
Epoch:  265  	Training Loss: 0.1501133143901825
Test Loss:  0.17683401703834534
Valid Loss:  0.1795990765094757
Epoch:  266  	Training Loss: 0.15011025965213776
Test Loss:  0.17683041095733643
Valid Loss:  0.17959535121917725
Epoch:  267  	Training Loss: 0.15010719001293182
Test Loss:  0.17682676017284393
Valid Loss:  0.17959165573120117
Epoch:  268  	Training Loss: 0.15010413527488708
Test Loss:  0.17682310938835144
Valid Loss:  0.1795879602432251
Epoch:  269  	Training Loss: 0.15010108053684235
Test Loss:  0.17681945860385895
Valid Loss:  0.17958424985408783
Epoch:  270  	Training Loss: 0.1500980257987976
Test Loss:  0.17681580781936646
Valid Loss:  0.17958053946495056
Epoch:  271  	Training Loss: 0.15009495615959167
Test Loss:  0.17681217193603516
Valid Loss:  0.1795768439769745
Epoch:  272  	Training Loss: 0.15009190142154694
Test Loss:  0.17680856585502625
Valid Loss:  0.1795731633901596
Epoch:  273  	Training Loss: 0.15008887648582458
Test Loss:  0.17680494487285614
Valid Loss:  0.17956948280334473
Epoch:  274  	Training Loss: 0.15008583664894104
Test Loss:  0.17680132389068604
Valid Loss:  0.17956581711769104
Epoch:  275  	Training Loss: 0.1500828117132187
Test Loss:  0.17679773271083832
Valid Loss:  0.17956215143203735
Epoch:  276  	Training Loss: 0.15007978677749634
Test Loss:  0.1767941117286682
Valid Loss:  0.17955848574638367
Epoch:  277  	Training Loss: 0.1500767469406128
Test Loss:  0.1767904907464981
Valid Loss:  0.17955482006072998
Epoch:  278  	Training Loss: 0.15007372200489044
Test Loss:  0.1767868846654892
Valid Loss:  0.1795511245727539
Epoch:  279  	Training Loss: 0.1500706970691681
Test Loss:  0.1767832636833191
Valid Loss:  0.17954745888710022
Epoch:  280  	Training Loss: 0.15006765723228455
Test Loss:  0.17677965760231018
Valid Loss:  0.17954379320144653
Epoch:  281  	Training Loss: 0.150064617395401
Test Loss:  0.17677605152130127
Valid Loss:  0.17954011261463165
Epoch:  282  	Training Loss: 0.15006159245967865
Test Loss:  0.17677247524261475
Valid Loss:  0.17953647673130035
Epoch:  283  	Training Loss: 0.1500585973262787
Test Loss:  0.17676888406276703
Valid Loss:  0.17953282594680786
Epoch:  284  	Training Loss: 0.15005557239055634
Test Loss:  0.1767652928829193
Valid Loss:  0.17952917516231537
Epoch:  285  	Training Loss: 0.15005256235599518
Test Loss:  0.1767617017030716
Valid Loss:  0.17952552437782288
Epoch:  286  	Training Loss: 0.15004956722259521
Test Loss:  0.17675811052322388
Valid Loss:  0.17952188849449158
Epoch:  287  	Training Loss: 0.15004654228687286
Test Loss:  0.17675453424453735
Valid Loss:  0.17951823770999908
Epoch:  288  	Training Loss: 0.1500435322523117
Test Loss:  0.17675092816352844
Valid Loss:  0.1795145869255066
Epoch:  289  	Training Loss: 0.15004052221775055
Test Loss:  0.17674735188484192
Valid Loss:  0.1795109510421753
Epoch:  290  	Training Loss: 0.1500375121831894
Test Loss:  0.1767437756061554
Valid Loss:  0.179507315158844
Epoch:  291  	Training Loss: 0.15003450214862823 58%|█████▊    | 291/500 [03:29<04:10,  1.20s/it] 59%|█████▊    | 293/500 [03:29<02:57,  1.16it/s] 59%|█████▉    | 295/500 [03:29<02:07,  1.61it/s] 59%|█████▉    | 297/500 [03:29<01:32,  2.20it/s] 60%|█████▉    | 299/500 [03:30<01:07,  2.96it/s] 60%|██████    | 301/500 [03:36<03:54,  1.18s/it] 61%|██████    | 303/500 [03:36<02:46,  1.18it/s] 61%|██████    | 305/500 [03:36<01:59,  1.64it/s] 61%|██████▏   | 307/500 [03:36<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:36<01:04,  2.95it/s] 62%|██████▏   | 311/500 [03:43<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:43<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:43<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:43<01:22,  2.21it/s] 64%|██████▍   | 319/500 [03:43<01:01,  2.96it/s] 64%|██████▍   | 321/500 [03:50<03:32,  1.19s/it] 65%|██████▍   | 323/500 [03:50<02:30,  1.17it/s] 65%|██████▌   | 325/500 [03:50<01:47,  1.62it/s] 65%|██████▌   | 327/500 [03:50<01:17,  2.22it/s] 66%|██████▌   | 329/500 [03:50<00:57,  2.97it/s] 66%|██████▌   | 331/500 [03:57<03:21,  1.19s/it] 67%|██████▋   | 333/500 [03:57<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:57<01:42,  1.62it/s] 67%|██████▋   | 337/500 [03:57<01:13,  2.21it/s] 68%|██████▊   | 339/500 [03:57<00:54,  2.97it/s] 68%|██████▊   | 341/500 [04:03<03:09,  1.19s/it] 69%|██████▊   | 343/500 [04:04<02:14,  1.17it/s] 69%|██████▉   | 345/500 [04:04<01:35,  1.61it/s] 69%|██████▉   | 347/500 [04:04<01:09,  2.21it/s] 70%|██████▉   | 349/500 [04:04<00:50,  2.97it/s] 70%|███████   | 351/500 [04:10<02:59,  1.21s/it] 71%|███████   | 353/500 [04:11<02:07,  1.15it/s] 71%|███████   | 355/500 [04:11<01:30,  1.60it/s] 71%|███████▏  | 357/500 [04:11<01:05,  2.19it/s] 72%|███████▏  | 359/500 [04:11<00:47,  2.94it/s] 72%|███████▏  | 361/500 [04:17<02:45,  1.19s/it]
Test Loss:  0.17674018442630768
Valid Loss:  0.1795036494731903
Epoch:  292  	Training Loss: 0.15003149211406708
Test Loss:  0.17673662304878235
Valid Loss:  0.1795000284910202
Epoch:  293  	Training Loss: 0.15002849698066711
Test Loss:  0.17673303186893463
Valid Loss:  0.1794963926076889
Epoch:  294  	Training Loss: 0.15002551674842834
Test Loss:  0.1767294853925705
Valid Loss:  0.1794927716255188
Epoch:  295  	Training Loss: 0.1500225067138672
Test Loss:  0.17672592401504517
Valid Loss:  0.1794891357421875
Epoch:  296  	Training Loss: 0.15001951158046722
Test Loss:  0.17672234773635864
Valid Loss:  0.1794855147600174
Epoch:  297  	Training Loss: 0.15001651644706726
Test Loss:  0.17671877145767212
Valid Loss:  0.1794818788766861
Epoch:  298  	Training Loss: 0.1500135362148285
Test Loss:  0.1767152100801468
Valid Loss:  0.179478257894516
Epoch:  299  	Training Loss: 0.15001052618026733
Test Loss:  0.17671164870262146
Valid Loss:  0.1794746369123459
Epoch:  300  	Training Loss: 0.15000753104686737
Test Loss:  0.17670807242393494
Valid Loss:  0.17947101593017578
Epoch:  301  	Training Loss: 0.1500045359134674
Test Loss:  0.1767045110464096
Valid Loss:  0.17946738004684448
Epoch:  302  	Training Loss: 0.15000154078006744
Test Loss:  0.17670097947120667
Valid Loss:  0.17946378886699677
Epoch:  303  	Training Loss: 0.14999857544898987
Test Loss:  0.17669743299484253
Valid Loss:  0.17946018278598785
Epoch:  304  	Training Loss: 0.1499955952167511
Test Loss:  0.1766938865184784
Valid Loss:  0.17945659160614014
Epoch:  305  	Training Loss: 0.14999264478683472
Test Loss:  0.17669036984443665
Valid Loss:  0.17945298552513123
Epoch:  306  	Training Loss: 0.14998966455459595
Test Loss:  0.1766868382692337
Valid Loss:  0.1794494092464447
Epoch:  307  	Training Loss: 0.14998669922351837
Test Loss:  0.17668329179286957
Valid Loss:  0.1794458031654358
Epoch:  308  	Training Loss: 0.1499837338924408
Test Loss:  0.17667976021766663
Valid Loss:  0.17944222688674927
Epoch:  309  	Training Loss: 0.14998076856136322
Test Loss:  0.1766762137413025
Valid Loss:  0.17943862080574036
Epoch:  310  	Training Loss: 0.14997780323028564
Test Loss:  0.17667269706726074
Valid Loss:  0.17943502962589264
Epoch:  311  	Training Loss: 0.14997483789920807
Test Loss:  0.1766691505908966
Valid Loss:  0.17943143844604492
Epoch:  312  	Training Loss: 0.1499718725681305
Test Loss:  0.17666563391685486
Valid Loss:  0.1794278621673584
Epoch:  313  	Training Loss: 0.1499689221382141
Test Loss:  0.1766621172428131
Valid Loss:  0.17942428588867188
Epoch:  314  	Training Loss: 0.14996597170829773
Test Loss:  0.17665861546993256
Valid Loss:  0.17942072451114655
Epoch:  315  	Training Loss: 0.14996302127838135
Test Loss:  0.1766550987958908
Valid Loss:  0.17941716313362122
Epoch:  316  	Training Loss: 0.14996007084846497
Test Loss:  0.17665158212184906
Valid Loss:  0.1794135868549347
Epoch:  317  	Training Loss: 0.14995712041854858
Test Loss:  0.1766480803489685
Valid Loss:  0.17941001057624817
Epoch:  318  	Training Loss: 0.1499541699886322
Test Loss:  0.17664457857608795
Valid Loss:  0.17940643429756165
Epoch:  319  	Training Loss: 0.14995121955871582
Test Loss:  0.176641047000885
Valid Loss:  0.1794028878211975
Epoch:  320  	Training Loss: 0.14994828402996063
Test Loss:  0.17663756012916565
Valid Loss:  0.179399311542511
Epoch:  321  	Training Loss: 0.14994533360004425
Test Loss:  0.1766340285539627
Valid Loss:  0.17939573526382446
Epoch:  322  	Training Loss: 0.14994238317012787
Test Loss:  0.17663054168224335
Valid Loss:  0.17939217388629913
Epoch:  323  	Training Loss: 0.14993944764137268
Test Loss:  0.1766270399093628
Valid Loss:  0.1793886423110962
Epoch:  324  	Training Loss: 0.1499365270137787
Test Loss:  0.17662355303764343
Valid Loss:  0.17938508093357086
Epoch:  325  	Training Loss: 0.1499335765838623
Test Loss:  0.17662006616592407
Valid Loss:  0.17938153445720673
Epoch:  326  	Training Loss: 0.1499306559562683
Test Loss:  0.17661654949188232
Valid Loss:  0.1793779730796814
Epoch:  327  	Training Loss: 0.14992772042751312
Test Loss:  0.17661306262016296
Valid Loss:  0.17937442660331726
Epoch:  328  	Training Loss: 0.14992478489875793
Test Loss:  0.1766095757484436
Valid Loss:  0.17937088012695312
Epoch:  329  	Training Loss: 0.14992184937000275
Test Loss:  0.17660607397556305
Valid Loss:  0.1793673187494278
Epoch:  330  	Training Loss: 0.14991891384124756
Test Loss:  0.17660260200500488
Valid Loss:  0.17936377227306366
Epoch:  331  	Training Loss: 0.14991599321365356
Test Loss:  0.17659910023212433
Valid Loss:  0.17936021089553833
Epoch:  332  	Training Loss: 0.14991304278373718
Test Loss:  0.17659562826156616
Valid Loss:  0.17935670912265778
Epoch:  333  	Training Loss: 0.14991015195846558
Test Loss:  0.1765921711921692
Valid Loss:  0.17935317754745483
Epoch:  334  	Training Loss: 0.14990723133087158
Test Loss:  0.17658871412277222
Valid Loss:  0.17934966087341309
Epoch:  335  	Training Loss: 0.14990434050559998
Test Loss:  0.17658525705337524
Valid Loss:  0.17934614419937134
Epoch:  336  	Training Loss: 0.14990141987800598
Test Loss:  0.17658179998397827
Valid Loss:  0.17934264242649078
Epoch:  337  	Training Loss: 0.14989852905273438
Test Loss:  0.1765783429145813
Valid Loss:  0.17933911085128784
Epoch:  338  	Training Loss: 0.14989560842514038
Test Loss:  0.17657488584518433
Valid Loss:  0.1793356090784073
Epoch:  339  	Training Loss: 0.14989271759986877
Test Loss:  0.17657142877578735
Valid Loss:  0.17933206260204315
Epoch:  340  	Training Loss: 0.14988981187343597
Test Loss:  0.1765679568052292
Valid Loss:  0.1793285757303238
Epoch:  341  	Training Loss: 0.14988690614700317
Test Loss:  0.1765645146369934
Valid Loss:  0.17932504415512085
Epoch:  342  	Training Loss: 0.14988401532173157
Test Loss:  0.17656105756759644
Valid Loss:  0.1793215423822403
Epoch:  343  	Training Loss: 0.14988109469413757
Test Loss:  0.17655761539936066
Valid Loss:  0.17931805551052094
Epoch:  344  	Training Loss: 0.14987820386886597
Test Loss:  0.17655417323112488
Valid Loss:  0.17931455373764038
Epoch:  345  	Training Loss: 0.14987531304359436
Test Loss:  0.1765507161617279
Valid Loss:  0.17931105196475983
Epoch:  346  	Training Loss: 0.14987243711948395
Test Loss:  0.17654728889465332
Valid Loss:  0.17930756509304047
Epoch:  347  	Training Loss: 0.14986953139305115
Test Loss:  0.17654384672641754
Valid Loss:  0.17930404841899872
Epoch:  348  	Training Loss: 0.14986664056777954
Test Loss:  0.17654040455818176
Valid Loss:  0.17930054664611816
Epoch:  349  	Training Loss: 0.14986374974250793
Test Loss:  0.17653696238994598
Valid Loss:  0.1792970597743988
Epoch:  350  	Training Loss: 0.14986087381839752
Test Loss:  0.1765335202217102
Valid Loss:  0.17929355800151825
Epoch:  351  	Training Loss: 0.14985796809196472
Test Loss:  0.17653007805347443
Valid Loss:  0.1792900562286377
Epoch:  352  	Training Loss: 0.14985507726669312
Test Loss:  0.17652666568756104
Valid Loss:  0.17928656935691833
Epoch:  353  	Training Loss: 0.1498522013425827
Test Loss:  0.17652323842048645
Valid Loss:  0.17928309738636017
Epoch:  354  	Training Loss: 0.14984934031963348
Test Loss:  0.17651981115341187
Valid Loss:  0.179279625415802
Epoch:  355  	Training Loss: 0.14984646439552307
Test Loss:  0.17651641368865967
Valid Loss:  0.17927613854408264
Epoch:  356  	Training Loss: 0.14984358847141266
Test Loss:  0.17651298642158508
Valid Loss:  0.17927268147468567
Epoch:  357  	Training Loss: 0.14984071254730225
Test Loss:  0.1765095740556717
Valid Loss:  0.1792691946029663
Epoch:  358  	Training Loss: 0.14983785152435303
Test Loss:  0.1765061318874359
Valid Loss:  0.17926572263240814
Epoch:  359  	Training Loss: 0.14983497560024261
Test Loss:  0.17650270462036133
Valid Loss:  0.17926225066184998
Epoch:  360  	Training Loss: 0.1498320996761322
Test Loss:  0.17649930715560913
Valid Loss:  0.17925876379013062
Epoch:  361  	Training Loss: 0.14982923865318298
Test Loss:  0.17649590969085693
Valid Loss:  0.17925529181957245
Epoch:  362  	Training Loss: 0.14982634782791138
Test Loss:  0.17649248242378235
Valid Loss:  0.17925184965133667
Epoch:  363  	Training Loss: 0.14982351660728455
Test Loss:  0.17648911476135254
Valid Loss:   73%|███████▎  | 363/500 [04:18<01:58,  1.16it/s] 73%|███████▎  | 365/500 [04:18<01:24,  1.59it/s] 73%|███████▎  | 367/500 [04:18<01:02,  2.14it/s] 74%|███████▍  | 369/500 [04:18<00:46,  2.83it/s] 74%|███████▍  | 371/500 [04:25<02:37,  1.22s/it] 75%|███████▍  | 373/500 [04:25<01:51,  1.14it/s] 75%|███████▌  | 375/500 [04:25<01:18,  1.58it/s] 75%|███████▌  | 377/500 [04:25<00:56,  2.17it/s] 76%|███████▌  | 379/500 [04:25<00:41,  2.88it/s] 76%|███████▌  | 381/500 [04:32<02:23,  1.21s/it] 77%|███████▋  | 383/500 [04:32<01:41,  1.15it/s] 77%|███████▋  | 385/500 [04:32<01:11,  1.60it/s] 77%|███████▋  | 387/500 [04:32<00:51,  2.19it/s] 78%|███████▊  | 389/500 [04:32<00:37,  2.94it/s] 78%|███████▊  | 391/500 [04:38<02:10,  1.20s/it] 79%|███████▊  | 393/500 [04:39<01:31,  1.16it/s] 79%|███████▉  | 395/500 [04:39<01:05,  1.61it/s] 79%|███████▉  | 397/500 [04:39<00:46,  2.20it/s] 80%|███████▉  | 399/500 [04:39<00:34,  2.96it/s] 80%|████████  | 401/500 [04:45<01:57,  1.19s/it] 81%|████████  | 403/500 [04:46<01:22,  1.17it/s] 81%|████████  | 405/500 [04:46<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:46<00:41,  2.21it/s] 82%|████████▏ | 409/500 [04:46<00:30,  2.98it/s] 82%|████████▏ | 411/500 [04:52<01:46,  1.19s/it] 83%|████████▎ | 413/500 [04:52<01:14,  1.16it/s] 83%|████████▎ | 415/500 [04:53<00:52,  1.61it/s] 83%|████████▎ | 417/500 [04:53<00:37,  2.20it/s] 84%|████████▍ | 419/500 [04:53<00:27,  2.96it/s] 84%|████████▍ | 421/500 [04:59<01:33,  1.19s/it] 85%|████████▍ | 423/500 [04:59<01:05,  1.17it/s] 85%|████████▌ | 425/500 [04:59<00:46,  1.62it/s] 85%|████████▌ | 427/500 [05:00<00:33,  2.20it/s] 86%|████████▌ | 429/500 [05:00<00:23,  2.97it/s] 86%|████████▌ | 431/500 [05:06<01:24,  1.22s/it] 87%|████████▋ | 433/500 [05:06<00:58,  1.14it/s] 87%|████████▋ | 435/500 [05:07<00:41,  1.58it/s]0.1792483925819397
Epoch:  364  	Training Loss: 0.14982065558433533
Test Loss:  0.17648571729660034
Valid Loss:  0.17924493551254272
Epoch:  365  	Training Loss: 0.1498178094625473
Test Loss:  0.17648231983184814
Valid Loss:  0.17924149334430695
Epoch:  366  	Training Loss: 0.14981496334075928
Test Loss:  0.17647892236709595
Valid Loss:  0.17923805117607117
Epoch:  367  	Training Loss: 0.14981210231781006
Test Loss:  0.17647552490234375
Valid Loss:  0.1792345941066742
Epoch:  368  	Training Loss: 0.14980924129486084
Test Loss:  0.17647214233875275
Valid Loss:  0.17923113703727722
Epoch:  369  	Training Loss: 0.149806410074234
Test Loss:  0.17646875977516174
Valid Loss:  0.17922770977020264
Epoch:  370  	Training Loss: 0.1498035490512848
Test Loss:  0.17646534740924835
Valid Loss:  0.17922423779964447
Epoch:  371  	Training Loss: 0.14980068802833557
Test Loss:  0.17646194994449615
Valid Loss:  0.1792207956314087
Epoch:  372  	Training Loss: 0.14979785680770874
Test Loss:  0.17645856738090515
Valid Loss:  0.1792173683643341
Epoch:  373  	Training Loss: 0.1497950255870819
Test Loss:  0.17645519971847534
Valid Loss:  0.17921394109725952
Epoch:  374  	Training Loss: 0.14979217946529388
Test Loss:  0.17645183205604553
Valid Loss:  0.17921051383018494
Epoch:  375  	Training Loss: 0.14978933334350586
Test Loss:  0.17644844949245453
Valid Loss:  0.17920707166194916
Epoch:  376  	Training Loss: 0.14978650212287903
Test Loss:  0.1764450967311859
Valid Loss:  0.17920362949371338
Epoch:  377  	Training Loss: 0.1497836709022522
Test Loss:  0.17644169926643372
Valid Loss:  0.1792002171278
Epoch:  378  	Training Loss: 0.14978083968162537
Test Loss:  0.1764383316040039
Valid Loss:  0.1791967749595642
Epoch:  379  	Training Loss: 0.14977800846099854
Test Loss:  0.1764349490404129
Valid Loss:  0.17919334769248962
Epoch:  380  	Training Loss: 0.14977514743804932
Test Loss:  0.1764315813779831
Valid Loss:  0.17918992042541504
Epoch:  381  	Training Loss: 0.14977233111858368
Test Loss:  0.17642821371555328
Valid Loss:  0.17918649315834045
Epoch:  382  	Training Loss: 0.14976948499679565
Test Loss:  0.17642486095428467
Valid Loss:  0.17918309569358826
Epoch:  383  	Training Loss: 0.1497666835784912
Test Loss:  0.17642152309417725
Valid Loss:  0.17917969822883606
Epoch:  384  	Training Loss: 0.14976386725902557
Test Loss:  0.17641818523406982
Valid Loss:  0.17917630076408386
Epoch:  385  	Training Loss: 0.14976108074188232
Test Loss:  0.1764148473739624
Valid Loss:  0.17917290329933167
Epoch:  386  	Training Loss: 0.1497582495212555
Test Loss:  0.17641150951385498
Valid Loss:  0.17916950583457947
Epoch:  387  	Training Loss: 0.14975544810295105
Test Loss:  0.17640817165374756
Valid Loss:  0.17916610836982727
Epoch:  388  	Training Loss: 0.1497526466846466
Test Loss:  0.17640481889247894
Valid Loss:  0.17916272580623627
Epoch:  389  	Training Loss: 0.14974984526634216
Test Loss:  0.17640149593353271
Valid Loss:  0.17915931344032288
Epoch:  390  	Training Loss: 0.14974702894687653
Test Loss:  0.1763981431722641
Valid Loss:  0.17915593087673187
Epoch:  391  	Training Loss: 0.1497442126274109
Test Loss:  0.17639482021331787
Valid Loss:  0.17915251851081848
Epoch:  392  	Training Loss: 0.14974141120910645
Test Loss:  0.17639148235321045
Valid Loss:  0.17914915084838867
Epoch:  393  	Training Loss: 0.1497386246919632
Test Loss:  0.17638817429542542
Valid Loss:  0.17914578318595886
Epoch:  394  	Training Loss: 0.14973583817481995
Test Loss:  0.17638486623764038
Valid Loss:  0.17914240062236786
Epoch:  395  	Training Loss: 0.1497330516576767
Test Loss:  0.17638152837753296
Valid Loss:  0.17913904786109924
Epoch:  396  	Training Loss: 0.14973028004169464
Test Loss:  0.17637822031974792
Valid Loss:  0.17913568019866943
Epoch:  397  	Training Loss: 0.1497274935245514
Test Loss:  0.1763749122619629
Valid Loss:  0.17913231253623962
Epoch:  398  	Training Loss: 0.14972469210624695
Test Loss:  0.17637160420417786
Valid Loss:  0.17912891507148743
Epoch:  399  	Training Loss: 0.1497219055891037
Test Loss:  0.17636826634407043
Valid Loss:  0.1791255623102188
Epoch:  400  	Training Loss: 0.14971911907196045
Test Loss:  0.1763649731874466
Valid Loss:  0.179122194647789
Epoch:  401  	Training Loss: 0.1497163474559784
Test Loss:  0.17636165022850037
Valid Loss:  0.179118812084198
Epoch:  402  	Training Loss: 0.14971354603767395
Test Loss:  0.17635835707187653
Valid Loss:  0.17911547422409058
Epoch:  403  	Training Loss: 0.1497107893228531
Test Loss:  0.17635506391525269
Valid Loss:  0.17911213636398315
Epoch:  404  	Training Loss: 0.14970800280570984
Test Loss:  0.17635175585746765
Valid Loss:  0.17910876870155334
Epoch:  405  	Training Loss: 0.14970523118972778
Test Loss:  0.176348477602005
Valid Loss:  0.17910543084144592
Epoch:  406  	Training Loss: 0.14970247447490692
Test Loss:  0.17634518444538116
Valid Loss:  0.1791020780801773
Epoch:  407  	Training Loss: 0.14969970285892487
Test Loss:  0.17634189128875732
Valid Loss:  0.17909874022006989
Epoch:  408  	Training Loss: 0.149696946144104
Test Loss:  0.1763385832309723
Valid Loss:  0.17909538745880127
Epoch:  409  	Training Loss: 0.14969417452812195
Test Loss:  0.17633530497550964
Valid Loss:  0.17909203469753265
Epoch:  410  	Training Loss: 0.1496914029121399
Test Loss:  0.1763319969177246
Valid Loss:  0.17908868193626404
Epoch:  411  	Training Loss: 0.14968863129615784
Test Loss:  0.17632871866226196
Valid Loss:  0.17908534407615662
Epoch:  412  	Training Loss: 0.14968585968017578
Test Loss:  0.17632544040679932
Valid Loss:  0.1790820062160492
Epoch:  413  	Training Loss: 0.1496831178665161
Test Loss:  0.17632219195365906
Valid Loss:  0.17907869815826416
Epoch:  414  	Training Loss: 0.14968037605285645
Test Loss:  0.1763189136981964
Valid Loss:  0.17907536029815674
Epoch:  415  	Training Loss: 0.14967763423919678
Test Loss:  0.17631565034389496
Valid Loss:  0.1790720522403717
Epoch:  416  	Training Loss: 0.14967487752437592
Test Loss:  0.1763123869895935
Valid Loss:  0.17906872928142548
Epoch:  417  	Training Loss: 0.14967213571071625
Test Loss:  0.17630910873413086
Valid Loss:  0.17906540632247925
Epoch:  418  	Training Loss: 0.14966939389705658
Test Loss:  0.1763058453798294
Valid Loss:  0.17906208336353302
Epoch:  419  	Training Loss: 0.14966663718223572
Test Loss:  0.17630258202552795
Valid Loss:  0.1790587604045868
Epoch:  420  	Training Loss: 0.14966389536857605
Test Loss:  0.1762993037700653
Valid Loss:  0.17905543744564056
Epoch:  421  	Training Loss: 0.149661123752594
Test Loss:  0.17629602551460266
Valid Loss:  0.17905211448669434
Epoch:  422  	Training Loss: 0.14965838193893433
Test Loss:  0.1762927919626236
Valid Loss:  0.1790488064289093
Epoch:  423  	Training Loss: 0.14965566992759705
Test Loss:  0.17628955841064453
Valid Loss:  0.17904551327228546
Epoch:  424  	Training Loss: 0.14965292811393738
Test Loss:  0.17628630995750427
Valid Loss:  0.17904222011566162
Epoch:  425  	Training Loss: 0.1496502161026001
Test Loss:  0.176283061504364
Valid Loss:  0.1790389120578766
Epoch:  426  	Training Loss: 0.14964748919010162
Test Loss:  0.17627981305122375
Valid Loss:  0.17903561890125275
Epoch:  427  	Training Loss: 0.14964473247528076
Test Loss:  0.1762765645980835
Valid Loss:  0.1790323257446289
Epoch:  428  	Training Loss: 0.14964202046394348
Test Loss:  0.17627331614494324
Valid Loss:  0.17902901768684387
Epoch:  429  	Training Loss: 0.149639293551445
Test Loss:  0.17627006769180298
Valid Loss:  0.17902570962905884
Epoch:  430  	Training Loss: 0.14963656663894653
Test Loss:  0.1762668490409851
Valid Loss:  0.1790224313735962
Epoch:  431  	Training Loss: 0.14963382482528687
Test Loss:  0.17626357078552246
Valid Loss:  0.17901912331581116
Epoch:  432  	Training Loss: 0.14963111281394958
Test Loss:  0.1762603521347046
Valid Loss:  0.1790158450603485
Epoch:  433  	Training Loss: 0.1496284008026123
Test Loss:  0.17625713348388672
Valid Loss:  0.17901255190372467
Epoch:  434  	Training Loss: 0.14962567389011383
Test Loss:  0.17625388503074646
Valid Loss:  0.17900925874710083
Epoch:  435  	Training Loss: 0.14962296187877655
Test Loss:  0.1762506663799286
Valid Loss:  0.17900599539279938
 87%|████████▋ | 437/500 [05:07<00:29,  2.16it/s] 88%|████████▊ | 439/500 [05:07<00:20,  2.91it/s] 88%|████████▊ | 441/500 [05:13<01:11,  1.21s/it] 89%|████████▊ | 443/500 [05:13<00:49,  1.15it/s] 89%|████████▉ | 445/500 [05:14<00:34,  1.59it/s] 89%|████████▉ | 447/500 [05:14<00:24,  2.17it/s] 90%|████████▉ | 449/500 [05:14<00:17,  2.86it/s] 90%|█████████ | 451/500 [05:20<00:59,  1.22s/it] 91%|█████████ | 453/500 [05:21<00:41,  1.14it/s] 91%|█████████ | 455/500 [05:21<00:28,  1.57it/s] 91%|█████████▏| 457/500 [05:21<00:19,  2.15it/s] 92%|█████████▏| 459/500 [05:21<00:14,  2.90it/s] 92%|█████████▏| 461/500 [05:28<00:47,  1.23s/it] 93%|█████████▎| 463/500 [05:28<00:32,  1.13it/s] 93%|█████████▎| 465/500 [05:28<00:22,  1.57it/s] 93%|█████████▎| 467/500 [05:28<00:15,  2.15it/s] 94%|█████████▍| 469/500 [05:28<00:10,  2.89it/s] 94%|█████████▍| 471/500 [05:35<00:35,  1.23s/it] 94%|█████████▍| 472/500 [05:35<00:28,  1.03s/it] 95%|█████████▍| 474/500 [05:35<00:18,  1.40it/s] 95%|█████████▌| 476/500 [05:35<00:12,  1.95it/s] 96%|█████████▌| 478/500 [05:35<00:08,  2.64it/s] 96%|█████████▌| 480/500 [05:36<00:05,  3.48it/s] 96%|█████████▋| 482/500 [05:42<00:22,  1.24s/it] 97%|█████████▋| 484/500 [05:42<00:14,  1.13it/s] 97%|█████████▋| 486/500 [05:43<00:08,  1.56it/s] 98%|█████████▊| 488/500 [05:43<00:05,  2.11it/s] 98%|█████████▊| 490/500 [05:43<00:03,  2.79it/s] 98%|█████████▊| 492/500 [05:49<00:09,  1.23s/it] 99%|█████████▉| 494/500 [05:50<00:05,  1.14it/s] 99%|█████████▉| 496/500 [05:50<00:02,  1.57it/s]100%|█████████▉| 498/500 [05:50<00:00,  2.15it/s]100%|██████████| 500/500 [05:50<00:00,  2.89it/s]100%|██████████| 500/500 [05:50<00:00,  1.43it/s]
Epoch:  436  	Training Loss: 0.14962023496627808
Test Loss:  0.17624744772911072
Valid Loss:  0.17900270223617554
Epoch:  437  	Training Loss: 0.1496175229549408
Test Loss:  0.17624419927597046
Valid Loss:  0.1789994239807129
Epoch:  438  	Training Loss: 0.14961481094360352
Test Loss:  0.1762409806251526
Valid Loss:  0.17899614572525024
Epoch:  439  	Training Loss: 0.14961208403110504
Test Loss:  0.17623776197433472
Valid Loss:  0.1789928674697876
Epoch:  440  	Training Loss: 0.14960937201976776
Test Loss:  0.17623452842235565
Valid Loss:  0.17898957431316376
Epoch:  441  	Training Loss: 0.14960666000843048
Test Loss:  0.1762312948703766
Valid Loss:  0.1789862960577011
Epoch:  442  	Training Loss: 0.1496039479970932
Test Loss:  0.1762280911207199
Valid Loss:  0.17898304760456085
Epoch:  443  	Training Loss: 0.1496012657880783
Test Loss:  0.17622491717338562
Valid Loss:  0.1789798140525818
Epoch:  444  	Training Loss: 0.14959858357906342
Test Loss:  0.17622172832489014
Valid Loss:  0.17897656559944153
Epoch:  445  	Training Loss: 0.14959590137004852
Test Loss:  0.17621853947639465
Valid Loss:  0.17897331714630127
Epoch:  446  	Training Loss: 0.14959323406219482
Test Loss:  0.17621535062789917
Valid Loss:  0.1789700835943222
Epoch:  447  	Training Loss: 0.14959052205085754
Test Loss:  0.1762121617794037
Valid Loss:  0.17896685004234314
Epoch:  448  	Training Loss: 0.14958785474300385
Test Loss:  0.1762089729309082
Valid Loss:  0.17896360158920288
Epoch:  449  	Training Loss: 0.14958517253398895
Test Loss:  0.17620578408241272
Valid Loss:  0.17896035313606262
Epoch:  450  	Training Loss: 0.14958250522613525
Test Loss:  0.17620259523391724
Valid Loss:  0.17895713448524475
Epoch:  451  	Training Loss: 0.14957980811595917
Test Loss:  0.17619940638542175
Valid Loss:  0.1789538860321045
Epoch:  452  	Training Loss: 0.14957712590694427
Test Loss:  0.17619621753692627
Valid Loss:  0.17895063757896423
Epoch:  453  	Training Loss: 0.14957445859909058
Test Loss:  0.1761930286884308
Valid Loss:  0.17894741892814636
Epoch:  454  	Training Loss: 0.14957177639007568
Test Loss:  0.1761898547410965
Valid Loss:  0.1789441704750061
Epoch:  455  	Training Loss: 0.1495690941810608
Test Loss:  0.1761866807937622
Valid Loss:  0.17894092202186584
Epoch:  456  	Training Loss: 0.1495664268732071
Test Loss:  0.17618349194526672
Valid Loss:  0.17893770337104797
Epoch:  457  	Training Loss: 0.1495637446641922
Test Loss:  0.17618031799793243
Valid Loss:  0.1789344698190689
Epoch:  458  	Training Loss: 0.1495610624551773
Test Loss:  0.17617712914943695
Valid Loss:  0.17893123626708984
Epoch:  459  	Training Loss: 0.14955838024616241
Test Loss:  0.17617395520210266
Valid Loss:  0.17892800271511078
Epoch:  460  	Training Loss: 0.14955571293830872
Test Loss:  0.17617078125476837
Valid Loss:  0.1789247691631317
Epoch:  461  	Training Loss: 0.14955304563045502
Test Loss:  0.17616760730743408
Valid Loss:  0.17892155051231384
Epoch:  462  	Training Loss: 0.14955037832260132
Test Loss:  0.176164448261261
Valid Loss:  0.17891833186149597
Epoch:  463  	Training Loss: 0.14954771101474762
Test Loss:  0.1761612892150879
Valid Loss:  0.1789151430130005
Epoch:  464  	Training Loss: 0.14954505860805511
Test Loss:  0.17615815997123718
Valid Loss:  0.17891192436218262
Epoch:  465  	Training Loss: 0.1495424211025238
Test Loss:  0.1761550009250641
Valid Loss:  0.17890870571136475
Epoch:  466  	Training Loss: 0.1495397686958313
Test Loss:  0.176151841878891
Valid Loss:  0.17890551686286926
Epoch:  467  	Training Loss: 0.1495371162891388
Test Loss:  0.1761486977338791
Valid Loss:  0.17890231311321259
Epoch:  468  	Training Loss: 0.1495344638824463
Test Loss:  0.176145538687706
Valid Loss:  0.1788991093635559
Epoch:  469  	Training Loss: 0.14953181147575378
Test Loss:  0.1761423945426941
Valid Loss:  0.17889592051506042
Epoch:  470  	Training Loss: 0.14952915906906128
Test Loss:  0.176139235496521
Valid Loss:  0.17889271676540375
Epoch:  471  	Training Loss: 0.14952650666236877
Test Loss:  0.1761361062526703
Valid Loss:  0.17888951301574707
Epoch:  472  	Training Loss: 0.14952386915683746
Test Loss:  0.17613297700881958
Valid Loss:  0.17888633906841278
Epoch:  473  	Training Loss: 0.14952124655246735
Test Loss:  0.17612984776496887
Valid Loss:  0.1788831651210785
Epoch:  474  	Training Loss: 0.14951862394809723
Test Loss:  0.17612673342227936
Valid Loss:  0.1788799911737442
Epoch:  475  	Training Loss: 0.14951598644256592
Test Loss:  0.17612360417842865
Valid Loss:  0.1788768172264099
Epoch:  476  	Training Loss: 0.1495133638381958
Test Loss:  0.17612048983573914
Valid Loss:  0.17887362837791443
Epoch:  477  	Training Loss: 0.14951074123382568
Test Loss:  0.17611736059188843
Valid Loss:  0.17887046933174133
Epoch:  478  	Training Loss: 0.14950811862945557
Test Loss:  0.1761142462491989
Valid Loss:  0.17886729538440704
Epoch:  479  	Training Loss: 0.14950548112392426
Test Loss:  0.1761111319065094
Valid Loss:  0.17886412143707275
Epoch:  480  	Training Loss: 0.14950287342071533
Test Loss:  0.1761080026626587
Valid Loss:  0.17886096239089966
Epoch:  481  	Training Loss: 0.14950023591518402
Test Loss:  0.17610490322113037
Valid Loss:  0.17885777354240417
Epoch:  482  	Training Loss: 0.1494975984096527
Test Loss:  0.17610177397727966
Valid Loss:  0.17885464429855347
Epoch:  483  	Training Loss: 0.14949500560760498
Test Loss:  0.17609870433807373
Valid Loss:  0.17885151505470276
Epoch:  484  	Training Loss: 0.14949241280555725
Test Loss:  0.1760956197977066
Valid Loss:  0.17884835600852966
Epoch:  485  	Training Loss: 0.14948982000350952
Test Loss:  0.17609253525733948
Valid Loss:  0.17884522676467896
Epoch:  486  	Training Loss: 0.1494872123003006
Test Loss:  0.17608945071697235
Valid Loss:  0.17884208261966705
Epoch:  487  	Training Loss: 0.14948461949825287
Test Loss:  0.17608636617660522
Valid Loss:  0.17883893847465515
Epoch:  488  	Training Loss: 0.14948201179504395
Test Loss:  0.1760832667350769
Valid Loss:  0.17883580923080444
Epoch:  489  	Training Loss: 0.14947941899299622
Test Loss:  0.17608019709587097
Valid Loss:  0.17883267998695374
Epoch:  490  	Training Loss: 0.1494768261909485
Test Loss:  0.17607709765434265
Valid Loss:  0.17882952094078064
Epoch:  491  	Training Loss: 0.14947423338890076
Test Loss:  0.17607399821281433
Valid Loss:  0.17882639169692993
Epoch:  492  	Training Loss: 0.14947162568569183
Test Loss:  0.1760709434747696
Valid Loss:  0.17882326245307922
Epoch:  493  	Training Loss: 0.1494690477848053
Test Loss:  0.17606785893440247
Valid Loss:  0.1788201481103897
Epoch:  494  	Training Loss: 0.14946645498275757
Test Loss:  0.17606478929519653
Valid Loss:  0.1788170337677002
Epoch:  495  	Training Loss: 0.14946389198303223
Test Loss:  0.1760617196559906
Valid Loss:  0.17881391942501068
Epoch:  496  	Training Loss: 0.1494612991809845
Test Loss:  0.17605866491794586
Valid Loss:  0.17881079018115997
Epoch:  497  	Training Loss: 0.14945872128009796
Test Loss:  0.17605561017990112
Valid Loss:  0.17880767583847046
Epoch:  498  	Training Loss: 0.14945614337921143
Test Loss:  0.1760525405406952
Valid Loss:  0.17880457639694214
Epoch:  499  	Training Loss: 0.1494535505771637
Test Loss:  0.17604947090148926
Valid Loss:  0.17880141735076904
Epoch:  500  	Training Loss: 0.14945098757743835
Test Loss:  0.17604640126228333
Valid Loss:  0.17879831790924072
seed is  12
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:20,  6.29s/it]  1%|          | 3/500 [00:06<13:55,  1.68s/it]  1%|          | 5/500 [00:06<07:00,  1.18it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.89it/s]  2%|▏         | 11/500 [00:13<10:59,  1.35s/it]  3%|▎         | 13/500 [00:13<07:29,  1.08it/s]  3%|▎         | 15/500 [00:13<05:13,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:43,  2.95it/s]  4%|▍         | 21/500 [00:20<09:47,  1.23s/it]  5%|▍         | 23/500 [00:20<06:55,  1.15it/s]  5%|▌         | 25/500 [00:20<04:57,  1.60it/s]  5%|▌         | 27/500 [00:20<03:36,  2.19it/s]  6%|▌         | 29/500 [00:20<02:41,  2.92it/s]  6%|▌         | 31/500 [00:33<16:53,  2.16s/it]  7%|▋         | 33/500 [00:33<11:54,  1.53s/it]  7%|▋         | 35/500 [00:33<08:26,  1.09s/it]  7%|▋         | 37/500 [00:33<06:02,  1.28it/s]  8%|▊         | 39/500 [00:34<04:21,  1.77it/s]  8%|▊         | 41/500 [00:40<10:16,  1.34s/it]  9%|▊         | 43/500 [00:40<07:19,  1.04it/s]  9%|▉         | 45/500 [00:40<05:15,  1.44it/s]  9%|▉         | 47/500 [00:40<03:49,  1.98it/s] 10%|▉         | 49/500 [00:40<02:48,  2.68it/s] 10%|█         | 51/500 [00:47<09:01,  1.21s/it] 11%|█         | 53/500 [00:47<06:25,  1.16it/s] 11%|█         | 55/500 [00:47<04:37,  1.60it/s] 11%|█▏        | 57/500 [00:47<03:21,  2.19it/s] 12%|█▏        | 59/500 [00:47<02:29,  2.96it/s] 12%|█▏        | 61/500 [00:54<08:49,  1.21s/it] 13%|█▎        | 63/500 [00:54<06:18,  1.15it/s] 13%|█▎        | 65/500 [00:54<04:33,  1.59it/s] 13%|█▎        | 67/500 [00:54<03:18,  2.18it/s]Epoch:  1  	Training Loss: 0.15179064869880676
Test Loss:  1.1800856590270996
Valid Loss:  1.1674495935440063
Epoch:  2  	Training Loss: 1.2638227939605713
Test Loss:  0.5105186700820923
Valid Loss:  0.518038809299469
Epoch:  3  	Training Loss: 0.46157923340797424
Test Loss:  0.02767738327383995
Valid Loss:  0.026822030544281006
Epoch:  4  	Training Loss: 0.02466004341840744
Test Loss:  0.016722284257411957
Valid Loss:  0.015588810667395592
Epoch:  5  	Training Loss: 0.017488643527030945
Test Loss:  0.013448318466544151
Valid Loss:  0.01246497593820095
Epoch:  6  	Training Loss: 0.014548372477293015
Test Loss:  0.011979751288890839
Valid Loss:  0.011128900572657585
Epoch:  7  	Training Loss: 0.012840533629059792
Test Loss:  0.011391771025955677
Valid Loss:  0.010650653392076492
Epoch:  8  	Training Loss: 0.011954272165894508
Test Loss:  0.010697058402001858
Valid Loss:  0.01001784112304449
Epoch:  9  	Training Loss: 0.011217184364795685
Test Loss:  0.01000550389289856
Valid Loss:  0.009373607113957405
Epoch:  10  	Training Loss: 0.010540948249399662
Test Loss:  0.009355142712593079
Valid Loss:  0.008764177560806274
Epoch:  11  	Training Loss: 0.009915605187416077
Test Loss:  0.00875073205679655
Valid Loss:  0.008198374882340431
Epoch:  12  	Training Loss: 0.009338556788861752
Test Loss:  0.0064883725717663765
Valid Loss:  0.0061339931562542915
Epoch:  13  	Training Loss: 0.00685462262481451
Test Loss:  0.003948281519114971
Valid Loss:  0.003772342810407281
Epoch:  14  	Training Loss: 0.004387840628623962
Test Loss:  0.002801197115331888
Valid Loss:  0.0027406259905546904
Epoch:  15  	Training Loss: 0.003010756801813841
Test Loss:  0.0019810486119240522
Valid Loss:  0.0018965566996484995
Epoch:  16  	Training Loss: 0.0022875198628753424
Test Loss:  0.00158979173284024
Valid Loss:  0.0015415824018418789
Epoch:  17  	Training Loss: 0.0018744829576462507
Test Loss:  0.0012604795629158616
Valid Loss:  0.0012371151242405176
Epoch:  18  	Training Loss: 0.001592421904206276
Test Loss:  0.001078229513950646
Valid Loss:  0.0010850029066205025
Epoch:  19  	Training Loss: 0.001389209646731615
Test Loss:  0.0009172145510092378
Valid Loss:  0.0009439480490982533
Epoch:  20  	Training Loss: 0.00123498379252851
Test Loss:  0.0008140957215800881
Valid Loss:  0.0008624682668596506
Epoch:  21  	Training Loss: 0.0011154848616570234
Test Loss:  0.0007254993543028831
Valid Loss:  0.0007907316321507096
Epoch:  22  	Training Loss: 0.0010216108057647943
Test Loss:  0.0005586462211795151
Valid Loss:  0.0006617880426347256
Epoch:  23  	Training Loss: 0.0008368472335860133
Test Loss:  0.0005232418770901859
Valid Loss:  0.0006590505945496261
Epoch:  24  	Training Loss: 0.000748997088521719
Test Loss:  0.0004649690235964954
Valid Loss:  0.0006181902135722339
Epoch:  25  	Training Loss: 0.0007105760741978884
Test Loss:  0.0005276880692690611
Valid Loss:  0.0006983139319345355
Epoch:  26  	Training Loss: 0.0007101790397427976
Test Loss:  0.000492639490403235
Valid Loss:  0.0006590995471924543
Epoch:  27  	Training Loss: 0.0007555331685580313
Test Loss:  0.0006128684617578983
Valid Loss:  0.0007988492725417018
Epoch:  28  	Training Loss: 0.0007728199125267565
Test Loss:  0.000588867231272161
Valid Loss:  0.000750115083064884
Epoch:  29  	Training Loss: 0.0008874727063812315
Test Loss:  0.000615208875387907
Valid Loss:  0.0008033091435208917
Epoch:  30  	Training Loss: 0.0007707980694249272
Test Loss:  0.0005276408046483994
Valid Loss:  0.0006958162412047386
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.000806221563834697
Test Loss:  0.0004240054404363036
Valid Loss:  0.0006005712202750146
Epoch:  32  	Training Loss: 0.0006585617084056139
Test Loss:  0.0003691672463901341
Valid Loss:  0.000556231418158859
Epoch:  33  	Training Loss: 0.0005591643275693059
Test Loss:  0.000353742390871048
Valid Loss:  0.0005438404623419046
Epoch:  34  	Training Loss: 0.0005350317806005478
Test Loss:  0.0003338308597449213
Valid Loss:  0.0005256931763142347
Epoch:  35  	Training Loss: 0.0005072407657280564
Test Loss:  0.0003155260346829891
Valid Loss:  0.0005078515969216824
Epoch:  36  	Training Loss: 0.0004833663406316191
Test Loss:  0.000302361004287377
Valid Loss:  0.0004948514979332685
Epoch:  37  	Training Loss: 0.0004678633122239262
Test Loss:  0.00029067654395475984
Valid Loss:  0.000483475043438375
Epoch:  38  	Training Loss: 0.00045287900138646364
Test Loss:  0.0002798137138597667
Valid Loss:  0.00047245435416698456
Epoch:  39  	Training Loss: 0.0004386623331811279
Test Loss:  0.0002696662559174001
Valid Loss:  0.00046248530270531774
Epoch:  40  	Training Loss: 0.00042512762593105435
Test Loss:  0.0002598543360363692
Valid Loss:  0.00045318331103771925
Epoch:  41  	Training Loss: 0.0004124554106965661
Test Loss:  0.00025028028176166117
Valid Loss:  0.0004442355129867792
Epoch:  42  	Training Loss: 0.00040053011616691947
Test Loss:  0.0002446649014018476
Valid Loss:  0.0004388026427477598
Epoch:  43  	Training Loss: 0.0003921643365174532
Test Loss:  0.00023898555082269013
Valid Loss:  0.0004336743731983006
Epoch:  44  	Training Loss: 0.0003844890743494034
Test Loss:  0.00023349901312030852
Valid Loss:  0.0004286810872144997
Epoch:  45  	Training Loss: 0.0003772323252633214
Test Loss:  0.00022832074319012463
Valid Loss:  0.0004238597466610372
Epoch:  46  	Training Loss: 0.00037045928183943033
Test Loss:  0.0002234907151432708
Valid Loss:  0.00041925132973119617
Epoch:  47  	Training Loss: 0.0003641553921625018
Test Loss:  0.00021897214173804969
Valid Loss:  0.0004147935542277992
Epoch:  48  	Training Loss: 0.0003582906210795045
Test Loss:  0.00021470060164574534
Valid Loss:  0.0004105130210518837
Epoch:  49  	Training Loss: 0.0003527941298671067
Test Loss:  0.00021064761676825583
Valid Loss:  0.0004064650274813175
Epoch:  50  	Training Loss: 0.0003476330603007227
Test Loss:  0.0002068390022031963
Valid Loss:  0.0004025837988592684
Epoch:  51  	Training Loss: 0.0003428075578995049
Test Loss:  0.0002032846095971763
Valid Loss:  0.00039885807200334966
Epoch:  52  	Training Loss: 0.0003383182338438928
Test Loss:  0.00019604376575443894
Valid Loss:  0.00039207126246765256
Epoch:  53  	Training Loss: 0.00033078042906709015
Test Loss:  0.00019031259580515325
Valid Loss:  0.00038672570372000337
Epoch:  54  	Training Loss: 0.0003246235428377986
Test Loss:  0.00018607883248478174
Valid Loss:  0.0003824734303634614
Epoch:  55  	Training Loss: 0.00032068073051050305
Test Loss:  0.00018279784126207232
Valid Loss:  0.00037871638778597116
Epoch:  56  	Training Loss: 0.0003178210463374853
Test Loss:  0.0001800666213966906
Valid Loss:  0.0003754360950551927
Epoch:  57  	Training Loss: 0.0003153548459522426
Test Loss:  0.00017791184654925019
Valid Loss:  0.0003725934657268226
Epoch:  58  	Training Loss: 0.0003131715930067003
Test Loss:  0.00017605850007385015
Valid Loss:  0.00037005299236625433
Epoch:  59  	Training Loss: 0.0003114033897873014
Test Loss:  0.0001745370391290635
Valid Loss:  0.00036800545058213174
Epoch:  60  	Training Loss: 0.000309829309117049
Test Loss:  0.00017319212201982737
Valid Loss:  0.00036611524410545826
Epoch:  61  	Training Loss: 0.000308443617541343
Test Loss:  0.00017193169333040714
Valid Loss:  0.00036432186607271433
Epoch:  62  	Training Loss: 0.0003072096733376384
Test Loss:  0.00016925841919146478
Valid Loss:  0.00036147714126855135
Epoch:  63  	Training Loss: 0.0003031699452549219
Test Loss:  0.0001666555617703125
Valid Loss:  0.00035873387241736054
Epoch:  64  	Training Loss: 0.00029941927641630173
Test Loss:  0.0001641499256948009
Valid Loss:  0.0003560795448720455
Epoch:  65  	Training Loss: 0.00029587498283945024
Test Loss:  0.00016174987831618637
Valid Loss:  0.00035349230165593326
Epoch:  66  	Training Loss: 0.000292597571387887
Test Loss:  0.00015963557234499604
Valid Loss:  0.0003511434479150921
Epoch:  67  	Training Loss: 0.0002896352962125093
Test Loss:  0.00015759046073071659
Valid Loss:  0.0003488067304715514
Epoch:  68  	Training Loss: 0.00028683990240097046
Test Loss:  0.00015564437489956617
Valid Loss:  0.0003465336048975587
 14%|█▍        | 69/500 [00:54<02:27,  2.93it/s] 14%|█▍        | 71/500 [01:00<08:24,  1.18s/it] 15%|█▍        | 73/500 [01:01<05:59,  1.19it/s] 15%|█▌        | 75/500 [01:01<04:19,  1.64it/s] 15%|█▌        | 77/500 [01:01<03:08,  2.24it/s] 16%|█▌        | 79/500 [01:01<02:19,  3.01it/s] 16%|█▌        | 81/500 [01:07<08:25,  1.21s/it] 17%|█▋        | 83/500 [01:08<06:00,  1.16it/s] 17%|█▋        | 85/500 [01:08<04:19,  1.60it/s] 17%|█▋        | 87/500 [01:08<03:09,  2.18it/s] 18%|█▊        | 89/500 [01:08<02:23,  2.87it/s] 18%|█▊        | 91/500 [01:14<08:09,  1.20s/it] 19%|█▊        | 93/500 [01:15<05:48,  1.17it/s] 19%|█▉        | 95/500 [01:15<04:11,  1.61it/s] 19%|█▉        | 97/500 [01:15<03:03,  2.20it/s] 20%|█▉        | 99/500 [01:15<02:17,  2.91it/s] 20%|██        | 101/500 [01:22<08:09,  1.23s/it] 21%|██        | 103/500 [01:22<05:49,  1.14it/s] 21%|██        | 105/500 [01:22<04:10,  1.57it/s] 21%|██▏       | 107/500 [01:22<03:02,  2.15it/s] 22%|██▏       | 109/500 [01:22<02:14,  2.90it/s] 22%|██▏       | 111/500 [01:28<07:41,  1.19s/it] 23%|██▎       | 113/500 [01:29<05:31,  1.17it/s] 23%|██▎       | 115/500 [01:29<04:00,  1.60it/s] 23%|██▎       | 117/500 [01:29<02:57,  2.16it/s] 24%|██▍       | 119/500 [01:29<02:13,  2.85it/s] 24%|██▍       | 121/500 [01:36<07:39,  1.21s/it] 25%|██▍       | 123/500 [01:36<05:27,  1.15it/s] 25%|██▌       | 125/500 [01:36<03:55,  1.59it/s] 25%|██▌       | 127/500 [01:36<02:51,  2.17it/s] 26%|██▌       | 129/500 [01:36<02:06,  2.93it/s] 26%|██▌       | 131/500 [01:43<07:26,  1.21s/it] 27%|██▋       | 133/500 [01:43<05:17,  1.15it/s] 27%|██▋       | 135/500 [01:43<03:48,  1.60it/s]Epoch:  69  	Training Loss: 0.0002842061221599579
Test Loss:  0.00015378060925286263
Valid Loss:  0.00034428510116413236
Epoch:  70  	Training Loss: 0.00028169917641207576
Test Loss:  0.0001520159130450338
Valid Loss:  0.00034210438025183976
Epoch:  71  	Training Loss: 0.00027933489764109254
Test Loss:  0.00015036363038234413
Valid Loss:  0.0003400223213247955
Epoch:  72  	Training Loss: 0.00027710909489542246
Test Loss:  0.00014816527254879475
Valid Loss:  0.0003369070473127067
Epoch:  73  	Training Loss: 0.000274092162726447
Test Loss:  0.0001463350054109469
Valid Loss:  0.00033408356830477715
Epoch:  74  	Training Loss: 0.0002716936869546771
Test Loss:  0.00014452324830926955
Valid Loss:  0.0003313751658424735
Epoch:  75  	Training Loss: 0.00026943496777676046
Test Loss:  0.00014281485346145928
Valid Loss:  0.00032879767240956426
Epoch:  76  	Training Loss: 0.00026729836827144027
Test Loss:  0.00014114842633716762
Valid Loss:  0.0003263078397139907
Epoch:  77  	Training Loss: 0.00026524902204982936
Test Loss:  0.00013955596659798175
Valid Loss:  0.0003239025827497244
Epoch:  78  	Training Loss: 0.00026326696388423443
Test Loss:  0.00013801982277072966
Valid Loss:  0.0003215694450773299
Epoch:  79  	Training Loss: 0.000261360255535692
Test Loss:  0.00013655374641530216
Valid Loss:  0.00031927693635225296
Epoch:  80  	Training Loss: 0.0002595775295048952
Test Loss:  0.00013515836326405406
Valid Loss:  0.0003170572454109788
Epoch:  81  	Training Loss: 0.0002578604035079479
Test Loss:  0.00013382098404690623
Valid Loss:  0.00031496342853643
Epoch:  82  	Training Loss: 0.0002561997971497476
Test Loss:  0.00013105844845995307
Valid Loss:  0.0003122579655610025
Epoch:  83  	Training Loss: 0.0002541530702728778
Test Loss:  0.0001298471470363438
Valid Loss:  0.00031118810875341296
Epoch:  84  	Training Loss: 0.00025249860482290387
Test Loss:  0.00012861691357102245
Valid Loss:  0.0003100782632827759
Epoch:  85  	Training Loss: 0.000250968529144302
Test Loss:  0.0001274681417271495
Valid Loss:  0.00030902790604159236
Epoch:  86  	Training Loss: 0.0002495235239621252
Test Loss:  0.00012637545296456665
Valid Loss:  0.00030802417313680053
Epoch:  87  	Training Loss: 0.0002481563133187592
Test Loss:  0.00012531274114735425
Valid Loss:  0.00030701415380463004
Epoch:  88  	Training Loss: 0.0002468785969540477
Test Loss:  0.00012432376388460398
Valid Loss:  0.00030605343636125326
Epoch:  89  	Training Loss: 0.0002456488728057593
Test Loss:  0.00012338662054389715
Valid Loss:  0.0003051052917726338
Epoch:  90  	Training Loss: 0.0002444708370603621
Test Loss:  0.00012252249871380627
Valid Loss:  0.00030419393442571163
Epoch:  91  	Training Loss: 0.00024336430942639709
Test Loss:  0.00012169082037871704
Valid Loss:  0.0003032904351130128
Epoch:  92  	Training Loss: 0.00024231929273810238
Test Loss:  0.00012004704331047833
Valid Loss:  0.00030173471895977855
Epoch:  93  	Training Loss: 0.00023970750044099987
Test Loss:  0.00011853579781018198
Valid Loss:  0.00030020365375094116
Epoch:  94  	Training Loss: 0.00023735396098345518
Test Loss:  0.00011720482143573463
Valid Loss:  0.00029878609348088503
Epoch:  95  	Training Loss: 0.00023522866831626743
Test Loss:  0.00011597972479648888
Valid Loss:  0.0002974715316668153
Epoch:  96  	Training Loss: 0.00023335922742262483
Test Loss:  0.00011487581650726497
Valid Loss:  0.0002962522266898304
Epoch:  97  	Training Loss: 0.00023166554456111044
Test Loss:  0.00011386425467208028
Valid Loss:  0.0002950673224404454
Epoch:  98  	Training Loss: 0.00023006819537840784
Test Loss:  0.00011292494309600443
Valid Loss:  0.00029394245939329267
Epoch:  99  	Training Loss: 0.00022857438307255507
Test Loss:  0.00011203065514564514
Valid Loss:  0.00029288107180036604
Epoch:  100  	Training Loss: 0.00022717186948284507
Test Loss:  0.00011117682879557833
Valid Loss:  0.0002918417449109256
Epoch:  101  	Training Loss: 0.00022585989790968597
Test Loss:  0.00011036344221793115
Valid Loss:  0.00029083056142553687
Epoch:  102  	Training Loss: 0.00022464452194981277
Test Loss:  0.00010985923290718347
Valid Loss:  0.0002900881227105856
Epoch:  103  	Training Loss: 0.0002238616143586114
Test Loss:  0.00010931238648481667
Valid Loss:  0.0002892425109166652
Epoch:  104  	Training Loss: 0.00022311820066533983
Test Loss:  0.00010877099703066051
Valid Loss:  0.00028839288279414177
Epoch:  105  	Training Loss: 0.0002223994815722108
Test Loss:  0.00010825743083842099
Valid Loss:  0.00028757203835994005
Epoch:  106  	Training Loss: 0.0002217017754446715
Test Loss:  0.00010776751878438517
Valid Loss:  0.00028676586225628853
Epoch:  107  	Training Loss: 0.00022101799550000578
Test Loss:  0.000107297943031881
Valid Loss:  0.0002859861124306917
Epoch:  108  	Training Loss: 0.0002203511685365811
Test Loss:  0.00010684320295695215
Valid Loss:  0.00028523613582365215
Epoch:  109  	Training Loss: 0.00021970616944599897
Test Loss:  0.00010640027903718874
Valid Loss:  0.00028450414538383484
Epoch:  110  	Training Loss: 0.00021907250629737973
Test Loss:  0.0001059701680787839
Valid Loss:  0.00028378621209412813
Epoch:  111  	Training Loss: 0.00021845236187800765
Test Loss:  0.00010555253538768739
Valid Loss:  0.00028308521723374724
Epoch:  112  	Training Loss: 0.00021785727585665882
Test Loss:  0.00010433259012643248
Valid Loss:  0.00028056331211701035
Epoch:  113  	Training Loss: 0.00021566374925896525
Test Loss:  0.00010317080159438774
Valid Loss:  0.0002782047085929662
Epoch:  114  	Training Loss: 0.00021376056247390807
Test Loss:  0.00010206080332864076
Valid Loss:  0.0002761151408776641
Epoch:  115  	Training Loss: 0.0002120349381584674
Test Loss:  0.00010104890679940581
Valid Loss:  0.0002741806674748659
Epoch:  116  	Training Loss: 0.0002104869345203042
Test Loss:  0.00010013237624661997
Valid Loss:  0.0002723740180954337
Epoch:  117  	Training Loss: 0.00020903740369249135
Test Loss:  9.927264181897044e-05
Valid Loss:  0.0002706611412577331
Epoch:  118  	Training Loss: 0.00020768532704096287
Test Loss:  9.84628131845966e-05
Valid Loss:  0.00026904017431661487
Epoch:  119  	Training Loss: 0.00020643134484998882
Test Loss:  9.771905024535954e-05
Valid Loss:  0.0002674982533790171
Epoch:  120  	Training Loss: 0.0002052586933132261
Test Loss:  9.705364936962724e-05
Valid Loss:  0.0002660535101313144
Epoch:  121  	Training Loss: 0.00020417006453499198
Test Loss:  9.643949306337163e-05
Valid Loss:  0.00026464066468179226
Epoch:  122  	Training Loss: 0.00020316964946687222
Test Loss:  9.569934627506882e-05
Valid Loss:  0.0002631558454595506
Epoch:  123  	Training Loss: 0.00020214045071043074
Test Loss:  9.505962952971458e-05
Valid Loss:  0.00026180711574852467
Epoch:  124  	Training Loss: 0.0002011601609410718
Test Loss:  9.447615593671799e-05
Valid Loss:  0.0002605420595500618
Epoch:  125  	Training Loss: 0.00020021782256662846
Test Loss:  9.392848005518317e-05
Valid Loss:  0.0002593346289359033
Epoch:  126  	Training Loss: 0.0001993062614928931
Test Loss:  9.340795804746449e-05
Valid Loss:  0.00025817620917223394
Epoch:  127  	Training Loss: 0.00019841895846184343
Test Loss:  9.290814341511577e-05
Valid Loss:  0.00025705943698994815
Epoch:  128  	Training Loss: 0.00019755400717258453
Test Loss:  9.242835221812129e-05
Valid Loss:  0.0002559811691753566
Epoch:  129  	Training Loss: 0.0001967145362868905
Test Loss:  9.196644532494247e-05
Valid Loss:  0.00025493622524663806
Epoch:  130  	Training Loss: 0.000195899949176237
Test Loss:  9.152200073003769e-05
Valid Loss:  0.0002539245178923011
Epoch:  131  	Training Loss: 0.00019511273421812803
Test Loss:  9.110024257097393e-05
Valid Loss:  0.00025294566876254976
Epoch:  132  	Training Loss: 0.00019436552247498184
Test Loss:  9.120178583543748e-05
Valid Loss:  0.00025311531499028206
Epoch:  133  	Training Loss: 0.00019363913452252746
Test Loss:  9.112370025832206e-05
Valid Loss:  0.00025279453257098794
Epoch:  134  	Training Loss: 0.0001932789891725406
Test Loss:  9.099800081457943e-05
Valid Loss:  0.00025238655507564545
Epoch:  135  	Training Loss: 0.00019296089885756373
Test Loss:  9.087542275665328e-05
Valid Loss:  0.00025199761148542166
Epoch:  136  	Training Loss: 0.00019265935407020152
Test Loss:   27%|██▋       | 137/500 [01:43<02:46,  2.18it/s] 28%|██▊       | 139/500 [01:43<02:02,  2.94it/s] 28%|██▊       | 141/500 [01:49<07:11,  1.20s/it] 29%|██▊       | 143/500 [01:50<05:08,  1.16it/s] 29%|██▉       | 145/500 [01:50<03:42,  1.60it/s] 29%|██▉       | 147/500 [01:50<02:41,  2.19it/s] 30%|██▉       | 149/500 [01:50<01:59,  2.93it/s] 30%|███       | 151/500 [01:56<06:49,  1.17s/it] 31%|███       | 153/500 [01:56<04:51,  1.19it/s] 31%|███       | 155/500 [01:57<03:29,  1.65it/s] 31%|███▏      | 157/500 [01:57<02:32,  2.25it/s] 32%|███▏      | 159/500 [01:57<01:52,  3.02it/s] 32%|███▏      | 161/500 [02:03<06:46,  1.20s/it] 33%|███▎      | 163/500 [02:03<04:49,  1.16it/s] 33%|███▎      | 165/500 [02:04<03:28,  1.61it/s] 33%|███▎      | 167/500 [02:04<02:31,  2.20it/s] 34%|███▍      | 169/500 [02:04<01:51,  2.96it/s] 34%|███▍      | 171/500 [02:10<06:37,  1.21s/it] 35%|███▍      | 173/500 [02:10<04:42,  1.16it/s] 35%|███▌      | 175/500 [02:11<03:22,  1.60it/s] 35%|███▌      | 177/500 [02:11<02:27,  2.19it/s] 36%|███▌      | 179/500 [02:11<01:49,  2.94it/s] 36%|███▌      | 181/500 [02:17<06:17,  1.18s/it] 37%|███▋      | 183/500 [02:17<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:17<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:18<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:18<01:44,  2.97it/s] 38%|███▊      | 191/500 [02:24<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:24<04:21,  1.17it/s] 39%|███▉      | 195/500 [02:24<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:24<02:16,  2.21it/s] 40%|███▉      | 199/500 [02:25<01:42,  2.94it/s] 40%|████      | 201/500 [02:31<05:56,  1.19s/it] 41%|████      | 203/500 [02:31<04:14,  1.17it/s]9.077636059373617e-05
Valid Loss:  0.0002516283420845866
Epoch:  137  	Training Loss: 0.00019237147353123873
Test Loss:  9.068370854947716e-05
Valid Loss:  0.00025127630215138197
Epoch:  138  	Training Loss: 0.00019209855236113071
Test Loss:  9.059674630407244e-05
Valid Loss:  0.0002509523765183985
Epoch:  139  	Training Loss: 0.00019183952827006578
Test Loss:  9.051932283909991e-05
Valid Loss:  0.0002506510354578495
Epoch:  140  	Training Loss: 0.0001915910979732871
Test Loss:  9.044895705301315e-05
Valid Loss:  0.00025036296574398875
Epoch:  141  	Training Loss: 0.00019135247566737235
Test Loss:  9.039546421263367e-05
Valid Loss:  0.0002500917762517929
Epoch:  142  	Training Loss: 0.0001911257568281144
Test Loss:  8.863545372150838e-05
Valid Loss:  0.00024694818421266973
Epoch:  143  	Training Loss: 0.00018968719814438373
Test Loss:  8.829843136481941e-05
Valid Loss:  0.0002457721857354045
Epoch:  144  	Training Loss: 0.00018850687774829566
Test Loss:  8.756053284741938e-05
Valid Loss:  0.00024403180577792227
Epoch:  145  	Training Loss: 0.00018737354548648
Test Loss:  8.699725731275976e-05
Valid Loss:  0.00024254489107988775
Epoch:  146  	Training Loss: 0.0001862634380813688
Test Loss:  8.638492727186531e-05
Valid Loss:  0.00024099720758385956
Epoch:  147  	Training Loss: 0.00018517467833589762
Test Loss:  8.580665598856285e-05
Valid Loss:  0.0002395103801973164
Epoch:  148  	Training Loss: 0.00018410367192700505
Test Loss:  8.522886491846293e-05
Valid Loss:  0.00023803503427188843
Epoch:  149  	Training Loss: 0.00018305238336324692
Test Loss:  8.466747385682538e-05
Valid Loss:  0.00023659283760935068
Epoch:  150  	Training Loss: 0.0001820203906390816
Test Loss:  8.411956514464691e-05
Valid Loss:  0.00023517513182014227
Epoch:  151  	Training Loss: 0.00018100868328474462
Test Loss:  8.358636114280671e-05
Valid Loss:  0.00023377779871225357
Epoch:  152  	Training Loss: 0.00018002108845394105
Test Loss:  8.3295235526748e-05
Valid Loss:  0.00023337626771535724
Epoch:  153  	Training Loss: 0.00017935707001015544
Test Loss:  8.288845128845423e-05
Valid Loss:  0.00023268851509783417
Epoch:  154  	Training Loss: 0.00017874887271318585
Test Loss:  8.252558473031968e-05
Valid Loss:  0.0002320357016287744
Epoch:  155  	Training Loss: 0.00017816504987422377
Test Loss:  8.218730363296345e-05
Valid Loss:  0.0002313877921551466
Epoch:  156  	Training Loss: 0.0001776002172846347
Test Loss:  8.186320337699726e-05
Valid Loss:  0.0002307328104507178
Epoch:  157  	Training Loss: 0.00017705143545754254
Test Loss:  8.155293471645564e-05
Valid Loss:  0.0002300777123309672
Epoch:  158  	Training Loss: 0.00017651361122261733
Test Loss:  8.125196472974494e-05
Valid Loss:  0.0002294211881235242
Epoch:  159  	Training Loss: 0.0001759848528308794
Test Loss:  8.09574848972261e-05
Valid Loss:  0.00022875868307892233
Epoch:  160  	Training Loss: 0.00017546351591590792
Test Loss:  8.067232556641102e-05
Valid Loss:  0.00022809838992543519
Epoch:  161  	Training Loss: 0.00017494767962489277
Test Loss:  8.039055683184415e-05
Valid Loss:  0.0002274421858601272
Epoch:  162  	Training Loss: 0.00017443564138375223
Test Loss:  7.993498002178967e-05
Valid Loss:  0.00022678691311739385
Epoch:  163  	Training Loss: 0.00017382903024554253
Test Loss:  7.959239883348346e-05
Valid Loss:  0.00022628465376328677
Epoch:  164  	Training Loss: 0.0001732718083076179
Test Loss:  7.925021054688841e-05
Valid Loss:  0.00022572075249627233
Epoch:  165  	Training Loss: 0.00017275138816330582
Test Loss:  7.895885937614366e-05
Valid Loss:  0.000225217139814049
Epoch:  166  	Training Loss: 0.00017225672490894794
Test Loss:  7.867342355893925e-05
Valid Loss:  0.0002246883959742263
Epoch:  167  	Training Loss: 0.00017178164853248745
Test Loss:  7.840998296160251e-05
Valid Loss:  0.00022416892170440406
Epoch:  168  	Training Loss: 0.0001713233650662005
Test Loss:  7.816485594958067e-05
Valid Loss:  0.00022366576013155282
Epoch:  169  	Training Loss: 0.00017087336163967848
Test Loss:  7.792537508066744e-05
Valid Loss:  0.0002231600956292823
Epoch:  170  	Training Loss: 0.00017043016850948334
Test Loss:  7.769131480017677e-05
Valid Loss:  0.00022265360166784376
Epoch:  171  	Training Loss: 0.00016999173385556787
Test Loss:  7.74616637500003e-05
Valid Loss:  0.00022214614728000015
Epoch:  172  	Training Loss: 0.0001695571991149336
Test Loss:  7.743548485450447e-05
Valid Loss:  0.00022200985404197127
Epoch:  173  	Training Loss: 0.0001693241356406361
Test Loss:  7.736706174910069e-05
Valid Loss:  0.00022175625781528652
Epoch:  174  	Training Loss: 0.0001691121724434197
Test Loss:  7.728372293058783e-05
Valid Loss:  0.00022146542323753238
Epoch:  175  	Training Loss: 0.000168904778547585
Test Loss:  7.719472341705114e-05
Valid Loss:  0.00022116382024250925
Epoch:  176  	Training Loss: 0.0001686999894445762
Test Loss:  7.710387581028044e-05
Valid Loss:  0.00022086143144406378
Epoch:  177  	Training Loss: 0.00016849707753863186
Test Loss:  7.70127953728661e-05
Valid Loss:  0.0002205616037826985
Epoch:  178  	Training Loss: 0.00016832452092785388
Test Loss:  7.692638610024005e-05
Valid Loss:  0.0002203900075983256
Epoch:  179  	Training Loss: 0.00016818183939903975
Test Loss:  7.684658339712769e-05
Valid Loss:  0.00022017586161382496
Epoch:  180  	Training Loss: 0.00016804778715595603
Test Loss:  7.677009853068739e-05
Valid Loss:  0.00022005036589689553
Epoch:  181  	Training Loss: 0.000167917474755086
Test Loss:  7.66930024838075e-05
Valid Loss:  0.00021979059965815395
Epoch:  182  	Training Loss: 0.00016779196448624134
Test Loss:  7.603077392559499e-05
Valid Loss:  0.00021735383779741824
Epoch:  183  	Training Loss: 0.0001665653835516423
Test Loss:  7.574106712127104e-05
Valid Loss:  0.00021562937763519585
Epoch:  184  	Training Loss: 0.00016553763998672366
Test Loss:  7.533439202234149e-05
Valid Loss:  0.00021392127382569015
Epoch:  185  	Training Loss: 0.00016463303472846746
Test Loss:  7.508060662075877e-05
Valid Loss:  0.00021255001774989069
Epoch:  186  	Training Loss: 0.000163810676895082
Test Loss:  7.475833990611136e-05
Valid Loss:  0.00021119782468304038
Epoch:  187  	Training Loss: 0.00016304179735016078
Test Loss:  7.448693213518709e-05
Valid Loss:  0.00021000803099013865
Epoch:  188  	Training Loss: 0.0001623226999072358
Test Loss:  7.418583845719695e-05
Valid Loss:  0.00020884766126982868
Epoch:  189  	Training Loss: 0.00016164936823770404
Test Loss:  7.393024861812592e-05
Valid Loss:  0.00020781721104867756
Epoch:  190  	Training Loss: 0.00016101110668387264
Test Loss:  7.365607598330826e-05
Valid Loss:  0.00020679466251749545
Epoch:  191  	Training Loss: 0.00016040456830523908
Test Loss:  7.341067248489708e-05
Valid Loss:  0.00020586478058248758
Epoch:  192  	Training Loss: 0.00015982305922079831
Test Loss:  7.348143844865263e-05
Valid Loss:  0.0002056917001027614
Epoch:  193  	Training Loss: 0.0001592747721588239
Test Loss:  7.335413101827726e-05
Valid Loss:  0.00020526185107883066
Epoch:  194  	Training Loss: 0.00015880852879490703
Test Loss:  7.316470146179199e-05
Valid Loss:  0.00020476826466619968
Epoch:  195  	Training Loss: 0.00015830605116207153
Test Loss:  7.29135936126113e-05
Valid Loss:  0.0002042326086666435
Epoch:  196  	Training Loss: 0.00015772797632962465
Test Loss:  7.263456063810736e-05
Valid Loss:  0.00020363955991342664
Epoch:  197  	Training Loss: 0.0001570631138747558
Test Loss:  7.230037590488791e-05
Valid Loss:  0.00020286557264626026
Epoch:  198  	Training Loss: 0.0001562959369039163
Test Loss:  7.190719043137506e-05
Valid Loss:  0.00020191160729154944
Epoch:  199  	Training Loss: 0.00015539335436187685
Test Loss:  7.135105988709256e-05
Valid Loss:  0.00020089821191504598
Epoch:  200  	Training Loss: 0.00015436949615832418
Test Loss:  7.083272794261575e-05
Valid Loss:  0.00019989386782981455
Epoch:  201  	Training Loss: 0.00015337455261033028
Test Loss:  7.051963621051982e-05
Valid Loss:  0.00019908143440261483
Epoch:  202  	Training Loss: 0.0001527039858046919
Test Loss:  7.00656819390133e-05
Valid Loss:  0.00019840794266201556
Epoch:  203  	Training Loss: 0.00015219362103380263
Test Loss:  6.975905853323638e-05
Valid Loss:  0.00019795003754552454
 41%|████      | 205/500 [02:31<03:02,  1.62it/s] 41%|████▏     | 207/500 [02:31<02:12,  2.21it/s] 42%|████▏     | 209/500 [02:31<01:38,  2.96it/s] 42%|████▏     | 211/500 [02:38<05:47,  1.20s/it] 43%|████▎     | 213/500 [02:38<04:07,  1.16it/s] 43%|████▎     | 215/500 [02:38<02:57,  1.60it/s] 43%|████▎     | 217/500 [02:38<02:09,  2.19it/s] 44%|████▍     | 219/500 [02:38<01:35,  2.94it/s] 44%|████▍     | 221/500 [02:45<05:33,  1.20s/it] 45%|████▍     | 223/500 [02:45<03:57,  1.17it/s] 45%|████▌     | 225/500 [02:45<02:50,  1.61it/s] 45%|████▌     | 227/500 [02:45<02:04,  2.20it/s] 46%|████▌     | 229/500 [02:45<01:31,  2.95it/s] 46%|████▌     | 231/500 [02:52<05:22,  1.20s/it] 47%|████▋     | 233/500 [02:52<03:51,  1.16it/s] 47%|████▋     | 235/500 [02:52<02:47,  1.58it/s] 47%|████▋     | 237/500 [02:52<02:03,  2.14it/s] 48%|████▊     | 239/500 [02:52<01:32,  2.83it/s] 48%|████▊     | 241/500 [02:59<05:16,  1.22s/it] 49%|████▊     | 243/500 [02:59<03:45,  1.14it/s] 49%|████▉     | 245/500 [02:59<02:41,  1.58it/s] 49%|████▉     | 247/500 [02:59<01:57,  2.15it/s] 50%|████▉     | 249/500 [03:00<01:26,  2.90it/s] 50%|█████     | 251/500 [03:06<04:57,  1.19s/it] 51%|█████     | 253/500 [03:06<03:32,  1.16it/s] 51%|█████     | 255/500 [03:06<02:33,  1.59it/s] 51%|█████▏    | 257/500 [03:06<01:51,  2.18it/s] 52%|█████▏    | 259/500 [03:06<01:22,  2.93it/s] 52%|█████▏    | 261/500 [03:13<04:51,  1.22s/it] 53%|█████▎    | 263/500 [03:13<03:27,  1.14it/s] 53%|█████▎    | 265/500 [03:13<02:28,  1.58it/s] 53%|█████▎    | 267/500 [03:13<01:48,  2.16it/s] 54%|█████▍    | 269/500 [03:14<01:19,  2.91it/s]Epoch:  204  	Training Loss: 0.0001517487980891019
Test Loss:  6.949961243662983e-05
Valid Loss:  0.00019757545669563115
Epoch:  205  	Training Loss: 0.0001513327588327229
Test Loss:  6.92659814376384e-05
Valid Loss:  0.00019723853620234877
Epoch:  206  	Training Loss: 0.00015095440903678536
Test Loss:  6.905222107889131e-05
Valid Loss:  0.00019693119975272566
Epoch:  207  	Training Loss: 0.00015060947043821216
Test Loss:  6.884760659886524e-05
Valid Loss:  0.00019662888371385634
Epoch:  208  	Training Loss: 0.00015027535846456885
Test Loss:  6.865515024401248e-05
Valid Loss:  0.00019633301417343318
Epoch:  209  	Training Loss: 0.00014995975652709603
Test Loss:  6.847472832305357e-05
Valid Loss:  0.00019604191766120493
Epoch:  210  	Training Loss: 0.00014965058653615415
Test Loss:  6.831309292465448e-05
Valid Loss:  0.00019575742771849036
Epoch:  211  	Training Loss: 0.00014934735372662544
Test Loss:  6.816482346039265e-05
Valid Loss:  0.00019548836280591786
Epoch:  212  	Training Loss: 0.00014905157149769366
Test Loss:  6.835740350652486e-05
Valid Loss:  0.00019550503930076957
Epoch:  213  	Training Loss: 0.00014875449414830655
Test Loss:  6.849776400486007e-05
Valid Loss:  0.00019532829173840582
Epoch:  214  	Training Loss: 0.00014858233043923974
Test Loss:  6.860715802758932e-05
Valid Loss:  0.00019511111895553768
Epoch:  215  	Training Loss: 0.0001484392414567992
Test Loss:  6.87032807036303e-05
Valid Loss:  0.00019490344857331365
Epoch:  216  	Training Loss: 0.00014831431326456368
Test Loss:  6.879320426378399e-05
Valid Loss:  0.00019471747509669513
Epoch:  217  	Training Loss: 0.0001482034713262692
Test Loss:  6.887651397846639e-05
Valid Loss:  0.0001945534022524953
Epoch:  218  	Training Loss: 0.00014810381981078535
Test Loss:  6.895420665387064e-05
Valid Loss:  0.0001944102259585634
Epoch:  219  	Training Loss: 0.00014801266661379486
Test Loss:  6.90251326886937e-05
Valid Loss:  0.0001942823437275365
Epoch:  220  	Training Loss: 0.00014792877482250333
Test Loss:  6.909001967869699e-05
Valid Loss:  0.0001941677473951131
Epoch:  221  	Training Loss: 0.0001478501653764397
Test Loss:  6.914992991369218e-05
Valid Loss:  0.00019406815408729017
Epoch:  222  	Training Loss: 0.0001477759360568598
Test Loss:  6.914156256243587e-05
Valid Loss:  0.00019376882119104266
Epoch:  223  	Training Loss: 0.00014759009354747832
Test Loss:  6.913969991728663e-05
Valid Loss:  0.00019349889771547168
Epoch:  224  	Training Loss: 0.00014741253107786179
Test Loss:  6.913835386512801e-05
Valid Loss:  0.00019325080211274326
Epoch:  225  	Training Loss: 0.00014724276843480766
Test Loss:  6.913585093570873e-05
Valid Loss:  0.0001930208527483046
Epoch:  226  	Training Loss: 0.00014708042726852
Test Loss:  6.912912795087323e-05
Valid Loss:  0.00019280573178548366
Epoch:  227  	Training Loss: 0.00014692230615764856
Test Loss:  6.911812670296058e-05
Valid Loss:  0.0001926016848301515
Epoch:  228  	Training Loss: 0.0001467682159272954
Test Loss:  6.910262163728476e-05
Valid Loss:  0.00019240882829762995
Epoch:  229  	Training Loss: 0.0001466171524953097
Test Loss:  6.908200157340616e-05
Valid Loss:  0.0001922225346788764
Epoch:  230  	Training Loss: 0.0001464682281948626
Test Loss:  6.905728514539078e-05
Valid Loss:  0.00019204287673346698
Epoch:  231  	Training Loss: 0.00014632128295488656
Test Loss:  6.902919994900003e-05
Valid Loss:  0.00019186829740647227
Epoch:  232  	Training Loss: 0.00014617574925068766
Test Loss:  6.848527118563652e-05
Valid Loss:  0.00019123812671750784
Epoch:  233  	Training Loss: 0.00014580880815628916
Test Loss:  6.808636680943891e-05
Valid Loss:  0.00019082616199739277
Epoch:  234  	Training Loss: 0.00014549314801115543
Test Loss:  6.775073416065425e-05
Valid Loss:  0.00019049709953833371
Epoch:  235  	Training Loss: 0.0001452022697776556
Test Loss:  6.745095015503466e-05
Valid Loss:  0.00019020633772015572
Epoch:  236  	Training Loss: 0.00014493224443867803
Test Loss:  6.717699579894543e-05
Valid Loss:  0.00018994043057318777
Epoch:  237  	Training Loss: 0.00014467824075836688
Test Loss:  6.692390161333606e-05
Valid Loss:  0.00018969012307934463
Epoch:  238  	Training Loss: 0.00014443884720094502
Test Loss:  6.668997230008245e-05
Valid Loss:  0.00018945214105769992
Epoch:  239  	Training Loss: 0.00014421129890251905
Test Loss:  6.647373083978891e-05
Valid Loss:  0.0001892272848635912
Epoch:  240  	Training Loss: 0.00014399543579202145
Test Loss:  6.627049879170954e-05
Valid Loss:  0.00018900999566540122
Epoch:  241  	Training Loss: 0.0001437898026779294
Test Loss:  6.607946124859154e-05
Valid Loss:  0.00018879788694903255
Epoch:  242  	Training Loss: 0.00014359335182234645
Test Loss:  6.631240103160962e-05
Valid Loss:  0.00018846429884433746
Epoch:  243  	Training Loss: 0.00014331197598949075
Test Loss:  6.649935676250607e-05
Valid Loss:  0.00018817851378116757
Epoch:  244  	Training Loss: 0.00014309905236586928
Test Loss:  6.664040120085701e-05
Valid Loss:  0.00018792276387102902
Epoch:  245  	Training Loss: 0.00014292217383626848
Test Loss:  6.674413452856243e-05
Valid Loss:  0.00018768383597489446
Epoch:  246  	Training Loss: 0.00014276491128839552
Test Loss:  6.681810191366822e-05
Valid Loss:  0.0001874591107480228
Epoch:  247  	Training Loss: 0.00014261913020163774
Test Loss:  6.686936831101775e-05
Valid Loss:  0.00018724624533206224
Epoch:  248  	Training Loss: 0.00014248168736230582
Test Loss:  6.690355075988919e-05
Valid Loss:  0.0001870442647486925
Epoch:  249  	Training Loss: 0.0001423496869392693
Test Loss:  6.69241271680221e-05
Valid Loss:  0.00018685084069147706
Epoch:  250  	Training Loss: 0.00014222151366993785
Test Loss:  6.693486648146063e-05
Valid Loss:  0.00018666501273401082
Epoch:  251  	Training Loss: 0.00014209726941771805
Test Loss:  6.693591421935707e-05
Valid Loss:  0.00018648753757588565
Epoch:  252  	Training Loss: 0.0001419756590621546
Test Loss:  6.661155202891678e-05
Valid Loss:  0.0001860332558862865
Epoch:  253  	Training Loss: 0.00014167917834129184
Test Loss:  6.636617763433605e-05
Valid Loss:  0.00018567228107713163
Epoch:  254  	Training Loss: 0.000141395372338593
Test Loss:  6.615086749661714e-05
Valid Loss:  0.00018533525872044265
Epoch:  255  	Training Loss: 0.00014111673226580024
Test Loss:  6.595203012693673e-05
Valid Loss:  0.00018500311125535518
Epoch:  256  	Training Loss: 0.00014084189024288207
Test Loss:  6.576642044819891e-05
Valid Loss:  0.00018467048357706517
Epoch:  257  	Training Loss: 0.00014057083171792328
Test Loss:  6.559011671924964e-05
Valid Loss:  0.00018433737568557262
Epoch:  258  	Training Loss: 0.0001403028581989929
Test Loss:  6.542236224049702e-05
Valid Loss:  0.00018400303088128567
Epoch:  259  	Training Loss: 0.00014003668911755085
Test Loss:  6.526082870550454e-05
Valid Loss:  0.0001836684823501855
Epoch:  260  	Training Loss: 0.0001397724263370037
Test Loss:  6.510547245852649e-05
Valid Loss:  0.00018333509797230363
Epoch:  261  	Training Loss: 0.00013950999709777534
Test Loss:  6.495472916867584e-05
Valid Loss:  0.00018299798830412328
Epoch:  262  	Training Loss: 0.00013924964878242463
Test Loss:  6.433166709030047e-05
Valid Loss:  0.0001819048629840836
Epoch:  263  	Training Loss: 0.00013872282579541206
Test Loss:  6.41810693196021e-05
Valid Loss:  0.00018143016495741904
Epoch:  264  	Training Loss: 0.0001383659546263516
Test Loss:  6.40175276203081e-05
Valid Loss:  0.0001809431705623865
Epoch:  265  	Training Loss: 0.00013801062596030533
Test Loss:  6.385262531694025e-05
Valid Loss:  0.0001804606436053291
Epoch:  266  	Training Loss: 0.00013765764015261084
Test Loss:  6.368663161993027e-05
Valid Loss:  0.00017998149269260466
Epoch:  267  	Training Loss: 0.00013730654609389603
Test Loss:  6.352116179186851e-05
Valid Loss:  0.000179510228917934
Epoch:  268  	Training Loss: 0.000136956776259467
Test Loss:  6.335267971735448e-05
Valid Loss:  0.00017903682601172477
Epoch:  269  	Training Loss: 0.00013661078992299736
Test Loss:  6.318583473330364e-05
Valid Loss:  0.00017856720660347492
Epoch:  270  	Training Loss: 0.00013626810687128454
Test Loss:  6.302030669758096e-05
Valid Loss:  0.00017810154531616718
Epoch:  271  	Training Loss: 0.0001359275629511103
Test Loss:   54%|█████▍    | 271/500 [03:20<04:33,  1.20s/it] 55%|█████▍    | 273/500 [03:20<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:20<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:20<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:20<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:27<04:19,  1.19s/it] 57%|█████▋    | 283/500 [03:27<03:04,  1.18it/s] 57%|█████▋    | 285/500 [03:27<02:12,  1.63it/s] 57%|█████▋    | 287/500 [03:27<01:35,  2.22it/s] 58%|█████▊    | 289/500 [03:27<01:10,  2.98it/s] 58%|█████▊    | 291/500 [03:34<04:06,  1.18s/it] 59%|█████▊    | 293/500 [03:34<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:34<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:34<01:31,  2.23it/s] 60%|█████▉    | 299/500 [03:34<01:08,  2.94it/s] 60%|██████    | 301/500 [03:41<04:01,  1.21s/it] 61%|██████    | 303/500 [03:41<02:52,  1.14it/s] 61%|██████    | 305/500 [03:41<02:04,  1.57it/s] 61%|██████▏   | 307/500 [03:41<01:29,  2.15it/s] 62%|██████▏   | 309/500 [03:41<01:05,  2.90it/s] 62%|██████▏   | 311/500 [03:48<03:47,  1.20s/it] 63%|██████▎   | 313/500 [03:48<02:41,  1.16it/s] 63%|██████▎   | 315/500 [03:48<01:55,  1.61it/s] 63%|██████▎   | 317/500 [03:48<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:48<01:01,  2.96it/s] 64%|██████▍   | 321/500 [03:55<03:30,  1.18s/it] 65%|██████▍   | 323/500 [03:55<02:29,  1.18it/s] 65%|██████▌   | 325/500 [03:55<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:55<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:55<00:57,  3.00it/s] 66%|██████▌   | 331/500 [04:01<03:21,  1.20s/it] 67%|██████▋   | 333/500 [04:02<02:23,  1.16it/s] 67%|██████▋   | 335/500 [04:02<01:43,  1.59it/s] 67%|██████▋   | 337/500 [04:02<01:15,  2.14it/s]6.285560812102631e-05
Valid Loss:  0.00017763803771231323
Epoch:  272  	Training Loss: 0.00013559135550167412
Test Loss:  6.226819823496044e-05
Valid Loss:  0.00017710094107314944
Epoch:  273  	Training Loss: 0.00013522875087801367
Test Loss:  6.189416308188811e-05
Valid Loss:  0.00017688727530185133
Epoch:  274  	Training Loss: 0.00013492777361534536
Test Loss:  6.154965376481414e-05
Valid Loss:  0.000176669389475137
Epoch:  275  	Training Loss: 0.00013467296957969666
Test Loss:  6.125357322162017e-05
Valid Loss:  0.00017649511573836207
Epoch:  276  	Training Loss: 0.000134456466184929
Test Loss:  6.099574238760397e-05
Valid Loss:  0.0001763463660608977
Epoch:  277  	Training Loss: 0.0001342696778010577
Test Loss:  6.077490979805589e-05
Valid Loss:  0.00017623112944420427
Epoch:  278  	Training Loss: 0.00013410349492914975
Test Loss:  6.0580852732528e-05
Valid Loss:  0.00017613201634958386
Epoch:  279  	Training Loss: 0.00013395794667303562
Test Loss:  6.0406197007978335e-05
Valid Loss:  0.00017605198081582785
Epoch:  280  	Training Loss: 0.00013383393525145948
Test Loss:  6.02545915171504e-05
Valid Loss:  0.00017599810962565243
Epoch:  281  	Training Loss: 0.00013373167894314975
Test Loss:  6.012523590470664e-05
Valid Loss:  0.00017596174438949674
Epoch:  282  	Training Loss: 0.0001336456334684044
Test Loss:  6.01729734626133e-05
Valid Loss:  0.00017564160225447267
Epoch:  283  	Training Loss: 0.00013332394883036613
Test Loss:  6.0156609833939e-05
Valid Loss:  0.00017524237046018243
Epoch:  284  	Training Loss: 0.00013303919695317745
Test Loss:  6.0110083722975105e-05
Valid Loss:  0.00017482045223005116
Epoch:  285  	Training Loss: 0.0001327657519141212
Test Loss:  6.0049991589039564e-05
Valid Loss:  0.00017439748626202345
Epoch:  286  	Training Loss: 0.00013249972835183144
Test Loss:  5.9984267863910645e-05
Valid Loss:  0.00017398386262357235
Epoch:  287  	Training Loss: 0.0001322401367360726
Test Loss:  5.991568468743935e-05
Valid Loss:  0.00017358415061607957
Epoch:  288  	Training Loss: 0.00013198450324125588
Test Loss:  5.9842939663212746e-05
Valid Loss:  0.0001731900847516954
Epoch:  289  	Training Loss: 0.00013173362822271883
Test Loss:  5.976686588837765e-05
Valid Loss:  0.00017280533211305737
Epoch:  290  	Training Loss: 0.0001314856781391427
Test Loss:  5.968791447230615e-05
Valid Loss:  0.00017242772446479648
Epoch:  291  	Training Loss: 0.00013124146789778024
Test Loss:  5.960663838777691e-05
Valid Loss:  0.00017205443873535842
Epoch:  292  	Training Loss: 0.0001310005463892594
Test Loss:  5.964001320535317e-05
Valid Loss:  0.0001717256527626887
Epoch:  293  	Training Loss: 0.0001307983766309917
Test Loss:  5.9662423154804856e-05
Valid Loss:  0.0001714070385787636
Epoch:  294  	Training Loss: 0.0001306054909946397
Test Loss:  5.96750651311595e-05
Valid Loss:  0.00017109877080656588
Epoch:  295  	Training Loss: 0.00013041960482951254
Test Loss:  5.968131881672889e-05
Valid Loss:  0.0001707997580524534
Epoch:  296  	Training Loss: 0.00013023984502069652
Test Loss:  5.968163532088511e-05
Valid Loss:  0.00017051046597771347
Epoch:  297  	Training Loss: 0.00013006509107071906
Test Loss:  5.967701144982129e-05
Valid Loss:  0.0001702296722214669
Epoch:  298  	Training Loss: 0.00012989460083190352
Test Loss:  5.966814933344722e-05
Valid Loss:  0.0001699576387181878
Epoch:  299  	Training Loss: 0.00012972769036423415
Test Loss:  5.9656020312104374e-05
Valid Loss:  0.00016969234275165945
Epoch:  300  	Training Loss: 0.0001295639667659998
Test Loss:  5.964042429695837e-05
Valid Loss:  0.00016943385708145797
Epoch:  301  	Training Loss: 0.00012940280430484563
Test Loss:  5.962270006421022e-05
Valid Loss:  0.00016918234177865088
Epoch:  302  	Training Loss: 0.0001292442757403478
Test Loss:  5.9435271396068856e-05
Valid Loss:  0.000168882921570912
Epoch:  303  	Training Loss: 0.00012901038280688226
Test Loss:  5.925585355726071e-05
Valid Loss:  0.0001685830793576315
Epoch:  304  	Training Loss: 0.00012877921108156443
Test Loss:  5.9083293308503926e-05
Valid Loss:  0.00016828101070132107
Epoch:  305  	Training Loss: 0.00012855151726398617
Test Loss:  5.891931868973188e-05
Valid Loss:  0.00016797817079350352
Epoch:  306  	Training Loss: 0.0001283266901737079
Test Loss:  5.876070645172149e-05
Valid Loss:  0.00016767560737207532
Epoch:  307  	Training Loss: 0.0001281041477341205
Test Loss:  5.860887176822871e-05
Valid Loss:  0.00016737394616939127
Epoch:  308  	Training Loss: 0.00012788429739885032
Test Loss:  5.846231579198502e-05
Valid Loss:  0.0001670721103437245
Epoch:  309  	Training Loss: 0.00012766644067596644
Test Loss:  5.832087845192291e-05
Valid Loss:  0.00016677039093337953
Epoch:  310  	Training Loss: 0.00012745094136334956
Test Loss:  5.818369390908629e-05
Valid Loss:  0.0001664699666434899
Epoch:  311  	Training Loss: 0.00012723686813842505
Test Loss:  5.805076943943277e-05
Valid Loss:  0.00016616960056126118
Epoch:  312  	Training Loss: 0.0001270247739739716
Test Loss:  5.770834468421526e-05
Valid Loss:  0.0001653647341299802
Epoch:  313  	Training Loss: 0.00012664578389376402
Test Loss:  5.762742512160912e-05
Valid Loss:  0.00016489269910380244
Epoch:  314  	Training Loss: 0.00012628988770302385
Test Loss:  5.7483593991491944e-05
Valid Loss:  0.00016435779980383813
Epoch:  315  	Training Loss: 0.00012593824067153037
Test Loss:  5.7350447605131194e-05
Valid Loss:  0.00016384845366701484
Epoch:  316  	Training Loss: 0.00012558996968436986
Test Loss:  5.7212033425457776e-05
Valid Loss:  0.00016334274550899863
Epoch:  317  	Training Loss: 0.00012524478370323777
Test Loss:  5.707258969778195e-05
Valid Loss:  0.00016284493904095143
Epoch:  318  	Training Loss: 0.00012490260996855795
Test Loss:  5.693150160368532e-05
Valid Loss:  0.0001623543503228575
Epoch:  319  	Training Loss: 0.0001245631428901106
Test Loss:  5.679022433469072e-05
Valid Loss:  0.00016187259461730719
Epoch:  320  	Training Loss: 0.00012422571307979524
Test Loss:  5.664612035616301e-05
Valid Loss:  0.00016139226499944925
Epoch:  321  	Training Loss: 0.0001238906552316621
Test Loss:  5.6500848586438224e-05
Valid Loss:  0.00016091795987449586
Epoch:  322  	Training Loss: 0.00012355820217635483
Test Loss:  5.627662540064193e-05
Valid Loss:  0.0001605181023478508
Epoch:  323  	Training Loss: 0.00012325499847065657
Test Loss:  5.61302003916353e-05
Valid Loss:  0.00016019705799408257
Epoch:  324  	Training Loss: 0.00012296190834604204
Test Loss:  5.598165444098413e-05
Valid Loss:  0.0001598467497387901
Epoch:  325  	Training Loss: 0.00012267669080756605
Test Loss:  5.5853743106126785e-05
Valid Loss:  0.00015950395027175546
Epoch:  326  	Training Loss: 0.00012239586794748902
Test Loss:  5.573308590101078e-05
Valid Loss:  0.00015915838594082743
Epoch:  327  	Training Loss: 0.0001221190468640998
Test Loss:  5.562060687225312e-05
Valid Loss:  0.00015881247236393392
Epoch:  328  	Training Loss: 0.00012184556544525549
Test Loss:  5.551362846745178e-05
Valid Loss:  0.0001584612618898973
Epoch:  329  	Training Loss: 0.00012157596211181954
Test Loss:  5.5414788221241906e-05
Valid Loss:  0.00015811578487046063
Epoch:  330  	Training Loss: 0.00012130746472394094
Test Loss:  5.531878559850156e-05
Valid Loss:  0.0001577633956912905
Epoch:  331  	Training Loss: 0.00012103949848096818
Test Loss:  5.522440915228799e-05
Valid Loss:  0.0001574113848619163
Epoch:  332  	Training Loss: 0.00012077289284206927
Test Loss:  5.5661141232121736e-05
Valid Loss:  0.0001571135362610221
Epoch:  333  	Training Loss: 0.00012039428111165762
Test Loss:  5.5680669902358204e-05
Valid Loss:  0.00015649423585273325
Epoch:  334  	Training Loss: 0.00012010762293357402
Test Loss:  5.571236397372559e-05
Valid Loss:  0.0001559900410939008
Epoch:  335  	Training Loss: 0.00011984413140453398
Test Loss:  5.5708471336402e-05
Valid Loss:  0.0001555293711135164
Epoch:  336  	Training Loss: 0.00011959511903114617
Test Loss:  5.567752305069007e-05
Valid Loss:  0.0001551012392155826
Epoch:  337  	Training Loss: 0.00011935560905840248
Test Loss:  5.562405931414105e-05
Valid Loss:  0.0001546836574561894
Epoch:  338  	Training Loss: 0.00011912357877008617
Test Loss:  5.5564596550539136e-05
Valid Loss:   68%|██████▊   | 339/500 [04:02<00:56,  2.84it/s] 68%|██████▊   | 341/500 [04:09<03:14,  1.22s/it] 69%|██████▊   | 343/500 [04:09<02:18,  1.14it/s] 69%|██████▉   | 345/500 [04:09<01:38,  1.58it/s] 69%|██████▉   | 347/500 [04:09<01:11,  2.15it/s] 70%|██████▉   | 349/500 [04:09<00:52,  2.90it/s] 70%|███████   | 351/500 [04:16<02:59,  1.20s/it] 71%|███████   | 353/500 [04:16<02:06,  1.16it/s] 71%|███████   | 355/500 [04:16<01:30,  1.61it/s] 71%|███████▏  | 357/500 [04:16<01:05,  2.19it/s] 72%|███████▏  | 359/500 [04:16<00:47,  2.95it/s] 72%|███████▏  | 361/500 [04:22<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:23<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:23<01:23,  1.61it/s] 73%|███████▎  | 367/500 [04:23<01:01,  2.18it/s] 74%|███████▍  | 369/500 [04:23<00:45,  2.88it/s] 74%|███████▍  | 371/500 [04:29<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:30<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:30<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:30<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:30<00:40,  2.96it/s] 76%|███████▌  | 381/500 [04:36<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:37<01:41,  1.15it/s] 77%|███████▋  | 385/500 [04:37<01:12,  1.60it/s] 77%|███████▋  | 387/500 [04:37<00:51,  2.18it/s] 78%|███████▊  | 389/500 [04:37<00:38,  2.92it/s] 78%|███████▊  | 391/500 [04:43<02:11,  1.20s/it] 79%|███████▊  | 393/500 [04:44<01:32,  1.16it/s] 79%|███████▉  | 395/500 [04:44<01:05,  1.60it/s] 79%|███████▉  | 397/500 [04:44<00:47,  2.19it/s] 80%|███████▉  | 399/500 [04:44<00:34,  2.95it/s] 80%|████████  | 401/500 [04:50<01:58,  1.20s/it] 81%|████████  | 403/500 [04:51<01:23,  1.16it/s] 81%|████████  | 405/500 [04:51<00:59,  1.60it/s]0.00015429884660989046
Epoch:  339  	Training Loss: 0.00011889703455381095
Test Loss:  5.548852641368285e-05
Valid Loss:  0.0001539147342555225
Epoch:  340  	Training Loss: 0.00011867450666613877
Test Loss:  5.541320570046082e-05
Valid Loss:  0.00015355540381278843
Epoch:  341  	Training Loss: 0.00011845566041301936
Test Loss:  5.5328164307866246e-05
Valid Loss:  0.00015320564853027463
Epoch:  342  	Training Loss: 0.0001182389969471842
Test Loss:  5.4894979257369414e-05
Valid Loss:  0.00015265756519511342
Epoch:  343  	Training Loss: 0.00011787146650021896
Test Loss:  5.46318078704644e-05
Valid Loss:  0.0001522859965916723
Epoch:  344  	Training Loss: 0.00011753033322747797
Test Loss:  5.4421372624346986e-05
Valid Loss:  0.0001519628567621112
Epoch:  345  	Training Loss: 0.00011720594193320721
Test Loss:  5.42329580639489e-05
Valid Loss:  0.00015165549120865762
Epoch:  346  	Training Loss: 0.00011689204256981611
Test Loss:  5.405877891462296e-05
Valid Loss:  0.000151356915012002
Epoch:  347  	Training Loss: 0.00011659198207780719
Test Loss:  5.3892166761215776e-05
Valid Loss:  0.00015105996862985194
Epoch:  348  	Training Loss: 0.00011629509390331805
Test Loss:  5.3731891966890544e-05
Valid Loss:  0.0001507643610239029
Epoch:  349  	Training Loss: 0.00011600129073485732
Test Loss:  5.357723784982227e-05
Valid Loss:  0.0001504685787949711
Epoch:  350  	Training Loss: 0.00011571004870347679
Test Loss:  5.342702570487745e-05
Valid Loss:  0.00015017302939668298
Epoch:  351  	Training Loss: 0.00011542146967258304
Test Loss:  5.3279825806384906e-05
Valid Loss:  0.00014987867325544357
Epoch:  352  	Training Loss: 0.00011513890058267862
Test Loss:  5.325618985807523e-05
Valid Loss:  0.00014970664051361382
Epoch:  353  	Training Loss: 0.00011480694956844673
Test Loss:  5.296904782881029e-05
Valid Loss:  0.00014918002125341445
Epoch:  354  	Training Loss: 0.00011448931763879955
Test Loss:  5.2804785809712484e-05
Valid Loss:  0.0001487882254878059
Epoch:  355  	Training Loss: 0.00011417764471843839
Test Loss:  5.261441401671618e-05
Valid Loss:  0.00014834586181677878
Epoch:  356  	Training Loss: 0.00011387074482627213
Test Loss:  5.245151260169223e-05
Valid Loss:  0.00014792577712796628
Epoch:  357  	Training Loss: 0.0001135661150328815
Test Loss:  5.228799273027107e-05
Valid Loss:  0.00014749485126230866
Epoch:  358  	Training Loss: 0.00011326598178129643
Test Loss:  5.213704935158603e-05
Valid Loss:  0.0001470717543270439
Epoch:  359  	Training Loss: 0.00011296878074062988
Test Loss:  5.1992501539643854e-05
Valid Loss:  0.000146655977005139
Epoch:  360  	Training Loss: 0.00011267303489148617
Test Loss:  5.184873953112401e-05
Valid Loss:  0.00014623746392317116
Epoch:  361  	Training Loss: 0.00011238159640925005
Test Loss:  5.1711896958295256e-05
Valid Loss:  0.00014581922732759267
Epoch:  362  	Training Loss: 0.0001120937813539058
Test Loss:  5.179172148928046e-05
Valid Loss:  0.0001457997423131019
Epoch:  363  	Training Loss: 0.00011193657701369375
Test Loss:  5.18198539793957e-05
Valid Loss:  0.00014567430480383337
Epoch:  364  	Training Loss: 0.00011179187276866287
Test Loss:  5.183022585697472e-05
Valid Loss:  0.0001455229357816279
Epoch:  365  	Training Loss: 0.00011165021714987233
Test Loss:  5.1835399062838405e-05
Valid Loss:  0.00014536664821207523
Epoch:  366  	Training Loss: 0.00011151074431836605
Test Loss:  5.183705434319563e-05
Valid Loss:  0.00014521097182296216
Epoch:  367  	Training Loss: 0.00011137255933135748
Test Loss:  5.18349843332544e-05
Valid Loss:  0.00014505650324281305
Epoch:  368  	Training Loss: 0.00011123494186904281
Test Loss:  5.183008761378005e-05
Valid Loss:  0.0001449061674065888
Epoch:  369  	Training Loss: 0.00011109924525953829
Test Loss:  5.1822338718920946e-05
Valid Loss:  0.0001447576069040224
Epoch:  370  	Training Loss: 0.00011096468369942158
Test Loss:  5.1813145546475425e-05
Valid Loss:  0.00014461044338531792
Epoch:  371  	Training Loss: 0.00011083119898103178
Test Loss:  5.1800012442981824e-05
Valid Loss:  0.0001444639783585444
Epoch:  372  	Training Loss: 0.00011069668107666075
Test Loss:  5.1479866669978946e-05
Valid Loss:  0.00014382174413185567
Epoch:  373  	Training Loss: 0.00011042055848520249
Test Loss:  5.1410745072644204e-05
Valid Loss:  0.000143490222399123
Epoch:  374  	Training Loss: 0.00011015725613106042
Test Loss:  5.129481723997742e-05
Valid Loss:  0.00014311418635770679
Epoch:  375  	Training Loss: 0.00010989407019224018
Test Loss:  5.118003173265606e-05
Valid Loss:  0.00014274462591856718
Epoch:  376  	Training Loss: 0.00010963284876197577
Test Loss:  5.1064620492979884e-05
Valid Loss:  0.00014237768482416868
Epoch:  377  	Training Loss: 0.00010937327169813216
Test Loss:  5.095082815387286e-05
Valid Loss:  0.00014201973681338131
Epoch:  378  	Training Loss: 0.00010911381104961038
Test Loss:  5.083252108306624e-05
Valid Loss:  0.00014165756874717772
Epoch:  379  	Training Loss: 0.00010885616211453453
Test Loss:  5.071606210549362e-05
Valid Loss:  0.00014129915507510304
Epoch:  380  	Training Loss: 0.00010860113252419978
Test Loss:  5.060027615400031e-05
Valid Loss:  0.00014093512436375022
Epoch:  381  	Training Loss: 0.00010834868589881808
Test Loss:  5.048942693974823e-05
Valid Loss:  0.0001405775547027588
Epoch:  382  	Training Loss: 0.00010809882951434702
Test Loss:  5.04728959640488e-05
Valid Loss:  0.00014030811144039035
Epoch:  383  	Training Loss: 0.00010798717266879976
Test Loss:  5.048359889769927e-05
Valid Loss:  0.00014006586570758373
Epoch:  384  	Training Loss: 0.00010788739018607885
Test Loss:  5.051145126344636e-05
Valid Loss:  0.00013984355609863997
Epoch:  385  	Training Loss: 0.00010779645526781678
Test Loss:  5.055105430074036e-05
Valid Loss:  0.00013963988749310374
Epoch:  386  	Training Loss: 0.00010771318193292245
Test Loss:  5.059839168097824e-05
Valid Loss:  0.00013945024693384767
Epoch:  387  	Training Loss: 0.00010763666068669409
Test Loss:  5.065051664132625e-05
Valid Loss:  0.0001392735430272296
Epoch:  388  	Training Loss: 0.00010756516712717712
Test Loss:  5.070580664323643e-05
Valid Loss:  0.00013910843699704856
Epoch:  389  	Training Loss: 0.00010749899229267612
Test Loss:  5.076306115370244e-05
Valid Loss:  0.0001389540557283908
Epoch:  390  	Training Loss: 0.00010743714665295556
Test Loss:  5.0821607146644965e-05
Valid Loss:  0.00013880860933568329
Epoch:  391  	Training Loss: 0.0001073796593118459
Test Loss:  5.0880560593213886e-05
Valid Loss:  0.0001386721560265869
Epoch:  392  	Training Loss: 0.00010732595546869561
Test Loss:  5.095093365525827e-05
Valid Loss:  0.0001389265526086092
Epoch:  393  	Training Loss: 0.00010697828838601708
Test Loss:  5.063979551778175e-05
Valid Loss:  0.00013860678882338107
Epoch:  394  	Training Loss: 0.00010671428753994405
Test Loss:  5.0427421228960156e-05
Valid Loss:  0.00013834673154633492
Epoch:  395  	Training Loss: 0.00010646154987625778
Test Loss:  5.0244416343048215e-05
Valid Loss:  0.0001380697503918782
Epoch:  396  	Training Loss: 0.00010621627006912604
Test Loss:  5.0088739953935146e-05
Valid Loss:  0.0001377906446577981
Epoch:  397  	Training Loss: 0.00010597629443509504
Test Loss:  4.9952919653151184e-05
Valid Loss:  0.00013750710058957338
Epoch:  398  	Training Loss: 0.00010574032785370946
Test Loss:  4.983379039913416e-05
Valid Loss:  0.0001372266124235466
Epoch:  399  	Training Loss: 0.00010550674051046371
Test Loss:  4.9721740651875734e-05
Valid Loss:  0.00013694021617993712
Epoch:  400  	Training Loss: 0.00010527596896281466
Test Loss:  4.961917147738859e-05
Valid Loss:  0.00013665096776094288
Epoch:  401  	Training Loss: 0.00010504864621907473
Test Loss:  4.9525988288223743e-05
Valid Loss:  0.00013636844232678413
Epoch:  402  	Training Loss: 0.00010482320067239925
Test Loss:  4.922593871015124e-05
Valid Loss:  0.0001359076122753322
Epoch:  403  	Training Loss: 0.00010463905346114188
Test Loss:  4.911247378913686e-05
Valid Loss:  0.00013563959510065615
Epoch:  404  	Training Loss: 0.00010448271495988593
Test Loss:  4.904164597974159e-05
Valid Loss:  0.00013541965745389462
Epoch:  405  	Training Loss: 0.00010433144052512944
Test Loss:  4.8981517466017976e-05
Valid Loss:  0.00013520181528292596
 81%|████████▏ | 407/500 [04:51<00:42,  2.19it/s] 82%|████████▏ | 409/500 [04:51<00:30,  2.95it/s] 82%|████████▏ | 411/500 [04:57<01:45,  1.19s/it] 83%|████████▎ | 413/500 [04:57<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:57<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:58<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:58<00:27,  3.00it/s] 84%|████████▍ | 421/500 [05:04<01:33,  1.19s/it] 85%|████████▍ | 423/500 [05:04<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:04<00:46,  1.62it/s] 85%|████████▌ | 427/500 [05:05<00:32,  2.22it/s] 86%|████████▌ | 429/500 [05:05<00:23,  2.98it/s] 86%|████████▌ | 431/500 [05:11<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:11<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:11<00:40,  1.59it/s] 87%|████████▋ | 437/500 [05:12<00:29,  2.17it/s] 88%|████████▊ | 439/500 [05:12<00:20,  2.92it/s] 88%|████████▊ | 441/500 [05:18<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:18<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:18<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:18<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:18<00:17,  2.97it/s] 90%|█████████ | 451/500 [05:25<00:59,  1.21s/it] 91%|█████████ | 453/500 [05:25<00:40,  1.15it/s] 91%|█████████ | 455/500 [05:25<00:28,  1.59it/s] 91%|█████████▏| 457/500 [05:25<00:19,  2.17it/s] 92%|█████████▏| 459/500 [05:26<00:14,  2.92it/s] 92%|█████████▏| 461/500 [05:32<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:32<00:31,  1.16it/s] 93%|█████████▎| 465/500 [05:32<00:22,  1.59it/s] 93%|█████████▎| 467/500 [05:32<00:15,  2.14it/s] 94%|█████████▍| 469/500 [05:33<00:10,  2.84it/s] 94%|█████████▍| 471/500 [05:39<00:34,  1.18s/it]Epoch:  406  	Training Loss: 0.00010419336467748508
Test Loss:  4.893328878097236e-05
Valid Loss:  0.0001349919766653329
Epoch:  407  	Training Loss: 0.00010406310320831835
Test Loss:  4.890715717920102e-05
Valid Loss:  0.00013479719928000122
Epoch:  408  	Training Loss: 0.00010393471166025847
Test Loss:  4.8888890887610614e-05
Valid Loss:  0.0001346083008684218
Epoch:  409  	Training Loss: 0.00010380748426541686
Test Loss:  4.88689292978961e-05
Valid Loss:  0.00013442448107525706
Epoch:  410  	Training Loss: 0.00010368311632191762
Test Loss:  4.8846974095795304e-05
Valid Loss:  0.00013423612108454108
Epoch:  411  	Training Loss: 0.00010356484563089907
Test Loss:  4.882876601186581e-05
Valid Loss:  0.0001340599119430408
Epoch:  412  	Training Loss: 0.00010344732436351478
Test Loss:  4.8787580453790724e-05
Valid Loss:  0.00013390363892540336
Epoch:  413  	Training Loss: 0.00010334896796848625
Test Loss:  4.8764763050712645e-05
Valid Loss:  0.00013376394053921103
Epoch:  414  	Training Loss: 0.00010325192124582827
Test Loss:  4.874596925219521e-05
Valid Loss:  0.00013362585741560906
Epoch:  415  	Training Loss: 0.00010315633699065074
Test Loss:  4.873002035310492e-05
Valid Loss:  0.00013348959328141063
Epoch:  416  	Training Loss: 0.0001030612547765486
Test Loss:  4.87147735839244e-05
Valid Loss:  0.0001333516265731305
Epoch:  417  	Training Loss: 0.0001029671257128939
Test Loss:  4.870168777415529e-05
Valid Loss:  0.00013321470760274678
Epoch:  418  	Training Loss: 0.00010287424811394885
Test Loss:  4.8690686526242644e-05
Valid Loss:  0.0001330779050476849
Epoch:  419  	Training Loss: 0.0001027826510835439
Test Loss:  4.86815843032673e-05
Valid Loss:  0.00013294238306116313
Epoch:  420  	Training Loss: 0.00010269207996316254
Test Loss:  4.867381721851416e-05
Valid Loss:  0.0001328072976320982
Epoch:  421  	Training Loss: 0.00010260278941132128
Test Loss:  4.866810922976583e-05
Valid Loss:  0.00013267372560221702
Epoch:  422  	Training Loss: 0.00010251341882394627
Test Loss:  4.857176827499643e-05
Valid Loss:  0.0001325310586253181
Epoch:  423  	Training Loss: 0.00010243852739222348
Test Loss:  4.850902041653171e-05
Valid Loss:  0.0001324247132288292
Epoch:  424  	Training Loss: 0.00010236834350507706
Test Loss:  4.845661169383675e-05
Valid Loss:  0.00013232622586656362
Epoch:  425  	Training Loss: 0.00010230664338450879
Test Loss:  4.8420315579278395e-05
Valid Loss:  0.00013222507550381124
Epoch:  426  	Training Loss: 0.00010225131700281054
Test Loss:  4.839775283471681e-05
Valid Loss:  0.0001321343006566167
Epoch:  427  	Training Loss: 0.00010219755495199934
Test Loss:  4.837721644435078e-05
Valid Loss:  0.0001320447336183861
Epoch:  428  	Training Loss: 0.00010214639769401401
Test Loss:  4.83599396829959e-05
Valid Loss:  0.0001319666625931859
Epoch:  429  	Training Loss: 0.00010209569882135838
Test Loss:  4.834304127143696e-05
Valid Loss:  0.00013189188030082732
Epoch:  430  	Training Loss: 0.00010204889258602634
Test Loss:  4.832650665775873e-05
Valid Loss:  0.00013180790119804442
Epoch:  431  	Training Loss: 0.00010201011173194274
Test Loss:  4.832164995605126e-05
Valid Loss:  0.00013173898332752287
Epoch:  432  	Training Loss: 0.0001019714109133929
Test Loss:  4.832795821130276e-05
Valid Loss:  0.0001318386202910915
Epoch:  433  	Training Loss: 0.00010169744928134605
Test Loss:  4.799926682608202e-05
Valid Loss:  0.00013145191769581288
Epoch:  434  	Training Loss: 0.00010145082342205569
Test Loss:  4.7799854655750096e-05
Valid Loss:  0.00013120626681484282
Epoch:  435  	Training Loss: 0.00010121284140041098
Test Loss:  4.7584500862285495e-05
Valid Loss:  0.00013091466098558158
Epoch:  436  	Training Loss: 0.00010098253551404923
Test Loss:  4.740297663374804e-05
Valid Loss:  0.00013065595703665167
Epoch:  437  	Training Loss: 0.00010075525642605498
Test Loss:  4.7226254537235945e-05
Valid Loss:  0.0001303950703004375
Epoch:  438  	Training Loss: 0.00010052989819087088
Test Loss:  4.706135223386809e-05
Valid Loss:  0.00013013608986511827
Epoch:  439  	Training Loss: 0.00010030682460637763
Test Loss:  4.6903362090233713e-05
Valid Loss:  0.00012987722584512085
Epoch:  440  	Training Loss: 0.0001000922784442082
Test Loss:  4.674459341913462e-05
Valid Loss:  0.00012957854778505862
Epoch:  441  	Training Loss: 9.988485544454306e-05
Test Loss:  4.663501385948621e-05
Valid Loss:  0.00012934193364344537
Epoch:  442  	Training Loss: 9.967850928660482e-05
Test Loss:  4.652413917938247e-05
Valid Loss:  0.00012899196008220315
Epoch:  443  	Training Loss: 9.929254883900285e-05
Test Loss:  4.64176555396989e-05
Valid Loss:  0.00012866361066699028
Epoch:  444  	Training Loss: 9.892984962789342e-05
Test Loss:  4.631589399650693e-05
Valid Loss:  0.0001283413148485124
Epoch:  445  	Training Loss: 9.859068086370826e-05
Test Loss:  4.621699918061495e-05
Valid Loss:  0.00012802827404811978
Epoch:  446  	Training Loss: 9.827045141719282e-05
Test Loss:  4.611870099324733e-05
Valid Loss:  0.00012772814079653472
Epoch:  447  	Training Loss: 9.795848745852709e-05
Test Loss:  4.60242445115e-05
Valid Loss:  0.00012744551349896938
Epoch:  448  	Training Loss: 9.76570081547834e-05
Test Loss:  4.592943878378719e-05
Valid Loss:  0.00012716274068225175
Epoch:  449  	Training Loss: 9.736130596138537e-05
Test Loss:  4.583675035974011e-05
Valid Loss:  0.0001268842606805265
Epoch:  450  	Training Loss: 9.707224671728909e-05
Test Loss:  4.57468195236288e-05
Valid Loss:  0.00012660377251449972
Epoch:  451  	Training Loss: 9.678724745754153e-05
Test Loss:  4.566554707707837e-05
Valid Loss:  0.00012632610742002726
Epoch:  452  	Training Loss: 9.65059589361772e-05
Test Loss:  4.562915273709223e-05
Valid Loss:  0.00012606785458046943
Epoch:  453  	Training Loss: 9.639390918891877e-05
Test Loss:  4.5634471462108195e-05
Valid Loss:  0.00012585624062921852
Epoch:  454  	Training Loss: 9.62865015026182e-05
Test Loss:  4.564609480439685e-05
Valid Loss:  0.0001256611867574975
Epoch:  455  	Training Loss: 9.618200419936329e-05
Test Loss:  4.565669223666191e-05
Valid Loss:  0.00012547273945529014
Epoch:  456  	Training Loss: 9.608226537238806e-05
Test Loss:  4.566651114146225e-05
Valid Loss:  0.00012528827937785536
Epoch:  457  	Training Loss: 9.598874021321535e-05
Test Loss:  4.567784708342515e-05
Valid Loss:  0.0001251117791980505
Epoch:  458  	Training Loss: 9.59001190494746e-05
Test Loss:  4.5688160753343254e-05
Valid Loss:  0.0001249430060852319
Epoch:  459  	Training Loss: 9.58141463343054e-05
Test Loss:  4.569568045553751e-05
Valid Loss:  0.00012477829295676202
Epoch:  460  	Training Loss: 9.573159331921488e-05
Test Loss:  4.570595410768874e-05
Valid Loss:  0.00012462050653994083
Epoch:  461  	Training Loss: 9.565096843289211e-05
Test Loss:  4.5718603360001e-05
Valid Loss:  0.0001244668528670445
Epoch:  462  	Training Loss: 9.557168232277036e-05
Test Loss:  4.570612873067148e-05
Valid Loss:  0.0001248176267836243
Epoch:  463  	Training Loss: 9.536232391837984e-05
Test Loss:  4.5603650505654514e-05
Valid Loss:  0.00012479390716180205
Epoch:  464  	Training Loss: 9.524729830445722e-05
Test Loss:  4.548931246972643e-05
Valid Loss:  0.00012472379603423178
Epoch:  465  	Training Loss: 9.514080011285841e-05
Test Loss:  4.537286804406904e-05
Valid Loss:  0.00012464009341783822
Epoch:  466  	Training Loss: 9.503723413217813e-05
Test Loss:  4.525584517978132e-05
Valid Loss:  0.00012454875104594976
Epoch:  467  	Training Loss: 9.493560355622321e-05
Test Loss:  4.514135071076453e-05
Valid Loss:  0.00012445327593013644
Epoch:  468  	Training Loss: 9.483571193413809e-05
Test Loss:  4.50296065537259e-05
Valid Loss:  0.00012435909593477845
Epoch:  469  	Training Loss: 9.473759564571083e-05
Test Loss:  4.492045991355553e-05
Valid Loss:  0.00012426532339304686
Epoch:  470  	Training Loss: 9.464075264986604e-05
Test Loss:  4.481411451706663e-05
Valid Loss:  0.00012417348625604063
Epoch:  471  	Training Loss: 9.45456195040606e-05
Test Loss:  4.471038482734002e-05
Valid Loss:  0.0001240819983649999
Epoch:  472  	Training Loss: 9.445151954423636e-05
Test Loss:  4.4485168473329395e-05
Valid Loss:  0.00012356739898677915
Epoch:  473  	Training Loss: 9.426625911146402e-05
Test Loss:   95%|█████████▍| 473/500 [05:39<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:39<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:39<00:10,  2.22it/s] 96%|█████████▌| 479/500 [05:39<00:07,  2.99it/s] 96%|█████████▌| 481/500 [05:46<00:22,  1.20s/it] 97%|█████████▋| 483/500 [05:46<00:14,  1.16it/s] 97%|█████████▋| 485/500 [05:46<00:09,  1.61it/s] 97%|█████████▋| 487/500 [05:46<00:05,  2.20it/s] 98%|█████████▊| 489/500 [05:46<00:03,  2.96it/s] 98%|█████████▊| 491/500 [05:53<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:53<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:53<00:03,  1.62it/s] 99%|█████████▉| 497/500 [05:53<00:01,  2.21it/s]100%|█████████▉| 499/500 [05:53<00:00,  2.97it/s]100%|██████████| 500/500 [05:53<00:00,  1.41it/s]
4.446153252501972e-05
Valid Loss:  0.00012325703573878855
Epoch:  474  	Training Loss: 9.409961057826877e-05
Test Loss:  4.443831494427286e-05
Valid Loss:  0.00012296551722101867
Epoch:  475  	Training Loss: 9.393716754857451e-05
Test Loss:  4.4407763198250905e-05
Valid Loss:  0.00012268427235540003
Epoch:  476  	Training Loss: 9.37783916015178e-05
Test Loss:  4.436986273503862e-05
Valid Loss:  0.00012241187505424023
Epoch:  477  	Training Loss: 9.362268610857427e-05
Test Loss:  4.4325490307528526e-05
Valid Loss:  0.00012214596790727228
Epoch:  478  	Training Loss: 9.347006562165916e-05
Test Loss:  4.427612293511629e-05
Valid Loss:  0.00012188711843919009
Epoch:  479  	Training Loss: 9.332088666269556e-05
Test Loss:  4.4179472752148286e-05
Valid Loss:  0.00012164533836767077
Epoch:  480  	Training Loss: 9.318166848970577e-05
Test Loss:  4.4144635467091575e-05
Valid Loss:  0.00012141156184952706
Epoch:  481  	Training Loss: 9.303992555942386e-05
Test Loss:  4.4044099922757596e-05
Valid Loss:  0.00012116645666537806
Epoch:  482  	Training Loss: 9.290452726418152e-05
Test Loss:  4.4079275539843366e-05
Valid Loss:  0.00012120288738515228
Epoch:  483  	Training Loss: 9.266327106161043e-05
Test Loss:  4.392619302961975e-05
Valid Loss:  0.00012091637472622097
Epoch:  484  	Training Loss: 9.244371904060245e-05
Test Loss:  4.382922634249553e-05
Valid Loss:  0.00012070254888385534
Epoch:  485  	Training Loss: 9.222736116498709e-05
Test Loss:  4.37289709225297e-05
Valid Loss:  0.00012047275231452659
Epoch:  486  	Training Loss: 9.20152451726608e-05
Test Loss:  4.364312189863995e-05
Valid Loss:  0.00012026503100059927
Epoch:  487  	Training Loss: 9.180855704471469e-05
Test Loss:  4.3548832763917744e-05
Valid Loss:  0.00012003274605376646
Epoch:  488  	Training Loss: 9.160351328318939e-05
Test Loss:  4.346254718257114e-05
Valid Loss:  0.00011980612180195749
Epoch:  489  	Training Loss: 9.139932808466256e-05
Test Loss:  4.337616701377556e-05
Valid Loss:  0.00011956841626670212
Epoch:  490  	Training Loss: 9.11961542442441e-05
Test Loss:  4.3297986849211156e-05
Valid Loss:  0.00011934353096876293
Epoch:  491  	Training Loss: 9.099423186853528e-05
Test Loss:  4.32166998507455e-05
Valid Loss:  0.00011911048932233825
Epoch:  492  	Training Loss: 9.07934590941295e-05
Test Loss:  4.3122036004206166e-05
Valid Loss:  0.00011867073044413701
Epoch:  493  	Training Loss: 9.06109344214201e-05
Test Loss:  4.3145351810380816e-05
Valid Loss:  0.000118350209959317
Epoch:  494  	Training Loss: 9.044284524861723e-05
Test Loss:  4.3174561142222956e-05
Valid Loss:  0.00011806408292613924
Epoch:  495  	Training Loss: 9.028119529830292e-05
Test Loss:  4.319348226999864e-05
Valid Loss:  0.00011779489432228729
Epoch:  496  	Training Loss: 9.012522059492767e-05
Test Loss:  4.3201493099331856e-05
Valid Loss:  0.00011753980652429163
Epoch:  497  	Training Loss: 8.997526310849935e-05
Test Loss:  4.319695653975941e-05
Valid Loss:  0.00011728463869076222
Epoch:  498  	Training Loss: 8.983178122434765e-05
Test Loss:  4.319687286624685e-05
Valid Loss:  0.00011705015640472993
Epoch:  499  	Training Loss: 8.969218470156193e-05
Test Loss:  4.3190324504394084e-05
Valid Loss:  0.00011682618787745014
Epoch:  500  	Training Loss: 8.955548400990665e-05
Test Loss:  4.317641651141457e-05
Valid Loss:  0.00011660970631055534
seed is  13
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:35, 13.88it/s]  1%|          | 4/500 [00:00<00:32, 15.22it/s]  1%|          | 6/500 [00:00<00:31, 15.68it/s]  2%|▏         | 8/500 [00:00<00:33, 14.62it/s]  2%|▏         | 10/500 [00:00<00:35, 13.69it/s]  2%|▏         | 12/500 [00:00<00:37, 12.98it/s]  3%|▎         | 14/500 [00:01<00:38, 12.53it/s]  3%|▎         | 16/500 [00:01<00:39, 12.40it/s]  4%|▎         | 18/500 [00:01<00:39, 12.12it/s]  4%|▍         | 20/500 [00:01<00:39, 12.02it/s]  4%|▍         | 22/500 [00:01<00:39, 12.00it/s]  5%|▍         | 24/500 [00:01<00:39, 12.10it/s]  5%|▌         | 26/500 [00:02<00:39, 11.93it/s]  6%|▌         | 28/500 [00:02<00:39, 12.03it/s]  6%|▌         | 30/500 [00:02<00:39, 12.05it/s]  6%|▋         | 32/500 [00:02<00:36, 12.75it/s]  7%|▋         | 34/500 [00:02<00:34, 13.50it/s]  7%|▋         | 36/500 [00:02<00:32, 14.09it/s]  8%|▊         | 38/500 [00:02<00:31, 14.58it/s]  8%|▊         | 40/500 [00:03<00:30, 15.08it/s]  8%|▊         | 42/500 [00:03<00:30, 15.26it/s]  9%|▉         | 44/500 [00:03<00:29, 15.48it/s]  9%|▉         | 46/500 [00:03<00:28, 15.71it/s] 10%|▉         | 48/500 [00:03<00:28, 15.89it/s] 10%|█         | 50/500 [00:03<00:28, 16.06it/s] 10%|█         | 52/500 [00:03<00:27, 16.01it/s] 11%|█         | 54/500 [00:03<00:27, 15.98it/s] 11%|█         | 56/500 [00:04<00:28, 15.81it/s] 12%|█▏        | 58/500 [00:04<00:28, 15.78it/s] 12%|█▏        | 60/500 [00:04<00:28, 15.71it/s] 12%|█▏        | 62/500 [00:04<00:27, 15.67it/s] 13%|█▎        | 64/500 [00:04<00:27, 15.69it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.81it/s] 14%|█▎        | 68/500 [00:04<00:28, 14.97it/s] 14%|█▍        | 70/500 [00:04<00:31, 13.48it/s] 14%|█▍        | 72/500 [00:05<00:32, 13.37it/s] 15%|█▍        | 74/500 [00:05<00:30, 14.09it/s] 15%|█▌        | 76/500 [00:05<00:28, 14.66it/s] 16%|█▌        | 78/500 [00:05<00:28, 14.90it/s] 16%|█▌        | 80/500 [00:05<00:27, 15.28it/s] 16%|█▋        | 82/500 [00:05<00:27, 15.46it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.70it/s] 17%|█▋        | 86/500 [00:06<00:26, 15.78it/s] 18%|█▊        | 88/500 [00:06<00:25, 15.98it/s] 18%|█▊        | 90/500 [00:06<00:27, 14.82it/s] 18%|█▊        | 92/500 [00:06<00:29, 13.93it/s] 19%|█▉        | 94/500 [00:06<00:28, 14.16it/s] 19%|█▉        | 96/500 [00:06<00:27, 14.72it/s] 20%|█▉        | 98/500 [00:06<00:26, 15.15it/s] 20%|██        | 100/500 [00:06<00:26, 15.13it/s] 20%|██        | 102/500 [00:07<00:28, 14.09it/s] 21%|██        | 104/500 [00:07<00:30, 13.18it/s] 21%|██        | 106/500 [00:07<00:28, 13.83it/s] 22%|██▏       | 108/500 [00:07<00:27, 14.48it/s] 22%|██▏       | 110/500 [00:07<00:26, 14.95it/s] 22%|██▏       | 112/500 [00:07<00:25, 15.35it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.64it/s] 23%|██▎       | 116/500 [00:08<00:24, 15.87it/s] 24%|██▎       | 118/500 [00:08<00:23, 15.98it/s] 24%|██▍       | 120/500 [00:08<00:23, 16.06it/s] 24%|██▍       | 122/500 [00:08<00:23, 15.81it/s] 25%|██▍       | 124/500 [00:08<00:26, 14.38it/s]Epoch:  1  	Training Loss: 0.04272831231355667
Test Loss:  87.72386932373047
Valid Loss:  87.60717010498047
Epoch:  2  	Training Loss: 88.3944091796875
Test Loss:  98607960.0
Valid Loss:  98766144.0
Epoch:  3  	Training Loss: 98188560.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  125  	Training Loss: nan
 25%|██▌       | 126/500 [00:08<00:27, 13.65it/s] 26%|██▌       | 128/500 [00:08<00:27, 13.68it/s] 26%|██▌       | 130/500 [00:09<00:25, 14.24it/s] 26%|██▋       | 132/500 [00:09<00:26, 13.97it/s] 27%|██▋       | 134/500 [00:09<00:25, 14.55it/s] 27%|██▋       | 136/500 [00:09<00:24, 14.99it/s] 28%|██▊       | 138/500 [00:09<00:23, 15.41it/s] 28%|██▊       | 140/500 [00:09<00:23, 15.63it/s] 28%|██▊       | 142/500 [00:09<00:22, 15.70it/s] 29%|██▉       | 144/500 [00:09<00:22, 15.61it/s] 29%|██▉       | 146/500 [00:10<00:22, 15.68it/s] 30%|██▉       | 148/500 [00:10<00:22, 15.85it/s] 30%|███       | 150/500 [00:10<00:23, 14.84it/s] 30%|███       | 152/500 [00:10<00:25, 13.74it/s] 31%|███       | 154/500 [00:10<00:26, 13.29it/s] 31%|███       | 156/500 [00:10<00:24, 13.99it/s] 32%|███▏      | 158/500 [00:10<00:23, 14.42it/s] 32%|███▏      | 160/500 [00:11<00:23, 14.76it/s] 32%|███▏      | 162/500 [00:11<00:22, 14.70it/s] 33%|███▎      | 164/500 [00:11<00:22, 14.75it/s] 33%|███▎      | 166/500 [00:11<00:22, 15.09it/s] 34%|███▎      | 168/500 [00:11<00:21, 15.41it/s] 34%|███▍      | 170/500 [00:11<00:21, 15.69it/s] 34%|███▍      | 172/500 [00:11<00:20, 15.83it/s] 35%|███▍      | 174/500 [00:11<00:20, 15.86it/s] 35%|███▌      | 176/500 [00:12<00:20, 15.97it/s] 36%|███▌      | 178/500 [00:12<00:20, 15.84it/s] 36%|███▌      | 180/500 [00:12<00:20, 15.79it/s] 36%|███▋      | 182/500 [00:12<00:20, 15.46it/s] 37%|███▋      | 184/500 [00:12<00:22, 14.25it/s] 37%|███▋      | 186/500 [00:12<00:23, 13.51it/s] 38%|███▊      | 188/500 [00:12<00:24, 12.98it/s] 38%|███▊      | 190/500 [00:13<00:24, 12.56it/s] 38%|███▊      | 192/500 [00:13<00:23, 13.04it/s] 39%|███▉      | 194/500 [00:13<00:22, 13.87it/s] 39%|███▉      | 196/500 [00:13<00:20, 14.51it/s] 40%|███▉      | 198/500 [00:13<00:20, 15.00it/s] 40%|████      | 200/500 [00:13<00:19, 15.40it/s] 40%|████      | 202/500 [00:13<00:19, 15.59it/s] 41%|████      | 204/500 [00:14<00:18, 15.77it/s] 41%|████      | 206/500 [00:14<00:18, 15.78it/s] 42%|████▏     | 208/500 [00:14<00:18, 15.78it/s] 42%|████▏     | 210/500 [00:14<00:18, 15.68it/s] 42%|████▏     | 212/500 [00:14<00:18, 15.89it/s] 43%|████▎     | 214/500 [00:14<00:17, 16.06it/s] 43%|████▎     | 216/500 [00:14<00:17, 16.17it/s] 44%|████▎     | 218/500 [00:14<00:17, 16.25it/s] 44%|████▍     | 220/500 [00:15<00:17, 16.30it/s] 44%|████▍     | 222/500 [00:15<00:17, 15.91it/s] 45%|████▍     | 224/500 [00:15<00:17, 15.86it/s] 45%|████▌     | 226/500 [00:15<00:18, 14.99it/s] 46%|████▌     | 228/500 [00:15<00:19, 13.93it/s] 46%|████▌     | 230/500 [00:15<00:20, 13.35it/s] 46%|████▋     | 232/500 [00:15<00:20, 13.01it/s] 47%|████▋     | 234/500 [00:16<00:20, 12.79it/s] 47%|████▋     | 236/500 [00:16<00:19, 13.32it/s] 48%|████▊     | 238/500 [00:16<00:18, 14.02it/s] 48%|████▊     | 240/500 [00:16<00:17, 14.54it/s] 48%|████▊     | 242/500 [00:16<00:17, 15.01it/s] 49%|████▉     | 244/500 [00:16<00:16, 15.18it/s] 49%|████▉     | 246/500 [00:16<00:16, 15.44it/s] 50%|████▉     | 248/500 [00:16<00:16, 15.46it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  249  	Training Loss: nan
 50%|█████     | 250/500 [00:17<00:16, 15.17it/s] 50%|█████     | 252/500 [00:17<00:17, 14.21it/s] 51%|█████     | 254/500 [00:17<00:17, 14.09it/s] 51%|█████     | 256/500 [00:17<00:18, 13.42it/s] 52%|█████▏    | 258/500 [00:17<00:18, 13.18it/s] 52%|█████▏    | 260/500 [00:17<00:17, 13.93it/s] 52%|█████▏    | 262/500 [00:17<00:16, 14.55it/s] 53%|█████▎    | 264/500 [00:18<00:15, 14.92it/s] 53%|█████▎    | 266/500 [00:18<00:15, 15.13it/s] 54%|█████▎    | 268/500 [00:18<00:15, 14.81it/s] 54%|█████▍    | 270/500 [00:18<00:16, 13.96it/s] 54%|█████▍    | 272/500 [00:18<00:16, 14.12it/s] 55%|█████▍    | 274/500 [00:18<00:15, 14.58it/s] 55%|█████▌    | 276/500 [00:18<00:15, 14.23it/s] 56%|█████▌    | 278/500 [00:19<00:16, 13.35it/s] 56%|█████▌    | 280/500 [00:19<00:17, 12.74it/s] 56%|█████▋    | 282/500 [00:19<00:17, 12.45it/s] 57%|█████▋    | 284/500 [00:19<00:17, 12.35it/s] 57%|█████▋    | 286/500 [00:19<00:17, 12.28it/s] 58%|█████▊    | 288/500 [00:19<00:17, 12.02it/s] 58%|█████▊    | 290/500 [00:20<00:17, 12.15it/s] 58%|█████▊    | 292/500 [00:20<00:15, 13.16it/s] 59%|█████▉    | 294/500 [00:20<00:14, 13.97it/s] 59%|█████▉    | 296/500 [00:20<00:14, 14.55it/s] 60%|█████▉    | 298/500 [00:20<00:13, 14.91it/s] 60%|██████    | 300/500 [00:20<00:13, 15.06it/s] 60%|██████    | 302/500 [00:20<00:13, 15.20it/s] 61%|██████    | 304/500 [00:21<00:12, 15.49it/s] 61%|██████    | 306/500 [00:21<00:12, 15.79it/s] 62%|██████▏   | 308/500 [00:21<00:12, 15.93it/s] 62%|██████▏   | 310/500 [00:21<00:11, 16.06it/s] 62%|██████▏   | 312/500 [00:21<00:11, 15.92it/s] 63%|██████▎   | 314/500 [00:21<00:11, 16.02it/s] 63%|██████▎   | 316/500 [00:21<00:11, 15.96it/s] 64%|██████▎   | 318/500 [00:21<00:11, 16.08it/s] 64%|██████▍   | 320/500 [00:21<00:11, 16.17it/s] 64%|██████▍   | 322/500 [00:22<00:11, 16.06it/s] 65%|██████▍   | 324/500 [00:22<00:11, 15.99it/s] 65%|██████▌   | 326/500 [00:22<00:10, 16.02it/s] 66%|██████▌   | 328/500 [00:22<00:10, 16.08it/s] 66%|██████▌   | 330/500 [00:22<00:10, 16.01it/s] 66%|██████▋   | 332/500 [00:22<00:10, 15.89it/s] 67%|██████▋   | 334/500 [00:22<00:10, 15.86it/s] 67%|██████▋   | 336/500 [00:22<00:10, 15.87it/s] 68%|██████▊   | 338/500 [00:23<00:10, 15.95it/s] 68%|██████▊   | 340/500 [00:23<00:10, 15.89it/s] 68%|██████▊   | 342/500 [00:23<00:09, 15.91it/s] 69%|██████▉   | 344/500 [00:23<00:09, 15.89it/s] 69%|██████▉   | 346/500 [00:23<00:09, 15.46it/s] 70%|██████▉   | 348/500 [00:23<00:09, 15.65it/s] 70%|███████   | 350/500 [00:23<00:09, 15.72it/s] 70%|███████   | 352/500 [00:24<00:09, 15.83it/s] 71%|███████   | 354/500 [00:24<00:09, 15.78it/s] 71%|███████   | 356/500 [00:24<00:09, 15.83it/s] 72%|███████▏  | 358/500 [00:24<00:08, 15.97it/s] 72%|███████▏  | 360/500 [00:24<00:08, 15.96it/s] 72%|███████▏  | 362/500 [00:24<00:08, 15.96it/s] 73%|███████▎  | 364/500 [00:24<00:08, 16.04it/s] 73%|███████▎  | 366/500 [00:24<00:08, 15.91it/s] 74%|███████▎  | 368/500 [00:25<00:08, 16.00it/s] 74%|███████▍  | 370/500 [00:25<00:08, 16.07it/s] 74%|███████▍  | 372/500 [00:25<00:07, 16.05it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  373  	Training Loss: nan
 75%|███████▍  | 374/500 [00:25<00:07, 15.97it/s] 75%|███████▌  | 376/500 [00:25<00:07, 15.70it/s] 76%|███████▌  | 378/500 [00:25<00:07, 15.59it/s] 76%|███████▌  | 380/500 [00:25<00:08, 14.71it/s] 76%|███████▋  | 382/500 [00:25<00:07, 14.91it/s] 77%|███████▋  | 384/500 [00:26<00:07, 15.26it/s] 77%|███████▋  | 386/500 [00:26<00:07, 15.37it/s] 78%|███████▊  | 388/500 [00:26<00:07, 15.68it/s] 78%|███████▊  | 390/500 [00:26<00:07, 15.65it/s] 78%|███████▊  | 392/500 [00:26<00:06, 15.74it/s] 79%|███████▉  | 394/500 [00:26<00:06, 15.93it/s] 79%|███████▉  | 396/500 [00:26<00:06, 16.02it/s] 80%|███████▉  | 398/500 [00:26<00:06, 16.15it/s] 80%|████████  | 400/500 [00:27<00:06, 16.15it/s] 80%|████████  | 402/500 [00:27<00:06, 16.13it/s] 81%|████████  | 404/500 [00:27<00:06, 15.93it/s] 81%|████████  | 406/500 [00:27<00:05, 15.91it/s] 82%|████████▏ | 408/500 [00:27<00:05, 15.98it/s] 82%|████████▏ | 410/500 [00:27<00:05, 16.14it/s] 82%|████████▏ | 412/500 [00:27<00:05, 16.21it/s] 83%|████████▎ | 414/500 [00:27<00:05, 15.80it/s] 83%|████████▎ | 416/500 [00:28<00:05, 14.53it/s] 84%|████████▎ | 418/500 [00:28<00:05, 13.77it/s] 84%|████████▍ | 420/500 [00:28<00:06, 12.89it/s] 84%|████████▍ | 422/500 [00:28<00:05, 13.38it/s] 85%|████████▍ | 424/500 [00:28<00:05, 14.16it/s] 85%|████████▌ | 426/500 [00:28<00:05, 14.70it/s] 86%|████████▌ | 428/500 [00:28<00:04, 15.01it/s] 86%|████████▌ | 430/500 [00:29<00:04, 15.36it/s] 86%|████████▋ | 432/500 [00:29<00:04, 15.50it/s] 87%|████████▋ | 434/500 [00:29<00:04, 15.69it/s] 87%|████████▋ | 436/500 [00:29<00:04, 15.54it/s] 88%|████████▊ | 438/500 [00:29<00:04, 14.39it/s] 88%|████████▊ | 440/500 [00:29<00:04, 13.87it/s] 88%|████████▊ | 442/500 [00:29<00:03, 14.58it/s] 89%|████████▉ | 444/500 [00:30<00:03, 15.07it/s] 89%|████████▉ | 446/500 [00:30<00:03, 15.43it/s] 90%|████████▉ | 448/500 [00:30<00:03, 15.53it/s] 90%|█████████ | 450/500 [00:30<00:03, 15.76it/s] 90%|█████████ | 452/500 [00:30<00:03, 15.92it/s] 91%|█████████ | 454/500 [00:30<00:02, 16.04it/s] 91%|█████████ | 456/500 [00:30<00:02, 16.09it/s] 92%|█████████▏| 458/500 [00:30<00:02, 16.06it/s] 92%|█████████▏| 460/500 [00:30<00:02, 16.25it/s] 92%|█████████▏| 462/500 [00:31<00:02, 15.84it/s] 93%|█████████▎| 464/500 [00:31<00:02, 14.39it/s] 93%|█████████▎| 466/500 [00:31<00:02, 14.38it/s] 94%|█████████▎| 468/500 [00:31<00:02, 14.85it/s] 94%|█████████▍| 470/500 [00:31<00:01, 15.26it/s] 94%|█████████▍| 472/500 [00:31<00:01, 15.46it/s] 95%|█████████▍| 474/500 [00:31<00:01, 15.74it/s] 95%|█████████▌| 476/500 [00:32<00:01, 15.90it/s] 96%|█████████▌| 478/500 [00:32<00:01, 16.09it/s] 96%|█████████▌| 480/500 [00:32<00:01, 16.26it/s] 96%|█████████▋| 482/500 [00:32<00:01, 16.18it/s] 97%|█████████▋| 484/500 [00:32<00:01, 15.99it/s] 97%|█████████▋| 486/500 [00:32<00:00, 15.96it/s] 98%|█████████▊| 488/500 [00:32<00:00, 16.10it/s] 98%|█████████▊| 490/500 [00:32<00:00, 15.78it/s] 98%|█████████▊| 492/500 [00:33<00:00, 16.06it/s] 99%|█████████▉| 494/500 [00:33<00:00, 16.17it/s] 99%|█████████▉| 496/500 [00:33<00:00, 16.28it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
100%|█████████▉| 498/500 [00:33<00:00, 16.34it/s]100%|██████████| 500/500 [00:33<00:00, 16.28it/s]100%|██████████| 500/500 [00:33<00:00, 14.91it/s]
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  13
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:44,  6.46s/it]  1%|          | 3/500 [00:06<14:17,  1.73s/it]  1%|          | 5/500 [00:06<07:11,  1.15it/s]  1%|▏         | 7/500 [00:06<04:22,  1.88it/s]  2%|▏         | 9/500 [00:06<02:55,  2.80it/s]  2%|▏         | 11/500 [00:13<11:03,  1.36s/it]  3%|▎         | 13/500 [00:13<07:33,  1.07it/s]  3%|▎         | 15/500 [00:13<05:17,  1.53it/s]  3%|▎         | 17/500 [00:13<03:48,  2.11it/s]  4%|▍         | 19/500 [00:14<02:50,  2.83it/s]  4%|▍         | 21/500 [00:20<09:51,  1.24s/it]  5%|▍         | 23/500 [00:20<06:58,  1.14it/s]  5%|▌         | 25/500 [00:20<04:59,  1.58it/s]  5%|▌         | 27/500 [00:20<03:37,  2.17it/s]  6%|▌         | 29/500 [00:21<02:40,  2.93it/s]  6%|▌         | 31/500 [00:27<09:18,  1.19s/it]  7%|▋         | 33/500 [00:27<06:39,  1.17it/s]  7%|▋         | 35/500 [00:27<04:47,  1.62it/s]  7%|▋         | 37/500 [00:27<03:29,  2.21it/s]  8%|▊         | 39/500 [00:27<02:35,  2.97it/s]  8%|▊         | 41/500 [00:34<09:06,  1.19s/it]  9%|▊         | 43/500 [00:34<06:32,  1.17it/s]  9%|▉         | 45/500 [00:34<04:42,  1.61it/s]  9%|▉         | 47/500 [00:34<03:25,  2.20it/s] 10%|▉         | 49/500 [00:34<02:32,  2.97it/s] 10%|█         | 51/500 [00:41<08:51,  1.18s/it] 11%|█         | 53/500 [00:41<06:19,  1.18it/s] 11%|█         | 55/500 [00:41<04:33,  1.63it/s] 11%|█▏        | 57/500 [00:41<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:41<02:27,  2.98it/s] 12%|█▏        | 61/500 [00:48<08:54,  1.22s/it] 13%|█▎        | 63/500 [00:48<06:21,  1.15it/s] 13%|█▎        | 65/500 [00:48<04:34,  1.58it/s] 13%|█▎        | 67/500 [00:48<03:19,  2.17it/s] 14%|█▍        | 69/500 [00:48<02:27,  2.92it/s] 14%|█▍        | 71/500 [00:55<08:33,  1.20s/it] 15%|█▍        | 73/500 [00:55<06:06,  1.16it/s]Epoch:  1  	Training Loss: 0.04272831231355667
Test Loss:  66.18562316894531
Valid Loss:  66.97463989257812
Epoch:  2  	Training Loss: 60.94786071777344
Test Loss:  3623.798095703125
Valid Loss:  3632.345947265625
Epoch:  3  	Training Loss: 3616.40478515625
Test Loss:  6.752503871917725
Valid Loss:  6.787784099578857
Epoch:  4  	Training Loss: 6.624555587768555
Test Loss:  5.8680033683776855
Valid Loss:  5.900109767913818
Epoch:  5  	Training Loss: 5.747475624084473
Test Loss:  5.141706466674805
Valid Loss:  5.171095848083496
Epoch:  6  	Training Loss: 5.027956485748291
Test Loss:  4.53426456451416
Valid Loss:  4.561288833618164
Epoch:  7  	Training Loss: 4.426756858825684
Test Loss:  4.018490791320801
Valid Loss:  4.043422698974609
Epoch:  8  	Training Loss: 3.9167704582214355
Test Loss:  3.5750482082366943
Valid Loss:  3.598111152648926
Epoch:  9  	Training Loss: 3.4787306785583496
Test Loss:  3.1898560523986816
Valid Loss:  3.2112343311309814
Epoch:  10  	Training Loss: 3.0986108779907227
Test Loss:  2.8524301052093506
Valid Loss:  2.8722760677337646
Epoch:  11  	Training Loss: 2.765967845916748
Test Loss:  2.6906604766845703
Valid Loss:  2.7101192474365234
Epoch:  12  	Training Loss: 2.6033360958099365
Test Loss:  2.5184779167175293
Valid Loss:  2.537100076675415
Epoch:  13  	Training Loss: 2.433934211730957
Test Loss:  2.355954170227051
Valid Loss:  2.3737683296203613
Epoch:  14  	Training Loss: 2.274143695831299
Test Loss:  2.2026968002319336
Valid Loss:  2.2197322845458984
Epoch:  15  	Training Loss: 2.1235694885253906
Test Loss:  2.0583138465881348
Valid Loss:  2.0745983123779297
Epoch:  16  	Training Loss: 1.9818183183670044
Test Loss:  1.9224138259887695
Valid Loss:  1.937974214553833
Epoch:  17  	Training Loss: 1.848496913909912
Test Loss:  1.7946118116378784
Valid Loss:  1.8094760179519653
Epoch:  18  	Training Loss: 1.7232197523117065
Test Loss:  1.6745271682739258
Valid Loss:  1.6887198686599731
Epoch:  19  	Training Loss: 1.6056047677993774
Test Loss:  1.5617867708206177
Valid Loss:  1.5753341913223267
Epoch:  20  	Training Loss: 1.4952788352966309
Test Loss:  1.4560258388519287
Valid Loss:  1.46895170211792
Epoch:  21  	Training Loss: 1.3918747901916504
Test Loss:  1.3568894863128662
Valid Loss:  1.369218111038208
Epoch:  22  	Training Loss: 1.2950382232666016
Test Loss:  1.258273959159851
Valid Loss:  1.2699928283691406
Epoch:  23  	Training Loss: 1.1987979412078857
Test Loss:  1.167094349861145
Valid Loss:  1.1782339811325073
Epoch:  24  	Training Loss: 1.1099109649658203
Test Loss:  1.0827739238739014
Valid Loss:  1.09336256980896
Epoch:  25  	Training Loss: 1.0278019905090332
Test Loss:  1.0047829151153564
Valid Loss:  1.014847993850708
Epoch:  26  	Training Loss: 0.9519446492195129
Test Loss:  0.9326335787773132
Valid Loss:  0.9421999454498291
Epoch:  27  	Training Loss: 0.8818524479866028
Test Loss:  0.8658768534660339
Valid Loss:  0.8749691843986511
Epoch:  28  	Training Loss: 0.8170794248580933
Test Loss:  0.8040992021560669
Valid Loss:  0.8127399682998657
Epoch:  29  	Training Loss: 0.757213830947876
Test Loss:  0.7469191551208496
Valid Loss:  0.7551302313804626
Epoch:  30  	Training Loss: 0.7018767595291138
Test Loss:  0.6939867734909058
Valid Loss:  0.7017883658409119
Epoch:  31  	Training Loss: 0.6507198810577393
Test Loss:  0.6449775695800781
Valid Loss:  0.6523892879486084
Epoch:  32  	Training Loss: 0.6034213304519653
Test Loss:  0.599183201789856
Valid Loss:  0.6062203645706177
Epoch:  33  	Training Loss: 0.5592905282974243
Test Loss:  0.5568186044692993
Valid Loss:  0.5634989738464355
Epoch:  34  	Training Loss: 0.518526554107666
Test Loss:  0.5176181793212891
Valid Loss:  0.5239590406417847
Epoch:  35  	Training Loss: 0.4808664917945862
Test Loss:  0.48133864998817444
Valid Loss:  0.4873558580875397
Epoch:  36  	Training Loss: 0.446068674325943
Test Loss:  0.44775551557540894
Valid Loss:  0.4534645080566406
Epoch:  37  	Training Loss: 0.4139108955860138
Test Loss:  0.41666218638420105
Valid Loss:  0.4220772981643677
Epoch:  38  	Training Loss: 0.38418856263160706
Test Loss:  0.38786789774894714
Valid Loss:  0.3930031955242157
Epoch:  39  	Training Loss: 0.35671302676200867
Test Loss:  0.3611977696418762
Valid Loss:  0.3660660684108734
Epoch:  40  	Training Loss: 0.3313109278678894
Test Loss:  0.33649009466171265
Valid Loss:  0.3411039113998413
Epoch:  41  	Training Loss: 0.30782270431518555
Test Loss:  0.31359586119651794
Valid Loss:  0.31796711683273315
Epoch:  42  	Training Loss: 0.2861011326313019
Test Loss:  0.29263702034950256
Valid Loss:  0.29677945375442505
Epoch:  43  	Training Loss: 0.2662603259086609
Test Loss:  0.273155152797699
Valid Loss:  0.2770788073539734
Epoch:  44  	Training Loss: 0.24785543978214264
Test Loss:  0.25504612922668457
Valid Loss:  0.2587606906890869
Epoch:  45  	Training Loss: 0.23078377544879913
Test Loss:  0.23821336030960083
Valid Loss:  0.24172794818878174
Epoch:  46  	Training Loss: 0.21494989097118378
Test Loss:  0.2225666642189026
Valid Loss:  0.2258901298046112
Epoch:  47  	Training Loss: 0.20026497542858124
Test Loss:  0.20802217721939087
Valid Loss:  0.21116286516189575
Epoch:  48  	Training Loss: 0.18664637207984924
Test Loss:  0.1945018768310547
Valid Loss:  0.1974678784608841
Epoch:  49  	Training Loss: 0.17401725053787231
Test Loss:  0.18193325400352478
Valid Loss:  0.18473228812217712
Epoch:  50  	Training Loss: 0.1623062789440155
Test Loss:  0.17024895548820496
Valid Loss:  0.17288827896118164
Epoch:  51  	Training Loss: 0.15144716203212738
Test Loss:  0.1593860238790512
Valid Loss:  0.1618727594614029
Epoch:  52  	Training Loss: 0.14137819409370422
Test Loss:  0.1492520272731781
Valid Loss:  0.151592418551445
Epoch:  53  	Training Loss: 0.1320091187953949
Test Loss:  0.13983678817749023
Valid Loss:  0.1420373171567917
Epoch:  54  	Training Loss: 0.12332920730113983
Test Loss:  0.13108810782432556
Valid Loss:  0.1331550031900406
Epoch:  55  	Training Loss: 0.11528744548559189
Test Loss:  0.12295769900083542
Valid Loss:  0.12489695101976395
Epoch:  56  	Training Loss: 0.10783649981021881
Test Loss:  0.11540080606937408
Valid Loss:  0.11721807718276978
Epoch:  57  	Training Loss: 0.10093266516923904
Test Loss:  0.10837586224079132
Valid Loss:  0.11007657647132874
Epoch:  58  	Training Loss: 0.09453535079956055
Test Loss:  0.10184440016746521
Valid Loss:  0.10343378782272339
Epoch:  59  	Training Loss: 0.08860703557729721
Test Loss:  0.09577082842588425
Valid Loss:  0.09725380688905716
Epoch:  60  	Training Loss: 0.08311298489570618
Test Loss:  0.09012201428413391
Valid Loss:  0.09150335192680359
Epoch:  61  	Training Loss: 0.07802101969718933
Test Loss:  0.08486731350421906
Valid Loss:  0.08615152537822723
Epoch:  62  	Training Loss: 0.07330131530761719
Test Loss:  0.07997122406959534
Valid Loss:  0.08116258680820465
Epoch:  63  	Training Loss: 0.0689208135008812
Test Loss:  0.07541050016880035
Valid Loss:  0.07651309669017792
Epoch:  64  	Training Loss: 0.06485580652952194
Test Loss:  0.07116182148456573
Valid Loss:  0.07217954099178314
Epoch:  65  	Training Loss: 0.06108364835381508
Test Loss:  0.06720344722270966
Valid Loss:  0.06814002990722656
Epoch:  66  	Training Loss: 0.05758330225944519
Test Loss:  0.06351515650749207
Valid Loss:  0.06437418609857559
Epoch:  67  	Training Loss: 0.05433518439531326
Test Loss:  0.060078058391809464
Valid Loss:  0.06086297333240509
Epoch:  68  	Training Loss: 0.05132107436656952
Test Loss:  0.05687462165951729
Valid Loss:  0.05758871138095856
Epoch:  69  	Training Loss: 0.04852403700351715
Test Loss:  0.05388850346207619
Valid Loss:  0.05453493446111679
Epoch:  70  	Training Loss: 0.04592834785580635
Test Loss:  0.05110448598861694
Valid Loss:  0.05168628692626953
Epoch:  71  	Training Loss: 0.04351936653256416
Test Loss:  0.0485084131360054
Valid Loss:  0.04902847856283188
Epoch:  72  	Training Loss: 0.0412835031747818
Test Loss:  0.04609990864992142
Valid Loss:  0.04656144604086876
Epoch:  73  	Training Loss: 0.03921925276517868
Test Loss:  0.04385102912783623
Valid Loss:  0.04425664246082306
Epoch:  74  	Training Loss: 0.03730115666985512
Test Loss:  0.04175080731511116
Valid Loss:  0.04213748499751091
 15%|█▌        | 75/500 [00:55<04:23,  1.61it/s] 15%|█▌        | 77/500 [00:55<03:12,  2.20it/s] 16%|█▌        | 79/500 [00:55<02:21,  2.96it/s] 16%|█▌        | 81/500 [01:02<08:19,  1.19s/it] 17%|█▋        | 83/500 [01:02<05:57,  1.17it/s] 17%|█▋        | 85/500 [01:02<04:17,  1.61it/s] 17%|█▋        | 87/500 [01:02<03:07,  2.20it/s] 18%|█▊        | 89/500 [01:02<02:18,  2.97it/s] 18%|█▊        | 91/500 [01:09<08:11,  1.20s/it] 19%|█▊        | 93/500 [01:09<05:51,  1.16it/s] 19%|█▉        | 95/500 [01:09<04:12,  1.60it/s] 19%|█▉        | 97/500 [01:09<03:04,  2.19it/s] 20%|█▉        | 99/500 [01:09<02:16,  2.95it/s] 20%|██        | 101/500 [01:15<07:53,  1.19s/it] 21%|██        | 103/500 [01:16<05:38,  1.17it/s] 21%|██        | 105/500 [01:16<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:16<02:59,  2.19it/s] 22%|██▏       | 109/500 [01:16<02:14,  2.91it/s] 22%|██▏       | 111/500 [01:22<07:50,  1.21s/it] 23%|██▎       | 113/500 [01:23<05:36,  1.15it/s] 23%|██▎       | 115/500 [01:23<04:01,  1.59it/s] 23%|██▎       | 117/500 [01:23<02:56,  2.17it/s] 24%|██▍       | 119/500 [01:23<02:10,  2.93it/s] 24%|██▍       | 121/500 [01:29<07:35,  1.20s/it] 25%|██▍       | 123/500 [01:30<05:25,  1.16it/s] 25%|██▌       | 125/500 [01:30<03:54,  1.60it/s] 25%|██▌       | 127/500 [01:30<02:50,  2.18it/s] 26%|██▌       | 129/500 [01:30<02:06,  2.93it/s] 26%|██▌       | 131/500 [01:37<07:28,  1.21s/it] 27%|██▋       | 133/500 [01:37<05:19,  1.15it/s] 27%|██▋       | 135/500 [01:37<03:49,  1.59it/s] 27%|██▋       | 137/500 [01:37<02:48,  2.16it/s] 28%|██▊       | 139/500 [01:37<02:04,  2.91it/s] 28%|██▊       | 141/500 [01:43<07:06,  1.19s/it] 29%|██▊       | 143/500 [01:44<05:04,  1.17it/s] 29%|██▉       | 145/500 [01:44<03:38,  1.62it/s]Epoch:  75  	Training Loss: 0.03555414453148842
Test Loss:  0.03989391028881073
Valid Loss:  0.04036363214254379
Epoch:  76  	Training Loss: 0.03406393900513649
Test Loss:  0.03837689012289047
Valid Loss:  0.03889966383576393
Epoch:  77  	Training Loss: 0.03281254321336746
Test Loss:  0.037292227149009705
Valid Loss:  0.0377001091837883
Epoch:  78  	Training Loss: 0.03182270750403404
Test Loss:  0.03649699315428734
Valid Loss:  0.036712758243083954
Epoch:  79  	Training Loss: 0.03102203831076622
Test Loss:  0.03584694117307663
Valid Loss:  0.03592313453555107
Epoch:  80  	Training Loss: 0.030345134437084198
Test Loss:  0.035373255610466
Valid Loss:  0.0353287011384964
Epoch:  81  	Training Loss: 0.029792118817567825
Test Loss:  0.034970153123140335
Valid Loss:  0.03487173467874527
Epoch:  82  	Training Loss: 0.02934960648417473
Test Loss:  0.03465769812464714
Valid Loss:  0.03454270958900452
Epoch:  83  	Training Loss: 0.0290465597063303
Test Loss:  0.03441133350133896
Valid Loss:  0.03428614139556885
Epoch:  84  	Training Loss: 0.028820063918828964
Test Loss:  0.03420475497841835
Valid Loss:  0.03406985104084015
Epoch:  85  	Training Loss: 0.028626415878534317
Test Loss:  0.03403829038143158
Valid Loss:  0.033892400562763214
Epoch:  86  	Training Loss: 0.02847879007458687
Test Loss:  0.03389942646026611
Valid Loss:  0.03376486152410507
Epoch:  87  	Training Loss: 0.02836158499121666
Test Loss:  0.03378197178244591
Valid Loss:  0.03365767374634743
Epoch:  88  	Training Loss: 0.028258226811885834
Test Loss:  0.033690378069877625
Valid Loss:  0.033580608665943146
Epoch:  89  	Training Loss: 0.02818726934492588
Test Loss:  0.033622726798057556
Valid Loss:  0.033526789397001266
Epoch:  90  	Training Loss: 0.028138654306530952
Test Loss:  0.03355952352285385
Valid Loss:  0.033477794378995895
Epoch:  91  	Training Loss: 0.0280973669141531
Test Loss:  0.033505506813526154
Valid Loss:  0.03343511372804642
Epoch:  92  	Training Loss: 0.02806331031024456
Test Loss:  0.0334508940577507
Valid Loss:  0.033387165516614914
Epoch:  93  	Training Loss: 0.028026634827256203
Test Loss:  0.03340486064553261
Valid Loss:  0.033340513706207275
Epoch:  94  	Training Loss: 0.02799457311630249
Test Loss:  0.03336722031235695
Valid Loss:  0.03330092504620552
Epoch:  95  	Training Loss: 0.02796797640621662
Test Loss:  0.03333438187837601
Valid Loss:  0.0332641527056694
Epoch:  96  	Training Loss: 0.027943264693021774
Test Loss:  0.033302225172519684
Valid Loss:  0.03323063999414444
Epoch:  97  	Training Loss: 0.027919664978981018
Test Loss:  0.03327181935310364
Valid Loss:  0.0331990048289299
Epoch:  98  	Training Loss: 0.02789744734764099
Test Loss:  0.03324199840426445
Valid Loss:  0.033170249313116074
Epoch:  99  	Training Loss: 0.027875855565071106
Test Loss:  0.033214107155799866
Valid Loss:  0.033143334090709686
Epoch:  100  	Training Loss: 0.027856597676873207
Test Loss:  0.03319038823246956
Valid Loss:  0.03311882168054581
Epoch:  101  	Training Loss: 0.027839113026857376
Test Loss:  0.03316785767674446
Valid Loss:  0.033095624297857285
Epoch:  102  	Training Loss: 0.027822712436318398
Test Loss:  0.03315260261297226
Valid Loss:  0.03307821601629257
Epoch:  103  	Training Loss: 0.027811182662844658
Test Loss:  0.03313913941383362
Valid Loss:  0.03306381776928902
Epoch:  104  	Training Loss: 0.027801014482975006
Test Loss:  0.0331270731985569
Valid Loss:  0.03305000811815262
Epoch:  105  	Training Loss: 0.027790958061814308
Test Loss:  0.03311512991786003
Valid Loss:  0.03303702175617218
Epoch:  106  	Training Loss: 0.02778100222349167
Test Loss:  0.033103324472904205
Valid Loss:  0.03302549570798874
Epoch:  107  	Training Loss: 0.02777114510536194
Test Loss:  0.03309164196252823
Valid Loss:  0.0330146886408329
Epoch:  108  	Training Loss: 0.027761384844779968
Test Loss:  0.033080071210861206
Valid Loss:  0.03300398588180542
Epoch:  109  	Training Loss: 0.027751833200454712
Test Loss:  0.033069077879190445
Valid Loss:  0.03299381956458092
Epoch:  110  	Training Loss: 0.027742793783545494
Test Loss:  0.03305817395448685
Valid Loss:  0.03298373520374298
Epoch:  111  	Training Loss: 0.02773384563624859
Test Loss:  0.03304780274629593
Valid Loss:  0.03297413885593414
Epoch:  112  	Training Loss: 0.02772558480501175
Test Loss:  0.03303917497396469
Valid Loss:  0.032966263592243195
Epoch:  113  	Training Loss: 0.027718523517251015
Test Loss:  0.03303107991814613
Valid Loss:  0.032958440482616425
Epoch:  114  	Training Loss: 0.027711492031812668
Test Loss:  0.03302324563264847
Valid Loss:  0.032950662076473236
Epoch:  115  	Training Loss: 0.02770448476076126
Test Loss:  0.03301544487476349
Valid Loss:  0.03294292464852333
Epoch:  116  	Training Loss: 0.027697496116161346
Test Loss:  0.03300769254565239
Valid Loss:  0.032935239374637604
Epoch:  117  	Training Loss: 0.02769053913652897
Test Loss:  0.03299997001886368
Valid Loss:  0.03292759507894516
Epoch:  118  	Training Loss: 0.027683602645993233
Test Loss:  0.03299228101968765
Valid Loss:  0.0329199880361557
Epoch:  119  	Training Loss: 0.02767672762274742
Test Loss:  0.03298492729663849
Valid Loss:  0.03291301429271698
Epoch:  120  	Training Loss: 0.027670111507177353
Test Loss:  0.032977595925331116
Valid Loss:  0.032906368374824524
Epoch:  121  	Training Loss: 0.027663588523864746
Test Loss:  0.032970573753118515
Valid Loss:  0.032899998128414154
Epoch:  122  	Training Loss: 0.02765721082687378
Test Loss:  0.03296405076980591
Valid Loss:  0.032894134521484375
Epoch:  123  	Training Loss: 0.027651309967041016
Test Loss:  0.03295784071087837
Valid Loss:  0.03288854658603668
Epoch:  124  	Training Loss: 0.02764550969004631
Test Loss:  0.03295163810253143
Valid Loss:  0.032882966101169586
Epoch:  125  	Training Loss: 0.027639713138341904
Test Loss:  0.03294543921947479
Valid Loss:  0.032877400517463684
Epoch:  126  	Training Loss: 0.027633922174572945
Test Loss:  0.03293924778699875
Valid Loss:  0.03287183493375778
Epoch:  127  	Training Loss: 0.027628131210803986
Test Loss:  0.0329330638051033
Valid Loss:  0.03286626562476158
Epoch:  128  	Training Loss: 0.027622342109680176
Test Loss:  0.032926883548498154
Valid Loss:  0.03286071494221687
Epoch:  129  	Training Loss: 0.027616560459136963
Test Loss:  0.032920707017183304
Valid Loss:  0.032855160534381866
Epoch:  130  	Training Loss: 0.0276107769459486
Test Loss:  0.03291453793644905
Valid Loss:  0.03284960985183716
Epoch:  131  	Training Loss: 0.027604997158050537
Test Loss:  0.03290838003158569
Valid Loss:  0.032844074070453644
Epoch:  132  	Training Loss: 0.02759922668337822
Test Loss:  0.03290338069200516
Valid Loss:  0.03283972293138504
Epoch:  133  	Training Loss: 0.02759438380599022
Test Loss:  0.03289838880300522
Valid Loss:  0.03283537179231644
Epoch:  134  	Training Loss: 0.027589548379182816
Test Loss:  0.03289340063929558
Valid Loss:  0.03283103182911873
Epoch:  135  	Training Loss: 0.02758471667766571
Test Loss:  0.03288841247558594
Valid Loss:  0.03282669186592102
Epoch:  136  	Training Loss: 0.027579888701438904
Test Loss:  0.03288343921303749
Valid Loss:  0.03282235935330391
Epoch:  137  	Training Loss: 0.027575060725212097
Test Loss:  0.032878465950489044
Valid Loss:  0.0328180268406868
Epoch:  138  	Training Loss: 0.027570286765694618
Test Loss:  0.032873764634132385
Valid Loss:  0.032813943922519684
Epoch:  139  	Training Loss: 0.027565553784370422
Test Loss:  0.03286905959248543
Valid Loss:  0.03280985727906227
Epoch:  140  	Training Loss: 0.027560822665691376
Test Loss:  0.03286435827612877
Valid Loss:  0.03280576318502426
Epoch:  141  	Training Loss: 0.027556097134947777
Test Loss:  0.03285965323448181
Valid Loss:  0.03280168026685715
Epoch:  142  	Training Loss: 0.027551375329494476
Test Loss:  0.03285419940948486
Valid Loss:  0.032796815037727356
Epoch:  143  	Training Loss: 0.02754604071378708
Test Loss:  0.032848745584487915
Valid Loss:  0.03279195725917816
Epoch:  144  	Training Loss: 0.027540717273950577
Test Loss:  0.03284328430891037
Valid Loss:  0.03278709575533867
Epoch:  145  	Training Loss: 0.027535388246178627
Test Loss:  0.03283783048391342
Valid Loss:  0.03278222680091858
Epoch:  146  	Training Loss: 0.027530094608664513
 29%|██▉       | 147/500 [01:44<02:39,  2.21it/s] 30%|██▉       | 149/500 [01:44<01:58,  2.96it/s] 30%|███       | 151/500 [01:50<06:50,  1.18s/it] 31%|███       | 153/500 [01:50<04:53,  1.18it/s] 31%|███       | 155/500 [01:50<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:51<02:33,  2.23it/s] 32%|███▏      | 159/500 [01:51<01:54,  2.99it/s] 32%|███▏      | 161/500 [01:57<06:49,  1.21s/it] 33%|███▎      | 163/500 [01:57<04:53,  1.15it/s] 33%|███▎      | 165/500 [01:58<03:31,  1.59it/s] 33%|███▎      | 167/500 [01:58<02:33,  2.17it/s] 34%|███▍      | 169/500 [01:58<01:53,  2.91it/s] 34%|███▍      | 171/500 [02:04<06:34,  1.20s/it] 35%|███▍      | 173/500 [02:04<04:43,  1.16it/s] 35%|███▌      | 175/500 [02:05<03:25,  1.58it/s] 35%|███▌      | 177/500 [02:05<02:31,  2.14it/s] 36%|███▌      | 179/500 [02:05<01:53,  2.83it/s] 36%|███▌      | 181/500 [02:11<06:29,  1.22s/it] 37%|███▋      | 183/500 [02:12<04:37,  1.14it/s] 37%|███▋      | 185/500 [02:12<03:18,  1.58it/s] 37%|███▋      | 187/500 [02:12<02:24,  2.16it/s] 38%|███▊      | 189/500 [02:12<01:46,  2.92it/s] 38%|███▊      | 191/500 [02:18<06:09,  1.20s/it] 39%|███▊      | 193/500 [02:18<04:25,  1.16it/s] 39%|███▉      | 195/500 [02:19<03:11,  1.60it/s] 39%|███▉      | 197/500 [02:19<02:18,  2.18it/s] 40%|███▉      | 199/500 [02:19<01:42,  2.94it/s] 40%|████      | 201/500 [02:25<06:01,  1.21s/it] 41%|████      | 203/500 [02:26<04:19,  1.15it/s] 41%|████      | 205/500 [02:26<03:07,  1.57it/s] 41%|████▏     | 207/500 [02:26<02:16,  2.15it/s] 42%|████▏     | 209/500 [02:26<01:40,  2.89it/s] 42%|████▏     | 211/500 [02:32<05:47,  1.20s/it] 43%|████▎     | 213/500 [02:33<04:07,  1.16it/s] 43%|████▎     | 215/500 [02:33<02:57,  1.60it/s]Test Loss:  0.03283265233039856
Valid Loss:  0.03277762234210968
Epoch:  147  	Training Loss: 0.027524828910827637
Test Loss:  0.032827459275722504
Valid Loss:  0.03277300298213959
Epoch:  148  	Training Loss: 0.027519559487700462
Test Loss:  0.032822273671627045
Valid Loss:  0.032768379896879196
Epoch:  149  	Training Loss: 0.027514295652508736
Test Loss:  0.03281707316637039
Valid Loss:  0.03276374563574791
Epoch:  150  	Training Loss: 0.027509033679962158
Test Loss:  0.03281187638640404
Valid Loss:  0.03275911882519722
Epoch:  151  	Training Loss: 0.027503781020641327
Test Loss:  0.03280666470527649
Valid Loss:  0.032754480838775635
Epoch:  152  	Training Loss: 0.027498532086610794
Test Loss:  0.03280145302414894
Valid Loss:  0.03274983912706375
Epoch:  153  	Training Loss: 0.027493271976709366
Test Loss:  0.03279624134302139
Valid Loss:  0.03274519741535187
Epoch:  154  	Training Loss: 0.027488015592098236
Test Loss:  0.03279101848602295
Valid Loss:  0.032740551978349686
Epoch:  155  	Training Loss: 0.027482766658067703
Test Loss:  0.032785799354314804
Valid Loss:  0.03273589909076691
Epoch:  156  	Training Loss: 0.02747751958668232
Test Loss:  0.03278057277202606
Valid Loss:  0.03273124247789383
Epoch:  157  	Training Loss: 0.027472272515296936
Test Loss:  0.03277533873915672
Valid Loss:  0.032726578414440155
Epoch:  158  	Training Loss: 0.0274670347571373
Test Loss:  0.032770104706287384
Valid Loss:  0.03272191807627678
Epoch:  159  	Training Loss: 0.02746179699897766
Test Loss:  0.032764874398708344
Valid Loss:  0.032717254012823105
Epoch:  160  	Training Loss: 0.02745656482875347
Test Loss:  0.03275962918996811
Valid Loss:  0.032712578773498535
Epoch:  161  	Training Loss: 0.02745133265852928
Test Loss:  0.03275438770651817
Valid Loss:  0.032707907259464264
Epoch:  162  	Training Loss: 0.02744610607624054
Test Loss:  0.03274925425648689
Valid Loss:  0.03270334377884865
Epoch:  163  	Training Loss: 0.027440980076789856
Test Loss:  0.032744117081165314
Valid Loss:  0.032698772847652435
Epoch:  164  	Training Loss: 0.02743585780262947
Test Loss:  0.032738976180553436
Valid Loss:  0.03269420191645622
Epoch:  165  	Training Loss: 0.027430741116404533
Test Loss:  0.03273383527994156
Valid Loss:  0.03268963471055031
Epoch:  166  	Training Loss: 0.027425626292824745
Test Loss:  0.03272871673107147
Valid Loss:  0.0326850563287735
Epoch:  167  	Training Loss: 0.027420517057180405
Test Loss:  0.03272365778684616
Valid Loss:  0.03268047422170639
Epoch:  168  	Training Loss: 0.027415405958890915
Test Loss:  0.03271859511733055
Valid Loss:  0.032675888389348984
Epoch:  169  	Training Loss: 0.027410298585891724
Test Loss:  0.03271353244781494
Valid Loss:  0.03267130255699158
Epoch:  170  	Training Loss: 0.02740519493818283
Test Loss:  0.03270846605300903
Valid Loss:  0.032666709274053574
Epoch:  171  	Training Loss: 0.027400091290473938
Test Loss:  0.03270340338349342
Valid Loss:  0.03266211971640587
Epoch:  172  	Training Loss: 0.027394989505410194
Test Loss:  0.03269834816455841
Valid Loss:  0.032657526433467865
Epoch:  173  	Training Loss: 0.027389919385313988
Test Loss:  0.032693296670913696
Valid Loss:  0.03265292942523956
Epoch:  174  	Training Loss: 0.027384871616959572
Test Loss:  0.03268842771649361
Valid Loss:  0.032648585736751556
Epoch:  175  	Training Loss: 0.02737983874976635
Test Loss:  0.03268355131149292
Valid Loss:  0.032644230872392654
Epoch:  176  	Training Loss: 0.027374807745218277
Test Loss:  0.03267867490649223
Valid Loss:  0.03263987600803375
Epoch:  177  	Training Loss: 0.027369778603315353
Test Loss:  0.03267379477620125
Valid Loss:  0.032635509967803955
Epoch:  178  	Training Loss: 0.027364755049347878
Test Loss:  0.03266891837120056
Valid Loss:  0.03263114020228386
Epoch:  179  	Training Loss: 0.027359742671251297
Test Loss:  0.03266402706503868
Valid Loss:  0.03262675553560257
Epoch:  180  	Training Loss: 0.02735472470521927
Test Loss:  0.0326591357588768
Valid Loss:  0.03262237459421158
Epoch:  181  	Training Loss: 0.027349714189767838
Test Loss:  0.03265424445271492
Valid Loss:  0.03261798620223999
Epoch:  182  	Training Loss: 0.027344707399606705
Test Loss:  0.032649360597133636
Valid Loss:  0.0326136089861393
Epoch:  183  	Training Loss: 0.027339693158864975
Test Loss:  0.032644473016262054
Valid Loss:  0.032609228044748306
Epoch:  184  	Training Loss: 0.027334686368703842
Test Loss:  0.03263958916068077
Valid Loss:  0.032604850828647614
Epoch:  185  	Training Loss: 0.027329683303833008
Test Loss:  0.03263470157980919
Valid Loss:  0.03260045871138573
Epoch:  186  	Training Loss: 0.027324680238962173
Test Loss:  0.03262980654835701
Valid Loss:  0.03259607031941414
Epoch:  187  	Training Loss: 0.027319684624671936
Test Loss:  0.03262491151690483
Valid Loss:  0.03259166702628136
Epoch:  188  	Training Loss: 0.0273146890103817
Test Loss:  0.032620012760162354
Valid Loss:  0.032587263733148575
Epoch:  189  	Training Loss: 0.027309700846672058
Test Loss:  0.032615114003419876
Valid Loss:  0.032582852989435196
Epoch:  190  	Training Loss: 0.027304712682962418
Test Loss:  0.0326102115213871
Valid Loss:  0.03257844224572182
Epoch:  191  	Training Loss: 0.027299730107188225
Test Loss:  0.03260530158877373
Valid Loss:  0.032574012875556946
Epoch:  192  	Training Loss: 0.027294743806123734
Test Loss:  0.03260044753551483
Valid Loss:  0.03256964311003685
Epoch:  193  	Training Loss: 0.027289826422929764
Test Loss:  0.03259558975696564
Valid Loss:  0.03256526589393616
Epoch:  194  	Training Loss: 0.027284901589155197
Test Loss:  0.03259073197841644
Valid Loss:  0.032560884952545166
Epoch:  195  	Training Loss: 0.027279982343316078
Test Loss:  0.03258587419986725
Valid Loss:  0.03255649656057358
Epoch:  196  	Training Loss: 0.027275066822767258
Test Loss:  0.032581012696027756
Valid Loss:  0.03255210071802139
Epoch:  197  	Training Loss: 0.027270153164863586
Test Loss:  0.032576147466897964
Valid Loss:  0.032547708600759506
Epoch:  198  	Training Loss: 0.027265243232250214
Test Loss:  0.032571278512477875
Valid Loss:  0.03254330903291702
Epoch:  199  	Training Loss: 0.02726033888757229
Test Loss:  0.032566409558057785
Valid Loss:  0.032538898289203644
Epoch:  200  	Training Loss: 0.027255430817604065
Test Loss:  0.0325615331530571
Valid Loss:  0.032534487545490265
Epoch:  201  	Training Loss: 0.02725052833557129
Test Loss:  0.03255666047334671
Valid Loss:  0.032530076801776886
Epoch:  202  	Training Loss: 0.02724562957882881
Test Loss:  0.032551709562540054
Valid Loss:  0.032525595277547836
Epoch:  203  	Training Loss: 0.027240661904215813
Test Loss:  0.0325467623770237
Valid Loss:  0.03252110257744789
Epoch:  204  	Training Loss: 0.027235696092247963
Test Loss:  0.03254181146621704
Valid Loss:  0.03251660615205765
Epoch:  205  	Training Loss: 0.027230732142925262
Test Loss:  0.03253685310482979
Valid Loss:  0.0325121134519577
Epoch:  206  	Training Loss: 0.02722577378153801
Test Loss:  0.03253190219402313
Valid Loss:  0.03250760957598686
Epoch:  207  	Training Loss: 0.027220815420150757
Test Loss:  0.03252694755792618
Valid Loss:  0.03250311315059662
Epoch:  208  	Training Loss: 0.027215858921408653
Test Loss:  0.032521989196538925
Valid Loss:  0.03249860554933548
Epoch:  209  	Training Loss: 0.027210906147956848
Test Loss:  0.03251703083515167
Valid Loss:  0.03249409422278404
Epoch:  210  	Training Loss: 0.027205955237150192
Test Loss:  0.03251206874847412
Valid Loss:  0.032489582896232605
Epoch:  211  	Training Loss: 0.027201004326343536
Test Loss:  0.03250710666179657
Valid Loss:  0.03248506784439087
Epoch:  212  	Training Loss: 0.027196059003472328
Test Loss:  0.03250247240066528
Valid Loss:  0.0324808768928051
Epoch:  213  	Training Loss: 0.02719140611588955
Test Loss:  0.032497838139534
Valid Loss:  0.03247668594121933
Epoch:  214  	Training Loss: 0.02718675695359707
Test Loss:  0.03249320760369301
Valid Loss:  0.03247249126434326
Epoch:  215  	Training Loss: 0.02718212828040123
Test Loss:  0.03248879313468933
Valid Loss:  0.03246857970952988
Epoch:  216  	Training Loss: 0.02717752754688263
Test Loss:  0.032484374940395355
Valid Loss:  0.0324646532535553
Epoch:  217  	Training Loss: 0.027172932401299477
Test Loss:   43%|████▎     | 217/500 [02:33<02:09,  2.19it/s] 44%|████▍     | 219/500 [02:33<01:35,  2.95it/s] 44%|████▍     | 221/500 [02:39<05:28,  1.18s/it] 45%|████▍     | 223/500 [02:39<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:39<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:40<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:40<01:30,  2.99it/s] 46%|████▌     | 231/500 [02:46<05:20,  1.19s/it] 47%|████▋     | 233/500 [02:46<03:48,  1.17it/s] 47%|████▋     | 235/500 [02:46<02:43,  1.62it/s] 47%|████▋     | 237/500 [02:47<01:59,  2.20it/s] 48%|████▊     | 239/500 [02:47<01:28,  2.96it/s] 48%|████▊     | 241/500 [02:53<05:11,  1.20s/it] 49%|████▊     | 243/500 [02:53<03:43,  1.15it/s] 49%|████▉     | 245/500 [02:53<02:41,  1.58it/s] 49%|████▉     | 247/500 [02:54<01:58,  2.13it/s] 50%|████▉     | 249/500 [02:54<01:28,  2.82it/s] 50%|█████     | 251/500 [03:00<05:00,  1.21s/it] 51%|█████     | 253/500 [03:00<03:33,  1.16it/s] 51%|█████     | 255/500 [03:00<02:33,  1.60it/s] 51%|█████▏    | 257/500 [03:01<01:51,  2.18it/s] 52%|█████▏    | 259/500 [03:01<01:23,  2.88it/s] 52%|█████▏    | 261/500 [03:07<04:46,  1.20s/it] 53%|█████▎    | 263/500 [03:07<03:24,  1.16it/s] 53%|█████▎    | 265/500 [03:07<02:26,  1.60it/s] 53%|█████▎    | 267/500 [03:08<01:46,  2.19it/s] 54%|█████▍    | 269/500 [03:08<01:18,  2.94it/s] 54%|█████▍    | 271/500 [03:14<04:34,  1.20s/it] 54%|█████▍    | 272/500 [03:14<03:49,  1.00s/it] 55%|█████▍    | 274/500 [03:14<02:37,  1.43it/s] 55%|█████▌    | 276/500 [03:15<01:51,  2.00it/s] 56%|█████▌    | 278/500 [03:15<01:22,  2.71it/s] 56%|█████▌    | 280/500 [03:15<01:02,  3.53it/s] 56%|█████▋    | 282/500 [03:21<04:15,  1.17s/it] 57%|█████▋    | 284/500 [03:21<03:00,  1.20it/s] 57%|█████▋    | 286/500 [03:22<02:08,  1.66it/s]0.03247995674610138
Valid Loss:  0.032460734248161316
Epoch:  218  	Training Loss: 0.02716834470629692
Test Loss:  0.03247552365064621
Valid Loss:  0.03245679289102554
Epoch:  219  	Training Loss: 0.027163755148649216
Test Loss:  0.03247108310461044
Valid Loss:  0.032452844083309174
Epoch:  220  	Training Loss: 0.02715916931629181
Test Loss:  0.032466646283864975
Valid Loss:  0.032448895275592804
Epoch:  221  	Training Loss: 0.027154583483934402
Test Loss:  0.03246220946311951
Valid Loss:  0.03244493529200554
Epoch:  222  	Training Loss: 0.02715000882744789
Test Loss:  0.03245750069618225
Valid Loss:  0.03244071826338768
Epoch:  223  	Training Loss: 0.027145210653543472
Test Loss:  0.032452791929244995
Valid Loss:  0.032436490058898926
Epoch:  224  	Training Loss: 0.027140410616993904
Test Loss:  0.03244808316230774
Valid Loss:  0.032432254403829575
Epoch:  225  	Training Loss: 0.027135618031024933
Test Loss:  0.03244336321949959
Valid Loss:  0.032428015023469925
Epoch:  226  	Training Loss: 0.027130823582410812
Test Loss:  0.032438650727272034
Valid Loss:  0.03242376819252968
Epoch:  227  	Training Loss: 0.02712603658437729
Test Loss:  0.032433923333883286
Valid Loss:  0.03241952136158943
Epoch:  228  	Training Loss: 0.027121255174279213
Test Loss:  0.032429199665784836
Valid Loss:  0.03241526335477829
Epoch:  229  	Training Loss: 0.027116475626826286
Test Loss:  0.032424475997686386
Valid Loss:  0.03241100534796715
Epoch:  230  	Training Loss: 0.027111701667308807
Test Loss:  0.03241974487900734
Valid Loss:  0.03240673616528511
Epoch:  231  	Training Loss: 0.02710692398250103
Test Loss:  0.032415010035037994
Valid Loss:  0.03240246698260307
Epoch:  232  	Training Loss: 0.027102157473564148
Test Loss:  0.03241054713726044
Valid Loss:  0.03239846229553223
Epoch:  233  	Training Loss: 0.027097607031464577
Test Loss:  0.032406073063611984
Valid Loss:  0.032394446432590485
Epoch:  234  	Training Loss: 0.027093058452010155
Test Loss:  0.03240159526467323
Valid Loss:  0.03239043056964874
Epoch:  235  	Training Loss: 0.02708851359784603
Test Loss:  0.03239711374044418
Valid Loss:  0.032386407256126404
Epoch:  236  	Training Loss: 0.027083974331617355
Test Loss:  0.03239263594150543
Valid Loss:  0.03238237649202347
Epoch:  237  	Training Loss: 0.027079429477453232
Test Loss:  0.032388150691986084
Valid Loss:  0.03237834572792053
Epoch:  238  	Training Loss: 0.027074893936514854
Test Loss:  0.032383669167757034
Valid Loss:  0.032374307513237
Epoch:  239  	Training Loss: 0.027070362120866776
Test Loss:  0.03237924724817276
Valid Loss:  0.03237026929855347
Epoch:  240  	Training Loss: 0.027065832167863846
Test Loss:  0.03237481787800789
Valid Loss:  0.03236622363328934
Epoch:  241  	Training Loss: 0.027061305940151215
Test Loss:  0.03237038850784302
Valid Loss:  0.03236217424273491
Epoch:  242  	Training Loss: 0.027056779712438583
Test Loss:  0.03236591815948486
Valid Loss:  0.032358068972826004
Epoch:  243  	Training Loss: 0.027052219957113266
Test Loss:  0.032361432909965515
Valid Loss:  0.0323539562523365
Epoch:  244  	Training Loss: 0.02704766020178795
Test Loss:  0.03235695883631706
Valid Loss:  0.0323498472571373
Epoch:  245  	Training Loss: 0.02704310230910778
Test Loss:  0.03235247731208801
Valid Loss:  0.0323457345366478
Epoch:  246  	Training Loss: 0.02703854814171791
Test Loss:  0.03234799951314926
Valid Loss:  0.032341618090867996
Epoch:  247  	Training Loss: 0.027034001424908638
Test Loss:  0.03234352171421051
Valid Loss:  0.032337501645088196
Epoch:  248  	Training Loss: 0.027029454708099365
Test Loss:  0.03233904391527176
Valid Loss:  0.0323333702981472
Epoch:  249  	Training Loss: 0.027024922892451286
Test Loss:  0.03233467414975166
Valid Loss:  0.0323294997215271
Epoch:  250  	Training Loss: 0.027020391076803207
Test Loss:  0.032330308109521866
Valid Loss:  0.0323256216943264
Epoch:  251  	Training Loss: 0.027015864849090576
Test Loss:  0.03232593834400177
Valid Loss:  0.032321736216545105
Epoch:  252  	Training Loss: 0.027011342346668243
Test Loss:  0.03232152760028839
Valid Loss:  0.03231779485940933
Epoch:  253  	Training Loss: 0.02700679376721382
Test Loss:  0.032317109405994415
Valid Loss:  0.03231384605169296
Epoch:  254  	Training Loss: 0.0270022414624691
Test Loss:  0.03231268748641014
Valid Loss:  0.032309889793395996
Epoch:  255  	Training Loss: 0.026997696608304977
Test Loss:  0.032308269292116165
Valid Loss:  0.03230592980980873
Epoch:  256  	Training Loss: 0.026993155479431152
Test Loss:  0.03230384364724159
Valid Loss:  0.03230195865035057
Epoch:  257  	Training Loss: 0.026988618075847626
Test Loss:  0.03229942545294762
Valid Loss:  0.03229798376560211
Epoch:  258  	Training Loss: 0.02698408253490925
Test Loss:  0.032294996082782745
Valid Loss:  0.03229399770498276
Epoch:  259  	Training Loss: 0.02697955258190632
Test Loss:  0.032290566712617874
Valid Loss:  0.03229000046849251
Epoch:  260  	Training Loss: 0.02697502076625824
Test Loss:  0.0322861410677433
Valid Loss:  0.03228600323200226
Epoch:  261  	Training Loss: 0.026970498263835907
Test Loss:  0.03228171169757843
Valid Loss:  0.03228199481964111
Epoch:  262  	Training Loss: 0.026965977624058723
Test Loss:  0.03227744251489639
Valid Loss:  0.0322781503200531
Epoch:  263  	Training Loss: 0.026961592957377434
Test Loss:  0.03227316588163376
Valid Loss:  0.03227429836988449
Epoch:  264  	Training Loss: 0.026957210153341293
Test Loss:  0.032268889248371124
Valid Loss:  0.032270435243844986
Epoch:  265  	Training Loss: 0.02695283479988575
Test Loss:  0.03226461634039879
Valid Loss:  0.03226656839251518
Epoch:  266  	Training Loss: 0.02694845385849476
Test Loss:  0.032260358333587646
Valid Loss:  0.032262690365314484
Epoch:  267  	Training Loss: 0.026944082230329514
Test Loss:  0.0322561115026474
Valid Loss:  0.03225880488753319
Epoch:  268  	Training Loss: 0.02693970687687397
Test Loss:  0.03225187212228775
Valid Loss:  0.032254915684461594
Epoch:  269  	Training Loss: 0.026935338973999023
Test Loss:  0.032247625291347504
Valid Loss:  0.0322510190308094
Epoch:  270  	Training Loss: 0.02693096734583378
Test Loss:  0.03224337846040726
Valid Loss:  0.032247111201286316
Epoch:  271  	Training Loss: 0.026926597580313683
Test Loss:  0.032239142805337906
Valid Loss:  0.03224320709705353
Epoch:  272  	Training Loss: 0.026922237128019333
Test Loss:  0.032234735786914825
Valid Loss:  0.03223913162946701
Epoch:  273  	Training Loss: 0.026917731389403343
Test Loss:  0.03223032504320145
Valid Loss:  0.0322350412607193
Epoch:  274  	Training Loss: 0.026913229376077652
Test Loss:  0.032225918024778366
Valid Loss:  0.03223095089197159
Epoch:  275  	Training Loss: 0.02690872922539711
Test Loss:  0.032221511006355286
Valid Loss:  0.03222685679793358
Epoch:  276  	Training Loss: 0.026904232800006866
Test Loss:  0.0322171114385128
Valid Loss:  0.03222275525331497
Epoch:  277  	Training Loss: 0.026899738237261772
Test Loss:  0.03221270442008972
Valid Loss:  0.03221864998340607
Epoch:  278  	Training Loss: 0.026895247399806976
Test Loss:  0.03220830112695694
Valid Loss:  0.03221454098820686
Epoch:  279  	Training Loss: 0.02689075656235218
Test Loss:  0.03220389783382416
Valid Loss:  0.03221042826771736
Epoch:  280  	Training Loss: 0.026886269450187683
Test Loss:  0.032199498265981674
Valid Loss:  0.03220631182193756
Epoch:  281  	Training Loss: 0.026881782338023186
Test Loss:  0.032195091247558594
Valid Loss:  0.032202187925577164
Epoch:  282  	Training Loss: 0.026877298951148987
Test Loss:  0.03219052776694298
Valid Loss:  0.03219788521528244
Epoch:  283  	Training Loss: 0.026872694492340088
Test Loss:  0.03218601644039154
Valid Loss:  0.0321938619017601
Epoch:  284  	Training Loss: 0.02686810865998268
Test Loss:  0.0321815088391304
Valid Loss:  0.03218984231352806
Epoch:  285  	Training Loss: 0.02686353027820587
Test Loss:  0.032176945358514786
Valid Loss:  0.03218551725149155
Epoch:  286  	Training Loss: 0.026858944445848465
Test Loss:  0.032172445207834244
Valid Loss:  0.03218148276209831
Epoch:  287  	Training Loss: 0.02685437723994255
Test Loss:  0.0321679413318634
Valid Loss:  0.032177433371543884
Epoch:  288  	Training Loss: 0.026849808171391487
Test Loss:  0.03216343745589256
 58%|█████▊    | 288/500 [03:22<01:33,  2.28it/s] 58%|█████▊    | 290/500 [03:22<01:08,  3.06it/s] 58%|█████▊    | 292/500 [03:28<04:07,  1.19s/it] 59%|█████▉    | 294/500 [03:28<02:55,  1.18it/s] 59%|█████▉    | 296/500 [03:28<02:05,  1.63it/s] 60%|█████▉    | 298/500 [03:29<01:31,  2.21it/s] 60%|██████    | 300/500 [03:29<01:07,  2.97it/s] 60%|██████    | 302/500 [03:35<03:56,  1.19s/it] 61%|██████    | 304/500 [03:35<02:47,  1.17it/s] 61%|██████    | 306/500 [03:35<01:59,  1.62it/s] 62%|██████▏   | 308/500 [03:35<01:26,  2.21it/s] 62%|██████▏   | 310/500 [03:36<01:04,  2.97it/s] 62%|██████▏   | 312/500 [03:42<03:43,  1.19s/it] 63%|██████▎   | 314/500 [03:42<02:40,  1.16it/s] 63%|██████▎   | 316/500 [03:42<01:55,  1.59it/s] 64%|██████▎   | 318/500 [03:43<01:24,  2.14it/s] 64%|██████▍   | 320/500 [03:43<01:03,  2.84it/s] 64%|██████▍   | 322/500 [03:49<03:35,  1.21s/it] 65%|██████▍   | 324/500 [03:49<02:32,  1.15it/s] 65%|██████▌   | 326/500 [03:49<01:49,  1.60it/s] 66%|██████▌   | 328/500 [03:49<01:18,  2.18it/s] 66%|██████▌   | 330/500 [03:50<00:57,  2.94it/s] 66%|██████▋   | 332/500 [03:56<03:19,  1.19s/it] 67%|██████▋   | 334/500 [03:56<02:21,  1.17it/s] 67%|██████▋   | 336/500 [03:56<01:41,  1.62it/s] 68%|██████▊   | 338/500 [03:56<01:13,  2.22it/s] 68%|██████▊   | 340/500 [03:56<00:53,  2.98it/s] 68%|██████▊   | 342/500 [04:03<03:08,  1.19s/it] 69%|██████▉   | 344/500 [04:03<02:13,  1.17it/s] 69%|██████▉   | 346/500 [04:03<01:34,  1.62it/s] 70%|██████▉   | 348/500 [04:03<01:08,  2.22it/s] 70%|███████   | 350/500 [04:03<00:50,  2.98it/s] 70%|███████   | 352/500 [04:10<02:56,  1.20s/it] 71%|███████   | 354/500 [04:10<02:04,  1.17it/s] 71%|███████   | 356/500 [04:10<01:28,  1.62it/s] 72%|███████▏  | 358/500 [04:10<01:04,  2.21it/s]Valid Loss:  0.032173383980989456
Epoch:  289  	Training Loss: 0.02684524469077587
Test Loss:  0.03215894103050232
Valid Loss:  0.03216932341456413
Epoch:  290  	Training Loss: 0.026840683072805405
Test Loss:  0.03215443342924118
Valid Loss:  0.032165247946977615
Epoch:  291  	Training Loss: 0.026836123317480087
Test Loss:  0.03214993327856064
Valid Loss:  0.0321611724793911
Epoch:  292  	Training Loss: 0.026831569150090218
Test Loss:  0.03214563429355621
Valid Loss:  0.03215726464986801
Epoch:  293  	Training Loss: 0.026827234774827957
Test Loss:  0.03214133530855179
Valid Loss:  0.032153353095054626
Epoch:  294  	Training Loss: 0.026822900399565697
Test Loss:  0.03213703632354736
Valid Loss:  0.03214943781495094
Epoch:  295  	Training Loss: 0.026818571612238884
Test Loss:  0.03213274106383324
Valid Loss:  0.03214551508426666
Epoch:  296  	Training Loss: 0.02681424841284752
Test Loss:  0.03212843835353851
Valid Loss:  0.03214157745242119
Epoch:  297  	Training Loss: 0.026809923350811005
Test Loss:  0.032124146819114685
Valid Loss:  0.032137639820575714
Epoch:  298  	Training Loss: 0.026805603876709938
Test Loss:  0.03211985528469086
Valid Loss:  0.03213369846343994
Epoch:  299  	Training Loss: 0.02680128812789917
Test Loss:  0.03211556375026703
Valid Loss:  0.03212974593043327
Epoch:  300  	Training Loss: 0.02679697424173355
Test Loss:  0.032111264765262604
Valid Loss:  0.032125793397426605
Epoch:  301  	Training Loss: 0.02679266594350338
Test Loss:  0.032106973230838776
Valid Loss:  0.03212183713912964
Epoch:  302  	Training Loss: 0.026788361370563507
Test Loss:  0.032102715224027634
Valid Loss:  0.03211792930960655
Epoch:  303  	Training Loss: 0.026784032583236694
Test Loss:  0.032098472118377686
Valid Loss:  0.03211402893066406
Epoch:  304  	Training Loss: 0.026779714971780777
Test Loss:  0.03209421783685684
Valid Loss:  0.032110121101140976
Epoch:  305  	Training Loss: 0.02677539922297001
Test Loss:  0.032089971005916595
Valid Loss:  0.03210620954632759
Epoch:  306  	Training Loss: 0.02677108533680439
Test Loss:  0.03208572044968605
Valid Loss:  0.03210228681564331
Epoch:  307  	Training Loss: 0.02676677703857422
Test Loss:  0.032081473618745804
Valid Loss:  0.03209835663437843
Epoch:  308  	Training Loss: 0.0267624668776989
Test Loss:  0.032077230513095856
Valid Loss:  0.032094426453113556
Epoch:  309  	Training Loss: 0.026758164167404175
Test Loss:  0.03207298368215561
Valid Loss:  0.03209049254655838
Epoch:  310  	Training Loss: 0.026753859594464302
Test Loss:  0.03206873685121536
Valid Loss:  0.03208655118942261
Epoch:  311  	Training Loss: 0.026749562472105026
Test Loss:  0.032064490020275116
Valid Loss:  0.03208260238170624
Epoch:  312  	Training Loss: 0.0267452634871006
Test Loss:  0.03205995261669159
Valid Loss:  0.03207835927605629
Epoch:  313  	Training Loss: 0.02674071490764618
Test Loss:  0.032055407762527466
Valid Loss:  0.032074108719825745
Epoch:  314  	Training Loss: 0.026736170053482056
Test Loss:  0.03205087408423424
Valid Loss:  0.0320698544383049
Epoch:  315  	Training Loss: 0.026731640100479126
Test Loss:  0.0320463627576828
Valid Loss:  0.03206584230065346
Epoch:  316  	Training Loss: 0.02672707475721836
Test Loss:  0.032041843980550766
Valid Loss:  0.03206181898713112
Epoch:  317  	Training Loss: 0.026722516864538193
Test Loss:  0.03203731030225754
Valid Loss:  0.03205754607915878
Epoch:  318  	Training Loss: 0.026717999950051308
Test Loss:  0.0320328027009964
Valid Loss:  0.03205350786447525
Epoch:  319  	Training Loss: 0.026713451370596886
Test Loss:  0.03202829509973526
Valid Loss:  0.032049473375082016
Epoch:  320  	Training Loss: 0.026708904653787613
Test Loss:  0.03202378749847412
Valid Loss:  0.03204542398452759
Epoch:  321  	Training Loss: 0.026704365387558937
Test Loss:  0.03201928362250328
Valid Loss:  0.032041363418102264
Epoch:  322  	Training Loss: 0.02669982984662056
Test Loss:  0.032015103846788406
Valid Loss:  0.032037630677223206
Epoch:  323  	Training Loss: 0.026695573702454567
Test Loss:  0.03201092779636383
Valid Loss:  0.03203389048576355
Epoch:  324  	Training Loss: 0.02669132500886917
Test Loss:  0.03200668841600418
Valid Loss:  0.032029855996370316
Epoch:  325  	Training Loss: 0.026687081903219223
Test Loss:  0.032002512365579605
Valid Loss:  0.032026104629039764
Epoch:  326  	Training Loss: 0.026682840660214424
Test Loss:  0.03199833631515503
Valid Loss:  0.03202234208583832
Epoch:  327  	Training Loss: 0.026678599417209625
Test Loss:  0.03199415281414986
Valid Loss:  0.03201856091618538
Epoch:  328  	Training Loss: 0.026674356311559677
Test Loss:  0.03198997676372528
Valid Loss:  0.03201478719711304
Epoch:  329  	Training Loss: 0.026670124381780624
Test Loss:  0.031985796988010406
Valid Loss:  0.0320110060274601
Epoch:  330  	Training Loss: 0.026665888726711273
Test Loss:  0.03198162093758583
Valid Loss:  0.032007209956645966
Epoch:  331  	Training Loss: 0.026661664247512817
Test Loss:  0.031977444887161255
Valid Loss:  0.032003410160541534
Epoch:  332  	Training Loss: 0.02665743976831436
Test Loss:  0.031973257660865784
Valid Loss:  0.03199959546327591
Epoch:  333  	Training Loss: 0.026653209701180458
Test Loss:  0.031969062983989716
Valid Loss:  0.03199576586484909
Epoch:  334  	Training Loss: 0.026648979634046555
Test Loss:  0.031964875757694244
Valid Loss:  0.03199193254113197
Epoch:  335  	Training Loss: 0.026644757017493248
Test Loss:  0.03196068853139877
Valid Loss:  0.03198809176683426
Epoch:  336  	Training Loss: 0.02664053440093994
Test Loss:  0.0319565013051033
Valid Loss:  0.03198423981666565
Epoch:  337  	Training Loss: 0.026636313647031784
Test Loss:  0.031952306628227234
Valid Loss:  0.03198038786649704
Epoch:  338  	Training Loss: 0.026632094755768776
Test Loss:  0.031948115676641464
Valid Loss:  0.031976524740457535
Epoch:  339  	Training Loss: 0.026627879589796066
Test Loss:  0.031943924725055695
Valid Loss:  0.03197266161441803
Epoch:  340  	Training Loss: 0.026623666286468506
Test Loss:  0.03193973749876022
Valid Loss:  0.03196878731250763
Epoch:  341  	Training Loss: 0.026619452983140945
Test Loss:  0.031935542821884155
Valid Loss:  0.031964898109436035
Epoch:  342  	Training Loss: 0.026615247130393982
Test Loss:  0.03193146735429764
Valid Loss:  0.03196113556623459
Epoch:  343  	Training Loss: 0.02661113627254963
Test Loss:  0.03192738816142082
Valid Loss:  0.03195735812187195
Epoch:  344  	Training Loss: 0.026607021689414978
Test Loss:  0.0319233164191246
Valid Loss:  0.031953588128089905
Epoch:  345  	Training Loss: 0.026602916419506073
Test Loss:  0.031919244676828384
Valid Loss:  0.03194980323314667
Epoch:  346  	Training Loss: 0.026598816737532616
Test Loss:  0.031915172934532166
Valid Loss:  0.03194601461291313
Epoch:  347  	Training Loss: 0.02659471333026886
Test Loss:  0.03191109746694565
Valid Loss:  0.031942218542099
Epoch:  348  	Training Loss: 0.02659061923623085
Test Loss:  0.03190702199935913
Valid Loss:  0.03193841874599457
Epoch:  349  	Training Loss: 0.026586519554257393
Test Loss:  0.031902946531772614
Valid Loss:  0.03193461522459984
Epoch:  350  	Training Loss: 0.026582423597574234
Test Loss:  0.031898871064186096
Valid Loss:  0.03193080425262451
Epoch:  351  	Training Loss: 0.026578331366181374
Test Loss:  0.03189479559659958
Valid Loss:  0.03192698210477829
Epoch:  352  	Training Loss: 0.026574235409498215
Test Loss:  0.0318906232714653
Valid Loss:  0.03192304074764252
Epoch:  353  	Training Loss: 0.026570020243525505
Test Loss:  0.03188647702336311
Valid Loss:  0.03191910311579704
Epoch:  354  	Training Loss: 0.026565810665488243
Test Loss:  0.031882330775260925
Valid Loss:  0.031915150582790375
Epoch:  355  	Training Loss: 0.02656160108745098
Test Loss:  0.031878188252449036
Valid Loss:  0.03191119432449341
Epoch:  356  	Training Loss: 0.02655739337205887
Test Loss:  0.03187403455376625
Valid Loss:  0.031907230615615845
Epoch:  357  	Training Loss: 0.026553180068731308
Test Loss:  0.03186989203095436
Valid Loss:  0.031903259456157684
Epoch:  358  	Training Loss: 0.026548974215984344
Test Loss:  0.03186575323343277
Valid Loss:  0.03189929574728012
Epoch:  359  	Training Loss: 0.02654477208852768
Test Loss:  0.03186161071062088
Valid Loss:  72%|███████▏  | 360/500 [04:10<00:46,  2.98it/s] 72%|███████▏  | 362/500 [04:17<02:43,  1.18s/it] 73%|███████▎  | 364/500 [04:17<01:55,  1.18it/s] 73%|███████▎  | 366/500 [04:17<01:22,  1.63it/s] 74%|███████▎  | 368/500 [04:17<00:59,  2.23it/s] 74%|███████▍  | 370/500 [04:17<00:43,  3.00it/s] 74%|███████▍  | 372/500 [04:23<02:31,  1.18s/it] 75%|███████▍  | 374/500 [04:24<01:47,  1.17it/s] 75%|███████▌  | 376/500 [04:24<01:17,  1.61it/s] 76%|███████▌  | 378/500 [04:24<00:56,  2.17it/s] 76%|███████▌  | 380/500 [04:24<00:41,  2.86it/s] 76%|███████▋  | 382/500 [04:31<02:22,  1.21s/it] 77%|███████▋  | 384/500 [04:31<01:40,  1.16it/s] 77%|███████▋  | 386/500 [04:31<01:11,  1.60it/s] 78%|███████▊  | 388/500 [04:31<00:51,  2.18it/s] 78%|███████▊  | 390/500 [04:31<00:37,  2.93it/s] 78%|███████▊  | 392/500 [04:38<02:11,  1.22s/it] 79%|███████▉  | 394/500 [04:38<01:32,  1.15it/s] 79%|███████▉  | 396/500 [04:38<01:05,  1.59it/s] 80%|███████▉  | 398/500 [04:38<00:47,  2.17it/s] 80%|████████  | 400/500 [04:38<00:34,  2.92it/s] 80%|████████  | 402/500 [04:45<02:00,  1.23s/it] 81%|████████  | 404/500 [04:45<01:24,  1.14it/s] 81%|████████  | 406/500 [04:45<00:59,  1.58it/s] 82%|████████▏ | 408/500 [04:45<00:42,  2.15it/s] 82%|████████▏ | 410/500 [04:45<00:31,  2.88it/s] 82%|████████▏ | 412/500 [04:52<01:47,  1.22s/it] 83%|████████▎ | 414/500 [04:52<01:15,  1.14it/s] 83%|████████▎ | 416/500 [04:52<00:53,  1.58it/s] 84%|████████▎ | 418/500 [04:52<00:38,  2.16it/s] 84%|████████▍ | 420/500 [04:52<00:27,  2.90it/s] 84%|████████▍ | 422/500 [04:59<01:34,  1.21s/it] 85%|████████▍ | 424/500 [04:59<01:06,  1.15it/s] 85%|████████▌ | 426/500 [04:59<00:47,  1.57it/s] 86%|████████▌ | 428/500 [04:59<00:33,  2.14it/s] 86%|████████▌ | 430/500 [04:59<00:24,  2.89it/s] 0.03189532086253166
Epoch:  360  	Training Loss: 0.026540569961071014
Test Loss:  0.03185747191309929
Valid Loss:  0.0318913459777832
Epoch:  361  	Training Loss: 0.026536371558904648
Test Loss:  0.031853336840867996
Valid Loss:  0.03188735991716385
Epoch:  362  	Training Loss: 0.02653217315673828
Test Loss:  0.03184923529624939
Valid Loss:  0.03188341110944748
Epoch:  363  	Training Loss: 0.026528019458055496
Test Loss:  0.03184514120221138
Valid Loss:  0.03187945857644081
Epoch:  364  	Training Loss: 0.02652386948466301
Test Loss:  0.03184104710817337
Valid Loss:  0.031875502318143845
Epoch:  365  	Training Loss: 0.026519719511270523
Test Loss:  0.03183694928884506
Valid Loss:  0.03187153488397598
Epoch:  366  	Training Loss: 0.026515573263168335
Test Loss:  0.03183285519480705
Valid Loss:  0.03186756744980812
Epoch:  367  	Training Loss: 0.026511425152420998
Test Loss:  0.03182877227663994
Valid Loss:  0.031863901764154434
Epoch:  368  	Training Loss: 0.0265073012560606
Test Loss:  0.03182469308376312
Valid Loss:  0.031860221177339554
Epoch:  369  	Training Loss: 0.02650318294763565
Test Loss:  0.03182061016559601
Valid Loss:  0.031856536865234375
Epoch:  370  	Training Loss: 0.02649906650185585
Test Loss:  0.031816527247428894
Valid Loss:  0.0318528413772583
Epoch:  371  	Training Loss: 0.0264949481934309
Test Loss:  0.03181244805455208
Valid Loss:  0.03184913471341133
Epoch:  372  	Training Loss: 0.026490841060876846
Test Loss:  0.03180844709277153
Valid Loss:  0.03184549883008003
Epoch:  373  	Training Loss: 0.026486799120903015
Test Loss:  0.03180444985628128
Valid Loss:  0.03184185549616814
Epoch:  374  	Training Loss: 0.026482759043574333
Test Loss:  0.03180044889450073
Valid Loss:  0.03183819726109505
Epoch:  375  	Training Loss: 0.0264787245541811
Test Loss:  0.031796447932720184
Valid Loss:  0.03183453902602196
Epoch:  376  	Training Loss: 0.026474691927433014
Test Loss:  0.03179245814681053
Valid Loss:  0.03183087706565857
Epoch:  377  	Training Loss: 0.026470666751265526
Test Loss:  0.03178846463561058
Valid Loss:  0.03182720020413399
Epoch:  378  	Training Loss: 0.02646663971245289
Test Loss:  0.03178447484970093
Valid Loss:  0.03182351961731911
Epoch:  379  	Training Loss: 0.0264626182615757
Test Loss:  0.031780485063791275
Valid Loss:  0.03181982785463333
Epoch:  380  	Training Loss: 0.02645859867334366
Test Loss:  0.03177649900317192
Valid Loss:  0.031816139817237854
Epoch:  381  	Training Loss: 0.026454579085111618
Test Loss:  0.03177250921726227
Valid Loss:  0.03181243687868118
Epoch:  382  	Training Loss: 0.026450561359524727
Test Loss:  0.03176846355199814
Valid Loss:  0.03180866688489914
Epoch:  383  	Training Loss: 0.026446498930454254
Test Loss:  0.03176441788673401
Valid Loss:  0.0318048894405365
Epoch:  384  	Training Loss: 0.026442434638738632
Test Loss:  0.03176036849617958
Valid Loss:  0.03180110082030296
Epoch:  385  	Training Loss: 0.02643837034702301
Test Loss:  0.03175632655620575
Valid Loss:  0.031797315925359726
Epoch:  386  	Training Loss: 0.026434313505887985
Test Loss:  0.03175228461623192
Valid Loss:  0.031793516129255295
Epoch:  387  	Training Loss: 0.026430252939462662
Test Loss:  0.031748250126838684
Valid Loss:  0.03178972378373146
Epoch:  388  	Training Loss: 0.026426203548908234
Test Loss:  0.03174420818686485
Valid Loss:  0.031785912811756134
Epoch:  389  	Training Loss: 0.026422150433063507
Test Loss:  0.03174016624689102
Valid Loss:  0.03178210183978081
Epoch:  390  	Training Loss: 0.02641809731721878
Test Loss:  0.03173612803220749
Valid Loss:  0.031778279691934586
Epoch:  391  	Training Loss: 0.026414047926664352
Test Loss:  0.031732089817523956
Valid Loss:  0.031774453818798065
Epoch:  392  	Training Loss: 0.026409996673464775
Test Loss:  0.031728021800518036
Valid Loss:  0.03177059069275856
Epoch:  393  	Training Loss: 0.026405928656458855
Test Loss:  0.031723953783512115
Valid Loss:  0.031766727566719055
Epoch:  394  	Training Loss: 0.026401862502098083
Test Loss:  0.03171989321708679
Valid Loss:  0.031762853264808655
Epoch:  395  	Training Loss: 0.026397794485092163
Test Loss:  0.03171582520008087
Valid Loss:  0.031758978962898254
Epoch:  396  	Training Loss: 0.026393726468086243
Test Loss:  0.03171176463365555
Valid Loss:  0.03175509721040726
Epoch:  397  	Training Loss: 0.02638966590166092
Test Loss:  0.031707704067230225
Valid Loss:  0.03175120800733566
Epoch:  398  	Training Loss: 0.026385605335235596
Test Loss:  0.0317036435008049
Valid Loss:  0.03174731880426407
Epoch:  399  	Training Loss: 0.02638154849410057
Test Loss:  0.031699590384960175
Valid Loss:  0.031743429601192474
Epoch:  400  	Training Loss: 0.026377491652965546
Test Loss:  0.03169553726911545
Valid Loss:  0.03173953294754028
Epoch:  401  	Training Loss: 0.02637344039976597
Test Loss:  0.03169148415327072
Valid Loss:  0.03173563629388809
Epoch:  402  	Training Loss: 0.02636938914656639
Test Loss:  0.03168751299381256
Valid Loss:  0.03173181414604187
Epoch:  403  	Training Loss: 0.026365410536527634
Test Loss:  0.031683549284935
Valid Loss:  0.03172799572348595
Epoch:  404  	Training Loss: 0.026361435651779175
Test Loss:  0.031679585576057434
Valid Loss:  0.031724173575639725
Epoch:  405  	Training Loss: 0.026357464492321014
Test Loss:  0.03167562186717987
Valid Loss:  0.031720347702503204
Epoch:  406  	Training Loss: 0.026353493332862854
Test Loss:  0.031671665608882904
Valid Loss:  0.03171651437878609
Epoch:  407  	Training Loss: 0.026349525898694992
Test Loss:  0.03166770562529564
Valid Loss:  0.03171268105506897
Epoch:  408  	Training Loss: 0.02634555846452713
Test Loss:  0.031663745641708374
Valid Loss:  0.03170884773135185
Epoch:  409  	Training Loss: 0.026341594755649567
Test Loss:  0.03165978938341141
Valid Loss:  0.03170500695705414
Epoch:  410  	Training Loss: 0.026337629184126854
Test Loss:  0.03165583312511444
Valid Loss:  0.031701162457466125
Epoch:  411  	Training Loss: 0.02633366733789444
Test Loss:  0.031651876866817474
Valid Loss:  0.031697310507297516
Epoch:  412  	Training Loss: 0.026329705491662025
Test Loss:  0.031648069620132446
Valid Loss:  0.03169361501932144
Epoch:  413  	Training Loss: 0.02632586658000946
Test Loss:  0.03164426609873772
Valid Loss:  0.03168991208076477
Epoch:  414  	Training Loss: 0.026322025805711746
Test Loss:  0.03164045885205269
Valid Loss:  0.0316862054169178
Epoch:  415  	Training Loss: 0.02631818875670433
Test Loss:  0.03163665533065796
Valid Loss:  0.03168249875307083
Epoch:  416  	Training Loss: 0.026314370334148407
Test Loss:  0.03163287788629532
Valid Loss:  0.031679097563028336
Epoch:  417  	Training Loss: 0.02631056122481823
Test Loss:  0.03162910416722298
Valid Loss:  0.03167569264769554
Epoch:  418  	Training Loss: 0.02630675584077835
Test Loss:  0.03162533417344093
Valid Loss:  0.03167227655649185
Epoch:  419  	Training Loss: 0.02630295604467392
Test Loss:  0.03162156045436859
Valid Loss:  0.031668856739997864
Epoch:  420  	Training Loss: 0.02629915624856949
Test Loss:  0.03161779046058655
Valid Loss:  0.03166542202234268
Epoch:  421  	Training Loss: 0.026295356452465057
Test Loss:  0.03161401301622391
Valid Loss:  0.0316619835793972
Epoch:  422  	Training Loss: 0.026291564106941223
Test Loss:  0.031610339879989624
Valid Loss:  0.03165862709283829
Epoch:  423  	Training Loss: 0.026287836953997612
Test Loss:  0.031606659293174744
Valid Loss:  0.03165527433156967
Epoch:  424  	Training Loss: 0.0262841135263443
Test Loss:  0.03160297870635986
Valid Loss:  0.031651899218559265
Epoch:  425  	Training Loss: 0.026280390098690987
Test Loss:  0.03159930557012558
Valid Loss:  0.03164852783083916
Epoch:  426  	Training Loss: 0.02627667412161827
Test Loss:  0.0315956249833107
Valid Loss:  0.031645145267248154
Epoch:  427  	Training Loss: 0.026272956281900406
Test Loss:  0.03159194439649582
Valid Loss:  0.03164175525307655
Epoch:  428  	Training Loss: 0.02626924030482769
Test Loss:  0.031588274985551834
Valid Loss:  0.03163835406303406
Epoch:  429  	Training Loss: 0.026265529915690422
Test Loss:  0.03158459812402725
Valid Loss:  0.031634945422410965
Epoch:  430  	Training Loss: 0.026261817663908005
Test Loss:  0.03158092498779297
Valid Loss:  0.03163154050707817
 86%|████████▋ | 432/500 [05:06<01:22,  1.22s/it] 87%|████████▋ | 434/500 [05:06<00:57,  1.14it/s] 87%|████████▋ | 436/500 [05:06<00:40,  1.58it/s] 88%|████████▊ | 438/500 [05:06<00:28,  2.16it/s] 88%|████████▊ | 440/500 [05:06<00:20,  2.90it/s] 88%|████████▊ | 442/500 [05:13<01:10,  1.21s/it] 89%|████████▉ | 444/500 [05:13<00:48,  1.15it/s] 89%|████████▉ | 446/500 [05:13<00:33,  1.59it/s] 90%|████████▉ | 448/500 [05:13<00:23,  2.17it/s] 90%|█████████ | 450/500 [05:13<00:17,  2.93it/s] 90%|█████████ | 452/500 [05:20<00:58,  1.21s/it] 91%|█████████ | 454/500 [05:20<00:39,  1.15it/s] 91%|█████████ | 456/500 [05:20<00:27,  1.60it/s] 92%|█████████▏| 458/500 [05:20<00:19,  2.17it/s] 92%|█████████▏| 460/500 [05:21<00:13,  2.93it/s] 92%|█████████▏| 462/500 [05:27<00:46,  1.23s/it] 93%|█████████▎| 464/500 [05:27<00:31,  1.14it/s] 93%|█████████▎| 466/500 [05:27<00:21,  1.57it/s] 94%|█████████▎| 468/500 [05:28<00:15,  2.12it/s] 94%|█████████▍| 470/500 [05:28<00:10,  2.80it/s] 94%|█████████▍| 472/500 [05:34<00:34,  1.24s/it] 95%|█████████▍| 474/500 [05:34<00:23,  1.13it/s] 95%|█████████▌| 476/500 [05:35<00:15,  1.56it/s] 96%|█████████▌| 478/500 [05:35<00:10,  2.14it/s] 96%|█████████▌| 480/500 [05:35<00:06,  2.88it/s] 96%|█████████▋| 482/500 [05:42<00:22,  1.25s/it] 97%|█████████▋| 484/500 [05:42<00:14,  1.11it/s] 97%|█████████▋| 486/500 [05:42<00:09,  1.53it/s] 98%|█████████▊| 488/500 [05:42<00:05,  2.06it/s] 98%|█████████▊| 490/500 [05:42<00:03,  2.74it/s] 98%|█████████▊| 492/500 [05:49<00:09,  1.25s/it] 99%|█████████▉| 494/500 [05:49<00:05,  1.12it/s] 99%|█████████▉| 496/500 [05:49<00:02,  1.54it/s]100%|█████████▉| 498/500 [05:49<00:00,  2.11it/s]100%|██████████| 500/500 [05:49<00:00,  2.84it/s]100%|██████████| 500/500 [05:49<00:00,  1.43it/s]
Epoch:  431  	Training Loss: 0.026258109137415886
Test Loss:  0.031577251851558685
Valid Loss:  0.03162812441587448
Epoch:  432  	Training Loss: 0.026254404336214066
Test Loss:  0.03157337009906769
Valid Loss:  0.03162447735667229
Epoch:  433  	Training Loss: 0.026250530034303665
Test Loss:  0.031569477170705795
Valid Loss:  0.0316208191215992
Epoch:  434  	Training Loss: 0.026246655732393265
Test Loss:  0.0315655879676342
Valid Loss:  0.03161715343594551
Epoch:  435  	Training Loss: 0.026242781430482864
Test Loss:  0.031561702489852905
Valid Loss:  0.031613484025001526
Epoch:  436  	Training Loss: 0.026238910853862762
Test Loss:  0.03155781701207161
Valid Loss:  0.03160981088876724
Epoch:  437  	Training Loss: 0.02623504213988781
Test Loss:  0.03155393898487091
Valid Loss:  0.03160614147782326
Epoch:  438  	Training Loss: 0.026231180876493454
Test Loss:  0.031550049781799316
Valid Loss:  0.03160245716571808
Epoch:  439  	Training Loss: 0.02622731402516365
Test Loss:  0.03154616802930832
Valid Loss:  0.0315987654030323
Epoch:  440  	Training Loss: 0.026223450899124146
Test Loss:  0.03154228627681732
Valid Loss:  0.03159506618976593
Epoch:  441  	Training Loss: 0.02621959149837494
Test Loss:  0.03153839707374573
Valid Loss:  0.031591370701789856
Epoch:  442  	Training Loss: 0.026215728372335434
Test Loss:  0.0315345823764801
Valid Loss:  0.031587716192007065
Epoch:  443  	Training Loss: 0.02621193416416645
Test Loss:  0.03153075650334358
Valid Loss:  0.031584061682224274
Epoch:  444  	Training Loss: 0.02620813623070717
Test Loss:  0.031526923179626465
Valid Loss:  0.03158039227128029
Epoch:  445  	Training Loss: 0.026204336434602737
Test Loss:  0.03152310103178024
Valid Loss:  0.0315767265856266
Epoch:  446  	Training Loss: 0.026200540363788605
Test Loss:  0.03151927515864372
Valid Loss:  0.03157304972410202
Epoch:  447  	Training Loss: 0.02619674801826477
Test Loss:  0.0315154567360878
Valid Loss:  0.03156936913728714
Epoch:  448  	Training Loss: 0.026192957535386086
Test Loss:  0.03151163458824158
Valid Loss:  0.03156569227576256
Epoch:  449  	Training Loss: 0.0261891670525074
Test Loss:  0.031507812440395355
Valid Loss:  0.03156200796365738
Epoch:  450  	Training Loss: 0.026185378432273865
Test Loss:  0.03150399029254913
Valid Loss:  0.031558312475681305
Epoch:  451  	Training Loss: 0.02618158608675003
Test Loss:  0.03150016814470291
Valid Loss:  0.03155461326241493
Epoch:  452  	Training Loss: 0.026177799329161644
Test Loss:  0.031496405601501465
Valid Loss:  0.03155098482966423
Epoch:  453  	Training Loss: 0.026174038648605347
Test Loss:  0.03149263933300972
Valid Loss:  0.03154735267162323
Epoch:  454  	Training Loss: 0.0261702761054039
Test Loss:  0.03148888051509857
Valid Loss:  0.03154372051358223
Epoch:  455  	Training Loss: 0.026166513562202454
Test Loss:  0.031485117971897125
Valid Loss:  0.031540073454380035
Epoch:  456  	Training Loss: 0.026162754744291306
Test Loss:  0.03148135542869568
Valid Loss:  0.03153643012046814
Epoch:  457  	Training Loss: 0.026158995926380157
Test Loss:  0.03147759288549423
Valid Loss:  0.031532786786556244
Epoch:  458  	Training Loss: 0.026155240833759308
Test Loss:  0.03147383779287338
Valid Loss:  0.03152913227677345
Epoch:  459  	Training Loss: 0.026151489466428757
Test Loss:  0.031470075249671936
Valid Loss:  0.03152547776699066
Epoch:  460  	Training Loss: 0.026147734373807907
Test Loss:  0.03146631270647049
Valid Loss:  0.03152181953191757
Epoch:  461  	Training Loss: 0.026143983006477356
Test Loss:  0.03146255761384964
Valid Loss:  0.031518153846263885
Epoch:  462  	Training Loss: 0.026140231639146805
Test Loss:  0.03145886957645416
Valid Loss:  0.03151455521583557
Epoch:  463  	Training Loss: 0.02613653615117073
Test Loss:  0.03145517408847809
Valid Loss:  0.03151094540953636
Epoch:  464  	Training Loss: 0.026132840663194656
Test Loss:  0.031451474875211716
Valid Loss:  0.031507328152656555
Epoch:  465  	Training Loss: 0.026129141449928284
Test Loss:  0.03144778311252594
Valid Loss:  0.03150371462106705
Epoch:  466  	Training Loss: 0.02612544596195221
Test Loss:  0.03144408389925957
Valid Loss:  0.03150009363889694
Epoch:  467  	Training Loss: 0.026121752336621284
Test Loss:  0.03144038841128349
Valid Loss:  0.03149646520614624
Epoch:  468  	Training Loss: 0.02611805498600006
Test Loss:  0.031436704099178314
Valid Loss:  0.031492847949266434
Epoch:  469  	Training Loss: 0.026114370673894882
Test Loss:  0.03143300861120224
Valid Loss:  0.03148922324180603
Epoch:  470  	Training Loss: 0.026110677048563957
Test Loss:  0.031429316848516464
Valid Loss:  0.03148558735847473
Epoch:  471  	Training Loss: 0.02610698528587818
Test Loss:  0.03142562508583069
Valid Loss:  0.03148195892572403
Epoch:  472  	Training Loss: 0.026103299111127853
Test Loss:  0.03142184019088745
Valid Loss:  0.03147822618484497
Epoch:  473  	Training Loss: 0.026099536567926407
Test Loss:  0.03141805902123451
Valid Loss:  0.03147448971867561
Epoch:  474  	Training Loss: 0.02609577775001526
Test Loss:  0.031414274126291275
Valid Loss:  0.031470756977796555
Epoch:  475  	Training Loss: 0.02609201893210411
Test Loss:  0.03141048923134804
Valid Loss:  0.0314670167863369
Epoch:  476  	Training Loss: 0.026088260114192963
Test Loss:  0.0314067080616951
Valid Loss:  0.031463272869586945
Epoch:  477  	Training Loss: 0.026084505021572113
Test Loss:  0.03140292316675186
Valid Loss:  0.03145952522754669
Epoch:  478  	Training Loss: 0.026080746203660965
Test Loss:  0.03139914572238922
Valid Loss:  0.031455785036087036
Epoch:  479  	Training Loss: 0.026076992973685265
Test Loss:  0.03139536455273628
Valid Loss:  0.03145203739404678
Epoch:  480  	Training Loss: 0.026073243468999863
Test Loss:  0.03139159083366394
Valid Loss:  0.03144828975200653
Epoch:  481  	Training Loss: 0.02606949210166931
Test Loss:  0.0313878059387207
Valid Loss:  0.03144453838467598
Epoch:  482  	Training Loss: 0.02606574073433876
Test Loss:  0.03138409182429314
Valid Loss:  0.03144083917140961
Epoch:  483  	Training Loss: 0.026062045246362686
Test Loss:  0.03138037025928497
Valid Loss:  0.03143714368343353
Epoch:  484  	Training Loss: 0.026058349758386612
Test Loss:  0.0313766747713089
Valid Loss:  0.03143344819545746
Epoch:  485  	Training Loss: 0.026054657995700836
Test Loss:  0.0313730388879776
Valid Loss:  0.031429748982191086
Epoch:  486  	Training Loss: 0.026050962507724762
Test Loss:  0.0313694104552269
Valid Loss:  0.03142605349421501
Epoch:  487  	Training Loss: 0.026047274470329285
Test Loss:  0.031365767121315
Valid Loss:  0.03142234683036804
Epoch:  488  	Training Loss: 0.026043595746159554
Test Loss:  0.03136199712753296
Valid Loss:  0.031419187784194946
Epoch:  489  	Training Loss: 0.026039883494377136
Test Loss:  0.03135836869478226
Valid Loss:  0.03141547366976738
Epoch:  490  	Training Loss: 0.026036225259304047
Test Loss:  0.03135460615158081
Valid Loss:  0.03141230344772339
Epoch:  491  	Training Loss: 0.02603251300752163
Test Loss:  0.03135091811418533
Valid Loss:  0.031408850103616714
Epoch:  492  	Training Loss: 0.026028834283351898
Test Loss:  0.031347256153821945
Valid Loss:  0.03140542283654213
Epoch:  493  	Training Loss: 0.02602517232298851
Test Loss:  0.03134356811642647
Valid Loss:  0.03140230476856232
Epoch:  494  	Training Loss: 0.02602151222527027
Test Loss:  0.031339917331933975
Valid Loss:  0.03139885514974594
Epoch:  495  	Training Loss: 0.026017852127552032
Test Loss:  0.03133627027273178
Valid Loss:  0.031395405530929565
Epoch:  496  	Training Loss: 0.02601419761776924
Test Loss:  0.0313325859606266
Valid Loss:  0.031392261385917664
Epoch:  497  	Training Loss: 0.026010548695921898
Test Loss:  0.031328946352005005
Valid Loss:  0.031388793140649796
Epoch:  498  	Training Loss: 0.026006896048784256
Test Loss:  0.03132530674338341
Valid Loss:  0.03138532489538193
Epoch:  499  	Training Loss: 0.02600325271487236
Test Loss:  0.031321629881858826
Valid Loss:  0.03138215094804764
Epoch:  500  	Training Loss: 0.025999605655670166
Test Loss:  0.03131799399852753
Valid Loss:  0.03137866407632828
seed is  13
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:46,  6.35s/it]  1%|          | 3/500 [00:06<14:02,  1.70s/it]  1%|          | 5/500 [00:06<07:04,  1.17it/s]  1%|▏         | 7/500 [00:06<04:17,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.86it/s]  2%|▏         | 11/500 [00:13<10:56,  1.34s/it]  3%|▎         | 13/500 [00:13<07:27,  1.09it/s]  3%|▎         | 15/500 [00:13<05:12,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:43,  2.93it/s]  4%|▍         | 21/500 [00:20<09:48,  1.23s/it]  5%|▍         | 23/500 [00:20<06:57,  1.14it/s]  5%|▌         | 25/500 [00:20<04:59,  1.59it/s]  5%|▌         | 27/500 [00:20<03:37,  2.18it/s]  6%|▌         | 29/500 [00:20<02:40,  2.93it/s]  6%|▌         | 31/500 [00:33<16:51,  2.16s/it]  7%|▋         | 33/500 [00:33<11:53,  1.53s/it]  7%|▋         | 35/500 [00:40<15:44,  2.03s/it]  7%|▋         | 37/500 [00:40<11:08,  1.44s/it]  8%|▊         | 39/500 [00:40<07:54,  1.03s/it]  8%|▊         | 41/500 [00:46<12:55,  1.69s/it]  9%|▊         | 43/500 [00:46<09:10,  1.20s/it]  9%|▉         | 45/500 [00:47<06:32,  1.16it/s]  9%|▉         | 47/500 [00:47<04:42,  1.60it/s] 10%|▉         | 49/500 [00:47<03:25,  2.19it/s] 10%|█         | 51/500 [00:53<09:39,  1.29s/it] 11%|█         | 53/500 [00:53<06:53,  1.08it/s] 11%|█         | 55/500 [00:54<04:57,  1.50it/s] 11%|█▏        | 57/500 [00:54<03:36,  2.05it/s] 12%|█▏        | 59/500 [00:54<02:39,  2.77it/s] 12%|█▏        | 61/500 [01:00<08:55,  1.22s/it] 13%|█▎        | 63/500 [01:00<06:23,  1.14it/s] 13%|█▎        | 65/500 [01:07<11:27,  1.58s/it] 13%|█▎        | 67/500 [01:07<08:07,  1.13s/it]Epoch:  1  	Training Loss: 0.04272831231355667
Test Loss:  5.285874366760254
Valid Loss:  5.372360706329346
Epoch:  2  	Training Loss: 4.694278717041016
Test Loss:  1213.156982421875
Valid Loss:  1215.4697265625
Epoch:  3  	Training Loss: 1214.843017578125
Test Loss:  1.7303167581558228
Valid Loss:  1.7630035877227783
Epoch:  4  	Training Loss: 1.5076196193695068
Test Loss:  1.5773615837097168
Valid Loss:  1.6065828800201416
Epoch:  5  	Training Loss: 1.3803918361663818
Test Loss:  1.5773569345474243
Valid Loss:  1.60657799243927
Epoch:  6  	Training Loss: 1.380387544631958
Test Loss:  1.5773520469665527
Valid Loss:  1.6065733432769775
Epoch:  7  	Training Loss: 1.3803831338882446
Test Loss:  1.5773475170135498
Valid Loss:  1.6065685749053955
Epoch:  8  	Training Loss: 1.3803789615631104
Test Loss:  1.5773427486419678
Valid Loss:  1.6065638065338135
Epoch:  9  	Training Loss: 1.380374550819397
Test Loss:  1.5773382186889648
Valid Loss:  1.6065590381622314
Epoch:  10  	Training Loss: 1.3803701400756836
Test Loss:  1.5773334503173828
Valid Loss:  1.6065545082092285
Epoch:  11  	Training Loss: 1.3803658485412598
Test Loss:  1.5773289203643799
Valid Loss:  1.6065493822097778
Epoch:  12  	Training Loss: 1.380361557006836
Test Loss:  17.6757869720459
Valid Loss:  17.612510681152344
Epoch:  13  	Training Loss: 18.534011840820312
Test Loss:  0.4277612566947937
Valid Loss:  0.4354611039161682
Epoch:  14  	Training Loss: 0.38151973485946655
Test Loss:  0.4276733994483948
Valid Loss:  0.4353930950164795
Epoch:  15  	Training Loss: 0.3814048171043396
Test Loss:  0.4275858402252197
Valid Loss:  0.43532049655914307
Epoch:  16  	Training Loss: 0.3812900185585022
Test Loss:  0.42749667167663574
Valid Loss:  0.4352352023124695
Epoch:  17  	Training Loss: 0.38117218017578125
Test Loss:  0.4274076819419861
Valid Loss:  0.4351319670677185
Epoch:  18  	Training Loss: 0.38105255365371704
Test Loss:  0.4273149371147156
Valid Loss:  0.4350154399871826
Epoch:  19  	Training Loss: 0.38092464208602905
Test Loss:  0.4272080063819885
Valid Loss:  0.4348907768726349
Epoch:  20  	Training Loss: 0.38078582286834717
Test Loss:  0.42709881067276
Valid Loss:  0.4347553253173828
Epoch:  21  	Training Loss: 0.38064244389533997
Test Loss:  0.4269837439060211
Valid Loss:  0.43461304903030396
Epoch:  22  	Training Loss: 0.38049423694610596
Test Loss:  9.637628555297852
Valid Loss:  9.724342346191406
Epoch:  23  	Training Loss: 9.107316970825195
Test Loss:  0.5435863733291626
Valid Loss:  0.5545934438705444
Epoch:  24  	Training Loss: 0.4793780744075775
Test Loss:  0.5435863733291626
Valid Loss:  0.5545934438705444
Epoch:  25  	Training Loss: 0.4793780446052551
Test Loss:  0.5435863733291626
Valid Loss:  0.5545934438705444
Epoch:  26  	Training Loss: 0.4793780446052551
Test Loss:  0.5435863733291626
Valid Loss:  0.5545934438705444
Epoch:  27  	Training Loss: 0.4793780446052551
Test Loss:  0.5435863733291626
Valid Loss:  0.5545934438705444
Epoch:  28  	Training Loss: 0.4793780446052551
Test Loss:  0.5435863733291626
Valid Loss:  0.5545934438705444
Epoch:  29  	Training Loss: 0.4793780744075775
Test Loss:  0.5435863733291626
Valid Loss:  0.5545934438705444
Epoch:  30  	Training Loss: 0.4793780446052551
Test Loss:  0.5435863733291626
Valid Loss:  0.5545934438705444
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.4793780744075775
Test Loss:  0.02175852470099926
Valid Loss:  0.019641447812318802
Epoch:  32  	Training Loss: 0.027722638100385666
Test Loss:  0.3519778549671173
Valid Loss:  0.3572148084640503
Epoch:  33  	Training Loss: 0.33025383949279785
Test Loss:  2.346750497817993
Valid Loss:  2.3719539642333984
Epoch:  34  	Training Loss: 2.109226703643799
Test Loss:  0.5021746158599854
Valid Loss:  0.5119765996932983
Epoch:  35  	Training Loss: 0.4147757589817047
Test Loss:  0.43489816784858704
Valid Loss:  0.44550833106040955
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.35895633697509766
Test Loss:  0.07654900848865509
Valid Loss:  0.07759784162044525
Epoch:  37  	Training Loss: 0.05730534344911575
Test Loss:  0.04819798842072487
Valid Loss:  0.048829372972249985
Epoch:  38  	Training Loss: 0.03668642044067383
Test Loss:  0.03419676423072815
Valid Loss:  0.035334911197423935
Epoch:  39  	Training Loss: 0.027621891349554062
Test Loss:  0.02612520009279251
Valid Loss:  0.028107253834605217
Epoch:  40  	Training Loss: 0.022605307400226593
Test Loss:  0.021233471110463142
Valid Loss:  0.02367081679403782
Epoch:  41  	Training Loss: 0.019273290410637856
Test Loss:  0.017833050340414047
Valid Loss:  0.020579762756824493
Epoch:  42  	Training Loss: 0.016904402524232864
Test Loss:  0.00283624860458076
Valid Loss:  0.0036873980425298214
Epoch:  43  	Training Loss: 0.004157236311584711
Test Loss:  0.0022321618162095547
Valid Loss:  0.0030224244110286236
Epoch:  44  	Training Loss: 0.003348981961607933
Test Loss:  0.0017551279161125422
Valid Loss:  0.0025078863836824894
Epoch:  45  	Training Loss: 0.002697831252589822
Test Loss:  0.001394697930663824
Valid Loss:  0.002111197216436267
Epoch:  46  	Training Loss: 0.002194324042648077
Test Loss:  0.0011298396857455373
Valid Loss:  0.0018122533801943064
Epoch:  47  	Training Loss: 0.0018133283592760563
Test Loss:  0.0010042309295386076
Valid Loss:  0.0016445042565464973
Epoch:  48  	Training Loss: 0.001616987632587552
Test Loss:  0.0009609295520931482
Valid Loss:  0.0015516839921474457
Epoch:  49  	Training Loss: 0.0015001012943685055
Test Loss:  0.0009028076892718673
Valid Loss:  0.0014870073646306992
Epoch:  50  	Training Loss: 0.001408121082931757
Test Loss:  0.0008541111601516604
Valid Loss:  0.00143235397990793
Epoch:  51  	Training Loss: 0.0013292476069182158
Test Loss:  0.0008143930463120341
Valid Loss:  0.0013862182386219501
Epoch:  52  	Training Loss: 0.0012614448787644506
Test Loss:  0.0006048581562936306
Valid Loss:  0.001100180670619011
Epoch:  53  	Training Loss: 0.0009559075115248561
Test Loss:  0.0006278826622292399
Valid Loss:  0.0009160332847386599
Epoch:  54  	Training Loss: 0.0007825514185242355
Test Loss:  0.0006206179969012737
Valid Loss:  0.00084231625078246
Epoch:  55  	Training Loss: 0.000726427068002522
Test Loss:  0.0006593565922230482
Valid Loss:  0.0007935254834592342
Epoch:  56  	Training Loss: 0.0006813177606090903
Test Loss:  0.0006243798416107893
Valid Loss:  0.0007502228254452348
Epoch:  57  	Training Loss: 0.0006474140100181103
Test Loss:  0.0006485308986157179
Valid Loss:  0.0007214914076030254
Epoch:  58  	Training Loss: 0.0006189812556840479
Test Loss:  0.0006251471349969506
Valid Loss:  0.0006920336745679379
Epoch:  59  	Training Loss: 0.0005950747290626168
Test Loss:  0.0006410956848412752
Valid Loss:  0.0006709982408210635
Epoch:  60  	Training Loss: 0.000577420461922884
Test Loss:  0.0006252228049561381
Valid Loss:  0.0006516305729746819
Epoch:  61  	Training Loss: 0.0005639271694235504
Test Loss:  0.0006426882464438677
Valid Loss:  0.0006363833090290427
Epoch:  62  	Training Loss: 0.0005532492650672793
Test Loss:  0.0005924233701080084
Valid Loss:  0.0006287582218647003
Epoch:  63  	Training Loss: 0.0005564963212236762
Test Loss:  0.00074966304237023
Valid Loss:  0.0006825727177783847
Epoch:  64  	Training Loss: 0.0005826848791912198
Test Loss:  0.0006266445270739496
Valid Loss:  0.0008231675019487739
Epoch:  65  	Training Loss: 0.000774721906054765
Test Loss:  0.002606903202831745
Valid Loss:  0.0021728267893195152
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.0019780825823545456
Test Loss:  0.0017579934792593122
Valid Loss:  0.0014597787521779537
Epoch:  67  	Training Loss: 0.0012062096502631903
Test Loss:  0.001323558622971177
Valid Loss:  0.0010786158964037895
Epoch:  68  	Training Loss: 0.0008505092700943351
Test Loss:  0.0011314041912555695
Valid Loss:  0.0009175738669000566
Epoch:  69  	Training Loss: 0.0007167040021158755
Test Loss:  0.0010345459450036287
Valid Loss:   14%|█▍        | 69/500 [01:07<05:48,  1.24it/s] 14%|█▍        | 71/500 [01:14<10:51,  1.52s/it] 15%|█▍        | 73/500 [01:14<07:42,  1.08s/it] 15%|█▌        | 75/500 [01:14<05:30,  1.28it/s] 15%|█▌        | 77/500 [01:14<03:58,  1.77it/s] 16%|█▌        | 79/500 [01:14<02:56,  2.38it/s] 16%|█▌        | 81/500 [01:21<08:55,  1.28s/it] 17%|█▋        | 83/500 [01:21<06:24,  1.08it/s] 17%|█▋        | 85/500 [01:21<04:38,  1.49it/s] 17%|█▋        | 87/500 [01:21<03:25,  2.01it/s] 18%|█▊        | 89/500 [01:21<02:31,  2.71it/s] 18%|█▊        | 91/500 [01:28<08:22,  1.23s/it] 19%|█▊        | 93/500 [01:28<05:58,  1.14it/s] 19%|█▉        | 95/500 [01:28<04:17,  1.57it/s] 19%|█▉        | 97/500 [01:28<03:08,  2.13it/s] 20%|█▉        | 99/500 [01:28<02:19,  2.88it/s] 20%|██        | 101/500 [01:35<07:59,  1.20s/it] 21%|██        | 103/500 [01:35<05:43,  1.16it/s] 21%|██        | 105/500 [01:35<04:06,  1.60it/s] 21%|██▏       | 107/500 [01:35<02:59,  2.18it/s] 22%|██▏       | 109/500 [01:35<02:14,  2.91it/s] 22%|██▏       | 111/500 [01:42<07:47,  1.20s/it] 23%|██▎       | 113/500 [01:42<05:33,  1.16it/s] 23%|██▎       | 115/500 [01:42<03:59,  1.60it/s] 23%|██▎       | 117/500 [01:42<02:54,  2.19it/s] 24%|██▍       | 119/500 [01:42<02:09,  2.94it/s] 24%|██▍       | 121/500 [01:49<07:30,  1.19s/it] 25%|██▍       | 123/500 [01:49<05:24,  1.16it/s] 25%|██▌       | 125/500 [01:49<03:55,  1.59it/s] 25%|██▌       | 127/500 [01:49<02:53,  2.15it/s] 26%|██▌       | 129/500 [01:49<02:08,  2.88it/s] 26%|██▌       | 131/500 [01:56<07:20,  1.19s/it] 27%|██▋       | 133/500 [01:56<05:15,  1.16it/s] 27%|██▋       | 135/500 [01:56<03:46,  1.61it/s] 27%|██▋       | 137/500 [01:56<02:45,  2.20it/s]0.0008439604425802827
Epoch:  70  	Training Loss: 0.0006598820327781141
Test Loss:  0.0009746950236149132
Valid Loss:  0.0008020605891942978
Epoch:  71  	Training Loss: 0.0006288318545557559
Test Loss:  0.0009312211768701673
Valid Loss:  0.0007729787030257285
Epoch:  72  	Training Loss: 0.0006073604454286397
Test Loss:  0.0007507099653594196
Valid Loss:  0.0006844266317784786
Epoch:  73  	Training Loss: 0.0005446209688670933
Test Loss:  0.0006634460296481848
Valid Loss:  0.0006504610646516085
Epoch:  74  	Training Loss: 0.0005214675911702216
Test Loss:  0.000618454534560442
Valid Loss:  0.0006360289989970624
Epoch:  75  	Training Loss: 0.0005118422559462488
Test Loss:  0.0005940351402387023
Valid Loss:  0.0006289699813351035
Epoch:  76  	Training Loss: 0.0005069694016128778
Test Loss:  0.0005802379455417395
Valid Loss:  0.0006248566787689924
Epoch:  77  	Training Loss: 0.0005038926028646529
Test Loss:  0.0005721509223803878
Valid Loss:  0.0006220978684723377
Epoch:  78  	Training Loss: 0.000501596718095243
Test Loss:  0.0005671570543199778
Valid Loss:  0.0006199618801474571
Epoch:  79  	Training Loss: 0.0004996711504645646
Test Loss:  0.0005639492301270366
Valid Loss:  0.0006181440548971295
Epoch:  80  	Training Loss: 0.0004979693330824375
Test Loss:  0.0005617862334474921
Valid Loss:  0.0006165066733956337
Epoch:  81  	Training Loss: 0.0004964197287335992
Test Loss:  0.0005602353485301137
Valid Loss:  0.0006149795954115689
Epoch:  82  	Training Loss: 0.0004949569702148438
Test Loss:  0.0005654599517583847
Valid Loss:  0.0006135539733804762
Epoch:  83  	Training Loss: 0.000494000967592001
Test Loss:  0.0005700464826077223
Valid Loss:  0.0006122689810581505
Epoch:  84  	Training Loss: 0.0004932684823870659
Test Loss:  0.0005740339984185994
Valid Loss:  0.0006110528483986855
Epoch:  85  	Training Loss: 0.0004926849505864084
Test Loss:  0.0005775472964160144
Valid Loss:  0.0006098832236602902
Epoch:  86  	Training Loss: 0.0004921951331198215
Test Loss:  0.0005806101253256202
Valid Loss:  0.0006087329238653183
Epoch:  87  	Training Loss: 0.0004917717888019979
Test Loss:  0.0005833031609654427
Valid Loss:  0.0006075907731428742
Epoch:  88  	Training Loss: 0.0004913939628750086
Test Loss:  0.0005856311181560159
Valid Loss:  0.0006064441986382008
Epoch:  89  	Training Loss: 0.0004910408169962466
Test Loss:  0.0005877464427612722
Valid Loss:  0.0006053197430446744
Epoch:  90  	Training Loss: 0.0004907103138975799
Test Loss:  0.0005896533839404583
Valid Loss:  0.000604214845225215
Epoch:  91  	Training Loss: 0.0004903968656435609
Test Loss:  0.0005913872737437487
Valid Loss:  0.0006031275261193514
Epoch:  92  	Training Loss: 0.0004900951171293855
Test Loss:  0.0005699776811525226
Valid Loss:  0.0005873548798263073
Epoch:  93  	Training Loss: 0.00048078864347189665
Test Loss:  0.0005273611750453711
Valid Loss:  0.0005797562189400196
Epoch:  94  	Training Loss: 0.00047839293256402016
Test Loss:  0.0005383214447647333
Valid Loss:  0.0005782567895948887
Epoch:  95  	Training Loss: 0.00047680590068921447
Test Loss:  0.0005458142259158194
Valid Loss:  0.0005771573632955551
Epoch:  96  	Training Loss: 0.00047577786608599126
Test Loss:  0.0005509790498763323
Valid Loss:  0.0005761486827395856
Epoch:  97  	Training Loss: 0.00047504465328529477
Test Loss:  0.0005545468884520233
Valid Loss:  0.0005751277785748243
Epoch:  98  	Training Loss: 0.0004744444158859551
Test Loss:  0.0005570140201598406
Valid Loss:  0.0005740933120250702
Epoch:  99  	Training Loss: 0.0004739109717775136
Test Loss:  0.0005588722415268421
Valid Loss:  0.000573095167055726
Epoch:  100  	Training Loss: 0.00047344708582386374
Test Loss:  0.0005603593308478594
Valid Loss:  0.0005721052293665707
Epoch:  101  	Training Loss: 0.0004730285727418959
Test Loss:  0.0005615224363282323
Valid Loss:  0.0005711428239010274
Epoch:  102  	Training Loss: 0.00047264317981898785
Test Loss:  0.0005669065285474062
Valid Loss:  0.0005706283263862133
Epoch:  103  	Training Loss: 0.0004703780869022012
Test Loss:  0.0005692319828085601
Valid Loss:  0.0005703453789465129
Epoch:  104  	Training Loss: 0.0004693100636359304
Test Loss:  0.0005696958396583796
Valid Loss:  0.0005699013127014041
Epoch:  105  	Training Loss: 0.00046856491826474667
Test Loss:  0.0005691410624422133
Valid Loss:  0.0005693137063644826
Epoch:  106  	Training Loss: 0.000467910198494792
Test Loss:  0.0005680570611730218
Valid Loss:  0.0005686322692781687
Epoch:  107  	Training Loss: 0.0004672861541621387
Test Loss:  0.0005667089717462659
Valid Loss:  0.0005679047899320722
Epoch:  108  	Training Loss: 0.00046667925198562443
Test Loss:  0.0005652378313243389
Valid Loss:  0.000567161594517529
Epoch:  109  	Training Loss: 0.00046608690172433853
Test Loss:  0.0005637173308059573
Valid Loss:  0.0005664150812663138
Epoch:  110  	Training Loss: 0.00046550348633900285
Test Loss:  0.0005621820455417037
Valid Loss:  0.0005656721186824143
Epoch:  111  	Training Loss: 0.00046492787078022957
Test Loss:  0.0005606593331322074
Valid Loss:  0.000564936432056129
Epoch:  112  	Training Loss: 0.000464360840851441
Test Loss:  0.0005585612962022424
Valid Loss:  0.0005645777564495802
Epoch:  113  	Training Loss: 0.00046422219020314515
Test Loss:  0.0005566331674344838
Valid Loss:  0.0005642580799758434
Epoch:  114  	Training Loss: 0.00046410365030169487
Test Loss:  0.0005548574845306575
Valid Loss:  0.0005639715818688273
Epoch:  115  	Training Loss: 0.0004640013794414699
Test Loss:  0.0005532225477509201
Valid Loss:  0.0005637158174067736
Epoch:  116  	Training Loss: 0.00046391342766582966
Test Loss:  0.0005517179379239678
Valid Loss:  0.0005634858971461654
Epoch:  117  	Training Loss: 0.00046383831067942083
Test Loss:  0.0005503307329490781
Valid Loss:  0.000563279667403549
Epoch:  118  	Training Loss: 0.0004637730307877064
Test Loss:  0.0005490526091307402
Valid Loss:  0.0005630947998724878
Epoch:  119  	Training Loss: 0.0004637170641217381
Test Loss:  0.0005478743696585298
Valid Loss:  0.0005629279185086489
Epoch:  120  	Training Loss: 0.00046366878086701035
Test Loss:  0.0005467880982905626
Valid Loss:  0.0005627775099128485
Epoch:  121  	Training Loss: 0.0004636271041817963
Test Loss:  0.0005457861698232591
Valid Loss:  0.0005626423517242074
Epoch:  122  	Training Loss: 0.0004635911900550127
Test Loss:  0.0005397698259912431
Valid Loss:  0.000561774882953614
Epoch:  123  	Training Loss: 0.0004633002099581063
Test Loss:  0.0005364888929761946
Valid Loss:  0.0005612870445474982
Epoch:  124  	Training Loss: 0.0004631083575077355
Test Loss:  0.0005346061661839485
Valid Loss:  0.0005609669024124742
Epoch:  125  	Training Loss: 0.00046294386265799403
Test Loss:  0.0005334472516551614
Valid Loss:  0.0005607271450571716
Epoch:  126  	Training Loss: 0.00046278757508844137
Test Loss:  0.0005326641257852316
Valid Loss:  0.0005605265032500029
Epoch:  127  	Training Loss: 0.00046263428521342576
Test Loss:  0.0005320767522789538
Valid Loss:  0.0005603456520475447
Epoch:  128  	Training Loss: 0.00046248198486864567
Test Loss:  0.0005315927555784583
Valid Loss:  0.0005601765587925911
Epoch:  129  	Training Loss: 0.000462330412119627
Test Loss:  0.0005311628920026124
Valid Loss:  0.0005600197473540902
Epoch:  130  	Training Loss: 0.00046218003262765706
Test Loss:  0.000530762248672545
Valid Loss:  0.0005598666612058878
Epoch:  131  	Training Loss: 0.00046203023521229625
Test Loss:  0.0005303768557496369
Valid Loss:  0.0005597159615717828
Epoch:  132  	Training Loss: 0.0004618810780812055
Test Loss:  0.0005297423340380192
Valid Loss:  0.000558984000235796
Epoch:  133  	Training Loss: 0.0004612267075572163
Test Loss:  0.0005284104263409972
Valid Loss:  0.0005584058817476034
Epoch:  134  	Training Loss: 0.00046071482938714325
Test Loss:  0.0005269168759696186
Valid Loss:  0.0005578803247772157
Epoch:  135  	Training Loss: 0.00046023615868762136
Test Loss:  0.0005254533607512712
Valid Loss:  0.0005573906237259507
Epoch:  136  	Training Loss: 0.00045977113768458366
Test Loss:  0.0005240868194960058
Valid Loss:  0.0005569251952692866
Epoch:  137  	Training Loss: 0.0004593156627379358
Test Loss:  0.0005228068330325186
Valid Loss:  0.0005564842722378671
 28%|██▊       | 139/500 [01:56<02:01,  2.96it/s] 28%|██▊       | 141/500 [02:03<07:08,  1.19s/it] 29%|██▊       | 143/500 [02:03<05:05,  1.17it/s] 29%|██▉       | 145/500 [02:03<03:39,  1.61it/s] 29%|██▉       | 147/500 [02:03<02:40,  2.20it/s] 30%|██▉       | 149/500 [02:03<01:58,  2.97it/s] 30%|███       | 151/500 [02:10<07:02,  1.21s/it] 31%|███       | 153/500 [02:10<05:02,  1.15it/s] 31%|███       | 155/500 [02:10<03:37,  1.59it/s] 31%|███▏      | 157/500 [02:10<02:38,  2.16it/s] 32%|███▏      | 159/500 [02:10<01:59,  2.86it/s] 32%|███▏      | 161/500 [02:17<06:59,  1.24s/it] 33%|███▎      | 163/500 [02:17<05:00,  1.12it/s] 33%|███▎      | 165/500 [02:17<03:37,  1.54it/s] 33%|███▎      | 167/500 [02:17<02:38,  2.10it/s] 34%|███▍      | 169/500 [02:17<01:56,  2.83it/s] 34%|███▍      | 171/500 [02:24<06:37,  1.21s/it] 35%|███▍      | 173/500 [02:24<04:43,  1.15it/s] 35%|███▌      | 175/500 [02:24<03:24,  1.59it/s] 35%|███▌      | 177/500 [02:24<02:28,  2.17it/s] 36%|███▌      | 179/500 [02:24<01:50,  2.91it/s] 36%|███▌      | 181/500 [02:31<06:21,  1.20s/it] 37%|███▋      | 183/500 [02:31<04:34,  1.16it/s] 37%|███▋      | 185/500 [02:31<03:18,  1.58it/s] 37%|███▋      | 187/500 [02:31<02:24,  2.16it/s] 38%|███▊      | 189/500 [02:31<01:46,  2.91it/s] 38%|███▊      | 191/500 [02:38<06:13,  1.21s/it] 39%|███▊      | 193/500 [02:38<04:27,  1.15it/s] 39%|███▉      | 195/500 [02:38<03:12,  1.59it/s] 39%|███▉      | 197/500 [02:38<02:20,  2.16it/s] 40%|███▉      | 199/500 [02:39<01:45,  2.86it/s] 40%|████      | 201/500 [02:45<06:05,  1.22s/it] 41%|████      | 203/500 [02:45<04:20,  1.14it/s] 41%|████      | 205/500 [02:45<03:07,  1.58it/s]Epoch:  138  	Training Loss: 0.0004588834708556533
Test Loss:  0.0005216182908043265
Valid Loss:  0.0005560695426538587
Epoch:  139  	Training Loss: 0.0004584801790770143
Test Loss:  0.000520526256877929
Valid Loss:  0.0005556840915232897
Epoch:  140  	Training Loss: 0.0004580938839353621
Test Loss:  0.0005194735713303089
Valid Loss:  0.0005553169175982475
Epoch:  141  	Training Loss: 0.0004577159706968814
Test Loss:  0.0005184686160646379
Valid Loss:  0.000554965459741652
Epoch:  142  	Training Loss: 0.00045735444291494787
Test Loss:  0.0005182609893381596
Valid Loss:  0.000554987695068121
Epoch:  143  	Training Loss: 0.00045730749843642116
Test Loss:  0.0005180917796678841
Valid Loss:  0.0005549966008402407
Epoch:  144  	Training Loss: 0.00045726876123808324
Test Loss:  0.0005179427680559456
Valid Loss:  0.0005549959023483098
Epoch:  145  	Training Loss: 0.00045723305083811283
Test Loss:  0.0005178051069378853
Valid Loss:  0.0005549897905439138
Epoch:  146  	Training Loss: 0.00045719859190285206
Test Loss:  0.0005176737904548645
Valid Loss:  0.0005549811758100986
Epoch:  147  	Training Loss: 0.0004571647441480309
Test Loss:  0.0005175480619072914
Valid Loss:  0.0005549709894694388
Epoch:  148  	Training Loss: 0.0004571318859234452
Test Loss:  0.0005174271645955741
Valid Loss:  0.0005549610359594226
Epoch:  149  	Training Loss: 0.0004570994060486555
Test Loss:  0.0005173093522898853
Valid Loss:  0.0005549503839574754
Epoch:  150  	Training Loss: 0.0004570677992887795
Test Loss:  0.0005171948578208685
Valid Loss:  0.0005549404304474592
Epoch:  151  	Training Loss: 0.0004570364544633776
Test Loss:  0.0005170837393961847
Valid Loss:  0.0005549308843910694
Epoch:  152  	Training Loss: 0.0004570060991682112
Test Loss:  0.0005165991024114192
Valid Loss:  0.0005544091109186411
Epoch:  153  	Training Loss: 0.0004563750990200788
Test Loss:  0.0005160045111551881
Valid Loss:  0.0005539023550227284
Epoch:  154  	Training Loss: 0.0004557734646368772
Test Loss:  0.0005153226666152477
Valid Loss:  0.0005533847725018859
Epoch:  155  	Training Loss: 0.00045519397826865315
Test Loss:  0.0005145786562934518
Valid Loss:  0.0005528869805857539
Epoch:  156  	Training Loss: 0.0004546456038951874
Test Loss:  0.0005137913976795971
Valid Loss:  0.0005524182925000787
Epoch:  157  	Training Loss: 0.0004541263042483479
Test Loss:  0.000512955361045897
Valid Loss:  0.0005519639234989882
Epoch:  158  	Training Loss: 0.0004536228661891073
Test Loss:  0.0005120811983942986
Valid Loss:  0.0005515202647075057
Epoch:  159  	Training Loss: 0.0004531393351498991
Test Loss:  0.0005112013895995915
Valid Loss:  0.0005510908085852861
Epoch:  160  	Training Loss: 0.00045267667155712843
Test Loss:  0.000510334619320929
Valid Loss:  0.000550679222214967
Epoch:  161  	Training Loss: 0.0004522429371718317
Test Loss:  0.0005094776279293001
Valid Loss:  0.0005502876592800021
Epoch:  162  	Training Loss: 0.0004518390924204141
Test Loss:  0.0005075832596048713
Valid Loss:  0.0005501247942447662
Epoch:  163  	Training Loss: 0.0004518189816735685
Test Loss:  0.0005072294152341783
Valid Loss:  0.0005501102423295379
Epoch:  164  	Training Loss: 0.0004518050409387797
Test Loss:  0.000507008982822299
Valid Loss:  0.0005501073319464922
Epoch:  165  	Training Loss: 0.00045179208973422647
Test Loss:  0.0005068235332146287
Valid Loss:  0.0005501050036400557
Epoch:  166  	Training Loss: 0.0004517798952292651
Test Loss:  0.0005066590383648872
Valid Loss:  0.0005501026753336191
Epoch:  167  	Training Loss: 0.0004517679044511169
Test Loss:  0.0005065119476057589
Valid Loss:  0.0005501010455191135
Epoch:  168  	Training Loss: 0.00045175643754191697
Test Loss:  0.0005063812714070082
Valid Loss:  0.0005500992992892861
Epoch:  169  	Training Loss: 0.00045174540719017386
Test Loss:  0.0005062647978775203
Valid Loss:  0.0005500981351360679
Epoch:  170  	Training Loss: 0.0004517346969805658
Test Loss:  0.0005061563570052385
Valid Loss:  0.0005500955739989877
Epoch:  171  	Training Loss: 0.0004517242487054318
Test Loss:  0.0005060581606812775
Valid Loss:  0.0005500934785231948
Epoch:  172  	Training Loss: 0.00045171380043029785
Test Loss:  0.0005064675351604819
Valid Loss:  0.0005495866062119603
Epoch:  173  	Training Loss: 0.0004513449384830892
Test Loss:  0.0005062487907707691
Valid Loss:  0.0005492728669196367
Epoch:  174  	Training Loss: 0.00045105916797183454
Test Loss:  0.0005057922098785639
Valid Loss:  0.0005489777540788054
Epoch:  175  	Training Loss: 0.0004507963312789798
Test Loss:  0.0005052736960351467
Valid Loss:  0.0005487033631652594
Epoch:  176  	Training Loss: 0.0004505472898017615
Test Loss:  0.00050472462316975
Valid Loss:  0.0005484368884935975
Epoch:  177  	Training Loss: 0.0004503115778788924
Test Loss:  0.0005041647236794233
Valid Loss:  0.0005481763510033488
Epoch:  178  	Training Loss: 0.0004500900686252862
Test Loss:  0.0005034460918977857
Valid Loss:  0.0005479562096297741
Epoch:  179  	Training Loss: 0.0004498928028624505
Test Loss:  0.0005026867147535086
Valid Loss:  0.0005477619124576449
Epoch:  180  	Training Loss: 0.00044971099123358727
Test Loss:  0.0005019830423407257
Valid Loss:  0.0005475819343701005
Epoch:  181  	Training Loss: 0.00044954323675483465
Test Loss:  0.0005013237241655588
Valid Loss:  0.0005474112695083022
Epoch:  182  	Training Loss: 0.00044938488281331956
Test Loss:  0.0005073743523098528
Valid Loss:  0.0005391280283220112
Epoch:  183  	Training Loss: 0.0004447604587767273
Test Loss:  0.0005132175283506513
Valid Loss:  0.000531559344381094
Epoch:  184  	Training Loss: 0.00044056918704882264
Test Loss:  0.0005188228096812963
Valid Loss:  0.0005246168002486229
Epoch:  185  	Training Loss: 0.0004363696789368987
Test Loss:  0.0005263703060336411
Valid Loss:  0.0005168211064301431
Epoch:  186  	Training Loss: 0.00043144283699803054
Test Loss:  0.0005336716421879828
Valid Loss:  0.0005097272805869579
Epoch:  187  	Training Loss: 0.00042698014294728637
Test Loss:  0.0005407090066000819
Valid Loss:  0.0005032625049352646
Epoch:  188  	Training Loss: 0.0004229330806992948
Test Loss:  0.0005474580102600157
Valid Loss:  0.0004973500035703182
Epoch:  189  	Training Loss: 0.0004192402702756226
Test Loss:  0.0005539040430448949
Valid Loss:  0.0004919265629723668
Epoch:  190  	Training Loss: 0.0004158600349910557
Test Loss:  0.0005588107742369175
Valid Loss:  0.00048694032011553645
Epoch:  191  	Training Loss: 0.000412758527090773
Test Loss:  0.0005634709377773106
Valid Loss:  0.0004823403141926974
Epoch:  192  	Training Loss: 0.0004098975914530456
Test Loss:  0.0005594856338575482
Valid Loss:  0.0004811932158190757
Epoch:  193  	Training Loss: 0.0004094990435987711
Test Loss:  0.0005567196058109403
Valid Loss:  0.0004804452182725072
Epoch:  194  	Training Loss: 0.00040929100941866636
Test Loss:  0.0005547761102207005
Valid Loss:  0.00047994102351367474
Epoch:  195  	Training Loss: 0.00040917578735388815
Test Loss:  0.0005533718504011631
Valid Loss:  0.00047958522918634117
Epoch:  196  	Training Loss: 0.0004091045702807605
Test Loss:  0.0005523462314158678
Valid Loss:  0.0004793249536305666
Epoch:  197  	Training Loss: 0.00040905707282945514
Test Loss:  0.0005515632219612598
Valid Loss:  0.00047912198351696134
Epoch:  198  	Training Loss: 0.0004090182192157954
Test Loss:  0.0005509605980478227
Valid Loss:  0.0004789624363183975
Epoch:  199  	Training Loss: 0.00040898629231378436
Test Loss:  0.0005504842265509069
Valid Loss:  0.0004788332153111696
Epoch:  200  	Training Loss: 0.00040895765414461493
Test Loss:  0.0005500958068296313
Valid Loss:  0.0004787234356626868
Epoch:  201  	Training Loss: 0.0004089310532435775
Test Loss:  0.0005497511010617018
Valid Loss:  0.000478624424431473
Epoch:  202  	Training Loss: 0.00040890375385060906
Test Loss:  0.0005439927917905152
Valid Loss:  0.00047335991985164583
Epoch:  203  	Training Loss: 0.00040615920443087816
Test Loss:  0.0005441958201117814
Valid Loss:  0.0004692120710387826
Epoch:  204  	Training Loss: 0.00040356721729040146
Test Loss:  0.0005415033083409071
Valid Loss:  0.0004647487949114293
Epoch:  205  	Training Loss: 0.00040111126145347953
Test Loss:  0.0005408609285950661
Valid Loss:  0.00046074221609160304
 41%|████▏     | 207/500 [02:45<02:15,  2.16it/s] 42%|████▏     | 209/500 [02:46<01:40,  2.91it/s] 42%|████▏     | 211/500 [02:52<05:43,  1.19s/it] 43%|████▎     | 213/500 [02:52<04:04,  1.17it/s] 43%|████▎     | 215/500 [02:52<02:55,  1.62it/s] 43%|████▎     | 217/500 [02:52<02:09,  2.19it/s] 44%|████▍     | 219/500 [02:52<01:35,  2.93it/s] 44%|████▍     | 221/500 [02:59<05:39,  1.22s/it] 45%|████▍     | 223/500 [02:59<04:01,  1.15it/s] 45%|████▌     | 225/500 [02:59<02:53,  1.59it/s] 45%|████▌     | 227/500 [02:59<02:06,  2.15it/s] 46%|████▌     | 229/500 [03:00<01:35,  2.85it/s] 46%|████▌     | 231/500 [03:06<05:24,  1.21s/it] 47%|████▋     | 233/500 [03:06<03:52,  1.15it/s] 47%|████▋     | 235/500 [03:06<02:48,  1.58it/s] 47%|████▋     | 237/500 [03:06<02:01,  2.16it/s] 48%|████▊     | 239/500 [03:07<01:29,  2.91it/s] 48%|████▊     | 241/500 [03:13<05:07,  1.19s/it] 49%|████▊     | 243/500 [03:13<03:39,  1.17it/s] 49%|████▉     | 245/500 [03:13<02:37,  1.62it/s] 49%|████▉     | 247/500 [03:13<01:54,  2.22it/s] 50%|████▉     | 249/500 [03:13<01:24,  2.99it/s] 50%|█████     | 251/500 [03:20<04:58,  1.20s/it] 51%|█████     | 253/500 [03:20<03:32,  1.16it/s] 51%|█████     | 255/500 [03:20<02:32,  1.60it/s] 51%|█████▏    | 257/500 [03:20<01:52,  2.17it/s] 52%|█████▏    | 259/500 [03:20<01:24,  2.87it/s] 52%|█████▏    | 261/500 [03:27<04:45,  1.20s/it] 53%|█████▎    | 263/500 [03:27<03:23,  1.16it/s] 53%|█████▎    | 265/500 [03:27<02:25,  1.61it/s] 53%|█████▎    | 267/500 [03:27<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:27<01:18,  2.95it/s] 54%|█████▍    | 271/500 [03:34<04:34,  1.20s/it]Epoch:  206  	Training Loss: 0.0003987792879343033
Test Loss:  0.0005394036998040974
Valid Loss:  0.00045680481707677245
Epoch:  207  	Training Loss: 0.0003965619544032961
Test Loss:  0.0005387029377743602
Valid Loss:  0.0004532499297056347
Epoch:  208  	Training Loss: 0.0003944509953726083
Test Loss:  0.0005378247005864978
Valid Loss:  0.00044979495578445494
Epoch:  209  	Training Loss: 0.0003924397751688957
Test Loss:  0.0005372633459046483
Valid Loss:  0.0004465065721888095
Epoch:  210  	Training Loss: 0.000390522473026067
Test Loss:  0.0005367078119888902
Valid Loss:  0.0004433373105712235
Epoch:  211  	Training Loss: 0.00038869254058226943
Test Loss:  0.0005363088566809893
Valid Loss:  0.00044030428398400545
Epoch:  212  	Training Loss: 0.00038694654358550906
Test Loss:  0.000536664214450866
Valid Loss:  0.0004363908665254712
Epoch:  213  	Training Loss: 0.0003845791216008365
Test Loss:  0.0005372983287088573
Valid Loss:  0.0004327463684603572
Epoch:  214  	Training Loss: 0.00038232715451158583
Test Loss:  0.0005377460038289428
Valid Loss:  0.0004292925586923957
Epoch:  215  	Training Loss: 0.00038017844781279564
Test Loss:  0.0005380187649279833
Valid Loss:  0.0004260085988789797
Epoch:  216  	Training Loss: 0.0003781228151638061
Test Loss:  0.0005381429800763726
Valid Loss:  0.00042288031545467675
Epoch:  217  	Training Loss: 0.00037615152541548014
Test Loss:  0.0005381429218687117
Valid Loss:  0.0004198933020234108
Epoch:  218  	Training Loss: 0.0003742577973753214
Test Loss:  0.0005380391958169639
Valid Loss:  0.00041703740134835243
Epoch:  219  	Training Loss: 0.0003724351117853075
Test Loss:  0.0005378491478040814
Valid Loss:  0.0004143031546846032
Epoch:  220  	Training Loss: 0.00037055567372590303
Test Loss:  0.0005397481727413833
Valid Loss:  0.0004111567686777562
Epoch:  221  	Training Loss: 0.0003684221301227808
Test Loss:  0.0005409079603850842
Valid Loss:  0.0004081331135239452
Epoch:  222  	Training Loss: 0.0003663959796540439
Test Loss:  0.000546645256690681
Valid Loss:  0.0004059263155795634
Epoch:  223  	Training Loss: 0.0003646712866611779
Test Loss:  0.0005506681045517325
Valid Loss:  0.0004037855542264879
Epoch:  224  	Training Loss: 0.0003630933351814747
Test Loss:  0.0005539460107684135
Valid Loss:  0.0004017688916064799
Epoch:  225  	Training Loss: 0.0003616516478359699
Test Loss:  0.000556772225536406
Valid Loss:  0.00039996637497097254
Epoch:  226  	Training Loss: 0.0003604334779083729
Test Loss:  0.0005592626985162497
Valid Loss:  0.0003982753260061145
Epoch:  227  	Training Loss: 0.0003592781431507319
Test Loss:  0.0005614532856270671
Valid Loss:  0.00039668011595495045
Epoch:  228  	Training Loss: 0.000358175253495574
Test Loss:  0.0005633541732095182
Valid Loss:  0.00039516587276011705
Epoch:  229  	Training Loss: 0.00035711482632905245
Test Loss:  0.0005650054663419724
Valid Loss:  0.00039372354513034225
Epoch:  230  	Training Loss: 0.00035609109909273684
Test Loss:  0.0005664096679538488
Valid Loss:  0.00039234079304151237
Epoch:  231  	Training Loss: 0.00035509816370904446
Test Loss:  0.0005676066502928734
Valid Loss:  0.0003910125815309584
Epoch:  232  	Training Loss: 0.0003541304904501885
Test Loss:  0.0005582724697887897
Valid Loss:  0.0003890368971042335
Epoch:  233  	Training Loss: 0.00035251822555437684
Test Loss:  0.0005546555621549487
Valid Loss:  0.0003878378192894161
Epoch:  234  	Training Loss: 0.000351063150446862
Test Loss:  0.0005498347454704344
Valid Loss:  0.00038662596489302814
Epoch:  235  	Training Loss: 0.0003497211146168411
Test Loss:  0.0005460222018882632
Valid Loss:  0.0003855268587358296
Epoch:  236  	Training Loss: 0.000348465982824564
Test Loss:  0.0005421918467618525
Valid Loss:  0.0003844495804514736
Epoch:  237  	Training Loss: 0.00034726079320535064
Test Loss:  0.0005384985124692321
Valid Loss:  0.0003834209928754717
Epoch:  238  	Training Loss: 0.00034609815338626504
Test Loss:  0.0005350110004656017
Valid Loss:  0.00038258489803411067
Epoch:  239  	Training Loss: 0.0003449789946898818
Test Loss:  0.0005317839095368981
Valid Loss:  0.000381775462301448
Epoch:  240  	Training Loss: 0.00034391641383990645
Test Loss:  0.0005287203821353614
Valid Loss:  0.00038097097421996295
Epoch:  241  	Training Loss: 0.00034288890310563147
Test Loss:  0.0005257613374851644
Valid Loss:  0.00038019835483282804
Epoch:  242  	Training Loss: 0.0003418977721594274
Test Loss:  0.0005229667876847088
Valid Loss:  0.00037988790427334607
Epoch:  243  	Training Loss: 0.0003417719854041934
Test Loss:  0.0005207813810557127
Valid Loss:  0.00037962468923069537
Epoch:  244  	Training Loss: 0.0003416868858039379
Test Loss:  0.000518937420565635
Valid Loss:  0.0003794123767875135
Epoch:  245  	Training Loss: 0.0003416206454858184
Test Loss:  0.0005173783283680677
Valid Loss:  0.0003792384814005345
Epoch:  246  	Training Loss: 0.0003415672981645912
Test Loss:  0.0005160529399290681
Valid Loss:  0.0003790946211665869
Epoch:  247  	Training Loss: 0.0003415235551074147
Test Loss:  0.0005149196367710829
Valid Loss:  0.0003789748589042574
Epoch:  248  	Training Loss: 0.0003414867096580565
Test Loss:  0.0005139490822330117
Valid Loss:  0.0003788734320551157
Epoch:  249  	Training Loss: 0.00034145472454838455
Test Loss:  0.0005131111829541624
Valid Loss:  0.0003787871391978115
Epoch:  250  	Training Loss: 0.0003414259699638933
Test Loss:  0.000512385624460876
Valid Loss:  0.00037871257518418133
Epoch:  251  	Training Loss: 0.0003413999220356345
Test Loss:  0.0005117512191645801
Valid Loss:  0.0003786479355767369
Epoch:  252  	Training Loss: 0.00034137588227167726
Test Loss:  0.0005133966915309429
Valid Loss:  0.00037710805190727115
Epoch:  253  	Training Loss: 0.0003404278540983796
Test Loss:  0.0005147048505023122
Valid Loss:  0.00037563283694908023
Epoch:  254  	Training Loss: 0.00033953620004467666
Test Loss:  0.0005157737759873271
Valid Loss:  0.00037421181332319975
Epoch:  255  	Training Loss: 0.0003386910248082131
Test Loss:  0.0005166835617274046
Valid Loss:  0.0003728497540578246
Epoch:  256  	Training Loss: 0.0003378946566954255
Test Loss:  0.0005174725083634257
Valid Loss:  0.0003715437778737396
Epoch:  257  	Training Loss: 0.00033714048913680017
Test Loss:  0.0005181579617783427
Valid Loss:  0.00037028922815807164
Epoch:  258  	Training Loss: 0.0003364229341968894
Test Loss:  0.00051875039935112
Valid Loss:  0.00036908272886648774
Epoch:  259  	Training Loss: 0.0003357388195581734
Test Loss:  0.000519281136803329
Valid Loss:  0.0003679220099002123
Epoch:  260  	Training Loss: 0.00033508415799587965
Test Loss:  0.000519760767929256
Valid Loss:  0.00036680515040643513
Epoch:  261  	Training Loss: 0.0003344469587318599
Test Loss:  0.0005201824242249131
Valid Loss:  0.00036571809323504567
Epoch:  262  	Training Loss: 0.0003338218084536493
Test Loss:  0.0005304993828758597
Valid Loss:  0.00036674400325864553
Epoch:  263  	Training Loss: 0.00033321749651804566
Test Loss:  0.0005276718875393271
Valid Loss:  0.00036617350997403264
Epoch:  264  	Training Loss: 0.0003329624596517533
Test Loss:  0.0005293901194818318
Valid Loss:  0.0003663139941636473
Epoch:  265  	Training Loss: 0.00033277866896241903
Test Loss:  0.0005294674192555249
Valid Loss:  0.0003662349481601268
Epoch:  266  	Training Loss: 0.0003326292207930237
Test Loss:  0.0005300383782014251
Valid Loss:  0.00036624702624976635
Epoch:  267  	Training Loss: 0.00033250555861741304
Test Loss:  0.0005303926300257444
Valid Loss:  0.0003662348899524659
Epoch:  268  	Training Loss: 0.0003324012504890561
Test Loss:  0.00053076958283782
Valid Loss:  0.00036623748019337654
Epoch:  269  	Training Loss: 0.0003323137934785336
Test Loss:  0.0005310924025252461
Valid Loss:  0.000366238527931273
Epoch:  270  	Training Loss: 0.0003322390839457512
Test Loss:  0.0005313859437592328
Valid Loss:  0.00036624091444537044
Epoch:  271  	Training Loss: 0.00033217412419617176
Test Loss:  0.0005316464812494814
Valid Loss:  0.0003662430972326547
Epoch:  272  	Training Loss: 0.00033211795380339026
Test Loss:  0.0005286931991577148
Valid Loss:  0.0003658216737676412
Epoch:  273  	Training Loss: 0.0003318917006254196
Test Loss:  0.0005278869066387415
Valid Loss:   55%|█████▍    | 273/500 [03:34<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:34<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:34<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:34<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:41<04:26,  1.22s/it] 57%|█████▋    | 283/500 [03:41<03:09,  1.14it/s] 57%|█████▋    | 285/500 [03:41<02:17,  1.57it/s] 57%|█████▋    | 287/500 [03:41<01:40,  2.12it/s] 58%|█████▊    | 289/500 [03:42<01:15,  2.81it/s] 58%|█████▊    | 291/500 [03:48<04:18,  1.24s/it] 59%|█████▊    | 293/500 [03:48<03:03,  1.13it/s] 59%|█████▉    | 295/500 [03:48<02:11,  1.56it/s] 59%|█████▉    | 297/500 [03:48<01:34,  2.14it/s] 60%|█████▉    | 299/500 [03:49<01:09,  2.89it/s] 60%|██████    | 301/500 [03:55<03:58,  1.20s/it] 61%|██████    | 303/500 [03:55<02:49,  1.16it/s] 61%|██████    | 305/500 [03:55<02:01,  1.61it/s] 61%|██████▏   | 307/500 [03:55<01:27,  2.20it/s] 62%|██████▏   | 309/500 [03:56<01:04,  2.96it/s] 62%|██████▏   | 311/500 [04:02<03:44,  1.19s/it] 63%|██████▎   | 313/500 [04:02<02:39,  1.17it/s] 63%|██████▎   | 315/500 [04:02<01:53,  1.62it/s] 63%|██████▎   | 317/500 [04:02<01:22,  2.22it/s] 64%|██████▍   | 319/500 [04:02<01:00,  2.99it/s] 64%|██████▍   | 321/500 [04:09<03:38,  1.22s/it] 65%|██████▍   | 323/500 [04:09<02:35,  1.14it/s] 65%|██████▌   | 325/500 [04:09<01:50,  1.58it/s] 65%|██████▌   | 327/500 [04:09<01:20,  2.16it/s] 66%|██████▌   | 329/500 [04:10<00:59,  2.90it/s] 66%|██████▌   | 331/500 [04:16<03:26,  1.22s/it] 67%|██████▋   | 333/500 [04:16<02:26,  1.14it/s] 67%|██████▋   | 335/500 [04:16<01:44,  1.58it/s] 67%|██████▋   | 337/500 [04:16<01:15,  2.16it/s] 68%|██████▊   | 339/500 [04:17<00:55,  2.92it/s]0.00036573209217749536
Epoch:  274  	Training Loss: 0.0003316801739856601
Test Loss:  0.0005245477659627795
Valid Loss:  0.00036523977178148925
Epoch:  275  	Training Loss: 0.0003314778150524944
Test Loss:  0.0005242573097348213
Valid Loss:  0.00036520668072625995
Epoch:  276  	Training Loss: 0.0003312818007543683
Test Loss:  0.0005217329598963261
Valid Loss:  0.00036482600262388587
Epoch:  277  	Training Loss: 0.00033108959905803204
Test Loss:  0.0005209230585023761
Valid Loss:  0.0003646978293545544
Epoch:  278  	Training Loss: 0.00033090534270741045
Test Loss:  0.0005193810793571174
Valid Loss:  0.00036445457953959703
Epoch:  279  	Training Loss: 0.0003307269944343716
Test Loss:  0.0005183774046599865
Valid Loss:  0.00036428560269996524
Epoch:  280  	Training Loss: 0.0003305527498014271
Test Loss:  0.0005171799566596746
Valid Loss:  0.0003640836221165955
Epoch:  281  	Training Loss: 0.00033038348192349076
Test Loss:  0.0005162128363735974
Valid Loss:  0.00036391045432537794
Epoch:  282  	Training Loss: 0.000330217182636261
Test Loss:  0.0005166175542399287
Valid Loss:  0.00036397407529875636
Epoch:  283  	Training Loss: 0.00033021491253748536
Test Loss:  0.0005167335039004683
Valid Loss:  0.0003639923525042832
Epoch:  284  	Training Loss: 0.0003302136901766062
Test Loss:  0.0005167749477550387
Valid Loss:  0.00036399878445081413
Epoch:  285  	Training Loss: 0.00033021304989233613
Test Loss:  0.0005167979397810996
Valid Loss:  0.00036400207318365574
Epoch:  286  	Training Loss: 0.0003302122640889138
Test Loss:  0.0005168148200027645
Valid Loss:  0.000364004576113075
Epoch:  287  	Training Loss: 0.00033021142007783055
Test Loss:  0.0005168318166397512
Valid Loss:  0.00036400696262717247
Epoch:  288  	Training Loss: 0.0003302107215858996
Test Loss:  0.0005168473580852151
Valid Loss:  0.0003640096983872354
Epoch:  289  	Training Loss: 0.0003302099066786468
Test Loss:  0.0005168630741536617
Valid Loss:  0.0003640117356553674
Epoch:  290  	Training Loss: 0.00033020914997905493
Test Loss:  0.0005168784991838038
Valid Loss:  0.00036401423858478665
Epoch:  291  	Training Loss: 0.00033020833507180214
Test Loss:  0.0005168935749679804
Valid Loss:  0.00036401586839929223
Epoch:  292  	Training Loss: 0.00033020757837221026
Test Loss:  0.0005119076813571155
Valid Loss:  0.0003623765951488167
Epoch:  293  	Training Loss: 0.000329538801452145
Test Loss:  0.0005093614454381168
Valid Loss:  0.0003610796993598342
Epoch:  294  	Training Loss: 0.0003290247987024486
Test Loss:  0.0005082901334390044
Valid Loss:  0.0003599793999455869
Epoch:  295  	Training Loss: 0.00032858873601071537
Test Loss:  0.0005081130657345057
Valid Loss:  0.0003590065171010792
Epoch:  296  	Training Loss: 0.00032819941407069564
Test Loss:  0.0005084779113531113
Valid Loss:  0.00035812397254630923
Epoch:  297  	Training Loss: 0.00032784463837742805
Test Loss:  0.0005091655184514821
Valid Loss:  0.0003573111607693136
Epoch:  298  	Training Loss: 0.0003275172202847898
Test Loss:  0.0005100426496937871
Valid Loss:  0.00035655556712299585
Epoch:  299  	Training Loss: 0.00032721401657909155
Test Loss:  0.0005109255434945226
Valid Loss:  0.000355848838808015
Epoch:  300  	Training Loss: 0.00032693264074623585
Test Loss:  0.0005115130916237831
Valid Loss:  0.0003551859699655324
Epoch:  301  	Training Loss: 0.00032667163759469986
Test Loss:  0.0005121378926560283
Valid Loss:  0.0003545623039826751
Epoch:  302  	Training Loss: 0.00032642928999848664
Test Loss:  0.0005116333486512303
Valid Loss:  0.00035433104494586587
Epoch:  303  	Training Loss: 0.0003260899684391916
Test Loss:  0.0005111708305776119
Valid Loss:  0.00035411224234849215
Epoch:  304  	Training Loss: 0.0003257617063354701
Test Loss:  0.000510739628225565
Valid Loss:  0.0003539014724083245
Epoch:  305  	Training Loss: 0.00032544429996050894
Test Loss:  0.0005104247247800231
Valid Loss:  0.0003536923322826624
Epoch:  306  	Training Loss: 0.00032513399492017925
Test Loss:  0.0005101363640278578
Valid Loss:  0.00035348854726180434
Epoch:  307  	Training Loss: 0.0003248280263505876
Test Loss:  0.0005098695401102304
Valid Loss:  0.00035328976809978485
Epoch:  308  	Training Loss: 0.0003245254629291594
Test Loss:  0.00050962227396667
Valid Loss:  0.0003530944522935897
Epoch:  309  	Training Loss: 0.0003242255188524723
Test Loss:  0.0005093847867101431
Valid Loss:  0.0003529027453623712
Epoch:  310  	Training Loss: 0.00032392810680903494
Test Loss:  0.000509160163346678
Valid Loss:  0.0003527134540490806
Epoch:  311  	Training Loss: 0.00032363185891881585
Test Loss:  0.0005089490441605449
Valid Loss:  0.0003525268111843616
Epoch:  312  	Training Loss: 0.0003233373281545937
Test Loss:  0.0005238077137619257
Valid Loss:  0.00035426439717411995
Epoch:  313  	Training Loss: 0.00032254314282909036
Test Loss:  0.0005012439796701074
Valid Loss:  0.00035142264096066356
Epoch:  314  	Training Loss: 0.00032197049586102366
Test Loss:  0.0005107378819957376
Valid Loss:  0.0003525337087921798
Epoch:  315  	Training Loss: 0.00032154846121557057
Test Loss:  0.0004959903308190405
Valid Loss:  0.00035084079718217254
Epoch:  316  	Training Loss: 0.0003212250885553658
Test Loss:  0.0005020670359954238
Valid Loss:  0.00035154831130057573
Epoch:  317  	Training Loss: 0.00032096877112053335
Test Loss:  0.0004922691150568426
Valid Loss:  0.00035049032885581255
Epoch:  318  	Training Loss: 0.00032075773924589157
Test Loss:  0.0004961300874128938
Valid Loss:  0.00035093631595373154
Epoch:  319  	Training Loss: 0.00032057793578132987
Test Loss:  0.0004895501770079136
Valid Loss:  0.0003502497565932572
Epoch:  320  	Training Loss: 0.0003204199019819498
Test Loss:  0.0004919500788673759
Valid Loss:  0.00035052208113484085
Epoch:  321  	Training Loss: 0.00032027834095060825
Test Loss:  0.0004874757141806185
Valid Loss:  0.0003500626189634204
Epoch:  322  	Training Loss: 0.00032014865428209305
Test Loss:  0.0004882534849457443
Valid Loss:  0.00034982949728146195
Epoch:  323  	Training Loss: 0.0003195621247868985
Test Loss:  0.000488937133923173
Valid Loss:  0.00034962582867592573
Epoch:  324  	Training Loss: 0.00031903019407764077
Test Loss:  0.0004894868470728397
Valid Loss:  0.00034942422644235194
Epoch:  325  	Training Loss: 0.00031851499807089567
Test Loss:  0.0004900232888758183
Valid Loss:  0.00034924695501103997
Epoch:  326  	Training Loss: 0.000318049278575927
Test Loss:  0.0004905036767013371
Valid Loss:  0.0003490836243145168
Epoch:  327  	Training Loss: 0.00031762378057464957
Test Loss:  0.0004909284762106836
Valid Loss:  0.00034892934490926564
Epoch:  328  	Training Loss: 0.0003172233991790563
Test Loss:  0.0004913238808512688
Valid Loss:  0.0003487790818326175
Epoch:  329  	Training Loss: 0.00031683273846283555
Test Loss:  0.0004916529287584126
Valid Loss:  0.0003486342029646039
Epoch:  330  	Training Loss: 0.0003164577065035701
Test Loss:  0.0004919135826639831
Valid Loss:  0.00034848699579015374
Epoch:  331  	Training Loss: 0.00031609227880835533
Test Loss:  0.0004921969957649708
Valid Loss:  0.00034835009137168527
Epoch:  332  	Training Loss: 0.0003157415776513517
Test Loss:  0.0004908659029752016
Valid Loss:  0.0003481837338767946
Epoch:  333  	Training Loss: 0.00031553718145005405
Test Loss:  0.0004896235768683255
Valid Loss:  0.00034802325535565615
Epoch:  334  	Training Loss: 0.00031533758738078177
Test Loss:  0.0004884328227490187
Valid Loss:  0.0003478692378848791
Epoch:  335  	Training Loss: 0.0003151431737933308
Test Loss:  0.0004872884601354599
Valid Loss:  0.0003477194986771792
Epoch:  336  	Training Loss: 0.00031495298026129603
Test Loss:  0.0004861825436819345
Valid Loss:  0.00034757429966703057
Epoch:  337  	Training Loss: 0.00031476846197620034
Test Loss:  0.0004851107078138739
Valid Loss:  0.0003474330878816545
Epoch:  338  	Training Loss: 0.0003145883674733341
Test Loss:  0.00048407423309981823
Valid Loss:  0.00034729609615169466
Epoch:  339  	Training Loss: 0.0003144130459986627
Test Loss:  0.00048307160614058375
Valid Loss:  0.0003471616073511541
Epoch:  340  	Training Loss: 0.0003142423229292035
Test Loss:  0.00048202378093264997
Valid Loss:  0.00034703940036706626
Epoch:  341  	Training Loss: 0.0003140746266581118
Test Loss:   68%|██████▊   | 341/500 [04:23<03:10,  1.20s/it] 69%|██████▊   | 343/500 [04:23<02:15,  1.16it/s] 69%|██████▉   | 345/500 [04:23<01:36,  1.60it/s] 69%|██████▉   | 347/500 [04:23<01:09,  2.19it/s] 70%|██████▉   | 349/500 [04:24<00:51,  2.95it/s] 70%|███████   | 351/500 [04:30<03:01,  1.22s/it] 71%|███████   | 353/500 [04:30<02:08,  1.15it/s] 71%|███████   | 355/500 [04:30<01:31,  1.59it/s] 71%|███████▏  | 357/500 [04:31<01:06,  2.14it/s] 72%|███████▏  | 359/500 [04:31<00:49,  2.84it/s] 72%|███████▏  | 361/500 [04:37<02:49,  1.22s/it] 73%|███████▎  | 363/500 [04:37<02:00,  1.14it/s] 73%|███████▎  | 365/500 [04:37<01:25,  1.58it/s] 73%|███████▎  | 367/500 [04:38<01:01,  2.16it/s] 74%|███████▍  | 369/500 [04:38<00:45,  2.91it/s] 74%|███████▍  | 371/500 [04:44<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:44<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:44<01:17,  1.62it/s] 75%|███████▌  | 377/500 [04:44<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:45<00:40,  2.98it/s] 76%|███████▌  | 381/500 [04:51<02:23,  1.21s/it] 77%|███████▋  | 383/500 [04:51<01:41,  1.15it/s] 77%|███████▋  | 385/500 [04:51<01:12,  1.60it/s] 77%|███████▋  | 387/500 [04:51<00:51,  2.18it/s] 78%|███████▊  | 389/500 [04:52<00:37,  2.92it/s] 78%|███████▊  | 391/500 [04:58<02:14,  1.23s/it] 79%|███████▊  | 393/500 [04:58<01:34,  1.13it/s] 79%|███████▉  | 395/500 [04:58<01:06,  1.57it/s] 79%|███████▉  | 397/500 [04:59<00:47,  2.15it/s] 80%|███████▉  | 399/500 [04:59<00:34,  2.89it/s] 80%|████████  | 401/500 [05:05<01:57,  1.19s/it] 81%|████████  | 403/500 [05:05<01:22,  1.17it/s] 81%|████████  | 405/500 [05:05<00:58,  1.62it/s] 81%|████████▏ | 407/500 [05:05<00:42,  2.21it/s]0.00048109301133081317
Valid Loss:  0.00034691282780840993
Epoch:  342  	Training Loss: 0.00031390890944749117
Test Loss:  0.0004815157735720277
Valid Loss:  0.0003470225492492318
Epoch:  343  	Training Loss: 0.00031388038769364357
Test Loss:  0.00048009087913669646
Valid Loss:  0.00034684455022215843
Epoch:  344  	Training Loss: 0.0003138537285849452
Test Loss:  0.0004806126235052943
Valid Loss:  0.0003469667863100767
Epoch:  345  	Training Loss: 0.00031382846646010876
Test Loss:  0.0004791480314452201
Valid Loss:  0.00034678270458243787
Epoch:  346  	Training Loss: 0.00031380471773445606
Test Loss:  0.0004797730944119394
Valid Loss:  0.0003469173680059612
Epoch:  347  	Training Loss: 0.00031378233688883483
Test Loss:  0.00047826056834310293
Valid Loss:  0.0003467261849436909
Epoch:  348  	Training Loss: 0.000313761382130906
Test Loss:  0.00047899194760248065
Valid Loss:  0.0003468738868832588
Epoch:  349  	Training Loss: 0.00031374170794151723
Test Loss:  0.0004774246481247246
Valid Loss:  0.0003466741763986647
Epoch:  350  	Training Loss: 0.00031372284865938127
Test Loss:  0.00047826662193983793
Valid Loss:  0.0003468353534117341
Epoch:  351  	Training Loss: 0.0003137053281534463
Test Loss:  0.00047663639998063445
Valid Loss:  0.0003466265625320375
Epoch:  352  	Training Loss: 0.0003136887971777469
Test Loss:  0.0004757262649945915
Valid Loss:  0.0003464389592409134
Epoch:  353  	Training Loss: 0.0003136401646770537
Test Loss:  0.0004750187508761883
Valid Loss:  0.00034626672277227044
Epoch:  354  	Training Loss: 0.0003135965671390295
Test Loss:  0.0004744703182950616
Valid Loss:  0.0003461072046775371
Epoch:  355  	Training Loss: 0.00031355713144876063
Test Loss:  0.00047404784709215164
Valid Loss:  0.000345957581885159
Epoch:  356  	Training Loss: 0.0003135199658572674
Test Loss:  0.0004737251147162169
Valid Loss:  0.00034581590443849564
Epoch:  357  	Training Loss: 0.0003134855651296675
Test Loss:  0.00047348072985187173
Valid Loss:  0.0003456808626651764
Epoch:  358  	Training Loss: 0.00031345232855528593
Test Loss:  0.00047329903463833034
Valid Loss:  0.00034555152524262667
Epoch:  359  	Training Loss: 0.0003134207217954099
Test Loss:  0.00047316617565229535
Valid Loss:  0.0003454270772635937
Epoch:  360  	Training Loss: 0.0003133903373964131
Test Loss:  0.000473073567263782
Valid Loss:  0.0003453074605204165
Epoch:  361  	Training Loss: 0.00031336129177361727
Test Loss:  0.00047301105223596096
Valid Loss:  0.0003451906668487936
Epoch:  362  	Training Loss: 0.000313333235681057
Test Loss:  0.00047272740630432963
Valid Loss:  0.0003444694448262453
Epoch:  363  	Training Loss: 0.00031256815418601036
Test Loss:  0.0004738072748295963
Valid Loss:  0.00034430151572450995
Epoch:  364  	Training Loss: 0.00031222362304106355
Test Loss:  0.0004745710757561028
Valid Loss:  0.00034422025782987475
Epoch:  365  	Training Loss: 0.0003119640750810504
Test Loss:  0.0004748016071971506
Valid Loss:  0.00034413550747558475
Epoch:  366  	Training Loss: 0.00031173627940006554
Test Loss:  0.000474608619697392
Valid Loss:  0.00034403635072521865
Epoch:  367  	Training Loss: 0.00031152591691352427
Test Loss:  0.00047413684660568833
Valid Loss:  0.00034392427187412977
Epoch:  368  	Training Loss: 0.00031132460571825504
Test Loss:  0.00047348192310892045
Valid Loss:  0.00034380221040919423
Epoch:  369  	Training Loss: 0.00031112993019632995
Test Loss:  0.000472718762466684
Valid Loss:  0.0003436750848777592
Epoch:  370  	Training Loss: 0.0003109410754404962
Test Loss:  0.00047187943710014224
Valid Loss:  0.0003435460093896836
Epoch:  371  	Training Loss: 0.00031075775041244924
Test Loss:  0.0004709901986643672
Valid Loss:  0.0003434173413552344
Epoch:  372  	Training Loss: 0.0003105802752543241
Test Loss:  0.0004727855557575822
Valid Loss:  0.000342001294484362
Epoch:  373  	Training Loss: 0.00030927464831620455
Test Loss:  0.00047337301657535136
Valid Loss:  0.0003405958414077759
Epoch:  374  	Training Loss: 0.000308026559650898
Test Loss:  0.0004734511021524668
Valid Loss:  0.0003393337538000196
Epoch:  375  	Training Loss: 0.00030682020587846637
Test Loss:  0.00047330226516351104
Valid Loss:  0.00033840807736851275
Epoch:  376  	Training Loss: 0.00030565023189410567
Test Loss:  0.0004730407672468573
Valid Loss:  0.0003375329833943397
Epoch:  377  	Training Loss: 0.0003045139601454139
Test Loss:  0.00047271675430238247
Valid Loss:  0.00033670529955998063
Epoch:  378  	Training Loss: 0.0003034589171875268
Test Loss:  0.0004723483871202916
Valid Loss:  0.00033592002000659704
Epoch:  379  	Training Loss: 0.0003025588230229914
Test Loss:  0.00047199061373248696
Valid Loss:  0.0003348708851262927
Epoch:  380  	Training Loss: 0.0003016887349076569
Test Loss:  0.0004716042894870043
Valid Loss:  0.0003337468660902232
Epoch:  381  	Training Loss: 0.00030084274476394057
Test Loss:  0.00047119834925979376
Valid Loss:  0.00033267674734815955
Epoch:  382  	Training Loss: 0.00030002015409991145
Test Loss:  0.0004713360976893455
Valid Loss:  0.00033158870064653456
Epoch:  383  	Training Loss: 0.00029966305010020733
Test Loss:  0.0004714601091109216
Valid Loss:  0.00033053907100111246
Epoch:  384  	Training Loss: 0.0002993189846165478
Test Loss:  0.00047156907385215163
Valid Loss:  0.0003295253263786435
Epoch:  385  	Training Loss: 0.0002989895292557776
Test Loss:  0.0004716204712167382
Valid Loss:  0.00032855855533853173
Epoch:  386  	Training Loss: 0.00029867736157029867
Test Loss:  0.0004716688417829573
Valid Loss:  0.0003276343340985477
Epoch:  387  	Training Loss: 0.00029837750480510294
Test Loss:  0.0004717221308965236
Valid Loss:  0.00032674282556399703
Epoch:  388  	Training Loss: 0.00029808806721121073
Test Loss:  0.0004717413685284555
Valid Loss:  0.00032588234171271324
Epoch:  389  	Training Loss: 0.00029781495686620474
Test Loss:  0.00047175231156870723
Valid Loss:  0.00032506001298315823
Epoch:  390  	Training Loss: 0.0002975527895614505
Test Loss:  0.00047175283543765545
Valid Loss:  0.0003242648672312498
Epoch:  391  	Training Loss: 0.0002973034861497581
Test Loss:  0.00047169887693598866
Valid Loss:  0.0003234898904338479
Epoch:  392  	Training Loss: 0.0002970760688185692
Test Loss:  0.00047113699838519096
Valid Loss:  0.0003235995536670089
Epoch:  393  	Training Loss: 0.0002970411442220211
Test Loss:  0.0004707718326244503
Valid Loss:  0.0003236830234527588
Epoch:  394  	Training Loss: 0.00029700639424845576
Test Loss:  0.0004702568694483489
Valid Loss:  0.0003237858763895929
Epoch:  395  	Training Loss: 0.00029697263380512595
Test Loss:  0.00046976475277915597
Valid Loss:  0.0003238852368667722
Epoch:  396  	Training Loss: 0.00029694149270653725
Test Loss:  0.00046946582733653486
Valid Loss:  0.0003239570651203394
Epoch:  397  	Training Loss: 0.00029691075906157494
Test Loss:  0.00046901183668524027
Valid Loss:  0.0003240497026126832
Epoch:  398  	Training Loss: 0.00029688028735108674
Test Loss:  0.00046857880079187453
Valid Loss:  0.00032413797453045845
Epoch:  399  	Training Loss: 0.0002968509215861559
Test Loss:  0.00046816447866149247
Valid Loss:  0.0003242228995077312
Epoch:  400  	Training Loss: 0.00029682283638976514
Test Loss:  0.0004679372359532863
Valid Loss:  0.0003242804086767137
Epoch:  401  	Training Loss: 0.0002967952168546617
Test Loss:  0.0004675520467571914
Valid Loss:  0.00032435933826491237
Epoch:  402  	Training Loss: 0.00029676780104637146
Test Loss:  0.0004697178374044597
Valid Loss:  0.0003246269770897925
Epoch:  403  	Training Loss: 0.0002962971921078861
Test Loss:  0.00046726889559067786
Valid Loss:  0.0003244891995564103
Epoch:  404  	Training Loss: 0.0002959360717795789
Test Loss:  0.0004651721683330834
Valid Loss:  0.00032438605558127165
Epoch:  405  	Training Loss: 0.0002956039970740676
Test Loss:  0.000463294330984354
Valid Loss:  0.00032430150895379484
Epoch:  406  	Training Loss: 0.00029529485618695617
Test Loss:  0.00046158424811437726
Valid Loss:  0.0003242286038585007
Epoch:  407  	Training Loss: 0.0002950037596747279
Test Loss:  0.0004601175314746797
Valid Loss:  0.0003241744125261903
Epoch:  408  	Training Loss: 0.00029472471214830875
Test Loss:  0.00045879808021709323
Valid Loss:  0.00032412930158898234
 82%|████████▏ | 409/500 [05:06<00:30,  2.98it/s] 82%|████████▏ | 411/500 [05:12<01:45,  1.19s/it] 83%|████████▎ | 413/500 [05:12<01:14,  1.17it/s] 83%|████████▎ | 415/500 [05:12<00:52,  1.62it/s] 83%|████████▎ | 417/500 [05:12<00:37,  2.22it/s] 84%|████████▍ | 419/500 [05:12<00:27,  2.99it/s] 84%|████████▍ | 421/500 [05:19<01:35,  1.21s/it] 85%|████████▍ | 423/500 [05:19<01:06,  1.16it/s] 85%|████████▌ | 425/500 [05:19<00:46,  1.60it/s] 85%|████████▌ | 427/500 [05:19<00:33,  2.18it/s] 86%|████████▌ | 429/500 [05:19<00:24,  2.90it/s] 86%|████████▌ | 431/500 [05:26<01:25,  1.24s/it] 87%|████████▋ | 433/500 [05:26<01:00,  1.11it/s] 87%|████████▋ | 435/500 [05:27<00:42,  1.53it/s] 87%|████████▋ | 437/500 [05:27<00:30,  2.07it/s] 88%|████████▊ | 439/500 [05:27<00:22,  2.74it/s] 88%|████████▊ | 441/500 [05:33<01:12,  1.22s/it] 89%|████████▊ | 443/500 [05:33<00:50,  1.14it/s] 89%|████████▉ | 445/500 [05:34<00:34,  1.58it/s] 89%|████████▉ | 447/500 [05:34<00:24,  2.16it/s] 90%|████████▉ | 449/500 [05:34<00:17,  2.90it/s] 90%|█████████ | 451/500 [05:40<00:59,  1.22s/it] 91%|█████████ | 453/500 [05:41<00:41,  1.14it/s] 91%|█████████ | 455/500 [05:41<00:28,  1.58it/s] 91%|█████████▏| 457/500 [05:41<00:19,  2.16it/s] 92%|█████████▏| 459/500 [05:41<00:14,  2.90it/s] 92%|█████████▏| 461/500 [05:48<00:48,  1.24s/it] 93%|█████████▎| 463/500 [05:48<00:32,  1.13it/s] 93%|█████████▎| 465/500 [05:48<00:22,  1.56it/s] 93%|█████████▎| 467/500 [05:48<00:15,  2.13it/s] 94%|█████████▍| 469/500 [05:48<00:10,  2.83it/s] 94%|█████████▍| 471/500 [05:55<00:35,  1.22s/it] 95%|█████████▍| 473/500 [05:55<00:23,  1.13it/s] 95%|█████████▌| 475/500 [05:55<00:16,  1.55it/s]Epoch:  409  	Training Loss: 0.0002944553270936012
Test Loss:  0.0004576098872348666
Valid Loss:  0.0003240907099097967
Epoch:  410  	Training Loss: 0.0002942044229712337
Test Loss:  0.00045648030936717987
Valid Loss:  0.0003240527294110507
Epoch:  411  	Training Loss: 0.0002940173726528883
Test Loss:  0.0004555222112685442
Valid Loss:  0.00032402516808360815
Epoch:  412  	Training Loss: 0.0002938354737125337
Test Loss:  0.00045533262891694903
Valid Loss:  0.00032396503956988454
Epoch:  413  	Training Loss: 0.00029375270241871476
Test Loss:  0.0004552002646960318
Valid Loss:  0.000323921674862504
Epoch:  414  	Training Loss: 0.0002936932141892612
Test Loss:  0.000455110683105886
Valid Loss:  0.0003238889039494097
Epoch:  415  	Training Loss: 0.00029364952933974564
Test Loss:  0.00045505582238547504
Valid Loss:  0.0003238641074858606
Epoch:  416  	Training Loss: 0.00029361643828451633
Test Loss:  0.0004550265148282051
Valid Loss:  0.0003238450735807419
Epoch:  417  	Training Loss: 0.00029359044856391847
Test Loss:  0.0004550183657556772
Valid Loss:  0.0003238306089770049
Epoch:  418  	Training Loss: 0.0002935695229098201
Test Loss:  0.0004550266021396965
Valid Loss:  0.0003238188801333308
Epoch:  419  	Training Loss: 0.00029355217702686787
Test Loss:  0.000455048109870404
Valid Loss:  0.00032380991615355015
Epoch:  420  	Training Loss: 0.00029353692661970854
Test Loss:  0.0004550791345536709
Valid Loss:  0.0003238028148189187
Epoch:  421  	Training Loss: 0.0002935236261691898
Test Loss:  0.00045511871576309204
Valid Loss:  0.000323796906741336
Epoch:  422  	Training Loss: 0.0002935113152489066
Test Loss:  0.00045939756091684103
Valid Loss:  0.0003232098533771932
Epoch:  423  	Training Loss: 0.0002931866911239922
Test Loss:  0.0004577938816510141
Valid Loss:  0.00032214249949902296
Epoch:  424  	Training Loss: 0.0002929197798948735
Test Loss:  0.00045804225374013186
Valid Loss:  0.00032126886071637273
Epoch:  425  	Training Loss: 0.0002926712913904339
Test Loss:  0.00045782062807120383
Valid Loss:  0.0003203766536898911
Epoch:  426  	Training Loss: 0.00029243764583952725
Test Loss:  0.0004578048537950963
Valid Loss:  0.00031952589051797986
Epoch:  427  	Training Loss: 0.0002922169805970043
Test Loss:  0.0004577835788950324
Valid Loss:  0.0003186986141372472
Epoch:  428  	Training Loss: 0.00029200862627476454
Test Loss:  0.0004578120424412191
Valid Loss:  0.0003178990737069398
Epoch:  429  	Training Loss: 0.00029181153513491154
Test Loss:  0.0004578643711283803
Valid Loss:  0.00031712488271296024
Epoch:  430  	Training Loss: 0.00029162567807361484
Test Loss:  0.00045794350444339216
Valid Loss:  0.0003163762157782912
Epoch:  431  	Training Loss: 0.0002914498036261648
Test Loss:  0.00045804347610101104
Valid Loss:  0.0003156516177114099
Epoch:  432  	Training Loss: 0.00029128356254659593
Test Loss:  0.00045634148409590125
Valid Loss:  0.0003155847080051899
Epoch:  433  	Training Loss: 0.0002912395866587758
Test Loss:  0.00045522250002250075
Valid Loss:  0.0003155547601636499
Epoch:  434  	Training Loss: 0.0002912036725319922
Test Loss:  0.0004544015973806381
Valid Loss:  0.00031554215820506215
Epoch:  435  	Training Loss: 0.00029117200756445527
Test Loss:  0.00045374163892120123
Valid Loss:  0.00031553872395306826
Epoch:  436  	Training Loss: 0.0002911433402914554
Test Loss:  0.0004531723679974675
Valid Loss:  0.0003155401209369302
Epoch:  437  	Training Loss: 0.0002911173505708575
Test Loss:  0.0004526597331278026
Valid Loss:  0.00031554404995404184
Epoch:  438  	Training Loss: 0.0002910934272222221
Test Loss:  0.0004521860391832888
Valid Loss:  0.0003155495214741677
Epoch:  439  	Training Loss: 0.00029107180307619274
Test Loss:  0.0004517408669926226
Valid Loss:  0.0003155561280436814
Epoch:  440  	Training Loss: 0.0002910520415753126
Test Loss:  0.00045132054947316647
Valid Loss:  0.00031556416070088744
Epoch:  441  	Training Loss: 0.00029103399720042944
Test Loss:  0.0004509217105805874
Valid Loss:  0.0003155721933580935
Epoch:  442  	Training Loss: 0.00029101746622473
Test Loss:  0.00045201019383966923
Valid Loss:  0.00031570286955684423
Epoch:  443  	Training Loss: 0.0002910062321461737
Test Loss:  0.00045060680713504553
Valid Loss:  0.0003155602898914367
Epoch:  444  	Training Loss: 0.0002909953473135829
Test Loss:  0.0004517094057518989
Valid Loss:  0.00031569311977364123
Epoch:  445  	Training Loss: 0.0002909844624809921
Test Loss:  0.00045029816101305187
Valid Loss:  0.0003155492013320327
Epoch:  446  	Training Loss: 0.0002909741597250104
Test Loss:  0.0004514139436651021
Valid Loss:  0.0003156837192364037
Epoch:  447  	Training Loss: 0.00029096438083797693
Test Loss:  0.00044999568490311503
Valid Loss:  0.0003155389567837119
Epoch:  448  	Training Loss: 0.00029095460195094347
Test Loss:  0.00045112540828995407
Valid Loss:  0.00031567487167194486
Epoch:  449  	Training Loss: 0.00029094531782902777
Test Loss:  0.0004497003392316401
Valid Loss:  0.0003155294107273221
Epoch:  450  	Training Loss: 0.0002909369068220258
Test Loss:  0.0004508498532231897
Valid Loss:  0.0003156679158564657
Epoch:  451  	Training Loss: 0.00029092893237248063
Test Loss:  0.0004494175664149225
Valid Loss:  0.0003155216691084206
Epoch:  452  	Training Loss: 0.00029092089971527457
Test Loss:  0.00045062534627504647
Valid Loss:  0.0003146434319205582
Epoch:  453  	Training Loss: 0.00029067430295981467
Test Loss:  0.00045167363714426756
Valid Loss:  0.00031382247107103467
Epoch:  454  	Training Loss: 0.00029046437703073025
Test Loss:  0.00045250417315401137
Valid Loss:  0.00031304708682000637
Epoch:  455  	Training Loss: 0.0002902699343394488
Test Loss:  0.00045302038779482245
Valid Loss:  0.0003123177448287606
Epoch:  456  	Training Loss: 0.0002901020343415439
Test Loss:  0.0004534844192676246
Valid Loss:  0.00031162885716184974
Epoch:  457  	Training Loss: 0.00028995564207434654
Test Loss:  0.00045390817103907466
Valid Loss:  0.0003109762619715184
Epoch:  458  	Training Loss: 0.00028982595540583134
Test Loss:  0.0004542969400063157
Valid Loss:  0.00031035655410960317
Epoch:  459  	Training Loss: 0.0002897098893299699
Test Loss:  0.00045465672155842185
Valid Loss:  0.00030976685229688883
Epoch:  460  	Training Loss: 0.0002896052901633084
Test Loss:  0.000454992288723588
Valid Loss:  0.0003092055267188698
Epoch:  461  	Training Loss: 0.0002895101788453758
Test Loss:  0.000455307075753808
Valid Loss:  0.0003086698998231441
Epoch:  462  	Training Loss: 0.0002894238568842411
Test Loss:  0.0004611964977812022
Valid Loss:  0.0003086133219767362
Epoch:  463  	Training Loss: 0.0002887490554712713
Test Loss:  0.000461181509308517
Valid Loss:  0.0003079144225921482
Epoch:  464  	Training Loss: 0.0002883058041334152
Test Loss:  0.00046580092748627067
Valid Loss:  0.000308132148347795
Epoch:  465  	Training Loss: 0.0002880312968045473
Test Loss:  0.00046510971151292324
Valid Loss:  0.00030766037525609136
Epoch:  466  	Training Loss: 0.00028785603353753686
Test Loss:  0.0004687095351982862
Valid Loss:  0.00030796509236097336
Epoch:  467  	Training Loss: 0.00028774107340723276
Test Loss:  0.0004679789999499917
Valid Loss:  0.0003076485591009259
Epoch:  468  	Training Loss: 0.000287670292891562
Test Loss:  0.0004705516912508756
Valid Loss:  0.0003079178277403116
Epoch:  469  	Training Loss: 0.0002876209618989378
Test Loss:  0.00046994505100883543
Valid Loss:  0.00030769570730626583
Epoch:  470  	Training Loss: 0.0002875850477721542
Test Loss:  0.00047169369645416737
Valid Loss:  0.0003078922163695097
Epoch:  471  	Training Loss: 0.0002875587670132518
Test Loss:  0.0004712302761618048
Valid Loss:  0.00030773942125961185
Epoch:  472  	Training Loss: 0.00028753868537023664
Test Loss:  0.0004587617877405137
Valid Loss:  0.00030696787871420383
Epoch:  473  	Training Loss: 0.0002868499723263085
Test Loss:  0.0004535166663117707
Valid Loss:  0.0003068721853196621
Epoch:  474  	Training Loss: 0.00028648911393247545
Test Loss:  0.00045029420289210975
Valid Loss:  0.0003069060912821442
Epoch:  475  	Training Loss: 0.0002862150431610644
Test Loss:  0.0004478233167901635
Valid Loss:  0.0003069777740165591
Epoch:  476  	Training Loss: 0.0002859976375475526
Test Loss:   95%|█████████▌| 477/500 [05:55<00:10,  2.10it/s] 96%|█████████▌| 479/500 [05:55<00:07,  2.77it/s] 96%|█████████▌| 481/500 [06:02<00:23,  1.21s/it] 97%|█████████▋| 483/500 [06:02<00:14,  1.14it/s] 97%|█████████▋| 485/500 [06:02<00:09,  1.56it/s] 97%|█████████▋| 487/500 [06:02<00:06,  2.13it/s] 98%|█████████▊| 489/500 [06:02<00:03,  2.87it/s] 98%|█████████▊| 491/500 [06:09<00:10,  1.20s/it] 99%|█████████▊| 493/500 [06:09<00:06,  1.15it/s] 99%|█████████▉| 495/500 [06:09<00:03,  1.58it/s] 99%|█████████▉| 497/500 [06:09<00:01,  2.13it/s]100%|█████████▉| 499/500 [06:10<00:00,  2.82it/s]100%|██████████| 500/500 [06:10<00:00,  1.35it/s]
0.00044573572813533247
Valid Loss:  0.00030706223333254457
Epoch:  477  	Training Loss: 0.00028582397499121726
Test Loss:  0.0004439462209120393
Valid Loss:  0.0003071523969992995
Epoch:  478  	Training Loss: 0.00028568325797095895
Test Loss:  0.00044238800182938576
Valid Loss:  0.00030724360840395093
Epoch:  479  	Training Loss: 0.00028556835604831576
Test Loss:  0.00044100647210143507
Valid Loss:  0.00030733077437616885
Epoch:  480  	Training Loss: 0.0002854739432223141
Test Loss:  0.000439806462964043
Valid Loss:  0.00030741418595425785
Epoch:  481  	Training Loss: 0.00028539460618048906
Test Loss:  0.0004387537483125925
Valid Loss:  0.0003074922424275428
Epoch:  482  	Training Loss: 0.0002853271726053208
Test Loss:  0.0004380749014671892
Valid Loss:  0.00030746759148314595
Epoch:  483  	Training Loss: 0.0002853088080883026
Test Loss:  0.0004375556600280106
Valid Loss:  0.00030745050753466785
Epoch:  484  	Training Loss: 0.00028529419796541333
Test Loss:  0.00043715478386729956
Valid Loss:  0.0003074394480790943
Epoch:  485  	Training Loss: 0.00028528241091407835
Test Loss:  0.00043684354750439525
Valid Loss:  0.00030743173556402326
Epoch:  486  	Training Loss: 0.00028527225367724895
Test Loss:  0.0004365975328255445
Valid Loss:  0.0003074267297051847
Epoch:  487  	Training Loss: 0.0002852632605936378
Test Loss:  0.00043640134390443563
Valid Loss:  0.0003074245760217309
Epoch:  488  	Training Loss: 0.00028525444213300943
Test Loss:  0.00043624124373309314
Valid Loss:  0.0003074224223382771
Epoch:  489  	Training Loss: 0.00028524635126814246
Test Loss:  0.00043610803550109267
Valid Loss:  0.00030742224771529436
Epoch:  490  	Training Loss: 0.00028523860964924097
Test Loss:  0.00043599438504315913
Valid Loss:  0.0003074222768191248
Epoch:  491  	Training Loss: 0.0002852310717571527
Test Loss:  0.0004358960432000458
Valid Loss:  0.00030742352828383446
Epoch:  492  	Training Loss: 0.00028522341744974256
Test Loss:  0.000438946794020012
Valid Loss:  0.00030729876016266644
Epoch:  493  	Training Loss: 0.00028488115640357137
Test Loss:  0.00043858622666448355
Valid Loss:  0.0003070071688853204
Epoch:  494  	Training Loss: 0.0002846071729436517
Test Loss:  0.0004389353562146425
Valid Loss:  0.0003068826044909656
Epoch:  495  	Training Loss: 0.00028436537832021713
Test Loss:  0.00043820112477988005
Valid Loss:  0.0003067057696171105
Epoch:  496  	Training Loss: 0.00028414474218152463
Test Loss:  0.0004375323187559843
Valid Loss:  0.00030659689218737185
Epoch:  497  	Training Loss: 0.0002839419466909021
Test Loss:  0.00043647224083542824
Valid Loss:  0.0003064866177737713
Epoch:  498  	Training Loss: 0.0002837495703715831
Test Loss:  0.00043573995935730636
Valid Loss:  0.00030637235613539815
Epoch:  499  	Training Loss: 0.0002835669438354671
Test Loss:  0.0004346875357441604
Valid Loss:  0.0003062818432226777
Epoch:  500  	Training Loss: 0.0002833893522620201
Test Loss:  0.0004337155551183969
Valid Loss:  0.00030621117912232876
seed is  14
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:34, 14.32it/s]  1%|          | 4/500 [00:00<00:31, 15.58it/s]  1%|          | 6/500 [00:00<00:30, 16.03it/s]  2%|▏         | 8/500 [00:00<00:30, 16.04it/s]  2%|▏         | 10/500 [00:00<00:30, 16.01it/s]  2%|▏         | 12/500 [00:00<00:30, 16.00it/s]  3%|▎         | 14/500 [00:00<00:30, 16.02it/s]  3%|▎         | 16/500 [00:01<00:30, 15.90it/s]  4%|▎         | 18/500 [00:01<00:30, 15.85it/s]  4%|▍         | 20/500 [00:01<00:30, 15.53it/s]  4%|▍         | 22/500 [00:01<00:30, 15.55it/s]  5%|▍         | 24/500 [00:01<00:30, 15.58it/s]  5%|▌         | 26/500 [00:01<00:30, 15.73it/s]  6%|▌         | 28/500 [00:01<00:30, 15.66it/s]  6%|▌         | 30/500 [00:01<00:30, 15.52it/s]  6%|▋         | 32/500 [00:02<00:30, 15.23it/s]  7%|▋         | 34/500 [00:02<00:32, 14.17it/s]  7%|▋         | 36/500 [00:02<00:31, 14.58it/s]  8%|▊         | 38/500 [00:02<00:30, 15.02it/s]  8%|▊         | 40/500 [00:02<00:29, 15.34it/s]  8%|▊         | 42/500 [00:02<00:29, 15.56it/s]  9%|▉         | 44/500 [00:02<00:29, 15.66it/s]  9%|▉         | 46/500 [00:02<00:29, 15.65it/s] 10%|▉         | 48/500 [00:03<00:28, 15.74it/s] 10%|█         | 50/500 [00:03<00:28, 15.88it/s] 10%|█         | 52/500 [00:03<00:28, 15.84it/s] 11%|█         | 54/500 [00:03<00:27, 15.96it/s] 11%|█         | 56/500 [00:03<00:27, 15.97it/s] 12%|█▏        | 58/500 [00:03<00:29, 15.06it/s] 12%|█▏        | 60/500 [00:03<00:28, 15.40it/s] 12%|█▏        | 62/500 [00:03<00:28, 15.62it/s] 13%|█▎        | 64/500 [00:04<00:27, 15.84it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.99it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.06it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.04it/s] 14%|█▍        | 72/500 [00:04<00:26, 15.96it/s] 15%|█▍        | 74/500 [00:04<00:28, 15.08it/s] 15%|█▌        | 76/500 [00:04<00:30, 14.12it/s] 16%|█▌        | 78/500 [00:05<00:30, 13.66it/s] 16%|█▌        | 80/500 [00:05<00:31, 13.39it/s] 16%|█▋        | 82/500 [00:05<00:29, 14.17it/s] 17%|█▋        | 84/500 [00:05<00:28, 14.72it/s] 17%|█▋        | 86/500 [00:05<00:27, 15.17it/s] 18%|█▊        | 88/500 [00:05<00:26, 15.41it/s] 18%|█▊        | 90/500 [00:05<00:26, 15.60it/s] 18%|█▊        | 92/500 [00:05<00:25, 15.86it/s] 19%|█▉        | 94/500 [00:06<00:25, 15.92it/s] 19%|█▉        | 96/500 [00:06<00:25, 16.09it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.17it/s] 20%|██        | 100/500 [00:06<00:24, 16.15it/s] 20%|██        | 102/500 [00:06<00:24, 15.94it/s] 21%|██        | 104/500 [00:06<00:24, 15.88it/s] 21%|██        | 106/500 [00:06<00:24, 16.00it/s] 22%|██▏       | 108/500 [00:06<00:24, 15.71it/s] 22%|██▏       | 110/500 [00:07<00:24, 15.91it/s] 22%|██▏       | 112/500 [00:07<00:24, 15.87it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.91it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.99it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.13it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.04it/s] 24%|██▍       | 122/500 [00:07<00:23, 15.99it/s] 25%|██▍       | 124/500 [00:07<00:24, 15.52it/s]Epoch:  1  	Training Loss: 0.2322888970375061
Test Loss:  3726.952880859375
Valid Loss:  3725.2177734375
Epoch:  2  	Training Loss: 3732.7412109375
Test Loss:  20308008370176.0
Valid Loss:  20317128884224.0
Epoch:  3  	Training Loss: 20370660786176.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:25, 14.50it/s] 26%|██▌       | 128/500 [00:08<00:24, 14.93it/s] 26%|██▌       | 130/500 [00:08<00:25, 14.68it/s] 26%|██▋       | 132/500 [00:08<00:24, 14.98it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.33it/s] 27%|██▋       | 136/500 [00:08<00:25, 14.52it/s] 28%|██▊       | 138/500 [00:08<00:27, 13.25it/s] 28%|██▊       | 140/500 [00:09<00:27, 12.90it/s] 28%|██▊       | 142/500 [00:09<00:28, 12.65it/s] 29%|██▉       | 144/500 [00:09<00:28, 12.51it/s] 29%|██▉       | 146/500 [00:09<00:27, 13.10it/s] 30%|██▉       | 148/500 [00:09<00:25, 13.85it/s] 30%|███       | 150/500 [00:09<00:24, 14.51it/s] 30%|███       | 152/500 [00:09<00:23, 15.02it/s] 31%|███       | 154/500 [00:10<00:23, 14.91it/s] 31%|███       | 156/500 [00:10<00:22, 15.30it/s] 32%|███▏      | 158/500 [00:10<00:21, 15.56it/s] 32%|███▏      | 160/500 [00:10<00:21, 15.57it/s] 32%|███▏      | 162/500 [00:10<00:21, 15.62it/s] 33%|███▎      | 164/500 [00:10<00:21, 15.85it/s] 33%|███▎      | 166/500 [00:10<00:20, 15.96it/s] 34%|███▎      | 168/500 [00:11<00:20, 16.00it/s] 34%|███▍      | 170/500 [00:11<00:20, 15.97it/s] 34%|███▍      | 172/500 [00:11<00:21, 15.32it/s] 35%|███▍      | 174/500 [00:11<00:21, 15.50it/s] 35%|███▌      | 176/500 [00:11<00:20, 15.62it/s] 36%|███▌      | 178/500 [00:11<00:20, 15.80it/s] 36%|███▌      | 180/500 [00:11<00:20, 15.94it/s] 36%|███▋      | 182/500 [00:11<00:20, 15.63it/s] 37%|███▋      | 184/500 [00:12<00:21, 14.59it/s] 37%|███▋      | 186/500 [00:12<00:20, 15.04it/s] 38%|███▊      | 188/500 [00:12<00:20, 15.00it/s] 38%|███▊      | 190/500 [00:12<00:22, 13.89it/s] 38%|███▊      | 192/500 [00:12<00:23, 13.27it/s] 39%|███▉      | 194/500 [00:12<00:22, 13.68it/s] 39%|███▉      | 196/500 [00:12<00:21, 13.95it/s] 40%|███▉      | 198/500 [00:13<00:20, 14.40it/s] 40%|████      | 200/500 [00:13<00:20, 14.92it/s] 40%|████      | 202/500 [00:13<00:19, 15.32it/s] 41%|████      | 204/500 [00:13<00:19, 15.42it/s] 41%|████      | 206/500 [00:13<00:20, 14.53it/s] 42%|████▏     | 208/500 [00:13<00:21, 13.71it/s] 42%|████▏     | 210/500 [00:13<00:22, 13.17it/s] 42%|████▏     | 212/500 [00:14<00:22, 12.70it/s] 43%|████▎     | 214/500 [00:14<00:23, 12.36it/s] 43%|████▎     | 216/500 [00:14<00:23, 12.31it/s] 44%|████▎     | 218/500 [00:14<00:23, 12.21it/s] 44%|████▍     | 220/500 [00:14<00:22, 12.18it/s] 44%|████▍     | 222/500 [00:14<00:22, 12.21it/s] 45%|████▍     | 224/500 [00:15<00:22, 12.22it/s] 45%|████▌     | 226/500 [00:15<00:22, 12.01it/s] 46%|████▌     | 228/500 [00:15<00:22, 12.05it/s] 46%|████▌     | 230/500 [00:15<00:21, 12.44it/s] 46%|████▋     | 232/500 [00:15<00:20, 13.16it/s] 47%|████▋     | 234/500 [00:15<00:19, 13.84it/s] 47%|████▋     | 236/500 [00:15<00:18, 14.52it/s] 48%|████▊     | 238/500 [00:16<00:17, 14.95it/s] 48%|████▊     | 240/500 [00:16<00:16, 15.37it/s] 48%|████▊     | 242/500 [00:16<00:16, 15.63it/s] 49%|████▉     | 244/500 [00:16<00:16, 15.82it/s] 49%|████▉     | 246/500 [00:16<00:15, 15.93it/s] 50%|████▉     | 248/500 [00:16<00:15, 16.04it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 16.12it/s] 50%|█████     | 252/500 [00:16<00:15, 15.77it/s] 51%|█████     | 254/500 [00:17<00:15, 15.96it/s] 51%|█████     | 256/500 [00:17<00:15, 16.02it/s] 52%|█████▏    | 258/500 [00:17<00:15, 16.07it/s] 52%|█████▏    | 260/500 [00:17<00:14, 16.17it/s] 52%|█████▏    | 262/500 [00:17<00:14, 16.21it/s] 53%|█████▎    | 264/500 [00:17<00:14, 16.20it/s] 53%|█████▎    | 266/500 [00:17<00:14, 16.23it/s] 54%|█████▎    | 268/500 [00:17<00:14, 16.29it/s] 54%|█████▍    | 270/500 [00:18<00:14, 16.39it/s] 54%|█████▍    | 272/500 [00:18<00:13, 16.30it/s] 55%|█████▍    | 274/500 [00:18<00:14, 15.52it/s] 55%|█████▌    | 276/500 [00:18<00:14, 15.74it/s] 56%|█████▌    | 278/500 [00:18<00:14, 15.72it/s] 56%|█████▌    | 280/500 [00:18<00:13, 15.73it/s] 56%|█████▋    | 282/500 [00:18<00:14, 14.70it/s] 57%|█████▋    | 284/500 [00:19<00:15, 13.86it/s] 57%|█████▋    | 286/500 [00:19<00:15, 14.09it/s] 58%|█████▊    | 288/500 [00:19<00:14, 14.23it/s] 58%|█████▊    | 290/500 [00:19<00:15, 13.47it/s] 58%|█████▊    | 292/500 [00:19<00:14, 14.16it/s] 59%|█████▉    | 294/500 [00:19<00:14, 14.65it/s] 59%|█████▉    | 296/500 [00:19<00:13, 14.92it/s] 60%|█████▉    | 298/500 [00:19<00:13, 15.22it/s] 60%|██████    | 300/500 [00:20<00:12, 15.47it/s] 60%|██████    | 302/500 [00:20<00:12, 15.69it/s] 61%|██████    | 304/500 [00:20<00:12, 15.87it/s] 61%|██████    | 306/500 [00:20<00:12, 15.89it/s] 62%|██████▏   | 308/500 [00:20<00:12, 15.66it/s] 62%|██████▏   | 310/500 [00:20<00:12, 15.56it/s] 62%|██████▏   | 312/500 [00:20<00:12, 15.63it/s] 63%|██████▎   | 314/500 [00:20<00:12, 15.19it/s] 63%|██████▎   | 316/500 [00:21<00:13, 13.99it/s] 64%|██████▎   | 318/500 [00:21<00:13, 13.24it/s] 64%|██████▍   | 320/500 [00:21<00:13, 12.90it/s] 64%|██████▍   | 322/500 [00:21<00:13, 13.25it/s] 65%|██████▍   | 324/500 [00:21<00:12, 13.88it/s] 65%|██████▌   | 326/500 [00:21<00:12, 14.43it/s] 66%|██████▌   | 328/500 [00:22<00:11, 14.78it/s] 66%|██████▌   | 330/500 [00:22<00:11, 14.99it/s] 66%|██████▋   | 332/500 [00:22<00:11, 15.23it/s] 67%|██████▋   | 334/500 [00:22<00:10, 15.17it/s] 67%|██████▋   | 336/500 [00:22<00:10, 15.36it/s] 68%|██████▊   | 338/500 [00:22<00:10, 15.57it/s] 68%|██████▊   | 340/500 [00:22<00:10, 15.81it/s] 68%|██████▊   | 342/500 [00:22<00:09, 15.88it/s] 69%|██████▉   | 344/500 [00:23<00:09, 15.95it/s] 69%|██████▉   | 346/500 [00:23<00:09, 15.92it/s] 70%|██████▉   | 348/500 [00:23<00:09, 15.82it/s] 70%|███████   | 350/500 [00:23<00:09, 15.91it/s] 70%|███████   | 352/500 [00:23<00:09, 15.83it/s] 71%|███████   | 354/500 [00:23<00:09, 14.90it/s] 71%|███████   | 356/500 [00:23<00:10, 13.85it/s] 72%|███████▏  | 358/500 [00:23<00:10, 13.45it/s] 72%|███████▏  | 360/500 [00:24<00:09, 14.07it/s] 72%|███████▏  | 362/500 [00:24<00:09, 14.65it/s] 73%|███████▎  | 364/500 [00:24<00:09, 14.97it/s] 73%|███████▎  | 366/500 [00:24<00:08, 15.13it/s] 74%|███████▎  | 368/500 [00:24<00:08, 15.35it/s] 74%|███████▍  | 370/500 [00:24<00:08, 15.56it/s] 74%|███████▍  | 372/500 [00:24<00:08, 15.64it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:25<00:07, 15.80it/s] 75%|███████▌  | 376/500 [00:25<00:07, 15.87it/s] 76%|███████▌  | 378/500 [00:25<00:07, 16.00it/s] 76%|███████▌  | 380/500 [00:25<00:07, 16.10it/s] 76%|███████▋  | 382/500 [00:25<00:07, 16.13it/s] 77%|███████▋  | 384/500 [00:25<00:07, 16.15it/s] 77%|███████▋  | 386/500 [00:25<00:07, 15.77it/s] 78%|███████▊  | 388/500 [00:25<00:07, 14.43it/s] 78%|███████▊  | 390/500 [00:26<00:07, 14.74it/s] 78%|███████▊  | 392/500 [00:26<00:07, 15.06it/s] 79%|███████▉  | 394/500 [00:26<00:06, 15.37it/s] 79%|███████▉  | 396/500 [00:26<00:06, 15.62it/s] 80%|███████▉  | 398/500 [00:26<00:06, 15.84it/s] 80%|████████  | 400/500 [00:26<00:06, 15.84it/s] 80%|████████  | 402/500 [00:26<00:06, 15.98it/s] 81%|████████  | 404/500 [00:26<00:06, 15.93it/s] 81%|████████  | 406/500 [00:27<00:05, 15.94it/s] 82%|████████▏ | 408/500 [00:27<00:05, 15.97it/s] 82%|████████▏ | 410/500 [00:27<00:05, 16.01it/s] 82%|████████▏ | 412/500 [00:27<00:05, 15.71it/s] 83%|████████▎ | 414/500 [00:27<00:05, 15.58it/s] 83%|████████▎ | 416/500 [00:27<00:05, 15.72it/s] 84%|████████▎ | 418/500 [00:27<00:05, 14.78it/s] 84%|████████▍ | 420/500 [00:28<00:05, 13.88it/s] 84%|████████▍ | 422/500 [00:28<00:05, 13.35it/s] 85%|████████▍ | 424/500 [00:28<00:05, 12.96it/s] 85%|████████▌ | 426/500 [00:28<00:05, 13.09it/s] 86%|████████▌ | 428/500 [00:28<00:05, 13.86it/s] 86%|████████▌ | 430/500 [00:28<00:04, 14.19it/s] 86%|████████▋ | 432/500 [00:28<00:05, 13.54it/s] 87%|████████▋ | 434/500 [00:29<00:05, 13.15it/s] 87%|████████▋ | 436/500 [00:29<00:04, 13.87it/s] 88%|████████▊ | 438/500 [00:29<00:04, 14.43it/s] 88%|████████▊ | 440/500 [00:29<00:04, 14.84it/s] 88%|████████▊ | 442/500 [00:29<00:03, 15.18it/s] 89%|████████▉ | 444/500 [00:29<00:03, 15.30it/s] 89%|████████▉ | 446/500 [00:29<00:03, 15.59it/s] 90%|████████▉ | 448/500 [00:29<00:03, 15.74it/s] 90%|█████████ | 450/500 [00:30<00:03, 15.84it/s] 90%|█████████ | 452/500 [00:30<00:03, 15.93it/s] 91%|█████████ | 454/500 [00:30<00:02, 15.94it/s] 91%|█████████ | 456/500 [00:30<00:02, 15.81it/s] 92%|█████████▏| 458/500 [00:30<00:02, 15.72it/s] 92%|█████████▏| 460/500 [00:30<00:02, 15.91it/s] 92%|█████████▏| 462/500 [00:30<00:02, 14.81it/s] 93%|█████████▎| 464/500 [00:30<00:02, 14.76it/s] 93%|█████████▎| 466/500 [00:31<00:02, 15.23it/s] 94%|█████████▎| 468/500 [00:31<00:02, 15.54it/s] 94%|█████████▍| 470/500 [00:31<00:01, 15.51it/s] 94%|█████████▍| 472/500 [00:31<00:01, 15.74it/s] 95%|█████████▍| 474/500 [00:31<00:01, 15.90it/s] 95%|█████████▌| 476/500 [00:31<00:01, 15.63it/s] 96%|█████████▌| 478/500 [00:31<00:01, 15.83it/s] 96%|█████████▌| 480/500 [00:31<00:01, 15.60it/s] 96%|█████████▋| 482/500 [00:32<00:01, 14.16it/s] 97%|█████████▋| 484/500 [00:32<00:01, 14.47it/s] 97%|█████████▋| 486/500 [00:32<00:00, 14.75it/s] 98%|█████████▊| 488/500 [00:32<00:00, 15.07it/s] 98%|█████████▊| 490/500 [00:32<00:00, 15.17it/s] 98%|█████████▊| 492/500 [00:32<00:00, 15.36it/s] 99%|█████████▉| 494/500 [00:32<00:00, 15.63it/s] 99%|█████████▉| 496/500 [00:33<00:00, 15.92it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:33<00:00, 15.97it/s]100%|██████████| 500/500 [00:33<00:00, 16.12it/s]100%|██████████| 500/500 [00:33<00:00, 15.02it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  14
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:43,  6.46s/it]  1%|          | 3/500 [00:06<14:18,  1.73s/it]  1%|          | 5/500 [00:06<07:12,  1.14it/s]  1%|▏         | 7/500 [00:06<04:23,  1.87it/s]  2%|▏         | 9/500 [00:07<02:55,  2.79it/s]  2%|▏         | 11/500 [00:13<11:18,  1.39s/it]  3%|▎         | 13/500 [00:13<07:45,  1.05it/s]  3%|▎         | 15/500 [00:13<05:24,  1.49it/s]  3%|▎         | 17/500 [00:14<03:51,  2.08it/s]  4%|▍         | 19/500 [00:14<02:48,  2.85it/s]  4%|▍         | 21/500 [00:20<09:57,  1.25s/it]  5%|▍         | 23/500 [00:20<07:04,  1.12it/s]  5%|▌         | 25/500 [00:21<05:03,  1.56it/s]  5%|▌         | 27/500 [00:21<03:40,  2.14it/s]  6%|▌         | 29/500 [00:21<02:42,  2.89it/s]  6%|▌         | 31/500 [00:27<09:45,  1.25s/it]  7%|▋         | 33/500 [00:28<06:57,  1.12it/s]  7%|▋         | 35/500 [00:28<04:59,  1.55it/s]  7%|▋         | 37/500 [00:28<03:38,  2.12it/s]  8%|▊         | 39/500 [00:28<02:41,  2.86it/s]  8%|▊         | 41/500 [00:34<09:12,  1.20s/it]  9%|▊         | 43/500 [00:35<06:37,  1.15it/s]  9%|▉         | 45/500 [00:35<04:47,  1.58it/s]  9%|▉         | 47/500 [00:35<03:29,  2.16it/s] 10%|▉         | 49/500 [00:35<02:35,  2.90it/s] 10%|█         | 51/500 [00:41<08:56,  1.19s/it] 11%|█         | 53/500 [00:42<06:24,  1.16it/s] 11%|█         | 55/500 [00:42<04:36,  1.61it/s] 11%|█▏        | 57/500 [00:42<03:21,  2.20it/s] 12%|█▏        | 59/500 [00:42<02:28,  2.96it/s] 12%|█▏        | 61/500 [00:48<08:51,  1.21s/it] 13%|█▎        | 63/500 [00:49<06:19,  1.15it/s] 13%|█▎        | 65/500 [00:49<04:32,  1.59it/s] 13%|█▎        | 67/500 [00:49<03:18,  2.18it/s] 14%|█▍        | 69/500 [00:49<02:27,  2.91it/s]Epoch:  1  	Training Loss: 0.2322888970375061
Test Loss:  0.032374992966651917
Valid Loss:  0.03145858272910118
Epoch:  2  	Training Loss: 0.028821643441915512
Test Loss:  0.021233076229691505
Valid Loss:  0.01986134797334671
Epoch:  3  	Training Loss: 0.02181292325258255
Test Loss:  0.017786741256713867
Valid Loss:  0.01661205291748047
Epoch:  4  	Training Loss: 0.01836998015642166
Test Loss:  0.014842100441455841
Valid Loss:  0.013825314119458199
Epoch:  5  	Training Loss: 0.015514976345002651
Test Loss:  0.012412010692059994
Valid Loss:  0.01153654046356678
Epoch:  6  	Training Loss: 0.01314558181911707
Test Loss:  0.010406207293272018
Valid Loss:  0.009657037444412708
Epoch:  7  	Training Loss: 0.011181684210896492
Test Loss:  0.00874757394194603
Valid Loss:  0.008109642192721367
Epoch:  8  	Training Loss: 0.00955680850893259
Test Loss:  0.0073814052157104015
Valid Loss:  0.006843083072453737
Epoch:  9  	Training Loss: 0.00820676889270544
Test Loss:  0.0062654223293066025
Valid Loss:  0.005818479228764772
Epoch:  10  	Training Loss: 0.007085918448865414
Test Loss:  0.005339009687304497
Valid Loss:  0.004969106055796146
Epoch:  11  	Training Loss: 0.006166568957269192
Test Loss:  0.00456913560628891
Valid Loss:  0.00426821643486619
Epoch:  12  	Training Loss: 0.005402590148150921
Test Loss:  0.003952912054955959
Valid Loss:  0.003718178253620863
Epoch:  13  	Training Loss: 0.004766244441270828
Test Loss:  0.003443290013819933
Valid Loss:  0.003267870284616947
Epoch:  14  	Training Loss: 0.004235867410898209
Test Loss:  0.0030223156791180372
Valid Loss:  0.002900246763601899
Epoch:  15  	Training Loss: 0.0037937425076961517
Test Loss:  0.002676171250641346
Valid Loss:  0.0026021446101367474
Epoch:  16  	Training Loss: 0.003425875212997198
Test Loss:  0.00239002937451005
Valid Loss:  0.002358331112191081
Epoch:  17  	Training Loss: 0.0031213932670652866
Test Loss:  0.002159083727747202
Valid Loss:  0.0021669776178896427
Epoch:  18  	Training Loss: 0.002867282833904028
Test Loss:  0.001967614982277155
Valid Loss:  0.0020106728188693523
Epoch:  19  	Training Loss: 0.002655196934938431
Test Loss:  0.0018113648984581232
Valid Loss:  0.0018864007433876395
Epoch:  20  	Training Loss: 0.00247806403785944
Test Loss:  0.001684393035247922
Valid Loss:  0.00178879639133811
Epoch:  21  	Training Loss: 0.0023301297333091497
Test Loss:  0.0015803633723407984
Valid Loss:  0.001711314544081688
Epoch:  22  	Training Loss: 0.0022065946832299232
Test Loss:  0.0014957605162635446
Valid Loss:  0.0016507778782397509
Epoch:  23  	Training Loss: 0.0021034986712038517
Test Loss:  0.0014268874656409025
Valid Loss:  0.0016036797314882278
Epoch:  24  	Training Loss: 0.0020173480734229088
Test Loss:  0.0013712961226701736
Valid Loss:  0.0015678044874221087
Epoch:  25  	Training Loss: 0.0019453231943771243
Test Loss:  0.0013266956666484475
Valid Loss:  0.0015412128996104002
Epoch:  26  	Training Loss: 0.0018852145876735449
Test Loss:  0.0012908095959573984
Valid Loss:  0.0015215586172416806
Epoch:  27  	Training Loss: 0.0018353242194280028
Test Loss:  0.0012626859825104475
Valid Loss:  0.0015086010098457336
Epoch:  28  	Training Loss: 0.0017936183139681816
Test Loss:  0.0012398653198033571
Valid Loss:  0.001499216421507299
Epoch:  29  	Training Loss: 0.0017588246846571565
Test Loss:  0.001222172286361456
Valid Loss:  0.0014938751701265574
Epoch:  30  	Training Loss: 0.0017297524027526379
Test Loss:  0.0012084003537893295
Valid Loss:  0.001491333357989788
Epoch:  31  	Training Loss: 0.001705416478216648
Test Loss:  0.0011977753601968288
Valid Loss:  0.0014908619923517108
Epoch:  32  	Training Loss: 0.0016850184183567762
Test Loss:  0.0011898772791028023
Valid Loss:  0.0014923415146768093
Epoch:  33  	Training Loss: 0.0016679121181368828
Test Loss:  0.0011840362567454576
Valid Loss:  0.0014950542245060205
Epoch:  34  	Training Loss: 0.0016535843024030328
Test Loss:  0.0011798216728493571
Valid Loss:  0.0014986037276685238
Epoch:  35  	Training Loss: 0.0016415694262832403
Test Loss:  0.0011769834673032165
Valid Loss:  0.001502896542660892
Epoch:  36  	Training Loss: 0.0016314976383000612
Test Loss:  0.0011752380523830652
Valid Loss:  0.0015077274292707443
Epoch:  37  	Training Loss: 0.0016230554319918156
Test Loss:  0.0011742329224944115
Valid Loss:  0.001512641552835703
Epoch:  38  	Training Loss: 0.0016159764491021633
Test Loss:  0.0011739220935851336
Valid Loss:  0.0015177589375525713
Epoch:  39  	Training Loss: 0.001610034960322082
Test Loss:  0.0011741394409909844
Valid Loss:  0.0015229794662445784
Epoch:  40  	Training Loss: 0.0016050499398261309
Test Loss:  0.0011747241951525211
Valid Loss:  0.001528124208562076
Epoch:  41  	Training Loss: 0.001600871910341084
Test Loss:  0.0011755931191146374
Valid Loss:  0.0015331448521465063
Epoch:  42  	Training Loss: 0.001597364665940404
Test Loss:  0.0011766457464545965
Valid Loss:  0.001537963398732245
Epoch:  43  	Training Loss: 0.0015944154001772404
Test Loss:  0.001177841448225081
Valid Loss:  0.0015425893943756819
Epoch:  44  	Training Loss: 0.0015919345896691084
Test Loss:  0.0011791246943175793
Valid Loss:  0.0015470036305487156
Epoch:  45  	Training Loss: 0.00158983888104558
Test Loss:  0.0011804557871073484
Valid Loss:  0.0015511754900217056
Epoch:  46  	Training Loss: 0.0015880630817264318
Test Loss:  0.0011818057391792536
Valid Loss:  0.0015551153337582946
Epoch:  47  	Training Loss: 0.0015865531750023365
Test Loss:  0.0011831431183964014
Valid Loss:  0.0015588081441819668
Epoch:  48  	Training Loss: 0.0015852698124945164
Test Loss:  0.0011844560503959656
Valid Loss:  0.0015622747596353292
Epoch:  49  	Training Loss: 0.0015841705026105046
Test Loss:  0.0011857249774038792
Valid Loss:  0.0015655001625418663
Epoch:  50  	Training Loss: 0.001583225093781948
Test Loss:  0.0011869460577145219
Valid Loss:  0.0015684983227401972
Epoch:  51  	Training Loss: 0.0015824066940695047
Test Loss:  0.001188112422823906
Valid Loss:  0.0015712915919721127
Epoch:  52  	Training Loss: 0.0015816972590982914
Test Loss:  0.001189213478937745
Valid Loss:  0.0015738646034151316
Epoch:  53  	Training Loss: 0.0015810782788321376
Test Loss:  0.0011902542319148779
Valid Loss:  0.0015762539114803076
Epoch:  54  	Training Loss: 0.001580534502863884
Test Loss:  0.0011912350310012698
Valid Loss:  0.001578452531248331
Epoch:  55  	Training Loss: 0.0015800816472619772
Test Loss:  0.0011922605335712433
Valid Loss:  0.0015808094758540392
Epoch:  56  	Training Loss: 0.0015797072555869818
Test Loss:  0.00119322061073035
Valid Loss:  0.0015829349867999554
Epoch:  57  	Training Loss: 0.0015794055070728064
Test Loss:  0.0011941032717004418
Valid Loss:  0.0015848390758037567
Epoch:  58  	Training Loss: 0.0015791517216712236
Test Loss:  0.0011949308682233095
Valid Loss:  0.0015866284957155585
Epoch:  59  	Training Loss: 0.0015789380995556712
Test Loss:  0.0011956999078392982
Valid Loss:  0.0015882530715316534
Epoch:  60  	Training Loss: 0.0015787524171173573
Test Loss:  0.0011964058503508568
Valid Loss:  0.001589748077094555
Epoch:  61  	Training Loss: 0.0015785922296345234
Test Loss:  0.0011970626655966043
Valid Loss:  0.0015911152586340904
Epoch:  62  	Training Loss: 0.0015784518327564
Test Loss:  0.0011977236717939377
Valid Loss:  0.0015925383195281029
Epoch:  63  	Training Loss: 0.0015783400740474463
Test Loss:  0.0011982825817540288
Valid Loss:  0.001593653578311205
Epoch:  64  	Training Loss: 0.0015782350674271584
Test Loss:  0.0011988504556939006
Valid Loss:  0.0015948452055454254
Epoch:  65  	Training Loss: 0.0015781510155647993
Test Loss:  0.001199317048303783
Valid Loss:  0.001595767098478973
Epoch:  66  	Training Loss: 0.0015780730172991753
Test Loss:  0.0011997930705547333
Valid Loss:  0.0015967786312103271
Epoch:  67  	Training Loss: 0.0015780054964125156
Test Loss:  0.0012001877184957266
Valid Loss:  0.0015975490678101778
Epoch:  68  	Training Loss: 0.001577945426106453
Test Loss:  0.0012006050674244761
Valid Loss:  0.0015984392957761884
Epoch:  69  	Training Loss: 0.0015778935048729181
Test Loss:  0.0012009619968011975
Valid Loss:  0.0015991467516869307
Epoch:  70  	Training Loss: 0.0015778482193127275
Test Loss:  0.0012012568768113852
 14%|█▍        | 71/500 [00:55<08:42,  1.22s/it] 15%|█▍        | 73/500 [00:56<06:15,  1.14it/s] 15%|█▌        | 75/500 [00:56<04:32,  1.56it/s] 15%|█▌        | 77/500 [00:56<03:18,  2.13it/s] 16%|█▌        | 79/500 [00:56<02:26,  2.87it/s] 16%|█▌        | 81/500 [01:03<08:25,  1.21s/it] 17%|█▋        | 83/500 [01:03<06:01,  1.15it/s] 17%|█▋        | 85/500 [01:03<04:19,  1.60it/s] 17%|█▋        | 87/500 [01:03<03:09,  2.18it/s] 18%|█▊        | 89/500 [01:03<02:20,  2.93it/s] 18%|█▊        | 91/500 [01:10<08:14,  1.21s/it] 19%|█▊        | 93/500 [01:10<05:52,  1.15it/s] 19%|█▉        | 95/500 [01:10<04:13,  1.60it/s] 19%|█▉        | 97/500 [01:10<03:04,  2.18it/s] 20%|█▉        | 99/500 [01:10<02:16,  2.94it/s] 20%|██        | 101/500 [01:17<08:01,  1.21s/it] 21%|██        | 103/500 [01:17<05:43,  1.16it/s] 21%|██        | 105/500 [01:17<04:07,  1.60it/s] 21%|██▏       | 107/500 [01:17<02:59,  2.18it/s] 22%|██▏       | 109/500 [01:17<02:13,  2.93it/s] 22%|██▏       | 111/500 [01:23<07:45,  1.20s/it] 23%|██▎       | 113/500 [01:24<05:32,  1.17it/s] 23%|██▎       | 115/500 [01:24<03:58,  1.61it/s] 23%|██▎       | 117/500 [01:24<02:53,  2.21it/s] 24%|██▍       | 119/500 [01:24<02:08,  2.97it/s] 24%|██▍       | 121/500 [01:30<07:36,  1.21s/it] 25%|██▍       | 123/500 [01:31<05:26,  1.16it/s] 25%|██▌       | 125/500 [01:31<03:54,  1.60it/s] 25%|██▌       | 127/500 [01:31<02:50,  2.19it/s] 26%|██▌       | 129/500 [01:31<02:05,  2.95it/s] 26%|██▌       | 131/500 [01:38<07:33,  1.23s/it] 27%|██▋       | 133/500 [01:38<05:23,  1.13it/s] 27%|██▋       | 135/500 [01:38<03:53,  1.57it/s] 27%|██▋       | 137/500 [01:38<02:49,  2.14it/s]Valid Loss:  0.0015997111331671476
Epoch:  71  	Training Loss: 0.0015778052620589733
Test Loss:  0.0012015901738777757
Valid Loss:  0.001600428018718958
Epoch:  72  	Training Loss: 0.0015777659136801958
Test Loss:  0.0012018508277833462
Valid Loss:  0.0016009416431188583
Epoch:  73  	Training Loss: 0.0015777295920997858
Test Loss:  0.0012021262664347887
Valid Loss:  0.0016015148721635342
Epoch:  74  	Training Loss: 0.0015776979271322489
Test Loss:  0.0012023102026432753
Valid Loss:  0.0016018464230000973
Epoch:  75  	Training Loss: 0.0015776692889630795
Test Loss:  0.001202546525746584
Valid Loss:  0.00160236656665802
Epoch:  76  	Training Loss: 0.0015776408836245537
Test Loss:  0.001202743616886437
Valid Loss:  0.001602768199518323
Epoch:  77  	Training Loss: 0.0015776155050843954
Test Loss:  0.001202933257445693
Valid Loss:  0.0016031444538384676
Epoch:  78  	Training Loss: 0.0015775904757902026
Test Loss:  0.0012030801735818386
Valid Loss:  0.0016034313011914492
Epoch:  79  	Training Loss: 0.0015775643987581134
Test Loss:  0.0012032313970848918
Valid Loss:  0.0016037754248827696
Epoch:  80  	Training Loss: 0.0015775441424921155
Test Loss:  0.0012033538660034537
Valid Loss:  0.0016040063928812742
Epoch:  81  	Training Loss: 0.0015775214415043592
Test Loss:  0.0012034529354423285
Valid Loss:  0.0016041970811784267
Epoch:  82  	Training Loss: 0.0015774995554238558
Test Loss:  0.001203570980578661
Valid Loss:  0.00160446937661618
Epoch:  83  	Training Loss: 0.001577479881234467
Test Loss:  0.0012036828557029366
Valid Loss:  0.001604690682142973
Epoch:  84  	Training Loss: 0.0015774620696902275
Test Loss:  0.0012037762207910419
Valid Loss:  0.0016048874240368605
Epoch:  85  	Training Loss: 0.0015774439089000225
Test Loss:  0.0012038545683026314
Valid Loss:  0.001605049124918878
Epoch:  86  	Training Loss: 0.0015774248167872429
Test Loss:  0.0012039364082738757
Valid Loss:  0.001605225377716124
Epoch:  87  	Training Loss: 0.0015774071216583252
Test Loss:  0.0012040033470839262
Valid Loss:  0.001605370780453086
Epoch:  88  	Training Loss: 0.0015773903578519821
Test Loss:  0.0012040663277730346
Valid Loss:  0.0016055006999522448
Epoch:  89  	Training Loss: 0.001577373594045639
Test Loss:  0.0012041237205266953
Valid Loss:  0.001605620956979692
Epoch:  90  	Training Loss: 0.001577354734763503
Test Loss:  0.001204152125865221
Valid Loss:  0.001605673343874514
Epoch:  91  	Training Loss: 0.001577340648509562
Test Loss:  0.001204193918965757
Valid Loss:  0.001605799188837409
Epoch:  92  	Training Loss: 0.0015773207414895296
Test Loss:  0.001204233500175178
Valid Loss:  0.001605889410711825
Epoch:  93  	Training Loss: 0.0015773040940985084
Test Loss:  0.0012042706366628408
Valid Loss:  0.0016059722984209657
Epoch:  94  	Training Loss: 0.001577288145199418
Test Loss:  0.001204299391247332
Valid Loss:  0.0016060428461059928
Epoch:  95  	Training Loss: 0.0015772702172398567
Test Loss:  0.0012043258175253868
Valid Loss:  0.0016061075730249286
Epoch:  96  	Training Loss: 0.0015772555489093065
Test Loss:  0.0012043453752994537
Valid Loss:  0.0016061655478551984
Epoch:  97  	Training Loss: 0.0015772411134094
Test Loss:  0.0012043665628880262
Valid Loss:  0.001606215606443584
Epoch:  98  	Training Loss: 0.0015772238839417696
Test Loss:  0.0012043851893395185
Valid Loss:  0.0016062627546489239
Epoch:  99  	Training Loss: 0.001577210146933794
Test Loss:  0.0012043833266943693
Valid Loss:  0.001606257283128798
Epoch:  100  	Training Loss: 0.0015771943144500256
Test Loss:  0.0012043621391057968
Valid Loss:  0.0016062173526734114
Epoch:  101  	Training Loss: 0.0015771808102726936
Test Loss:  0.0012043812312185764
Valid Loss:  0.0016062974464148283
Epoch:  102  	Training Loss: 0.0015771656762808561
Test Loss:  0.0012043870519846678
Valid Loss:  0.0016063223592936993
Epoch:  103  	Training Loss: 0.0015771491453051567
Test Loss:  0.0012043960159644485
Valid Loss:  0.0016063580987975001
Epoch:  104  	Training Loss: 0.0015771358739584684
Test Loss:  0.0012044005561619997
Valid Loss:  0.0016063875518739223
Epoch:  105  	Training Loss: 0.0015771191101521254
Test Loss:  0.0012044032337144017
Valid Loss:  0.0016064099036157131
Epoch:  106  	Training Loss: 0.00157710793428123
Test Loss:  0.0012044067261740565
Valid Loss:  0.0016064285300672054
Epoch:  107  	Training Loss: 0.0015770907048135996
Test Loss:  0.001204407773911953
Valid Loss:  0.0016064437804743648
Epoch:  108  	Training Loss: 0.0015770751051604748
Test Loss:  0.001204407773911953
Valid Loss:  0.001606460427865386
Epoch:  109  	Training Loss: 0.0015770620666444302
Test Loss:  0.0012044018367305398
Valid Loss:  0.001606472535058856
Epoch:  110  	Training Loss: 0.001577046699821949
Test Loss:  0.00120440567843616
Valid Loss:  0.0016064848750829697
Epoch:  111  	Training Loss: 0.0015770330792292953
Test Loss:  0.001204399624839425
Valid Loss:  0.0016064869705587626
Epoch:  112  	Training Loss: 0.0015770159661769867
Test Loss:  0.0012043926399201155
Valid Loss:  0.0016064901137724519
Epoch:  113  	Training Loss: 0.0015770026948302984
Test Loss:  0.0012043884489685297
Valid Loss:  0.0016065032687038183
Epoch:  114  	Training Loss: 0.0015769891906529665
Test Loss:  0.00120438018348068
Valid Loss:  0.0016065058298408985
Epoch:  115  	Training Loss: 0.0015769721940159798
Test Loss:  0.0012043745955452323
Valid Loss:  0.0016065083909779787
Epoch:  116  	Training Loss: 0.0015769595047459006
Test Loss:  0.001204365398734808
Valid Loss:  0.001606503501534462
Epoch:  117  	Training Loss: 0.0015769435558468103
Test Loss:  0.001204357948154211
Valid Loss:  0.0016065050149336457
Epoch:  118  	Training Loss: 0.0015769291203469038
Test Loss:  0.0012043497990816832
Valid Loss:  0.0016065051313489676
Epoch:  119  	Training Loss: 0.0015769156161695719
Test Loss:  0.0012043374590575695
Valid Loss:  0.0016065052477642894
Epoch:  120  	Training Loss: 0.00157690211199224
Test Loss:  0.0012043293099850416
Valid Loss:  0.0016064939554780722
Epoch:  121  	Training Loss: 0.0015768861630931497
Test Loss:  0.0012043185997754335
Valid Loss:  0.0016064910450950265
Epoch:  122  	Training Loss: 0.0015768723096698523
Test Loss:  0.0012043060269206762
Valid Loss:  0.001606489298865199
Epoch:  123  	Training Loss: 0.0015768579905852675
Test Loss:  0.0012042998569086194
Valid Loss:  0.001606479985639453
Epoch:  124  	Training Loss: 0.0015768441371619701
Test Loss:  0.0012042854214087129
Valid Loss:  0.0016064747469499707
Epoch:  125  	Training Loss: 0.001576828071847558
Test Loss:  0.001204280648380518
Valid Loss:  0.0016064654337242246
Epoch:  126  	Training Loss: 0.0015768149169161916
Test Loss:  0.0012042690068483353
Valid Loss:  0.0016064583323895931
Epoch:  127  	Training Loss: 0.0015768010634928942
Test Loss:  0.0012042574817314744
Valid Loss:  0.0016064499504864216
Epoch:  128  	Training Loss: 0.001576784299686551
Test Loss:  0.0012042468879371881
Valid Loss:  0.0016064434312283993
Epoch:  129  	Training Loss: 0.0015767726581543684
Test Loss:  0.0012042364105582237
Valid Loss:  0.0016064334195107222
Epoch:  130  	Training Loss: 0.001576756127178669
Test Loss:  0.0012042272137477994
Valid Loss:  0.0016064259689301252
Epoch:  131  	Training Loss: 0.0015767443692311645
Test Loss:  0.0012042165035381913
Valid Loss:  0.0016064216615632176
Epoch:  132  	Training Loss: 0.0015767328441143036
Test Loss:  0.0012042010203003883
Valid Loss:  0.0016064064111560583
Epoch:  133  	Training Loss: 0.001576717826537788
Test Loss:  0.0012041942682117224
Valid Loss:  0.0016064016381278634
Epoch:  134  	Training Loss: 0.0015767032746225595
Test Loss:  0.001204182393848896
Valid Loss:  0.0016063892981037498
Epoch:  135  	Training Loss: 0.0015766886062920094
Test Loss:  0.0012041726149618626
Valid Loss:  0.0016063814982771873
Epoch:  136  	Training Loss: 0.0015766771975904703
Test Loss:  0.0012041544541716576
Valid Loss:  0.0016063656657934189
Epoch:  137  	Training Loss: 0.001576664624735713
Test Loss:  0.001204148749820888
Valid Loss:  0.001606362289749086
Epoch:  138  	Training Loss: 0.0015766520518809557
Test Loss:  0.001204141415655613
Valid Loss:  0.0016063493676483631
Epoch:  139  	Training Loss: 0.0015766414580866694
Test Loss:  0.0012041297741234303
 28%|██▊       | 139/500 [01:38<02:05,  2.88it/s] 28%|██▊       | 141/500 [01:45<07:11,  1.20s/it] 29%|██▊       | 143/500 [01:45<05:08,  1.16it/s] 29%|██▉       | 145/500 [01:45<03:41,  1.60it/s] 29%|██▉       | 147/500 [01:45<02:41,  2.19it/s] 30%|██▉       | 149/500 [01:45<01:59,  2.94it/s] 30%|███       | 151/500 [01:51<06:55,  1.19s/it] 31%|███       | 153/500 [01:52<04:56,  1.17it/s] 31%|███       | 155/500 [01:52<03:33,  1.62it/s] 31%|███▏      | 157/500 [01:52<02:35,  2.21it/s] 32%|███▏      | 159/500 [01:52<01:54,  2.98it/s] 32%|███▏      | 161/500 [01:58<06:42,  1.19s/it] 33%|███▎      | 163/500 [01:58<04:47,  1.17it/s] 33%|███▎      | 165/500 [01:59<03:26,  1.62it/s] 33%|███▎      | 167/500 [01:59<02:30,  2.21it/s] 34%|███▍      | 169/500 [01:59<01:51,  2.97it/s] 34%|███▍      | 171/500 [02:05<06:31,  1.19s/it] 35%|███▍      | 173/500 [02:05<04:39,  1.17it/s] 35%|███▌      | 175/500 [02:05<03:20,  1.62it/s] 35%|███▌      | 177/500 [02:06<02:25,  2.21it/s] 36%|███▌      | 179/500 [02:06<01:48,  2.97it/s] 36%|███▌      | 181/500 [02:12<06:17,  1.18s/it] 37%|███▋      | 183/500 [02:12<04:29,  1.18it/s] 37%|███▋      | 185/500 [02:12<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:12<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:13<01:44,  2.97it/s] 38%|███▊      | 191/500 [02:19<06:09,  1.20s/it] 39%|███▊      | 193/500 [02:19<04:23,  1.16it/s] 39%|███▉      | 195/500 [02:19<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:19<02:17,  2.20it/s] 40%|███▉      | 199/500 [02:20<01:41,  2.97it/s] 40%|████      | 201/500 [02:26<06:02,  1.21s/it] 41%|████      | 203/500 [02:26<04:17,  1.15it/s] 41%|████      | 205/500 [02:26<03:05,  1.59it/s] 41%|████▏     | 207/500 [02:26<02:15,  2.16it/s]Valid Loss:  0.0016063377261161804
Epoch:  140  	Training Loss: 0.0015766284195706248
Test Loss:  0.001204115804284811
Valid Loss:  0.0016063337679952383
Epoch:  141  	Training Loss: 0.0015766164287924767
Test Loss:  0.0012041046284139156
Valid Loss:  0.0016063221264630556
Epoch:  142  	Training Loss: 0.0015766064170747995
Test Loss:  0.0012040948495268822
Valid Loss:  0.0016063125804066658
Epoch:  143  	Training Loss: 0.0015765913994982839
Test Loss:  0.001204082160256803
Valid Loss:  0.0016063012881204486
Epoch:  144  	Training Loss: 0.0015765810385346413
Test Loss:  0.0012040715664625168
Valid Loss:  0.0016062925569713116
Epoch:  145  	Training Loss: 0.001576568465679884
Test Loss:  0.0012040601577609777
Valid Loss:  0.0016062797512859106
Epoch:  146  	Training Loss: 0.0015765596181154251
Test Loss:  0.0012040480505675077
Valid Loss:  0.0016062692739069462
Epoch:  147  	Training Loss: 0.0015765477437525988
Test Loss:  0.0012040382716804743
Valid Loss:  0.001606255304068327
Epoch:  148  	Training Loss: 0.0015765366842970252
Test Loss:  0.0012040266301482916
Valid Loss:  0.001606247154995799
Epoch:  149  	Training Loss: 0.0015765251591801643
Test Loss:  0.001204017549753189
Valid Loss:  0.001606234349310398
Epoch:  150  	Training Loss: 0.001576512586325407
Test Loss:  0.0012040077708661556
Valid Loss:  0.0016062280628830194
Epoch:  151  	Training Loss: 0.0015765017597004771
Test Loss:  0.0012039939174428582
Valid Loss:  0.0016062159556895494
Epoch:  152  	Training Loss: 0.0015764887211844325
Test Loss:  0.001203982625156641
Valid Loss:  0.0016062023350968957
Epoch:  153  	Training Loss: 0.0015764774288982153
Test Loss:  0.001203974592499435
Valid Loss:  0.0016061970964074135
Epoch:  154  	Training Loss: 0.001576468930579722
Test Loss:  0.0012039643479511142
Valid Loss:  0.0016061885980889201
Epoch:  155  	Training Loss: 0.0015764579875394702
Test Loss:  0.0012039508437737823
Valid Loss:  0.0016061767237260938
Epoch:  156  	Training Loss: 0.0015764448326081038
Test Loss:  0.0012039414141327143
Valid Loss:  0.0016061699716374278
Epoch:  157  	Training Loss: 0.0015764355193823576
Test Loss:  0.0012039293069392443
Valid Loss:  0.0016061628703027964
Epoch:  158  	Training Loss: 0.0015764241106808186
Test Loss:  0.0012039190623909235
Valid Loss:  0.0016061537899076939
Epoch:  159  	Training Loss: 0.0015764154959470034
Test Loss:  0.001203910680487752
Valid Loss:  0.0016061421483755112
Epoch:  160  	Training Loss: 0.0015764068812131882
Test Loss:  0.001203899271786213
Valid Loss:  0.0016061326023191214
Epoch:  161  	Training Loss: 0.0015763940755277872
Test Loss:  0.0012038875138387084
Valid Loss:  0.0016061286441981792
Epoch:  162  	Training Loss: 0.0015763838309794664
Test Loss:  0.0012038805289193988
Valid Loss:  0.001606122124940157
Epoch:  163  	Training Loss: 0.0015763749834150076
Test Loss:  0.0012038671411573887
Valid Loss:  0.0016061123460531235
Epoch:  164  	Training Loss: 0.0015763647388666868
Test Loss:  0.001203857478685677
Valid Loss:  0.0016061082715168595
Epoch:  165  	Training Loss: 0.001576352515257895
Test Loss:  0.0012038483982905746
Valid Loss:  0.0016060989582911134
Epoch:  166  	Training Loss: 0.0015763439005240798
Test Loss:  0.0012038343120366335
Valid Loss:  0.0016060855705291033
Epoch:  167  	Training Loss: 0.0015763358678668737
Test Loss:  0.0012038245331496
Valid Loss:  0.0016060791676864028
Epoch:  168  	Training Loss: 0.001576324226334691
Test Loss:  0.001203817198984325
Valid Loss:  0.0016060713678598404
Epoch:  169  	Training Loss: 0.001576312119141221
Test Loss:  0.0012038041604682803
Valid Loss:  0.0016060681082308292
Epoch:  170  	Training Loss: 0.0015763046685606241
Test Loss:  0.0012037932174280286
Valid Loss:  0.0016060578636825085
Epoch:  171  	Training Loss: 0.0015762968687340617
Test Loss:  0.0012037826236337423
Valid Loss:  0.0016060539055615664
Epoch:  172  	Training Loss: 0.0015762858092784882
Test Loss:  0.0012037749402225018
Valid Loss:  0.0016060436610132456
Epoch:  173  	Training Loss: 0.001576276496052742
Test Loss:  0.0012037605047225952
Valid Loss:  0.0016060362104326487
Epoch:  174  	Training Loss: 0.0015762649709358811
Test Loss:  0.0012037537526339293
Valid Loss:  0.001606025150977075
Epoch:  175  	Training Loss: 0.0015762550756335258
Test Loss:  0.0012037414126098156
Valid Loss:  0.0016060203779488802
Epoch:  176  	Training Loss: 0.001576245529577136
Test Loss:  0.0012037318665534258
Valid Loss:  0.0016060136258602142
Epoch:  177  	Training Loss: 0.0015762371476739645
Test Loss:  0.0012037185952067375
Valid Loss:  0.0016060096677392721
Epoch:  178  	Training Loss: 0.001576226670295
Test Loss:  0.0012037113774567842
Valid Loss:  0.0016059984918683767
Epoch:  179  	Training Loss: 0.001576215261593461
Test Loss:  0.001203704159706831
Valid Loss:  0.0016059883637353778
Epoch:  180  	Training Loss: 0.001576207228936255
Test Loss:  0.0012036936823278666
Valid Loss:  0.00160598277579993
Epoch:  181  	Training Loss: 0.0015761995455250144
Test Loss:  0.0012036864645779133
Valid Loss:  0.001605974161066115
Epoch:  182  	Training Loss: 0.0015761891845613718
Test Loss:  0.0012036734260618687
Valid Loss:  0.0016059665940701962
Epoch:  183  	Training Loss: 0.00157617824152112
Test Loss:  0.0012036636471748352
Valid Loss:  0.0016059563495218754
Epoch:  184  	Training Loss: 0.001576168229803443
Test Loss:  0.0012036552652716637
Valid Loss:  0.0016059534391388297
Epoch:  185  	Training Loss: 0.0015761579852551222
Test Loss:  0.0012036440894007683
Valid Loss:  0.001605939120054245
Epoch:  186  	Training Loss: 0.0015761521644890308
Test Loss:  0.0012036333791911602
Valid Loss:  0.0016059374902397394
Epoch:  187  	Training Loss: 0.0015761409886181355
Test Loss:  0.0012036275584250689
Valid Loss:  0.0016059335321187973
Epoch:  188  	Training Loss: 0.0015761316753923893
Test Loss:  0.0012036158004775643
Valid Loss:  0.0016059203771874309
Epoch:  189  	Training Loss: 0.001576119801029563
Test Loss:  0.0012036056723445654
Valid Loss:  0.0016059157205745578
Epoch:  190  	Training Loss: 0.0015761100221425295
Test Loss:  0.0012035989202558994
Valid Loss:  0.0016059123445302248
Epoch:  191  	Training Loss: 0.001576101640239358
Test Loss:  0.0012035872787237167
Valid Loss:  0.0016059032641351223
Epoch:  192  	Training Loss: 0.0015760913956910372
Test Loss:  0.0012035807594656944
Valid Loss:  0.0016059000045061111
Epoch:  193  	Training Loss: 0.0015760809183120728
Test Loss:  0.0012035730760544538
Valid Loss:  0.0016058911569416523
Epoch:  194  	Training Loss: 0.0015760730020701885
Test Loss:  0.0012035627150908113
Valid Loss:  0.0016058877808973193
Epoch:  195  	Training Loss: 0.0015760634560137987
Test Loss:  0.0012035489780828357
Valid Loss:  0.0016058774199336767
Epoch:  196  	Training Loss: 0.0015760529786348343
Test Loss:  0.0012035390827804804
Valid Loss:  0.0016058715991675854
Epoch:  197  	Training Loss: 0.001576044480316341
Test Loss:  0.0012035336112603545
Valid Loss:  0.0016058613546192646
Epoch:  198  	Training Loss: 0.0015760345850139856
Test Loss:  0.001203527208417654
Valid Loss:  0.001605854369699955
Epoch:  199  	Training Loss: 0.0015760255046188831
Test Loss:  0.0012035123072564602
Valid Loss:  0.0016058504115790129
Epoch:  200  	Training Loss: 0.0015760150272399187
Test Loss:  0.0012035060208290815
Valid Loss:  0.0016058464534580708
Epoch:  201  	Training Loss: 0.0015760061796754599
Test Loss:  0.0012034948449581861
Valid Loss:  0.0016058359760791063
Epoch:  202  	Training Loss: 0.0015759975649416447
Test Loss:  0.0012034887913614511
Valid Loss:  0.0016058201435953379
Epoch:  203  	Training Loss: 0.0015759874368086457
Test Loss:  0.0012034818064421415
Valid Loss:  0.0016058229375630617
Epoch:  204  	Training Loss: 0.0015759782399982214
Test Loss:  0.0012034716783091426
Valid Loss:  0.0016058171167969704
Epoch:  205  	Training Loss: 0.001575971720740199
Test Loss:  0.0012034624814987183
Valid Loss:  0.0016058075707405806
Epoch:  206  	Training Loss: 0.001575962291099131
Test Loss:  0.0012034554965794086
Valid Loss:  0.0016058022156357765
Epoch:  207  	Training Loss: 0.001575956353917718
Test Loss:  0.001203442458063364
Valid Loss:  0.0016057798638939857
 42%|████▏     | 209/500 [02:27<01:41,  2.88it/s] 42%|████▏     | 211/500 [02:33<05:46,  1.20s/it] 43%|████▎     | 213/500 [02:33<04:07,  1.16it/s] 43%|████▎     | 215/500 [02:33<02:57,  1.61it/s] 43%|████▎     | 217/500 [02:33<02:08,  2.19it/s] 44%|████▍     | 219/500 [02:34<01:35,  2.95it/s] 44%|████▍     | 221/500 [02:40<05:30,  1.19s/it] 45%|████▍     | 223/500 [02:40<03:55,  1.18it/s] 45%|████▌     | 225/500 [02:40<02:49,  1.63it/s] 45%|████▌     | 227/500 [02:40<02:04,  2.19it/s] 46%|████▌     | 229/500 [02:40<01:33,  2.91it/s] 46%|████▌     | 231/500 [02:47<05:24,  1.21s/it] 47%|████▋     | 233/500 [02:47<03:51,  1.15it/s] 47%|████▋     | 235/500 [02:47<02:45,  1.60it/s] 47%|████▋     | 237/500 [02:47<02:00,  2.18it/s] 48%|████▊     | 239/500 [02:48<01:30,  2.88it/s] 48%|████▊     | 241/500 [02:54<05:15,  1.22s/it] 49%|████▊     | 243/500 [02:54<03:44,  1.15it/s] 49%|████▉     | 245/500 [02:54<02:40,  1.59it/s] 49%|████▉     | 247/500 [02:54<01:56,  2.17it/s] 50%|████▉     | 249/500 [02:55<01:25,  2.92it/s] 50%|█████     | 251/500 [03:01<04:57,  1.19s/it] 51%|█████     | 253/500 [03:01<03:31,  1.17it/s] 51%|█████     | 255/500 [03:01<02:31,  1.61it/s] 51%|█████▏    | 257/500 [03:01<01:50,  2.20it/s] 52%|█████▏    | 259/500 [03:01<01:21,  2.96it/s] 52%|█████▏    | 261/500 [03:08<04:40,  1.17s/it] 53%|█████▎    | 263/500 [03:08<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:08<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:08<01:43,  2.24it/s] 54%|█████▍    | 269/500 [03:08<01:16,  3.00it/s] 54%|█████▍    | 271/500 [03:15<04:45,  1.25s/it] 55%|█████▍    | 273/500 [03:15<03:22,  1.12it/s] 55%|█████▌    | 275/500 [03:15<02:25,  1.55it/s]Epoch:  208  	Training Loss: 0.0015759465750306845
Test Loss:  0.0012034373357892036
Valid Loss:  0.0016057838220149279
Epoch:  209  	Training Loss: 0.0015759370289742947
Test Loss:  0.001203430350869894
Valid Loss:  0.0016057835891842842
Epoch:  210  	Training Loss: 0.001575932139530778
Test Loss:  0.001203426392748952
Valid Loss:  0.001605776371434331
Epoch:  211  	Training Loss: 0.001575923291966319
Test Loss:  0.0012034180108457804
Valid Loss:  0.0016057733446359634
Epoch:  212  	Training Loss: 0.0015759158413857222
Test Loss:  0.0012034084647893906
Valid Loss:  0.0016057683387771249
Epoch:  213  	Training Loss: 0.0015759100206196308
Test Loss:  0.001203404739499092
Valid Loss:  0.001605762867256999
Epoch:  214  	Training Loss: 0.0015758995432406664
Test Loss:  0.0012033958919346333
Valid Loss:  0.001605764962732792
Epoch:  215  	Training Loss: 0.0015758945373818278
Test Loss:  0.0012033885577693582
Valid Loss:  0.0016057544853538275
Epoch:  216  	Training Loss: 0.0015758868539705873
Test Loss:  0.0012033822713419795
Valid Loss:  0.0016057465691119432
Epoch:  217  	Training Loss: 0.0015758802182972431
Test Loss:  0.001203371910378337
Valid Loss:  0.001605740049853921
Epoch:  218  	Training Loss: 0.0015758720692247152
Test Loss:  0.0012033641105517745
Valid Loss:  0.0016057395841926336
Epoch:  219  	Training Loss: 0.001575865433551371
Test Loss:  0.0012033587554469705
Valid Loss:  0.0016057356260716915
Epoch:  220  	Training Loss: 0.0015758578665554523
Test Loss:  0.001203353051096201
Valid Loss:  0.001605728641152382
Epoch:  221  	Training Loss: 0.0015758501831442118
Test Loss:  0.001203344203531742
Valid Loss:  0.0016057263128459454
Epoch:  222  	Training Loss: 0.0015758437803015113
Test Loss:  0.0012033400125801563
Valid Loss:  0.0016057242173701525
Epoch:  223  	Training Loss: 0.001575839938595891
Test Loss:  0.0012033297680318356
Valid Loss:  0.0016057195607572794
Epoch:  224  	Training Loss: 0.0015758329536765814
Test Loss:  0.0012033273233100772
Valid Loss:  0.0016057159518823028
Epoch:  225  	Training Loss: 0.0015758250374346972
Test Loss:  0.001203318010084331
Valid Loss:  0.0016057156026363373
Epoch:  226  	Training Loss: 0.0015758185181766748
Test Loss:  0.0012033134698867798
Valid Loss:  0.001605706987902522
Epoch:  227  	Training Loss: 0.001575810951180756
Test Loss:  0.0012033043894916773
Valid Loss:  0.0016057051252573729
Epoch:  228  	Training Loss: 0.0015758066438138485
Test Loss:  0.0012032989179715514
Valid Loss:  0.0016056930180639029
Epoch:  229  	Training Loss: 0.0015757987275719643
Test Loss:  0.001203291118144989
Valid Loss:  0.001605689525604248
Epoch:  230  	Training Loss: 0.0015757931396365166
Test Loss:  0.0012032841332256794
Valid Loss:  0.001605694298632443
Epoch:  231  	Training Loss: 0.0015757880173623562
Test Loss:  0.0012032766826450825
Valid Loss:  0.0016056860331445932
Epoch:  232  	Training Loss: 0.0015757789369672537
Test Loss:  0.0012032710947096348
Valid Loss:  0.001605681492947042
Epoch:  233  	Training Loss: 0.0015757727669551969
Test Loss:  0.0012032611994072795
Valid Loss:  0.0016056785825639963
Epoch:  234  	Training Loss: 0.0015757698565721512
Test Loss:  0.001203258172608912
Valid Loss:  0.0016056757885962725
Epoch:  235  	Training Loss: 0.0015757635701447725
Test Loss:  0.0012032506056129932
Valid Loss:  0.0016056736931204796
Epoch:  236  	Training Loss: 0.0015757584478706121
Test Loss:  0.0012032457161694765
Valid Loss:  0.0016056662425398827
Epoch:  237  	Training Loss: 0.0015757521614432335
Test Loss:  0.0012032422237098217
Valid Loss:  0.0016056620515882969
Epoch:  238  	Training Loss: 0.0015757475048303604
Test Loss:  0.0012032336089760065
Valid Loss:  0.0016056632157415152
Epoch:  239  	Training Loss: 0.0015757400542497635
Test Loss:  0.0012032333761453629
Valid Loss:  0.0016056578606367111
Epoch:  240  	Training Loss: 0.0015757341170683503
Test Loss:  0.0012032246449962258
Valid Loss:  0.0016056480817496777
Epoch:  241  	Training Loss: 0.0015757324872538447
Test Loss:  0.001203217078000307
Valid Loss:  0.001605647150427103
Epoch:  242  	Training Loss: 0.0015757237561047077
Test Loss:  0.001203212421387434
Valid Loss:  0.001605643192306161
Epoch:  243  	Training Loss: 0.0015757207293063402
Test Loss:  0.0012032062513753772
Valid Loss:  0.001605640398338437
Epoch:  244  	Training Loss: 0.0015757158398628235
Test Loss:  0.0012032035738229752
Valid Loss:  0.0016056334134191275
Epoch:  245  	Training Loss: 0.0015757100190967321
Test Loss:  0.0012031968217343092
Valid Loss:  0.0016056360909715295
Epoch:  246  	Training Loss: 0.0015757036162540317
Test Loss:  0.001203189487569034
Valid Loss:  0.0016056307358667254
Epoch:  247  	Training Loss: 0.0015757004730403423
Test Loss:  0.0012031849473714828
Valid Loss:  0.0016056286403909326
Epoch:  248  	Training Loss: 0.001575696631334722
Test Loss:  0.0012031788937747478
Valid Loss:  0.0016056234017014503
Epoch:  249  	Training Loss: 0.0015756901120766997
Test Loss:  0.0012031736550852656
Valid Loss:  0.0016056210733950138
Epoch:  250  	Training Loss: 0.0015756858047097921
Test Loss:  0.0012031698133796453
Valid Loss:  0.0016056178137660027
Epoch:  251  	Training Loss: 0.0015756807988509536
Test Loss:  0.001203164691105485
Valid Loss:  0.0016056213062256575
Epoch:  252  	Training Loss: 0.001575674396008253
Test Loss:  0.0012031611986458302
Valid Loss:  0.0016056103631854057
Epoch:  253  	Training Loss: 0.001575671718455851
Test Loss:  0.001203153165988624
Valid Loss:  0.001605610130354762
Epoch:  254  	Training Loss: 0.001575665781274438
Test Loss:  0.00120314653031528
Valid Loss:  0.0016056086169555783
Epoch:  255  	Training Loss: 0.0015756585635244846
Test Loss:  0.0012031395453959703
Valid Loss:  0.0016056043095886707
Epoch:  256  	Training Loss: 0.0015756553038954735
Test Loss:  0.0012031362857669592
Valid Loss:  0.0016056010499596596
Epoch:  257  	Training Loss: 0.001575651578605175
Test Loss:  0.0012031299993395805
Valid Loss:  0.001605598023161292
Epoch:  258  	Training Loss: 0.0015756452921777964
Test Loss:  0.0012031260412186384
Valid Loss:  0.001605592668056488
Epoch:  259  	Training Loss: 0.0015756411012262106
Test Loss:  0.001203120220452547
Valid Loss:  0.0016055938322097063
Epoch:  260  	Training Loss: 0.0015756344655528665
Test Loss:  0.0012031157966703176
Valid Loss:  0.0016055863816291094
Epoch:  261  	Training Loss: 0.0015756298089399934
Test Loss:  0.001203109510242939
Valid Loss:  0.0016055844025686383
Epoch:  262  	Training Loss: 0.0015756262000650167
Test Loss:  0.0012031060177832842
Valid Loss:  0.0016055791638791561
Epoch:  263  	Training Loss: 0.0015756223583593965
Test Loss:  0.0012031004298478365
Valid Loss:  0.0016055788146331906
Epoch:  264  	Training Loss: 0.001575617236085236
Test Loss:  0.0012030957732349634
Valid Loss:  0.0016055756714195013
Epoch:  265  	Training Loss: 0.001575611298903823
Test Loss:  0.0012030868092551827
Valid Loss:  0.0016055731102824211
Epoch:  266  	Training Loss: 0.0015756061766296625
Test Loss:  0.0012030823854729533
Valid Loss:  0.0016055703163146973
Epoch:  267  	Training Loss: 0.0015756022185087204
Test Loss:  0.0012030801735818386
Valid Loss:  0.001605565776117146
Epoch:  268  	Training Loss: 0.0015755966305732727
Test Loss:  0.0012030713260173798
Valid Loss:  0.001605564379133284
Epoch:  269  	Training Loss: 0.0015755929052829742
Test Loss:  0.001203068415634334
Valid Loss:  0.0016055603045970201
Epoch:  270  	Training Loss: 0.0015755891799926758
Test Loss:  0.0012030611978843808
Valid Loss:  0.0016055613523349166
Epoch:  271  	Training Loss: 0.0015755844069644809
Test Loss:  0.0012030546786263585
Valid Loss:  0.0016055547166615725
Epoch:  272  	Training Loss: 0.0015755798667669296
Test Loss:  0.0012030492071062326
Valid Loss:  0.0016055535525083542
Epoch:  273  	Training Loss: 0.0015755733475089073
Test Loss:  0.001203045598231256
Valid Loss:  0.0016055500600486994
Epoch:  274  	Training Loss: 0.0015755700878798962
Test Loss:  0.001203038264065981
Valid Loss:  0.0016055455198511481
Epoch:  275  	Training Loss: 0.0015755651984363794
Test Loss:  0.0012030362850055099
Valid Loss:  0.0016055464511737227
Epoch:  276  	Training Loss: 0.0015755603089928627
Test Loss:   55%|█████▌    | 277/500 [03:15<01:45,  2.12it/s] 56%|█████▌    | 279/500 [03:16<01:17,  2.85it/s] 56%|█████▌    | 281/500 [03:22<04:21,  1.20s/it] 57%|█████▋    | 283/500 [03:22<03:06,  1.16it/s] 57%|█████▋    | 285/500 [03:22<02:14,  1.60it/s] 57%|█████▋    | 287/500 [03:22<01:37,  2.19it/s] 58%|█████▊    | 289/500 [03:22<01:11,  2.95it/s] 58%|█████▊    | 291/500 [03:29<04:08,  1.19s/it] 59%|█████▊    | 293/500 [03:29<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:29<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:29<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:29<01:07,  2.96it/s] 60%|██████    | 301/500 [03:36<03:59,  1.20s/it] 61%|██████    | 303/500 [03:36<02:49,  1.16it/s] 61%|██████    | 305/500 [03:36<02:01,  1.60it/s] 61%|██████▏   | 307/500 [03:36<01:28,  2.19it/s] 62%|██████▏   | 309/500 [03:36<01:04,  2.94it/s] 62%|██████▏   | 311/500 [03:43<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:43<02:40,  1.17it/s] 63%|██████▎   | 315/500 [03:43<01:54,  1.61it/s] 63%|██████▎   | 317/500 [03:43<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:43<01:01,  2.96it/s] 64%|██████▍   | 321/500 [03:50<03:37,  1.21s/it] 65%|██████▍   | 323/500 [03:50<02:34,  1.15it/s] 65%|██████▌   | 325/500 [03:50<01:50,  1.58it/s] 65%|██████▌   | 327/500 [03:50<01:19,  2.16it/s] 66%|██████▌   | 329/500 [03:50<00:58,  2.91it/s] 66%|██████▌   | 331/500 [03:57<03:21,  1.19s/it] 67%|██████▋   | 333/500 [03:57<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:57<01:42,  1.61it/s] 67%|██████▋   | 337/500 [03:57<01:13,  2.20it/s] 68%|██████▊   | 339/500 [03:57<00:54,  2.97it/s] 68%|██████▊   | 341/500 [04:04<03:12,  1.21s/it] 69%|██████▊   | 343/500 [04:04<02:16,  1.15it/s]0.0012030296493321657
Valid Loss:  0.0016055421438068151
Epoch:  277  	Training Loss: 0.0015755549538880587
Test Loss:  0.0012030251091346145
Valid Loss:  0.0016055421438068151
Epoch:  278  	Training Loss: 0.0015755512285977602
Test Loss:  0.0012030217330902815
Valid Loss:  0.0016055379528552294
Epoch:  279  	Training Loss: 0.0015755492495372891
Test Loss:  0.0012030145153403282
Valid Loss:  0.0016055318992584944
Epoch:  280  	Training Loss: 0.001575543312355876
Test Loss:  0.0012030070647597313
Valid Loss:  0.0016055295709520578
Epoch:  281  	Training Loss: 0.0015755407512187958
Test Loss:  0.0012030042707920074
Valid Loss:  0.0016055282903835177
Epoch:  282  	Training Loss: 0.0015755377244204283
Test Loss:  0.0012030010111629963
Valid Loss:  0.0016055278247222304
Epoch:  283  	Training Loss: 0.0015755316708236933
Test Loss:  0.001202995190396905
Valid Loss:  0.001605524681508541
Epoch:  284  	Training Loss: 0.0015755263157188892
Test Loss:  0.001202995190396905
Valid Loss:  0.0016055215382948518
Epoch:  285  	Training Loss: 0.0015755228232592344
Test Loss:  0.0012029882054775953
Valid Loss:  0.0016055182786658406
Epoch:  286  	Training Loss: 0.0015755182830616832
Test Loss:  0.0012029869249090552
Valid Loss:  0.0016055167652666569
Epoch:  287  	Training Loss: 0.0015755144413560629
Test Loss:  0.001202980289235711
Valid Loss:  0.0016055081505328417
Epoch:  288  	Training Loss: 0.0015755121130496264
Test Loss:  0.0012029750505462289
Valid Loss:  0.0016055053565651178
Epoch:  289  	Training Loss: 0.0015755085041746497
Test Loss:  0.0012029658537358046
Valid Loss:  0.0016055067535489798
Epoch:  290  	Training Loss: 0.0015755021013319492
Test Loss:  0.0012029591016471386
Valid Loss:  0.0016055009327828884
Epoch:  291  	Training Loss: 0.0015754979103803635
Test Loss:  0.0012029568897560239
Valid Loss:  0.0016054976731538773
Epoch:  292  	Training Loss: 0.0015754944179207087
Test Loss:  0.0012029511854052544
Valid Loss:  0.0016054981388151646
Epoch:  293  	Training Loss: 0.0015754925552755594
Test Loss:  0.0012029485078528523
Valid Loss:  0.0016054974403232336
Epoch:  294  	Training Loss: 0.00157548685092479
Test Loss:  0.001202944666147232
Valid Loss:  0.0016054948791861534
Epoch:  295  	Training Loss: 0.001575482776388526
Test Loss:  0.0012029417557641864
Valid Loss:  0.0016054906882345676
Epoch:  296  	Training Loss: 0.0015754792839288712
Test Loss:  0.0012029354693368077
Valid Loss:  0.0016054876614362001
Epoch:  297  	Training Loss: 0.001575475325807929
Test Loss:  0.001202927902340889
Valid Loss:  0.0016054866136983037
Epoch:  298  	Training Loss: 0.0015754714841023088
Test Loss:  0.0012029269710183144
Valid Loss:  0.0016054875450208783
Epoch:  299  	Training Loss: 0.0015754683408886194
Test Loss:  0.0012029210338369012
Valid Loss:  0.001605482306331396
Epoch:  300  	Training Loss: 0.0015754634514451027
Test Loss:  0.0012029130011796951
Valid Loss:  0.001605479745194316
Epoch:  301  	Training Loss: 0.0015754601918160915
Test Loss:  0.0012029086938127875
Valid Loss:  0.0016054741572588682
Epoch:  302  	Training Loss: 0.0015754550695419312
Test Loss:  0.0012029046192765236
Valid Loss:  0.00160547299310565
Epoch:  303  	Training Loss: 0.0015754514606669545
Test Loss:  0.0012029024073854089
Valid Loss:  0.0016054719453677535
Epoch:  304  	Training Loss: 0.0015754475025460124
Test Loss:  0.0012028987985104322
Valid Loss:  0.0016054629813879728
Epoch:  305  	Training Loss: 0.0015754431951791048
Test Loss:  0.0012028918135911226
Valid Loss:  0.0016054571606218815
Epoch:  306  	Training Loss: 0.0015754392370581627
Test Loss:  0.0012028838973492384
Valid Loss:  0.0016054579755291343
Epoch:  307  	Training Loss: 0.0015754386549815536
Test Loss:  0.00120288017205894
Valid Loss:  0.0016054571606218815
Epoch:  308  	Training Loss: 0.0015754334162920713
Test Loss:  0.0012028769124299288
Valid Loss:  0.0016054564621299505
Epoch:  309  	Training Loss: 0.0015754273626953363
Test Loss:  0.0012028736528009176
Valid Loss:  0.0016054557636380196
Epoch:  310  	Training Loss: 0.0015754250343888998
Test Loss:  0.001202865969389677
Valid Loss:  0.001605452038347721
Epoch:  311  	Training Loss: 0.0015754194464534521
Test Loss:  0.001202861312776804
Valid Loss:  0.0016054443549364805
Epoch:  312  	Training Loss: 0.0015754157211631536
Test Loss:  0.001202859217301011
Valid Loss:  0.0016054450534284115
Epoch:  313  	Training Loss: 0.0015754115302115679
Test Loss:  0.001202853163704276
Valid Loss:  0.0016054415609687567
Epoch:  314  	Training Loss: 0.0015754071064293385
Test Loss:  0.0012028439668938518
Valid Loss:  0.0016054342268034816
Epoch:  315  	Training Loss: 0.0015754044288769364
Test Loss:  0.0012028455967083573
Valid Loss:  0.0016054358566179872
Epoch:  316  	Training Loss: 0.0015754015184938908
Test Loss:  0.0012028379132971168
Valid Loss:  0.001605433993972838
Epoch:  317  	Training Loss: 0.0015753972111269832
Test Loss:  0.001202834420837462
Valid Loss:  0.0016054294537752867
Epoch:  318  	Training Loss: 0.0015753920888528228
Test Loss:  0.001202827668748796
Valid Loss:  0.0016054287552833557
Epoch:  319  	Training Loss: 0.001575389178469777
Test Loss:  0.001202824292704463
Valid Loss:  0.0016054282896220684
Epoch:  320  	Training Loss: 0.0015753875486552715
Test Loss:  0.0012028194032609463
Valid Loss:  0.0016054247971624136
Epoch:  321  	Training Loss: 0.0015753837069496512
Test Loss:  0.001202816958539188
Valid Loss:  0.0016054216539487243
Epoch:  322  	Training Loss: 0.0015753792831674218
Test Loss:  0.0012028131168335676
Valid Loss:  0.0016054195584729314
Epoch:  323  	Training Loss: 0.001575374393723905
Test Loss:  0.0012028136989101768
Valid Loss:  0.001605415134690702
Epoch:  324  	Training Loss: 0.0015753702027723193
Test Loss:  0.0012028082273900509
Valid Loss:  0.0016054135048761964
Epoch:  325  	Training Loss: 0.0015753679908812046
Test Loss:  0.001202802755869925
Valid Loss:  0.0016054126899689436
Epoch:  326  	Training Loss: 0.0015753655461594462
Test Loss:  0.0012027978664264083
Valid Loss:  0.0016054102452471852
Epoch:  327  	Training Loss: 0.0015753612387925386
Test Loss:  0.0012027935590595007
Valid Loss:  0.001605407102033496
Epoch:  328  	Training Loss: 0.0015753579791635275
Test Loss:  0.0012027909979224205
Valid Loss:  0.0016054040752351284
Epoch:  329  	Training Loss: 0.0015753546031191945
Test Loss:  0.0012027885532006621
Valid Loss:  0.0016054032603278756
Epoch:  330  	Training Loss: 0.001575351576320827
Test Loss:  0.001202779938466847
Valid Loss:  0.0016053963918238878
Epoch:  331  	Training Loss: 0.001575346803292632
Test Loss:  0.001202777260914445
Valid Loss:  0.001605391502380371
Epoch:  332  	Training Loss: 0.0015753444749861956
Test Loss:  0.0012027735356241465
Valid Loss:  0.0016053937142714858
Epoch:  333  	Training Loss: 0.0015753398183733225
Test Loss:  0.0012027719058096409
Valid Loss:  0.0016053905710577965
Epoch:  334  	Training Loss: 0.0015753358602523804
Test Loss:  0.0012027682969346642
Valid Loss:  0.0016053917352110147
Epoch:  335  	Training Loss: 0.0015753324842080474
Test Loss:  0.0012027635239064693
Valid Loss:  0.0016053847502917051
Epoch:  336  	Training Loss: 0.0015753294574096799
Test Loss:  0.0012027595657855272
Valid Loss:  0.0016053835861384869
Epoch:  337  	Training Loss: 0.0015753263141959906
Test Loss:  0.001202756422571838
Valid Loss:  0.0016053798608481884
Epoch:  338  	Training Loss: 0.0015753230545669794
Test Loss:  0.001202749670483172
Valid Loss:  0.001605380792170763
Epoch:  339  	Training Loss: 0.0015753202605992556
Test Loss:  0.0012027476914227009
Valid Loss:  0.0016053771832957864
Epoch:  340  	Training Loss: 0.0015753154875710607
Test Loss:  0.0012027407065033913
Valid Loss:  0.0016053724102675915
Epoch:  341  	Training Loss: 0.001575312577188015
Test Loss:  0.0012027400080114603
Valid Loss:  0.0016053670551627874
Epoch:  342  	Training Loss: 0.0015753086190670729
Test Loss:  0.001202736864797771
Valid Loss:  0.0016053628642112017
Epoch:  343  	Training Loss: 0.0015753039624541998
Test Loss:  0.001202728832140565
Valid Loss:  0.0016053621657192707
Epoch:  344  	Training Loss: 0.0015753016341477633
Test Loss:  0.0012027248740196228
Valid Loss:  0.001605362631380558
 69%|██████▉   | 345/500 [04:04<01:37,  1.59it/s] 69%|██████▉   | 347/500 [04:04<01:10,  2.16it/s] 70%|██████▉   | 349/500 [04:04<00:52,  2.90it/s] 70%|███████   | 351/500 [04:11<02:58,  1.20s/it] 71%|███████   | 353/500 [04:11<02:06,  1.16it/s] 71%|███████   | 355/500 [04:11<01:30,  1.61it/s] 71%|███████▏  | 357/500 [04:11<01:05,  2.20it/s] 72%|███████▏  | 359/500 [04:11<00:47,  2.96it/s] 72%|███████▏  | 361/500 [04:18<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:18<01:58,  1.16it/s] 73%|███████▎  | 365/500 [04:18<01:24,  1.59it/s] 73%|███████▎  | 367/500 [04:18<01:01,  2.18it/s] 74%|███████▍  | 369/500 [04:18<00:44,  2.93it/s] 74%|███████▍  | 371/500 [04:25<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:25<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:25<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:25<00:56,  2.20it/s] 76%|███████▌  | 379/500 [04:25<00:41,  2.94it/s] 76%|███████▌  | 381/500 [04:31<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:32<01:40,  1.17it/s] 77%|███████▋  | 385/500 [04:32<01:11,  1.62it/s] 77%|███████▋  | 387/500 [04:32<00:51,  2.19it/s] 78%|███████▊  | 389/500 [04:32<00:37,  2.95it/s] 78%|███████▊  | 391/500 [04:38<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:38<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:39<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:39<00:46,  2.21it/s] 80%|███████▉  | 399/500 [04:39<00:34,  2.95it/s] 80%|████████  | 401/500 [04:45<01:58,  1.20s/it] 81%|████████  | 403/500 [04:45<01:23,  1.16it/s] 81%|████████  | 405/500 [04:46<00:59,  1.60it/s] 81%|████████▏ | 407/500 [04:46<00:42,  2.19it/s] 82%|████████▏ | 409/500 [04:46<00:30,  2.95it/s] 82%|████████▏ | 411/500 [04:52<01:48,  1.22s/it]Epoch:  345  	Training Loss: 0.0015752986073493958
Test Loss:  0.001202722080051899
Valid Loss:  0.001605360652320087
Epoch:  346  	Training Loss: 0.0015752953477203846
Test Loss:  0.0012027171906083822
Valid Loss:  0.0016053577419370413
Epoch:  347  	Training Loss: 0.0015752941835671663
Test Loss:  0.0012027123011648655
Valid Loss:  0.0016053540166467428
Epoch:  348  	Training Loss: 0.0015752874314785004
Test Loss:  0.0012027088087052107
Valid Loss:  0.0016053495928645134
Epoch:  349  	Training Loss: 0.0015752841718494892
Test Loss:  0.0012027031043544412
Valid Loss:  0.0016053474973887205
Epoch:  350  	Training Loss: 0.00157528230920434
Test Loss:  0.0012027022894471884
Valid Loss:  0.001605343772098422
Epoch:  351  	Training Loss: 0.0015752780018374324
Test Loss:  0.0012026980984956026
Valid Loss:  0.0016053441213443875
Epoch:  352  	Training Loss: 0.001575274160131812
Test Loss:  0.0012026919284835458
Valid Loss:  0.0016053454019129276
Epoch:  353  	Training Loss: 0.00157527020201087
Test Loss:  0.0012026922777295113
Valid Loss:  0.001605333643965423
Epoch:  354  	Training Loss: 0.001575265545397997
Test Loss:  0.0012026892509311438
Valid Loss:  0.0016053317813202739
Epoch:  355  	Training Loss: 0.0015752629842609167
Test Loss:  0.0012026833137497306
Valid Loss:  0.0016053322469815612
Epoch:  356  	Training Loss: 0.0015752617036923766
Test Loss:  0.0012026794720441103
Valid Loss:  0.0016053286381065845
Epoch:  357  	Training Loss: 0.0015752586768940091
Test Loss:  0.0012026787735521793
Valid Loss:  0.0016053281724452972
Epoch:  358  	Training Loss: 0.0015752546023577452
Test Loss:  0.00120267691090703
Valid Loss:  0.0016053244471549988
Epoch:  359  	Training Loss: 0.0015752522740513086
Test Loss:  0.001202672952786088
Valid Loss:  0.0016053211875259876
Epoch:  360  	Training Loss: 0.0015752512263134122
Test Loss:  0.001202671672217548
Valid Loss:  0.0016053221188485622
Epoch:  361  	Training Loss: 0.0015752477338537574
Test Loss:  0.0012026703916490078
Valid Loss:  0.0016053237486630678
Epoch:  362  	Training Loss: 0.00157524598762393
Test Loss:  0.0012026664335280657
Valid Loss:  0.001605320954695344
Epoch:  363  	Training Loss: 0.0015752422623336315
Test Loss:  0.0012026643380522728
Valid Loss:  0.0016053165309131145
Epoch:  364  	Training Loss: 0.0015752387698739767
Test Loss:  0.001202662126161158
Valid Loss:  0.0016053167637437582
Epoch:  365  	Training Loss: 0.0015752364415675402
Test Loss:  0.0012026572367176414
Valid Loss:  0.0016053086146712303
Epoch:  366  	Training Loss: 0.0015752337640151381
Test Loss:  0.0012026556069031358
Valid Loss:  0.0016053072176873684
Epoch:  367  	Training Loss: 0.0015752313192933798
Test Loss:  0.0012026503682136536
Valid Loss:  0.0016053082654252648
Epoch:  368  	Training Loss: 0.0015752277104184031
Test Loss:  0.0012026475742459297
Valid Loss:  0.0016053060535341501
Epoch:  369  	Training Loss: 0.0015752254985272884
Test Loss:  0.0012026457116007805
Valid Loss:  0.001605300698429346
Epoch:  370  	Training Loss: 0.0015752227045595646
Test Loss:  0.0012026428012177348
Valid Loss:  0.001605297438800335
Epoch:  371  	Training Loss: 0.0015752199105918407
Test Loss:  0.0012026363983750343
Valid Loss:  0.0016052949940785766
Epoch:  372  	Training Loss: 0.001575215719640255
Test Loss:  0.0012026354670524597
Valid Loss:  0.001605294761247933
Epoch:  373  	Training Loss: 0.0015752126928418875
Test Loss:  0.0012026326730847359
Valid Loss:  0.0016052952269092202
Epoch:  374  	Training Loss: 0.0015752094332128763
Test Loss:  0.0012026282493025064
Valid Loss:  0.0016052932478487492
Epoch:  375  	Training Loss: 0.0015752079198136926
Test Loss:  0.0012026283657178283
Valid Loss:  0.0016052925493568182
Epoch:  376  	Training Loss: 0.0015752052422612906
Test Loss:  0.0012026240583509207
Valid Loss:  0.001605288591235876
Epoch:  377  	Training Loss: 0.0015752038452774286
Test Loss:  0.001202621846459806
Valid Loss:  0.0016052850987762213
Epoch:  378  	Training Loss: 0.0015752024482935667
Test Loss:  0.0012026182375848293
Valid Loss:  0.0016052818391472101
Epoch:  379  	Training Loss: 0.0015751966275274754
Test Loss:  0.0012026161421090364
Valid Loss:  0.0016052762512117624
Epoch:  380  	Training Loss: 0.0015751949977129698
Test Loss:  0.0012026140466332436
Valid Loss:  0.0016052809078246355
Epoch:  381  	Training Loss: 0.0015751917380839586
Test Loss:  0.0012026119511574507
Valid Loss:  0.0016052788123488426
Epoch:  382  	Training Loss: 0.001575189526192844
Test Loss:  0.0012026086915284395
Valid Loss:  0.0016052762512117624
Epoch:  383  	Training Loss: 0.0015751859173178673
Test Loss:  0.0012026062468066812
Valid Loss:  0.0016052741557359695
Epoch:  384  	Training Loss: 0.0015751828905194998
Test Loss:  0.0012026051990687847
Valid Loss:  0.0016052693827077746
Epoch:  385  	Training Loss: 0.001575180096551776
Test Loss:  0.0012025970499962568
Valid Loss:  0.0016052706632763147
Epoch:  386  	Training Loss: 0.0015751761384308338
Test Loss:  0.001202593557536602
Valid Loss:  0.0016052642604336143
Epoch:  387  	Training Loss: 0.0015751763712614775
Test Loss:  0.0012025954201817513
Valid Loss:  0.0016052625142037868
Epoch:  388  	Training Loss: 0.0015751748578622937
Test Loss:  0.001202591578476131
Valid Loss:  0.0016052551800385118
Epoch:  389  	Training Loss: 0.0015751710161566734
Test Loss:  0.0012025884352624416
Valid Loss:  0.0016052547143772244
Epoch:  390  	Training Loss: 0.001575167290866375
Test Loss:  0.0012025833129882812
Valid Loss:  0.0016052557621151209
Epoch:  391  	Training Loss: 0.0015751663595438004
Test Loss:  0.0012025813339278102
Valid Loss:  0.001605252386070788
Epoch:  392  	Training Loss: 0.0015751620521768928
Test Loss:  0.0012025808682665229
Valid Loss:  0.0016052492428570986
Epoch:  393  	Training Loss: 0.0015751577448099852
Test Loss:  0.0012025755131617188
Valid Loss:  0.0016052493592724204
Epoch:  394  	Training Loss: 0.0015751554165035486
Test Loss:  0.0012025712057948112
Valid Loss:  0.0016052417922765017
Epoch:  395  	Training Loss: 0.001575154485180974
Test Loss:  0.0012025708565488458
Valid Loss:  0.0016052431892603636
Epoch:  396  	Training Loss: 0.0015751505270600319
Test Loss:  0.0012025670148432255
Valid Loss:  0.001605233526788652
Epoch:  397  	Training Loss: 0.001575147733092308
Test Loss:  0.001202563988044858
Valid Loss:  0.001605235505849123
Epoch:  398  	Training Loss: 0.0015751454047858715
Test Loss:  0.0012025621253997087
Valid Loss:  0.0016052339924499393
Epoch:  399  	Training Loss: 0.0015751428436487913
Test Loss:  0.0012025590986013412
Valid Loss:  0.0016052268911153078
Epoch:  400  	Training Loss: 0.0015751408645883203
Test Loss:  0.0012025577016174793
Valid Loss:  0.0016052285209298134
Epoch:  401  	Training Loss: 0.0015751370228827
Test Loss:  0.0012025542091578245
Valid Loss:  0.0016052258433774114
Epoch:  402  	Training Loss: 0.001575134345330298
Test Loss:  0.0012025536270812154
Valid Loss:  0.001605222700163722
Epoch:  403  	Training Loss: 0.0015751319006085396
Test Loss:  0.001202552579343319
Valid Loss:  0.0016052232822403312
Epoch:  404  	Training Loss: 0.001575129572302103
Test Loss:  0.001202547224238515
Valid Loss:  0.001605218625627458
Epoch:  405  	Training Loss: 0.0015751264290884137
Test Loss:  0.0012025462929159403
Valid Loss:  0.0016052115242928267
Epoch:  406  	Training Loss: 0.00157512491568923
Test Loss:  0.0012025429168716073
Valid Loss:  0.0016052122227847576
Epoch:  407  	Training Loss: 0.0015751218888908625
Test Loss:  0.0012025381438434124
Valid Loss:  0.0016052142018452287
Epoch:  408  	Training Loss: 0.0015751187456771731
Test Loss:  0.0012025366304442286
Valid Loss:  0.0016052084974944592
Epoch:  409  	Training Loss: 0.0015751158352941275
Test Loss:  0.0012025313917547464
Valid Loss:  0.0016052071005105972
Epoch:  410  	Training Loss: 0.0015751146711409092
Test Loss:  0.0012025295291095972
Valid Loss:  0.0016052103601396084
Epoch:  411  	Training Loss: 0.001575111411511898
Test Loss:  0.0012025302276015282
Valid Loss:  0.0016052055871114135
Epoch:  412  	Training Loss: 0.0015751076862215996
Test Loss:  0.0012025295291095972
Valid Loss:  0.0016052057035267353
Epoch:  413  	Training Loss: 0.001575105357915163
Test Loss:   83%|████████▎ | 413/500 [04:53<01:16,  1.14it/s] 83%|████████▎ | 415/500 [04:53<00:53,  1.59it/s] 83%|████████▎ | 417/500 [04:53<00:38,  2.17it/s] 84%|████████▍ | 419/500 [04:53<00:27,  2.92it/s] 84%|████████▍ | 421/500 [04:59<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:59<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:00<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:00<00:33,  2.20it/s] 86%|████████▌ | 429/500 [05:00<00:24,  2.96it/s] 86%|████████▌ | 431/500 [05:06<01:23,  1.21s/it] 87%|████████▋ | 433/500 [05:06<00:58,  1.15it/s] 87%|████████▋ | 435/500 [05:07<00:41,  1.58it/s] 87%|████████▋ | 437/500 [05:07<00:29,  2.13it/s] 88%|████████▊ | 439/500 [05:07<00:21,  2.83it/s] 88%|████████▊ | 441/500 [05:13<01:11,  1.22s/it] 89%|████████▊ | 443/500 [05:14<00:49,  1.14it/s] 89%|████████▉ | 445/500 [05:14<00:34,  1.58it/s] 89%|████████▉ | 447/500 [05:14<00:24,  2.16it/s] 90%|████████▉ | 449/500 [05:14<00:17,  2.92it/s] 90%|█████████ | 451/500 [05:20<00:59,  1.22s/it] 91%|█████████ | 453/500 [05:21<00:41,  1.14it/s] 91%|█████████ | 455/500 [05:21<00:28,  1.58it/s] 91%|█████████▏| 457/500 [05:21<00:19,  2.16it/s] 92%|█████████▏| 459/500 [05:21<00:14,  2.91it/s] 92%|█████████▏| 461/500 [05:27<00:46,  1.21s/it] 93%|█████████▎| 463/500 [05:28<00:32,  1.16it/s] 93%|█████████▎| 465/500 [05:28<00:21,  1.60it/s] 93%|█████████▎| 467/500 [05:28<00:15,  2.19it/s] 94%|█████████▍| 469/500 [05:28<00:10,  2.94it/s] 94%|█████████▍| 471/500 [05:34<00:35,  1.21s/it] 95%|█████████▍| 473/500 [05:35<00:23,  1.15it/s] 95%|█████████▌| 475/500 [05:35<00:15,  1.59it/s] 95%|█████████▌| 477/500 [05:35<00:10,  2.17it/s] 96%|█████████▌| 479/500 [05:35<00:07,  2.91it/s] 96%|█████████▌| 481/500 [05:41<00:22,  1.20s/it]0.001202525687403977
Valid Loss:  0.0016052054706960917
Epoch:  414  	Training Loss: 0.0015751027967780828
Test Loss:  0.0012025248724967241
Valid Loss:  0.001605196506716311
Epoch:  415  	Training Loss: 0.001575099304318428
Test Loss:  0.0012025227770209312
Valid Loss:  0.0016052003484219313
Epoch:  416  	Training Loss: 0.0015750960446894169
Test Loss:  0.001202520215883851
Valid Loss:  0.0016051970887929201
Epoch:  417  	Training Loss: 0.0015750948805361986
Test Loss:  0.0012025178875774145
Valid Loss:  0.001605193829163909
Epoch:  418  	Training Loss: 0.001575091271661222
Test Loss:  0.0012025153264403343
Valid Loss:  0.0016051915008574724
Epoch:  419  	Training Loss: 0.0015750911552459002
Test Loss:  0.0012025143951177597
Valid Loss:  0.0016051901038736105
Epoch:  420  	Training Loss: 0.00157508859410882
Test Loss:  0.0012025093892589211
Valid Loss:  0.0016051859129220247
Epoch:  421  	Training Loss: 0.0015750862658023834
Test Loss:  0.001202508108690381
Valid Loss:  0.0016051848651841283
Epoch:  422  	Training Loss: 0.0015750833554193377
Test Loss:  0.0012025077594444156
Valid Loss:  0.001605185680091381
Epoch:  423  	Training Loss: 0.001575081842020154
Test Loss:  0.0012025025207549334
Valid Loss:  0.0016051828861236572
Epoch:  424  	Training Loss: 0.0015750793972983956
Test Loss:  0.0012024983298033476
Valid Loss:  0.001605175668373704
Epoch:  425  	Training Loss: 0.0015750748571008444
Test Loss:  0.0012024964671581984
Valid Loss:  0.0016051759012043476
Epoch:  426  	Training Loss: 0.0015750727616250515
Test Loss:  0.0012024922762066126
Valid Loss:  0.0016051741549745202
Epoch:  427  	Training Loss: 0.0015750714810565114
Test Loss:  0.001202491926960647
Valid Loss:  0.0016051743878051639
Epoch:  428  	Training Loss: 0.0015750692691653967
Test Loss:  0.0012024890165776014
Valid Loss:  0.0016051693819463253
Epoch:  429  	Training Loss: 0.0015750639140605927
Test Loss:  0.0012024854077026248
Valid Loss:  0.0016051691491156816
Epoch:  430  	Training Loss: 0.0015750627499073744
Test Loss:  0.0012024824973195791
Valid Loss:  0.0016051677521318197
Epoch:  431  	Training Loss: 0.0015750611200928688
Test Loss:  0.0012024836614727974
Valid Loss:  0.0016051585553213954
Epoch:  432  	Training Loss: 0.0015750592574477196
Test Loss:  0.0012024849420413375
Valid Loss:  0.0016051610000431538
Epoch:  433  	Training Loss: 0.0015750568127259612
Test Loss:  0.0012024769093841314
Valid Loss:  0.0016051572747528553
Epoch:  434  	Training Loss: 0.001575050875544548
Test Loss:  0.0012024777242913842
Valid Loss:  0.001605154713615775
Epoch:  435  	Training Loss: 0.0015750506427139044
Test Loss:  0.0012024703901261091
Valid Loss:  0.0016051529673859477
Epoch:  436  	Training Loss: 0.0015750483144074678
Test Loss:  0.0012024699244648218
Valid Loss:  0.0016051532002165914
Epoch:  437  	Training Loss: 0.0015750464517623186
Test Loss:  0.001202467828989029
Valid Loss:  0.0016051523853093386
Epoch:  438  	Training Loss: 0.0015750440070405602
Test Loss:  0.001202464452944696
Valid Loss:  0.0016051498241722584
Epoch:  439  	Training Loss: 0.001575039466843009
Test Loss:  0.0012024615425616503
Valid Loss:  0.0016051467973738909
Epoch:  440  	Training Loss: 0.0015750359743833542
Test Loss:  0.0012024620082229376
Valid Loss:  0.0016051449347287416
Epoch:  441  	Training Loss: 0.0015750335296615958
Test Loss:  0.0012024582829326391
Valid Loss:  0.0016051437705755234
Epoch:  442  	Training Loss: 0.001575032132677734
Test Loss:  0.0012024565367028117
Valid Loss:  0.0016051419079303741
Epoch:  443  	Training Loss: 0.001575028756633401
Test Loss:  0.0012024522293359041
Valid Loss:  0.0016051403945311904
Epoch:  444  	Training Loss: 0.0015750267775729299
Test Loss:  0.0012024512980133295
Valid Loss:  0.0016051376005634665
Epoch:  445  	Training Loss: 0.001575026079080999
Test Loss:  0.001202450250275433
Valid Loss:  0.0016051351558417082
Epoch:  446  	Training Loss: 0.0015750231686979532
Test Loss:  0.0012024486204609275
Valid Loss:  0.0016051295679062605
Epoch:  447  	Training Loss: 0.001575022004544735
Test Loss:  0.0012024461757391691
Valid Loss:  0.001605125144124031
Epoch:  448  	Training Loss: 0.0015750182792544365
Test Loss:  0.0012024426832795143
Valid Loss:  0.001605128520168364
Epoch:  449  	Training Loss: 0.0015750153688713908
Test Loss:  0.0012024430325254798
Valid Loss:  0.0016051246784627438
Epoch:  450  	Training Loss: 0.001575013855472207
Test Loss:  0.0012024407042190433
Valid Loss:  0.0016051256097853184
Epoch:  451  	Training Loss: 0.0015750096645206213
Test Loss:  0.0012024351162835956
Valid Loss:  0.001605126541107893
Epoch:  452  	Training Loss: 0.001575007103383541
Test Loss:  0.001202435465529561
Valid Loss:  0.0016051220009103417
Epoch:  453  	Training Loss: 0.00157500512432307
Test Loss:  0.0012024312745779753
Valid Loss:  0.001605119090527296
Epoch:  454  	Training Loss: 0.0015750022139400244
Test Loss:  0.0012024289462715387
Valid Loss:  0.0016051166458055377
Epoch:  455  	Training Loss: 0.0015750008169561625
Test Loss:  0.0012024280149489641
Valid Loss:  0.0016051135025918484
Epoch:  456  	Training Loss: 0.0015749968588352203
Test Loss:  0.0012024245224893093
Valid Loss:  0.0016051102429628372
Epoch:  457  	Training Loss: 0.001574995694682002
Test Loss:  0.00120242265984416
Valid Loss:  0.0016051104757934809
Epoch:  458  	Training Loss: 0.0015749935992062092
Test Loss:  0.001202420680783689
Valid Loss:  0.001605106983333826
Epoch:  459  	Training Loss: 0.0015749904559925199
Test Loss:  0.001202418003231287
Valid Loss:  0.0016051066340878606
Epoch:  460  	Training Loss: 0.0015749867307022214
Test Loss:  0.0012024154420942068
Valid Loss:  0.0016051034908741713
Epoch:  461  	Training Loss: 0.001574986381456256
Test Loss:  0.0012024152092635632
Valid Loss:  0.001605103723704815
Epoch:  462  	Training Loss: 0.001574984285980463
Test Loss:  0.001202411251142621
Valid Loss:  0.0016050994163379073
Epoch:  463  	Training Loss: 0.0015749813755974174
Test Loss:  0.0012024100869894028
Valid Loss:  0.00160509767010808
Epoch:  464  	Training Loss: 0.0015749810263514519
Test Loss:  0.0012024038005620241
Valid Loss:  0.0016050972044467926
Epoch:  465  	Training Loss: 0.001574977533891797
Test Loss:  0.0012024024035781622
Valid Loss:  0.0016050968552008271
Epoch:  466  	Training Loss: 0.001574974274262786
Test Loss:  0.0012024042662233114
Valid Loss:  0.0016050939448177814
Epoch:  467  	Training Loss: 0.001574970781803131
Test Loss:  0.0012024019379168749
Valid Loss:  0.0016050913836807013
Epoch:  468  	Training Loss: 0.0015749684534966946
Test Loss:  0.0012023993767797947
Valid Loss:  0.001605091500096023
Epoch:  469  	Training Loss: 0.0015749662416055799
Test Loss:  0.0012023975141346455
Valid Loss:  0.001605088822543621
Epoch:  470  	Training Loss: 0.0015749633312225342
Test Loss:  0.0012023932067677379
Valid Loss:  0.0016050860285758972
Epoch:  471  	Training Loss: 0.001574962749145925
Test Loss:  0.0012023882009088993
Valid Loss:  0.001605083467438817
Epoch:  472  	Training Loss: 0.0015749591402709484
Test Loss:  0.001202389132231474
Valid Loss:  0.0016050832346081734
Epoch:  473  	Training Loss: 0.0015749575104564428
Test Loss:  0.0012023865710943937
Valid Loss:  0.0016050804406404495
Epoch:  474  	Training Loss: 0.001574954017996788
Test Loss:  0.001202387036755681
Valid Loss:  0.0016050809063017368
Epoch:  475  	Training Loss: 0.0015749511076137424
Test Loss:  0.0012023821473121643
Valid Loss:  0.0016050813719630241
Epoch:  476  	Training Loss: 0.0015749504091218114
Test Loss:  0.0012023808667436242
Valid Loss:  0.001605077413842082
Epoch:  477  	Training Loss: 0.0015749458689242601
Test Loss:  0.001202376908622682
Valid Loss:  0.0016050765989348292
Epoch:  478  	Training Loss: 0.00157494458835572
Test Loss:  0.0012023764429613948
Valid Loss:  0.0016050746198743582
Epoch:  479  	Training Loss: 0.0015749417943879962
Test Loss:  0.0012023737654089928
Valid Loss:  0.001605073339305818
Epoch:  480  	Training Loss: 0.001574937952682376
Test Loss:  0.0012023705057799816
Valid Loss:  0.001605070079676807
Epoch:  481  	Training Loss: 0.001574937952682376
Test Loss:  0.0012023658491671085
Valid Loss:  0.001605063327588141
 97%|█████████▋| 483/500 [05:42<00:14,  1.15it/s] 97%|█████████▋| 485/500 [05:42<00:09,  1.59it/s] 97%|█████████▋| 487/500 [05:42<00:05,  2.17it/s] 98%|█████████▊| 489/500 [05:42<00:03,  2.91it/s] 98%|█████████▊| 491/500 [05:48<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:48<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:55<00:07,  1.58s/it] 99%|█████████▉| 497/500 [05:55<00:03,  1.12s/it]100%|█████████▉| 499/500 [05:55<00:00,  1.24it/s]100%|██████████| 500/500 [05:55<00:00,  1.41it/s]
Epoch:  482  	Training Loss: 0.0015749349258840084
Test Loss:  0.0012023630551993847
Valid Loss:  0.0016050615813583136
Epoch:  483  	Training Loss: 0.0015749332960695028
Test Loss:  0.0012023625895380974
Valid Loss:  0.001605061930604279
Epoch:  484  	Training Loss: 0.001574929105117917
Test Loss:  0.0012023592134937644
Valid Loss:  0.001605061930604279
Epoch:  485  	Training Loss: 0.001574928406625986
Test Loss:  0.0012023577000945807
Valid Loss:  0.0016050576232373714
Epoch:  486  	Training Loss: 0.0015749256126582623
Test Loss:  0.0012023537419736385
Valid Loss:  0.0016050548292696476
Epoch:  487  	Training Loss: 0.0015749221201986074
Test Loss:  0.001202352810651064
Valid Loss:  0.0016050527337938547
Epoch:  488  	Training Loss: 0.0015749186277389526
Test Loss:  0.001202351413667202
Valid Loss:  0.0016050530830398202
Epoch:  489  	Training Loss: 0.001574916997924447
Test Loss:  0.0012023488525301218
Valid Loss:  0.0016050469130277634
Epoch:  490  	Training Loss: 0.0015749142039567232
Test Loss:  0.0012023458257317543
Valid Loss:  0.0016050473786890507
Epoch:  491  	Training Loss: 0.001574910245835781
Test Loss:  0.0012023411691188812
Valid Loss:  0.0016050476115196943
Epoch:  492  	Training Loss: 0.001574910944327712
Test Loss:  0.0012023429153487086
Valid Loss:  0.0016050508711487055
Epoch:  493  	Training Loss: 0.0015749086160212755
Test Loss:  0.0012023388408124447
Valid Loss:  0.0016050530830398202
Epoch:  494  	Training Loss: 0.0015749047743156552
Test Loss:  0.0012023367453366518
Valid Loss:  0.0016050453996285796
Epoch:  495  	Training Loss: 0.001574904192239046
Test Loss:  0.0012023365125060081
Valid Loss:  0.0016050415579229593
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.0015748993027955294
Test Loss:  0.0012023347662761807
Valid Loss:  0.0016050413250923157
Epoch:  497  	Training Loss: 0.0015749000012874603
Test Loss:  0.0012023311574012041
Valid Loss:  0.0016050389967858791
Epoch:  498  	Training Loss: 0.0015748969744890928
Test Loss:  0.0012023302260786295
Valid Loss:  0.0016050382982939482
Epoch:  499  	Training Loss: 0.0015748948790133
Test Loss:  0.0012023311574012041
Valid Loss:  0.0016050378326326609
Epoch:  500  	Training Loss: 0.0015748944133520126
Test Loss:  0.0012023329036310315
Valid Loss:  0.0016050385311245918
seed is  14
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:53,  6.36s/it]  1%|          | 3/500 [00:06<14:12,  1.72s/it]  1%|          | 5/500 [00:06<07:15,  1.14it/s]  1%|▏         | 7/500 [00:06<04:26,  1.85it/s]  2%|▏         | 9/500 [00:07<02:57,  2.76it/s]  2%|▏         | 11/500 [00:13<11:03,  1.36s/it]  3%|▎         | 13/500 [00:13<07:32,  1.08it/s]  3%|▎         | 15/500 [00:13<05:15,  1.53it/s]  3%|▎         | 17/500 [00:13<03:45,  2.14it/s]  4%|▍         | 19/500 [00:13<02:44,  2.92it/s]  4%|▍         | 21/500 [00:20<09:44,  1.22s/it]  5%|▍         | 23/500 [00:20<06:56,  1.14it/s]  5%|▌         | 25/500 [00:20<04:58,  1.59it/s]  5%|▌         | 27/500 [00:20<03:36,  2.18it/s]  6%|▌         | 29/500 [00:20<02:39,  2.94it/s]  6%|▌         | 31/500 [00:27<09:21,  1.20s/it]  7%|▋         | 33/500 [00:27<06:41,  1.16it/s]  7%|▋         | 35/500 [00:27<04:48,  1.61it/s]  7%|▋         | 37/500 [00:27<03:30,  2.20it/s]  8%|▊         | 39/500 [00:27<02:36,  2.94it/s]  8%|▊         | 41/500 [00:34<09:11,  1.20s/it]  9%|▊         | 43/500 [00:34<06:37,  1.15it/s]  9%|▉         | 45/500 [00:34<04:48,  1.58it/s]  9%|▉         | 47/500 [00:34<03:29,  2.16it/s] 10%|▉         | 49/500 [00:34<02:35,  2.90it/s] 10%|█         | 51/500 [00:41<08:59,  1.20s/it] 11%|█         | 53/500 [00:41<06:28,  1.15it/s] 11%|█         | 55/500 [00:41<04:40,  1.59it/s] 11%|█▏        | 57/500 [00:41<03:26,  2.15it/s] 12%|█▏        | 59/500 [00:41<02:32,  2.89it/s] 12%|█▏        | 61/500 [00:48<08:51,  1.21s/it] 13%|█▎        | 63/500 [00:48<06:20,  1.15it/s] 13%|█▎        | 65/500 [00:48<04:33,  1.59it/s] 13%|█▎        | 67/500 [00:48<03:19,  2.17it/s] 14%|█▍        | 69/500 [00:48<02:27,  2.92it/s]Epoch:  1  	Training Loss: 0.2322888970375061
Test Loss:  0.14503949880599976
Valid Loss:  0.14729033410549164
Epoch:  2  	Training Loss: 0.12399901449680328
Test Loss:  0.09922456741333008
Valid Loss:  0.10067348182201385
Epoch:  3  	Training Loss: 0.08362092077732086
Test Loss:  0.06666150689125061
Valid Loss:  0.06741705536842346
Epoch:  4  	Training Loss: 0.055377449840307236
Test Loss:  0.04584059864282608
Valid Loss:  0.04608067870140076
Epoch:  5  	Training Loss: 0.03793233633041382
Test Loss:  0.033566415309906006
Valid Loss:  0.03345364332199097
Epoch:  6  	Training Loss: 0.028081471100449562
Test Loss:  0.02612125128507614
Valid Loss:  0.02576938271522522
Epoch:  7  	Training Loss: 0.022374603897333145
Test Loss:  0.02142043597996235
Valid Loss:  0.020911933854222298
Epoch:  8  	Training Loss: 0.018908772617578506
Test Loss:  0.018244821578264236
Valid Loss:  0.01765415072441101
Epoch:  9  	Training Loss: 0.016589971259236336
Test Loss:  0.0159435011446476
Valid Loss:  0.015310043469071388
Epoch:  10  	Training Loss: 0.014885171316564083
Test Loss:  0.014263572171330452
Valid Loss:  0.013595683500170708
Epoch:  11  	Training Loss: 0.013631075620651245
Test Loss:  0.012968450784683228
Valid Loss:  0.012287991121411324
Epoch:  12  	Training Loss: 0.01267252117395401
Test Loss:  0.011539297178387642
Valid Loss:  0.010876156389713287
Epoch:  13  	Training Loss: 0.011516156606376171
Test Loss:  0.010465944185853004
Valid Loss:  0.009825882501900196
Epoch:  14  	Training Loss: 0.01056367065757513
Test Loss:  0.009693488478660583
Valid Loss:  0.009070560336112976
Epoch:  15  	Training Loss: 0.009876962751150131
Test Loss:  0.009120605885982513
Valid Loss:  0.008531985804438591
Epoch:  16  	Training Loss: 0.009397179819643497
Test Loss:  0.00862930342555046
Valid Loss:  0.008072508499026299
Epoch:  17  	Training Loss: 0.008984791114926338
Test Loss:  0.008186598308384418
Valid Loss:  0.00765672093257308
Epoch:  18  	Training Loss: 0.00861131027340889
Test Loss:  0.0077895792201161385
Valid Loss:  0.007277620956301689
Epoch:  19  	Training Loss: 0.00826726108789444
Test Loss:  0.007428753189742565
Valid Loss:  0.006928557530045509
Epoch:  20  	Training Loss: 0.007951246574521065
Test Loss:  0.007096982095390558
Valid Loss:  0.00660673575475812
Epoch:  21  	Training Loss: 0.007656123489141464
Test Loss:  0.006789011415094137
Valid Loss:  0.006310482509434223
Epoch:  22  	Training Loss: 0.007379082031548023
Test Loss:  0.006372467149049044
Valid Loss:  0.0059198420494794846
Epoch:  23  	Training Loss: 0.00697022769600153
Test Loss:  0.006004174239933491
Valid Loss:  0.00557673117145896
Epoch:  24  	Training Loss: 0.0066389357671141624
Test Loss:  0.0056762779131531715
Valid Loss:  0.005275847390294075
Epoch:  25  	Training Loss: 0.006350413430482149
Test Loss:  0.00538339838385582
Valid Loss:  0.005007227882742882
Epoch:  26  	Training Loss: 0.006090017966926098
Test Loss:  0.005116474814713001
Valid Loss:  0.004763862118124962
Epoch:  27  	Training Loss: 0.005854353308677673
Test Loss:  0.004872873425483704
Valid Loss:  0.004537003114819527
Epoch:  28  	Training Loss: 0.005640254355967045
Test Loss:  0.004653967916965485
Valid Loss:  0.0043312013149261475
Epoch:  29  	Training Loss: 0.005443117115646601
Test Loss:  0.004457493312656879
Valid Loss:  0.004144958220422268
Epoch:  30  	Training Loss: 0.005261031445115805
Test Loss:  0.0042776321060955524
Valid Loss:  0.003975335508584976
Epoch:  31  	Training Loss: 0.005090598948299885
Test Loss:  0.0041109248995780945
Valid Loss:  0.0038202302530407906
Epoch:  32  	Training Loss: 0.004930652678012848
Test Loss:  0.0039494838565588
Valid Loss:  0.0037141949869692326
Epoch:  33  	Training Loss: 0.0046286815777421
Test Loss:  0.0037460681051015854
Valid Loss:  0.003535899333655834
Epoch:  34  	Training Loss: 0.004389284178614616
Test Loss:  0.0036001517437398434
Valid Loss:  0.0034094287548214197
Epoch:  35  	Training Loss: 0.004192187916487455
Test Loss:  0.003469238057732582
Valid Loss:  0.0032850829884409904
Epoch:  36  	Training Loss: 0.004035537131130695
Test Loss:  0.0033501361031085253
Valid Loss:  0.003170058596879244
Epoch:  37  	Training Loss: 0.0039046488236635923
Test Loss:  0.0032429052516818047
Valid Loss:  0.003065768163651228
Epoch:  38  	Training Loss: 0.003788567380979657
Test Loss:  0.003143496345728636
Valid Loss:  0.0029719495214521885
Epoch:  39  	Training Loss: 0.003685471136122942
Test Loss:  0.0030513021629303694
Valid Loss:  0.0028862846083939075
Epoch:  40  	Training Loss: 0.0035925593692809343
Test Loss:  0.0029671175871044397
Valid Loss:  0.0028090954292565584
Epoch:  41  	Training Loss: 0.0035052048042416573
Test Loss:  0.0028850941453129053
Valid Loss:  0.002733440836891532
Epoch:  42  	Training Loss: 0.0034233403857797384
Test Loss:  0.0028354269452393055
Valid Loss:  0.0026931995525956154
Epoch:  43  	Training Loss: 0.003363449824973941
Test Loss:  0.00280111120082438
Valid Loss:  0.0026642316952347755
Epoch:  44  	Training Loss: 0.003331610932946205
Test Loss:  0.0027682494837790728
Valid Loss:  0.0026355586014688015
Epoch:  45  	Training Loss: 0.0033013825304806232
Test Loss:  0.002736592199653387
Valid Loss:  0.0026072380132973194
Epoch:  46  	Training Loss: 0.003272233996540308
Test Loss:  0.0027061274740844965
Valid Loss:  0.002580119762569666
Epoch:  47  	Training Loss: 0.0032438284251838923
Test Loss:  0.002676227129995823
Valid Loss:  0.0025531230494379997
Epoch:  48  	Training Loss: 0.003216058947145939
Test Loss:  0.002647008281201124
Valid Loss:  0.0025268932804465294
Epoch:  49  	Training Loss: 0.0031887609511613846
Test Loss:  0.0026185247115790844
Valid Loss:  0.0025013829581439495
Epoch:  50  	Training Loss: 0.003161914413794875
Test Loss:  0.002590787597000599
Valid Loss:  0.002476629102602601
Epoch:  51  	Training Loss: 0.0031354688107967377
Test Loss:  0.00256374035961926
Valid Loss:  0.002452554414048791
Epoch:  52  	Training Loss: 0.003109523095190525
Test Loss:  0.0024596555158495903
Valid Loss:  0.0023562079295516014
Epoch:  53  	Training Loss: 0.003021820681169629
Test Loss:  0.002367359818890691
Valid Loss:  0.00227197608910501
Epoch:  54  	Training Loss: 0.0029407022520899773
Test Loss:  0.002283308655023575
Valid Loss:  0.002196335233747959
Epoch:  55  	Training Loss: 0.002865210175514221
Test Loss:  0.0022061876952648163
Valid Loss:  0.002127572661265731
Epoch:  56  	Training Loss: 0.002795119769871235
Test Loss:  0.0021338961087167263
Valid Loss:  0.002063511870801449
Epoch:  57  	Training Loss: 0.002729690633714199
Test Loss:  0.0020679428707808256
Valid Loss:  0.0020061025861650705
Epoch:  58  	Training Loss: 0.002668513683602214
Test Loss:  0.0020071836188435555
Valid Loss:  0.0019537077751010656
Epoch:  59  	Training Loss: 0.0026108373422175646
Test Loss:  0.0019511478021740913
Valid Loss:  0.0019056119490414858
Epoch:  60  	Training Loss: 0.0025564865209162235
Test Loss:  0.0018991114338859916
Valid Loss:  0.0018612524727359414
Epoch:  61  	Training Loss: 0.002505125477910042
Test Loss:  0.001850651460699737
Valid Loss:  0.0018203777726739645
Epoch:  62  	Training Loss: 0.002456383779644966
Test Loss:  0.0018006148748099804
Valid Loss:  0.0017766543896868825
Epoch:  63  	Training Loss: 0.0024040150456130505
Test Loss:  0.0017549581825733185
Valid Loss:  0.0017368707340210676
Epoch:  64  	Training Loss: 0.002355185803025961
Test Loss:  0.0017128419131040573
Valid Loss:  0.001700530294328928
Epoch:  65  	Training Loss: 0.00231003831140697
Test Loss:  0.0016736541874706745
Valid Loss:  0.0016673484351485968
Epoch:  66  	Training Loss: 0.0022678840905427933
Test Loss:  0.0016369770746678114
Valid Loss:  0.0016364987241104245
Epoch:  67  	Training Loss: 0.002228042110800743
Test Loss:  0.0016025558579713106
Valid Loss:  0.0016078215558081865
Epoch:  68  	Training Loss: 0.002190287923440337
Test Loss:  0.0015700842486694455
Valid Loss:  0.0015811388147994876
Epoch:  69  	Training Loss: 0.0021544480696320534
Test Loss:  0.0015394235961139202
Valid Loss:  0.0015561850741505623
Epoch:  70  	Training Loss: 0.002120327902957797
Test Loss:  0.0015104423509910703
Valid Loss:  0.001532901544123888
 14%|█▍        | 71/500 [00:55<08:32,  1.19s/it] 15%|█▍        | 73/500 [00:55<06:06,  1.17it/s] 15%|█▌        | 75/500 [00:55<04:25,  1.60it/s] 15%|█▌        | 77/500 [00:55<03:15,  2.16it/s] 16%|█▌        | 79/500 [00:55<02:27,  2.86it/s] 16%|█▌        | 81/500 [01:02<08:28,  1.21s/it] 17%|█▋        | 83/500 [01:02<06:04,  1.14it/s] 17%|█▋        | 85/500 [01:02<04:22,  1.58it/s] 17%|█▋        | 87/500 [01:02<03:11,  2.16it/s] 18%|█▊        | 89/500 [01:02<02:21,  2.91it/s] 18%|█▊        | 91/500 [01:09<08:13,  1.21s/it] 19%|█▊        | 93/500 [01:09<05:52,  1.15it/s] 19%|█▉        | 95/500 [01:09<04:14,  1.59it/s] 19%|█▉        | 97/500 [01:09<03:05,  2.17it/s] 20%|█▉        | 99/500 [01:09<02:17,  2.93it/s] 20%|██        | 101/500 [01:16<08:07,  1.22s/it] 21%|██        | 103/500 [01:16<05:48,  1.14it/s] 21%|██        | 105/500 [01:16<04:12,  1.56it/s] 21%|██▏       | 107/500 [01:17<03:06,  2.11it/s] 22%|██▏       | 109/500 [01:17<02:18,  2.82it/s] 22%|██▏       | 111/500 [01:23<07:57,  1.23s/it] 23%|██▎       | 113/500 [01:23<05:43,  1.13it/s] 23%|██▎       | 115/500 [01:24<04:08,  1.55it/s] 23%|██▎       | 117/500 [01:24<03:01,  2.11it/s] 24%|██▍       | 119/500 [01:24<02:14,  2.83it/s] 24%|██▍       | 121/500 [01:30<07:32,  1.19s/it] 25%|██▍       | 123/500 [01:30<05:23,  1.17it/s] 25%|██▌       | 125/500 [01:30<03:52,  1.61it/s] 25%|██▌       | 127/500 [01:31<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:31<02:05,  2.96it/s] 26%|██▌       | 131/500 [01:37<07:19,  1.19s/it] 27%|██▋       | 133/500 [01:37<05:13,  1.17it/s] 27%|██▋       | 135/500 [01:37<03:45,  1.62it/s] 27%|██▋       | 137/500 [01:37<02:44,  2.21it/s]Epoch:  71  	Training Loss: 0.0020876803901046515
Test Loss:  0.0014830055879428983
Valid Loss:  0.0015110375825315714
Epoch:  72  	Training Loss: 0.0020564375445246696
Test Loss:  0.0014500969555228949
Valid Loss:  0.001490965485572815
Epoch:  73  	Training Loss: 0.0019978079944849014
Test Loss:  0.0014157288242131472
Valid Loss:  0.001461596810258925
Epoch:  74  	Training Loss: 0.0019569210708141327
Test Loss:  0.0013836936559528112
Valid Loss:  0.0014340311754494905
Epoch:  75  	Training Loss: 0.001918409368954599
Test Loss:  0.00135319703258574
Valid Loss:  0.001407931442372501
Epoch:  76  	Training Loss: 0.0018818257376551628
Test Loss:  0.001324398908764124
Valid Loss:  0.0013837020378559828
Epoch:  77  	Training Loss: 0.0018469286151230335
Test Loss:  0.001296754227951169
Valid Loss:  0.0013601898681372404
Epoch:  78  	Training Loss: 0.0018131646793335676
Test Loss:  0.0012707730056717992
Valid Loss:  0.00133780506439507
Epoch:  79  	Training Loss: 0.0017806976102292538
Test Loss:  0.0012462998274713755
Valid Loss:  0.0013168107252568007
Epoch:  80  	Training Loss: 0.0017495023785158992
Test Loss:  0.0012232234003022313
Valid Loss:  0.0012972952099516988
Epoch:  81  	Training Loss: 0.001719789463095367
Test Loss:  0.001201528706587851
Valid Loss:  0.0012787661980837584
Epoch:  82  	Training Loss: 0.00169148959685117
Test Loss:  0.0011707250960171223
Valid Loss:  0.001249703811481595
Epoch:  83  	Training Loss: 0.001655941130593419
Test Loss:  0.0011433588806539774
Valid Loss:  0.001224134350195527
Epoch:  84  	Training Loss: 0.0016225321451202035
Test Loss:  0.0011178345885127783
Valid Loss:  0.0012006588513031602
Epoch:  85  	Training Loss: 0.0015905853360891342
Test Loss:  0.0010935761965811253
Valid Loss:  0.0011787144467234612
Epoch:  86  	Training Loss: 0.0015598397003486753
Test Loss:  0.001069924095645547
Valid Loss:  0.0011565701570361853
Epoch:  87  	Training Loss: 0.0015290663577616215
Test Loss:  0.001046475488692522
Valid Loss:  0.0011346766259521246
Epoch:  88  	Training Loss: 0.0014987422619014978
Test Loss:  0.0010243889410048723
Valid Loss:  0.0011141594732180238
Epoch:  89  	Training Loss: 0.0014696945436298847
Test Loss:  0.0010041928617283702
Valid Loss:  0.0010955549078062177
Epoch:  90  	Training Loss: 0.0014422574313357472
Test Loss:  0.000985239865258336
Valid Loss:  0.0010789070511236787
Epoch:  91  	Training Loss: 0.001416584593243897
Test Loss:  0.0009675660403445363
Valid Loss:  0.0010636886581778526
Epoch:  92  	Training Loss: 0.0013926911633461714
Test Loss:  0.0009541026665829122
Valid Loss:  0.0010570492595434189
Epoch:  93  	Training Loss: 0.0013702025171369314
Test Loss:  0.000944398227147758
Valid Loss:  0.0010521096410229802
Epoch:  94  	Training Loss: 0.0013535346370190382
Test Loss:  0.0009365272708237171
Valid Loss:  0.001048120902851224
Epoch:  95  	Training Loss: 0.0013406709767878056
Test Loss:  0.0009295229683630168
Valid Loss:  0.0010446443920955062
Epoch:  96  	Training Loss: 0.0013297187397256494
Test Loss:  0.0009230517316609621
Valid Loss:  0.001041559036821127
Epoch:  97  	Training Loss: 0.0013198351953178644
Test Loss:  0.0009170679841190577
Valid Loss:  0.0010387388756498694
Epoch:  98  	Training Loss: 0.0013107063714414835
Test Loss:  0.0009114716667681932
Valid Loss:  0.0010361919412389398
Epoch:  99  	Training Loss: 0.0013021847698837519
Test Loss:  0.0009063387988135219
Valid Loss:  0.0010340979788452387
Epoch:  100  	Training Loss: 0.0012941956520080566
Test Loss:  0.0009014924871735275
Valid Loss:  0.0010321587324142456
Epoch:  101  	Training Loss: 0.001286658807657659
Test Loss:  0.0008969620103016496
Valid Loss:  0.001030400046147406
Epoch:  102  	Training Loss: 0.0012795035727322102
Test Loss:  0.000890446244738996
Valid Loss:  0.001026349957101047
Epoch:  103  	Training Loss: 0.0012717882636934519
Test Loss:  0.0008852512110024691
Valid Loss:  0.0010237304959446192
Epoch:  104  	Training Loss: 0.0012649593409150839
Test Loss:  0.0008809218415990472
Valid Loss:  0.0010219868272542953
Epoch:  105  	Training Loss: 0.0012587385717779398
Test Loss:  0.0008772380533628166
Valid Loss:  0.0010208608582615852
Epoch:  106  	Training Loss: 0.0012530060485005379
Test Loss:  0.0008740602061152458
Valid Loss:  0.0010201962431892753
Epoch:  107  	Training Loss: 0.0012476772535592318
Test Loss:  0.0008712686249054968
Valid Loss:  0.0010198695817962289
Epoch:  108  	Training Loss: 0.0012427001493051648
Test Loss:  0.000868803879711777
Valid Loss:  0.001019768649712205
Epoch:  109  	Training Loss: 0.0012380275875329971
Test Loss:  0.0008665708010084927
Valid Loss:  0.0010197518859058619
Epoch:  110  	Training Loss: 0.0012334835482761264
Test Loss:  0.0008645091438665986
Valid Loss:  0.0010196249932050705
Epoch:  111  	Training Loss: 0.0012290067970752716
Test Loss:  0.0008624977199360728
Valid Loss:  0.0010192592162638903
Epoch:  112  	Training Loss: 0.0012245059479027987
Test Loss:  0.0008572727674618363
Valid Loss:  0.0010158061049878597
Epoch:  113  	Training Loss: 0.0012170561822131276
Test Loss:  0.0008523662108927965
Valid Loss:  0.0010125269182026386
Epoch:  114  	Training Loss: 0.00120984623208642
Test Loss:  0.0008476302609778941
Valid Loss:  0.0010095217730849981
Epoch:  115  	Training Loss: 0.0012025963515043259
Test Loss:  0.0008430101443082094
Valid Loss:  0.0010064546950161457
Epoch:  116  	Training Loss: 0.0011956363450735807
Test Loss:  0.0008386097033508122
Valid Loss:  0.0010037475731223822
Epoch:  117  	Training Loss: 0.0011890579480677843
Test Loss:  0.0008343927329406142
Valid Loss:  0.001001268858090043
Epoch:  118  	Training Loss: 0.0011827603448182344
Test Loss:  0.000830279546789825
Valid Loss:  0.0009988168021664023
Epoch:  119  	Training Loss: 0.0011766809038817883
Test Loss:  0.0008262965129688382
Valid Loss:  0.0009964825585484505
Epoch:  120  	Training Loss: 0.0011707947123795748
Test Loss:  0.0008224645280279219
Valid Loss:  0.0009941859170794487
Epoch:  121  	Training Loss: 0.001165115158073604
Test Loss:  0.0008187645580619574
Valid Loss:  0.0009920690208673477
Epoch:  122  	Training Loss: 0.0011594945099204779
Test Loss:  0.0008102928404696286
Valid Loss:  0.0009871211368590593
Epoch:  123  	Training Loss: 0.0011453842744231224
Test Loss:  0.0008090321207419038
Valid Loss:  0.0009869815548881888
Epoch:  124  	Training Loss: 0.001139986445195973
Test Loss:  0.000808594049885869
Valid Loss:  0.0009875684045255184
Epoch:  125  	Training Loss: 0.0011375087779015303
Test Loss:  0.0008080506231635809
Valid Loss:  0.0009879658464342356
Epoch:  126  	Training Loss: 0.0011354165617376566
Test Loss:  0.0008073655189946294
Valid Loss:  0.000988091342151165
Epoch:  127  	Training Loss: 0.001133448793552816
Test Loss:  0.0008066993905231357
Valid Loss:  0.000988250831142068
Epoch:  128  	Training Loss: 0.0011315763695165515
Test Loss:  0.0008060688269324601
Valid Loss:  0.0009883529273793101
Epoch:  129  	Training Loss: 0.0011297925375401974
Test Loss:  0.0008055308717302978
Valid Loss:  0.0009884260362014174
Epoch:  130  	Training Loss: 0.0011280493345111609
Test Loss:  0.0008049109019339085
Valid Loss:  0.0009883621241897345
Epoch:  131  	Training Loss: 0.001126346061937511
Test Loss:  0.000804317940492183
Valid Loss:  0.0009883554885163903
Epoch:  132  	Training Loss: 0.0011247312650084496
Test Loss:  0.000798008288256824
Valid Loss:  0.0009822997963055968
Epoch:  133  	Training Loss: 0.001117017469368875
Test Loss:  0.0007921344367787242
Valid Loss:  0.0009768179152160883
Epoch:  134  	Training Loss: 0.0011096723610535264
Test Loss:  0.0007864517392590642
Valid Loss:  0.0009716159547679126
Epoch:  135  	Training Loss: 0.001102551817893982
Test Loss:  0.0007809418020769954
Valid Loss:  0.0009667158592492342
Epoch:  136  	Training Loss: 0.0010957270860671997
Test Loss:  0.0007757183630019426
Valid Loss:  0.0009622263023629785
Epoch:  137  	Training Loss: 0.001089327153749764
Test Loss:  0.0007706729811616242
Valid Loss:  0.0009580316254869103
Epoch:  138  	Training Loss: 0.0010831739054992795
Test Loss:  0.0007657880778424442
Valid Loss:  0.0009541884646750987
Epoch:  139  	Training Loss: 0.001077202265150845
Test Loss:  0.0007609690073877573
Valid Loss:   28%|██▊       | 139/500 [01:38<02:01,  2.97it/s] 28%|██▊       | 141/500 [01:44<07:07,  1.19s/it] 29%|██▊       | 143/500 [01:44<05:05,  1.17it/s] 29%|██▉       | 145/500 [01:44<03:39,  1.62it/s] 29%|██▉       | 147/500 [01:44<02:42,  2.18it/s] 30%|██▉       | 149/500 [01:45<02:02,  2.87it/s] 30%|███       | 151/500 [01:51<07:04,  1.22s/it] 31%|███       | 153/500 [01:51<05:02,  1.15it/s] 31%|███       | 155/500 [01:51<03:37,  1.59it/s] 31%|███▏      | 157/500 [01:51<02:38,  2.17it/s] 32%|███▏      | 159/500 [01:52<01:57,  2.91it/s] 32%|███▏      | 161/500 [01:58<06:43,  1.19s/it] 33%|███▎      | 163/500 [01:58<04:50,  1.16it/s] 33%|███▎      | 165/500 [01:58<03:31,  1.59it/s] 33%|███▎      | 167/500 [01:59<02:36,  2.13it/s] 34%|███▍      | 169/500 [01:59<01:57,  2.83it/s] 34%|███▍      | 171/500 [02:05<06:43,  1.23s/it] 35%|███▍      | 173/500 [02:05<04:47,  1.14it/s] 35%|███▌      | 175/500 [02:05<03:26,  1.57it/s] 35%|███▌      | 177/500 [02:06<02:30,  2.15it/s] 36%|███▌      | 179/500 [02:06<01:50,  2.89it/s] 36%|███▌      | 181/500 [02:12<06:27,  1.21s/it] 37%|███▋      | 183/500 [02:12<04:36,  1.15it/s] 37%|███▋      | 185/500 [02:12<03:18,  1.59it/s] 37%|███▋      | 187/500 [02:13<02:24,  2.17it/s] 38%|███▊      | 189/500 [02:13<01:46,  2.92it/s] 38%|███▊      | 191/500 [02:19<06:13,  1.21s/it] 39%|███▊      | 193/500 [02:19<04:26,  1.15it/s] 39%|███▉      | 195/500 [02:20<03:11,  1.59it/s] 39%|███▉      | 197/500 [02:20<02:19,  2.18it/s] 40%|███▉      | 199/500 [02:20<01:42,  2.93it/s] 40%|████      | 201/500 [02:26<05:57,  1.20s/it] 41%|████      | 203/500 [02:26<04:15,  1.16it/s] 41%|████      | 205/500 [02:26<03:03,  1.61it/s] 41%|████▏     | 207/500 [02:27<02:13,  2.20it/s]0.0009504028130322695
Epoch:  140  	Training Loss: 0.0010714182863011956
Test Loss:  0.0007563213584944606
Valid Loss:  0.0009467849740758538
Epoch:  141  	Training Loss: 0.0010658791288733482
Test Loss:  0.0007519290084019303
Valid Loss:  0.0009432397200725973
Epoch:  142  	Training Loss: 0.0010604705894365907
Test Loss:  0.0007476062746718526
Valid Loss:  0.000939801218919456
Epoch:  143  	Training Loss: 0.0010543512180447578
Test Loss:  0.0007437278982251883
Valid Loss:  0.0009366149897687137
Epoch:  144  	Training Loss: 0.0010490992572158575
Test Loss:  0.0007397524314001203
Valid Loss:  0.00093315658159554
Epoch:  145  	Training Loss: 0.0010441907215863466
Test Loss:  0.0007365156197920442
Valid Loss:  0.0009308336302638054
Epoch:  146  	Training Loss: 0.0010395296849310398
Test Loss:  0.0007330180378630757
Valid Loss:  0.0009279515943489969
Epoch:  147  	Training Loss: 0.0010352133540436625
Test Loss:  0.000730187923181802
Valid Loss:  0.0009261213708668947
Epoch:  148  	Training Loss: 0.0010311739752069116
Test Loss:  0.0007270601927302778
Valid Loss:  0.0009238352649845183
Epoch:  149  	Training Loss: 0.0010274553205817938
Test Loss:  0.0007244511507451534
Valid Loss:  0.0009225193643942475
Epoch:  150  	Training Loss: 0.0010238512186333537
Test Loss:  0.0007216471713036299
Valid Loss:  0.0009205440292134881
Epoch:  151  	Training Loss: 0.0010206005536019802
Test Loss:  0.000719273230060935
Valid Loss:  0.0009194596204906702
Epoch:  152  	Training Loss: 0.0010172710753977299
Test Loss:  0.000715959700755775
Valid Loss:  0.0009164997027255595
Epoch:  153  	Training Loss: 0.001013181172311306
Test Loss:  0.0007125940173864365
Valid Loss:  0.0009134566062130034
Epoch:  154  	Training Loss: 0.0010091682197526097
Test Loss:  0.0007093902677297592
Valid Loss:  0.0009106079232878983
Epoch:  155  	Training Loss: 0.001005367492325604
Test Loss:  0.0007062053773552179
Valid Loss:  0.0009077178547158837
Epoch:  156  	Training Loss: 0.0010016189189627767
Test Loss:  0.0007030522683635354
Valid Loss:  0.0009049016516655684
Epoch:  157  	Training Loss: 0.0009979192400351167
Test Loss:  0.0006999460165388882
Valid Loss:  0.0009021504665724933
Epoch:  158  	Training Loss: 0.00099428731482476
Test Loss:  0.0006969643873162568
Valid Loss:  0.0008994959061965346
Epoch:  159  	Training Loss: 0.0009907814674079418
Test Loss:  0.0006941119208931923
Valid Loss:  0.0008968519978225231
Epoch:  160  	Training Loss: 0.0009873335948213935
Test Loss:  0.0006914320401847363
Valid Loss:  0.0008942647837102413
Epoch:  161  	Training Loss: 0.0009839399717748165
Test Loss:  0.000688837026245892
Valid Loss:  0.0008918233797885478
Epoch:  162  	Training Loss: 0.0009806673042476177
Test Loss:  0.0006855473038740456
Valid Loss:  0.0008905334398150444
Epoch:  163  	Training Loss: 0.0009753448539413512
Test Loss:  0.0006823762087151408
Valid Loss:  0.0008891978650353849
Epoch:  164  	Training Loss: 0.000970399531070143
Test Loss:  0.0006792467320337892
Valid Loss:  0.0008877407526597381
Epoch:  165  	Training Loss: 0.00096568011213094
Test Loss:  0.0006762366974726319
Valid Loss:  0.0008863835828378797
Epoch:  166  	Training Loss: 0.0009612049907445908
Test Loss:  0.0006732687470503151
Valid Loss:  0.0008852350292727351
Epoch:  167  	Training Loss: 0.0009569344692863524
Test Loss:  0.0006703842664137483
Valid Loss:  0.000884234847035259
Epoch:  168  	Training Loss: 0.000952855683863163
Test Loss:  0.0006675573531538248
Valid Loss:  0.0008832605089992285
Epoch:  169  	Training Loss: 0.0009488862124271691
Test Loss:  0.0006648527923971415
Valid Loss:  0.0008823135867714882
Epoch:  170  	Training Loss: 0.0009450383950024843
Test Loss:  0.0006622773944400251
Valid Loss:  0.0008813616586849093
Epoch:  171  	Training Loss: 0.0009413515217602253
Test Loss:  0.000659929821267724
Valid Loss:  0.0008805939578451216
Epoch:  172  	Training Loss: 0.0009379500988870859
Test Loss:  0.0006580826593562961
Valid Loss:  0.000878533988725394
Epoch:  173  	Training Loss: 0.0009360502008348703
Test Loss:  0.0006566339870914817
Valid Loss:  0.0008770039421506226
Epoch:  174  	Training Loss: 0.000934332434553653
Test Loss:  0.0006554471328854561
Valid Loss:  0.0008759699994698167
Epoch:  175  	Training Loss: 0.0009327618754468858
Test Loss:  0.000654339964967221
Valid Loss:  0.0008751456625759602
Epoch:  176  	Training Loss: 0.0009312344482168555
Test Loss:  0.0006532773259095848
Valid Loss:  0.0008744864608161151
Epoch:  177  	Training Loss: 0.0009297284996137023
Test Loss:  0.0006522400071844459
Valid Loss:  0.0008738258038647473
Epoch:  178  	Training Loss: 0.0009282692917622626
Test Loss:  0.0006512588006444275
Valid Loss:  0.0008732550777494907
Epoch:  179  	Training Loss: 0.0009268725989386439
Test Loss:  0.0006503094336949289
Valid Loss:  0.0008727136882953346
Epoch:  180  	Training Loss: 0.0009255197364836931
Test Loss:  0.0006493875989690423
Valid Loss:  0.0008722349302843213
Epoch:  181  	Training Loss: 0.0009242460364475846
Test Loss:  0.0006486290949396789
Valid Loss:  0.0008720079204067588
Epoch:  182  	Training Loss: 0.0009231058647856116
Test Loss:  0.0006469186046160758
Valid Loss:  0.0008706459193490446
Epoch:  183  	Training Loss: 0.0009211439173668623
Test Loss:  0.0006453041569329798
Valid Loss:  0.0008694248972460628
Epoch:  184  	Training Loss: 0.0009193429723381996
Test Loss:  0.0006437213160097599
Valid Loss:  0.000868297996930778
Epoch:  185  	Training Loss: 0.0009176541934721172
Test Loss:  0.0006421580328606069
Valid Loss:  0.0008672620169818401
Epoch:  186  	Training Loss: 0.0009160671615973115
Test Loss:  0.0006406542379409075
Valid Loss:  0.0008662834297865629
Epoch:  187  	Training Loss: 0.000914568779990077
Test Loss:  0.0006392639479599893
Valid Loss:  0.0008654284756630659
Epoch:  188  	Training Loss: 0.0009131625993177295
Test Loss:  0.00063793093431741
Valid Loss:  0.0008645342313684523
Epoch:  189  	Training Loss: 0.0009118316229432821
Test Loss:  0.0006367969326674938
Valid Loss:  0.0008637631544843316
Epoch:  190  	Training Loss: 0.0009106373181566596
Test Loss:  0.0006356992525979877
Valid Loss:  0.0008630361407995224
Epoch:  191  	Training Loss: 0.0009094900451600552
Test Loss:  0.0006346393493004143
Valid Loss:  0.0008623847970739007
Epoch:  192  	Training Loss: 0.0009083813638426363
Test Loss:  0.0006331151816993952
Valid Loss:  0.0008614398539066315
Epoch:  193  	Training Loss: 0.0009069398511201143
Test Loss:  0.0006317875813692808
Valid Loss:  0.000860765459947288
Epoch:  194  	Training Loss: 0.0009056038688868284
Test Loss:  0.0006307543953880668
Valid Loss:  0.0008604447357356548
Epoch:  195  	Training Loss: 0.000904410844668746
Test Loss:  0.0006298355292528868
Valid Loss:  0.0008602401940152049
Epoch:  196  	Training Loss: 0.0009032799862325191
Test Loss:  0.0006289437878876925
Valid Loss:  0.0008600433357059956
Epoch:  197  	Training Loss: 0.000902175554074347
Test Loss:  0.0006281068781390786
Valid Loss:  0.0008598751155659556
Epoch:  198  	Training Loss: 0.0009011044749058783
Test Loss:  0.0006272993632592261
Valid Loss:  0.000859716790728271
Epoch:  199  	Training Loss: 0.0009000861318781972
Test Loss:  0.0006265376578085124
Valid Loss:  0.0008596185361966491
Epoch:  200  	Training Loss: 0.0008991206996142864
Test Loss:  0.0006257955683395267
Valid Loss:  0.000859529769513756
Epoch:  201  	Training Loss: 0.0008981873979791999
Test Loss:  0.00062508974224329
Valid Loss:  0.0008594702230766416
Epoch:  202  	Training Loss: 0.0008972957148216665
Test Loss:  0.000625255168415606
Valid Loss:  0.0008596063125878572
Epoch:  203  	Training Loss: 0.000896367768291384
Test Loss:  0.0006253975443542004
Valid Loss:  0.0008597260457463562
Epoch:  204  	Training Loss: 0.0008955762023106217
Test Loss:  0.0006255194311961532
Valid Loss:  0.0008598301792517304
Epoch:  205  	Training Loss: 0.0008949566399678588
Test Loss:  0.0006256704800762236
Valid Loss:  0.0008599447901360691
Epoch:  206  	Training Loss: 0.0008943872526288033
Test Loss:  0.0006258049979805946
Valid Loss:  0.0008600434521213174
Epoch:  207  	Training Loss: 0.0008938541868701577
Test Loss:  0.00062596146017313
Valid Loss:  0.0008602163288742304
 42%|████▏     | 209/500 [02:27<01:38,  2.95it/s] 42%|████▏     | 211/500 [02:33<05:46,  1.20s/it] 43%|████▎     | 213/500 [02:33<04:07,  1.16it/s] 43%|████▎     | 215/500 [02:33<02:57,  1.60it/s] 43%|████▎     | 217/500 [02:34<02:09,  2.19it/s] 44%|████▍     | 219/500 [02:34<01:35,  2.93it/s] 44%|████▍     | 221/500 [02:40<05:36,  1.21s/it] 45%|████▍     | 223/500 [02:40<03:59,  1.16it/s] 45%|████▌     | 225/500 [02:40<02:52,  1.60it/s] 45%|████▌     | 227/500 [02:41<02:05,  2.18it/s] 46%|████▌     | 229/500 [02:41<01:32,  2.94it/s] 46%|████▌     | 231/500 [02:47<05:22,  1.20s/it] 47%|████▋     | 233/500 [02:47<03:49,  1.16it/s] 47%|████▋     | 235/500 [02:47<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:47<01:59,  2.20it/s] 48%|████▊     | 239/500 [02:48<01:28,  2.95it/s] 48%|████▊     | 241/500 [02:54<05:12,  1.21s/it] 49%|████▊     | 243/500 [02:54<03:42,  1.15it/s] 49%|████▉     | 245/500 [02:54<02:39,  1.60it/s] 49%|████▉     | 247/500 [02:54<01:55,  2.18it/s] 50%|████▉     | 249/500 [02:55<01:25,  2.93it/s] 50%|█████     | 251/500 [03:01<04:55,  1.19s/it] 51%|█████     | 253/500 [03:01<03:32,  1.16it/s] 51%|█████     | 255/500 [03:01<02:33,  1.60it/s] 51%|█████▏    | 257/500 [03:01<01:51,  2.19it/s] 52%|█████▏    | 259/500 [03:02<01:21,  2.94it/s] 52%|█████▏    | 261/500 [03:08<04:46,  1.20s/it] 53%|█████▎    | 263/500 [03:08<03:23,  1.16it/s] 53%|█████▎    | 265/500 [03:08<02:25,  1.61it/s] 53%|█████▎    | 267/500 [03:08<01:46,  2.18it/s] 54%|█████▍    | 269/500 [03:09<01:20,  2.89it/s] 54%|█████▍    | 271/500 [03:15<04:34,  1.20s/it] 55%|█████▍    | 273/500 [03:15<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:15<02:20,  1.60it/s]Epoch:  208  	Training Loss: 0.0008934017969295382
Test Loss:  0.0006260836380533874
Valid Loss:  0.0008603751775808632
Epoch:  209  	Training Loss: 0.0008929651812650263
Test Loss:  0.0006261771777644753
Valid Loss:  0.0008605554467067122
Epoch:  210  	Training Loss: 0.0008925477741286159
Test Loss:  0.000626291090156883
Valid Loss:  0.0008607306517660618
Epoch:  211  	Training Loss: 0.0008921684348024428
Test Loss:  0.0006263942923396826
Valid Loss:  0.0008608779171481729
Epoch:  212  	Training Loss: 0.0008918361272662878
Test Loss:  0.0006256939959712327
Valid Loss:  0.0008604158065281808
Epoch:  213  	Training Loss: 0.0008914374629966915
Test Loss:  0.0006251077866181731
Valid Loss:  0.0008600937435403466
Epoch:  214  	Training Loss: 0.0008910815231502056
Test Loss:  0.0006246549310162663
Valid Loss:  0.0008599399589002132
Epoch:  215  	Training Loss: 0.0008907542214728892
Test Loss:  0.0006242766976356506
Valid Loss:  0.00085984799079597
Epoch:  216  	Training Loss: 0.0008904346614144742
Test Loss:  0.0006239542854018509
Valid Loss:  0.0008597637061029673
Epoch:  217  	Training Loss: 0.0008901180699467659
Test Loss:  0.0006236801855266094
Valid Loss:  0.0008597057894803584
Epoch:  218  	Training Loss: 0.0008898050873540342
Test Loss:  0.0006234185420908034
Valid Loss:  0.0008596679545007646
Epoch:  219  	Training Loss: 0.0008895036298781633
Test Loss:  0.0006232232553884387
Valid Loss:  0.0008597150444984436
Epoch:  220  	Training Loss: 0.000889226037543267
Test Loss:  0.0006230745348148048
Valid Loss:  0.0008598263375461102
Epoch:  221  	Training Loss: 0.0008889721939340234
Test Loss:  0.0006230240105651319
Valid Loss:  0.0008600722067058086
Epoch:  222  	Training Loss: 0.0008887425065040588
Test Loss:  0.0006197393522597849
Valid Loss:  0.0008572982624173164
Epoch:  223  	Training Loss: 0.0008846262935549021
Test Loss:  0.000616887875366956
Valid Loss:  0.0008548354962840676
Epoch:  224  	Training Loss: 0.0008809086866676807
Test Loss:  0.0006147645181044936
Valid Loss:  0.000853347999509424
Epoch:  225  	Training Loss: 0.0008780683856457472
Test Loss:  0.0006130895344540477
Valid Loss:  0.0008524208096787333
Epoch:  226  	Training Loss: 0.000875681871548295
Test Loss:  0.0006117857992649078
Valid Loss:  0.0008519302355125546
Epoch:  227  	Training Loss: 0.0008735940791666508
Test Loss:  0.0006106453947722912
Valid Loss:  0.0008516381494700909
Epoch:  228  	Training Loss: 0.0008716639131307602
Test Loss:  0.0006096262950450182
Valid Loss:  0.0008513724897056818
Epoch:  229  	Training Loss: 0.0008698720484972
Test Loss:  0.0006088294321671128
Valid Loss:  0.000851317192427814
Epoch:  230  	Training Loss: 0.0008682487532496452
Test Loss:  0.0006079598097130656
Valid Loss:  0.0008512157364748418
Epoch:  231  	Training Loss: 0.000866688962560147
Test Loss:  0.0006071157404221594
Valid Loss:  0.0008511063060723245
Epoch:  232  	Training Loss: 0.0008652206743136048
Test Loss:  0.0006028534844517708
Valid Loss:  0.0008470990578643978
Epoch:  233  	Training Loss: 0.0008610098739154637
Test Loss:  0.0006001899018883705
Valid Loss:  0.0008451294852420688
Epoch:  234  	Training Loss: 0.0008580074645578861
Test Loss:  0.0005978622939437628
Valid Loss:  0.000843654852360487
Epoch:  235  	Training Loss: 0.0008553022053092718
Test Loss:  0.0005960911512374878
Valid Loss:  0.0008426655549556017
Epoch:  236  	Training Loss: 0.0008527419995516539
Test Loss:  0.0005942505085840821
Valid Loss:  0.0008416242199018598
Epoch:  237  	Training Loss: 0.0008502347627654672
Test Loss:  0.0005923910066485405
Valid Loss:  0.0008405190892517567
Epoch:  238  	Training Loss: 0.0008477719966322184
Test Loss:  0.0005906120641157031
Valid Loss:  0.0008395347977057099
Epoch:  239  	Training Loss: 0.0008453696500509977
Test Loss:  0.0005888937739655375
Valid Loss:  0.000838566804304719
Epoch:  240  	Training Loss: 0.0008430177113041282
Test Loss:  0.0005871662287972867
Valid Loss:  0.0008375701727345586
Epoch:  241  	Training Loss: 0.000840722699649632
Test Loss:  0.0005856381030753255
Valid Loss:  0.0008367430418729782
Epoch:  242  	Training Loss: 0.0008385191904380918
Test Loss:  0.0005847477586939931
Valid Loss:  0.0008364347158931196
Epoch:  243  	Training Loss: 0.0008361892541870475
Test Loss:  0.0005839288933202624
Valid Loss:  0.0008358635241165757
Epoch:  244  	Training Loss: 0.0008343278896063566
Test Loss:  0.0005829018773511052
Valid Loss:  0.0008350035641342402
Epoch:  245  	Training Loss: 0.0008326671668328345
Test Loss:  0.0005818353965878487
Valid Loss:  0.0008342457003891468
Epoch:  246  	Training Loss: 0.0008310681441798806
Test Loss:  0.0005806926637887955
Valid Loss:  0.0008333004079759121
Epoch:  247  	Training Loss: 0.0008295662701129913
Test Loss:  0.0005796529585495591
Valid Loss:  0.0008325367816723883
Epoch:  248  	Training Loss: 0.0008282872149720788
Test Loss:  0.0005786428228020668
Valid Loss:  0.0008318115724250674
Epoch:  249  	Training Loss: 0.000827127369120717
Test Loss:  0.0005776596954092383
Valid Loss:  0.0008311911951750517
Epoch:  250  	Training Loss: 0.0008260568138211966
Test Loss:  0.0005767638795077801
Valid Loss:  0.0008305802475661039
Epoch:  251  	Training Loss: 0.0008250825339928269
Test Loss:  0.0005759659688919783
Valid Loss:  0.0008300697081722319
Epoch:  252  	Training Loss: 0.0008242129697464406
Test Loss:  0.0005745760281570256
Valid Loss:  0.0008291527046822011
Epoch:  253  	Training Loss: 0.0008228394435718656
Test Loss:  0.000573283527046442
Valid Loss:  0.0008283351780846715
Epoch:  254  	Training Loss: 0.0008215169655159116
Test Loss:  0.0005720111075788736
Valid Loss:  0.000827557931188494
Epoch:  255  	Training Loss: 0.0008202084572985768
Test Loss:  0.0005708259996026754
Valid Loss:  0.0008268383098766208
Epoch:  256  	Training Loss: 0.0008189314976334572
Test Loss:  0.0005697029992006719
Valid Loss:  0.0008261617040261626
Epoch:  257  	Training Loss: 0.0008177030249498785
Test Loss:  0.0005686299409717321
Valid Loss:  0.0008255141437985003
Epoch:  258  	Training Loss: 0.0008164881728589535
Test Loss:  0.0005675514694303274
Valid Loss:  0.0008248707745224237
Epoch:  259  	Training Loss: 0.000815276987850666
Test Loss:  0.0005664720665663481
Valid Loss:  0.0008242021431215107
Epoch:  260  	Training Loss: 0.0008140889694914222
Test Loss:  0.0005654667038470507
Valid Loss:  0.0008236130815930665
Epoch:  261  	Training Loss: 0.0008129501366056502
Test Loss:  0.0005644555203616619
Valid Loss:  0.0008230077801272273
Epoch:  262  	Training Loss: 0.0008118252735584974
Test Loss:  0.0005632825195789337
Valid Loss:  0.000822212197817862
Epoch:  263  	Training Loss: 0.0008104730513878167
Test Loss:  0.0005621487507596612
Valid Loss:  0.0008214616682380438
Epoch:  264  	Training Loss: 0.0008092275820672512
Test Loss:  0.0005609842482954264
Valid Loss:  0.0008207138162106276
Epoch:  265  	Training Loss: 0.0008080422412604094
Test Loss:  0.000559869862627238
Valid Loss:  0.0008200476877391338
Epoch:  266  	Training Loss: 0.0008069495670497417
Test Loss:  0.0005588260246440768
Valid Loss:  0.0008194517577067018
Epoch:  267  	Training Loss: 0.000805914867669344
Test Loss:  0.0005578109994530678
Valid Loss:  0.0008188670035451651
Epoch:  268  	Training Loss: 0.000804907875135541
Test Loss:  0.0005568265332840383
Valid Loss:  0.0008183091995306313
Epoch:  269  	Training Loss: 0.000803910312242806
Test Loss:  0.0005559315904974937
Valid Loss:  0.0008177576819434762
Epoch:  270  	Training Loss: 0.0008029717137105763
Test Loss:  0.0005550881614908576
Valid Loss:  0.0008172604721039534
Epoch:  271  	Training Loss: 0.000802092719823122
Test Loss:  0.0005542610306292772
Valid Loss:  0.0008168036583811045
Epoch:  272  	Training Loss: 0.0008012430625967681
Test Loss:  0.0005533330258913338
Valid Loss:  0.000816542946267873
Epoch:  273  	Training Loss: 0.0007991212187334895
Test Loss:  0.0005528677720576525
Valid Loss:  0.0008166097104549408
Epoch:  274  	Training Loss: 0.0007977394852787256
Test Loss:  0.0005524948355741799
Valid Loss:  0.0008165400940924883
Epoch:  275  	Training Loss: 0.0007966093253344297
Test Loss:  0.0005519802216440439
Valid Loss:  0.0008162672747857869
Epoch:  276  	Training Loss: 0.0007956426125019789
 55%|█████▌    | 277/500 [03:15<01:43,  2.16it/s] 56%|█████▌    | 279/500 [03:16<01:17,  2.85it/s] 56%|█████▌    | 281/500 [03:22<04:21,  1.19s/it] 57%|█████▋    | 283/500 [03:22<03:06,  1.16it/s] 57%|█████▋    | 285/500 [03:22<02:13,  1.61it/s] 57%|█████▋    | 287/500 [03:22<01:37,  2.19it/s] 58%|█████▊    | 289/500 [03:22<01:11,  2.94it/s] 58%|█████▊    | 291/500 [03:29<04:11,  1.21s/it] 59%|█████▊    | 293/500 [03:29<02:59,  1.16it/s] 59%|█████▉    | 295/500 [03:29<02:08,  1.60it/s] 59%|█████▉    | 297/500 [03:29<01:32,  2.18it/s] 60%|█████▉    | 299/500 [03:29<01:08,  2.93it/s] 60%|██████    | 301/500 [03:36<03:56,  1.19s/it] 61%|██████    | 303/500 [03:36<02:48,  1.17it/s] 61%|██████    | 305/500 [03:36<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:36<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:36<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:43<03:50,  1.22s/it] 63%|██████▎   | 313/500 [03:43<02:43,  1.14it/s] 63%|██████▎   | 315/500 [03:43<01:57,  1.58it/s] 63%|██████▎   | 317/500 [03:43<01:24,  2.16it/s] 64%|██████▍   | 319/500 [03:43<01:02,  2.91it/s] 64%|██████▍   | 321/500 [03:50<03:36,  1.21s/it] 65%|██████▍   | 323/500 [03:50<02:33,  1.15it/s] 65%|██████▌   | 325/500 [03:50<01:49,  1.59it/s] 65%|██████▌   | 327/500 [03:50<01:19,  2.18it/s] 66%|██████▌   | 329/500 [03:50<00:58,  2.92it/s] 66%|██████▌   | 331/500 [03:57<03:22,  1.20s/it] 67%|██████▋   | 333/500 [03:57<02:23,  1.16it/s] 67%|██████▋   | 335/500 [03:57<01:43,  1.59it/s] 67%|██████▋   | 337/500 [03:57<01:15,  2.15it/s] 68%|██████▊   | 339/500 [03:57<00:56,  2.84it/s] 68%|██████▊   | 341/500 [04:04<03:12,  1.21s/it] 69%|██████▊   | 343/500 [04:04<02:16,  1.15it/s]Test Loss:  0.0005513872019946575
Valid Loss:  0.0008159244316630065
Epoch:  277  	Training Loss: 0.0007947481935843825
Test Loss:  0.0005507587920874357
Valid Loss:  0.0008155400864779949
Epoch:  278  	Training Loss: 0.0007938774069771171
Test Loss:  0.0005500518018379807
Valid Loss:  0.0008150723879225552
Epoch:  279  	Training Loss: 0.0007930149440653622
Test Loss:  0.0005493636708706617
Valid Loss:  0.000814632629044354
Epoch:  280  	Training Loss: 0.0007921613287180662
Test Loss:  0.0005487006856128573
Valid Loss:  0.0008142150472849607
Epoch:  281  	Training Loss: 0.0007913445588201284
Test Loss:  0.000548082054592669
Valid Loss:  0.0008138280245475471
Epoch:  282  	Training Loss: 0.0007905485690571368
Test Loss:  0.0005458106752485037
Valid Loss:  0.0008120659040287137
Epoch:  283  	Training Loss: 0.0007879922632128
Test Loss:  0.0005437451181933284
Valid Loss:  0.0008104764856398106
Epoch:  284  	Training Loss: 0.0007855196017771959
Test Loss:  0.0005417764186859131
Valid Loss:  0.000808974145911634
Epoch:  285  	Training Loss: 0.0007831347174942493
Test Loss:  0.0005399321671575308
Valid Loss:  0.0008075493387877941
Epoch:  286  	Training Loss: 0.0007808588561601937
Test Loss:  0.0005381766241043806
Valid Loss:  0.0008062210399657488
Epoch:  287  	Training Loss: 0.000778678513597697
Test Loss:  0.0005364472162909806
Valid Loss:  0.0008049188181757927
Epoch:  288  	Training Loss: 0.000776558299548924
Test Loss:  0.0005347435362637043
Valid Loss:  0.0008036294020712376
Epoch:  289  	Training Loss: 0.0007744954200461507
Test Loss:  0.0005330839194357395
Valid Loss:  0.0008023555274121463
Epoch:  290  	Training Loss: 0.0007724905153736472
Test Loss:  0.0005314624286256731
Valid Loss:  0.0008010721066966653
Epoch:  291  	Training Loss: 0.0007705179741606116
Test Loss:  0.0005298706819303334
Valid Loss:  0.0007997944485396147
Epoch:  292  	Training Loss: 0.0007685875752940774
Test Loss:  0.0005297891329973936
Valid Loss:  0.0007994474144652486
Epoch:  293  	Training Loss: 0.0007680188282392919
Test Loss:  0.0005300387274473906
Valid Loss:  0.0007996368804015219
Epoch:  294  	Training Loss: 0.000767646124586463
Test Loss:  0.0005302682402543724
Valid Loss:  0.0007997867651283741
Epoch:  295  	Training Loss: 0.0007673241198062897
Test Loss:  0.0005304203368723392
Valid Loss:  0.0007998580113053322
Epoch:  296  	Training Loss: 0.0007670822087675333
Test Loss:  0.000530509976670146
Valid Loss:  0.0007998858345672488
Epoch:  297  	Training Loss: 0.0007668513571843505
Test Loss:  0.0005306540988385677
Valid Loss:  0.0007999688386917114
Epoch:  298  	Training Loss: 0.0007666324381716549
Test Loss:  0.0005307558458298445
Valid Loss:  0.0007999961380846798
Epoch:  299  	Training Loss: 0.0007664341828785837
Test Loss:  0.0005309094558469951
Valid Loss:  0.0008000850211828947
Epoch:  300  	Training Loss: 0.0007662455318495631
Test Loss:  0.0005309326807036996
Valid Loss:  0.0008000433444976807
Epoch:  301  	Training Loss: 0.0007660689298063517
Test Loss:  0.0005310086417011917
Valid Loss:  0.0008000407251529396
Epoch:  302  	Training Loss: 0.0007658952963538468
Test Loss:  0.0005279587348923087
Valid Loss:  0.0007970790611580014
Epoch:  303  	Training Loss: 0.0007633607601746917
Test Loss:  0.0005255967262201011
Valid Loss:  0.0007947910926304758
Epoch:  304  	Training Loss: 0.0007612422341480851
Test Loss:  0.0005234841955825686
Valid Loss:  0.0007927987026050687
Epoch:  305  	Training Loss: 0.0007592556066811085
Test Loss:  0.0005215578712522984
Valid Loss:  0.0007909896085038781
Epoch:  306  	Training Loss: 0.0007573586772195995
Test Loss:  0.0005197431892156601
Valid Loss:  0.0007893090369179845
Epoch:  307  	Training Loss: 0.0007555459742434323
Test Loss:  0.0005180455627851188
Valid Loss:  0.0007877200841903687
Epoch:  308  	Training Loss: 0.0007538212812505662
Test Loss:  0.000516472035087645
Valid Loss:  0.0007862865459173918
Epoch:  309  	Training Loss: 0.0007521571242250502
Test Loss:  0.0005149266216903925
Valid Loss:  0.0007849073735997081
Epoch:  310  	Training Loss: 0.0007505235262215137
Test Loss:  0.0005134909879416227
Valid Loss:  0.0007835894357413054
Epoch:  311  	Training Loss: 0.000748920370824635
Test Loss:  0.0005122112925164402
Valid Loss:  0.0007823470514267683
Epoch:  312  	Training Loss: 0.0007474284502677619
Test Loss:  0.0005113920196890831
Valid Loss:  0.0007815100252628326
Epoch:  313  	Training Loss: 0.0007467205869033933
Test Loss:  0.0005106074968352914
Valid Loss:  0.0007807346410118043
Epoch:  314  	Training Loss: 0.0007460508495569229
Test Loss:  0.000509852368850261
Valid Loss:  0.0007800046587362885
Epoch:  315  	Training Loss: 0.0007454071892425418
Test Loss:  0.0005091531202197075
Valid Loss:  0.0007793376571498811
Epoch:  316  	Training Loss: 0.0007447992684319615
Test Loss:  0.000508489552885294
Valid Loss:  0.0007786939386278391
Epoch:  317  	Training Loss: 0.0007442334899678826
Test Loss:  0.0005078709800727665
Valid Loss:  0.0007780740270391107
Epoch:  318  	Training Loss: 0.0007436770247295499
Test Loss:  0.0005072725471109152
Valid Loss:  0.0007774897385388613
Epoch:  319  	Training Loss: 0.0007431315025314689
Test Loss:  0.000506685406435281
Valid Loss:  0.0007769175572320819
Epoch:  320  	Training Loss: 0.0007426016381941736
Test Loss:  0.0005061146803200245
Valid Loss:  0.0007763892062939703
Epoch:  321  	Training Loss: 0.0007420872570946813
Test Loss:  0.0005055659567005932
Valid Loss:  0.0007759017171338201
Epoch:  322  	Training Loss: 0.0007415998261421919
Test Loss:  0.0005055230576545
Valid Loss:  0.0007758710999041796
Epoch:  323  	Training Loss: 0.0007410692051053047
Test Loss:  0.0005054710782133043
Valid Loss:  0.0007757977582514286
Epoch:  324  	Training Loss: 0.0007406094809994102
Test Loss:  0.0005053956992924213
Valid Loss:  0.0007756806444376707
Epoch:  325  	Training Loss: 0.000740171002689749
Test Loss:  0.0005052878987044096
Valid Loss:  0.0007755127735435963
Epoch:  326  	Training Loss: 0.0007397479494102299
Test Loss:  0.0005051522748544812
Valid Loss:  0.0007753393147140741
Epoch:  327  	Training Loss: 0.0007393506821244955
Test Loss:  0.0005049594328738749
Valid Loss:  0.0007751392549835145
Epoch:  328  	Training Loss: 0.0007389762322418392
Test Loss:  0.00050476158503443
Valid Loss:  0.0007749320357106626
Epoch:  329  	Training Loss: 0.0007386124925687909
Test Loss:  0.0005045690340921283
Valid Loss:  0.0007747329073026776
Epoch:  330  	Training Loss: 0.0007382649928331375
Test Loss:  0.0005043809651397169
Valid Loss:  0.0007745343609713018
Epoch:  331  	Training Loss: 0.0007379479939118028
Test Loss:  0.0005042254342697561
Valid Loss:  0.0007743783062323928
Epoch:  332  	Training Loss: 0.0007376510184258223
Test Loss:  0.0005043214769102633
Valid Loss:  0.0007744278991594911
Epoch:  333  	Training Loss: 0.0007375012501142919
Test Loss:  0.0005043887649662793
Valid Loss:  0.000774446758441627
Epoch:  334  	Training Loss: 0.0007373671396635473
Test Loss:  0.0005044402787461877
Valid Loss:  0.0007744571194052696
Epoch:  335  	Training Loss: 0.0007372350664809346
Test Loss:  0.000504503957927227
Valid Loss:  0.0007744787144474685
Epoch:  336  	Training Loss: 0.0007371072424575686
Test Loss:  0.0005045632133260369
Valid Loss:  0.0007744852919131517
Epoch:  337  	Training Loss: 0.00073697988409549
Test Loss:  0.0005045887664891779
Valid Loss:  0.0007744601462036371
Epoch:  338  	Training Loss: 0.0007368553197011352
Test Loss:  0.0005046325968578458
Valid Loss:  0.0007744455942884088
Epoch:  339  	Training Loss: 0.0007367350626736879
Test Loss:  0.0005046750884503126
Valid Loss:  0.0007744260365143418
Epoch:  340  	Training Loss: 0.0007366142235696316
Test Loss:  0.0005047125741839409
Valid Loss:  0.0007743991445749998
Epoch:  341  	Training Loss: 0.0007364990888163447
Test Loss:  0.0005047462182119489
Valid Loss:  0.0007743662572465837
Epoch:  342  	Training Loss: 0.000736388610675931
Test Loss:  0.0005047222366556525
Valid Loss:  0.0007742601446807384
Epoch:  343  	Training Loss: 0.0007362090400420129
Test Loss:  0.0005047066370025277
Valid Loss:  0.0007741556037217379
Epoch:  344  	Training Loss: 0.000736032088752836
Test Loss:  0.000504690280649811
Valid Loss:   69%|██████▉   | 345/500 [04:04<01:37,  1.59it/s] 69%|██████▉   | 347/500 [04:04<01:10,  2.17it/s] 70%|██████▉   | 349/500 [04:04<00:51,  2.93it/s] 70%|███████   | 351/500 [04:11<02:58,  1.20s/it] 71%|███████   | 353/500 [04:11<02:06,  1.16it/s] 71%|███████   | 355/500 [04:11<01:30,  1.61it/s] 71%|███████▏  | 357/500 [04:11<01:05,  2.18it/s] 72%|███████▏  | 359/500 [04:11<00:48,  2.93it/s] 72%|███████▏  | 361/500 [04:18<02:47,  1.21s/it] 73%|███████▎  | 363/500 [04:18<01:58,  1.15it/s] 73%|███████▎  | 365/500 [04:18<01:24,  1.59it/s] 73%|███████▎  | 367/500 [04:18<01:01,  2.18it/s] 74%|███████▍  | 369/500 [04:18<00:44,  2.93it/s] 74%|███████▍  | 371/500 [04:25<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:25<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:25<01:17,  1.62it/s] 75%|███████▌  | 377/500 [04:25<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:25<00:40,  2.97it/s] 76%|███████▌  | 381/500 [04:32<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:32<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:32<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:32<00:52,  2.17it/s] 78%|███████▊  | 389/500 [04:32<00:38,  2.86it/s] 78%|███████▊  | 391/500 [04:39<02:13,  1.23s/it] 79%|███████▊  | 393/500 [04:39<01:34,  1.13it/s] 79%|███████▉  | 395/500 [04:39<01:06,  1.57it/s] 79%|███████▉  | 397/500 [04:39<00:48,  2.14it/s] 80%|███████▉  | 399/500 [04:39<00:35,  2.88it/s] 80%|████████  | 401/500 [04:46<01:59,  1.20s/it] 81%|████████  | 403/500 [04:46<01:23,  1.16it/s] 81%|████████  | 405/500 [04:46<00:59,  1.60it/s] 81%|████████▏ | 407/500 [04:46<00:42,  2.18it/s] 82%|████████▏ | 409/500 [04:46<00:31,  2.92it/s] 82%|████████▏ | 411/500 [04:53<01:46,  1.20s/it]0.0007740691071376204
Epoch:  345  	Training Loss: 0.0007358589791692793
Test Loss:  0.0005046757869422436
Valid Loss:  0.0007739819120615721
Epoch:  346  	Training Loss: 0.000735687033738941
Test Loss:  0.0005046527367085218
Valid Loss:  0.0007738919230177999
Epoch:  347  	Training Loss: 0.000735524226911366
Test Loss:  0.0005046074511483312
Valid Loss:  0.0007737901760265231
Epoch:  348  	Training Loss: 0.0007353739347308874
Test Loss:  0.0005045808502472937
Valid Loss:  0.0007736874977126718
Epoch:  349  	Training Loss: 0.000735228240955621
Test Loss:  0.0005045529687777162
Valid Loss:  0.0007735876715742052
Epoch:  350  	Training Loss: 0.0007350895320996642
Test Loss:  0.0005045026773586869
Valid Loss:  0.0007734567625448108
Epoch:  351  	Training Loss: 0.0007349520456045866
Test Loss:  0.0005044544814154506
Valid Loss:  0.0007733487873338163
Epoch:  352  	Training Loss: 0.0007348242797888815
Test Loss:  0.0005033648340031505
Valid Loss:  0.0007722094305790961
Epoch:  353  	Training Loss: 0.0007328097708523273
Test Loss:  0.0005029671592637897
Valid Loss:  0.0007718570996075869
Epoch:  354  	Training Loss: 0.0007317123818211257
Test Loss:  0.0005027572624385357
Valid Loss:  0.0007716800319030881
Epoch:  355  	Training Loss: 0.0007308919448405504
Test Loss:  0.0005024629645049572
Valid Loss:  0.0007714537205174565
Epoch:  356  	Training Loss: 0.0007301797159016132
Test Loss:  0.0005021401448175311
Valid Loss:  0.0007712212391197681
Epoch:  357  	Training Loss: 0.000729501130990684
Test Loss:  0.0005017358344048262
Valid Loss:  0.0007709087803959846
Epoch:  358  	Training Loss: 0.0007288487977348268
Test Loss:  0.0005012777401134372
Valid Loss:  0.0007706013275310397
Epoch:  359  	Training Loss: 0.0007282293518073857
Test Loss:  0.0005008375737816095
Valid Loss:  0.0007702994626015425
Epoch:  360  	Training Loss: 0.0007276220712810755
Test Loss:  0.000500486115925014
Valid Loss:  0.0007700104033574462
Epoch:  361  	Training Loss: 0.0007270326605066657
Test Loss:  0.0005001190584152937
Valid Loss:  0.0007696523680351675
Epoch:  362  	Training Loss: 0.0007264914456754923
Test Loss:  0.000499415269587189
Valid Loss:  0.0007688518380746245
Epoch:  363  	Training Loss: 0.0007259421981871128
Test Loss:  0.0004987267311662436
Valid Loss:  0.000768084661103785
Epoch:  364  	Training Loss: 0.0007254146039485931
Test Loss:  0.000498090754263103
Valid Loss:  0.0007673415821045637
Epoch:  365  	Training Loss: 0.0007249094196595252
Test Loss:  0.0004974794574081898
Valid Loss:  0.0007666145102120936
Epoch:  366  	Training Loss: 0.0007244126172736287
Test Loss:  0.0004968828288838267
Valid Loss:  0.0007659044349566102
Epoch:  367  	Training Loss: 0.0007239271653816104
Test Loss:  0.0004962989478372037
Valid Loss:  0.0007652335916645825
Epoch:  368  	Training Loss: 0.0007234542863443494
Test Loss:  0.0004957212368026376
Valid Loss:  0.0007645951700396836
Epoch:  369  	Training Loss: 0.0007229868206195533
Test Loss:  0.0004951637238264084
Valid Loss:  0.0007639812538400292
Epoch:  370  	Training Loss: 0.0007225418230518699
Test Loss:  0.0004946237895637751
Valid Loss:  0.0007633750210516155
Epoch:  371  	Training Loss: 0.0007221080013550818
Test Loss:  0.0004940946819260716
Valid Loss:  0.0007627846207469702
Epoch:  372  	Training Loss: 0.0007216770900413394
Test Loss:  0.000493269762955606
Valid Loss:  0.0007620506221428514
Epoch:  373  	Training Loss: 0.0007210099138319492
Test Loss:  0.0004925327957607806
Valid Loss:  0.0007614028872922063
Epoch:  374  	Training Loss: 0.0007204344146884978
Test Loss:  0.0004918382619507611
Valid Loss:  0.0007607873994857073
Epoch:  375  	Training Loss: 0.0007199157262220979
Test Loss:  0.0004912123549729586
Valid Loss:  0.0007602027617394924
Epoch:  376  	Training Loss: 0.0007194416248239577
Test Loss:  0.0004906865069642663
Valid Loss:  0.0007596664945594966
Epoch:  377  	Training Loss: 0.0007190275937318802
Test Loss:  0.0004901838838122785
Valid Loss:  0.0007591337198391557
Epoch:  378  	Training Loss: 0.0007186206057667732
Test Loss:  0.0004897096659988165
Valid Loss:  0.0007586411666125059
Epoch:  379  	Training Loss: 0.0007182337576523423
Test Loss:  0.0004892616998404264
Valid Loss:  0.0007581794634461403
Epoch:  380  	Training Loss: 0.0007178641390055418
Test Loss:  0.0004888171097263694
Valid Loss:  0.0007577415672130883
Epoch:  381  	Training Loss: 0.0007175072096288204
Test Loss:  0.0004884192021563649
Valid Loss:  0.0007573293405584991
Epoch:  382  	Training Loss: 0.0007171800825744867
Test Loss:  0.0004875181766692549
Valid Loss:  0.0007565603591501713
Epoch:  383  	Training Loss: 0.0007159614469856024
Test Loss:  0.00048669902025721967
Valid Loss:  0.0007558671059086919
Epoch:  384  	Training Loss: 0.000714923779014498
Test Loss:  0.0004859658074565232
Valid Loss:  0.0007552048191428185
Epoch:  385  	Training Loss: 0.0007139990339055657
Test Loss:  0.00048526644241064787
Valid Loss:  0.0007546780398115516
Epoch:  386  	Training Loss: 0.0007131508318707347
Test Loss:  0.0004846467636525631
Valid Loss:  0.0007542242528870702
Epoch:  387  	Training Loss: 0.0007123433751985431
Test Loss:  0.0004841033660341054
Valid Loss:  0.0007537580095231533
Epoch:  388  	Training Loss: 0.0007116363267414272
Test Loss:  0.00048358453204855323
Valid Loss:  0.000753303524106741
Epoch:  389  	Training Loss: 0.000711003434844315
Test Loss:  0.0004831137484870851
Valid Loss:  0.0007529004360549152
Epoch:  390  	Training Loss: 0.0007104207761585712
Test Loss:  0.0004826866206713021
Valid Loss:  0.0007525114342570305
Epoch:  391  	Training Loss: 0.000709857908077538
Test Loss:  0.0004822984919883311
Valid Loss:  0.0007521331426687539
Epoch:  392  	Training Loss: 0.0007093292661011219
Test Loss:  0.0004817901935894042
Valid Loss:  0.0007517471676692367
Epoch:  393  	Training Loss: 0.000708715058863163
Test Loss:  0.0004812386177945882
Valid Loss:  0.0007513149175792933
Epoch:  394  	Training Loss: 0.0007081326330080628
Test Loss:  0.00048073739162646234
Valid Loss:  0.0007509191636927426
Epoch:  395  	Training Loss: 0.0007075578905642033
Test Loss:  0.0004801873292308301
Valid Loss:  0.0007504798122681677
Epoch:  396  	Training Loss: 0.0007070000865496695
Test Loss:  0.0004796864523086697
Valid Loss:  0.0007500826613977551
Epoch:  397  	Training Loss: 0.0007064559031277895
Test Loss:  0.0004791670653503388
Valid Loss:  0.0007496600737795234
Epoch:  398  	Training Loss: 0.0007059156778268516
Test Loss:  0.0004786318459082395
Valid Loss:  0.0007492309086956084
Epoch:  399  	Training Loss: 0.0007054033922031522
Test Loss:  0.0004781264578923583
Valid Loss:  0.000748812104575336
Epoch:  400  	Training Loss: 0.0007049377891235054
Test Loss:  0.0004776335845235735
Valid Loss:  0.0007484136149287224
Epoch:  401  	Training Loss: 0.000704476609826088
Test Loss:  0.00047713640378788114
Valid Loss:  0.0007480086060240865
Epoch:  402  	Training Loss: 0.0007040294585749507
Test Loss:  0.0004762641037814319
Valid Loss:  0.0007471865392290056
Epoch:  403  	Training Loss: 0.0007027622195892036
Test Loss:  0.0004754229448735714
Valid Loss:  0.0007462945068255067
Epoch:  404  	Training Loss: 0.0007016710005700588
Test Loss:  0.0004747365601360798
Valid Loss:  0.0007454694714397192
Epoch:  405  	Training Loss: 0.0007007360691204667
Test Loss:  0.00047404825454577804
Valid Loss:  0.0007446416420862079
Epoch:  406  	Training Loss: 0.0006998495664447546
Test Loss:  0.00047335572890006006
Valid Loss:  0.0007438207394443452
Epoch:  407  	Training Loss: 0.0006990062538534403
Test Loss:  0.0004727814521174878
Valid Loss:  0.0007430997211486101
Epoch:  408  	Training Loss: 0.0006982131162658334
Test Loss:  0.0004722017329186201
Valid Loss:  0.0007424117648042738
Epoch:  409  	Training Loss: 0.0006974409916438162
Test Loss:  0.00047163519775494933
Valid Loss:  0.00074176792986691
Epoch:  410  	Training Loss: 0.0006966824294067919
Test Loss:  0.00047112503671087325
Valid Loss:  0.0007411727565340698
Epoch:  411  	Training Loss: 0.0006959470920264721
Test Loss:  0.0004706031468231231
Valid Loss:  0.0007405613432638347
Epoch:  412  	Training Loss: 0.0006952228141017258
Test Loss:  0.000469321443233639
Valid Loss:  0.0007393575506284833
 83%|████████▎ | 413/500 [04:53<01:14,  1.16it/s] 83%|████████▎ | 415/500 [04:53<00:52,  1.61it/s] 83%|████████▎ | 417/500 [04:53<00:37,  2.20it/s] 84%|████████▍ | 419/500 [04:53<00:27,  2.96it/s] 84%|████████▍ | 421/500 [05:00<01:34,  1.19s/it] 85%|████████▍ | 423/500 [05:00<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:00<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:00<00:33,  2.20it/s] 86%|████████▌ | 429/500 [05:00<00:24,  2.96it/s] 86%|████████▌ | 431/500 [05:07<01:23,  1.21s/it] 87%|████████▋ | 433/500 [05:07<00:58,  1.15it/s] 87%|████████▋ | 435/500 [05:07<00:40,  1.60it/s] 87%|████████▋ | 437/500 [05:07<00:28,  2.18it/s] 88%|████████▊ | 439/500 [05:07<00:20,  2.92it/s] 88%|████████▊ | 441/500 [05:14<01:10,  1.19s/it] 89%|████████▊ | 443/500 [05:14<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:14<00:34,  1.61it/s] 89%|████████▉ | 447/500 [05:14<00:24,  2.20it/s] 90%|████████▉ | 449/500 [05:14<00:17,  2.96it/s] 90%|█████████ | 451/500 [05:21<00:59,  1.21s/it] 91%|█████████ | 453/500 [05:21<00:40,  1.15it/s] 91%|█████████ | 455/500 [05:21<00:28,  1.59it/s] 91%|█████████▏| 457/500 [05:21<00:19,  2.17it/s] 92%|█████████▏| 459/500 [05:21<00:14,  2.92it/s] 92%|█████████▏| 461/500 [05:28<00:46,  1.20s/it] 93%|█████████▎| 463/500 [05:28<00:31,  1.16it/s] 93%|█████████▎| 465/500 [05:28<00:21,  1.61it/s] 93%|█████████▎| 467/500 [05:28<00:15,  2.20it/s] 94%|█████████▍| 469/500 [05:28<00:10,  2.96it/s] 94%|█████████▍| 471/500 [05:35<00:34,  1.20s/it] 95%|█████████▍| 473/500 [05:35<00:23,  1.16it/s] 95%|█████████▌| 475/500 [05:35<00:15,  1.61it/s] 95%|█████████▌| 477/500 [05:35<00:10,  2.16it/s] 96%|█████████▌| 479/500 [05:35<00:07,  2.88it/s]Epoch:  413  	Training Loss: 0.0006941265892237425
Test Loss:  0.0004681717255152762
Valid Loss:  0.000738330592866987
Epoch:  414  	Training Loss: 0.0006930789677426219
Test Loss:  0.00046702875988557935
Valid Loss:  0.0007373131811618805
Epoch:  415  	Training Loss: 0.0006920635933056474
Test Loss:  0.00046600017230957747
Valid Loss:  0.0007364124758169055
Epoch:  416  	Training Loss: 0.0006910866359248757
Test Loss:  0.0004649591282941401
Valid Loss:  0.0007355102570727468
Epoch:  417  	Training Loss: 0.0006901196902617812
Test Loss:  0.0004639563267119229
Valid Loss:  0.0007346401689574122
Epoch:  418  	Training Loss: 0.0006891688099130988
Test Loss:  0.00046299913083203137
Valid Loss:  0.0007337987772189081
Epoch:  419  	Training Loss: 0.0006882372545078397
Test Loss:  0.00046209298307076097
Valid Loss:  0.0007329733343794942
Epoch:  420  	Training Loss: 0.00068732223007828
Test Loss:  0.00046130153350532055
Valid Loss:  0.0007322017336264253
Epoch:  421  	Training Loss: 0.0006864853203296661
Test Loss:  0.0004605258291121572
Valid Loss:  0.0007314452668651938
Epoch:  422  	Training Loss: 0.0006856563268229365
Test Loss:  0.0004605458816513419
Valid Loss:  0.0007315465481951833
Epoch:  423  	Training Loss: 0.0006852856604382396
Test Loss:  0.00046054221456870437
Valid Loss:  0.000731579726561904
Epoch:  424  	Training Loss: 0.0006849344354122877
Test Loss:  0.0004605077556334436
Valid Loss:  0.000731554813683033
Epoch:  425  	Training Loss: 0.0006846264004707336
Test Loss:  0.0004604628193192184
Valid Loss:  0.0007315502734854817
Epoch:  426  	Training Loss: 0.0006843276205472648
Test Loss:  0.0004603999841492623
Valid Loss:  0.0007315186085179448
Epoch:  427  	Training Loss: 0.0006840316345915198
Test Loss:  0.00046039410517551005
Valid Loss:  0.0007314634276553988
Epoch:  428  	Training Loss: 0.0006837427499704063
Test Loss:  0.0004603644192684442
Valid Loss:  0.0007313760579563677
Epoch:  429  	Training Loss: 0.0006834838422946632
Test Loss:  0.00046033901162445545
Valid Loss:  0.0007312740199267864
Epoch:  430  	Training Loss: 0.0006832322105765343
Test Loss:  0.00046031002420932055
Valid Loss:  0.0007311656954698265
Epoch:  431  	Training Loss: 0.0006829805206507444
Test Loss:  0.000460270355688408
Valid Loss:  0.0007310421788133681
Epoch:  432  	Training Loss: 0.0006827309844084084
Test Loss:  0.00045982340816408396
Valid Loss:  0.0007306787301786244
Epoch:  433  	Training Loss: 0.0006821881979703903
Test Loss:  0.0004594560887198895
Valid Loss:  0.0007303733727894723
Epoch:  434  	Training Loss: 0.0006816632230766118
Test Loss:  0.0004590668249875307
Valid Loss:  0.0007300031138584018
Epoch:  435  	Training Loss: 0.0006811722414568067
Test Loss:  0.00045868492452427745
Valid Loss:  0.0007296456024050713
Epoch:  436  	Training Loss: 0.0006806850433349609
Test Loss:  0.0004582835244946182
Valid Loss:  0.000729264342226088
Epoch:  437  	Training Loss: 0.0006801973795518279
Test Loss:  0.00045790040167048573
Valid Loss:  0.0007288851775228977
Epoch:  438  	Training Loss: 0.000679719727486372
Test Loss:  0.0004574962076731026
Valid Loss:  0.0007284856401383877
Epoch:  439  	Training Loss: 0.0006792476633563638
Test Loss:  0.00045707219396717846
Valid Loss:  0.000728062994312495
Epoch:  440  	Training Loss: 0.0006787771126255393
Test Loss:  0.00045667000813409686
Valid Loss:  0.0007276666001416743
Epoch:  441  	Training Loss: 0.0006783066783100367
Test Loss:  0.00045626668725162745
Valid Loss:  0.0007272707298398018
Epoch:  442  	Training Loss: 0.0006778351380489767
Test Loss:  0.0004558272776193917
Valid Loss:  0.0007269735215231776
Epoch:  443  	Training Loss: 0.0006772354245185852
Test Loss:  0.0004554237821139395
Valid Loss:  0.0007266862085089087
Epoch:  444  	Training Loss: 0.0006766659207642078
Test Loss:  0.000455045432318002
Valid Loss:  0.0007263552397489548
Epoch:  445  	Training Loss: 0.0006761655677109957
Test Loss:  0.0004546649579424411
Valid Loss:  0.0007259923149831593
Epoch:  446  	Training Loss: 0.0006757040973752737
Test Loss:  0.00045432517072185874
Valid Loss:  0.000725647434592247
Epoch:  447  	Training Loss: 0.0006752609042450786
Test Loss:  0.00045398110523819923
Valid Loss:  0.0007253166986629367
Epoch:  448  	Training Loss: 0.0006748238811269403
Test Loss:  0.0004536517371889204
Valid Loss:  0.0007249925401993096
Epoch:  449  	Training Loss: 0.0006743913982063532
Test Loss:  0.0004533234750851989
Valid Loss:  0.000724658602848649
Epoch:  450  	Training Loss: 0.0006739656673744321
Test Loss:  0.00045301587670110166
Valid Loss:  0.0007243338041007519
Epoch:  451  	Training Loss: 0.0006735496572218835
Test Loss:  0.000452692765975371
Valid Loss:  0.0007239817059598863
Epoch:  452  	Training Loss: 0.0006731440080329776
Test Loss:  0.0004514993051998317
Valid Loss:  0.0007226706366054714
Epoch:  453  	Training Loss: 0.0006721660029143095
Test Loss:  0.0004503901582211256
Valid Loss:  0.0007214751094579697
Epoch:  454  	Training Loss: 0.0006712699541822076
Test Loss:  0.0004493909946177155
Valid Loss:  0.0007204037392511964
Epoch:  455  	Training Loss: 0.0006704372353851795
Test Loss:  0.000448448583483696
Valid Loss:  0.0007194227073341608
Epoch:  456  	Training Loss: 0.0006696569034829736
Test Loss:  0.00044752066605724394
Valid Loss:  0.0007184660062193871
Epoch:  457  	Training Loss: 0.0006688914145343006
Test Loss:  0.00044672872172668576
Valid Loss:  0.000717567338142544
Epoch:  458  	Training Loss: 0.0006681635859422386
Test Loss:  0.0004460120399016887
Valid Loss:  0.0007167245494201779
Epoch:  459  	Training Loss: 0.0006675308686681092
Test Loss:  0.00044537190115079284
Valid Loss:  0.0007159610977396369
Epoch:  460  	Training Loss: 0.0006669549038633704
Test Loss:  0.00044477495248429477
Valid Loss:  0.0007152653415687382
Epoch:  461  	Training Loss: 0.0006664061220362782
Test Loss:  0.0004442007630132139
Valid Loss:  0.0007145949057303369
Epoch:  462  	Training Loss: 0.0006658679922111332
Test Loss:  0.00044426252134144306
Valid Loss:  0.0007146782008931041
Epoch:  463  	Training Loss: 0.0006654754979535937
Test Loss:  0.00044431252172216773
Valid Loss:  0.0007146369898691773
Epoch:  464  	Training Loss: 0.0006652072188444436
Test Loss:  0.00044436351163312793
Valid Loss:  0.0007145745912566781
Epoch:  465  	Training Loss: 0.0006649862043559551
Test Loss:  0.0004444039077498019
Valid Loss:  0.0007145005511119962
Epoch:  466  	Training Loss: 0.000664776423946023
Test Loss:  0.00044443760998547077
Valid Loss:  0.0007144083501771092
Epoch:  467  	Training Loss: 0.0006645778194069862
Test Loss:  0.00044446863466873765
Valid Loss:  0.0007143114344216883
Epoch:  468  	Training Loss: 0.0006643852684646845
Test Loss:  0.00044449116103351116
Valid Loss:  0.0007142096874304116
Epoch:  469  	Training Loss: 0.0006641955114901066
Test Loss:  0.00044453301234170794
Valid Loss:  0.0007140999077819288
Epoch:  470  	Training Loss: 0.0006640217616222799
Test Loss:  0.00044455198803916574
Valid Loss:  0.0007139575900509953
Epoch:  471  	Training Loss: 0.0006638604681938887
Test Loss:  0.0004445310914888978
Valid Loss:  0.0007137877983041108
Epoch:  472  	Training Loss: 0.0006637098267674446
Test Loss:  0.0004444840014912188
Valid Loss:  0.0007136728381738067
Epoch:  473  	Training Loss: 0.0006634126184508204
Test Loss:  0.0004444532096385956
Valid Loss:  0.0007135440246202052
Epoch:  474  	Training Loss: 0.0006631280994042754
Test Loss:  0.00044439506018534303
Valid Loss:  0.000713377317879349
Epoch:  475  	Training Loss: 0.0006628525443375111
Test Loss:  0.0004443500656634569
Valid Loss:  0.0007132015889510512
Epoch:  476  	Training Loss: 0.0006625938694924116
Test Loss:  0.00044429005356505513
Valid Loss:  0.0007129753939807415
Epoch:  477  	Training Loss: 0.0006623668596148491
Test Loss:  0.0004442348435986787
Valid Loss:  0.0007127526914700866
Epoch:  478  	Training Loss: 0.0006621450884267688
Test Loss:  0.0004441702621988952
Valid Loss:  0.0007125213160179555
Epoch:  479  	Training Loss: 0.000661921629216522
Test Loss:  0.0004441046039573848
Valid Loss:  0.0007122819079086185
Epoch:  480  	Training Loss: 0.0006617002654820681
Test Loss:  0.00044403629726730287
Valid Loss:  0.0007120255613699555
 96%|█████████▌| 481/500 [05:42<00:23,  1.22s/it] 97%|█████████▋| 483/500 [05:42<00:14,  1.14it/s] 97%|█████████▋| 485/500 [05:42<00:09,  1.57it/s] 97%|█████████▋| 487/500 [05:42<00:06,  2.15it/s] 98%|█████████▊| 489/500 [05:42<00:03,  2.89it/s] 98%|█████████▊| 491/500 [05:49<00:10,  1.20s/it] 99%|█████████▊| 493/500 [05:49<00:06,  1.16it/s] 99%|█████████▉| 495/500 [05:49<00:03,  1.60it/s] 99%|█████████▉| 497/500 [05:49<00:01,  2.17it/s]100%|█████████▉| 499/500 [05:49<00:00,  2.87it/s]100%|██████████| 500/500 [05:49<00:00,  1.43it/s]
Epoch:  481  	Training Loss: 0.0006614858284592628
Test Loss:  0.0004439483454916626
Valid Loss:  0.0007117592031136155
Epoch:  482  	Training Loss: 0.0006612747092731297
Test Loss:  0.0004433841095305979
Valid Loss:  0.0007110703736543655
Epoch:  483  	Training Loss: 0.0006607177201658487
Test Loss:  0.0004428692627698183
Valid Loss:  0.0007104139658622444
Epoch:  484  	Training Loss: 0.000660204328596592
Test Loss:  0.00044238040572963655
Valid Loss:  0.0007098366622813046
Epoch:  485  	Training Loss: 0.0006597272586077452
Test Loss:  0.00044194457586854696
Valid Loss:  0.000709299580194056
Epoch:  486  	Training Loss: 0.0006592756253667176
Test Loss:  0.0004415418952703476
Valid Loss:  0.0007087673293426633
Epoch:  487  	Training Loss: 0.0006588556570932269
Test Loss:  0.00044113126932643354
Valid Loss:  0.0007082499796524644
Epoch:  488  	Training Loss: 0.0006584606599062681
Test Loss:  0.0004407315282151103
Valid Loss:  0.000707753119058907
Epoch:  489  	Training Loss: 0.000658071250654757
Test Loss:  0.0004403455532155931
Valid Loss:  0.0007072704029269516
Epoch:  490  	Training Loss: 0.0006576888263225555
Test Loss:  0.00043996417662128806
Valid Loss:  0.0007067878032103181
Epoch:  491  	Training Loss: 0.0006573182763531804
Test Loss:  0.0004396142321638763
Valid Loss:  0.0007063207449391484
Epoch:  492  	Training Loss: 0.0006569616380147636
Test Loss:  0.00043940686737187207
Valid Loss:  0.0007062781951390207
Epoch:  493  	Training Loss: 0.0006562320049852133
Test Loss:  0.0004392205155454576
Valid Loss:  0.0007061647484079003
Epoch:  494  	Training Loss: 0.0006556219886988401
Test Loss:  0.0004390278772916645
Valid Loss:  0.0007060389034450054
Epoch:  495  	Training Loss: 0.0006550809484906495
Test Loss:  0.00043886119965463877
Valid Loss:  0.0007059257477521896
Epoch:  496  	Training Loss: 0.0006545616779476404
Test Loss:  0.00043868707143701613
Valid Loss:  0.0007057581096887589
Epoch:  497  	Training Loss: 0.0006540738395415246
Test Loss:  0.0004385004285722971
Valid Loss:  0.0007055518217384815
Epoch:  498  	Training Loss: 0.0006535997381433845
Test Loss:  0.00043828721391037107
Valid Loss:  0.0007052941946312785
Epoch:  499  	Training Loss: 0.0006531419348903
Test Loss:  0.0004380605823826045
Valid Loss:  0.000705012702383101
Epoch:  500  	Training Loss: 0.0006526930956169963
Test Loss:  0.00043783028377220035
Valid Loss:  0.0007047322578728199
seed is  15
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.12it/s]  1%|          | 4/500 [00:00<00:30, 16.10it/s]  1%|          | 6/500 [00:00<00:30, 16.05it/s]  2%|▏         | 8/500 [00:00<00:30, 16.11it/s]  2%|▏         | 10/500 [00:00<00:30, 16.23it/s]  2%|▏         | 12/500 [00:00<00:30, 16.25it/s]  3%|▎         | 14/500 [00:00<00:29, 16.27it/s]  3%|▎         | 16/500 [00:00<00:29, 16.27it/s]  4%|▎         | 18/500 [00:01<00:29, 16.18it/s]  4%|▍         | 20/500 [00:01<00:29, 16.19it/s]  4%|▍         | 22/500 [00:01<00:29, 16.15it/s]  5%|▍         | 24/500 [00:01<00:29, 16.01it/s]  5%|▌         | 26/500 [00:01<00:29, 16.09it/s]  6%|▌         | 28/500 [00:01<00:29, 16.25it/s]  6%|▌         | 30/500 [00:01<00:28, 16.22it/s]  6%|▋         | 32/500 [00:01<00:29, 15.92it/s]  7%|▋         | 34/500 [00:02<00:31, 14.62it/s]  7%|▋         | 36/500 [00:02<00:31, 14.66it/s]  8%|▊         | 38/500 [00:02<00:30, 15.12it/s]  8%|▊         | 40/500 [00:02<00:29, 15.54it/s]  8%|▊         | 42/500 [00:02<00:29, 15.77it/s]  9%|▉         | 44/500 [00:02<00:28, 15.94it/s]  9%|▉         | 46/500 [00:02<00:28, 16.05it/s] 10%|▉         | 48/500 [00:03<00:28, 15.96it/s] 10%|█         | 50/500 [00:03<00:28, 16.04it/s] 10%|█         | 52/500 [00:03<00:27, 16.13it/s] 11%|█         | 54/500 [00:03<00:27, 16.15it/s] 11%|█         | 56/500 [00:03<00:27, 16.17it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.22it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.31it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.32it/s] 13%|█▎        | 64/500 [00:04<00:26, 16.36it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.27it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.22it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.24it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.15it/s] 15%|█▍        | 74/500 [00:04<00:28, 14.89it/s] 15%|█▌        | 76/500 [00:04<00:30, 13.97it/s] 16%|█▌        | 78/500 [00:04<00:31, 13.51it/s] 16%|█▌        | 80/500 [00:05<00:29, 14.21it/s] 16%|█▋        | 82/500 [00:05<00:28, 14.74it/s] 17%|█▋        | 84/500 [00:05<00:27, 15.09it/s] 17%|█▋        | 86/500 [00:05<00:26, 15.36it/s] 18%|█▊        | 88/500 [00:05<00:26, 15.61it/s] 18%|█▊        | 90/500 [00:05<00:26, 15.74it/s] 18%|█▊        | 92/500 [00:05<00:25, 15.76it/s] 19%|█▉        | 94/500 [00:05<00:26, 15.55it/s] 19%|█▉        | 96/500 [00:06<00:25, 15.75it/s] 20%|█▉        | 98/500 [00:06<00:25, 15.70it/s] 20%|██        | 100/500 [00:06<00:25, 15.91it/s] 20%|██        | 102/500 [00:06<00:25, 15.65it/s] 21%|██        | 104/500 [00:06<00:24, 15.89it/s] 21%|██        | 106/500 [00:06<00:24, 15.97it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.13it/s] 22%|██▏       | 110/500 [00:06<00:24, 16.09it/s] 22%|██▏       | 112/500 [00:07<00:24, 16.09it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.22it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.26it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.38it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.43it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.27it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.29it/s]Epoch:  1  	Training Loss: 0.09167537093162537
Test Loss:  1438.2586669921875
Valid Loss:  1438.2596435546875
Epoch:  2  	Training Loss: 1437.943603515625
Test Loss:  14892736184320.0
Valid Loss:  14897938169856.0
Epoch:  3  	Training Loss: 14943464194048.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:23, 16.09it/s] 26%|██▌       | 128/500 [00:08<00:22, 16.19it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.26it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.30it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.34it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.27it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.17it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.15it/s] 28%|██▊       | 142/500 [00:08<00:22, 15.98it/s] 29%|██▉       | 144/500 [00:09<00:22, 16.08it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.18it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.25it/s] 30%|███       | 150/500 [00:09<00:21, 16.18it/s] 30%|███       | 152/500 [00:09<00:21, 15.86it/s] 31%|███       | 154/500 [00:09<00:21, 15.97it/s] 31%|███       | 156/500 [00:09<00:21, 15.85it/s] 32%|███▏      | 158/500 [00:09<00:21, 15.78it/s] 32%|███▏      | 160/500 [00:10<00:21, 15.93it/s] 32%|███▏      | 162/500 [00:10<00:21, 16.08it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.17it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.06it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.05it/s] 34%|███▍      | 170/500 [00:10<00:20, 15.96it/s] 34%|███▍      | 172/500 [00:10<00:20, 15.80it/s] 35%|███▍      | 174/500 [00:10<00:20, 15.91it/s] 35%|███▌      | 176/500 [00:11<00:20, 16.09it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.21it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.25it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.31it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.37it/s] 37%|███▋      | 186/500 [00:11<00:20, 15.57it/s] 38%|███▊      | 188/500 [00:11<00:19, 15.71it/s] 38%|███▊      | 190/500 [00:11<00:19, 15.81it/s] 38%|███▊      | 192/500 [00:12<00:19, 15.89it/s] 39%|███▉      | 194/500 [00:12<00:19, 16.00it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.91it/s] 40%|███▉      | 198/500 [00:12<00:18, 15.95it/s] 40%|████      | 200/500 [00:12<00:18, 16.07it/s] 40%|████      | 202/500 [00:12<00:18, 16.21it/s] 41%|████      | 204/500 [00:12<00:18, 16.30it/s] 41%|████      | 206/500 [00:12<00:18, 16.27it/s] 42%|████▏     | 208/500 [00:13<00:18, 16.17it/s] 42%|████▏     | 210/500 [00:13<00:18, 16.00it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.05it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.01it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.05it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.07it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.20it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.13it/s] 45%|████▍     | 224/500 [00:14<00:17, 16.20it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.26it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.32it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.34it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.32it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.24it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.09it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.21it/s] 48%|████▊     | 240/500 [00:15<00:16, 16.15it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.28it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.23it/s] 49%|████▉     | 246/500 [00:15<00:16, 15.01it/s] 50%|████▉     | 248/500 [00:15<00:16, 15.39it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 15.65it/s] 50%|█████     | 252/500 [00:15<00:16, 14.87it/s] 51%|█████     | 254/500 [00:15<00:16, 14.59it/s] 51%|█████     | 256/500 [00:16<00:16, 15.06it/s] 52%|█████▏    | 258/500 [00:16<00:15, 15.48it/s] 52%|█████▏    | 260/500 [00:16<00:15, 15.70it/s] 52%|█████▏    | 262/500 [00:16<00:16, 14.87it/s] 53%|█████▎    | 264/500 [00:16<00:16, 13.96it/s] 53%|█████▎    | 266/500 [00:16<00:17, 13.47it/s] 54%|█████▎    | 268/500 [00:16<00:16, 14.21it/s] 54%|█████▍    | 270/500 [00:17<00:15, 14.73it/s] 54%|█████▍    | 272/500 [00:17<00:15, 15.19it/s] 55%|█████▍    | 274/500 [00:17<00:14, 15.49it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.62it/s] 56%|█████▌    | 278/500 [00:17<00:14, 15.75it/s] 56%|█████▌    | 280/500 [00:17<00:14, 15.67it/s] 56%|█████▋    | 282/500 [00:17<00:13, 15.67it/s] 57%|█████▋    | 284/500 [00:17<00:13, 15.86it/s] 57%|█████▋    | 286/500 [00:18<00:13, 15.73it/s] 58%|█████▊    | 288/500 [00:18<00:14, 14.70it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.12it/s] 58%|█████▊    | 292/500 [00:18<00:13, 15.46it/s] 59%|█████▉    | 294/500 [00:18<00:13, 15.61it/s] 59%|█████▉    | 296/500 [00:18<00:12, 15.71it/s] 60%|█████▉    | 298/500 [00:18<00:12, 15.78it/s] 60%|██████    | 300/500 [00:18<00:12, 15.71it/s] 60%|██████    | 302/500 [00:19<00:12, 15.81it/s] 61%|██████    | 304/500 [00:19<00:12, 16.05it/s] 61%|██████    | 306/500 [00:19<00:12, 16.10it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.04it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.13it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.18it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.08it/s] 63%|██████▎   | 316/500 [00:19<00:11, 15.79it/s] 64%|██████▎   | 318/500 [00:20<00:11, 15.86it/s] 64%|██████▍   | 320/500 [00:20<00:11, 15.98it/s] 64%|██████▍   | 322/500 [00:20<00:11, 15.71it/s] 65%|██████▍   | 324/500 [00:20<00:11, 15.75it/s] 65%|██████▌   | 326/500 [00:20<00:11, 15.74it/s] 66%|██████▌   | 328/500 [00:20<00:10, 15.65it/s] 66%|██████▌   | 330/500 [00:20<00:10, 15.84it/s] 66%|██████▋   | 332/500 [00:21<00:10, 15.88it/s] 67%|██████▋   | 334/500 [00:21<00:10, 15.91it/s] 67%|██████▋   | 336/500 [00:21<00:10, 16.07it/s] 68%|██████▊   | 338/500 [00:21<00:10, 16.07it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.08it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.06it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.13it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.19it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.22it/s] 70%|███████   | 350/500 [00:22<00:09, 15.46it/s] 70%|███████   | 352/500 [00:22<00:09, 15.50it/s] 71%|███████   | 354/500 [00:22<00:10, 14.34it/s] 71%|███████   | 356/500 [00:22<00:10, 13.62it/s] 72%|███████▏  | 358/500 [00:22<00:10, 13.92it/s] 72%|███████▏  | 360/500 [00:22<00:09, 14.38it/s] 72%|███████▏  | 362/500 [00:23<00:10, 13.67it/s] 73%|███████▎  | 364/500 [00:23<00:09, 13.66it/s] 73%|███████▎  | 366/500 [00:23<00:10, 13.37it/s] 74%|███████▎  | 368/500 [00:23<00:09, 14.17it/s] 74%|███████▍  | 370/500 [00:23<00:08, 14.52it/s] 74%|███████▍  | 372/500 [00:23<00:09, 13.94it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:08, 14.51it/s] 75%|███████▌  | 376/500 [00:23<00:08, 14.91it/s] 76%|███████▌  | 378/500 [00:24<00:07, 15.35it/s] 76%|███████▌  | 380/500 [00:24<00:07, 15.50it/s] 76%|███████▋  | 382/500 [00:24<00:07, 15.77it/s] 77%|███████▋  | 384/500 [00:24<00:07, 15.90it/s] 77%|███████▋  | 386/500 [00:24<00:07, 15.69it/s] 78%|███████▊  | 388/500 [00:24<00:07, 14.64it/s] 78%|███████▊  | 390/500 [00:24<00:07, 15.00it/s] 78%|███████▊  | 392/500 [00:25<00:07, 15.29it/s] 79%|███████▉  | 394/500 [00:25<00:06, 15.26it/s] 79%|███████▉  | 396/500 [00:25<00:07, 14.15it/s] 80%|███████▉  | 398/500 [00:25<00:07, 13.47it/s] 80%|████████  | 400/500 [00:25<00:07, 14.17it/s] 80%|████████  | 402/500 [00:25<00:06, 14.79it/s] 81%|████████  | 404/500 [00:25<00:06, 15.18it/s] 81%|████████  | 406/500 [00:25<00:06, 15.37it/s] 82%|████████▏ | 408/500 [00:26<00:05, 15.55it/s] 82%|████████▏ | 410/500 [00:26<00:05, 15.78it/s] 82%|████████▏ | 412/500 [00:26<00:05, 15.91it/s] 83%|████████▎ | 414/500 [00:26<00:05, 16.06it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.14it/s] 84%|████████▎ | 418/500 [00:26<00:05, 16.13it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.14it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.22it/s] 85%|████████▍ | 424/500 [00:27<00:04, 16.18it/s] 85%|████████▌ | 426/500 [00:27<00:04, 16.18it/s] 86%|████████▌ | 428/500 [00:27<00:04, 16.18it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.23it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.30it/s] 87%|████████▋ | 434/500 [00:27<00:04, 16.25it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.22it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.14it/s] 88%|████████▊ | 440/500 [00:28<00:03, 15.15it/s] 88%|████████▊ | 442/500 [00:28<00:04, 14.14it/s] 89%|████████▉ | 444/500 [00:28<00:04, 13.52it/s] 89%|████████▉ | 446/500 [00:28<00:04, 13.24it/s] 90%|████████▉ | 448/500 [00:28<00:03, 13.85it/s] 90%|█████████ | 450/500 [00:28<00:03, 13.52it/s] 90%|█████████ | 452/500 [00:28<00:03, 14.25it/s] 91%|█████████ | 454/500 [00:29<00:03, 14.84it/s] 91%|█████████ | 456/500 [00:29<00:03, 14.36it/s] 92%|█████████▏| 458/500 [00:29<00:03, 13.55it/s] 92%|█████████▏| 460/500 [00:29<00:02, 13.79it/s] 92%|█████████▏| 462/500 [00:29<00:02, 14.45it/s] 93%|█████████▎| 464/500 [00:29<00:02, 14.84it/s] 93%|█████████▎| 466/500 [00:29<00:02, 14.60it/s] 94%|█████████▎| 468/500 [00:30<00:02, 15.12it/s] 94%|█████████▍| 470/500 [00:30<00:02, 14.48it/s] 94%|█████████▍| 472/500 [00:30<00:01, 14.56it/s] 95%|█████████▍| 474/500 [00:30<00:01, 14.36it/s] 95%|█████████▌| 476/500 [00:30<00:01, 14.80it/s] 96%|█████████▌| 478/500 [00:30<00:01, 15.10it/s] 96%|█████████▌| 480/500 [00:30<00:01, 15.43it/s] 96%|█████████▋| 482/500 [00:31<00:01, 14.95it/s] 97%|█████████▋| 484/500 [00:31<00:01, 15.20it/s] 97%|█████████▋| 486/500 [00:31<00:00, 15.52it/s] 98%|█████████▊| 488/500 [00:31<00:00, 15.08it/s] 98%|█████████▊| 490/500 [00:31<00:00, 15.20it/s] 98%|█████████▊| 492/500 [00:31<00:00, 14.97it/s] 99%|█████████▉| 494/500 [00:31<00:00, 15.20it/s] 99%|█████████▉| 496/500 [00:31<00:00, 15.39it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:32<00:00, 15.67it/s]100%|██████████| 500/500 [00:32<00:00, 15.84it/s]100%|██████████| 500/500 [00:32<00:00, 15.54it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  15
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:45,  6.34s/it]  1%|          | 3/500 [00:06<14:03,  1.70s/it]  1%|          | 5/500 [00:06<07:06,  1.16it/s]  1%|▏         | 7/500 [00:06<04:18,  1.90it/s]  2%|▏         | 9/500 [00:06<02:52,  2.84it/s]  2%|▏         | 11/500 [00:13<10:52,  1.33s/it]  3%|▎         | 13/500 [00:13<07:28,  1.09it/s]  3%|▎         | 15/500 [00:13<05:16,  1.53it/s]  3%|▎         | 17/500 [00:13<03:48,  2.12it/s]  4%|▍         | 19/500 [00:13<02:46,  2.89it/s]  4%|▍         | 21/500 [00:20<09:44,  1.22s/it]  5%|▍         | 23/500 [00:20<06:55,  1.15it/s]  5%|▌         | 25/500 [00:20<04:57,  1.59it/s]  5%|▌         | 27/500 [00:20<03:39,  2.15it/s]  6%|▌         | 29/500 [00:20<02:44,  2.86it/s]  6%|▌         | 31/500 [00:27<09:16,  1.19s/it]  7%|▋         | 33/500 [00:27<06:38,  1.17it/s]  7%|▋         | 35/500 [00:27<04:46,  1.62it/s]  7%|▋         | 37/500 [00:27<03:28,  2.22it/s]  8%|▊         | 39/500 [00:27<02:34,  2.98it/s]  8%|▊         | 41/500 [00:34<09:05,  1.19s/it]  9%|▊         | 43/500 [00:34<06:29,  1.17it/s]  9%|▉         | 45/500 [00:34<04:40,  1.62it/s]  9%|▉         | 47/500 [00:34<03:24,  2.21it/s] 10%|▉         | 49/500 [00:34<02:33,  2.94it/s] 10%|█         | 51/500 [00:41<09:07,  1.22s/it] 11%|█         | 53/500 [00:41<06:31,  1.14it/s] 11%|█         | 55/500 [00:41<04:41,  1.58it/s] 11%|█▏        | 57/500 [00:41<03:24,  2.16it/s] 12%|█▏        | 59/500 [00:41<02:31,  2.91it/s] 12%|█▏        | 61/500 [00:48<08:52,  1.21s/it] 13%|█▎        | 63/500 [00:48<06:20,  1.15it/s] 13%|█▎        | 65/500 [00:48<04:33,  1.59it/s] 13%|█▎        | 67/500 [00:48<03:19,  2.17it/s] 14%|█▍        | 69/500 [00:48<02:27,  2.92it/s] 14%|█▍        | 71/500 [00:55<08:34,  1.20s/it]Epoch:  1  	Training Loss: 0.09167537093162537
Test Loss:  279.706298828125
Valid Loss:  280.72979736328125
Epoch:  2  	Training Loss: 276.0710754394531
Test Loss:  2.8527982234954834
Valid Loss:  2.879490852355957
Epoch:  3  	Training Loss: 2.715510368347168
Test Loss:  2.0111677646636963
Valid Loss:  2.0321004390716553
Epoch:  4  	Training Loss: 1.8988573551177979
Test Loss:  1.5496068000793457
Valid Loss:  1.5669969320297241
Epoch:  5  	Training Loss: 1.4536908864974976
Test Loss:  1.2129700183868408
Valid Loss:  1.227447271347046
Epoch:  6  	Training Loss: 1.1314265727996826
Test Loss:  0.9509010910987854
Valid Loss:  0.9629545211791992
Epoch:  7  	Training Loss: 0.8815087080001831
Test Loss:  0.7468088865280151
Valid Loss:  0.756840169429779
Epoch:  8  	Training Loss: 0.6877123713493347
Test Loss:  0.5877941250801086
Valid Loss:  0.596133828163147
Epoch:  9  	Training Loss: 0.5374398231506348
Test Loss:  0.4638301432132721
Valid Loss:  0.47075140476226807
Epoch:  10  	Training Loss: 0.420913428068161
Test Loss:  0.36712461709976196
Valid Loss:  0.3728538155555725
Epoch:  11  	Training Loss: 0.3305470645427704
Test Loss:  0.2916218042373657
Valid Loss:  0.29634732007980347
Epoch:  12  	Training Loss: 0.26045656204223633
Test Loss:  0.23797322809696198
Valid Loss:  0.24193187057971954
Epoch:  13  	Training Loss: 0.21094122529029846
Test Loss:  0.19498394429683685
Valid Loss:  0.19828225672245026
Epoch:  14  	Training Loss: 0.1715579330921173
Test Loss:  0.160497784614563
Valid Loss:  0.1632269024848938
Epoch:  15  	Training Loss: 0.14022043347358704
Test Loss:  0.1327979415655136
Valid Loss:  0.13503608107566833
Epoch:  16  	Training Loss: 0.11527206003665924
Test Loss:  0.11051718890666962
Valid Loss:  0.11233151704072952
Epoch:  17  	Training Loss: 0.09539739787578583
Test Loss:  0.09256643056869507
Valid Loss:  0.09401483833789825
Epoch:  18  	Training Loss: 0.07955200970172882
Test Loss:  0.07807782292366028
Valid Loss:  0.07921023666858673
Epoch:  19  	Training Loss: 0.06690669059753418
Test Loss:  0.06635956466197968
Valid Loss:  0.06721915304660797
Epoch:  20  	Training Loss: 0.05680309981107712
Test Loss:  0.05686043202877045
Valid Loss:  0.05748521536588669
Epoch:  21  	Training Loss: 0.0487198643386364
Test Loss:  0.04914059489965439
Valid Loss:  0.0495639443397522
Epoch:  22  	Training Loss: 0.042241379618644714
Test Loss:  0.04280707612633705
Valid Loss:  0.04305586963891983
Epoch:  23  	Training Loss: 0.0370037816464901
Test Loss:  0.03763585165143013
Valid Loss:  0.037734709680080414
Epoch:  24  	Training Loss: 0.03279300034046173
Test Loss:  0.033398017287254333
Valid Loss:  0.03336838632822037
Epoch:  25  	Training Loss: 0.029397178441286087
Test Loss:  0.029911383986473083
Valid Loss:  0.02977149188518524
Epoch:  26  	Training Loss: 0.026648245751857758
Test Loss:  0.02703382819890976
Valid Loss:  0.026852592825889587
Epoch:  27  	Training Loss: 0.0244615375995636
Test Loss:  0.024973446503281593
Valid Loss:  0.024881094694137573
Epoch:  28  	Training Loss: 0.022964470088481903
Test Loss:  0.02390173263847828
Valid Loss:  0.023577304556965828
Epoch:  29  	Training Loss: 0.02204916626214981
Test Loss:  0.023299893364310265
Valid Loss:  0.022776948288083076
Epoch:  30  	Training Loss: 0.02148008905351162
Test Loss:  0.022982649505138397
Valid Loss:  0.022304289042949677
Epoch:  31  	Training Loss: 0.021099451929330826
Test Loss:  0.022764060646295547
Valid Loss:  0.022021863609552383
Epoch:  32  	Training Loss: 0.02084583230316639
Test Loss:  0.02261720784008503
Valid Loss:  0.021860111504793167
Epoch:  33  	Training Loss: 0.02069815993309021
Test Loss:  0.022504840046167374
Valid Loss:  0.021740037947893143
Epoch:  34  	Training Loss: 0.02059214934706688
Test Loss:  0.0224178247153759
Valid Loss:  0.02164531871676445
Epoch:  35  	Training Loss: 0.020506273955106735
Test Loss:  0.022342950105667114
Valid Loss:  0.02157118171453476
Epoch:  36  	Training Loss: 0.020432855933904648
Test Loss:  0.022269973531365395
Valid Loss:  0.0215041134506464
Epoch:  37  	Training Loss: 0.02036120370030403
Test Loss:  0.02220570296049118
Valid Loss:  0.021441537886857986
Epoch:  38  	Training Loss: 0.020293204113841057
Test Loss:  0.022150497883558273
Valid Loss:  0.021380342543125153
Epoch:  39  	Training Loss: 0.02022739127278328
Test Loss:  0.022100163623690605
Valid Loss:  0.02132575586438179
Epoch:  40  	Training Loss: 0.02016938477754593
Test Loss:  0.022056125104427338
Valid Loss:  0.02127995900809765
Epoch:  41  	Training Loss: 0.020115496590733528
Test Loss:  0.022014224901795387
Valid Loss:  0.021238630637526512
Epoch:  42  	Training Loss: 0.02006353810429573
Test Loss:  0.02197727933526039
Valid Loss:  0.021206974983215332
Epoch:  43  	Training Loss: 0.020013056695461273
Test Loss:  0.021940354257822037
Valid Loss:  0.021175287663936615
Epoch:  44  	Training Loss: 0.019963793456554413
Test Loss:  0.02190711349248886
Valid Loss:  0.021147292107343674
Epoch:  45  	Training Loss: 0.01991572603583336
Test Loss:  0.021873757243156433
Valid Loss:  0.021120307967066765
Epoch:  46  	Training Loss: 0.019868135452270508
Test Loss:  0.02184028923511505
Valid Loss:  0.021093349903821945
Epoch:  47  	Training Loss: 0.019821032881736755
Test Loss:  0.02180679515004158
Valid Loss:  0.021066412329673767
Epoch:  48  	Training Loss: 0.01977461762726307
Test Loss:  0.02177514135837555
Valid Loss:  0.021041033789515495
Epoch:  49  	Training Loss: 0.019729133695364
Test Loss:  0.02174338698387146
Valid Loss:  0.021015645936131477
Epoch:  50  	Training Loss: 0.019684094935655594
Test Loss:  0.02171158790588379
Valid Loss:  0.02099018543958664
Epoch:  51  	Training Loss: 0.019639531150460243
Test Loss:  0.0216798298060894
Valid Loss:  0.020964613184332848
Epoch:  52  	Training Loss: 0.019595373421907425
Test Loss:  0.021650541573762894
Valid Loss:  0.020940197631716728
Epoch:  53  	Training Loss: 0.019551649689674377
Test Loss:  0.021621204912662506
Valid Loss:  0.020915750414133072
Epoch:  54  	Training Loss: 0.019508343189954758
Test Loss:  0.02159188874065876
Valid Loss:  0.020891249179840088
Epoch:  55  	Training Loss: 0.01946544274687767
Test Loss:  0.021562574431300163
Valid Loss:  0.020867157727479935
Epoch:  56  	Training Loss: 0.01942294090986252
Test Loss:  0.021533194929361343
Valid Loss:  0.020843882113695145
Epoch:  57  	Training Loss: 0.019380807876586914
Test Loss:  0.02150377631187439
Valid Loss:  0.020820599049329758
Epoch:  58  	Training Loss: 0.01933904178440571
Test Loss:  0.021474331617355347
Valid Loss:  0.02079731412231922
Epoch:  59  	Training Loss: 0.019297655671834946
Test Loss:  0.02144484594464302
Valid Loss:  0.020774010568857193
Epoch:  60  	Training Loss: 0.01925656758248806
Test Loss:  0.02141626551747322
Valid Loss:  0.02075066789984703
Epoch:  61  	Training Loss: 0.019215751439332962
Test Loss:  0.021388383582234383
Valid Loss:  0.020727306604385376
Epoch:  62  	Training Loss: 0.019175546243786812
Test Loss:  0.02136358432471752
Valid Loss:  0.020707065239548683
Epoch:  63  	Training Loss: 0.019136788323521614
Test Loss:  0.02134001813828945
Valid Loss:  0.020688124001026154
Epoch:  64  	Training Loss: 0.019098784774541855
Test Loss:  0.021317657083272934
Valid Loss:  0.020670432597398758
Epoch:  65  	Training Loss: 0.019061461091041565
Test Loss:  0.021295199170708656
Valid Loss:  0.02065257355570793
Epoch:  66  	Training Loss: 0.019024668261408806
Test Loss:  0.02127261459827423
Valid Loss:  0.020634757354855537
Epoch:  67  	Training Loss: 0.018988344818353653
Test Loss:  0.02124992199242115
Valid Loss:  0.020617226138710976
Epoch:  68  	Training Loss: 0.01895246095955372
Test Loss:  0.021227123215794563
Valid Loss:  0.020599640905857086
Epoch:  69  	Training Loss: 0.018917005509138107
Test Loss:  0.021204214543104172
Valid Loss:  0.020581983029842377
Epoch:  70  	Training Loss: 0.01888207532465458
Test Loss:  0.021182630211114883
Valid Loss:  0.020565364509820938
Epoch:  71  	Training Loss: 0.018847767263650894
Test Loss:  0.02116091176867485
Valid Loss:  0.020548664033412933
Epoch:  72  	Training Loss: 0.018814006820321083
Test Loss:  0.02114059217274189
Valid Loss:  0.02053302712738514
 15%|█▍        | 73/500 [00:55<06:07,  1.16it/s] 15%|█▌        | 75/500 [00:55<04:26,  1.59it/s] 15%|█▌        | 77/500 [00:55<03:17,  2.15it/s] 16%|█▌        | 79/500 [00:55<02:25,  2.89it/s] 16%|█▌        | 81/500 [01:02<08:23,  1.20s/it] 17%|█▋        | 83/500 [01:02<05:59,  1.16it/s] 17%|█▋        | 85/500 [01:02<04:18,  1.60it/s] 17%|█▋        | 87/500 [01:02<03:08,  2.19it/s] 18%|█▊        | 89/500 [01:02<02:20,  2.92it/s] 18%|█▊        | 91/500 [01:09<08:13,  1.21s/it] 19%|█▊        | 93/500 [01:09<05:54,  1.15it/s] 19%|█▉        | 95/500 [01:09<04:16,  1.58it/s] 19%|█▉        | 97/500 [01:09<03:06,  2.16it/s] 20%|█▉        | 99/500 [01:09<02:18,  2.90it/s] 20%|██        | 101/500 [01:16<07:59,  1.20s/it] 21%|██        | 103/500 [01:16<05:42,  1.16it/s] 21%|██        | 105/500 [01:16<04:06,  1.60it/s] 21%|██▏       | 107/500 [01:16<02:59,  2.19it/s] 22%|██▏       | 109/500 [01:16<02:12,  2.95it/s] 22%|██▏       | 111/500 [01:23<07:44,  1.19s/it] 23%|██▎       | 113/500 [01:23<05:31,  1.17it/s] 23%|██▎       | 115/500 [01:23<03:58,  1.61it/s] 23%|██▎       | 117/500 [01:23<02:53,  2.21it/s] 24%|██▍       | 119/500 [01:23<02:08,  2.97it/s] 24%|██▍       | 121/500 [01:30<07:36,  1.20s/it] 25%|██▍       | 123/500 [01:30<05:26,  1.15it/s] 25%|██▌       | 125/500 [01:30<03:57,  1.58it/s] 25%|██▌       | 127/500 [01:30<02:55,  2.13it/s] 26%|██▌       | 129/500 [01:30<02:11,  2.82it/s] 26%|██▌       | 131/500 [01:37<07:35,  1.23s/it] 27%|██▋       | 133/500 [01:37<05:25,  1.13it/s] 27%|██▋       | 135/500 [01:37<03:53,  1.56it/s] 27%|██▋       | 137/500 [01:37<02:50,  2.13it/s] 28%|██▊       | 139/500 [01:37<02:05,  2.88it/s] 28%|██▊       | 141/500 [01:44<07:18,  1.22s/it]Epoch:  73  	Training Loss: 0.018780993297696114
Test Loss:  0.02112012542784214
Valid Loss:  0.020517297089099884
Epoch:  74  	Training Loss: 0.01874842867255211
Test Loss:  0.0210995115339756
Valid Loss:  0.020501479506492615
Epoch:  75  	Training Loss: 0.01871628500521183
Test Loss:  0.02107875421643257
Valid Loss:  0.020485633984208107
Epoch:  76  	Training Loss: 0.01868455857038498
Test Loss:  0.021059362217783928
Valid Loss:  0.020470868796110153
Epoch:  77  	Training Loss: 0.01865348219871521
Test Loss:  0.02103978767991066
Valid Loss:  0.02045597694814205
Epoch:  78  	Training Loss: 0.018622804433107376
Test Loss:  0.02102005109190941
Valid Loss:  0.020440969616174698
Epoch:  79  	Training Loss: 0.018592489883303642
Test Loss:  0.021000143140554428
Valid Loss:  0.02042582631111145
Epoch:  80  	Training Loss: 0.018562491983175278
Test Loss:  0.02098008431494236
Valid Loss:  0.020410623401403427
Epoch:  81  	Training Loss: 0.0185328871011734
Test Loss:  0.020961418747901917
Valid Loss:  0.020396992564201355
Epoch:  82  	Training Loss: 0.01850380003452301
Test Loss:  0.02094269171357155
Valid Loss:  0.020383469760417938
Epoch:  83  	Training Loss: 0.01847517490386963
Test Loss:  0.020923789590597153
Valid Loss:  0.020369889214634895
Epoch:  84  	Training Loss: 0.018446864560246468
Test Loss:  0.020904727280139923
Valid Loss:  0.020356252789497375
Epoch:  85  	Training Loss: 0.018418842926621437
Test Loss:  0.020885510370135307
Valid Loss:  0.020342573523521423
Epoch:  86  	Training Loss: 0.018391180783510208
Test Loss:  0.020867738872766495
Valid Loss:  0.020329803228378296
Epoch:  87  	Training Loss: 0.018364042043685913
Test Loss:  0.020849764347076416
Valid Loss:  0.020316947251558304
Epoch:  88  	Training Loss: 0.018337180837988853
Test Loss:  0.02083158679306507
Valid Loss:  0.02030400186777115
Epoch:  89  	Training Loss: 0.01831057295203209
Test Loss:  0.0208132266998291
Valid Loss:  0.020290972664952278
Epoch:  90  	Training Loss: 0.018284281715750694
Test Loss:  0.02079682983458042
Valid Loss:  0.020278895273804665
Epoch:  91  	Training Loss: 0.018258515745401382
Test Loss:  0.020780347287654877
Valid Loss:  0.020266732200980186
Epoch:  92  	Training Loss: 0.0182331632822752
Test Loss:  0.020765051245689392
Valid Loss:  0.02025545760989189
Epoch:  93  	Training Loss: 0.018208198249340057
Test Loss:  0.020749598741531372
Valid Loss:  0.020244063809514046
Epoch:  94  	Training Loss: 0.018183568492531776
Test Loss:  0.02073533833026886
Valid Loss:  0.020233603194355965
Epoch:  95  	Training Loss: 0.018159344792366028
Test Loss:  0.020720887929201126
Valid Loss:  0.02022300288081169
Epoch:  96  	Training Loss: 0.018135447055101395
Test Loss:  0.02070622891187668
Valid Loss:  0.020212285220623016
Epoch:  97  	Training Loss: 0.018111836165189743
Test Loss:  0.020691387355327606
Valid Loss:  0.020201444625854492
Epoch:  98  	Training Loss: 0.018088512122631073
Test Loss:  0.02067640982568264
Valid Loss:  0.02019050531089306
Epoch:  99  	Training Loss: 0.01806548982858658
Test Loss:  0.02066124975681305
Valid Loss:  0.020179428160190582
Epoch:  100  	Training Loss: 0.018042683601379395
Test Loss:  0.020645931363105774
Valid Loss:  0.020168229937553406
Epoch:  101  	Training Loss: 0.018020149320364
Test Loss:  0.020631913095712662
Valid Loss:  0.02015804871916771
Epoch:  102  	Training Loss: 0.01799801178276539
Test Loss:  0.020617716014385223
Valid Loss:  0.020147714763879776
Epoch:  103  	Training Loss: 0.017976131290197372
Test Loss:  0.020603327080607414
Valid Loss:  0.02013726904988289
Epoch:  104  	Training Loss: 0.017954472452402115
Test Loss:  0.02058875374495983
Valid Loss:  0.020126689225435257
Epoch:  105  	Training Loss: 0.01793300174176693
Test Loss:  0.020574022084474564
Valid Loss:  0.020116066560149193
Epoch:  106  	Training Loss: 0.017911721020936966
Test Loss:  0.020559124648571014
Valid Loss:  0.020105896517634392
Epoch:  107  	Training Loss: 0.017890607938170433
Test Loss:  0.020544078201055527
Valid Loss:  0.02009565383195877
Epoch:  108  	Training Loss: 0.017869651317596436
Test Loss:  0.02052888832986355
Valid Loss:  0.02008534036576748
Epoch:  109  	Training Loss: 0.017848843708634377
Test Loss:  0.020513584837317467
Valid Loss:  0.020074982196092606
Epoch:  110  	Training Loss: 0.017828190699219704
Test Loss:  0.020498162135481834
Valid Loss:  0.020064562559127808
Epoch:  111  	Training Loss: 0.017807668074965477
Test Loss:  0.0204826258122921
Valid Loss:  0.020054088905453682
Epoch:  112  	Training Loss: 0.01778736338019371
Test Loss:  0.020468471571803093
Valid Loss:  0.020044507458806038
Epoch:  113  	Training Loss: 0.017767425626516342
Test Loss:  0.020454196259379387
Valid Loss:  0.020034845918416977
Epoch:  114  	Training Loss: 0.017747636884450912
Test Loss:  0.020439796149730682
Valid Loss:  0.0200251005589962
Epoch:  115  	Training Loss: 0.017727984115481377
Test Loss:  0.02042527124285698
Valid Loss:  0.020015288144350052
Epoch:  116  	Training Loss: 0.01770845800638199
Test Loss:  0.020410630851984024
Valid Loss:  0.02000541239976883
Epoch:  117  	Training Loss: 0.0176890566945076
Test Loss:  0.020395860075950623
Valid Loss:  0.019995465874671936
Epoch:  118  	Training Loss: 0.01766977459192276
Test Loss:  0.020380984991788864
Valid Loss:  0.019985470920801163
Epoch:  119  	Training Loss: 0.01765061542391777
Test Loss:  0.020366022363305092
Valid Loss:  0.019975431263446808
Epoch:  120  	Training Loss: 0.017631571739912033
Test Loss:  0.020350966602563858
Valid Loss:  0.019965339452028275
Epoch:  121  	Training Loss: 0.01761271432042122
Test Loss:  0.020337391644716263
Valid Loss:  0.019956186413764954
Epoch:  122  	Training Loss: 0.017594344913959503
Test Loss:  0.020324895158410072
Valid Loss:  0.01994769088923931
Epoch:  123  	Training Loss: 0.017576005309820175
Test Loss:  0.020312197506427765
Valid Loss:  0.019939079880714417
Epoch:  124  	Training Loss: 0.01755782589316368
Test Loss:  0.020299308001995087
Valid Loss:  0.019930364564061165
Epoch:  125  	Training Loss: 0.017539795488119125
Test Loss:  0.020286228507757187
Valid Loss:  0.019921543076634407
Epoch:  126  	Training Loss: 0.017521897330880165
Test Loss:  0.020272990688681602
Valid Loss:  0.019912630319595337
Epoch:  127  	Training Loss: 0.01750417798757553
Test Loss:  0.02026119828224182
Valid Loss:  0.019904645159840584
Epoch:  128  	Training Loss: 0.017486821860074997
Test Loss:  0.020249195396900177
Valid Loss:  0.01989654265344143
Epoch:  129  	Training Loss: 0.017469622194767
Test Loss:  0.020236976444721222
Valid Loss:  0.019888320937752724
Epoch:  130  	Training Loss: 0.017452571541070938
Test Loss:  0.020224586129188538
Valid Loss:  0.019880032166838646
Epoch:  131  	Training Loss: 0.017435666173696518
Test Loss:  0.02021200582385063
Valid Loss:  0.019871653988957405
Epoch:  132  	Training Loss: 0.01741888001561165
Test Loss:  0.02019907906651497
Valid Loss:  0.019863057881593704
Epoch:  133  	Training Loss: 0.017402011901140213
Test Loss:  0.02018599584698677
Valid Loss:  0.01985437050461769
Epoch:  134  	Training Loss: 0.017385262995958328
Test Loss:  0.020172778517007828
Valid Loss:  0.01984560303390026
Epoch:  135  	Training Loss: 0.01736864075064659
Test Loss:  0.02015942707657814
Valid Loss:  0.019836757332086563
Epoch:  136  	Training Loss: 0.017352117225527763
Test Loss:  0.020145943388342857
Valid Loss:  0.019827835261821747
Epoch:  137  	Training Loss: 0.01733567751944065
Test Loss:  0.020132340490818024
Valid Loss:  0.019818859174847603
Epoch:  138  	Training Loss: 0.0173193272203207
Test Loss:  0.02011863887310028
Valid Loss:  0.019809827208518982
Epoch:  139  	Training Loss: 0.017303060740232468
Test Loss:  0.02010483108460903
Valid Loss:  0.01980072632431984
Epoch:  140  	Training Loss: 0.017286870628595352
Test Loss:  0.020090939477086067
Valid Loss:  0.01979157328605652
Epoch:  141  	Training Loss: 0.0172707661986351
Test Loss:  0.020076967775821686
Valid Loss:  0.01978236809372902
Epoch:  142  	Training Loss: 0.01725473627448082
Test Loss:  0.020062673836946487
Valid Loss:  0.019772952422499657
Epoch:  143  	Training Loss: 0.017238622531294823
Test Loss:  0.020048320293426514
Valid Loss:   29%|██▊       | 143/500 [01:44<05:13,  1.14it/s] 29%|██▉       | 145/500 [01:44<03:45,  1.58it/s] 29%|██▉       | 147/500 [01:44<02:43,  2.16it/s] 30%|██▉       | 149/500 [01:44<02:01,  2.90it/s] 30%|███       | 151/500 [01:51<06:54,  1.19s/it] 30%|███       | 152/500 [01:51<05:46,  1.00it/s] 31%|███       | 154/500 [01:51<03:59,  1.44it/s] 31%|███       | 156/500 [01:51<02:50,  2.01it/s] 32%|███▏      | 158/500 [01:51<02:03,  2.76it/s] 32%|███▏      | 160/500 [01:51<01:32,  3.68it/s] 32%|███▏      | 162/500 [01:58<06:46,  1.20s/it] 33%|███▎      | 164/500 [01:58<04:47,  1.17it/s] 33%|███▎      | 166/500 [01:58<03:26,  1.62it/s] 34%|███▎      | 168/500 [01:58<02:29,  2.22it/s] 34%|███▍      | 170/500 [01:59<01:50,  2.99it/s] 34%|███▍      | 172/500 [02:05<06:34,  1.20s/it] 35%|███▍      | 174/500 [02:05<04:40,  1.16it/s] 35%|███▌      | 176/500 [02:05<03:21,  1.61it/s] 36%|███▌      | 178/500 [02:05<02:27,  2.18it/s] 36%|███▌      | 180/500 [02:06<01:50,  2.90it/s] 36%|███▋      | 182/500 [02:12<06:29,  1.23s/it] 37%|███▋      | 184/500 [02:12<04:37,  1.14it/s] 37%|███▋      | 186/500 [02:12<03:20,  1.57it/s] 38%|███▊      | 188/500 [02:13<02:26,  2.12it/s] 38%|███▊      | 190/500 [02:13<01:48,  2.86it/s] 38%|███▊      | 192/500 [02:19<06:15,  1.22s/it] 39%|███▉      | 194/500 [02:19<04:28,  1.14it/s] 39%|███▉      | 196/500 [02:20<03:13,  1.57it/s] 40%|███▉      | 198/500 [02:20<02:21,  2.14it/s] 40%|████      | 200/500 [02:20<01:45,  2.84it/s] 40%|████      | 202/500 [02:26<06:01,  1.21s/it] 41%|████      | 204/500 [02:26<04:17,  1.15it/s] 41%|████      | 206/500 [02:27<03:05,  1.58it/s] 42%|████▏     | 208/500 [02:27<02:16,  2.15it/s] 42%|████▏     | 210/500 [02:27<01:40,  2.89it/s] 42%|████▏     | 212/500 [02:33<05:43,  1.19s/it]0.019763506948947906
Epoch:  144  	Training Loss: 0.017222583293914795
Test Loss:  0.020033912733197212
Valid Loss:  0.019754018634557724
Epoch:  145  	Training Loss: 0.017206698656082153
Test Loss:  0.020021095871925354
Valid Loss:  0.019745580852031708
Epoch:  146  	Training Loss: 0.017191197723150253
Test Loss:  0.020008191466331482
Valid Loss:  0.019737057387828827
Epoch:  147  	Training Loss: 0.017175773158669472
Test Loss:  0.019995901733636856
Valid Loss:  0.019728468731045723
Epoch:  148  	Training Loss: 0.01716054603457451
Test Loss:  0.019984900951385498
Valid Loss:  0.019720885902643204
Epoch:  149  	Training Loss: 0.017145594581961632
Test Loss:  0.019973769783973694
Valid Loss:  0.019713198766112328
Epoch:  150  	Training Loss: 0.017130747437477112
Test Loss:  0.019962508231401443
Valid Loss:  0.0197053961455822
Epoch:  151  	Training Loss: 0.017115991562604904
Test Loss:  0.019951127469539642
Valid Loss:  0.01969752460718155
Epoch:  152  	Training Loss: 0.01710132509469986
Test Loss:  0.019939571619033813
Valid Loss:  0.019689546898007393
Epoch:  153  	Training Loss: 0.01708662137389183
Test Loss:  0.01992790773510933
Valid Loss:  0.019681479781866074
Epoch:  154  	Training Loss: 0.017071999609470367
Test Loss:  0.019916150718927383
Valid Loss:  0.01967332884669304
Epoch:  155  	Training Loss: 0.017057452350854874
Test Loss:  0.019904300570487976
Valid Loss:  0.019665103405714035
Epoch:  156  	Training Loss: 0.01704297587275505
Test Loss:  0.0198923721909523
Valid Loss:  0.01965680718421936
Epoch:  157  	Training Loss: 0.017028572037816048
Test Loss:  0.01988035999238491
Valid Loss:  0.019648443907499313
Epoch:  158  	Training Loss: 0.01701422967016697
Test Loss:  0.019868284463882446
Valid Loss:  0.019640017300844193
Epoch:  159  	Training Loss: 0.016999948769807816
Test Loss:  0.01985616609454155
Valid Loss:  0.019631536677479744
Epoch:  160  	Training Loss: 0.016985731199383736
Test Loss:  0.019843995571136475
Valid Loss:  0.019623002037405968
Epoch:  161  	Training Loss: 0.01697157323360443
Test Loss:  0.019831780344247818
Valid Loss:  0.019614435732364655
Epoch:  162  	Training Loss: 0.016957493498921394
Test Loss:  0.01981925591826439
Valid Loss:  0.019605595618486404
Epoch:  163  	Training Loss: 0.016943320631980896
Test Loss:  0.01980670355260372
Valid Loss:  0.019596725702285767
Epoch:  164  	Training Loss: 0.01692921109497547
Test Loss:  0.01979445107281208
Valid Loss:  0.019587848335504532
Epoch:  165  	Training Loss: 0.016915198415517807
Test Loss:  0.01978386379778385
Valid Loss:  0.019580058753490448
Epoch:  166  	Training Loss: 0.01690169796347618
Test Loss:  0.01977553218603134
Valid Loss:  0.01957441121339798
Epoch:  167  	Training Loss: 0.016888579353690147
Test Loss:  0.019767113029956818
Valid Loss:  0.01956859976053238
Epoch:  168  	Training Loss: 0.016875598579645157
Test Loss:  0.019758762791752815
Valid Loss:  0.01956263557076454
Epoch:  169  	Training Loss: 0.016862809658050537
Test Loss:  0.019751248881220818
Valid Loss:  0.019557643681764603
Epoch:  170  	Training Loss: 0.016850173473358154
Test Loss:  0.01974361203610897
Valid Loss:  0.01955246552824974
Epoch:  171  	Training Loss: 0.01683768257498741
Test Loss:  0.01973586156964302
Valid Loss:  0.019547108560800552
Epoch:  172  	Training Loss: 0.01682533323764801
Test Loss:  0.01972801983356476
Valid Loss:  0.019541654735803604
Epoch:  173  	Training Loss: 0.01681298390030861
Test Loss:  0.01972007006406784
Valid Loss:  0.019536025822162628
Epoch:  174  	Training Loss: 0.01680075190961361
Test Loss:  0.01971200481057167
Valid Loss:  0.01953023672103882
Epoch:  175  	Training Loss: 0.016788626089692116
Test Loss:  0.019703838974237442
Valid Loss:  0.019524304196238518
Epoch:  176  	Training Loss: 0.01677660644054413
Test Loss:  0.019695570692420006
Valid Loss:  0.01951822265982628
Epoch:  177  	Training Loss: 0.016764676198363304
Test Loss:  0.01968720555305481
Valid Loss:  0.019512005150318146
Epoch:  178  	Training Loss: 0.016752826049923897
Test Loss:  0.0196787528693676
Valid Loss:  0.019505657255649567
Epoch:  179  	Training Loss: 0.016741055995225906
Test Loss:  0.019670218229293823
Valid Loss:  0.01949918642640114
Epoch:  180  	Training Loss: 0.016729358583688736
Test Loss:  0.01966160535812378
Valid Loss:  0.01949259638786316
Epoch:  181  	Training Loss: 0.016717731952667236
Test Loss:  0.019652919843792915
Valid Loss:  0.019485902041196823
Epoch:  182  	Training Loss: 0.01670616678893566
Test Loss:  0.019644219428300858
Valid Loss:  0.019479161128401756
Epoch:  183  	Training Loss: 0.016694702208042145
Test Loss:  0.019635478034615517
Valid Loss:  0.019472328945994377
Epoch:  184  	Training Loss: 0.01668330281972885
Test Loss:  0.01962667889893055
Valid Loss:  0.019465407356619835
Epoch:  185  	Training Loss: 0.016671957448124886
Test Loss:  0.019617822021245956
Valid Loss:  0.019458403810858727
Epoch:  186  	Training Loss: 0.016660666093230247
Test Loss:  0.01960892602801323
Valid Loss:  0.019451327621936798
Epoch:  187  	Training Loss: 0.016649428755044937
Test Loss:  0.01959998533129692
Valid Loss:  0.019444182515144348
Epoch:  188  	Training Loss: 0.016638237982988358
Test Loss:  0.01959100179374218
Valid Loss:  0.019436972215771675
Epoch:  189  	Training Loss: 0.01662709191441536
Test Loss:  0.019581981003284454
Valid Loss:  0.019429698586463928
Epoch:  190  	Training Loss: 0.016615988686680794
Test Loss:  0.019572928547859192
Valid Loss:  0.019422374665737152
Epoch:  191  	Training Loss: 0.016604933887720108
Test Loss:  0.019563846290111542
Valid Loss:  0.019415002316236496
Epoch:  192  	Training Loss: 0.016593918204307556
Test Loss:  0.01955481246113777
Valid Loss:  0.019407644867897034
Epoch:  193  	Training Loss: 0.016583021730184555
Test Loss:  0.01954576000571251
Valid Loss:  0.019400257617235184
Epoch:  194  	Training Loss: 0.01657233014702797
Test Loss:  0.019537709653377533
Valid Loss:  0.019394036382436752
Epoch:  195  	Training Loss: 0.016561811789870262
Test Loss:  0.019529588520526886
Valid Loss:  0.01938771829009056
Epoch:  196  	Training Loss: 0.016551345586776733
Test Loss:  0.019521411508321762
Valid Loss:  0.019381314516067505
Epoch:  197  	Training Loss: 0.016540931537747383
Test Loss:  0.01951344683766365
Valid Loss:  0.019374823197722435
Epoch:  198  	Training Loss: 0.016530556604266167
Test Loss:  0.019505716860294342
Valid Loss:  0.0193682499229908
Epoch:  199  	Training Loss: 0.01652022823691368
Test Loss:  0.019497964531183243
Valid Loss:  0.01936161518096924
Epoch:  200  	Training Loss: 0.016509944573044777
Test Loss:  0.01949017122387886
Valid Loss:  0.019354909658432007
Epoch:  201  	Training Loss: 0.01649969443678856
Test Loss:  0.019482355564832687
Valid Loss:  0.019348137080669403
Epoch:  202  	Training Loss: 0.016489490866661072
Test Loss:  0.019474422559142113
Valid Loss:  0.01934121549129486
Epoch:  203  	Training Loss: 0.01647925190627575
Test Loss:  0.01946646347641945
Valid Loss:  0.019334236159920692
Epoch:  204  	Training Loss: 0.016469042748212814
Test Loss:  0.01945849135518074
Valid Loss:  0.019327208399772644
Epoch:  205  	Training Loss: 0.016458874568343163
Test Loss:  0.019450508058071136
Valid Loss:  0.01932014524936676
Epoch:  206  	Training Loss: 0.016448743641376495
Test Loss:  0.019442500546574593
Valid Loss:  0.019313037395477295
Epoch:  207  	Training Loss: 0.016438640654087067
Test Loss:  0.019434485584497452
Valid Loss:  0.019305896013975143
Epoch:  208  	Training Loss: 0.016428573057055473
Test Loss:  0.019426465034484863
Valid Loss:  0.019298719242215157
Epoch:  209  	Training Loss: 0.016418538987636566
Test Loss:  0.019418437033891678
Valid Loss:  0.01929217390716076
Epoch:  210  	Training Loss: 0.016408542171120644
Test Loss:  0.019410395994782448
Valid Loss:  0.01928561180830002
Epoch:  211  	Training Loss: 0.01639856956899166
Test Loss:  0.019402354955673218
Valid Loss:  0.019279029220342636
Epoch:  212  	Training Loss: 0.016388632357120514
Test Loss:  0.01939428597688675
Valid Loss:  0.01927240751683712
Epoch:  213  	Training Loss: 0.016378723084926605
Test Loss:  0.019386226311326027
Valid Loss:  0.01926577463746071
Epoch:  214  	Training Loss: 0.01636897772550583
 43%|████▎     | 214/500 [02:33<04:04,  1.17it/s] 43%|████▎     | 216/500 [02:34<02:55,  1.62it/s] 44%|████▎     | 218/500 [02:34<02:07,  2.21it/s] 44%|████▍     | 220/500 [02:34<01:34,  2.97it/s] 44%|████▍     | 222/500 [02:40<05:32,  1.20s/it] 45%|████▍     | 224/500 [02:40<03:56,  1.17it/s] 45%|████▌     | 226/500 [02:40<02:49,  1.62it/s] 46%|████▌     | 228/500 [02:41<02:03,  2.21it/s] 46%|████▌     | 230/500 [02:41<01:31,  2.97it/s] 46%|████▋     | 232/500 [02:47<05:19,  1.19s/it] 47%|████▋     | 234/500 [02:47<03:47,  1.17it/s] 47%|████▋     | 236/500 [02:47<02:43,  1.62it/s] 48%|████▊     | 238/500 [02:47<01:58,  2.21it/s] 48%|████▊     | 240/500 [02:48<01:27,  2.97it/s] 48%|████▊     | 242/500 [02:54<05:09,  1.20s/it] 49%|████▉     | 244/500 [02:54<03:39,  1.17it/s] 49%|████▉     | 246/500 [02:54<02:37,  1.61it/s] 50%|████▉     | 248/500 [02:54<01:54,  2.20it/s] 50%|█████     | 250/500 [02:55<01:24,  2.97it/s] 50%|█████     | 252/500 [03:01<04:54,  1.19s/it] 51%|█████     | 254/500 [03:01<03:29,  1.17it/s] 51%|█████     | 256/500 [03:01<02:30,  1.62it/s] 52%|█████▏    | 258/500 [03:01<01:49,  2.22it/s] 52%|█████▏    | 260/500 [03:01<01:20,  2.99it/s] 52%|█████▏    | 262/500 [03:08<04:42,  1.19s/it] 53%|█████▎    | 264/500 [03:08<03:20,  1.18it/s] 53%|█████▎    | 266/500 [03:08<02:23,  1.63it/s] 54%|█████▎    | 268/500 [03:08<01:44,  2.22it/s] 54%|█████▍    | 270/500 [03:08<01:16,  2.99it/s] 54%|█████▍    | 272/500 [03:15<04:32,  1.20s/it] 55%|█████▍    | 274/500 [03:15<03:13,  1.17it/s] 55%|█████▌    | 276/500 [03:15<02:18,  1.61it/s] 56%|█████▌    | 278/500 [03:15<01:40,  2.20it/s] 56%|█████▌    | 280/500 [03:15<01:14,  2.96it/s] 56%|█████▋    | 282/500 [03:21<04:15,  1.17s/it] 57%|█████▋    | 284/500 [03:22<03:01,  1.19it/s]Test Loss:  0.019378965720534325
Valid Loss:  0.019260093569755554
Epoch:  215  	Training Loss: 0.01635943166911602
Test Loss:  0.01937166228890419
Valid Loss:  0.019254351034760475
Epoch:  216  	Training Loss: 0.016349922865629196
Test Loss:  0.019364330917596817
Valid Loss:  0.01924855262041092
Epoch:  217  	Training Loss: 0.016340455040335655
Test Loss:  0.019356977194547653
Valid Loss:  0.01924271322786808
Epoch:  218  	Training Loss: 0.016331028193235397
Test Loss:  0.019349589943885803
Valid Loss:  0.019236817955970764
Epoch:  219  	Training Loss: 0.016321631148457527
Test Loss:  0.019342176616191864
Valid Loss:  0.019230881705880165
Epoch:  220  	Training Loss: 0.016312267631292343
Test Loss:  0.019334740936756134
Valid Loss:  0.019224906340241432
Epoch:  221  	Training Loss: 0.016302935779094696
Test Loss:  0.019327295944094658
Valid Loss:  0.01921890303492546
Epoch:  222  	Training Loss: 0.01629364863038063
Test Loss:  0.019319823011755943
Valid Loss:  0.019212856888771057
Epoch:  223  	Training Loss: 0.01628437265753746
Test Loss:  0.019312335178256035
Valid Loss:  0.019206780940294266
Epoch:  224  	Training Loss: 0.016275126487016678
Test Loss:  0.01930483803153038
Valid Loss:  0.019200682640075684
Epoch:  225  	Training Loss: 0.01626591384410858
Test Loss:  0.01929732784628868
Valid Loss:  0.019194554537534714
Epoch:  226  	Training Loss: 0.016256729140877724
Test Loss:  0.019289806485176086
Valid Loss:  0.01918840780854225
Epoch:  227  	Training Loss: 0.016247576102614403
Test Loss:  0.019282279536128044
Valid Loss:  0.0191822350025177
Epoch:  228  	Training Loss: 0.016238445416092873
Test Loss:  0.019274739548563957
Valid Loss:  0.019176043570041656
Epoch:  229  	Training Loss: 0.01622934453189373
Test Loss:  0.01926720328629017
Valid Loss:  0.019169840961694717
Epoch:  230  	Training Loss: 0.016220271587371826
Test Loss:  0.019259657710790634
Valid Loss:  0.019163619726896286
Epoch:  231  	Training Loss: 0.01621122658252716
Test Loss:  0.01925211399793625
Valid Loss:  0.01915738731622696
Epoch:  232  	Training Loss: 0.016202207654714584
Test Loss:  0.01924462802708149
Valid Loss:  0.019151192158460617
Epoch:  233  	Training Loss: 0.01619328185915947
Test Loss:  0.019237138330936432
Valid Loss:  0.01914498582482338
Epoch:  234  	Training Loss: 0.016184378415346146
Test Loss:  0.019229650497436523
Valid Loss:  0.019138775765895844
Epoch:  235  	Training Loss: 0.01617550477385521
Test Loss:  0.019222160801291466
Valid Loss:  0.019132962450385094
Epoch:  236  	Training Loss: 0.016166653484106064
Test Loss:  0.019214686006307602
Valid Loss:  0.01912735030055046
Epoch:  237  	Training Loss: 0.01615782640874386
Test Loss:  0.01920720934867859
Valid Loss:  0.019121740013360977
Epoch:  238  	Training Loss: 0.01614902913570404
Test Loss:  0.01919974386692047
Valid Loss:  0.019116129726171494
Epoch:  239  	Training Loss: 0.016140252351760864
Test Loss:  0.0191922839730978
Valid Loss:  0.01911052316427231
Epoch:  240  	Training Loss: 0.016131501644849777
Test Loss:  0.01918482780456543
Valid Loss:  0.019104907289147377
Epoch:  241  	Training Loss: 0.01612277328968048
Test Loss:  0.019177384674549103
Valid Loss:  0.01909930445253849
Epoch:  242  	Training Loss: 0.016114158555865288
Test Loss:  0.019170746207237244
Valid Loss:  0.019094467163085938
Epoch:  243  	Training Loss: 0.016105787828564644
Test Loss:  0.019164083525538445
Valid Loss:  0.019089605659246445
Epoch:  244  	Training Loss: 0.016097452491521835
Test Loss:  0.019157391041517258
Valid Loss:  0.019084706902503967
Epoch:  245  	Training Loss: 0.016089141368865967
Test Loss:  0.01915067806839943
Valid Loss:  0.019079776480793953
Epoch:  246  	Training Loss: 0.016080860048532486
Test Loss:  0.01914394274353981
Valid Loss:  0.019074823707342148
Epoch:  247  	Training Loss: 0.016072604805231094
Test Loss:  0.019137190654873848
Valid Loss:  0.019069846719503403
Epoch:  248  	Training Loss: 0.016064420342445374
Test Loss:  0.01913117617368698
Valid Loss:  0.019065577536821365
Epoch:  249  	Training Loss: 0.016056424006819725
Test Loss:  0.019125107675790787
Valid Loss:  0.019061243161559105
Epoch:  250  	Training Loss: 0.016048504039645195
Test Loss:  0.019119739532470703
Valid Loss:  0.019057592377066612
Epoch:  251  	Training Loss: 0.016040712594985962
Test Loss:  0.01911429688334465
Valid Loss:  0.019053852185606956
Epoch:  252  	Training Loss: 0.016032975167036057
Test Loss:  0.019108841195702553
Valid Loss:  0.019050108268857002
Epoch:  253  	Training Loss: 0.016025295481085777
Test Loss:  0.019103316590189934
Valid Loss:  0.019046280533075333
Epoch:  254  	Training Loss: 0.016017664223909378
Test Loss:  0.019097724929451942
Valid Loss:  0.019042380154132843
Epoch:  255  	Training Loss: 0.016010068356990814
Test Loss:  0.019092077389359474
Valid Loss:  0.01903841644525528
Epoch:  256  	Training Loss: 0.016002515330910683
Test Loss:  0.019086383283138275
Valid Loss:  0.019034389406442642
Epoch:  257  	Training Loss: 0.015995001420378685
Test Loss:  0.01908063143491745
Valid Loss:  0.019030310213565826
Epoch:  258  	Training Loss: 0.015987522900104523
Test Loss:  0.019074836745858192
Valid Loss:  0.019026175141334534
Epoch:  259  	Training Loss: 0.015980076044797897
Test Loss:  0.019068986177444458
Valid Loss:  0.019021976739168167
Epoch:  260  	Training Loss: 0.01597265526652336
Test Loss:  0.01906326413154602
Valid Loss:  0.019017737358808517
Epoch:  261  	Training Loss: 0.01596527174115181
Test Loss:  0.019057709723711014
Valid Loss:  0.019013451412320137
Epoch:  262  	Training Loss: 0.01595791056752205
Test Loss:  0.01905211992561817
Valid Loss:  0.01900910958647728
Epoch:  263  	Training Loss: 0.015950582921504974
Test Loss:  0.019046500325202942
Valid Loss:  0.01900472305715084
Epoch:  264  	Training Loss: 0.015943273901939392
Test Loss:  0.01904086396098137
Valid Loss:  0.019000299274921417
Epoch:  265  	Training Loss: 0.0159359909594059
Test Loss:  0.019035210832953453
Valid Loss:  0.018995849415659904
Epoch:  266  	Training Loss: 0.015928734093904495
Test Loss:  0.019029537215828896
Valid Loss:  0.01899135857820511
Epoch:  267  	Training Loss: 0.015921495854854584
Test Loss:  0.019023846834897995
Valid Loss:  0.018986845389008522
Epoch:  268  	Training Loss: 0.01591428741812706
Test Loss:  0.019018150866031647
Valid Loss:  0.018982302397489548
Epoch:  269  	Training Loss: 0.01590709760785103
Test Loss:  0.019012438133358955
Valid Loss:  0.01897774264216423
Epoch:  270  	Training Loss: 0.015899930149316788
Test Loss:  0.01900670677423477
Valid Loss:  0.018973153084516525
Epoch:  271  	Training Loss: 0.01589278131723404
Test Loss:  0.019000979140400887
Valid Loss:  0.018968546763062477
Epoch:  272  	Training Loss: 0.01588565483689308
Test Loss:  0.018995169550180435
Valid Loss:  0.01896384358406067
Epoch:  273  	Training Loss: 0.015878617763519287
Test Loss:  0.018989956006407738
Valid Loss:  0.018959861248731613
Epoch:  274  	Training Loss: 0.01587168127298355
Test Loss:  0.01898471638560295
Valid Loss:  0.01895582675933838
Epoch:  275  	Training Loss: 0.015864776447415352
Test Loss:  0.018979445099830627
Valid Loss:  0.01895175129175186
Epoch:  276  	Training Loss: 0.015857897698879242
Test Loss:  0.018974140286445618
Valid Loss:  0.018947621807456017
Epoch:  277  	Training Loss: 0.015851039439439774
Test Loss:  0.018968813121318817
Valid Loss:  0.018943455070257187
Epoch:  278  	Training Loss: 0.015844210982322693
Test Loss:  0.018963463604450226
Valid Loss:  0.018939249217510223
Epoch:  279  	Training Loss: 0.015837404876947403
Test Loss:  0.018958086147904396
Valid Loss:  0.01893499866127968
Epoch:  280  	Training Loss: 0.015830613672733307
Test Loss:  0.018952693790197372
Valid Loss:  0.018930720165371895
Epoch:  281  	Training Loss: 0.01582385040819645
Test Loss:  0.018947280943393707
Valid Loss:  0.018926411867141724
Epoch:  282  	Training Loss: 0.015817109495401382
Test Loss:  0.01894197054207325
Valid Loss:  0.018922198563814163
Epoch:  283  	Training Loss: 0.01581047847867012
Test Loss:  0.0189366452395916
Valid Loss:  0.018917959183454514
Epoch:  284  	Training Loss: 0.015803862363100052
Test Loss:  0.0189313106238842
Valid Loss:  0.018913695588707924
 57%|█████▋    | 286/500 [03:22<02:09,  1.65it/s] 58%|█████▊    | 288/500 [03:22<01:34,  2.25it/s] 58%|█████▊    | 290/500 [03:22<01:09,  3.02it/s] 58%|█████▊    | 292/500 [03:28<04:03,  1.17s/it] 59%|█████▉    | 294/500 [03:28<02:53,  1.19it/s] 59%|█████▉    | 296/500 [03:29<02:04,  1.64it/s] 60%|█████▉    | 298/500 [03:29<01:30,  2.24it/s] 60%|██████    | 300/500 [03:29<01:06,  3.01it/s] 60%|██████    | 302/500 [03:35<03:54,  1.19s/it] 61%|██████    | 304/500 [03:35<02:46,  1.18it/s] 61%|██████    | 306/500 [03:35<01:59,  1.63it/s] 62%|██████▏   | 308/500 [03:36<01:26,  2.22it/s] 62%|██████▏   | 310/500 [03:36<01:03,  2.99it/s] 62%|██████▏   | 312/500 [03:42<03:44,  1.19s/it] 63%|██████▎   | 314/500 [03:42<02:38,  1.17it/s] 63%|██████▎   | 316/500 [03:42<01:53,  1.62it/s] 64%|██████▎   | 318/500 [03:42<01:22,  2.21it/s] 64%|██████▍   | 320/500 [03:43<01:00,  2.97it/s] 64%|██████▍   | 322/500 [03:49<03:30,  1.18s/it] 65%|██████▍   | 324/500 [03:49<02:29,  1.18it/s] 65%|██████▌   | 326/500 [03:49<01:46,  1.63it/s] 66%|██████▌   | 328/500 [03:49<01:17,  2.23it/s] 66%|██████▌   | 330/500 [03:49<00:56,  3.00it/s] 66%|██████▋   | 332/500 [03:56<03:17,  1.18s/it] 67%|██████▋   | 334/500 [03:56<02:19,  1.19it/s] 67%|██████▋   | 336/500 [03:56<01:39,  1.64it/s] 68%|██████▊   | 338/500 [03:56<01:12,  2.25it/s] 68%|██████▊   | 340/500 [03:56<00:52,  3.02it/s] 68%|██████▊   | 342/500 [04:03<03:08,  1.19s/it] 69%|██████▉   | 344/500 [04:03<02:13,  1.17it/s] 69%|██████▉   | 346/500 [04:03<01:35,  1.62it/s] 70%|██████▉   | 348/500 [04:03<01:08,  2.21it/s] 70%|███████   | 350/500 [04:03<00:50,  2.98it/s] 70%|███████   | 352/500 [04:09<02:55,  1.18s/it] 71%|███████   | 354/500 [04:10<02:03,  1.18it/s]Epoch:  285  	Training Loss: 0.015797272324562073
Test Loss:  0.01892595738172531
Valid Loss:  0.018909405916929245
Epoch:  286  	Training Loss: 0.015790699049830437
Test Loss:  0.018920596688985825
Valid Loss:  0.018905097618699074
Epoch:  287  	Training Loss: 0.015784142538905144
Test Loss:  0.01891522854566574
Valid Loss:  0.01890077069401741
Epoch:  288  	Training Loss: 0.01577761024236679
Test Loss:  0.01891019009053707
Valid Loss:  0.018896419554948807
Epoch:  289  	Training Loss: 0.015771087259054184
Test Loss:  0.018905214965343475
Valid Loss:  0.018892060965299606
Epoch:  290  	Training Loss: 0.015764590352773666
Test Loss:  0.01890023797750473
Valid Loss:  0.018887681886553764
Epoch:  291  	Training Loss: 0.015758171677589417
Test Loss:  0.018895715475082397
Valid Loss:  0.01888400875031948
Epoch:  292  	Training Loss: 0.015751872211694717
Test Loss:  0.018891185522079468
Valid Loss:  0.01888030767440796
Epoch:  293  	Training Loss: 0.0157456174492836
Test Loss:  0.018886638805270195
Valid Loss:  0.018876560032367706
Epoch:  294  	Training Loss: 0.015739385038614273
Test Loss:  0.01888207718729973
Valid Loss:  0.018872767686843872
Epoch:  295  	Training Loss: 0.015733174979686737
Test Loss:  0.018877506256103516
Valid Loss:  0.018868938088417053
Epoch:  296  	Training Loss: 0.01572698913514614
Test Loss:  0.01887291669845581
Valid Loss:  0.018865065649151802
Epoch:  297  	Training Loss: 0.015720821917057037
Test Loss:  0.01886831410229206
Valid Loss:  0.018861163407564163
Epoch:  298  	Training Loss: 0.015714678913354874
Test Loss:  0.018863704055547714
Valid Loss:  0.018857231363654137
Epoch:  299  	Training Loss: 0.01570855639874935
Test Loss:  0.01885908842086792
Valid Loss:  0.018853269517421722
Epoch:  300  	Training Loss: 0.015702523291110992
Test Loss:  0.018854927271604538
Valid Loss:  0.01885000616312027
Epoch:  301  	Training Loss: 0.015696583315730095
Test Loss:  0.018850740045309067
Valid Loss:  0.018846692517399788
Epoch:  302  	Training Loss: 0.015690669417381287
Test Loss:  0.01884648948907852
Valid Loss:  0.018843282014131546
Epoch:  303  	Training Loss: 0.01568474993109703
Test Loss:  0.018842220306396484
Valid Loss:  0.018839823082089424
Epoch:  304  	Training Loss: 0.015678860247135162
Test Loss:  0.018837928771972656
Valid Loss:  0.01883651316165924
Epoch:  305  	Training Loss: 0.015672992914915085
Test Loss:  0.01883361116051674
Valid Loss:  0.0188332237303257
Epoch:  306  	Training Loss: 0.0156671442091465
Test Loss:  0.01882927678525448
Valid Loss:  0.018829893320798874
Epoch:  307  	Training Loss: 0.015661321580410004
Test Loss:  0.018824921920895576
Valid Loss:  0.01882653310894966
Epoch:  308  	Training Loss: 0.0156555138528347
Test Loss:  0.018820546567440033
Valid Loss:  0.01882314309477806
Epoch:  309  	Training Loss: 0.01564973220229149
Test Loss:  0.018816150724887848
Valid Loss:  0.018819715827703476
Epoch:  310  	Training Loss: 0.015643958002328873
Test Loss:  0.018811751157045364
Valid Loss:  0.0188162662088871
Epoch:  311  	Training Loss: 0.015638208016753197
Test Loss:  0.018807409331202507
Valid Loss:  0.018812794238328934
Epoch:  312  	Training Loss: 0.015632476657629013
Test Loss:  0.018803352490067482
Valid Loss:  0.018809352070093155
Epoch:  313  	Training Loss: 0.015626808628439903
Test Loss:  0.018799293786287308
Valid Loss:  0.018805883824825287
Epoch:  314  	Training Loss: 0.015621159225702286
Test Loss:  0.018795236945152283
Valid Loss:  0.018802404403686523
Epoch:  315  	Training Loss: 0.015615531243383884
Test Loss:  0.01879117079079151
Valid Loss:  0.01879889704287052
Epoch:  316  	Training Loss: 0.015609911642968655
Test Loss:  0.01878710277378559
Valid Loss:  0.018795378506183624
Epoch:  317  	Training Loss: 0.015604309737682343
Test Loss:  0.018783029168844223
Valid Loss:  0.018791839480400085
Epoch:  318  	Training Loss: 0.01559872180223465
Test Loss:  0.018778957426548004
Valid Loss:  0.01878828927874565
Epoch:  319  	Training Loss: 0.015593147836625576
Test Loss:  0.018774889409542084
Valid Loss:  0.01878473162651062
Epoch:  320  	Training Loss: 0.015587594360113144
Test Loss:  0.018770810216665268
Valid Loss:  0.018781155347824097
Epoch:  321  	Training Loss: 0.015582048334181309
Test Loss:  0.0187667366117239
Valid Loss:  0.018777567893266678
Epoch:  322  	Training Loss: 0.015576518140733242
Test Loss:  0.018762648105621338
Valid Loss:  0.018773958086967468
Epoch:  323  	Training Loss: 0.015571001917123795
Test Loss:  0.018758561462163925
Valid Loss:  0.018770333379507065
Epoch:  324  	Training Loss: 0.015565495006740093
Test Loss:  0.018754474818706512
Valid Loss:  0.01876670867204666
Epoch:  325  	Training Loss: 0.015560006722807884
Test Loss:  0.018750391900539398
Valid Loss:  0.018763074651360512
Epoch:  326  	Training Loss: 0.015554528683423996
Test Loss:  0.018746307119727135
Valid Loss:  0.018759429454803467
Epoch:  327  	Training Loss: 0.015549065545201302
Test Loss:  0.01874222792685032
Valid Loss:  0.018756017088890076
Epoch:  328  	Training Loss: 0.015543614514172077
Test Loss:  0.018738148733973503
Valid Loss:  0.01875273510813713
Epoch:  329  	Training Loss: 0.015538174659013748
Test Loss:  0.018734071403741837
Valid Loss:  0.018749453127384186
Epoch:  330  	Training Loss: 0.015532747842371464
Test Loss:  0.018729999661445618
Valid Loss:  0.018746163696050644
Epoch:  331  	Training Loss: 0.015527334064245224
Test Loss:  0.018725931644439697
Valid Loss:  0.01874287612736225
Epoch:  332  	Training Loss: 0.01552193146198988
Test Loss:  0.01872190833091736
Valid Loss:  0.01873962953686714
Epoch:  333  	Training Loss: 0.01551659032702446
Test Loss:  0.018717892467975616
Valid Loss:  0.018736381083726883
Epoch:  334  	Training Loss: 0.015511257573962212
Test Loss:  0.018713880330324173
Valid Loss:  0.018733132630586624
Epoch:  335  	Training Loss: 0.015505939722061157
Test Loss:  0.018709871917963028
Valid Loss:  0.018729886040091515
Epoch:  336  	Training Loss: 0.015500632114708424
Test Loss:  0.01870586723089218
Valid Loss:  0.018726961687207222
Epoch:  337  	Training Loss: 0.015495339408516884
Test Loss:  0.018701869994401932
Valid Loss:  0.01872408390045166
Epoch:  338  	Training Loss: 0.01549005601555109
Test Loss:  0.01869787834584713
Valid Loss:  0.018721209838986397
Epoch:  339  	Training Loss: 0.015484785661101341
Test Loss:  0.018693890422582626
Valid Loss:  0.018718339502811432
Epoch:  340  	Training Loss: 0.015479526482522488
Test Loss:  0.01868990808725357
Valid Loss:  0.018715467303991318
Epoch:  341  	Training Loss: 0.015474282205104828
Test Loss:  0.01868593692779541
Valid Loss:  0.0187126025557518
Epoch:  342  	Training Loss: 0.01546904630959034
Test Loss:  0.018681975081562996
Valid Loss:  0.01870974712073803
Epoch:  343  	Training Loss: 0.015463844873011112
Test Loss:  0.018678024411201477
Valid Loss:  0.018706893548369408
Epoch:  344  	Training Loss: 0.015458655543625355
Test Loss:  0.018674075603485107
Valid Loss:  0.018704041838645935
Epoch:  345  	Training Loss: 0.015453475527465343
Test Loss:  0.01867014169692993
Valid Loss:  0.01870119944214821
Epoch:  346  	Training Loss: 0.01544831320643425
Test Loss:  0.018666207790374756
Valid Loss:  0.018698355183005333
Epoch:  347  	Training Loss: 0.015443154610693455
Test Loss:  0.018662279471755028
Valid Loss:  0.018695510923862457
Epoch:  348  	Training Loss: 0.015438010916113853
Test Loss:  0.018658358603715897
Valid Loss:  0.01869267225265503
Epoch:  349  	Training Loss: 0.015432874672114849
Test Loss:  0.018654439598321915
Valid Loss:  0.01868983544409275
Epoch:  350  	Training Loss: 0.01542775146663189
Test Loss:  0.018650539219379425
Valid Loss:  0.018687009811401367
Epoch:  351  	Training Loss: 0.015422646887600422
Test Loss:  0.018646635115146637
Valid Loss:  0.018684182316064835
Epoch:  352  	Training Loss: 0.015417548827826977
Test Loss:  0.01864274963736534
Valid Loss:  0.01868136040866375
Epoch:  353  	Training Loss: 0.015412479639053345
Test Loss:  0.018638871610164642
Valid Loss:  0.018678542226552963
Epoch:  354  	Training Loss: 0.015407421626150608
Test Loss:  0.018634993582963943
Valid Loss:  0.018675722181797028
Epoch:  355  	Training Loss: 0.015402414835989475
Test Loss:   71%|███████   | 356/500 [04:10<01:28,  1.63it/s] 72%|███████▏  | 358/500 [04:10<01:03,  2.23it/s] 72%|███████▏  | 360/500 [04:10<00:46,  3.00it/s] 72%|███████▏  | 362/500 [04:16<02:42,  1.18s/it] 73%|███████▎  | 364/500 [04:16<01:55,  1.18it/s] 73%|███████▎  | 366/500 [04:17<01:22,  1.63it/s] 74%|███████▎  | 368/500 [04:17<00:59,  2.20it/s] 74%|███████▍  | 370/500 [04:17<00:43,  2.97it/s] 74%|███████▍  | 372/500 [04:23<02:29,  1.17s/it] 75%|███████▍  | 374/500 [04:23<01:45,  1.20it/s] 75%|███████▌  | 376/500 [04:23<01:15,  1.65it/s] 76%|███████▌  | 378/500 [04:23<00:54,  2.25it/s] 76%|███████▌  | 380/500 [04:24<00:39,  3.01it/s] 76%|███████▋  | 382/500 [04:30<02:17,  1.17s/it] 77%|███████▋  | 384/500 [04:30<01:36,  1.20it/s] 77%|███████▋  | 386/500 [04:30<01:08,  1.65it/s] 78%|███████▊  | 388/500 [04:30<00:49,  2.26it/s] 78%|███████▊  | 390/500 [04:30<00:36,  3.03it/s] 78%|███████▊  | 392/500 [04:37<02:07,  1.18s/it] 79%|███████▉  | 394/500 [04:37<01:29,  1.18it/s] 79%|███████▉  | 396/500 [04:37<01:03,  1.63it/s] 80%|███████▉  | 398/500 [04:37<00:45,  2.22it/s] 80%|████████  | 400/500 [04:37<00:33,  2.99it/s] 80%|████████  | 402/500 [04:44<01:55,  1.18s/it] 81%|████████  | 404/500 [04:44<01:20,  1.19it/s] 81%|████████  | 406/500 [04:44<00:57,  1.64it/s] 82%|████████▏ | 408/500 [04:44<00:41,  2.24it/s] 82%|████████▏ | 410/500 [04:44<00:29,  3.01it/s] 82%|████████▏ | 412/500 [04:50<01:44,  1.19s/it] 83%|████████▎ | 414/500 [04:51<01:13,  1.17it/s] 83%|████████▎ | 416/500 [04:51<00:51,  1.62it/s] 84%|████████▎ | 418/500 [04:51<00:37,  2.21it/s] 84%|████████▍ | 420/500 [04:51<00:26,  2.98it/s] 84%|████████▍ | 422/500 [04:57<01:32,  1.18s/it] 85%|████████▍ | 424/500 [04:57<01:04,  1.18it/s]0.018631447106599808
Valid Loss:  0.018673228099942207
Epoch:  356  	Training Loss: 0.015397530980408192
Test Loss:  0.018627889454364777
Valid Loss:  0.01867072284221649
Epoch:  357  	Training Loss: 0.015392661094665527
Test Loss:  0.018624331802129745
Valid Loss:  0.01866820454597473
Epoch:  358  	Training Loss: 0.015387805178761482
Test Loss:  0.01862076297402382
Valid Loss:  0.018665678799152374
Epoch:  359  	Training Loss: 0.015382960438728333
Test Loss:  0.018617188557982445
Valid Loss:  0.01866314187645912
Epoch:  360  	Training Loss: 0.015378130599856377
Test Loss:  0.018613610416650772
Valid Loss:  0.01866060122847557
Epoch:  361  	Training Loss: 0.015373311936855316
Test Loss:  0.018610022962093353
Valid Loss:  0.018658041954040527
Epoch:  362  	Training Loss: 0.015368500724434853
Test Loss:  0.018606435507535934
Valid Loss:  0.018655478954315186
Epoch:  363  	Training Loss: 0.015363704413175583
Test Loss:  0.018602848052978516
Valid Loss:  0.018652910366654396
Epoch:  364  	Training Loss: 0.015358920209109783
Test Loss:  0.0185992568731308
Valid Loss:  0.01865033432841301
Epoch:  365  	Training Loss: 0.015354147180914879
Test Loss:  0.018595661967992783
Valid Loss:  0.018647756427526474
Epoch:  366  	Training Loss: 0.01534938346594572
Test Loss:  0.01859206333756447
Valid Loss:  0.018645161762833595
Epoch:  367  	Training Loss: 0.015344629064202309
Test Loss:  0.018588460981845856
Valid Loss:  0.018642570823431015
Epoch:  368  	Training Loss: 0.015339886769652367
Test Loss:  0.01858486607670784
Valid Loss:  0.018639981746673584
Epoch:  369  	Training Loss: 0.015335156582295895
Test Loss:  0.018581269308924675
Valid Loss:  0.018637381494045258
Epoch:  370  	Training Loss: 0.015330437570810318
Test Loss:  0.018577666953206062
Valid Loss:  0.018634779378771782
Epoch:  371  	Training Loss: 0.015325727872550488
Test Loss:  0.018574072048068047
Valid Loss:  0.018632175400853157
Epoch:  372  	Training Loss: 0.015321029350161552
Test Loss:  0.018570546060800552
Valid Loss:  0.018629644066095352
Epoch:  373  	Training Loss: 0.01531640812754631
Test Loss:  0.018567025661468506
Valid Loss:  0.0186271071434021
Epoch:  374  	Training Loss: 0.01531179528683424
Test Loss:  0.01856350712478161
Valid Loss:  0.018624568358063698
Epoch:  375  	Training Loss: 0.01530719269067049
Test Loss:  0.01855998858809471
Valid Loss:  0.018622031435370445
Epoch:  376  	Training Loss: 0.015302601270377636
Test Loss:  0.018556470051407814
Valid Loss:  0.018619488924741745
Epoch:  377  	Training Loss: 0.015298020094633102
Test Loss:  0.018552957102656364
Valid Loss:  0.01861695386469364
Epoch:  378  	Training Loss: 0.015293512493371964
Test Loss:  0.018549758940935135
Valid Loss:  0.018614720553159714
Epoch:  379  	Training Loss: 0.015289075672626495
Test Loss:  0.01854654587805271
Valid Loss:  0.01861247792840004
Epoch:  380  	Training Loss: 0.015284694731235504
Test Loss:  0.018543638288974762
Valid Loss:  0.018610529601573944
Epoch:  381  	Training Loss: 0.015280364081263542
Test Loss:  0.01854070834815502
Valid Loss:  0.01860855519771576
Epoch:  382  	Training Loss: 0.015276053920388222
Test Loss:  0.01853778585791588
Valid Loss:  0.01860659196972847
Epoch:  383  	Training Loss: 0.015271777287125587
Test Loss:  0.018534842878580093
Valid Loss:  0.01860460452735424
Epoch:  384  	Training Loss: 0.015267519280314445
Test Loss:  0.018531881272792816
Valid Loss:  0.018602589145302773
Epoch:  385  	Training Loss: 0.015263274312019348
Test Loss:  0.018528902903199196
Valid Loss:  0.01860055699944496
Epoch:  386  	Training Loss: 0.015259048901498318
Test Loss:  0.01852590963244438
Valid Loss:  0.01859850436449051
Epoch:  387  	Training Loss: 0.01525484025478363
Test Loss:  0.018522903323173523
Valid Loss:  0.01859644055366516
Epoch:  388  	Training Loss: 0.015250643715262413
Test Loss:  0.018519878387451172
Valid Loss:  0.018594346940517426
Epoch:  389  	Training Loss: 0.015246458351612091
Test Loss:  0.018516847863793373
Valid Loss:  0.018592240288853645
Epoch:  390  	Training Loss: 0.015242289751768112
Test Loss:  0.018513794988393784
Valid Loss:  0.01859012059867382
Epoch:  391  	Training Loss: 0.015238132327795029
Test Loss:  0.018510732799768448
Valid Loss:  0.018587982282042503
Epoch:  392  	Training Loss: 0.015233982354402542
Test Loss:  0.01850762404501438
Valid Loss:  0.01858578622341156
Epoch:  393  	Training Loss: 0.015229824930429459
Test Loss:  0.018504507839679718
Valid Loss:  0.01858357898890972
Epoch:  394  	Training Loss: 0.015225674957036972
Test Loss:  0.018501371145248413
Valid Loss:  0.01858135685324669
Epoch:  395  	Training Loss: 0.015221533365547657
Test Loss:  0.018498238176107407
Valid Loss:  0.01857912540435791
Epoch:  396  	Training Loss: 0.015217404812574387
Test Loss:  0.018495094031095505
Valid Loss:  0.018576882779598236
Epoch:  397  	Training Loss: 0.015213290229439735
Test Loss:  0.01849193498492241
Valid Loss:  0.018574625253677368
Epoch:  398  	Training Loss: 0.015209175646305084
Test Loss:  0.018488777801394463
Valid Loss:  0.018572364002466202
Epoch:  399  	Training Loss: 0.015205079689621925
Test Loss:  0.018485620617866516
Valid Loss:  0.018570097163319588
Epoch:  400  	Training Loss: 0.015200992114841938
Test Loss:  0.018482446670532227
Valid Loss:  0.01856781356036663
Epoch:  401  	Training Loss: 0.015196909196674824
Test Loss:  0.018479276448488235
Valid Loss:  0.018565528094768524
Epoch:  402  	Training Loss: 0.01519283838570118
Test Loss:  0.01847611367702484
Valid Loss:  0.018563248217105865
Epoch:  403  	Training Loss: 0.0151887908577919
Test Loss:  0.018473025411367416
Valid Loss:  0.01856096275150776
Epoch:  404  	Training Loss: 0.015184747986495495
Test Loss:  0.018470091745257378
Valid Loss:  0.018558667972683907
Epoch:  405  	Training Loss: 0.015180716291069984
Test Loss:  0.018467163667082787
Valid Loss:  0.018556375056505203
Epoch:  406  	Training Loss: 0.015176692977547646
Test Loss:  0.018464233726263046
Valid Loss:  0.018554076552391052
Epoch:  407  	Training Loss: 0.015172678977251053
Test Loss:  0.018461301922798157
Valid Loss:  0.018551770597696304
Epoch:  408  	Training Loss: 0.015168672427535057
Test Loss:  0.018458373844623566
Valid Loss:  0.018549460917711258
Epoch:  409  	Training Loss: 0.015164673328399658
Test Loss:  0.018455443903803825
Valid Loss:  0.01854715123772621
Epoch:  410  	Training Loss: 0.015160682611167431
Test Loss:  0.018452517688274384
Valid Loss:  0.018544837832450867
Epoch:  411  	Training Loss: 0.01515670120716095
Test Loss:  0.018449589610099792
Valid Loss:  0.018542516976594925
Epoch:  412  	Training Loss: 0.01515272632241249
Test Loss:  0.01844669133424759
Valid Loss:  0.018540222197771072
Epoch:  413  	Training Loss: 0.015148784965276718
Test Loss:  0.018443793058395386
Valid Loss:  0.018537919968366623
Epoch:  414  	Training Loss: 0.015144851990044117
Test Loss:  0.018440894782543182
Valid Loss:  0.01853562518954277
Epoch:  415  	Training Loss: 0.015140928328037262
Test Loss:  0.018438002094626427
Valid Loss:  0.01853332482278347
Epoch:  416  	Training Loss: 0.015137013047933578
Test Loss:  0.01843510940670967
Valid Loss:  0.018531018868088722
Epoch:  417  	Training Loss: 0.015133103355765343
Test Loss:  0.018432214856147766
Valid Loss:  0.018528714776039124
Epoch:  418  	Training Loss: 0.015129197388887405
Test Loss:  0.018429329618811607
Valid Loss:  0.018526410683989525
Epoch:  419  	Training Loss: 0.015125306323170662
Test Loss:  0.01842644438147545
Valid Loss:  0.018524106591939926
Epoch:  420  	Training Loss: 0.015121418982744217
Test Loss:  0.01842355728149414
Valid Loss:  0.018521800637245178
Epoch:  421  	Training Loss: 0.015117538161575794
Test Loss:  0.01842067390680313
Valid Loss:  0.018519490957260132
Epoch:  422  	Training Loss: 0.01511366292834282
Test Loss:  0.018417827785015106
Valid Loss:  0.018517211079597473
Epoch:  423  	Training Loss: 0.015109831467270851
Test Loss:  0.018414976075291634
Valid Loss:  0.018514929339289665
Epoch:  424  	Training Loss: 0.015106000006198883
Test Loss:  0.01841212622821331
Valid Loss:  0.018512647598981857
Epoch:  425  	Training Loss: 0.015102174133062363
Test Loss:  0.018409278243780136
Valid Loss:  0.0185103639960289
 85%|████████▌ | 426/500 [04:58<00:45,  1.63it/s] 86%|████████▌ | 428/500 [04:58<00:32,  2.23it/s] 86%|████████▌ | 430/500 [04:58<00:23,  2.99it/s] 86%|████████▋ | 432/500 [05:04<01:19,  1.17s/it] 87%|████████▋ | 434/500 [05:04<00:55,  1.19it/s] 87%|████████▋ | 436/500 [05:04<00:38,  1.64it/s] 88%|████████▊ | 438/500 [05:04<00:27,  2.24it/s] 88%|████████▊ | 440/500 [05:05<00:19,  3.01it/s] 88%|████████▊ | 442/500 [05:11<01:08,  1.18s/it] 89%|████████▉ | 444/500 [05:11<00:47,  1.18it/s] 89%|████████▉ | 446/500 [05:11<00:33,  1.63it/s] 90%|████████▉ | 448/500 [05:11<00:23,  2.22it/s] 90%|█████████ | 450/500 [05:11<00:16,  2.98it/s] 90%|█████████ | 452/500 [05:18<00:59,  1.23s/it] 91%|█████████ | 454/500 [05:18<00:40,  1.13it/s] 91%|█████████ | 456/500 [05:18<00:28,  1.57it/s] 92%|█████████▏| 458/500 [05:19<00:19,  2.14it/s] 92%|█████████▏| 460/500 [05:19<00:13,  2.89it/s] 92%|█████████▏| 462/500 [05:25<00:44,  1.18s/it] 93%|█████████▎| 464/500 [05:25<00:30,  1.18it/s] 93%|█████████▎| 466/500 [05:25<00:20,  1.63it/s] 94%|█████████▎| 468/500 [05:25<00:14,  2.23it/s] 94%|█████████▍| 470/500 [05:25<00:09,  3.00it/s] 94%|█████████▍| 472/500 [05:32<00:32,  1.17s/it] 95%|█████████▍| 474/500 [05:32<00:21,  1.19it/s] 95%|█████████▌| 476/500 [05:32<00:14,  1.64it/s] 96%|█████████▌| 478/500 [05:32<00:09,  2.24it/s] 96%|█████████▌| 480/500 [05:32<00:06,  2.99it/s] 96%|█████████▋| 482/500 [05:39<00:21,  1.19s/it] 97%|█████████▋| 484/500 [05:39<00:13,  1.17it/s] 97%|█████████▋| 486/500 [05:39<00:08,  1.62it/s] 98%|█████████▊| 488/500 [05:39<00:05,  2.21it/s] 98%|█████████▊| 490/500 [05:39<00:03,  2.96it/s] 98%|█████████▊| 492/500 [05:45<00:09,  1.17s/it] 99%|█████████▉| 494/500 [05:46<00:05,  1.19it/s]Epoch:  426  	Training Loss: 0.015098358504474163
Test Loss:  0.018406439572572708
Valid Loss:  0.018508080393075943
Epoch:  427  	Training Loss: 0.01509455032646656
Test Loss:  0.01840360462665558
Valid Loss:  0.018505804240703583
Epoch:  428  	Training Loss: 0.015090752393007278
Test Loss:  0.01840076968073845
Valid Loss:  0.018503522500395775
Epoch:  429  	Training Loss: 0.015086958184838295
Test Loss:  0.01839793473482132
Valid Loss:  0.018501244485378265
Epoch:  430  	Training Loss: 0.015083170495927334
Test Loss:  0.018395107239484787
Valid Loss:  0.018498966470360756
Epoch:  431  	Training Loss: 0.01507939025759697
Test Loss:  0.018392283469438553
Valid Loss:  0.018496692180633545
Epoch:  432  	Training Loss: 0.015075619332492352
Test Loss:  0.018389496952295303
Valid Loss:  0.01849445328116417
Epoch:  433  	Training Loss: 0.015071885660290718
Test Loss:  0.018386714160442352
Valid Loss:  0.018492214381694794
Epoch:  434  	Training Loss: 0.015068154782056808
Test Loss:  0.01838393323123455
Valid Loss:  0.018489975482225418
Epoch:  435  	Training Loss: 0.015064436011016369
Test Loss:  0.018381157889962196
Valid Loss:  0.01848774030804634
Epoch:  436  	Training Loss: 0.015060719102621078
Test Loss:  0.01837838441133499
Valid Loss:  0.018485506996512413
Epoch:  437  	Training Loss: 0.015057013370096684
Test Loss:  0.018375616520643234
Valid Loss:  0.018483273684978485
Epoch:  438  	Training Loss: 0.015053312294185162
Test Loss:  0.018372848629951477
Valid Loss:  0.018481044098734856
Epoch:  439  	Training Loss: 0.015049619600176811
Test Loss:  0.018370086327195168
Valid Loss:  0.018478818237781525
Epoch:  440  	Training Loss: 0.015045935288071632
Test Loss:  0.018367329612374306
Valid Loss:  0.018476588651537895
Epoch:  441  	Training Loss: 0.015042254701256752
Test Loss:  0.01836458221077919
Valid Loss:  0.01847437210381031
Epoch:  442  	Training Loss: 0.015038601122796535
Test Loss:  0.018362026661634445
Valid Loss:  0.01847243309020996
Epoch:  443  	Training Loss: 0.015035027638077736
Test Loss:  0.018359459936618805
Valid Loss:  0.01847047545015812
Epoch:  444  	Training Loss: 0.01503145694732666
Test Loss:  0.01835690066218376
Valid Loss:  0.01846851408481598
Epoch:  445  	Training Loss: 0.015027901157736778
Test Loss:  0.018354330211877823
Valid Loss:  0.018466541543602943
Epoch:  446  	Training Loss: 0.015024356544017792
Test Loss:  0.018351759761571884
Valid Loss:  0.018464554101228714
Epoch:  447  	Training Loss: 0.015020813792943954
Test Loss:  0.018349185585975647
Valid Loss:  0.018462561070919037
Epoch:  448  	Training Loss: 0.015017284080386162
Test Loss:  0.018346605822443962
Valid Loss:  0.018460555002093315
Epoch:  449  	Training Loss: 0.015013760887086391
Test Loss:  0.018344026058912277
Valid Loss:  0.018458714708685875
Epoch:  450  	Training Loss: 0.015010247007012367
Test Loss:  0.018341440707445145
Valid Loss:  0.01845688372850418
Epoch:  451  	Training Loss: 0.015006737783551216
Test Loss:  0.018338855355978012
Valid Loss:  0.01845504716038704
Epoch:  452  	Training Loss: 0.01500323973596096
Test Loss:  0.018336346372961998
Valid Loss:  0.018453283235430717
Epoch:  453  	Training Loss: 0.014999805949628353
Test Loss:  0.018333831802010536
Valid Loss:  0.018451515585184097
Epoch:  454  	Training Loss: 0.014996383339166641
Test Loss:  0.018331319093704224
Valid Loss:  0.01844974048435688
Epoch:  455  	Training Loss: 0.01499298494309187
Test Loss:  0.018329018726944923
Valid Loss:  0.018448181450366974
Epoch:  456  	Training Loss: 0.014989649876952171
Test Loss:  0.018326707184314728
Valid Loss:  0.01844661310315132
Epoch:  457  	Training Loss: 0.014986330643296242
Test Loss:  0.018324388191103935
Valid Loss:  0.018445029854774475
Epoch:  458  	Training Loss: 0.014983018860220909
Test Loss:  0.01832205429673195
Valid Loss:  0.018443426117300987
Epoch:  459  	Training Loss: 0.01497971173375845
Test Loss:  0.018319718539714813
Valid Loss:  0.01844182051718235
Epoch:  460  	Training Loss: 0.014976419508457184
Test Loss:  0.01831737533211708
Valid Loss:  0.018440207466483116
Epoch:  461  	Training Loss: 0.014973137527704239
Test Loss:  0.01831502467393875
Valid Loss:  0.018438585102558136
Epoch:  462  	Training Loss: 0.014969862997531891
Test Loss:  0.01831258274614811
Valid Loss:  0.0184368584305048
Epoch:  463  	Training Loss: 0.014966525137424469
Test Loss:  0.01831013336777687
Valid Loss:  0.018435124307870865
Epoch:  464  	Training Loss: 0.014963197521865368
Test Loss:  0.018307676538825035
Valid Loss:  0.018433386459946632
Epoch:  465  	Training Loss: 0.014959875494241714
Test Loss:  0.018305212259292603
Valid Loss:  0.018431633710861206
Epoch:  466  	Training Loss: 0.014956558123230934
Test Loss:  0.018302753567695618
Valid Loss:  0.01842987723648548
Epoch:  467  	Training Loss: 0.014953252859413624
Test Loss:  0.018300287425518036
Valid Loss:  0.018428117036819458
Epoch:  468  	Training Loss: 0.014949953183531761
Test Loss:  0.018297813832759857
Valid Loss:  0.018426351249217987
Epoch:  469  	Training Loss: 0.014946670271456242
Test Loss:  0.018295561894774437
Valid Loss:  0.018424803391098976
Epoch:  470  	Training Loss: 0.014943449757993221
Test Loss:  0.018293291330337524
Valid Loss:  0.018423236906528473
Epoch:  471  	Training Loss: 0.014940239489078522
Test Loss:  0.018291013315320015
Valid Loss:  0.018421657383441925
Epoch:  472  	Training Loss: 0.014937040396034718
Test Loss:  0.018288761377334595
Valid Loss:  0.018420105800032616
Epoch:  473  	Training Loss: 0.014933882281184196
Test Loss:  0.018286507576704025
Valid Loss:  0.01841854676604271
Epoch:  474  	Training Loss: 0.014930738136172295
Test Loss:  0.018284235149621964
Valid Loss:  0.01841696724295616
Epoch:  475  	Training Loss: 0.014927596785128117
Test Loss:  0.018281958997249603
Valid Loss:  0.018415376543998718
Epoch:  476  	Training Loss: 0.014924462884664536
Test Loss:  0.018279675394296646
Valid Loss:  0.018413778394460678
Epoch:  477  	Training Loss: 0.014921342954039574
Test Loss:  0.018277380615472794
Valid Loss:  0.018412169069051743
Epoch:  478  	Training Loss: 0.01491822674870491
Test Loss:  0.018275080248713493
Valid Loss:  0.01841054856777191
Epoch:  479  	Training Loss: 0.014915121719241142
Test Loss:  0.018272772431373596
Valid Loss:  0.018408920615911484
Epoch:  480  	Training Loss: 0.014912020415067673
Test Loss:  0.01827046647667885
Valid Loss:  0.018407288938760757
Epoch:  481  	Training Loss: 0.014908930286765099
Test Loss:  0.018268145620822906
Valid Loss:  0.018405644223093987
Epoch:  482  	Training Loss: 0.014905841089785099
Test Loss:  0.01826583966612816
Valid Loss:  0.01840400882065296
Epoch:  483  	Training Loss: 0.014902777969837189
Test Loss:  0.01826353184878826
Valid Loss:  0.01840236783027649
Epoch:  484  	Training Loss: 0.014899717643857002
Test Loss:  0.018261216580867767
Valid Loss:  0.01840072125196457
Epoch:  485  	Training Loss: 0.014896666631102562
Test Loss:  0.018258893862366676
Valid Loss:  0.018399063497781754
Epoch:  486  	Training Loss: 0.014893615618348122
Test Loss:  0.018256576731801033
Valid Loss:  0.01839740388095379
Epoch:  487  	Training Loss: 0.014890576712787151
Test Loss:  0.018254250288009644
Valid Loss:  0.018395740538835526
Epoch:  488  	Training Loss: 0.014887543395161629
Test Loss:  0.018251929432153702
Valid Loss:  0.018394071608781815
Epoch:  489  	Training Loss: 0.014884515665471554
Test Loss:  0.018249593675136566
Valid Loss:  0.018392402678728104
Epoch:  490  	Training Loss: 0.014881495386362076
Test Loss:  0.018247265368700027
Valid Loss:  0.018390722572803497
Epoch:  491  	Training Loss: 0.014878480695188046
Test Loss:  0.01824493333697319
Valid Loss:  0.018389038741588593
Epoch:  492  	Training Loss: 0.014875471591949463
Test Loss:  0.018242565914988518
Valid Loss:  0.018387321382761
Epoch:  493  	Training Loss: 0.014872439205646515
Test Loss:  0.018240194767713547
Valid Loss:  0.018385592848062515
Epoch:  494  	Training Loss: 0.014869412407279015
Test Loss:  0.018237821757793427
Valid Loss:  0.018383866176009178
Epoch:  495  	Training Loss: 0.014866393059492111
Test Loss:  0.018235448747873306
Valid Loss:  0.018382133916020393
Epoch:  496  	Training Loss: 0.014863379299640656 99%|█████████▉| 496/500 [05:46<00:02,  1.64it/s]100%|█████████▉| 498/500 [05:46<00:00,  2.21it/s]100%|██████████| 500/500 [05:46<00:00,  2.97it/s]100%|██████████| 500/500 [05:46<00:00,  1.44it/s]

Test Loss:  0.018233079463243484
Valid Loss:  0.01838040165603161
Epoch:  497  	Training Loss: 0.014860369265079498
Test Loss:  0.018230706453323364
Valid Loss:  0.018378667533397675
Epoch:  498  	Training Loss: 0.014857366681098938
Test Loss:  0.018228333443403244
Valid Loss:  0.01837693154811859
Epoch:  499  	Training Loss: 0.014854366891086102
Test Loss:  0.018225960433483124
Valid Loss:  0.01837519183754921
Epoch:  500  	Training Loss: 0.014851374551653862
Test Loss:  0.018223589286208153
Valid Loss:  0.018373453989624977
seed is  15
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:10,  6.27s/it]  1%|          | 3/500 [00:06<13:54,  1.68s/it]  1%|          | 5/500 [00:06<07:00,  1.18it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:47,  1.32s/it]  3%|▎         | 13/500 [00:13<07:21,  1.10it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  2.99it/s]  4%|▍         | 21/500 [00:19<09:26,  1.18s/it]  5%|▍         | 23/500 [00:19<06:43,  1.18it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:34,  2.21it/s]  6%|▌         | 29/500 [00:20<02:38,  2.97it/s]  6%|▌         | 31/500 [00:26<09:09,  1.17s/it]  7%|▋         | 33/500 [00:26<06:33,  1.19it/s]  7%|▋         | 35/500 [00:26<04:42,  1.64it/s]  7%|▋         | 37/500 [00:27<03:25,  2.25it/s]  8%|▊         | 39/500 [00:27<02:33,  3.01it/s]  8%|▊         | 41/500 [00:39<16:03,  2.10s/it]  9%|▊         | 43/500 [00:39<11:21,  1.49s/it]  9%|▉         | 45/500 [00:39<08:03,  1.06s/it]  9%|▉         | 47/500 [00:40<05:46,  1.31it/s] 10%|▉         | 49/500 [00:40<04:10,  1.80it/s] 10%|█         | 51/500 [00:46<09:56,  1.33s/it] 11%|█         | 53/500 [00:46<07:05,  1.05it/s] 11%|█         | 55/500 [00:52<11:53,  1.60s/it] 11%|█▏        | 57/500 [00:52<08:26,  1.14s/it] 12%|█▏        | 59/500 [00:53<06:01,  1.22it/s] 12%|█▏        | 61/500 [00:59<11:05,  1.52s/it] 13%|█▎        | 63/500 [00:59<07:53,  1.08s/it] 13%|█▎        | 65/500 [00:59<05:38,  1.29it/s] 13%|█▎        | 67/500 [00:59<04:03,  1.77it/s] 14%|█▍        | 69/500 [00:59<02:58,  2.42it/s]Epoch:  1  	Training Loss: 0.09167537093162537
Test Loss:  11.536214828491211
Valid Loss:  11.647943496704102
Epoch:  2  	Training Loss: 10.836450576782227
Test Loss:  404.94769287109375
Valid Loss:  405.02825927734375
Epoch:  3  	Training Loss: 412.5116271972656
Test Loss:  1.0189439058303833
Valid Loss:  0.9859520196914673
Epoch:  4  	Training Loss: 1.1103920936584473
Test Loss:  1.0132325887680054
Valid Loss:  0.9795112609863281
Epoch:  5  	Training Loss: 1.104404091835022
Test Loss:  1.0084378719329834
Valid Loss:  0.9740934371948242
Epoch:  6  	Training Loss: 1.099359393119812
Test Loss:  1.0042731761932373
Valid Loss:  0.9709632396697998
Epoch:  7  	Training Loss: 1.0952715873718262
Test Loss:  1.0002646446228027
Valid Loss:  0.9686704277992249
Epoch:  8  	Training Loss: 1.091402530670166
Test Loss:  0.9964041709899902
Valid Loss:  0.9664797782897949
Epoch:  9  	Training Loss: 1.0878866910934448
Test Loss:  0.99277663230896
Valid Loss:  0.9648820161819458
Epoch:  10  	Training Loss: 1.084646463394165
Test Loss:  0.9892804622650146
Valid Loss:  0.9635303616523743
Epoch:  11  	Training Loss: 1.081590175628662
Test Loss:  0.985824465751648
Valid Loss:  0.9621920585632324
Epoch:  12  	Training Loss: 1.0787073373794556
Test Loss:  38.48339080810547
Valid Loss:  38.3050537109375
Epoch:  13  	Training Loss: 40.39140701293945
Test Loss:  0.759111762046814
Valid Loss:  0.7575700879096985
Epoch:  14  	Training Loss: 0.7721081376075745
Test Loss:  0.6638809442520142
Valid Loss:  0.660143256187439
Epoch:  15  	Training Loss: 0.6891272068023682
Test Loss:  0.5846738219261169
Valid Loss:  0.5790969133377075
Epoch:  16  	Training Loss: 0.6196150779724121
Test Loss:  0.5188471078872681
Valid Loss:  0.5117297172546387
Epoch:  17  	Training Loss: 0.5613911151885986
Test Loss:  0.4641861319541931
Valid Loss:  0.4557788372039795
Epoch:  18  	Training Loss: 0.5126225352287292
Test Loss:  0.41883522272109985
Valid Loss:  0.4093473553657532
Epoch:  19  	Training Loss: 0.47176119685173035
Test Loss:  0.3812299966812134
Valid Loss:  0.3708465099334717
Epoch:  20  	Training Loss: 0.43751031160354614
Test Loss:  0.3500579595565796
Valid Loss:  0.3389349579811096
Epoch:  21  	Training Loss: 0.4087793827056885
Test Loss:  0.32423698902130127
Valid Loss:  0.3124968409538269
Epoch:  22  	Training Loss: 0.38459911942481995
Test Loss:  18.01679229736328
Valid Loss:  17.946537017822266
Epoch:  23  	Training Loss: 18.724376678466797
Test Loss:  3.0694568157196045
Valid Loss:  3.119399070739746
Epoch:  24  	Training Loss: 2.7246451377868652
Test Loss:  0.9488286375999451
Valid Loss:  0.9514966011047363
Epoch:  25  	Training Loss: 0.9364598989486694
Test Loss:  0.38921985030174255
Valid Loss:  0.3789498805999756
Epoch:  26  	Training Loss: 0.44583654403686523
Test Loss:  0.2482720911502838
Valid Loss:  0.23447465896606445
Epoch:  27  	Training Loss: 0.3119940161705017
Test Loss:  0.21037223935127258
Valid Loss:  0.19525910913944244
Epoch:  28  	Training Loss: 0.2712593078613281
Test Loss:  0.18999353051185608
Valid Loss:  0.17520321905612946
Epoch:  29  	Training Loss: 0.2497130185365677
Test Loss:  0.1770816445350647
Valid Loss:  0.16194646060466766
Epoch:  30  	Training Loss: 0.2356102615594864
Test Loss:  0.16774706542491913
Valid Loss:  0.15234382450580597
Epoch:  31  	Training Loss: 0.22488103806972504
Test Loss:  0.1606350839138031
Valid Loss:  0.1445685774087906
Epoch:  32  	Training Loss: 0.21641021966934204
Test Loss:  0.0520915687084198
Valid Loss:  0.04810016602277756
Epoch:  33  	Training Loss: 0.059052467346191406
Test Loss:  0.04361339658498764
Valid Loss:  0.0396508164703846
Epoch:  34  	Training Loss: 0.054091956466436386
Test Loss:  0.04221488535404205
Valid Loss:  0.03818894922733307
Epoch:  35  	Training Loss: 0.05337464064359665
Test Loss:  0.041787222027778625
Valid Loss:  0.03786728158593178
Epoch:  36  	Training Loss: 0.05348114296793938
Test Loss:  0.04296533390879631
Valid Loss:  0.038917265832424164
Epoch:  37  	Training Loss: 0.05349317938089371
Test Loss:  0.04114173352718353
Valid Loss:  0.037239398807287216
Epoch:  38  	Training Loss: 0.052878156304359436
Test Loss:  0.0411614365875721
Valid Loss:  0.03712821006774902
Epoch:  39  	Training Loss: 0.05264933407306671
Test Loss:  0.040640901774168015
Valid Loss:  0.03658956289291382
Epoch:  40  	Training Loss: 0.05249571055173874
Test Loss:  0.041369833052158356
Valid Loss:  0.03728421777486801
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.05247502028942108
Test Loss:  0.07049156725406647
Valid Loss:  0.07079926133155823
Epoch:  42  	Training Loss: 0.05885836109519005
Test Loss:  0.013081579469144344
Valid Loss:  0.013161279261112213
Epoch:  43  	Training Loss: 0.011275514960289001
Test Loss:  0.002609340939670801
Valid Loss:  0.002927519381046295
Epoch:  44  	Training Loss: 0.0025391802191734314
Test Loss:  0.0010059908963739872
Valid Loss:  0.0014669215306639671
Epoch:  45  	Training Loss: 0.0012156462762504816
Test Loss:  0.0007604134734719992
Valid Loss:  0.0012839727569371462
Epoch:  46  	Training Loss: 0.0010181162506341934
Test Loss:  0.0007205595029518008
Valid Loss:  0.0012695706682279706
Epoch:  47  	Training Loss: 0.0009878521086648107
Test Loss:  0.0007128196302801371
Valid Loss:  0.0012720029335469007
Epoch:  48  	Training Loss: 0.0009825289016589522
Test Loss:  0.00071047741221264
Valid Loss:  0.0012737908400595188
Epoch:  49  	Training Loss: 0.000981007469817996
Test Loss:  0.0007092168089002371
Valid Loss:  0.0012742991093546152
Epoch:  50  	Training Loss: 0.000980136450380087
Test Loss:  0.000708267732989043
Valid Loss:  0.0012741915415972471
Epoch:  51  	Training Loss: 0.0009794379584491253
Test Loss:  0.0007074602181091905
Valid Loss:  0.0012738584773615003
Epoch:  52  	Training Loss: 0.0009788312017917633
Test Loss:  0.0007072382140904665
Valid Loss:  0.0012329600285738707
Epoch:  53  	Training Loss: 0.0009747986914590001
Test Loss:  0.0010097644990310073
Valid Loss:  0.0016530826687812805
Epoch:  54  	Training Loss: 0.001284920610487461
Test Loss:  0.0033383744303137064
Valid Loss:  0.0035807653330266476
Epoch:  55  	Training Loss: 0.0035326769575476646
Test Loss:  0.00412913179025054
Valid Loss:  0.004975583404302597
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.004538591019809246
Test Loss:  0.00224642688408494
Valid Loss:  0.0025640365201979876
Epoch:  57  	Training Loss: 0.0023385505191981792
Test Loss:  0.0011929410975426435
Valid Loss:  0.0018425919115543365
Epoch:  58  	Training Loss: 0.0014877498615533113
Test Loss:  0.0009116249275393784
Valid Loss:  0.001362981740385294
Epoch:  59  	Training Loss: 0.0011369901476427913
Test Loss:  0.0007523911772295833
Valid Loss:  0.0013217476662248373
Epoch:  60  	Training Loss: 0.0010167192667722702
Test Loss:  0.0007232847856357694
Valid Loss:  0.0012279689544811845
Epoch:  61  	Training Loss: 0.000972957001067698
Test Loss:  0.000697731040418148
Valid Loss:  0.001243465580046177
Epoch:  62  	Training Loss: 0.0009556170552968979
Test Loss:  0.0006895982660353184
Valid Loss:  0.001221239916048944
Epoch:  63  	Training Loss: 0.0009458839194849133
Test Loss:  0.0006888838252052665
Valid Loss:  0.0012195166200399399
Epoch:  64  	Training Loss: 0.0009450586512684822
Test Loss:  0.0006883334717713296
Valid Loss:  0.0012190397828817368
Epoch:  65  	Training Loss: 0.0009445921168662608
Test Loss:  0.0006878593703731894
Valid Loss:  0.0012188865803182125
Epoch:  66  	Training Loss: 0.0009442451409995556
Test Loss:  0.0006874441169202328
Valid Loss:  0.0012187210377305746
Epoch:  67  	Training Loss: 0.0009439217392355204
Test Loss:  0.000687048421241343
Valid Loss:  0.001218587625771761
Epoch:  68  	Training Loss: 0.0009436011896468699
Test Loss:  0.0006866974290460348
Valid Loss:  0.0012184594525024295
Epoch:  69  	Training Loss: 0.000943304446991533
Test Loss:  0.0006863588932901621
Valid Loss:  0.0012184130027890205
Epoch:  70  	Training Loss: 0.0009430527570657432
Test Loss:  0.0006860337452962995
Valid Loss:   14%|█▍        | 71/500 [01:06<08:46,  1.23s/it] 15%|█▍        | 73/500 [01:06<06:15,  1.14it/s] 15%|█▌        | 75/500 [01:06<04:30,  1.57it/s] 15%|█▌        | 77/500 [01:06<03:16,  2.15it/s] 16%|█▌        | 79/500 [01:06<02:25,  2.89it/s] 16%|█▌        | 81/500 [01:13<08:17,  1.19s/it] 17%|█▋        | 83/500 [01:13<05:55,  1.17it/s] 17%|█▋        | 85/500 [01:13<04:15,  1.62it/s] 17%|█▋        | 87/500 [01:13<03:06,  2.22it/s] 18%|█▊        | 89/500 [01:13<02:18,  2.98it/s] 18%|█▊        | 91/500 [01:19<08:06,  1.19s/it] 19%|█▊        | 93/500 [01:20<05:47,  1.17it/s] 19%|█▉        | 95/500 [01:20<04:10,  1.62it/s] 19%|█▉        | 97/500 [01:20<03:02,  2.21it/s] 20%|█▉        | 99/500 [01:20<02:15,  2.97it/s] 20%|██        | 101/500 [01:26<07:49,  1.18s/it] 21%|██        | 103/500 [01:26<05:36,  1.18it/s] 21%|██        | 105/500 [01:27<04:01,  1.63it/s] 21%|██▏       | 107/500 [01:27<02:56,  2.23it/s] 22%|██▏       | 109/500 [01:27<02:10,  2.99it/s] 22%|██▏       | 111/500 [01:33<07:36,  1.17s/it] 23%|██▎       | 113/500 [01:33<05:26,  1.19it/s] 23%|██▎       | 115/500 [01:33<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:33<02:51,  2.24it/s] 24%|██▍       | 119/500 [01:34<02:07,  3.00it/s] 24%|██▍       | 119/500 [01:44<02:07,  3.00it/s] 24%|██▍       | 121/500 [01:46<13:12,  2.09s/it] 25%|██▍       | 123/500 [01:46<09:19,  1.48s/it] 25%|██▌       | 125/500 [01:46<06:36,  1.06s/it] 25%|██▌       | 127/500 [01:46<04:43,  1.32it/s] 26%|██▌       | 129/500 [01:46<03:24,  1.81it/s] 26%|██▌       | 131/500 [01:53<08:09,  1.33s/it] 27%|██▋       | 133/500 [01:53<05:48,  1.05it/s] 27%|██▋       | 135/500 [01:53<04:10,  1.46it/s] 27%|██▋       | 137/500 [01:53<03:01,  2.00it/s]0.001218336634337902
Epoch:  71  	Training Loss: 0.000942812766879797
Test Loss:  0.0006857168627902865
Valid Loss:  0.001218251301907003
Epoch:  72  	Training Loss: 0.0009425802272744477
Test Loss:  0.0006855621468275785
Valid Loss:  0.001218070276081562
Epoch:  73  	Training Loss: 0.0009424632880836725
Test Loss:  0.0006854026578366756
Valid Loss:  0.0012180284829810262
Epoch:  74  	Training Loss: 0.0009423492010682821
Test Loss:  0.0006852460210211575
Valid Loss:  0.0012179818004369736
Epoch:  75  	Training Loss: 0.0009422356961295009
Test Loss:  0.0006850910140201449
Valid Loss:  0.001217937096953392
Epoch:  76  	Training Loss: 0.0009421258000656962
Test Loss:  0.0006849390920251608
Valid Loss:  0.001217893324792385
Epoch:  77  	Training Loss: 0.0009420162532478571
Test Loss:  0.000684789614751935
Valid Loss:  0.0012178514152765274
Epoch:  78  	Training Loss: 0.0009419092675670981
Test Loss:  0.0006846410688012838
Valid Loss:  0.0012178110191598535
Epoch:  79  	Training Loss: 0.000941803096793592
Test Loss:  0.0006844952586106956
Valid Loss:  0.0012177717871963978
Epoch:  80  	Training Loss: 0.0009416996035724878
Test Loss:  0.0006843511364422739
Valid Loss:  0.0012177324388176203
Epoch:  81  	Training Loss: 0.0009415968088433146
Test Loss:  0.0006842092261649668
Valid Loss:  0.0012176944874227047
Epoch:  82  	Training Loss: 0.0009414965752512217
Test Loss:  0.0006342774722725153
Valid Loss:  0.0011721272021532059
Epoch:  83  	Training Loss: 0.0009008251945488155
Test Loss:  0.0006065239431336522
Valid Loss:  0.0011429127771407366
Epoch:  84  	Training Loss: 0.0008751041023060679
Test Loss:  0.0005844704573974013
Valid Loss:  0.0011167562333866954
Epoch:  85  	Training Loss: 0.0008557091932743788
Test Loss:  0.0005681795300915837
Valid Loss:  0.0010974493343383074
Epoch:  86  	Training Loss: 0.0008419458754360676
Test Loss:  0.0005571720539592206
Valid Loss:  0.0010829156963154674
Epoch:  87  	Training Loss: 0.000832633173558861
Test Loss:  0.0005501852720044553
Valid Loss:  0.0010738992132246494
Epoch:  88  	Training Loss: 0.000826369330752641
Test Loss:  0.0005441657267510891
Valid Loss:  0.0010638744570314884
Epoch:  89  	Training Loss: 0.0008216553833335638
Test Loss:  0.0005390066071413457
Valid Loss:  0.0010571777820587158
Epoch:  90  	Training Loss: 0.0008182846941053867
Test Loss:  0.000534678460098803
Valid Loss:  0.0010511244181543589
Epoch:  91  	Training Loss: 0.0008153185481205583
Test Loss:  0.0005308688851073384
Valid Loss:  0.001045769895426929
Epoch:  92  	Training Loss: 0.000812158512417227
Test Loss:  0.0005256893928162754
Valid Loss:  0.0010345896007493138
Epoch:  93  	Training Loss: 0.000806662137620151
Test Loss:  0.0005228699301369488
Valid Loss:  0.0010275666136294603
Epoch:  94  	Training Loss: 0.0008032760815694928
Test Loss:  0.0005210775416344404
Valid Loss:  0.0010229687904939055
Epoch:  95  	Training Loss: 0.000800970068667084
Test Loss:  0.0005198604776524007
Valid Loss:  0.0010198302334174514
Epoch:  96  	Training Loss: 0.0007992463652044535
Test Loss:  0.000518809596542269
Valid Loss:  0.0010176044888794422
Epoch:  97  	Training Loss: 0.0007978555513545871
Test Loss:  0.0005179430008865893
Valid Loss:  0.0010159672237932682
Epoch:  98  	Training Loss: 0.0007966706180013716
Test Loss:  0.0005171900265850127
Valid Loss:  0.0010147213470190763
Epoch:  99  	Training Loss: 0.0007956250919960439
Test Loss:  0.0005165159818716347
Valid Loss:  0.0010137438075616956
Epoch:  100  	Training Loss: 0.0007946832338348031
Test Loss:  0.0005159019492566586
Valid Loss:  0.001012955792248249
Epoch:  101  	Training Loss: 0.0007938074413686991
Test Loss:  0.0005152966477908194
Valid Loss:  0.001012294553220272
Epoch:  102  	Training Loss: 0.0007929593557491899
Test Loss:  0.0005144273163750768
Valid Loss:  0.0010101940715685487
Epoch:  103  	Training Loss: 0.0007914053276181221
Test Loss:  0.000513650244101882
Valid Loss:  0.0010083864908665419
Epoch:  104  	Training Loss: 0.0007900092750787735
Test Loss:  0.0005129225901328027
Valid Loss:  0.0010067997500300407
Epoch:  105  	Training Loss: 0.0007887253304943442
Test Loss:  0.0005121446447446942
Valid Loss:  0.0010053250007331371
Epoch:  106  	Training Loss: 0.0007874334696680307
Test Loss:  0.0005111962673254311
Valid Loss:  0.001003701938316226
Epoch:  107  	Training Loss: 0.0007859335746616125
Test Loss:  0.0005103080184198916
Valid Loss:  0.0010021625785157084
Epoch:  108  	Training Loss: 0.0007844110950827599
Test Loss:  0.0005092457286082208
Valid Loss:  0.0010005694348365068
Epoch:  109  	Training Loss: 0.0007828049128875136
Test Loss:  0.0005080530536361039
Valid Loss:  0.0009989984100684524
Epoch:  110  	Training Loss: 0.0007812121766619384
Test Loss:  0.0005067312158644199
Valid Loss:  0.0009973628912121058
Epoch:  111  	Training Loss: 0.0007792238611727953
Test Loss:  0.0005054160719737411
Valid Loss:  0.0009957668371498585
Epoch:  112  	Training Loss: 0.0007772772805765271
Test Loss:  0.0005054467474110425
Valid Loss:  0.000995641341432929
Epoch:  113  	Training Loss: 0.0007772755925543606
Test Loss:  0.0005054631037637591
Valid Loss:  0.0009955794084817171
Epoch:  114  	Training Loss: 0.0007772751851007342
Test Loss:  0.0005054700886830688
Valid Loss:  0.0009955497225746512
Epoch:  115  	Training Loss: 0.0007772753015160561
Test Loss:  0.0005054740468040109
Valid Loss:  0.0009955351706594229
Epoch:  116  	Training Loss: 0.0007772754179313779
Test Loss:  0.0005054756766185164
Valid Loss:  0.0009955279529094696
Epoch:  117  	Training Loss: 0.0007772754179313779
Test Loss:  0.0005054770736023784
Valid Loss:  0.0009955239947885275
Epoch:  118  	Training Loss: 0.0007772754179313779
Test Loss:  0.000505476666148752
Valid Loss:  0.0009955227142199874
Epoch:  119  	Training Loss: 0.0007772752433083951
Test Loss:  0.0005054773646406829
Valid Loss:  0.000995521666482091
Epoch:  120  	Training Loss: 0.0007772753015160561
Test Loss:  0.0005054775392636657
Valid Loss:  0.000995521666482091
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.0007772752433083951
Test Loss:  0.0005035112844780087
Valid Loss:  0.0009979854803532362
Epoch:  122  	Training Loss: 0.0007748727803118527
Test Loss:  0.0005031198961660266
Valid Loss:  0.0009993503335863352
Epoch:  123  	Training Loss: 0.0007742412271909416
Test Loss:  0.000502958835568279
Valid Loss:  0.0009997203014791012
Epoch:  124  	Training Loss: 0.0007738785352557898
Test Loss:  0.0005028499872423708
Valid Loss:  0.0009996519656851888
Epoch:  125  	Training Loss: 0.0007735851686447859
Test Loss:  0.0005027660517953336
Valid Loss:  0.0009994148276746273
Epoch:  126  	Training Loss: 0.0007733252714388072
Test Loss:  0.0005026990547776222
Valid Loss:  0.0009991242550313473
Epoch:  127  	Training Loss: 0.0007730903453193605
Test Loss:  0.0005026466096751392
Valid Loss:  0.0009988283272832632
Epoch:  128  	Training Loss: 0.0007728781783953309
Test Loss:  0.0005026086582802236
Valid Loss:  0.0009985449723899364
Epoch:  129  	Training Loss: 0.000772685743868351
Test Loss:  0.0005025817081332207
Valid Loss:  0.000998278963379562
Epoch:  130  	Training Loss: 0.0007725115865468979
Test Loss:  0.0005025643040426075
Valid Loss:  0.0009980311151593924
Epoch:  131  	Training Loss: 0.0007723534945398569
Test Loss:  0.0005025555728934705
Valid Loss:  0.0009978037560358644
Epoch:  132  	Training Loss: 0.0007722104201093316
Test Loss:  0.0005025448044762015
Valid Loss:  0.000998040777631104
Epoch:  133  	Training Loss: 0.0007721869042143226
Test Loss:  0.0005025399150326848
Valid Loss:  0.0009982050396502018
Epoch:  134  	Training Loss: 0.0007721695583313704
Test Loss:  0.0005025361897423863
Valid Loss:  0.0009983171476051211
Epoch:  135  	Training Loss: 0.0007721547153778374
Test Loss:  0.0005025346763432026
Valid Loss:  0.000998395262286067
Epoch:  136  	Training Loss: 0.0007721416186541319
Test Loss:  0.0005025325808674097
Valid Loss:  0.0009984492789953947
Epoch:  137  	Training Loss: 0.0007721290457993746
Test Loss:  0.0005025317659601569
Valid Loss:  0.0009984866483137012
Epoch:  138  	Training Loss: 0.0007721171132288873
Test Loss:   28%|██▊       | 139/500 [01:53<02:13,  2.70it/s] 28%|██▊       | 141/500 [02:00<07:06,  1.19s/it] 29%|██▊       | 143/500 [02:00<05:05,  1.17it/s] 29%|██▉       | 145/500 [02:00<03:39,  1.62it/s] 29%|██▉       | 147/500 [02:00<02:39,  2.21it/s] 30%|██▉       | 149/500 [02:00<01:58,  2.96it/s] 30%|███       | 151/500 [02:06<06:49,  1.17s/it] 31%|███       | 153/500 [02:06<04:53,  1.18it/s] 31%|███       | 155/500 [02:07<03:30,  1.64it/s] 31%|███▏      | 157/500 [02:07<02:33,  2.23it/s] 32%|███▏      | 159/500 [02:07<01:53,  3.00it/s] 32%|███▏      | 161/500 [02:13<06:41,  1.18s/it] 33%|███▎      | 163/500 [02:13<04:46,  1.18it/s] 33%|███▎      | 165/500 [02:13<03:26,  1.62it/s] 33%|███▎      | 167/500 [02:14<02:30,  2.22it/s] 34%|███▍      | 169/500 [02:14<01:51,  2.97it/s] 34%|███▍      | 171/500 [02:20<06:32,  1.19s/it] 35%|███▍      | 173/500 [02:20<04:40,  1.17it/s] 35%|███▌      | 175/500 [02:20<03:21,  1.61it/s] 35%|███▌      | 177/500 [02:21<02:26,  2.20it/s] 36%|███▌      | 179/500 [02:21<01:48,  2.97it/s] 36%|███▌      | 181/500 [02:27<06:13,  1.17s/it] 37%|███▋      | 183/500 [02:27<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:27<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:27<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:27<01:43,  3.02it/s] 38%|███▊      | 191/500 [02:34<05:59,  1.16s/it] 39%|███▊      | 193/500 [02:34<04:16,  1.20it/s] 39%|███▉      | 195/500 [02:34<03:05,  1.64it/s] 39%|███▉      | 197/500 [02:34<02:17,  2.20it/s] 40%|███▉      | 199/500 [02:34<01:42,  2.95it/s] 40%|████      | 201/500 [02:40<05:49,  1.17s/it] 41%|████      | 203/500 [02:41<04:09,  1.19it/s] 41%|████      | 205/500 [02:41<02:59,  1.64it/s]0.0005025304271839559
Valid Loss:  0.000998515053652227
Epoch:  139  	Training Loss: 0.0007721056463196874
Test Loss:  0.000502530368976295
Valid Loss:  0.0009985340293496847
Epoch:  140  	Training Loss: 0.0007720940047875047
Test Loss:  0.0005025290884077549
Valid Loss:  0.0009985491633415222
Epoch:  141  	Training Loss: 0.0007720831781625748
Test Loss:  0.0005025286227464676
Valid Loss:  0.0009985592914745212
Epoch:  142  	Training Loss: 0.0007720724097453058
Test Loss:  0.000502475188113749
Valid Loss:  0.000997812021523714
Epoch:  143  	Training Loss: 0.0007718921406194568
Test Loss:  0.0005024545826017857
Valid Loss:  0.00099721341393888
Epoch:  144  	Training Loss: 0.0007717647822573781
Test Loss:  0.0005024640122428536
Valid Loss:  0.0009967314545065165
Epoch:  145  	Training Loss: 0.0007716781692579389
Test Loss:  0.0005024919519200921
Valid Loss:  0.0009963237680494785
Epoch:  146  	Training Loss: 0.0007716162363067269
Test Loss:  0.0005025334539823234
Valid Loss:  0.0009960024617612362
Epoch:  147  	Training Loss: 0.0007715741521678865
Test Loss:  0.0005025767022743821
Valid Loss:  0.0009957252768799663
Epoch:  148  	Training Loss: 0.0007715425454080105
Test Loss:  0.0005026200087741017
Valid Loss:  0.0009954883717000484
Epoch:  149  	Training Loss: 0.0007715176325291395
Test Loss:  0.0005026611033827066
Valid Loss:  0.0009952844120562077
Epoch:  150  	Training Loss: 0.0007714983075857162
Test Loss:  0.0005027003353461623
Valid Loss:  0.0009951081592589617
Epoch:  151  	Training Loss: 0.0007714831735938787
Test Loss:  0.000502736191265285
Valid Loss:  0.000994955888018012
Epoch:  152  	Training Loss: 0.0007714711828157306
Test Loss:  0.0005024910788051784
Valid Loss:  0.000995537731796503
Epoch:  153  	Training Loss: 0.0007710743229836226
Test Loss:  0.0005024028359912336
Valid Loss:  0.0009954679990187287
Epoch:  154  	Training Loss: 0.000770790153183043
Test Loss:  0.0005023609264753759
Valid Loss:  0.0009952520485967398
Epoch:  155  	Training Loss: 0.0007705580210313201
Test Loss:  0.0005023389821872115
Valid Loss:  0.0009950139792636037
Epoch:  156  	Training Loss: 0.0007703634910285473
Test Loss:  0.0005023253615945578
Valid Loss:  0.000994784408248961
Epoch:  157  	Training Loss: 0.0007701996946707368
Test Loss:  0.0005023166304454207
Valid Loss:  0.0009945834754034877
Epoch:  158  	Training Loss: 0.00077006098581478
Test Loss:  0.0005023099947720766
Valid Loss:  0.0009944045450538397
Epoch:  159  	Training Loss: 0.0007699424168094993
Test Loss:  0.000502305047120899
Valid Loss:  0.0009942433098331094
Epoch:  160  	Training Loss: 0.0007698404369875789
Test Loss:  0.000502299633808434
Valid Loss:  0.0009940998861566186
Epoch:  161  	Training Loss: 0.0007697514956817031
Test Loss:  0.0005022931145504117
Valid Loss:  0.000993969151750207
Epoch:  162  	Training Loss: 0.0007696744287386537
Test Loss:  0.0005022441619075835
Valid Loss:  0.0009940358577296138
Epoch:  163  	Training Loss: 0.0007695932872593403
Test Loss:  0.0005022143013775349
Valid Loss:  0.000993948895484209
Epoch:  164  	Training Loss: 0.0007695166277699172
Test Loss:  0.0005021865945309401
Valid Loss:  0.0009938603034242988
Epoch:  165  	Training Loss: 0.0007694419473409653
Test Loss:  0.0005021612159907818
Valid Loss:  0.0009937763679772615
Epoch:  166  	Training Loss: 0.0007693702355027199
Test Loss:  0.0005021372344344854
Valid Loss:  0.0009936948772519827
Epoch:  167  	Training Loss: 0.0007693006191402674
Test Loss:  0.0005021140677854419
Valid Loss:  0.0009936171118170023
Epoch:  168  	Training Loss: 0.0007692337385378778
Test Loss:  0.0005020928801968694
Valid Loss:  0.0009935435373336077
Epoch:  169  	Training Loss: 0.0007691684877499938
Test Loss:  0.0005020721000619233
Valid Loss:  0.0009934722911566496
Epoch:  170  	Training Loss: 0.0007691020146012306
Test Loss:  0.0005020484095439315
Valid Loss:  0.0009933970868587494
Epoch:  171  	Training Loss: 0.0007690240163356066
Test Loss:  0.0005020286189392209
Valid Loss:  0.0009933190885931253
Epoch:  172  	Training Loss: 0.00076894840458408
Test Loss:  0.0005014354828745127
Valid Loss:  0.0009921807795763016
Epoch:  173  	Training Loss: 0.0007683330914005637
Test Loss:  0.0005008358275517821
Valid Loss:  0.0009911359520629048
Epoch:  174  	Training Loss: 0.0007677177782170475
Test Loss:  0.0005002353573217988
Valid Loss:  0.0009901365265250206
Epoch:  175  	Training Loss: 0.000767107994761318
Test Loss:  0.000499636575113982
Valid Loss:  0.00098916026763618
Epoch:  176  	Training Loss: 0.0007665039738640189
Test Loss:  0.0004990430315956473
Valid Loss:  0.0009881975129246712
Epoch:  177  	Training Loss: 0.0007659046677872539
Test Loss:  0.0004984508268535137
Valid Loss:  0.0009872413938865066
Epoch:  178  	Training Loss: 0.0007653111824765801
Test Loss:  0.0004978646757081151
Valid Loss:  0.0009862934239208698
Epoch:  179  	Training Loss: 0.0007647180464118719
Test Loss:  0.0004972821334376931
Valid Loss:  0.0009853499941527843
Epoch:  180  	Training Loss: 0.0007641218835487962
Test Loss:  0.0004967040731571615
Valid Loss:  0.000984412501566112
Epoch:  181  	Training Loss: 0.0007635318906977773
Test Loss:  0.0004961294471286237
Valid Loss:  0.0009834798984229565
Epoch:  182  	Training Loss: 0.0007629472529515624
Test Loss:  0.0004845909425057471
Valid Loss:  0.000963619735557586
Epoch:  183  	Training Loss: 0.0007533440366387367
Test Loss:  0.00047836327576078475
Valid Loss:  0.0009516851278021932
Epoch:  184  	Training Loss: 0.0007485261303372681
Test Loss:  0.0004744024481624365
Valid Loss:  0.0009434447856619954
Epoch:  185  	Training Loss: 0.0007457792526111007
Test Loss:  0.00047211741912178695
Valid Loss:  0.0009382171556353569
Epoch:  186  	Training Loss: 0.0007444671937264502
Test Loss:  0.00047076091868802905
Valid Loss:  0.0009348109597340226
Epoch:  187  	Training Loss: 0.000743861251976341
Test Loss:  0.00046992802526801825
Valid Loss:  0.0009325554710812867
Epoch:  188  	Training Loss: 0.0007435711449943483
Test Loss:  0.00046940837637521327
Valid Loss:  0.0009310441673733294
Epoch:  189  	Training Loss: 0.0007434299914166331
Test Loss:  0.0004690798232331872
Valid Loss:  0.0009300220408476889
Epoch:  190  	Training Loss: 0.0007433608407154679
Test Loss:  0.00046887382632121444
Valid Loss:  0.0009293275652453303
Epoch:  191  	Training Loss: 0.0007433185237459838
Test Loss:  0.00046854582615196705
Valid Loss:  0.0009282087557949126
Epoch:  192  	Training Loss: 0.0007432242855429649
Test Loss:  0.0004628855094779283
Valid Loss:  0.000930513022467494
Epoch:  193  	Training Loss: 0.0007369744125753641
Test Loss:  0.00046158168697729707
Valid Loss:  0.0009330168832093477
Epoch:  194  	Training Loss: 0.0007354684639722109
Test Loss:  0.0004612691991496831
Valid Loss:  0.0009345154394395649
Epoch:  195  	Training Loss: 0.0007350662490352988
Test Loss:  0.000461176794487983
Valid Loss:  0.0009352753404527903
Epoch:  196  	Training Loss: 0.0007349216612055898
Test Loss:  0.0004611305776052177
Valid Loss:  0.000935619231313467
Epoch:  197  	Training Loss: 0.0007348374929279089
Test Loss:  0.00046109361574053764
Valid Loss:  0.0009357485687360168
Epoch:  198  	Training Loss: 0.0007347682840190828
Test Loss:  0.0004610576434060931
Valid Loss:  0.0009357710368931293
Epoch:  199  	Training Loss: 0.0007347026839852333
Test Loss:  0.0004610218747984618
Valid Loss:  0.0009357432718388736
Epoch:  200  	Training Loss: 0.0007346387719735503
Test Loss:  0.000460986775578931
Valid Loss:  0.0009356897789984941
Epoch:  201  	Training Loss: 0.0007345749181695282
Test Loss:  0.000460951094282791
Valid Loss:  0.000935625983402133
Epoch:  202  	Training Loss: 0.0007345111225731671
Test Loss:  0.00046085903886705637
Valid Loss:  0.0009355255169793963
Epoch:  203  	Training Loss: 0.0007344399928115308
Test Loss:  0.0004607890732586384
Valid Loss:  0.0009354312787763774
Epoch:  204  	Training Loss: 0.0007343695615418255
Test Loss:  0.0004607388691511005
Valid Loss:  0.0009353398345410824
Epoch:  205  	Training Loss: 0.0007343008182942867
Test Loss:  0.00046069009113125503
Valid Loss:  0.0009352511260658503
Epoch:  206  	Training Loss: 0.0007342362077906728
Test Loss:  0.0004606490838341415
Valid Loss:   41%|████▏     | 207/500 [02:41<02:10,  2.25it/s] 42%|████▏     | 209/500 [02:41<01:36,  3.02it/s] 42%|████▏     | 211/500 [02:47<05:37,  1.17s/it] 43%|████▎     | 213/500 [02:47<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:48<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:48<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:48<01:33,  3.01it/s] 44%|████▍     | 221/500 [02:54<05:31,  1.19s/it] 45%|████▍     | 223/500 [02:54<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:54<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:55<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:55<01:31,  2.97it/s] 46%|████▌     | 231/500 [03:01<05:13,  1.17s/it] 47%|████▋     | 233/500 [03:01<03:43,  1.19it/s] 47%|████▋     | 235/500 [03:01<02:40,  1.65it/s] 47%|████▋     | 237/500 [03:01<01:56,  2.25it/s] 48%|████▊     | 239/500 [03:01<01:26,  3.03it/s] 48%|████▊     | 241/500 [03:08<05:01,  1.16s/it] 49%|████▊     | 243/500 [03:08<03:35,  1.20it/s] 49%|████▉     | 245/500 [03:08<02:34,  1.65it/s] 49%|████▉     | 247/500 [03:08<01:52,  2.25it/s] 50%|████▉     | 249/500 [03:08<01:22,  3.02it/s] 50%|█████     | 251/500 [03:14<04:49,  1.16s/it] 51%|█████     | 253/500 [03:15<03:26,  1.20it/s] 51%|█████     | 255/500 [03:15<02:28,  1.65it/s] 51%|█████▏    | 257/500 [03:15<01:47,  2.26it/s] 52%|█████▏    | 259/500 [03:15<01:19,  3.04it/s] 52%|█████▏    | 261/500 [03:21<04:36,  1.16s/it] 53%|█████▎    | 263/500 [03:21<03:16,  1.20it/s] 53%|█████▎    | 265/500 [03:21<02:21,  1.66it/s] 53%|█████▎    | 267/500 [03:22<01:42,  2.26it/s] 54%|█████▍    | 269/500 [03:22<01:16,  3.04it/s] 54%|█████▍    | 271/500 [03:28<04:26,  1.17s/it] 55%|█████▍    | 273/500 [03:28<03:10,  1.19it/s]0.0009351761545985937
Epoch:  207  	Training Loss: 0.0007341790478676558
Test Loss:  0.0004606144211720675
Valid Loss:  0.0009351103799417615
Epoch:  208  	Training Loss: 0.0007341232849285007
Test Loss:  0.00046058080624789
Valid Loss:  0.0009350392501801252
Epoch:  209  	Training Loss: 0.0007340682204812765
Test Loss:  0.00046054820995777845
Valid Loss:  0.0009349651518277824
Epoch:  210  	Training Loss: 0.0007340148440562189
Test Loss:  0.0004605278663802892
Valid Loss:  0.0009349140455015004
Epoch:  211  	Training Loss: 0.0007339604781009257
Test Loss:  0.0004604965215548873
Valid Loss:  0.0009348312160000205
Epoch:  212  	Training Loss: 0.0007339066360145807
Test Loss:  0.00046048726653680205
Valid Loss:  0.0009348469320684671
Epoch:  213  	Training Loss: 0.0007338933646678925
Test Loss:  0.00046047961222939193
Valid Loss:  0.0009348597377538681
Epoch:  214  	Training Loss: 0.0007338809664361179
Test Loss:  0.00046047085197642446
Valid Loss:  0.0009348690509796143
Epoch:  215  	Training Loss: 0.0007338680443353951
Test Loss:  0.0004604624991770834
Valid Loss:  0.000934877316467464
Epoch:  216  	Training Loss: 0.0007338551222346723
Test Loss:  0.00046045437920838594
Valid Loss:  0.0009348822059109807
Epoch:  217  	Training Loss: 0.0007338427240028977
Test Loss:  0.0004604462010320276
Valid Loss:  0.0009348870371468365
Epoch:  218  	Training Loss: 0.0007338296272791922
Test Loss:  0.000460437877336517
Valid Loss:  0.0009348891908302903
Epoch:  219  	Training Loss: 0.0007338178111240268
Test Loss:  0.0004604298737831414
Valid Loss:  0.0009348903549835086
Epoch:  220  	Training Loss: 0.0007338057039305568
Test Loss:  0.0004604214336723089
Valid Loss:  0.0009348905878141522
Epoch:  221  	Training Loss: 0.000733793480321765
Test Loss:  0.0004604127025231719
Valid Loss:  0.0009348905296064913
Epoch:  222  	Training Loss: 0.0007337818969972432
Test Loss:  0.0004600092943292111
Valid Loss:  0.000934091629460454
Epoch:  223  	Training Loss: 0.0007333123357966542
Test Loss:  0.0004596096114255488
Valid Loss:  0.0009333908674307168
Epoch:  224  	Training Loss: 0.0007328466163016856
Test Loss:  0.00045921423588879406
Valid Loss:  0.0009325596038252115
Epoch:  225  	Training Loss: 0.0007323847385123372
Test Loss:  0.0004588218289427459
Valid Loss:  0.0009317338699474931
Epoch:  226  	Training Loss: 0.0007319258875213563
Test Loss:  0.00045843212865293026
Valid Loss:  0.000930915295612067
Epoch:  227  	Training Loss: 0.0007314711110666394
Test Loss:  0.0004580459790304303
Valid Loss:  0.0009301026584580541
Epoch:  228  	Training Loss: 0.00073101872112602
Test Loss:  0.0004576626524794847
Valid Loss:  0.0009292952017858624
Epoch:  229  	Training Loss: 0.0007305702893063426
Test Loss:  0.0004572821198962629
Valid Loss:  0.0009284924017265439
Epoch:  230  	Training Loss: 0.0007301248842850327
Test Loss:  0.0004569044103845954
Valid Loss:  0.0009276947821490467
Epoch:  231  	Training Loss: 0.0007296829717233777
Test Loss:  0.00045653065899387
Valid Loss:  0.0009269034489989281
Epoch:  232  	Training Loss: 0.0007292443769983947
Test Loss:  0.0004559838562272489
Valid Loss:  0.0009243169333785772
Epoch:  233  	Training Loss: 0.000728266779333353
Test Loss:  0.00045569235226139426
Valid Loss:  0.0009223821689374745
Epoch:  234  	Training Loss: 0.0007275865646079183
Test Loss:  0.000455552275525406
Valid Loss:  0.0009209149284288287
Epoch:  235  	Training Loss: 0.0007271005306392908
Test Loss:  0.00045549863716587424
Valid Loss:  0.0009197922190651298
Epoch:  236  	Training Loss: 0.0007267441833391786
Test Loss:  0.0004554911283776164
Valid Loss:  0.000918920966796577
Epoch:  237  	Training Loss: 0.0007264709565788507
Test Loss:  0.00045550643699243665
Valid Loss:  0.0009182380745187402
Epoch:  238  	Training Loss: 0.0007262538420036435
Test Loss:  0.0004555285850074142
Valid Loss:  0.0009176965686492622
Epoch:  239  	Training Loss: 0.0007260751444846392
Test Loss:  0.00045555311953648925
Valid Loss:  0.0009172632126137614
Epoch:  240  	Training Loss: 0.0007259214180521667
Test Loss:  0.00045557209523394704
Valid Loss:  0.000916913035325706
Epoch:  241  	Training Loss: 0.0007257856195792556
Test Loss:  0.0004555856576189399
Valid Loss:  0.0009166274685412645
Epoch:  242  	Training Loss: 0.0007256617536768317
Test Loss:  0.00045146304182708263
Valid Loss:  0.0009106919169425964
Epoch:  243  	Training Loss: 0.0007208766764961183
Test Loss:  0.0004481020150706172
Valid Loss:  0.0009058830328285694
Epoch:  244  	Training Loss: 0.0007172430632635951
Test Loss:  0.0004467185353860259
Valid Loss:  0.000904002517927438
Epoch:  245  	Training Loss: 0.0007156610954552889
Test Loss:  0.00044576378422789276
Valid Loss:  0.000902923580724746
Epoch:  246  	Training Loss: 0.0007146982243284583
Test Loss:  0.00044520379742607474
Valid Loss:  0.0009022332960739732
Epoch:  247  	Training Loss: 0.000713992805685848
Test Loss:  0.00044476252514868975
Valid Loss:  0.000901568797416985
Epoch:  248  	Training Loss: 0.0007133904728107154
Test Loss:  0.0004444831283763051
Valid Loss:  0.0009010141366161406
Epoch:  249  	Training Loss: 0.0007129042642191052
Test Loss:  0.0004443058860488236
Valid Loss:  0.000900645914953202
Epoch:  250  	Training Loss: 0.0007125029806047678
Test Loss:  0.00044420096674002707
Valid Loss:  0.0009003650629892945
Epoch:  251  	Training Loss: 0.0007121526869013906
Test Loss:  0.000444116914877668
Valid Loss:  0.000900126644410193
Epoch:  252  	Training Loss: 0.0007118212524801493
Test Loss:  0.0004437478492036462
Valid Loss:  0.0009007983608171344
Epoch:  253  	Training Loss: 0.000711380154825747
Test Loss:  0.0004435479349922389
Valid Loss:  0.0009010114008560777
Epoch:  254  	Training Loss: 0.0007110793376341462
Test Loss:  0.00044340721797198057
Valid Loss:  0.0009009269415400922
Epoch:  255  	Training Loss: 0.0007108219433575869
Test Loss:  0.0004432938585523516
Valid Loss:  0.000900738756172359
Epoch:  256  	Training Loss: 0.0007105869008228183
Test Loss:  0.0004431964480318129
Valid Loss:  0.0009005090687423944
Epoch:  257  	Training Loss: 0.0007103682728484273
Test Loss:  0.00044311038800515234
Valid Loss:  0.0009002677397802472
Epoch:  258  	Training Loss: 0.0007101634400896728
Test Loss:  0.00044303221511654556
Valid Loss:  0.0009000268764793873
Epoch:  259  	Training Loss: 0.0007099703652784228
Test Loss:  0.00044296198757365346
Valid Loss:  0.0008997952099889517
Epoch:  260  	Training Loss: 0.0007097820052877069
Test Loss:  0.00044289109064266086
Valid Loss:  0.000899560924153775
Epoch:  261  	Training Loss: 0.0007095843320712447
Test Loss:  0.00044282854651100934
Valid Loss:  0.0008993328083306551
Epoch:  262  	Training Loss: 0.0007093962049111724
Test Loss:  0.00044272837112657726
Valid Loss:  0.0008982502622529864
Epoch:  263  	Training Loss: 0.0007089888677000999
Test Loss:  0.0004426914674695581
Valid Loss:  0.0008974882075563073
Epoch:  264  	Training Loss: 0.0007087257690727711
Test Loss:  0.0004426747909747064
Valid Loss:  0.0008969402406364679
Epoch:  265  	Training Loss: 0.0007085361867211759
Test Loss:  0.0004426739178597927
Valid Loss:  0.0008965447777882218
Epoch:  266  	Training Loss: 0.0007083983509801328
Test Loss:  0.0004426800296641886
Valid Loss:  0.0008962347055785358
Epoch:  267  	Training Loss: 0.0007082895608618855
Test Loss:  0.00044270456419326365
Valid Loss:  0.0008959771366789937
Epoch:  268  	Training Loss: 0.0007081881631165743
Test Loss:  0.0004427218227647245
Valid Loss:  0.000895785866305232
Epoch:  269  	Training Loss: 0.0007080954965204
Test Loss:  0.00044273154344409704
Valid Loss:  0.0008956317324191332
Epoch:  270  	Training Loss: 0.0007080108625814319
Test Loss:  0.00044275468098931015
Valid Loss:  0.0008955053053796291
Epoch:  271  	Training Loss: 0.0007079342612996697
Test Loss:  0.00044277531560510397
Valid Loss:  0.000895421311724931
Epoch:  272  	Training Loss: 0.0007078858907334507
Test Loss:  0.0004371931136120111
Valid Loss:  0.000882294843904674
Epoch:  273  	Training Loss: 0.000702701392583549
Test Loss:  0.00043379812268540263
Valid Loss:  0.0008734021103009582
Epoch:  274  	Training Loss: 0.0006996386800892651
Test Loss:  0.00043178407941013575
Valid Loss:  0.000867811031639576
 55%|█████▌    | 275/500 [03:28<02:16,  1.65it/s] 55%|█████▌    | 277/500 [03:28<01:38,  2.25it/s] 56%|█████▌    | 279/500 [03:28<01:13,  3.02it/s] 56%|█████▌    | 281/500 [03:35<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:35<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:35<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:35<01:37,  2.19it/s] 58%|█████▊    | 289/500 [03:35<01:12,  2.90it/s] 58%|█████▊    | 291/500 [03:42<04:10,  1.20s/it] 59%|█████▊    | 293/500 [03:42<02:58,  1.16it/s] 59%|█████▉    | 295/500 [03:42<02:07,  1.61it/s] 59%|█████▉    | 297/500 [03:42<01:32,  2.19it/s] 60%|█████▉    | 299/500 [03:42<01:08,  2.93it/s] 60%|██████    | 301/500 [03:49<03:56,  1.19s/it] 61%|██████    | 303/500 [03:49<02:47,  1.17it/s] 61%|██████    | 305/500 [03:49<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:49<01:26,  2.22it/s] 62%|██████▏   | 309/500 [03:49<01:04,  2.98it/s] 62%|██████▏   | 311/500 [03:56<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:56<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:56<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:56<01:22,  2.23it/s] 64%|██████▍   | 319/500 [03:56<01:00,  2.99it/s] 64%|██████▍   | 321/500 [04:02<03:29,  1.17s/it] 65%|██████▍   | 323/500 [04:02<02:28,  1.19it/s] 65%|██████▌   | 325/500 [04:03<01:46,  1.64it/s] 65%|██████▌   | 327/500 [04:03<01:17,  2.25it/s] 66%|██████▌   | 329/500 [04:03<00:56,  3.02it/s] 66%|██████▌   | 331/500 [04:09<03:18,  1.17s/it] 67%|██████▋   | 333/500 [04:09<02:20,  1.19it/s] 67%|██████▋   | 335/500 [04:09<01:40,  1.64it/s] 67%|██████▋   | 337/500 [04:10<01:13,  2.23it/s] 68%|██████▊   | 339/500 [04:10<00:53,  2.99it/s] 68%|██████▊   | 341/500 [04:16<03:05,  1.17s/it]Epoch:  275  	Training Loss: 0.0006980178877711296
Test Loss:  0.0004304497560951859
Valid Loss:  0.0008641358581371605
Epoch:  276  	Training Loss: 0.0006970416288822889
Test Loss:  0.00042947300244122744
Valid Loss:  0.0008616081322543323
Epoch:  277  	Training Loss: 0.0006963596679270267
Test Loss:  0.00042869121534749866
Valid Loss:  0.0008597886189818382
Epoch:  278  	Training Loss: 0.0006958134472370148
Test Loss:  0.00042803294491022825
Valid Loss:  0.0008584087481722236
Epoch:  279  	Training Loss: 0.0006953395204618573
Test Loss:  0.0004274577659089118
Valid Loss:  0.0008573129307478666
Epoch:  280  	Training Loss: 0.0006948484806343913
Test Loss:  0.00042682254570536315
Valid Loss:  0.0008557341061532497
Epoch:  281  	Training Loss: 0.0006943229818716645
Test Loss:  0.00042626820504665375
Valid Loss:  0.0008545075543224812
Epoch:  282  	Training Loss: 0.0006938483566045761
Test Loss:  0.0004258307162672281
Valid Loss:  0.0008544931188225746
Epoch:  283  	Training Loss: 0.0006933615659363568
Test Loss:  0.0004254237865097821
Valid Loss:  0.0008544892771169543
Epoch:  284  	Training Loss: 0.0006929070223122835
Test Loss:  0.00042504421435296535
Valid Loss:  0.0008544963202439249
Epoch:  285  	Training Loss: 0.000692482921294868
Test Loss:  0.000424689962528646
Valid Loss:  0.0008545118034817278
Epoch:  286  	Training Loss: 0.0006920866435393691
Test Loss:  0.0004243602161295712
Valid Loss:  0.0008545350865460932
Epoch:  287  	Training Loss: 0.0006917163846082985
Test Loss:  0.0004240519483573735
Valid Loss:  0.0008545633172616363
Epoch:  288  	Training Loss: 0.0006913696997798979
Test Loss:  0.00042376393685117364
Valid Loss:  0.0008545990567654371
Epoch:  289  	Training Loss: 0.0006910450174473226
Test Loss:  0.0004234949010424316
Valid Loss:  0.0008546389872208238
Epoch:  290  	Training Loss: 0.0006907424540258944
Test Loss:  0.0004232437931932509
Valid Loss:  0.0008546829922124743
Epoch:  291  	Training Loss: 0.0006904597394168377
Test Loss:  0.0004230093618389219
Valid Loss:  0.0008547298493795097
Epoch:  292  	Training Loss: 0.0006901960587128997
Test Loss:  0.0004212217463646084
Valid Loss:  0.0008560771821066737
Epoch:  293  	Training Loss: 0.0006882996531203389
Test Loss:  0.0004207867314107716
Valid Loss:  0.000857075909152627
Epoch:  294  	Training Loss: 0.0006877058767713606
Test Loss:  0.0004206558223813772
Valid Loss:  0.0008576582185924053
Epoch:  295  	Training Loss: 0.0006874583777971566
Test Loss:  0.00042060401756316423
Valid Loss:  0.0008579618879593909
Epoch:  296  	Training Loss: 0.000687338993884623
Test Loss:  0.0004205726436339319
Valid Loss:  0.0008580799913033843
Epoch:  297  	Training Loss: 0.0006872551748529077
Test Loss:  0.0004205442382954061
Valid Loss:  0.0008580888388678432
Epoch:  298  	Training Loss: 0.0006871949881315231
Test Loss:  0.0004205166478641331
Valid Loss:  0.0008580615976825356
Epoch:  299  	Training Loss: 0.000687138584908098
Test Loss:  0.00042049033800140023
Valid Loss:  0.00085801025852561
Epoch:  300  	Training Loss: 0.0006870829383842647
Test Loss:  0.000420463242335245
Valid Loss:  0.0008579526911489666
Epoch:  301  	Training Loss: 0.0006870274664834142
Test Loss:  0.0004204368160571903
Valid Loss:  0.0008578931447118521
Epoch:  302  	Training Loss: 0.0006869721692055464
Test Loss:  0.00042012782068923116
Valid Loss:  0.0008563303854316473
Epoch:  303  	Training Loss: 0.0006862339214421809
Test Loss:  0.00041983393020927906
Valid Loss:  0.0008557281689718366
Epoch:  304  	Training Loss: 0.0006855794927105308
Test Loss:  0.00041960616363212466
Valid Loss:  0.0008549571502953768
Epoch:  305  	Training Loss: 0.000684990780428052
Test Loss:  0.00041941413655877113
Valid Loss:  0.0008543349104002118
Epoch:  306  	Training Loss: 0.0006844642339274287
Test Loss:  0.0004192811611574143
Valid Loss:  0.0008534959051758051
Epoch:  307  	Training Loss: 0.0006839922862127423
Test Loss:  0.0004191212938167155
Valid Loss:  0.0008532747160643339
Epoch:  308  	Training Loss: 0.0006835663225501776
Test Loss:  0.0004190694307908416
Valid Loss:  0.00085242505883798
Epoch:  309  	Training Loss: 0.0006831834325566888
Test Loss:  0.0004189432365819812
Valid Loss:  0.0008523619617335498
Epoch:  310  	Training Loss: 0.0006828390760347247
Test Loss:  0.00041894533205777407
Valid Loss:  0.0008515932713635266
Epoch:  311  	Training Loss: 0.0006825250457040966
Test Loss:  0.00041885802056640387
Valid Loss:  0.0008515500812791288
Epoch:  312  	Training Loss: 0.0006822454743087292
Test Loss:  0.000418837065808475
Valid Loss:  0.000851629301905632
Epoch:  313  	Training Loss: 0.0006822262075729668
Test Loss:  0.00041882949881255627
Valid Loss:  0.0008516426896676421
Epoch:  314  	Training Loss: 0.0006822075229138136
Test Loss:  0.0004188258608337492
Valid Loss:  0.0008516320958733559
Epoch:  315  	Training Loss: 0.0006821899442002177
Test Loss:  0.0004188247839920223
Valid Loss:  0.0008516127709299326
Epoch:  316  	Training Loss: 0.0006821723654866219
Test Loss:  0.0004188239108771086
Valid Loss:  0.0008515881490893662
Epoch:  317  	Training Loss: 0.0006821549031883478
Test Loss:  0.00041882332880049944
Valid Loss:  0.0008515637600794435
Epoch:  318  	Training Loss: 0.0006821374408900738
Test Loss:  0.0004188228049315512
Valid Loss:  0.0008515385561622679
Epoch:  319  	Training Loss: 0.0006821201532147825
Test Loss:  0.00041882190271280706
Valid Loss:  0.0008515141671523452
Epoch:  320  	Training Loss: 0.0006821037386544049
Test Loss:  0.0004188210587017238
Valid Loss:  0.0008514889050275087
Epoch:  321  	Training Loss: 0.0006820864509791136
Test Loss:  0.0004188214079476893
Valid Loss:  0.0008514627115800977
Epoch:  322  	Training Loss: 0.0006820690468885005
Test Loss:  0.00041858083568513393
Valid Loss:  0.0008499814430251718
Epoch:  323  	Training Loss: 0.0006813990767113864
Test Loss:  0.00041836401214823127
Valid Loss:  0.0008486284641548991
Epoch:  324  	Training Loss: 0.0006807886529713869
Test Loss:  0.00041815958684310317
Valid Loss:  0.0008473849156871438
Epoch:  325  	Training Loss: 0.0006802249699831009
Test Loss:  0.00041796406731009483
Valid Loss:  0.0008462307159788907
Epoch:  326  	Training Loss: 0.0006796979578211904
Test Loss:  0.0004177696246188134
Valid Loss:  0.000845150847453624
Epoch:  327  	Training Loss: 0.0006791995256207883
Test Loss:  0.0004175749490968883
Valid Loss:  0.0008441321551799774
Epoch:  328  	Training Loss: 0.000678724842146039
Test Loss:  0.00041737762512639165
Valid Loss:  0.0008431664318777621
Epoch:  329  	Training Loss: 0.0006782698910683393
Test Loss:  0.0004171767504885793
Valid Loss:  0.0008422452956438065
Epoch:  330  	Training Loss: 0.000677829491905868
Test Loss:  0.00041697005508467555
Valid Loss:  0.0008413622854277492
Epoch:  331  	Training Loss: 0.0006773852510377765
Test Loss:  0.0004167349252384156
Valid Loss:  0.00084045430412516
Epoch:  332  	Training Loss: 0.0006769002065993845
Test Loss:  0.00041613075882196426
Valid Loss:  0.0008412681636400521
Epoch:  333  	Training Loss: 0.0006764919962733984
Test Loss:  0.0004159472300671041
Valid Loss:  0.0008416061755269766
Epoch:  334  	Training Loss: 0.000676315336022526
Test Loss:  0.00041590200271457434
Valid Loss:  0.0008416876080445945
Epoch:  335  	Training Loss: 0.0006761933327652514
Test Loss:  0.00041590991895645857
Valid Loss:  0.0008416521595790982
Epoch:  336  	Training Loss: 0.0006760894320905209
Test Loss:  0.00041594039066694677
Valid Loss:  0.0008415692136622965
Epoch:  337  	Training Loss: 0.0006759971147403121
Test Loss:  0.00041598296957090497
Valid Loss:  0.0008414699696004391
Epoch:  338  	Training Loss: 0.0006759135285392404
Test Loss:  0.00041602965211495757
Valid Loss:  0.0008413703180849552
Epoch:  339  	Training Loss: 0.0006758373929187655
Test Loss:  0.0004160797980148345
Valid Loss:  0.0008412726456299424
Epoch:  340  	Training Loss: 0.0006757687078788877
Test Loss:  0.0004161317483521998
Valid Loss:  0.0008411799790337682
Epoch:  341  	Training Loss: 0.0006757060764357448
Test Loss:  0.00041618559043854475
Valid Loss:  0.0008410961017943919
Epoch:  342  	Training Loss: 0.0006756494985893369
Test Loss:  0.000415814109146595
Valid Loss:  0.0008398569189012051
 69%|██████▊   | 343/500 [04:16<02:11,  1.19it/s] 69%|██████▉   | 345/500 [04:16<01:34,  1.65it/s] 69%|██████▉   | 347/500 [04:16<01:08,  2.25it/s] 70%|██████▉   | 349/500 [04:16<00:50,  3.02it/s] 70%|███████   | 351/500 [04:23<02:55,  1.18s/it] 71%|███████   | 353/500 [04:23<02:04,  1.18it/s] 71%|███████   | 355/500 [04:23<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:23<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:23<00:46,  3.00it/s] 72%|███████▏  | 361/500 [04:30<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:30<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:30<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:30<01:00,  2.21it/s] 74%|███████▍  | 369/500 [04:30<00:44,  2.98it/s] 74%|███████▍  | 371/500 [04:36<02:31,  1.17s/it] 75%|███████▍  | 373/500 [04:37<01:47,  1.19it/s] 75%|███████▌  | 375/500 [04:37<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:37<00:55,  2.24it/s] 76%|███████▌  | 379/500 [04:37<00:40,  2.99it/s] 76%|███████▌  | 381/500 [04:43<02:18,  1.17s/it] 77%|███████▋  | 383/500 [04:43<01:37,  1.19it/s] 77%|███████▋  | 385/500 [04:43<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:44<00:50,  2.24it/s] 78%|███████▊  | 389/500 [04:44<00:36,  3.01it/s] 78%|███████▊  | 391/500 [04:50<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:50<01:29,  1.19it/s] 79%|███████▉  | 395/500 [04:50<01:03,  1.65it/s] 79%|███████▉  | 397/500 [04:50<00:45,  2.25it/s] 80%|███████▉  | 399/500 [04:50<00:33,  3.02it/s] 80%|████████  | 401/500 [04:57<01:55,  1.17s/it] 81%|████████  | 403/500 [04:57<01:21,  1.20it/s] 81%|████████  | 405/500 [04:57<00:57,  1.65it/s] 81%|████████▏ | 407/500 [04:57<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:57<00:30,  3.03it/s]Epoch:  343  	Training Loss: 0.0006748667219653726
Test Loss:  0.00041550019523128867
Valid Loss:  0.0008386726258322597
Epoch:  344  	Training Loss: 0.0006741195684298873
Test Loss:  0.00041519920341670513
Valid Loss:  0.0008375318138860166
Epoch:  345  	Training Loss: 0.0006733954651281238
Test Loss:  0.0004149009473621845
Valid Loss:  0.0008362827356904745
Epoch:  346  	Training Loss: 0.0006726996507495642
Test Loss:  0.00041459931526333094
Valid Loss:  0.0008350670104846358
Epoch:  347  	Training Loss: 0.0006720296805724502
Test Loss:  0.0004142984398640692
Valid Loss:  0.0008338990737684071
Epoch:  348  	Training Loss: 0.0006713587208651006
Test Loss:  0.0004139906377531588
Valid Loss:  0.0008327516261488199
Epoch:  349  	Training Loss: 0.0006706748390570283
Test Loss:  0.00041368603706359863
Valid Loss:  0.0008316297899000347
Epoch:  350  	Training Loss: 0.0006700054509565234
Test Loss:  0.0004133747424930334
Valid Loss:  0.0008305241353809834
Epoch:  351  	Training Loss: 0.0006693493924103677
Test Loss:  0.00041303879697807133
Valid Loss:  0.0008293705177493393
Epoch:  352  	Training Loss: 0.0006686384440399706
Test Loss:  0.0004128937143832445
Valid Loss:  0.0008296235464513302
Epoch:  353  	Training Loss: 0.0006685121916234493
Test Loss:  0.0004129018634557724
Valid Loss:  0.0008296389132738113
Epoch:  354  	Training Loss: 0.0006684036343358457
Test Loss:  0.0004129431617911905
Valid Loss:  0.0008296007290482521
Epoch:  355  	Training Loss: 0.0006683038081973791
Test Loss:  0.0004129923472646624
Valid Loss:  0.0008295546285808086
Epoch:  356  	Training Loss: 0.0006682112580165267
Test Loss:  0.00041304060141555965
Valid Loss:  0.0008295084116980433
Epoch:  357  	Training Loss: 0.0006681246450170875
Test Loss:  0.00041308801155537367
Valid Loss:  0.000829468946903944
Epoch:  358  	Training Loss: 0.0006680445512756705
Test Loss:  0.0004131331224925816
Valid Loss:  0.0008294339058920741
Epoch:  359  	Training Loss: 0.0006679692305624485
Test Loss:  0.00041317619616165757
Valid Loss:  0.0008294011349789798
Epoch:  360  	Training Loss: 0.0006678983336314559
Test Loss:  0.0004132170579396188
Valid Loss:  0.000829371449071914
Epoch:  361  	Training Loss: 0.0006678324425593019
Test Loss:  0.00041325553320348263
Valid Loss:  0.0008293451392091811
Epoch:  362  	Training Loss: 0.0006677700439468026
Test Loss:  0.0004132224712520838
Valid Loss:  0.0008294235449284315
Epoch:  363  	Training Loss: 0.0006677663186565042
Test Loss:  0.00041320681339129806
Valid Loss:  0.0008294651051983237
Epoch:  364  	Training Loss: 0.0006677645142190158
Test Loss:  0.00041320061427541077
Valid Loss:  0.0008294855942949653
Epoch:  365  	Training Loss: 0.0006677630008198321
Test Loss:  0.0004131986352149397
Valid Loss:  0.0008294963045045733
Epoch:  366  	Training Loss: 0.0006677617784589529
Test Loss:  0.0004131988389417529
Valid Loss:  0.0008295031730085611
Epoch:  367  	Training Loss: 0.000667760381475091
Test Loss:  0.0004131999157834798
Valid Loss:  0.0008295074803754687
Epoch:  368  	Training Loss: 0.0006677589844912291
Test Loss:  0.00041320218588225543
Valid Loss:  0.0008295095758512616
Epoch:  369  	Training Loss: 0.0006677577621303499
Test Loss:  0.00041320291347801685
Valid Loss:  0.0008295123698189855
Epoch:  370  	Training Loss: 0.0006677566561847925
Test Loss:  0.0004132053581997752
Valid Loss:  0.0008295135339722037
Epoch:  371  	Training Loss: 0.0006677549099549651
Test Loss:  0.00041320687159895897
Valid Loss:  0.0008295151637867093
Epoch:  372  	Training Loss: 0.0006677544442936778
Test Loss:  0.0004128214786760509
Valid Loss:  0.000828381220344454
Epoch:  373  	Training Loss: 0.0006670566508546472
Test Loss:  0.00041244260501116514
Valid Loss:  0.0008272631093859673
Epoch:  374  	Training Loss: 0.000666367937810719
Test Loss:  0.0004120702506043017
Valid Loss:  0.0008261553011834621
Epoch:  375  	Training Loss: 0.00066568044712767
Test Loss:  0.0004117035132367164
Valid Loss:  0.0008250636165030301
Epoch:  376  	Training Loss: 0.0006650072755292058
Test Loss:  0.00041134245111607015
Valid Loss:  0.0008239849703386426
Epoch:  377  	Training Loss: 0.0006643477245233953
Test Loss:  0.00041098991641774774
Valid Loss:  0.0008229210507124662
Epoch:  378  	Training Loss: 0.0006637016776949167
Test Loss:  0.0004106425039935857
Valid Loss:  0.0008218712755478919
Epoch:  379  	Training Loss: 0.0006630680873058736
Test Loss:  0.00041030067950487137
Valid Loss:  0.0008208344224840403
Epoch:  380  	Training Loss: 0.0006624464876949787
Test Loss:  0.0004099637735635042
Valid Loss:  0.000819811481051147
Epoch:  381  	Training Loss: 0.0006618353072553873
Test Loss:  0.0004096312914043665
Valid Loss:  0.0008188017527572811
Epoch:  382  	Training Loss: 0.0006612350698560476
Test Loss:  0.00040963306673802435
Valid Loss:  0.0008188076317310333
Epoch:  383  	Training Loss: 0.0006612333236262202
Test Loss:  0.0004096343764103949
Valid Loss:  0.0008188121137209237
Epoch:  384  	Training Loss: 0.0006612319266423583
Test Loss:  0.0004096346674486995
Valid Loss:  0.0008188169449567795
Epoch:  385  	Training Loss: 0.00066123012220487
Test Loss:  0.00040963577339425683
Valid Loss:  0.0008188215433619916
Epoch:  386  	Training Loss: 0.0006612283759750426
Test Loss:  0.00040963783976621926
Valid Loss:  0.0008188248611986637
Epoch:  387  	Training Loss: 0.0006612271536141634
Test Loss:  0.00040963926585391164
Valid Loss:  0.0008188295178115368
Epoch:  388  	Training Loss: 0.0006612255237996578
Test Loss:  0.0004096413613297045
Valid Loss:  0.0008188328938558698
Epoch:  389  	Training Loss: 0.0006612234865315259
Test Loss:  0.00040964322397485375
Valid Loss:  0.0008188370265997946
Epoch:  390  	Training Loss: 0.000661222031340003
Test Loss:  0.00040964511572383344
Valid Loss:  0.0008188404608517885
Epoch:  391  	Training Loss: 0.000661221332848072
Test Loss:  0.0004096438060514629
Valid Loss:  0.0008188362699002028
Epoch:  392  	Training Loss: 0.0006612204015254974
Test Loss:  0.00040964171057567
Valid Loss:  0.0008188424399122596
Epoch:  393  	Training Loss: 0.0006611519493162632
Test Loss:  0.000409636995755136
Valid Loss:  0.0008188489591702819
Epoch:  394  	Training Loss: 0.0006610754644498229
Test Loss:  0.0004096326883882284
Valid Loss:  0.0008188573410734534
Epoch:  395  	Training Loss: 0.0006610061973333359
Test Loss:  0.00040962756611406803
Valid Loss:  0.0008188526844605803
Epoch:  396  	Training Loss: 0.0006609409465454519
Test Loss:  0.0004096142656635493
Valid Loss:  0.0008188319043256342
Epoch:  397  	Training Loss: 0.0006608811672776937
Test Loss:  0.00040957730379886925
Valid Loss:  0.0008188133360818028
Epoch:  398  	Training Loss: 0.0006608259864151478
Test Loss:  0.0004095429612789303
Valid Loss:  0.0008187978528439999
Epoch:  399  	Training Loss: 0.0006607744144275784
Test Loss:  0.00040950963739305735
Valid Loss:  0.0008187841158360243
Epoch:  400  	Training Loss: 0.0006607265677303076
Test Loss:  0.00040947861270979047
Valid Loss:  0.0008187722414731979
Epoch:  401  	Training Loss: 0.000660682562738657
Test Loss:  0.000409448315622285
Valid Loss:  0.0008187629864551127
Epoch:  402  	Training Loss: 0.0006606423994526267
Test Loss:  0.0004092417366337031
Valid Loss:  0.0008182725869119167
Epoch:  403  	Training Loss: 0.0006603116635233164
Test Loss:  0.0004090374568477273
Valid Loss:  0.0008178625721484423
Epoch:  404  	Training Loss: 0.0006600257474929094
Test Loss:  0.00040886661736294627
Valid Loss:  0.0008175792754627764
Epoch:  405  	Training Loss: 0.0006598079344257712
Test Loss:  0.00040870049269869924
Valid Loss:  0.0008173228125087917
Epoch:  406  	Training Loss: 0.0006596026360057294
Test Loss:  0.000408579915529117
Valid Loss:  0.000817093241494149
Epoch:  407  	Training Loss: 0.0006594223668798804
Test Loss:  0.0004085304099135101
Valid Loss:  0.0008168669883161783
Epoch:  408  	Training Loss: 0.0006592547870241106
Test Loss:  0.00040848550270311534
Valid Loss:  0.0008166831685230136
Epoch:  409  	Training Loss: 0.0006591483834199607
Test Loss:  0.0004084477841388434
Valid Loss:  0.0008165586041286588
Epoch:  410  	Training Loss: 0.0006590805132873356
Test Loss:  0.00040841661393642426
Valid Loss:  0.0008164468454197049
 82%|████████▏ | 411/500 [05:04<01:44,  1.17s/it] 83%|████████▎ | 413/500 [05:04<01:13,  1.19it/s] 83%|████████▎ | 415/500 [05:04<00:51,  1.64it/s] 83%|████████▎ | 417/500 [05:04<00:36,  2.25it/s] 84%|████████▍ | 419/500 [05:04<00:26,  3.02it/s] 84%|████████▍ | 421/500 [05:10<01:32,  1.17s/it] 85%|████████▍ | 423/500 [05:10<01:04,  1.19it/s] 85%|████████▌ | 425/500 [05:11<00:45,  1.65it/s] 85%|████████▌ | 427/500 [05:11<00:32,  2.25it/s] 86%|████████▌ | 429/500 [05:11<00:23,  3.03it/s] 86%|████████▌ | 431/500 [05:17<01:21,  1.17s/it] 87%|████████▋ | 433/500 [05:17<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:17<00:39,  1.64it/s] 87%|████████▋ | 437/500 [05:18<00:28,  2.24it/s] 88%|████████▊ | 439/500 [05:18<00:20,  3.01it/s] 88%|████████▊ | 441/500 [05:24<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:24<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:24<00:33,  1.62it/s] 89%|████████▉ | 447/500 [05:24<00:23,  2.21it/s] 90%|████████▉ | 449/500 [05:25<00:17,  2.97it/s] 90%|█████████ | 451/500 [05:31<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:31<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:31<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:31<00:19,  2.22it/s] 92%|█████████▏| 459/500 [05:31<00:13,  2.98it/s] 92%|█████████▏| 461/500 [05:38<00:46,  1.18s/it] 93%|█████████▎| 463/500 [05:38<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:38<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:38<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:38<00:10,  2.96it/s] 94%|█████████▍| 471/500 [05:44<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:45<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:45<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:45<00:10,  2.25it/s]Epoch:  411  	Training Loss: 0.0006590273696929216
Test Loss:  0.00040838634595274925
Valid Loss:  0.0008163568563759327
Epoch:  412  	Training Loss: 0.0006589816766791046
Test Loss:  0.0004083499079570174
Valid Loss:  0.0008163230959326029
Epoch:  413  	Training Loss: 0.0006589097902178764
Test Loss:  0.0004083155654370785
Valid Loss:  0.0008162928279489279
Epoch:  414  	Training Loss: 0.0006588486139662564
Test Loss:  0.00040828619967214763
Valid Loss:  0.0008162681479007006
Epoch:  415  	Training Loss: 0.0006587972166016698
Test Loss:  0.0004082585219293833
Valid Loss:  0.0008162464946508408
Epoch:  416  	Training Loss: 0.0006587525131180882
Test Loss:  0.0004082334926351905
Valid Loss:  0.0008162284502759576
Epoch:  417  	Training Loss: 0.0006587144453078508
Test Loss:  0.0004082110244780779
Valid Loss:  0.0008162120939232409
Epoch:  418  	Training Loss: 0.000658680684864521
Test Loss:  0.00040819120476953685
Valid Loss:  0.0008161990554071963
Epoch:  419  	Training Loss: 0.000658651813864708
Test Loss:  0.0004081727238371968
Valid Loss:  0.0008161877049133182
Epoch:  420  	Training Loss: 0.0006586263771168888
Test Loss:  0.0004081561928614974
Valid Loss:  0.0008161771111190319
Epoch:  421  	Training Loss: 0.0006586047820746899
Test Loss:  0.0004081409424543381
Valid Loss:  0.0008161681471392512
Epoch:  422  	Training Loss: 0.0006585833616554737
Test Loss:  0.00040795066161081195
Valid Loss:  0.0008160256547853351
Epoch:  423  	Training Loss: 0.0006583081558346748
Test Loss:  0.0004077979829162359
Valid Loss:  0.0008159286808222532
Epoch:  424  	Training Loss: 0.0006581665948033333
Test Loss:  0.00040776192327030003
Valid Loss:  0.0008158778655342758
Epoch:  425  	Training Loss: 0.0006581105990335345
Test Loss:  0.00040776701644062996
Valid Loss:  0.000815828621853143
Epoch:  426  	Training Loss: 0.0006580556510016322
Test Loss:  0.00040777266258373857
Valid Loss:  0.0008157797856256366
Epoch:  427  	Training Loss: 0.0006580096087418497
Test Loss:  0.00040777793037705123
Valid Loss:  0.0008157398551702499
Epoch:  428  	Training Loss: 0.0006579738110303879
Test Loss:  0.00040778348920866847
Valid Loss:  0.0008157235570251942
Epoch:  429  	Training Loss: 0.0006579388864338398
Test Loss:  0.00040778954280540347
Valid Loss:  0.0008157140109688044
Epoch:  430  	Training Loss: 0.000657904427498579
Test Loss:  0.0004077963239978999
Valid Loss:  0.0008157053380273283
Epoch:  431  	Training Loss: 0.0006578732281923294
Test Loss:  0.00040780060226097703
Valid Loss:  0.000815696083009243
Epoch:  432  	Training Loss: 0.0006578635657206178
Test Loss:  0.00040780071867629886
Valid Loss:  0.0008156494004651904
Epoch:  433  	Training Loss: 0.0006577714812010527
Test Loss:  0.0004078044439665973
Valid Loss:  0.0008156078984029591
Epoch:  434  	Training Loss: 0.0006576884770765901
Test Loss:  0.00040781014831736684
Valid Loss:  0.0008155686082318425
Epoch:  435  	Training Loss: 0.0006576139712706208
Test Loss:  0.000407817424274981
Valid Loss:  0.0008155335672199726
Epoch:  436  	Training Loss: 0.000657547265291214
Test Loss:  0.0004078245547134429
Valid Loss:  0.0008155003888532519
Epoch:  437  	Training Loss: 0.0006574876606464386
Test Loss:  0.00040783456643112004
Valid Loss:  0.0008154708775691688
Epoch:  438  	Training Loss: 0.0006574338767677546
Test Loss:  0.00040784545126371086
Valid Loss:  0.000815442472230643
Epoch:  439  	Training Loss: 0.0006573850987479091
Test Loss:  0.0004078559868503362
Valid Loss:  0.0008154169772751629
Epoch:  440  	Training Loss: 0.0006573410937562585
Test Loss:  0.0004078675410710275
Valid Loss:  0.0008153937524184585
Epoch:  441  	Training Loss: 0.0006573019782081246
Test Loss:  0.0004078800557181239
Valid Loss:  0.0008153729140758514
Epoch:  442  	Training Loss: 0.0006572633283212781
Test Loss:  0.00040791803621686995
Valid Loss:  0.0008153109811246395
Epoch:  443  	Training Loss: 0.0006572475540451705
Test Loss:  0.00040795153472572565
Valid Loss:  0.0008152578375302255
Epoch:  444  	Training Loss: 0.000657233118545264
Test Loss:  0.0004079797654412687
Valid Loss:  0.0008152115042321384
Epoch:  445  	Training Loss: 0.0006572202546522021
Test Loss:  0.00040800427086651325
Valid Loss:  0.0008151704096235335
Epoch:  446  	Training Loss: 0.0006572080892510712
Test Loss:  0.0004080260405316949
Valid Loss:  0.0008151328656822443
Epoch:  447  	Training Loss: 0.0006571968551725149
Test Loss:  0.00040804361924529076
Valid Loss:  0.0008151013171300292
Epoch:  448  	Training Loss: 0.0006571868434548378
Test Loss:  0.00040805869502946734
Valid Loss:  0.0008150733774527907
Epoch:  449  	Training Loss: 0.0006571769481524825
Test Loss:  0.0004080711514689028
Valid Loss:  0.0008150467183440924
Epoch:  450  	Training Loss: 0.000657167169265449
Test Loss:  0.0004080817161593586
Valid Loss:  0.0008150251815095544
Epoch:  451  	Training Loss: 0.0006571573903784156
Test Loss:  0.0004080897197127342
Valid Loss:  0.0008150033536367118
Epoch:  452  	Training Loss: 0.0006571452249772847
Test Loss:  0.0004080589860677719
Valid Loss:  0.0008150623179972172
Epoch:  453  	Training Loss: 0.0006571403937414289
Test Loss:  0.0004080391372554004
Valid Loss:  0.0008151071378961205
Epoch:  454  	Training Loss: 0.0006571367266587913
Test Loss:  0.00040803285082802176
Valid Loss:  0.0008151262300089002
Epoch:  455  	Training Loss: 0.0006571339326910675
Test Loss:  0.00040803791489452124
Valid Loss:  0.0008151281508617103
Epoch:  456  	Training Loss: 0.0006571314297616482
Test Loss:  0.00040804213494993746
Valid Loss:  0.0008151307119987905
Epoch:  457  	Training Loss: 0.0006571293342858553
Test Loss:  0.0004080464714206755
Valid Loss:  0.0008151328074745834
Epoch:  458  	Training Loss: 0.0006571270641870797
Test Loss:  0.0004080502549186349
Valid Loss:  0.0008151344954967499
Epoch:  459  	Training Loss: 0.000657124794088304
Test Loss:  0.0004080542712472379
Valid Loss:  0.0008151358924806118
Epoch:  460  	Training Loss: 0.000657122815027833
Test Loss:  0.0004080661165062338
Valid Loss:  0.0008151254733093083
Epoch:  461  	Training Loss: 0.0006571207195520401
Test Loss:  0.00040806844481267035
Valid Loss:  0.0008151315851137042
Epoch:  462  	Training Loss: 0.0006571182166226208
Test Loss:  0.0004081474326085299
Valid Loss:  0.000814990431535989
Epoch:  463  	Training Loss: 0.0006570538389496505
Test Loss:  0.0004081925726495683
Valid Loss:  0.0008148804772645235
Epoch:  464  	Training Loss: 0.0006569950492121279
Test Loss:  0.00040822161827236414
Valid Loss:  0.0008147929911501706
Epoch:  465  	Training Loss: 0.000656939169857651
Test Loss:  0.0004082424275111407
Valid Loss:  0.000814719358459115
Epoch:  466  	Training Loss: 0.0006568850949406624
Test Loss:  0.00040825799806043506
Valid Loss:  0.0008146464824676514
Epoch:  467  	Training Loss: 0.0006568242097273469
Test Loss:  0.00040827260818332434
Valid Loss:  0.0008145755855366588
Epoch:  468  	Training Loss: 0.0006567657692357898
Test Loss:  0.00040828424971550703
Valid Loss:  0.0008145092288032174
Epoch:  469  	Training Loss: 0.0006567108212038875
Test Loss:  0.00040829298086464405
Valid Loss:  0.0008144460734911263
Epoch:  470  	Training Loss: 0.0006566581432707608
Test Loss:  0.0004082982777617872
Valid Loss:  0.0008143871673382819
Epoch:  471  	Training Loss: 0.0006566074443981051
Test Loss:  0.0004083012754563242
Valid Loss:  0.0008143313461914659
Epoch:  472  	Training Loss: 0.000656559073831886
Test Loss:  0.00040316098602488637
Valid Loss:  0.0007989744772203267
Epoch:  473  	Training Loss: 0.000649253954179585
Test Loss:  0.0003995303122792393
Valid Loss:  0.0007904443773441017
Epoch:  474  	Training Loss: 0.0006450202781707048
Test Loss:  0.0003962935006711632
Valid Loss:  0.0007842745399102569
Epoch:  475  	Training Loss: 0.0006417587865144014
Test Loss:  0.0003929155645892024
Valid Loss:  0.0007786218775436282
Epoch:  476  	Training Loss: 0.0006388492183759809
Test Loss:  0.0003902227617800236
Valid Loss:  0.0007741234730929136
Epoch:  477  	Training Loss: 0.0006365462904796004
Test Loss:  0.0003880424774251878
Valid Loss:  0.0007703399751335382
Epoch:  478  	Training Loss: 0.0006345538422465324
Test Loss:  0.00038605218287557364
Valid Loss:  0.0007656742236576974
 96%|█████████▌| 479/500 [05:45<00:06,  3.03it/s] 96%|█████████▌| 481/500 [05:51<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:51<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:52<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:52<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:52<00:03,  3.01it/s] 98%|█████████▊| 491/500 [05:58<00:10,  1.16s/it] 99%|█████████▊| 493/500 [05:58<00:05,  1.20it/s] 99%|█████████▉| 495/500 [05:58<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:58<00:01,  2.25it/s]100%|█████████▉| 499/500 [05:59<00:00,  3.01it/s]100%|██████████| 500/500 [05:59<00:00,  1.39it/s]
Epoch:  479  	Training Loss: 0.0006324600544758141
Test Loss:  0.00038421712815761566
Valid Loss:  0.000760082621127367
Epoch:  480  	Training Loss: 0.0006304370472207665
Test Loss:  0.000382460217224434
Valid Loss:  0.000755443936213851
Epoch:  481  	Training Loss: 0.0006286987918429077
Test Loss:  0.00038048389251343906
Valid Loss:  0.0007513512391597033
Epoch:  482  	Training Loss: 0.0006271107704378664
Test Loss:  0.0003800079575739801
Valid Loss:  0.0007495312602259219
Epoch:  483  	Training Loss: 0.0006261803791858256
Test Loss:  0.00037958082975819707
Valid Loss:  0.0007478985353372991
Epoch:  484  	Training Loss: 0.0006253421306610107
Test Loss:  0.00037918396992608905
Valid Loss:  0.0007464115042239428
Epoch:  485  	Training Loss: 0.0006245718104764819
Test Loss:  0.0003788016620092094
Valid Loss:  0.0007450402481481433
Epoch:  486  	Training Loss: 0.0006238408386707306
Test Loss:  0.00037839694414287806
Valid Loss:  0.0007436888408847153
Epoch:  487  	Training Loss: 0.000623093917965889
Test Loss:  0.0003779943217523396
Valid Loss:  0.0007424131617881358
Epoch:  488  	Training Loss: 0.0006223773816600442
Test Loss:  0.0003775906516239047
Valid Loss:  0.0007411988917738199
Epoch:  489  	Training Loss: 0.0006216864567250013
Test Loss:  0.00037718279054388404
Valid Loss:  0.0007400335744023323
Epoch:  490  	Training Loss: 0.0006210156134329736
Test Loss:  0.0003767712914850563
Valid Loss:  0.0007389119127765298
Epoch:  491  	Training Loss: 0.0006203604862093925
Test Loss:  0.00037635499029420316
Valid Loss:  0.0007378217997029424
Epoch:  492  	Training Loss: 0.000619717757217586
Test Loss:  0.00037634908221662045
Valid Loss:  0.0007375581189990044
Epoch:  493  	Training Loss: 0.0006195221212692559
Test Loss:  0.0003763348504435271
Valid Loss:  0.0007373261032626033
Epoch:  494  	Training Loss: 0.0006193379522301257
Test Loss:  0.00037631357554346323
Valid Loss:  0.0007371175452135503
Epoch:  495  	Training Loss: 0.0006191623397171497
Test Loss:  0.000376284820958972
Valid Loss:  0.0007369299419224262
Epoch:  496  	Training Loss: 0.0006189928390085697
Test Loss:  0.0003762529813684523
Valid Loss:  0.0007367579964920878
Epoch:  497  	Training Loss: 0.0006188309052959085
Test Loss:  0.0003762168635148555
Valid Loss:  0.0007366001955233514
Epoch:  498  	Training Loss: 0.0006186740356497467
Test Loss:  0.0003761783300433308
Valid Loss:  0.0007364526391029358
Epoch:  499  	Training Loss: 0.0006185223464854062
Test Loss:  0.0003761373518500477
Valid Loss:  0.0007363142794929445
Epoch:  500  	Training Loss: 0.000618375837802887
Test Loss:  0.00037609515129588544
Valid Loss:  0.0007361859316006303
seed is  16
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:31, 16.04it/s]  1%|          | 4/500 [00:00<00:30, 16.31it/s]  1%|          | 6/500 [00:00<00:30, 16.44it/s]  2%|▏         | 8/500 [00:00<00:29, 16.49it/s]  2%|▏         | 10/500 [00:00<00:29, 16.50it/s]  2%|▏         | 12/500 [00:00<00:29, 16.30it/s]  3%|▎         | 14/500 [00:00<00:29, 16.25it/s]  3%|▎         | 16/500 [00:00<00:29, 16.16it/s]  4%|▎         | 18/500 [00:01<00:29, 16.21it/s]  4%|▍         | 20/500 [00:01<00:29, 16.21it/s]  4%|▍         | 22/500 [00:01<00:29, 16.39it/s]  5%|▍         | 24/500 [00:01<00:28, 16.44it/s]  5%|▌         | 26/500 [00:01<00:28, 16.47it/s]  6%|▌         | 28/500 [00:01<00:29, 16.18it/s]  6%|▌         | 30/500 [00:01<00:28, 16.23it/s]  6%|▋         | 32/500 [00:01<00:28, 16.28it/s]  7%|▋         | 34/500 [00:02<00:28, 16.20it/s]  7%|▋         | 36/500 [00:02<00:28, 16.26it/s]  8%|▊         | 38/500 [00:02<00:28, 16.32it/s]  8%|▊         | 40/500 [00:02<00:28, 16.35it/s]  8%|▊         | 42/500 [00:02<00:27, 16.38it/s]  9%|▉         | 44/500 [00:02<00:27, 16.41it/s]  9%|▉         | 46/500 [00:02<00:27, 16.41it/s] 10%|▉         | 48/500 [00:02<00:27, 16.31it/s] 10%|█         | 50/500 [00:03<00:27, 16.33it/s] 10%|█         | 52/500 [00:03<00:27, 16.36it/s] 11%|█         | 54/500 [00:03<00:27, 16.29it/s] 11%|█         | 56/500 [00:03<00:27, 16.26it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.29it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.35it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.42it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.43it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.46it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.45it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.45it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.31it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.24it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.28it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.33it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.40it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.74it/s] 17%|█▋        | 84/500 [00:05<00:27, 15.36it/s] 17%|█▋        | 86/500 [00:05<00:26, 15.69it/s] 18%|█▊        | 88/500 [00:05<00:25, 15.93it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.03it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.14it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.26it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.25it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.10it/s] 20%|██        | 100/500 [00:06<00:24, 16.25it/s] 20%|██        | 102/500 [00:06<00:24, 16.32it/s] 21%|██        | 104/500 [00:06<00:24, 16.29it/s] 21%|██        | 106/500 [00:06<00:24, 16.33it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.30it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.26it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.19it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.15it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.28it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.32it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.34it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.34it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.20it/s]Epoch:  1  	Training Loss: 0.49134325981140137
Test Loss:  4955.08935546875
Valid Loss:  4958.0947265625
Epoch:  2  	Training Loss: 4937.7724609375
Test Loss:  2.1686992746137518e+18
Valid Loss:  2.1697207209159557e+18
Epoch:  3  	Training Loss: 2.1750978825315942e+18
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:23, 16.10it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.19it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.14it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.16it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.27it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.33it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.24it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.32it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.41it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.41it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.18it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.25it/s] 30%|███       | 150/500 [00:09<00:21, 16.27it/s] 30%|███       | 152/500 [00:09<00:21, 15.97it/s] 31%|███       | 154/500 [00:09<00:22, 15.46it/s] 31%|███       | 156/500 [00:09<00:22, 15.43it/s] 32%|███▏      | 158/500 [00:09<00:21, 15.68it/s] 32%|███▏      | 160/500 [00:09<00:21, 15.77it/s] 32%|███▏      | 162/500 [00:09<00:21, 15.85it/s] 33%|███▎      | 164/500 [00:10<00:21, 15.97it/s] 33%|███▎      | 166/500 [00:10<00:21, 15.74it/s] 34%|███▎      | 168/500 [00:10<00:20, 15.94it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.01it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.10it/s] 35%|███▍      | 174/500 [00:10<00:20, 16.23it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.33it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.40it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.44it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.40it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.28it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.22it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.28it/s] 38%|███▊      | 190/500 [00:11<00:19, 16.24it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.30it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.31it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.39it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.41it/s] 40%|████      | 200/500 [00:12<00:18, 16.44it/s] 40%|████      | 202/500 [00:12<00:18, 16.42it/s] 41%|████      | 204/500 [00:12<00:18, 16.25it/s] 41%|████      | 206/500 [00:12<00:18, 16.30it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.38it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.39it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.39it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.18it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.17it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.11it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.07it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.20it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.30it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.37it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.42it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.41it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.42it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.37it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.29it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.30it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.39it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.43it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.48it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.50it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.54it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.57it/s] 50%|█████     | 252/500 [00:15<00:15, 16.52it/s] 51%|█████     | 254/500 [00:15<00:15, 16.25it/s] 51%|█████     | 256/500 [00:15<00:15, 16.16it/s] 52%|█████▏    | 258/500 [00:15<00:15, 16.11it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.24it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.21it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.27it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.33it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.37it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.19it/s] 54%|█████▍    | 272/500 [00:16<00:14, 15.28it/s] 55%|█████▍    | 274/500 [00:16<00:14, 15.64it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.86it/s] 56%|█████▌    | 278/500 [00:17<00:13, 15.89it/s] 56%|█████▌    | 280/500 [00:17<00:13, 15.99it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.11it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.20it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.31it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.33it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.39it/s] 58%|█████▊    | 292/500 [00:17<00:12, 16.34it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.47it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.18it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.11it/s] 60%|██████    | 300/500 [00:18<00:12, 16.22it/s] 60%|██████    | 302/500 [00:18<00:12, 16.17it/s] 61%|██████    | 304/500 [00:18<00:12, 16.24it/s] 61%|██████    | 306/500 [00:18<00:12, 16.14it/s] 62%|██████▏   | 308/500 [00:18<00:11, 16.27it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.32it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.32it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.26it/s] 63%|██████▎   | 316/500 [00:19<00:11, 15.97it/s] 64%|██████▎   | 318/500 [00:19<00:11, 15.47it/s] 64%|██████▍   | 320/500 [00:19<00:11, 15.52it/s] 64%|██████▍   | 322/500 [00:19<00:11, 15.38it/s] 65%|██████▍   | 324/500 [00:19<00:11, 15.69it/s] 65%|██████▌   | 326/500 [00:20<00:11, 15.82it/s] 66%|██████▌   | 328/500 [00:20<00:10, 15.96it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.00it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.11it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.21it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.22it/s] 68%|██████▊   | 338/500 [00:20<00:10, 16.18it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.06it/s] 68%|██████▊   | 342/500 [00:21<00:09, 15.93it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.14it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.14it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.14it/s] 70%|███████   | 350/500 [00:21<00:09, 16.19it/s] 70%|███████   | 352/500 [00:21<00:09, 16.26it/s] 71%|███████   | 354/500 [00:21<00:08, 16.36it/s] 71%|███████   | 356/500 [00:21<00:08, 16.11it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.25it/s] 72%|███████▏  | 360/500 [00:22<00:08, 15.72it/s] 72%|███████▏  | 362/500 [00:22<00:08, 15.89it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.06it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.12it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.23it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.31it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.34it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.40it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.47it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.49it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.38it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.35it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.39it/s] 77%|███████▋  | 386/500 [00:23<00:07, 15.57it/s] 78%|███████▊  | 388/500 [00:23<00:07, 15.79it/s] 78%|███████▊  | 390/500 [00:24<00:06, 15.86it/s] 78%|███████▊  | 392/500 [00:24<00:06, 15.70it/s] 79%|███████▉  | 394/500 [00:24<00:06, 15.88it/s] 79%|███████▉  | 396/500 [00:24<00:06, 15.85it/s] 80%|███████▉  | 398/500 [00:24<00:06, 15.83it/s] 80%|████████  | 400/500 [00:24<00:06, 15.81it/s] 80%|████████  | 402/500 [00:24<00:06, 15.93it/s] 81%|████████  | 404/500 [00:24<00:06, 15.99it/s] 81%|████████  | 406/500 [00:25<00:05, 16.02it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.13it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.18it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.25it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.30it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.25it/s] 84%|████████▎ | 418/500 [00:25<00:05, 16.27it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.20it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.24it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.31it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.23it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.35it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.37it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.44it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.43it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.46it/s] 88%|████████▊ | 438/500 [00:27<00:04, 15.03it/s] 88%|████████▊ | 440/500 [00:27<00:04, 14.65it/s] 88%|████████▊ | 442/500 [00:27<00:03, 15.14it/s] 89%|████████▉ | 444/500 [00:27<00:03, 15.50it/s] 89%|████████▉ | 446/500 [00:27<00:03, 15.77it/s] 90%|████████▉ | 448/500 [00:27<00:03, 15.97it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.11it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.09it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.08it/s] 91%|█████████ | 456/500 [00:28<00:02, 15.93it/s] 92%|█████████▏| 458/500 [00:28<00:02, 15.94it/s] 92%|█████████▏| 460/500 [00:28<00:02, 15.91it/s] 92%|█████████▏| 462/500 [00:28<00:02, 15.99it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.10it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.20it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.22it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.26it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.29it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.30it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.28it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.35it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.46it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.51it/s] 97%|█████████▋| 484/500 [00:29<00:01, 15.89it/s] 97%|█████████▋| 486/500 [00:30<00:00, 14.81it/s] 98%|█████████▊| 488/500 [00:30<00:00, 15.24it/s] 98%|█████████▊| 490/500 [00:30<00:00, 15.53it/s] 98%|█████████▊| 492/500 [00:30<00:00, 15.76it/s] 99%|█████████▉| 494/500 [00:30<00:00, 15.97it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.17it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.16it/s]100%|██████████| 500/500 [00:30<00:00, 16.06it/s]100%|██████████| 500/500 [00:30<00:00, 16.15it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  16
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:00,  6.13s/it]  1%|          | 3/500 [00:06<13:36,  1.64s/it]  1%|          | 5/500 [00:06<06:51,  1.20it/s]  1%|▏         | 7/500 [00:06<04:09,  1.97it/s]  2%|▏         | 9/500 [00:06<02:47,  2.94it/s]  2%|▏         | 11/500 [00:12<10:36,  1.30s/it]  3%|▎         | 13/500 [00:12<07:14,  1.12it/s]  3%|▎         | 15/500 [00:13<05:03,  1.60it/s]  3%|▎         | 17/500 [00:13<03:36,  2.23it/s]  4%|▍         | 19/500 [00:13<02:38,  3.04it/s]  4%|▍         | 21/500 [00:19<09:28,  1.19s/it]  5%|▍         | 23/500 [00:19<06:43,  1.18it/s]  5%|▌         | 25/500 [00:19<04:49,  1.64it/s]  5%|▌         | 27/500 [00:20<03:32,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.00it/s]  6%|▌         | 31/500 [00:26<09:10,  1.17s/it]  7%|▋         | 33/500 [00:26<06:33,  1.19it/s]  7%|▋         | 35/500 [00:26<04:42,  1.64it/s]  7%|▋         | 37/500 [00:26<03:26,  2.25it/s]  8%|▊         | 39/500 [00:26<02:32,  3.01it/s]  8%|▊         | 41/500 [00:33<08:56,  1.17s/it]  9%|▊         | 43/500 [00:33<06:24,  1.19it/s]  9%|▉         | 45/500 [00:33<04:36,  1.65it/s]  9%|▉         | 47/500 [00:33<03:21,  2.25it/s] 10%|▉         | 49/500 [00:33<02:29,  3.02it/s] 10%|█         | 51/500 [00:40<08:48,  1.18s/it] 11%|█         | 53/500 [00:40<06:19,  1.18it/s] 11%|█         | 55/500 [00:40<04:34,  1.62it/s] 11%|█▏        | 57/500 [00:40<03:21,  2.20it/s] 12%|█▏        | 59/500 [00:40<02:31,  2.90it/s] 12%|█▏        | 61/500 [00:47<08:43,  1.19s/it] 13%|█▎        | 63/500 [00:47<06:14,  1.17it/s] 13%|█▎        | 65/500 [00:47<04:29,  1.61it/s] 13%|█▎        | 67/500 [00:47<03:16,  2.21it/s] 14%|█▍        | 69/500 [00:47<02:25,  2.96it/s] 14%|█▍        | 71/500 [00:53<08:21,  1.17s/it] 15%|█▍        | 73/500 [00:53<05:58,  1.19it/s]Epoch:  1  	Training Loss: 0.49134331941604614
Test Loss:  140.57635498046875
Valid Loss:  140.8424835205078
Epoch:  2  	Training Loss: 140.64425659179688
Test Loss:  0.6045868992805481
Valid Loss:  0.6122567653656006
Epoch:  3  	Training Loss: 0.5527739524841309
Test Loss:  0.6045799851417542
Valid Loss:  0.6122465133666992
Epoch:  4  	Training Loss: 0.5527657270431519
Test Loss:  0.6045728921890259
Valid Loss:  0.6122359037399292
Epoch:  5  	Training Loss: 0.552757203578949
Test Loss:  0.6045657396316528
Valid Loss:  0.6122252345085144
Epoch:  6  	Training Loss: 0.5527485609054565
Test Loss:  0.6045585870742798
Valid Loss:  0.6122146248817444
Epoch:  7  	Training Loss: 0.5527400374412537
Test Loss:  0.6045515537261963
Valid Loss:  0.6122040748596191
Epoch:  8  	Training Loss: 0.5527313947677612
Test Loss:  0.6045432686805725
Valid Loss:  0.6121931076049805
Epoch:  9  	Training Loss: 0.5527223348617554
Test Loss:  0.6045349836349487
Valid Loss:  0.6121821999549866
Epoch:  10  	Training Loss: 0.5527132749557495
Test Loss:  0.6045265197753906
Valid Loss:  0.6121699810028076
Epoch:  11  	Training Loss: 0.5527036190032959
Test Loss:  0.6045173406600952
Valid Loss:  0.6121563911437988
Epoch:  12  	Training Loss: 0.5526934862136841
Test Loss:  0.6044803261756897
Valid Loss:  0.6121119260787964
Epoch:  13  	Training Loss: 0.5526508092880249
Test Loss:  0.6044385433197021
Valid Loss:  0.6120646595954895
Epoch:  14  	Training Loss: 0.5526034832000732
Test Loss:  0.6043961644172668
Valid Loss:  0.6120166778564453
Epoch:  15  	Training Loss: 0.5525540113449097
Test Loss:  0.604352593421936
Valid Loss:  0.6119672060012817
Epoch:  16  	Training Loss: 0.5525022149085999
Test Loss:  0.6043073534965515
Valid Loss:  0.6119171380996704
Epoch:  17  	Training Loss: 0.5524469017982483
Test Loss:  0.6042559146881104
Valid Loss:  0.6118602752685547
Epoch:  18  	Training Loss: 0.5523846745491028
Test Loss:  0.604204535484314
Valid Loss:  0.6118022799491882
Epoch:  19  	Training Loss: 0.5523220300674438
Test Loss:  0.6041524410247803
Valid Loss:  0.6117406487464905
Epoch:  20  	Training Loss: 0.5522576570510864
Test Loss:  0.6040996313095093
Valid Loss:  0.6116774082183838
Epoch:  21  	Training Loss: 0.5521916151046753
Test Loss:  0.6040453910827637
Valid Loss:  0.611611008644104
Epoch:  22  	Training Loss: 0.5521221160888672
Test Loss:  0.6039903163909912
Valid Loss:  0.6115411520004272
Epoch:  23  	Training Loss: 0.5520504117012024
Test Loss:  0.6039323210716248
Valid Loss:  0.6114682555198669
Epoch:  24  	Training Loss: 0.5519713759422302
Test Loss:  0.6038663983345032
Valid Loss:  0.6113901734352112
Epoch:  25  	Training Loss: 0.5518829822540283
Test Loss:  0.6037899255752563
Valid Loss:  0.6113100051879883
Epoch:  26  	Training Loss: 0.5517881512641907
Test Loss:  0.6037001609802246
Valid Loss:  0.6112256050109863
Epoch:  27  	Training Loss: 0.5516844987869263
Test Loss:  0.6036055684089661
Valid Loss:  0.6111389398574829
Epoch:  28  	Training Loss: 0.5515749454498291
Test Loss:  0.6035059690475464
Valid Loss:  0.6110430955886841
Epoch:  29  	Training Loss: 0.5514571666717529
Test Loss:  0.6034002304077148
Valid Loss:  0.6109457015991211
Epoch:  30  	Training Loss: 0.5513341426849365
Test Loss:  0.6032862067222595
Valid Loss:  0.6108299493789673
Epoch:  31  	Training Loss: 0.5512044429779053
Test Loss:  0.6031560897827148
Valid Loss:  0.6107058525085449
Epoch:  32  	Training Loss: 0.5510660409927368
Test Loss:  0.6030466556549072
Valid Loss:  0.6105989217758179
Epoch:  33  	Training Loss: 0.550946831703186
Test Loss:  0.6029362082481384
Valid Loss:  0.610487699508667
Epoch:  34  	Training Loss: 0.5508265495300293
Test Loss:  0.6028175354003906
Valid Loss:  0.6103726625442505
Epoch:  35  	Training Loss: 0.5507012605667114
Test Loss:  0.6026822924613953
Valid Loss:  0.6102523803710938
Epoch:  36  	Training Loss: 0.5505651831626892
Test Loss:  0.6025392413139343
Valid Loss:  0.6101294755935669
Epoch:  37  	Training Loss: 0.550423264503479
Test Loss:  0.6023930907249451
Valid Loss:  0.6100030541419983
Epoch:  38  	Training Loss: 0.5502732992172241
Test Loss:  0.6022393107414246
Valid Loss:  0.6098666191101074
Epoch:  39  	Training Loss: 0.5501129627227783
Test Loss:  0.6020692586898804
Valid Loss:  0.6097098588943481
Epoch:  40  	Training Loss: 0.5499283075332642
Test Loss:  0.6018792390823364
Valid Loss:  0.6095343828201294
Epoch:  41  	Training Loss: 0.5497273206710815
Test Loss:  0.6016832590103149
Valid Loss:  0.6093428730964661
Epoch:  42  	Training Loss: 0.5495196580886841
Test Loss:  0.601507306098938
Valid Loss:  0.6091623902320862
Epoch:  43  	Training Loss: 0.549323320388794
Test Loss:  0.6013155579566956
Valid Loss:  0.6089743971824646
Epoch:  44  	Training Loss: 0.5491135120391846
Test Loss:  0.6011176109313965
Valid Loss:  0.6087822318077087
Epoch:  45  	Training Loss: 0.5489006042480469
Test Loss:  0.6009197235107422
Valid Loss:  0.6085823774337769
Epoch:  46  	Training Loss: 0.5486840605735779
Test Loss:  0.6007119417190552
Valid Loss:  0.6083747148513794
Epoch:  47  	Training Loss: 0.548457145690918
Test Loss:  0.6004957556724548
Valid Loss:  0.6081583499908447
Epoch:  48  	Training Loss: 0.5482152700424194
Test Loss:  0.6002729535102844
Valid Loss:  0.6079268455505371
Epoch:  49  	Training Loss: 0.5479577779769897
Test Loss:  0.600040078163147
Valid Loss:  0.6076797842979431
Epoch:  50  	Training Loss: 0.5476779937744141
Test Loss:  0.5998005867004395
Valid Loss:  0.6074143648147583
Epoch:  51  	Training Loss: 0.5473858118057251
Test Loss:  0.5995529890060425
Valid Loss:  0.6071330308914185
Epoch:  52  	Training Loss: 0.5470854043960571
Test Loss:  0.5992532968521118
Valid Loss:  0.6067969799041748
Epoch:  53  	Training Loss: 0.5467264652252197
Test Loss:  0.5989265441894531
Valid Loss:  0.606438934803009
Epoch:  54  	Training Loss: 0.5463589429855347
Test Loss:  0.5985810160636902
Valid Loss:  0.6060600876808167
Epoch:  55  	Training Loss: 0.5459811091423035
Test Loss:  0.5982294082641602
Valid Loss:  0.605666995048523
Epoch:  56  	Training Loss: 0.5455920696258545
Test Loss:  0.5978646874427795
Valid Loss:  0.6052467823028564
Epoch:  57  	Training Loss: 0.5451894998550415
Test Loss:  0.5974774360656738
Valid Loss:  0.6048241853713989
Epoch:  58  	Training Loss: 0.5447796583175659
Test Loss:  0.5970679521560669
Valid Loss:  0.6043897867202759
Epoch:  59  	Training Loss: 0.5443545579910278
Test Loss:  0.5966289043426514
Valid Loss:  0.6039459705352783
Epoch:  60  	Training Loss: 0.5439218282699585
Test Loss:  0.5961626768112183
Valid Loss:  0.6034853458404541
Epoch:  61  	Training Loss: 0.543464183807373
Test Loss:  0.5956517457962036
Valid Loss:  0.6030020117759705
Epoch:  62  	Training Loss: 0.5429854989051819
Test Loss:  0.5951085090637207
Valid Loss:  0.6025128364562988
Epoch:  63  	Training Loss: 0.5425326228141785
Test Loss:  0.5945525169372559
Valid Loss:  0.6020013093948364
Epoch:  64  	Training Loss: 0.542060375213623
Test Loss:  0.5939834117889404
Valid Loss:  0.6014659404754639
Epoch:  65  	Training Loss: 0.5415737628936768
Test Loss:  0.593386173248291
Valid Loss:  0.6008881330490112
Epoch:  66  	Training Loss: 0.5410588979721069
Test Loss:  0.5927853584289551
Valid Loss:  0.6002792119979858
Epoch:  67  	Training Loss: 0.5405248403549194
Test Loss:  0.5921600461006165
Valid Loss:  0.5996453762054443
Epoch:  68  	Training Loss: 0.5399630069732666
Test Loss:  0.5915355682373047
Valid Loss:  0.5990122556686401
Epoch:  69  	Training Loss: 0.5394017100334167
Test Loss:  0.5909116268157959
Valid Loss:  0.5983797311782837
Epoch:  70  	Training Loss: 0.5388411283493042
Test Loss:  0.5902884602546692
Valid Loss:  0.5977479815483093
Epoch:  71  	Training Loss: 0.5382810831069946
Test Loss:  0.589665949344635
Valid Loss:  0.5971168279647827
Epoch:  72  	Training Loss: 0.5377216935157776
Test Loss:  0.5890015363693237
Valid Loss:  0.596442699432373
Epoch:  73  	Training Loss: 0.5371307134628296
Test Loss:  0.5883378982543945
Valid Loss:  0.5957694053649902
Epoch:  74  	Training Loss: 0.5365405082702637
Test Loss:  0.5876750946044922
Valid Loss:  0.5950968265533447
Epoch:  75  	Training Loss: 0.5359508991241455
Test Loss:  0.5870129466056824
 15%|█▌        | 75/500 [00:54<04:17,  1.65it/s] 15%|█▌        | 77/500 [00:54<03:07,  2.25it/s] 16%|█▌        | 79/500 [00:54<02:18,  3.03it/s] 16%|█▌        | 81/500 [01:00<08:12,  1.18s/it] 17%|█▋        | 83/500 [01:00<05:51,  1.18it/s] 17%|█▋        | 85/500 [01:00<04:13,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:05,  2.23it/s] 18%|█▊        | 89/500 [01:01<02:17,  3.00it/s] 18%|█▊        | 91/500 [01:07<08:02,  1.18s/it] 19%|█▊        | 93/500 [01:07<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:07<04:08,  1.63it/s] 19%|█▉        | 97/500 [01:07<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:08<02:14,  2.99it/s] 20%|██        | 101/500 [01:14<07:54,  1.19s/it] 21%|██        | 103/500 [01:14<05:38,  1.17it/s] 21%|██        | 105/500 [01:14<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:14<02:58,  2.20it/s] 22%|██▏       | 109/500 [01:14<02:13,  2.94it/s] 22%|██▏       | 111/500 [01:21<07:37,  1.18s/it] 23%|██▎       | 113/500 [01:21<05:26,  1.18it/s] 23%|██▎       | 115/500 [01:21<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:21<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:21<02:07,  2.98it/s] 24%|██▍       | 121/500 [01:28<07:25,  1.18s/it] 25%|██▍       | 123/500 [01:28<05:18,  1.18it/s] 25%|██▌       | 125/500 [01:28<03:49,  1.64it/s] 25%|██▌       | 127/500 [01:28<02:46,  2.23it/s] 26%|██▌       | 129/500 [01:28<02:03,  3.00it/s] 26%|██▌       | 131/500 [01:34<07:10,  1.17s/it] 27%|██▋       | 133/500 [01:34<05:08,  1.19it/s] 27%|██▋       | 135/500 [01:35<03:41,  1.65it/s] 27%|██▋       | 137/500 [01:35<02:41,  2.24it/s] 28%|██▊       | 139/500 [01:35<01:59,  3.01it/s] 28%|██▊       | 141/500 [01:41<07:00,  1.17s/it] 29%|██▊       | 143/500 [01:41<05:00,  1.19it/s] 29%|██▉       | 145/500 [01:41<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:42<02:37,  2.24it/s]Valid Loss:  0.5944249629974365
Epoch:  76  	Training Loss: 0.5353618860244751
Test Loss:  0.5863516330718994
Valid Loss:  0.5937540531158447
Epoch:  77  	Training Loss: 0.5347737073898315
Test Loss:  0.585690975189209
Valid Loss:  0.5930837392807007
Epoch:  78  	Training Loss: 0.5341860055923462
Test Loss:  0.5850310325622559
Valid Loss:  0.5924142599105835
Epoch:  79  	Training Loss: 0.5335990190505981
Test Loss:  0.5843719244003296
Valid Loss:  0.5917454361915588
Epoch:  80  	Training Loss: 0.5330127477645874
Test Loss:  0.5837135910987854
Valid Loss:  0.591077446937561
Epoch:  81  	Training Loss: 0.5324270725250244
Test Loss:  0.5830559730529785
Valid Loss:  0.5904102325439453
Epoch:  82  	Training Loss: 0.5318421125411987
Test Loss:  0.582460880279541
Valid Loss:  0.5898069143295288
Epoch:  83  	Training Loss: 0.5313074588775635
Test Loss:  0.5818663835525513
Valid Loss:  0.5892042517662048
Epoch:  84  	Training Loss: 0.530773401260376
Test Loss:  0.5812724828720093
Valid Loss:  0.5886021852493286
Epoch:  85  	Training Loss: 0.5302398800849915
Test Loss:  0.5806792974472046
Valid Loss:  0.5880006551742554
Epoch:  86  	Training Loss: 0.5297068953514099
Test Loss:  0.5800866484642029
Valid Loss:  0.5873998403549194
Epoch:  87  	Training Loss: 0.5291744470596313
Test Loss:  0.5794945955276489
Valid Loss:  0.5867996215820312
Epoch:  88  	Training Loss: 0.5286425352096558
Test Loss:  0.578903079032898
Valid Loss:  0.5861999988555908
Epoch:  89  	Training Loss: 0.5281111001968384
Test Loss:  0.5783122181892395
Valid Loss:  0.5856009125709534
Epoch:  90  	Training Loss: 0.5275802612304688
Test Loss:  0.5777219533920288
Valid Loss:  0.5850025415420532
Epoch:  91  	Training Loss: 0.5270499587059021
Test Loss:  0.5771323442459106
Valid Loss:  0.584404706954956
Epoch:  92  	Training Loss: 0.5265201330184937
Test Loss:  0.5765761137008667
Valid Loss:  0.5838411450386047
Epoch:  93  	Training Loss: 0.5260167121887207
Test Loss:  0.576020359992981
Valid Loss:  0.5832780599594116
Epoch:  94  	Training Loss: 0.525513768196106
Test Loss:  0.575465202331543
Valid Loss:  0.5827155113220215
Epoch:  95  	Training Loss: 0.5250113010406494
Test Loss:  0.5749105215072632
Valid Loss:  0.5821535587310791
Epoch:  96  	Training Loss: 0.5245092511177063
Test Loss:  0.5743563175201416
Valid Loss:  0.5815920829772949
Epoch:  97  	Training Loss: 0.5240076780319214
Test Loss:  0.5738027095794678
Valid Loss:  0.5810311436653137
Epoch:  98  	Training Loss: 0.5235066413879395
Test Loss:  0.5732496976852417
Valid Loss:  0.5804707407951355
Epoch:  99  	Training Loss: 0.523006021976471
Test Loss:  0.5726970434188843
Valid Loss:  0.5799108147621155
Epoch:  100  	Training Loss: 0.5225058794021606
Test Loss:  0.5721449851989746
Valid Loss:  0.579351544380188
Epoch:  101  	Training Loss: 0.5220061540603638
Test Loss:  0.5715935230255127
Valid Loss:  0.5787926912307739
Epoch:  102  	Training Loss: 0.5215070247650146
Test Loss:  0.5710619688034058
Valid Loss:  0.5782543420791626
Epoch:  103  	Training Loss: 0.5210233926773071
Test Loss:  0.5705310106277466
Valid Loss:  0.5777165293693542
Epoch:  104  	Training Loss: 0.5205402374267578
Test Loss:  0.5700004696846008
Valid Loss:  0.5771791934967041
Epoch:  105  	Training Loss: 0.5200576782226562
Test Loss:  0.5694704055786133
Valid Loss:  0.5766424536705017
Epoch:  106  	Training Loss: 0.5195754170417786
Test Loss:  0.5689408779144287
Valid Loss:  0.5761061310768127
Epoch:  107  	Training Loss: 0.5190936923027039
Test Loss:  0.5684119462966919
Valid Loss:  0.5755703449249268
Epoch:  108  	Training Loss: 0.5186123847961426
Test Loss:  0.5678833723068237
Valid Loss:  0.5750350952148438
Epoch:  109  	Training Loss: 0.5181316137313843
Test Loss:  0.5673553943634033
Valid Loss:  0.574500322341919
Epoch:  110  	Training Loss: 0.5176511406898499
Test Loss:  0.5668278336524963
Valid Loss:  0.5739660263061523
Epoch:  111  	Training Loss: 0.5171712040901184
Test Loss:  0.5663008093833923
Valid Loss:  0.573432207107544
Epoch:  112  	Training Loss: 0.5166917443275452
Test Loss:  0.5657869577407837
Valid Loss:  0.5729119777679443
Epoch:  113  	Training Loss: 0.5162224769592285
Test Loss:  0.565273642539978
Valid Loss:  0.5723922252655029
Epoch:  114  	Training Loss: 0.5157537460327148
Test Loss:  0.5647608041763306
Valid Loss:  0.5718729496002197
Epoch:  115  	Training Loss: 0.5152853727340698
Test Loss:  0.5642483234405518
Valid Loss:  0.5713541507720947
Epoch:  116  	Training Loss: 0.514817476272583
Test Loss:  0.5637364387512207
Valid Loss:  0.5708358287811279
Epoch:  117  	Training Loss: 0.5143499374389648
Test Loss:  0.5632250308990479
Valid Loss:  0.5703179836273193
Epoch:  118  	Training Loss: 0.5138828754425049
Test Loss:  0.5627139806747437
Valid Loss:  0.569800615310669
Epoch:  119  	Training Loss: 0.5134163498878479
Test Loss:  0.5622034668922424
Valid Loss:  0.569283664226532
Epoch:  120  	Training Loss: 0.5129501223564148
Test Loss:  0.5616933703422546
Valid Loss:  0.5687671899795532
Epoch:  121  	Training Loss: 0.5124843120574951
Test Loss:  0.561183750629425
Valid Loss:  0.5682512521743774
Epoch:  122  	Training Loss: 0.5120189785957336
Test Loss:  0.5606836080551147
Valid Loss:  0.5677449107170105
Epoch:  123  	Training Loss: 0.5115609765052795
Test Loss:  0.5601837635040283
Valid Loss:  0.5672389268875122
Epoch:  124  	Training Loss: 0.5111033320426941
Test Loss:  0.5596843957901001
Valid Loss:  0.5667334794998169
Epoch:  125  	Training Loss: 0.5106461644172668
Test Loss:  0.5591854453086853
Valid Loss:  0.5662283301353455
Epoch:  126  	Training Loss: 0.5101892948150635
Test Loss:  0.5586869120597839
Valid Loss:  0.5657237768173218
Epoch:  127  	Training Loss: 0.5097328424453735
Test Loss:  0.5581888556480408
Valid Loss:  0.5652195811271667
Epoch:  128  	Training Loss: 0.5092768669128418
Test Loss:  0.557691216468811
Valid Loss:  0.5647157430648804
Epoch:  129  	Training Loss: 0.5088212490081787
Test Loss:  0.5571940541267395
Valid Loss:  0.5642125606536865
Epoch:  130  	Training Loss: 0.508366048336029
Test Loss:  0.5566972494125366
Valid Loss:  0.5637096166610718
Epoch:  131  	Training Loss: 0.5079111456871033
Test Loss:  0.5562009811401367
Valid Loss:  0.5632072687149048
Epoch:  132  	Training Loss: 0.5074567794799805
Test Loss:  0.5557105541229248
Valid Loss:  0.5627108812332153
Epoch:  133  	Training Loss: 0.5070069432258606
Test Loss:  0.5552206039428711
Valid Loss:  0.5622150301933289
Epoch:  134  	Training Loss: 0.5065574645996094
Test Loss:  0.5547310709953308
Valid Loss:  0.561719536781311
Epoch:  135  	Training Loss: 0.5061084032058716
Test Loss:  0.5542420148849487
Valid Loss:  0.5612245202064514
Epoch:  136  	Training Loss: 0.5056596994400024
Test Loss:  0.5537533760070801
Valid Loss:  0.5607299208641052
Epoch:  137  	Training Loss: 0.5052114725112915
Test Loss:  0.5532650947570801
Valid Loss:  0.5602357983589172
Epoch:  138  	Training Loss: 0.5047636032104492
Test Loss:  0.5527772903442383
Valid Loss:  0.5597420930862427
Epoch:  139  	Training Loss: 0.5043160915374756
Test Loss:  0.5522899627685547
Valid Loss:  0.5592488050460815
Epoch:  140  	Training Loss: 0.5038690567016602
Test Loss:  0.5518029928207397
Valid Loss:  0.5587559342384338
Epoch:  141  	Training Loss: 0.5034223794937134
Test Loss:  0.551316499710083
Valid Loss:  0.5582635402679443
Epoch:  142  	Training Loss: 0.5029760599136353
Test Loss:  0.550834596157074
Valid Loss:  0.5577758550643921
Epoch:  143  	Training Loss: 0.5025333166122437
Test Loss:  0.5503531098365784
Valid Loss:  0.5572885274887085
Epoch:  144  	Training Loss: 0.5020909309387207
Test Loss:  0.5498720407485962
Valid Loss:  0.5568016767501831
Epoch:  145  	Training Loss: 0.5016489624977112
Test Loss:  0.5493913888931274
Valid Loss:  0.5563153028488159
Epoch:  146  	Training Loss: 0.5012073516845703
Test Loss:  0.5489112138748169
Valid Loss:  0.5558294057846069
Epoch:  147  	Training Loss: 0.5007662177085876
Test Loss:  0.5484315156936646
Valid Loss:  0.5553438663482666
Epoch:  148  	Training Loss: 0.5003254413604736
Test Loss:  0.5479521155357361
Valid Loss:  0.5548588037490845
Epoch:  149  	Training Loss: 0.49988502264022827
Test Loss:  0.5474732518196106
Valid Loss:   30%|██▉       | 149/500 [01:42<01:56,  3.02it/s] 30%|███       | 151/500 [01:48<06:47,  1.17s/it] 31%|███       | 153/500 [01:48<04:50,  1.19it/s] 31%|███       | 155/500 [01:48<03:29,  1.65it/s] 31%|███▏      | 157/500 [01:48<02:32,  2.25it/s] 32%|███▏      | 159/500 [01:48<01:53,  3.01it/s] 32%|███▏      | 161/500 [01:55<06:37,  1.17s/it] 33%|███▎      | 163/500 [01:55<04:43,  1.19it/s] 33%|███▎      | 165/500 [01:55<03:24,  1.64it/s] 33%|███▎      | 167/500 [01:55<02:28,  2.24it/s] 34%|███▍      | 169/500 [01:55<01:49,  3.01it/s] 34%|███▍      | 171/500 [02:02<06:27,  1.18s/it] 35%|███▍      | 173/500 [02:02<04:36,  1.18it/s] 35%|███▌      | 175/500 [02:02<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:02<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:02<01:46,  3.00it/s] 36%|███▌      | 181/500 [02:08<06:11,  1.17s/it] 37%|███▋      | 183/500 [02:08<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:09<03:13,  1.63it/s] 37%|███▋      | 187/500 [02:09<02:22,  2.20it/s] 38%|███▊      | 189/500 [02:09<01:44,  2.97it/s] 38%|███▊      | 191/500 [02:15<06:02,  1.17s/it] 39%|███▊      | 193/500 [02:15<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:15<03:06,  1.63it/s] 39%|███▉      | 197/500 [02:16<02:15,  2.23it/s] 40%|███▉      | 199/500 [02:16<01:40,  2.99it/s] 40%|████      | 201/500 [02:22<05:59,  1.20s/it] 41%|████      | 203/500 [02:22<04:17,  1.15it/s] 41%|████      | 205/500 [02:22<03:04,  1.60it/s] 41%|████▏     | 207/500 [02:23<02:14,  2.18it/s] 42%|████▏     | 209/500 [02:23<01:39,  2.94it/s] 42%|████▏     | 211/500 [02:29<05:38,  1.17s/it] 43%|████▎     | 213/500 [02:29<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:29<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:29<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:29<01:33,  3.01it/s] 44%|████▍     | 221/500 [02:36<05:28,  1.18s/it]0.5543742179870605
Epoch:  150  	Training Loss: 0.4994450807571411
Test Loss:  0.5469948053359985
Valid Loss:  0.5538899898529053
Epoch:  151  	Training Loss: 0.4990054666996002
Test Loss:  0.5465167760848999
Valid Loss:  0.5534061193466187
Epoch:  152  	Training Loss: 0.49856626987457275
Test Loss:  0.5460420846939087
Valid Loss:  0.5529259443283081
Epoch:  153  	Training Loss: 0.49812978506088257
Test Loss:  0.5455679893493652
Valid Loss:  0.5524461269378662
Epoch:  154  	Training Loss: 0.49769365787506104
Test Loss:  0.5450941920280457
Valid Loss:  0.551966667175293
Epoch:  155  	Training Loss: 0.4972579777240753
Test Loss:  0.5446208715438843
Valid Loss:  0.5514876246452332
Epoch:  156  	Training Loss: 0.49682262539863586
Test Loss:  0.5441478490829468
Valid Loss:  0.5510090589523315
Epoch:  157  	Training Loss: 0.4963876008987427
Test Loss:  0.5436753034591675
Valid Loss:  0.5505308508872986
Epoch:  158  	Training Loss: 0.4959529638290405
Test Loss:  0.5432031154632568
Valid Loss:  0.5500530004501343
Epoch:  159  	Training Loss: 0.49551868438720703
Test Loss:  0.5427312850952148
Valid Loss:  0.5495756268501282
Epoch:  160  	Training Loss: 0.4950847923755646
Test Loss:  0.542259931564331
Valid Loss:  0.5490986108779907
Epoch:  161  	Training Loss: 0.49465131759643555
Test Loss:  0.5417889356613159
Valid Loss:  0.5486220121383667
Epoch:  162  	Training Loss: 0.49421820044517517
Test Loss:  0.5413203239440918
Valid Loss:  0.5481478571891785
Epoch:  163  	Training Loss: 0.4937867522239685
Test Loss:  0.5408520698547363
Valid Loss:  0.5476740598678589
Epoch:  164  	Training Loss: 0.49335572123527527
Test Loss:  0.5403842926025391
Valid Loss:  0.5472006797790527
Epoch:  165  	Training Loss: 0.4929250478744507
Test Loss:  0.5399168729782104
Valid Loss:  0.54672771692276
Epoch:  166  	Training Loss: 0.49249470233917236
Test Loss:  0.5394498109817505
Valid Loss:  0.5462552309036255
Epoch:  167  	Training Loss: 0.49206477403640747
Test Loss:  0.5389832258224487
Valid Loss:  0.5457830429077148
Epoch:  168  	Training Loss: 0.49163520336151123
Test Loss:  0.5385169982910156
Valid Loss:  0.5453113317489624
Epoch:  169  	Training Loss: 0.4912060499191284
Test Loss:  0.538051187992096
Valid Loss:  0.5448399782180786
Epoch:  170  	Training Loss: 0.49077728390693665
Test Loss:  0.5375857949256897
Valid Loss:  0.544369101524353
Epoch:  171  	Training Loss: 0.49034881591796875
Test Loss:  0.5371208190917969
Valid Loss:  0.5438985824584961
Epoch:  172  	Training Loss: 0.48992079496383667
Test Loss:  0.536657452583313
Valid Loss:  0.5434297919273376
Epoch:  173  	Training Loss: 0.4894939064979553
Test Loss:  0.5361945629119873
Valid Loss:  0.5429613590240479
Epoch:  174  	Training Loss: 0.4890673756599426
Test Loss:  0.5357319116592407
Valid Loss:  0.5424933433532715
Epoch:  175  	Training Loss: 0.48864126205444336
Test Loss:  0.5352698564529419
Valid Loss:  0.5420258045196533
Epoch:  176  	Training Loss: 0.48821550607681274
Test Loss:  0.5348080992698669
Valid Loss:  0.5415586233139038
Epoch:  177  	Training Loss: 0.48779016733169556
Test Loss:  0.5343467593193054
Valid Loss:  0.5410918593406677
Epoch:  178  	Training Loss: 0.48736512660980225
Test Loss:  0.5338857769966125
Valid Loss:  0.5406254529953003
Epoch:  179  	Training Loss: 0.48694050312042236
Test Loss:  0.5334253311157227
Valid Loss:  0.5401595830917358
Epoch:  180  	Training Loss: 0.48651623725891113
Test Loss:  0.5329651832580566
Valid Loss:  0.5396939516067505
Epoch:  181  	Training Loss: 0.48609232902526855
Test Loss:  0.5325053930282593
Valid Loss:  0.5392287969589233
Epoch:  182  	Training Loss: 0.48566877841949463
Test Loss:  0.5320464372634888
Valid Loss:  0.5387644171714783
Epoch:  183  	Training Loss: 0.4852456748485565
Test Loss:  0.5315878391265869
Valid Loss:  0.5383005142211914
Epoch:  184  	Training Loss: 0.48482298851013184
Test Loss:  0.5311297178268433
Valid Loss:  0.5378369092941284
Epoch:  185  	Training Loss: 0.4844006299972534
Test Loss:  0.5306719541549683
Valid Loss:  0.5373737812042236
Epoch:  186  	Training Loss: 0.48397865891456604
Test Loss:  0.5302146673202515
Valid Loss:  0.536911129951477
Epoch:  187  	Training Loss: 0.4835571050643921
Test Loss:  0.5297577381134033
Valid Loss:  0.5364488363265991
Epoch:  188  	Training Loss: 0.4831358790397644
Test Loss:  0.5293011665344238
Valid Loss:  0.5359870195388794
Epoch:  189  	Training Loss: 0.48271507024765015
Test Loss:  0.5288450717926025
Valid Loss:  0.5355255603790283
Epoch:  190  	Training Loss: 0.4822946786880493
Test Loss:  0.5283893942832947
Valid Loss:  0.5350644588470459
Epoch:  191  	Training Loss: 0.48187461495399475
Test Loss:  0.5279340744018555
Valid Loss:  0.5346038937568665
Epoch:  192  	Training Loss: 0.4814549684524536
Test Loss:  0.5274792909622192
Valid Loss:  0.5341436862945557
Epoch:  193  	Training Loss: 0.4810354709625244
Test Loss:  0.5270248651504517
Valid Loss:  0.5336840152740479
Epoch:  194  	Training Loss: 0.48061633110046387
Test Loss:  0.526570737361908
Valid Loss:  0.5332245826721191
Epoch:  195  	Training Loss: 0.480197548866272
Test Loss:  0.5261170864105225
Valid Loss:  0.5327656269073486
Epoch:  196  	Training Loss: 0.4797791838645935
Test Loss:  0.5256638526916504
Valid Loss:  0.5323070287704468
Epoch:  197  	Training Loss: 0.4793611168861389
Test Loss:  0.525210976600647
Valid Loss:  0.5318489074707031
Epoch:  198  	Training Loss: 0.47894343733787537
Test Loss:  0.5247583985328674
Valid Loss:  0.5313910245895386
Epoch:  199  	Training Loss: 0.47852617502212524
Test Loss:  0.5243062973022461
Valid Loss:  0.530933678150177
Epoch:  200  	Training Loss: 0.4781091511249542
Test Loss:  0.5238546133041382
Valid Loss:  0.5304766893386841
Epoch:  201  	Training Loss: 0.477692574262619
Test Loss:  0.5234032869338989
Valid Loss:  0.530019998550415
Epoch:  202  	Training Loss: 0.4772763252258301
Test Loss:  0.5229520797729492
Valid Loss:  0.5295635461807251
Epoch:  203  	Training Loss: 0.47686001658439636
Test Loss:  0.5225012302398682
Valid Loss:  0.5291074514389038
Epoch:  204  	Training Loss: 0.4764440655708313
Test Loss:  0.5220507383346558
Valid Loss:  0.528651773929596
Epoch:  205  	Training Loss: 0.4760284721851349
Test Loss:  0.5216007232666016
Valid Loss:  0.5281964540481567
Epoch:  206  	Training Loss: 0.47561323642730713
Test Loss:  0.521151065826416
Valid Loss:  0.527741551399231
Epoch:  207  	Training Loss: 0.4751983880996704
Test Loss:  0.5207017660140991
Valid Loss:  0.5272870659828186
Epoch:  208  	Training Loss: 0.47478389739990234
Test Loss:  0.5202528834342957
Valid Loss:  0.5268329381942749
Epoch:  209  	Training Loss: 0.47436973452568054
Test Loss:  0.5198044776916504
Valid Loss:  0.5263792276382446
Epoch:  210  	Training Loss: 0.47395598888397217
Test Loss:  0.519356369972229
Valid Loss:  0.525925874710083
Epoch:  211  	Training Loss: 0.47354263067245483
Test Loss:  0.5189086198806763
Valid Loss:  0.5254729986190796
Epoch:  212  	Training Loss: 0.4731295704841614
Test Loss:  0.5184606313705444
Valid Loss:  0.5250197052955627
Epoch:  213  	Training Loss: 0.4727160334587097
Test Loss:  0.5180129408836365
Valid Loss:  0.5245668888092041
Epoch:  214  	Training Loss: 0.4723028540611267
Test Loss:  0.5175657272338867
Valid Loss:  0.5241143703460693
Epoch:  215  	Training Loss: 0.47189003229141235
Test Loss:  0.5171188116073608
Valid Loss:  0.5236623287200928
Epoch:  216  	Training Loss: 0.47147756814956665
Test Loss:  0.5166723728179932
Valid Loss:  0.5232106447219849
Epoch:  217  	Training Loss: 0.4710655212402344
Test Loss:  0.5162262320518494
Valid Loss:  0.5227593779563904
Epoch:  218  	Training Loss: 0.470653772354126
Test Loss:  0.5157805681228638
Valid Loss:  0.5223084688186646
Epoch:  219  	Training Loss: 0.470242440700531
Test Loss:  0.5153352618217468
Valid Loss:  0.5218580365180969
Epoch:  220  	Training Loss: 0.4698314666748047
Test Loss:  0.5148904323577881
Valid Loss:  0.5214079022407532
Epoch:  221  	Training Loss: 0.469420850276947
Test Loss:  0.5144458413124084
Valid Loss:  0.5209582448005676
Epoch:  222  	Training Loss: 0.469010591506958
Test Loss:  0.5140008926391602
Valid Loss:  0.5205081701278687
Epoch:  223  	Training Loss: 0.468599796295166
 45%|████▍     | 223/500 [02:36<03:55,  1.18it/s] 45%|████▌     | 225/500 [02:36<02:51,  1.61it/s] 45%|████▌     | 227/500 [02:36<02:04,  2.19it/s] 46%|████▌     | 229/500 [02:36<01:32,  2.94it/s] 46%|████▌     | 231/500 [02:43<05:18,  1.18s/it] 47%|████▋     | 233/500 [02:43<03:47,  1.17it/s] 47%|████▋     | 235/500 [02:43<02:43,  1.62it/s] 47%|████▋     | 237/500 [02:43<01:58,  2.22it/s] 48%|████▊     | 239/500 [02:43<01:27,  2.98it/s] 48%|████▊     | 241/500 [02:49<05:00,  1.16s/it] 49%|████▊     | 243/500 [02:50<03:34,  1.20it/s] 49%|████▉     | 245/500 [02:50<02:33,  1.66it/s] 49%|████▉     | 247/500 [02:50<01:51,  2.26it/s] 50%|████▉     | 249/500 [02:50<01:22,  3.04it/s] 50%|█████     | 251/500 [02:56<04:49,  1.16s/it] 51%|█████     | 253/500 [02:56<03:26,  1.20it/s] 51%|█████     | 255/500 [02:56<02:28,  1.65it/s] 51%|█████▏    | 257/500 [02:57<01:48,  2.25it/s] 52%|█████▏    | 259/500 [02:57<01:21,  2.96it/s] 52%|█████▏    | 261/500 [03:03<04:39,  1.17s/it] 53%|█████▎    | 263/500 [03:03<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:03<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:03<01:44,  2.24it/s] 54%|█████▍    | 269/500 [03:04<01:17,  2.97it/s] 54%|█████▍    | 271/500 [03:10<04:28,  1.17s/it] 55%|█████▍    | 273/500 [03:10<03:11,  1.19it/s] 55%|█████▌    | 275/500 [03:10<02:17,  1.64it/s] 55%|█████▌    | 277/500 [03:10<01:39,  2.24it/s] 56%|█████▌    | 279/500 [03:10<01:13,  3.01it/s] 56%|█████▌    | 281/500 [03:17<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:17<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:17<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:17<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:17<01:10,  2.98it/s] 58%|█████▊    | 291/500 [03:24<04:10,  1.20s/it] 59%|█████▊    | 293/500 [03:24<02:58,  1.16it/s] 59%|█████▉    | 295/500 [03:24<02:07,  1.61it/s]Test Loss:  0.5135563611984253
Valid Loss:  0.5200583934783936
Epoch:  224  	Training Loss: 0.46818938851356506
Test Loss:  0.5131121873855591
Valid Loss:  0.5196090936660767
Epoch:  225  	Training Loss: 0.46777933835983276
Test Loss:  0.5126683712005615
Valid Loss:  0.5191601514816284
Epoch:  226  	Training Loss: 0.4673696756362915
Test Loss:  0.5122250318527222
Valid Loss:  0.5187116861343384
Epoch:  227  	Training Loss: 0.4669603705406189
Test Loss:  0.5117821097373962
Valid Loss:  0.5182635188102722
Epoch:  228  	Training Loss: 0.46655142307281494
Test Loss:  0.5113394260406494
Valid Loss:  0.5178158283233643
Epoch:  229  	Training Loss: 0.46614283323287964
Test Loss:  0.5108972787857056
Valid Loss:  0.5173684358596802
Epoch:  230  	Training Loss: 0.465734601020813
Test Loss:  0.5104554891586304
Valid Loss:  0.5169215202331543
Epoch:  231  	Training Loss: 0.4653267562389374
Test Loss:  0.5100140571594238
Valid Loss:  0.5164749622344971
Epoch:  232  	Training Loss: 0.46491923928260803
Test Loss:  0.5095717310905457
Valid Loss:  0.5160275101661682
Epoch:  233  	Training Loss: 0.46451079845428467
Test Loss:  0.5091298222541809
Valid Loss:  0.5155805349349976
Epoch:  234  	Training Loss: 0.46410271525382996
Test Loss:  0.5086883306503296
Valid Loss:  0.515133798122406
Epoch:  235  	Training Loss: 0.4636949896812439
Test Loss:  0.5082471370697021
Valid Loss:  0.5146875381469727
Epoch:  236  	Training Loss: 0.4632875919342041
Test Loss:  0.5078064203262329
Valid Loss:  0.514241635799408
Epoch:  237  	Training Loss: 0.46288061141967773
Test Loss:  0.5073660612106323
Valid Loss:  0.5137962698936462
Epoch:  238  	Training Loss: 0.46247398853302
Test Loss:  0.5069260597229004
Valid Loss:  0.5133512020111084
Epoch:  239  	Training Loss: 0.46206772327423096
Test Loss:  0.5064865350723267
Valid Loss:  0.5129064917564392
Epoch:  240  	Training Loss: 0.46166181564331055
Test Loss:  0.5060473680496216
Valid Loss:  0.5124622583389282
Epoch:  241  	Training Loss: 0.4612562656402588
Test Loss:  0.5056085586547852
Valid Loss:  0.5120183229446411
Epoch:  242  	Training Loss: 0.4608510732650757
Test Loss:  0.5051686763763428
Valid Loss:  0.511573314666748
Epoch:  243  	Training Loss: 0.46044468879699707
Test Loss:  0.5047290325164795
Valid Loss:  0.5111286640167236
Epoch:  244  	Training Loss: 0.4600386619567871
Test Loss:  0.5042898654937744
Valid Loss:  0.5106843709945679
Epoch:  245  	Training Loss: 0.4596329927444458
Test Loss:  0.5038511157035828
Valid Loss:  0.5102405548095703
Epoch:  246  	Training Loss: 0.45922771096229553
Test Loss:  0.503412663936615
Valid Loss:  0.5097969770431519
Epoch:  247  	Training Loss: 0.45882272720336914
Test Loss:  0.5029746890068054
Valid Loss:  0.5093539953231812
Epoch:  248  	Training Loss: 0.45841819047927856
Test Loss:  0.5025370121002197
Valid Loss:  0.5089112520217896
Epoch:  249  	Training Loss: 0.45801395177841187
Test Loss:  0.5020997524261475
Valid Loss:  0.5084689855575562
Epoch:  250  	Training Loss: 0.4576100707054138
Test Loss:  0.5016629099845886
Valid Loss:  0.5080270171165466
Epoch:  251  	Training Loss: 0.4572065472602844
Test Loss:  0.5012263655662537
Valid Loss:  0.5075854659080505
Epoch:  252  	Training Loss: 0.4568033814430237
Test Loss:  0.5007888078689575
Valid Loss:  0.5071428418159485
Epoch:  253  	Training Loss: 0.456399142742157
Test Loss:  0.5003516674041748
Valid Loss:  0.5067005753517151
Epoch:  254  	Training Loss: 0.45599523186683655
Test Loss:  0.4999147653579712
Valid Loss:  0.5062587261199951
Epoch:  255  	Training Loss: 0.45559173822402954
Test Loss:  0.49947839975357056
Valid Loss:  0.5058172345161438
Epoch:  256  	Training Loss: 0.4551885724067688
Test Loss:  0.4990423619747162
Valid Loss:  0.5053761005401611
Epoch:  257  	Training Loss: 0.45478570461273193
Test Loss:  0.4986066520214081
Valid Loss:  0.5049353837966919
Epoch:  258  	Training Loss: 0.4543832540512085
Test Loss:  0.49817129969596863
Valid Loss:  0.5044950246810913
Epoch:  259  	Training Loss: 0.4539811313152313
Test Loss:  0.497736394405365
Valid Loss:  0.5040550827980042
Epoch:  260  	Training Loss: 0.4535793662071228
Test Loss:  0.4973018765449524
Valid Loss:  0.5036154985427856
Epoch:  261  	Training Loss: 0.45317792892456055
Test Loss:  0.49686771631240845
Valid Loss:  0.5031763315200806
Epoch:  262  	Training Loss: 0.4527769088745117
Test Loss:  0.496432363986969
Valid Loss:  0.50273597240448
Epoch:  263  	Training Loss: 0.452374666929245
Test Loss:  0.49599748849868774
Valid Loss:  0.5022960901260376
Epoch:  264  	Training Loss: 0.4519728720188141
Test Loss:  0.49556294083595276
Valid Loss:  0.5018565058708191
Epoch:  265  	Training Loss: 0.45157140493392944
Test Loss:  0.4951288104057312
Valid Loss:  0.501417338848114
Epoch:  266  	Training Loss: 0.45117026567459106
Test Loss:  0.4946950674057007
Valid Loss:  0.5009785890579224
Epoch:  267  	Training Loss: 0.4507695138454437
Test Loss:  0.49426162242889404
Valid Loss:  0.5005401968955994
Epoch:  268  	Training Loss: 0.45036911964416504
Test Loss:  0.49382874369621277
Valid Loss:  0.5001022219657898
Epoch:  269  	Training Loss: 0.4499691426753998
Test Loss:  0.493396133184433
Valid Loss:  0.4996646046638489
Epoch:  270  	Training Loss: 0.4495694637298584
Test Loss:  0.49296391010284424
Valid Loss:  0.4992274045944214
Epoch:  271  	Training Loss: 0.44917014241218567
Test Loss:  0.4925321042537689
Valid Loss:  0.4987906217575073
Epoch:  272  	Training Loss: 0.4487711787223816
Test Loss:  0.49209898710250854
Valid Loss:  0.4983524680137634
Epoch:  273  	Training Loss: 0.44837093353271484
Test Loss:  0.49166619777679443
Valid Loss:  0.4979146718978882
Epoch:  274  	Training Loss: 0.44797101616859436
Test Loss:  0.491233766078949
Valid Loss:  0.49747729301452637
Epoch:  275  	Training Loss: 0.44757145643234253
Test Loss:  0.49080175161361694
Valid Loss:  0.4970402717590332
Epoch:  276  	Training Loss: 0.44717225432395935
Test Loss:  0.49037015438079834
Valid Loss:  0.49660366773605347
Epoch:  277  	Training Loss: 0.4467734098434448
Test Loss:  0.4899388551712036
Valid Loss:  0.4961674213409424
Epoch:  278  	Training Loss: 0.44637492299079895
Test Loss:  0.4895080029964447
Valid Loss:  0.49573156237602234
Epoch:  279  	Training Loss: 0.44597679376602173
Test Loss:  0.48907750844955444
Valid Loss:  0.4952961206436157
Epoch:  280  	Training Loss: 0.44557899236679077
Test Loss:  0.4886474013328552
Valid Loss:  0.494860976934433
Epoch:  281  	Training Loss: 0.44518154859542847
Test Loss:  0.48821765184402466
Valid Loss:  0.49442631006240845
Epoch:  282  	Training Loss: 0.4447844624519348
Test Loss:  0.4877866506576538
Valid Loss:  0.49399033188819885
Epoch:  283  	Training Loss: 0.44438618421554565
Test Loss:  0.4873560667037964
Valid Loss:  0.4935547709465027
Epoch:  284  	Training Loss: 0.44398826360702515
Test Loss:  0.4869258403778076
Valid Loss:  0.4931195378303528
Epoch:  285  	Training Loss: 0.4435907006263733
Test Loss:  0.4864960312843323
Valid Loss:  0.49268484115600586
Epoch:  286  	Training Loss: 0.4431934952735901
Test Loss:  0.486066609621048
Valid Loss:  0.49225038290023804
Epoch:  287  	Training Loss: 0.44279664754867554
Test Loss:  0.4856375455856323
Valid Loss:  0.4918164014816284
Epoch:  288  	Training Loss: 0.44240015745162964
Test Loss:  0.4852088987827301
Valid Loss:  0.49138280749320984
Epoch:  289  	Training Loss: 0.4420040249824524
Test Loss:  0.4847806692123413
Valid Loss:  0.4909495711326599
Epoch:  290  	Training Loss: 0.4416082799434662
Test Loss:  0.4843527674674988
Valid Loss:  0.4905167818069458
Epoch:  291  	Training Loss: 0.44121286273002625
Test Loss:  0.4839252829551697
Valid Loss:  0.49008435010910034
Epoch:  292  	Training Loss: 0.44081783294677734
Test Loss:  0.4834965169429779
Valid Loss:  0.4896506071090698
Epoch:  293  	Training Loss: 0.44042155146598816
Test Loss:  0.4830681085586548
Valid Loss:  0.48921728134155273
Epoch:  294  	Training Loss: 0.4400256276130676
Test Loss:  0.4826400876045227
Valid Loss:  0.4887843132019043
Epoch:  295  	Training Loss: 0.43963003158569336
Test Loss:  0.48221245408058167
Valid Loss:  0.4883517622947693
Epoch:  296  	Training Loss: 0.4392348527908325
Test Loss:  0.48178523778915405
 59%|█████▉    | 297/500 [03:24<01:32,  2.20it/s] 60%|█████▉    | 299/500 [03:24<01:08,  2.95it/s] 60%|██████    | 301/500 [03:30<03:53,  1.17s/it] 61%|██████    | 303/500 [03:31<02:45,  1.19it/s] 61%|██████    | 305/500 [03:31<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:31<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:31<01:05,  2.92it/s] 62%|██████▏   | 311/500 [03:37<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:37<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:38<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:38<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:38<01:00,  3.01it/s] 64%|██████▍   | 321/500 [03:44<03:29,  1.17s/it] 65%|██████▍   | 323/500 [03:44<02:28,  1.19it/s] 65%|██████▌   | 325/500 [03:44<01:46,  1.65it/s] 65%|██████▌   | 327/500 [03:44<01:16,  2.25it/s] 66%|██████▌   | 329/500 [03:45<00:56,  3.01it/s] 66%|██████▌   | 331/500 [03:51<03:18,  1.17s/it] 67%|██████▋   | 333/500 [03:51<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:51<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:51<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:51<00:53,  3.00it/s] 68%|██████▊   | 341/500 [03:58<03:06,  1.17s/it] 69%|██████▊   | 343/500 [03:58<02:11,  1.19it/s] 69%|██████▉   | 345/500 [03:58<01:34,  1.64it/s] 69%|██████▉   | 347/500 [03:58<01:08,  2.24it/s] 70%|██████▉   | 349/500 [03:58<00:50,  3.02it/s] 70%|███████   | 351/500 [04:04<02:54,  1.17s/it] 71%|███████   | 353/500 [04:05<02:03,  1.19it/s] 71%|███████   | 355/500 [04:05<01:27,  1.65it/s] 71%|███████▏  | 357/500 [04:05<01:03,  2.25it/s] 72%|███████▏  | 359/500 [04:05<00:46,  3.02it/s] 72%|███████▏  | 361/500 [04:11<02:40,  1.15s/it] 73%|███████▎  | 363/500 [04:11<01:53,  1.21it/s] 73%|███████▎  | 365/500 [04:11<01:20,  1.67it/s] 73%|███████▎  | 367/500 [04:12<00:58,  2.28it/s]Valid Loss:  0.4879196286201477
Epoch:  297  	Training Loss: 0.43884003162384033
Test Loss:  0.4813584089279175
Valid Loss:  0.4874878227710724
Epoch:  298  	Training Loss: 0.4384455382823944
Test Loss:  0.48093193769454956
Valid Loss:  0.4870564341545105
Epoch:  299  	Training Loss: 0.43805140256881714
Test Loss:  0.48050588369369507
Valid Loss:  0.4866254925727844
Epoch:  300  	Training Loss: 0.4376576542854309
Test Loss:  0.48008018732070923
Valid Loss:  0.486194908618927
Epoch:  301  	Training Loss: 0.43726423382759094
Test Loss:  0.4796549081802368
Valid Loss:  0.48576468229293823
Epoch:  302  	Training Loss: 0.436871200799942
Test Loss:  0.4792277216911316
Valid Loss:  0.48533254861831665
Epoch:  303  	Training Loss: 0.43647634983062744
Test Loss:  0.47880101203918457
Valid Loss:  0.48490089178085327
Epoch:  304  	Training Loss: 0.4360819160938263
Test Loss:  0.4783746004104614
Valid Loss:  0.48446962237358093
Epoch:  305  	Training Loss: 0.4356878399848938
Test Loss:  0.4779486656188965
Valid Loss:  0.48403874039649963
Epoch:  306  	Training Loss: 0.43529415130615234
Test Loss:  0.4775230586528778
Valid Loss:  0.4836082458496094
Epoch:  307  	Training Loss: 0.43490076065063477
Test Loss:  0.47709783911705017
Valid Loss:  0.48317813873291016
Epoch:  308  	Training Loss: 0.43450772762298584
Test Loss:  0.47667303681373596
Valid Loss:  0.4827483892440796
Epoch:  309  	Training Loss: 0.43411511182785034
Test Loss:  0.4762486219406128
Valid Loss:  0.4823191165924072
Epoch:  310  	Training Loss: 0.4337228238582611
Test Loss:  0.47582459449768066
Valid Loss:  0.48189014196395874
Epoch:  311  	Training Loss: 0.4333308935165405
Test Loss:  0.4754009246826172
Valid Loss:  0.48146161437034607
Epoch:  312  	Training Loss: 0.4329393804073334
Test Loss:  0.4749760329723358
Valid Loss:  0.4810318648815155
Epoch:  313  	Training Loss: 0.43254661560058594
Test Loss:  0.4745514988899231
Valid Loss:  0.4806023836135864
Epoch:  314  	Training Loss: 0.43215420842170715
Test Loss:  0.4741274118423462
Valid Loss:  0.48017340898513794
Epoch:  315  	Training Loss: 0.431762158870697
Test Loss:  0.47370362281799316
Valid Loss:  0.47974473237991333
Epoch:  316  	Training Loss: 0.43137046694755554
Test Loss:  0.47328028082847595
Valid Loss:  0.47931650280952454
Epoch:  317  	Training Loss: 0.4309791922569275
Test Loss:  0.472857266664505
Valid Loss:  0.4788886308670044
Epoch:  318  	Training Loss: 0.4305881857872009
Test Loss:  0.4724346995353699
Valid Loss:  0.4784611463546753
Epoch:  319  	Training Loss: 0.4301975965499878
Test Loss:  0.4720124900341034
Valid Loss:  0.478034108877182
Epoch:  320  	Training Loss: 0.4298073649406433
Test Loss:  0.47159066796302795
Valid Loss:  0.4776074290275574
Epoch:  321  	Training Loss: 0.4294174909591675
Test Loss:  0.47116923332214355
Valid Loss:  0.4771811366081238
Epoch:  322  	Training Loss: 0.4290279746055603
Test Loss:  0.47074612975120544
Valid Loss:  0.4767531156539917
Epoch:  323  	Training Loss: 0.4286368787288666
Test Loss:  0.47032344341278076
Valid Loss:  0.4763255715370178
Epoch:  324  	Training Loss: 0.4282461702823639
Test Loss:  0.46990111470222473
Valid Loss:  0.4758983552455902
Epoch:  325  	Training Loss: 0.42785578966140747
Test Loss:  0.46947920322418213
Valid Loss:  0.4754716157913208
Epoch:  326  	Training Loss: 0.4274657964706421
Test Loss:  0.46905767917633057
Valid Loss:  0.47504520416259766
Epoch:  327  	Training Loss: 0.42707619071006775
Test Loss:  0.46863657236099243
Valid Loss:  0.47461920976638794
Epoch:  328  	Training Loss: 0.42668694257736206
Test Loss:  0.46821579337120056
Valid Loss:  0.47419360280036926
Epoch:  329  	Training Loss: 0.42629802227020264
Test Loss:  0.4677954316139221
Valid Loss:  0.4737683832645416
Epoch:  330  	Training Loss: 0.42590945959091187
Test Loss:  0.4673754572868347
Valid Loss:  0.47334355115890503
Epoch:  331  	Training Loss: 0.4255213141441345
Test Loss:  0.46695590019226074
Valid Loss:  0.4729191064834595
Epoch:  332  	Training Loss: 0.42513346672058105
Test Loss:  0.4665348529815674
Valid Loss:  0.4724932312965393
Epoch:  333  	Training Loss: 0.42474427819252014
Test Loss:  0.46611422300338745
Valid Loss:  0.47206777334213257
Epoch:  334  	Training Loss: 0.42435547709465027
Test Loss:  0.46569401025772095
Valid Loss:  0.47164273262023926
Epoch:  335  	Training Loss: 0.42396703362464905
Test Loss:  0.46527421474456787
Valid Loss:  0.4712180495262146
Epoch:  336  	Training Loss: 0.42357897758483887
Test Loss:  0.4648546874523163
Valid Loss:  0.4707936942577362
Epoch:  337  	Training Loss: 0.42319121956825256
Test Loss:  0.4644356369972229
Valid Loss:  0.47036978602409363
Epoch:  338  	Training Loss: 0.4228038489818573
Test Loss:  0.4640169143676758
Valid Loss:  0.4699462652206421
Epoch:  339  	Training Loss: 0.4224168658256531
Test Loss:  0.4635986089706421
Valid Loss:  0.4695231318473816
Epoch:  340  	Training Loss: 0.4220302104949951
Test Loss:  0.4631807208061218
Valid Loss:  0.46910035610198975
Epoch:  341  	Training Loss: 0.4216439127922058
Test Loss:  0.4627631902694702
Valid Loss:  0.4686780273914337
Epoch:  342  	Training Loss: 0.42125797271728516
Test Loss:  0.46234381198883057
Valid Loss:  0.46825385093688965
Epoch:  343  	Training Loss: 0.4208703637123108
Test Loss:  0.4619249105453491
Valid Loss:  0.4678301215171814
Epoch:  344  	Training Loss: 0.4204831123352051
Test Loss:  0.4615064263343811
Valid Loss:  0.4674067795276642
Epoch:  345  	Training Loss: 0.4200962483882904
Test Loss:  0.46108824014663696
Valid Loss:  0.4669837951660156
Epoch:  346  	Training Loss: 0.4197096824645996
Test Loss:  0.46067047119140625
Valid Loss:  0.4665611982345581
Epoch:  347  	Training Loss: 0.41932350397109985
Test Loss:  0.4602530598640442
Valid Loss:  0.46613895893096924
Epoch:  348  	Training Loss: 0.41893768310546875
Test Loss:  0.45983603596687317
Valid Loss:  0.4657171368598938
Epoch:  349  	Training Loss: 0.4185522198677063
Test Loss:  0.4594193994998932
Valid Loss:  0.465295672416687
Epoch:  350  	Training Loss: 0.4181671142578125
Test Loss:  0.45900315046310425
Valid Loss:  0.4648746848106384
Epoch:  351  	Training Loss: 0.41778236627578735
Test Loss:  0.45858728885650635
Valid Loss:  0.4644539952278137
Epoch:  352  	Training Loss: 0.41739794611930847
Test Loss:  0.45817017555236816
Valid Loss:  0.46403205394744873
Epoch:  353  	Training Loss: 0.41701239347457886
Test Loss:  0.45775341987609863
Valid Loss:  0.4636104702949524
Epoch:  354  	Training Loss: 0.4166271686553955
Test Loss:  0.45733705163002014
Valid Loss:  0.4631893038749695
Epoch:  355  	Training Loss: 0.4162423014640808
Test Loss:  0.4569211006164551
Valid Loss:  0.4627685546875
Epoch:  356  	Training Loss: 0.4158577620983124
Test Loss:  0.4565054774284363
Valid Loss:  0.46234816312789917
Epoch:  357  	Training Loss: 0.415473610162735
Test Loss:  0.4560903012752533
Valid Loss:  0.4619281589984894
Epoch:  358  	Training Loss: 0.41508984565734863
Test Loss:  0.45567548274993896
Valid Loss:  0.461508572101593
Epoch:  359  	Training Loss: 0.41470640897750854
Test Loss:  0.45526108145713806
Valid Loss:  0.4610893726348877
Epoch:  360  	Training Loss: 0.4143233895301819
Test Loss:  0.4548470377922058
Valid Loss:  0.460670530796051
Epoch:  361  	Training Loss: 0.4139406681060791
Test Loss:  0.4544333815574646
Valid Loss:  0.4602521061897278
Epoch:  362  	Training Loss: 0.41355833411216736
Test Loss:  0.4540178179740906
Valid Loss:  0.45983177423477173
Epoch:  363  	Training Loss: 0.41317418217658997
Test Loss:  0.45360270142555237
Valid Loss:  0.4594118595123291
Epoch:  364  	Training Loss: 0.4127904176712036
Test Loss:  0.4531879425048828
Valid Loss:  0.4589923024177551
Epoch:  365  	Training Loss: 0.4124070405960083
Test Loss:  0.4527735710144043
Valid Loss:  0.4585731327533722
Epoch:  366  	Training Loss: 0.41202402114868164
Test Loss:  0.45235955715179443
Valid Loss:  0.4581543803215027
Epoch:  367  	Training Loss: 0.41164129972457886
Test Loss:  0.451945960521698
Valid Loss:  0.4577360153198242
Epoch:  368  	Training Loss: 0.4112589955329895
Test Loss:  0.4515327215194702
Valid Loss:  0.4573180079460144
Epoch:  369  	Training Loss: 0.4108770191669464
Test Loss:  0.45111989974975586
 74%|███████▍  | 369/500 [04:12<00:42,  3.06it/s] 74%|███████▍  | 371/500 [04:18<02:29,  1.16s/it] 75%|███████▍  | 373/500 [04:18<01:45,  1.20it/s] 75%|███████▌  | 375/500 [04:18<01:15,  1.66it/s] 75%|███████▌  | 377/500 [04:18<00:54,  2.27it/s] 76%|███████▌  | 379/500 [04:18<00:39,  3.04it/s] 76%|███████▌  | 381/500 [04:25<02:18,  1.16s/it] 77%|███████▋  | 383/500 [04:25<01:37,  1.20it/s] 77%|███████▋  | 385/500 [04:25<01:09,  1.66it/s] 77%|███████▋  | 387/500 [04:25<00:49,  2.26it/s] 78%|███████▊  | 389/500 [04:25<00:36,  3.02it/s] 78%|███████▊  | 391/500 [04:31<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:32<01:29,  1.19it/s] 79%|███████▉  | 395/500 [04:32<01:03,  1.65it/s] 79%|███████▉  | 397/500 [04:32<00:45,  2.25it/s] 80%|███████▉  | 399/500 [04:32<00:33,  3.01it/s] 80%|████████  | 401/500 [04:38<01:56,  1.17s/it] 81%|████████  | 403/500 [04:38<01:21,  1.19it/s] 81%|████████  | 405/500 [04:38<00:57,  1.64it/s] 81%|████████▏ | 407/500 [04:39<00:41,  2.24it/s] 82%|████████▏ | 409/500 [04:39<00:30,  3.02it/s] 82%|████████▏ | 411/500 [04:45<01:45,  1.18s/it] 83%|████████▎ | 413/500 [04:45<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:45<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:45<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:46<00:27,  2.99it/s] 84%|████████▍ | 421/500 [04:52<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:52<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:52<00:45,  1.63it/s] 85%|████████▌ | 427/500 [04:52<00:32,  2.23it/s] 86%|████████▌ | 429/500 [04:52<00:23,  3.00it/s] 86%|████████▌ | 431/500 [04:59<01:21,  1.18s/it] 87%|████████▋ | 433/500 [04:59<00:56,  1.18it/s] 87%|████████▋ | 435/500 [04:59<00:39,  1.63it/s] 87%|████████▋ | 437/500 [04:59<00:28,  2.22it/s] 88%|████████▊ | 439/500 [04:59<00:20,  2.98it/s] 88%|████████▊ | 441/500 [05:05<01:08,  1.17s/it]Valid Loss:  0.456900417804718
Epoch:  370  	Training Loss: 0.41049546003341675
Test Loss:  0.45070743560791016
Valid Loss:  0.4564831852912903
Epoch:  371  	Training Loss: 0.41011419892311096
Test Loss:  0.4502953886985779
Valid Loss:  0.456066370010376
Epoch:  372  	Training Loss: 0.40973329544067383
Test Loss:  0.44988182187080383
Valid Loss:  0.4556480050086975
Epoch:  373  	Training Loss: 0.40935102105140686
Test Loss:  0.4494686722755432
Valid Loss:  0.45523011684417725
Epoch:  374  	Training Loss: 0.40896910429000854
Test Loss:  0.44905588030815125
Valid Loss:  0.45481258630752563
Epoch:  375  	Training Loss: 0.4085875153541565
Test Loss:  0.4486434757709503
Valid Loss:  0.4543953537940979
Epoch:  376  	Training Loss: 0.40820634365081787
Test Loss:  0.4482314884662628
Valid Loss:  0.45397859811782837
Epoch:  377  	Training Loss: 0.4078254699707031
Test Loss:  0.44781988859176636
Valid Loss:  0.45356225967407227
Epoch:  378  	Training Loss: 0.4074450135231018
Test Loss:  0.44740867614746094
Valid Loss:  0.4531462788581848
Epoch:  379  	Training Loss: 0.40706491470336914
Test Loss:  0.44699782133102417
Valid Loss:  0.4527307152748108
Epoch:  380  	Training Loss: 0.4066851735115051
Test Loss:  0.44658738374710083
Valid Loss:  0.4523155391216278
Epoch:  381  	Training Loss: 0.40630581974983215
Test Loss:  0.4461773633956909
Valid Loss:  0.45190078020095825
Epoch:  382  	Training Loss: 0.40592682361602783
Test Loss:  0.4457661509513855
Valid Loss:  0.4514847993850708
Epoch:  383  	Training Loss: 0.40554672479629517
Test Loss:  0.4453553259372711
Valid Loss:  0.4510692358016968
Epoch:  384  	Training Loss: 0.40516701340675354
Test Loss:  0.44494491815567017
Valid Loss:  0.4506540894508362
Epoch:  385  	Training Loss: 0.40478768944740295
Test Loss:  0.44453489780426025
Valid Loss:  0.4502393305301666
Epoch:  386  	Training Loss: 0.40440869331359863
Test Loss:  0.444125235080719
Valid Loss:  0.4498249292373657
Epoch:  387  	Training Loss: 0.40403005480766296
Test Loss:  0.4437159299850464
Valid Loss:  0.44941088557243347
Epoch:  388  	Training Loss: 0.40365177392959595
Test Loss:  0.4433070421218872
Valid Loss:  0.44899728894233704
Epoch:  389  	Training Loss: 0.40327388048171997
Test Loss:  0.4428984820842743
Valid Loss:  0.44858402013778687
Epoch:  390  	Training Loss: 0.4028962552547455
Test Loss:  0.4424903392791748
Valid Loss:  0.4481711685657501
Epoch:  391  	Training Loss: 0.4025190770626068
Test Loss:  0.44208261370658875
Valid Loss:  0.44775867462158203
Epoch:  392  	Training Loss: 0.4021422266960144
Test Loss:  0.44167327880859375
Valid Loss:  0.4473446309566498
Epoch:  393  	Training Loss: 0.401763916015625
Test Loss:  0.44126439094543457
Valid Loss:  0.44693100452423096
Epoch:  394  	Training Loss: 0.40138599276542664
Test Loss:  0.4408559203147888
Valid Loss:  0.44651779532432556
Epoch:  395  	Training Loss: 0.4010084271430969
Test Loss:  0.44044771790504456
Valid Loss:  0.4461049437522888
Epoch:  396  	Training Loss: 0.4006311893463135
Test Loss:  0.4400399923324585
Valid Loss:  0.4456924796104431
Epoch:  397  	Training Loss: 0.40025433897972107
Test Loss:  0.4396325945854187
Valid Loss:  0.4452803432941437
Epoch:  398  	Training Loss: 0.39987778663635254
Test Loss:  0.43922561407089233
Valid Loss:  0.44486868381500244
Epoch:  399  	Training Loss: 0.3995016813278198
Test Loss:  0.4388189911842346
Valid Loss:  0.4444572925567627
Epoch:  400  	Training Loss: 0.3991258442401886
Test Loss:  0.43841272592544556
Valid Loss:  0.44404640793800354
Epoch:  401  	Training Loss: 0.3987504243850708
Test Loss:  0.43800684809684753
Valid Loss:  0.44363582134246826
Epoch:  402  	Training Loss: 0.39837533235549927
Test Loss:  0.43759945034980774
Valid Loss:  0.4432236850261688
Epoch:  403  	Training Loss: 0.39799875020980835
Test Loss:  0.4371923804283142
Valid Loss:  0.4428119659423828
Epoch:  404  	Training Loss: 0.39762258529663086
Test Loss:  0.4367857575416565
Valid Loss:  0.44240057468414307
Epoch:  405  	Training Loss: 0.39724671840667725
Test Loss:  0.43637943267822266
Valid Loss:  0.44198963046073914
Epoch:  406  	Training Loss: 0.3968712389469147
Test Loss:  0.435973584651947
Valid Loss:  0.44157904386520386
Epoch:  407  	Training Loss: 0.39649611711502075
Test Loss:  0.43556806445121765
Valid Loss:  0.44116881489753723
Epoch:  408  	Training Loss: 0.39612138271331787
Test Loss:  0.4351629316806793
Valid Loss:  0.44075900316238403
Epoch:  409  	Training Loss: 0.39574694633483887
Test Loss:  0.43475815653800964
Valid Loss:  0.4403495788574219
Epoch:  410  	Training Loss: 0.3953728675842285
Test Loss:  0.434353768825531
Valid Loss:  0.439940482378006
Epoch:  411  	Training Loss: 0.3949991464614868
Test Loss:  0.4339497983455658
Valid Loss:  0.4395318031311035
Epoch:  412  	Training Loss: 0.39462581276893616
Test Loss:  0.43354442715644836
Valid Loss:  0.4391217529773712
Epoch:  413  	Training Loss: 0.39425116777420044
Test Loss:  0.43313950300216675
Valid Loss:  0.43871212005615234
Epoch:  414  	Training Loss: 0.39387694001197815
Test Loss:  0.432734876871109
Valid Loss:  0.4383028447628021
Epoch:  415  	Training Loss: 0.39350301027297974
Test Loss:  0.4323306977748871
Valid Loss:  0.4378940165042877
Epoch:  416  	Training Loss: 0.39312946796417236
Test Loss:  0.4319269061088562
Valid Loss:  0.4374855160713196
Epoch:  417  	Training Loss: 0.39275628328323364
Test Loss:  0.43152347207069397
Valid Loss:  0.43707743287086487
Epoch:  418  	Training Loss: 0.3923834562301636
Test Loss:  0.4311204254627228
Valid Loss:  0.4366697669029236
Epoch:  419  	Training Loss: 0.39201098680496216
Test Loss:  0.43071770668029785
Valid Loss:  0.4362623691558838
Epoch:  420  	Training Loss: 0.3916388154029846
Test Loss:  0.43031546473503113
Valid Loss:  0.4358554482460022
Epoch:  421  	Training Loss: 0.3912670910358429
Test Loss:  0.4299135208129883
Valid Loss:  0.4354488253593445
Epoch:  422  	Training Loss: 0.39089566469192505
Test Loss:  0.42951029539108276
Valid Loss:  0.4350409507751465
Epoch:  423  	Training Loss: 0.3905230164527893
Test Loss:  0.4291073977947235
Valid Loss:  0.43463337421417236
Epoch:  424  	Training Loss: 0.3901507258415222
Test Loss:  0.4287049472332001
Valid Loss:  0.43422627449035645
Epoch:  425  	Training Loss: 0.3897787928581238
Test Loss:  0.4283028542995453
Valid Loss:  0.4338195323944092
Epoch:  426  	Training Loss: 0.389407217502594
Test Loss:  0.42790114879608154
Valid Loss:  0.43341317772865295
Epoch:  427  	Training Loss: 0.38903599977493286
Test Loss:  0.42749983072280884
Valid Loss:  0.4330071806907654
Epoch:  428  	Training Loss: 0.38866516947746277
Test Loss:  0.4270988702774048
Valid Loss:  0.43260160088539124
Epoch:  429  	Training Loss: 0.38829469680786133
Test Loss:  0.42669832706451416
Valid Loss:  0.43219640851020813
Epoch:  430  	Training Loss: 0.38792455196380615
Test Loss:  0.42629820108413696
Valid Loss:  0.43179160356521606
Epoch:  431  	Training Loss: 0.38755476474761963
Test Loss:  0.42589840292930603
Valid Loss:  0.43138718605041504
Epoch:  432  	Training Loss: 0.38718533515930176
Test Loss:  0.42549723386764526
Valid Loss:  0.4309813976287842
Epoch:  433  	Training Loss: 0.386814683675766
Test Loss:  0.4250965118408203
Valid Loss:  0.43057602643966675
Epoch:  434  	Training Loss: 0.3864443898200989
Test Loss:  0.4246961772441864
Valid Loss:  0.43017101287841797
Epoch:  435  	Training Loss: 0.3860744535923004
Test Loss:  0.42429617047309875
Valid Loss:  0.4297664165496826
Epoch:  436  	Training Loss: 0.3857048451900482
Test Loss:  0.42389655113220215
Valid Loss:  0.4293621778488159
Epoch:  437  	Training Loss: 0.3853355944156647
Test Loss:  0.4234973192214966
Valid Loss:  0.42895829677581787
Epoch:  438  	Training Loss: 0.3849667012691498
Test Loss:  0.42309850454330444
Valid Loss:  0.42855483293533325
Epoch:  439  	Training Loss: 0.3845981955528259
Test Loss:  0.42270004749298096
Valid Loss:  0.42815178632736206
Epoch:  440  	Training Loss: 0.38423001766204834
Test Loss:  0.4223020076751709
Valid Loss:  0.4277490973472595
Epoch:  441  	Training Loss: 0.3838621973991394
Test Loss:  0.4219042658805847
Valid Loss:  0.42734676599502563
Epoch:  442  	Training Loss: 0.3834947347640991
Test Loss:   89%|████████▊ | 443/500 [05:06<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:06<00:33,  1.65it/s] 89%|████████▉ | 447/500 [05:06<00:23,  2.25it/s] 90%|████████▉ | 449/500 [05:06<00:16,  3.02it/s] 90%|█████████ | 451/500 [05:12<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:12<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:13<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:13<00:19,  2.24it/s] 92%|█████████▏| 459/500 [05:13<00:13,  3.01it/s] 92%|█████████▏| 461/500 [05:19<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:19<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:19<00:21,  1.65it/s] 93%|█████████▎| 467/500 [05:19<00:14,  2.25it/s] 94%|█████████▍| 469/500 [05:20<00:10,  3.02it/s] 94%|█████████▍| 471/500 [05:26<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:26<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:26<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:26<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:26<00:07,  2.99it/s] 96%|█████████▌| 481/500 [05:33<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:33<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:33<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:33<00:05,  2.21it/s] 98%|█████████▊| 489/500 [05:33<00:03,  2.97it/s] 98%|█████████▊| 491/500 [05:40<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:40<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:40<00:03,  1.62it/s] 99%|█████████▉| 497/500 [05:40<00:01,  2.21it/s]100%|█████████▉| 499/500 [05:40<00:00,  2.96it/s]100%|██████████| 500/500 [05:40<00:00,  1.47it/s]
0.42150557041168213
Valid Loss:  0.42694348096847534
Epoch:  443  	Training Loss: 0.3831263482570648
Test Loss:  0.4211072325706482
Valid Loss:  0.4265405237674713
Epoch:  444  	Training Loss: 0.38275831937789917
Test Loss:  0.4207093119621277
Valid Loss:  0.4261379539966583
Epoch:  445  	Training Loss: 0.3823906183242798
Test Loss:  0.42031174898147583
Valid Loss:  0.4257357716560364
Epoch:  446  	Training Loss: 0.38202333450317383
Test Loss:  0.4199146032333374
Valid Loss:  0.42533400654792786
Epoch:  447  	Training Loss: 0.38165634870529175
Test Loss:  0.4195178151130676
Valid Loss:  0.42493265867233276
Epoch:  448  	Training Loss: 0.3812897503376007
Test Loss:  0.4191213846206665
Valid Loss:  0.42453160881996155
Epoch:  449  	Training Loss: 0.3809235095977783
Test Loss:  0.4187253713607788
Valid Loss:  0.42413097620010376
Epoch:  450  	Training Loss: 0.3805575966835022
Test Loss:  0.41832977533340454
Valid Loss:  0.423730731010437
Epoch:  451  	Training Loss: 0.3801920413970947
Test Loss:  0.41793447732925415
Valid Loss:  0.4233309030532837
Epoch:  452  	Training Loss: 0.3798268735408783
Test Loss:  0.41753777861595154
Valid Loss:  0.4229296147823334
Epoch:  453  	Training Loss: 0.3794603645801544
Test Loss:  0.41714149713516235
Valid Loss:  0.4225287139415741
Epoch:  454  	Training Loss: 0.3790941834449768
Test Loss:  0.4167455732822418
Valid Loss:  0.42212820053100586
Epoch:  455  	Training Loss: 0.37872838973999023
Test Loss:  0.41635003685951233
Valid Loss:  0.42172807455062866
Epoch:  456  	Training Loss: 0.3783629536628723
Test Loss:  0.4159548282623291
Valid Loss:  0.42132827639579773
Epoch:  457  	Training Loss: 0.37799781560897827
Test Loss:  0.4155600368976593
Valid Loss:  0.4209289252758026
Epoch:  458  	Training Loss: 0.37763309478759766
Test Loss:  0.41516563296318054
Valid Loss:  0.42052993178367615
Epoch:  459  	Training Loss: 0.3772687017917633
Test Loss:  0.4147716164588928
Valid Loss:  0.4201313555240631
Epoch:  460  	Training Loss: 0.3769046664237976
Test Loss:  0.41437798738479614
Valid Loss:  0.41973310708999634
Epoch:  461  	Training Loss: 0.37654101848602295
Test Loss:  0.4139847159385681
Valid Loss:  0.419335275888443
Epoch:  462  	Training Loss: 0.37617769837379456
Test Loss:  0.413590669631958
Valid Loss:  0.41893666982650757
Epoch:  463  	Training Loss: 0.37581366300582886
Test Loss:  0.41319698095321655
Valid Loss:  0.4185384213924408
Epoch:  464  	Training Loss: 0.3754499554634094
Test Loss:  0.4128037095069885
Valid Loss:  0.41814059019088745
Epoch:  465  	Training Loss: 0.37508663535118103
Test Loss:  0.41241082549095154
Valid Loss:  0.41774314641952515
Epoch:  466  	Training Loss: 0.3747236728668213
Test Loss:  0.4120182991027832
Valid Loss:  0.4173460602760315
Epoch:  467  	Training Loss: 0.3743610978126526
Test Loss:  0.4116261601448059
Valid Loss:  0.41694939136505127
Epoch:  468  	Training Loss: 0.37399882078170776
Test Loss:  0.41123443841934204
Valid Loss:  0.4165530800819397
Epoch:  469  	Training Loss: 0.37363696098327637
Test Loss:  0.41084304451942444
Valid Loss:  0.41615715622901917
Epoch:  470  	Training Loss: 0.37327542901039124
Test Loss:  0.41045206785202026
Valid Loss:  0.4157615900039673
Epoch:  471  	Training Loss: 0.37291425466537476
Test Loss:  0.41006141901016235
Valid Loss:  0.41536641120910645
Epoch:  472  	Training Loss: 0.37255334854125977
Test Loss:  0.4096691906452179
Valid Loss:  0.41496962308883667
Epoch:  473  	Training Loss: 0.37219101190567017
Test Loss:  0.4092773497104645
Valid Loss:  0.4145732522010803
Epoch:  474  	Training Loss: 0.3718290627002716
Test Loss:  0.4088859260082245
Valid Loss:  0.414177268743515
Epoch:  475  	Training Loss: 0.3714674413204193
Test Loss:  0.40849488973617554
Valid Loss:  0.41378167271614075
Epoch:  476  	Training Loss: 0.37110620737075806
Test Loss:  0.40810418128967285
Valid Loss:  0.41338640451431274
Epoch:  477  	Training Loss: 0.3707452714443207
Test Loss:  0.4077138602733612
Valid Loss:  0.41299158334732056
Epoch:  478  	Training Loss: 0.37038472294807434
Test Loss:  0.4073239266872406
Valid Loss:  0.412597119808197
Epoch:  479  	Training Loss: 0.37002450227737427
Test Loss:  0.40693438053131104
Valid Loss:  0.41220301389694214
Epoch:  480  	Training Loss: 0.36966466903686523
Test Loss:  0.40654516220092773
Valid Loss:  0.4118092954158783
Epoch:  481  	Training Loss: 0.36930516362190247
Test Loss:  0.40615636110305786
Valid Loss:  0.4114159643650055
Epoch:  482  	Training Loss: 0.36894601583480835
Test Loss:  0.40576642751693726
Valid Loss:  0.41102153062820435
Epoch:  483  	Training Loss: 0.36858585476875305
Test Loss:  0.4053769111633301
Valid Loss:  0.41062742471694946
Epoch:  484  	Training Loss: 0.36822599172592163
Test Loss:  0.40498772263526917
Valid Loss:  0.410233736038208
Epoch:  485  	Training Loss: 0.36786654591560364
Test Loss:  0.40459898114204407
Valid Loss:  0.40984046459198
Epoch:  486  	Training Loss: 0.3675074279308319
Test Loss:  0.40421056747436523
Valid Loss:  0.4094475507736206
Epoch:  487  	Training Loss: 0.3671486973762512
Test Loss:  0.40382254123687744
Valid Loss:  0.4090549945831299
Epoch:  488  	Training Loss: 0.3667902648448944
Test Loss:  0.4034348726272583
Valid Loss:  0.4086628556251526
Epoch:  489  	Training Loss: 0.36643218994140625
Test Loss:  0.4030475914478302
Valid Loss:  0.40827107429504395
Epoch:  490  	Training Loss: 0.36607447266578674
Test Loss:  0.4026607871055603
Valid Loss:  0.40787971019744873
Epoch:  491  	Training Loss: 0.36571717262268066
Test Loss:  0.4022742509841919
Valid Loss:  0.40748870372772217
Epoch:  492  	Training Loss: 0.36536020040512085
Test Loss:  0.40188661217689514
Valid Loss:  0.4070965647697449
Epoch:  493  	Training Loss: 0.3650021553039551
Test Loss:  0.4014993906021118
Valid Loss:  0.406704843044281
Epoch:  494  	Training Loss: 0.36464452743530273
Test Loss:  0.40111255645751953
Valid Loss:  0.4063134789466858
Epoch:  495  	Training Loss: 0.36428719758987427
Test Loss:  0.4007260501384735
Valid Loss:  0.40592247247695923
Epoch:  496  	Training Loss: 0.36393022537231445
Test Loss:  0.4003399610519409
Valid Loss:  0.4055318832397461
Epoch:  497  	Training Loss: 0.36357367038726807
Test Loss:  0.39995425939559937
Valid Loss:  0.405141681432724
Epoch:  498  	Training Loss: 0.36321741342544556
Test Loss:  0.39956891536712646
Valid Loss:  0.40475186705589294
Epoch:  499  	Training Loss: 0.3628615140914917
Test Loss:  0.3991839289665222
Valid Loss:  0.40436238050460815
Epoch:  500  	Training Loss: 0.3625059723854065
Test Loss:  0.3987993597984314
Valid Loss:  0.4039733409881592
seed is  16
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:34,  6.20s/it]  1%|          | 3/500 [00:06<13:45,  1.66s/it]  1%|          | 5/500 [00:06<06:56,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:12<10:41,  1.31s/it]  3%|▎         | 13/500 [00:13<07:19,  1.11it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  3.00it/s]  4%|▍         | 21/500 [00:19<09:28,  1.19s/it]  5%|▍         | 23/500 [00:19<06:43,  1.18it/s]  5%|▌         | 25/500 [00:20<04:50,  1.64it/s]  5%|▌         | 27/500 [00:20<03:30,  2.24it/s]  6%|▌         | 29/500 [00:20<02:35,  3.02it/s]  6%|▌         | 31/500 [00:26<09:14,  1.18s/it]  7%|▋         | 33/500 [00:26<06:35,  1.18it/s]  7%|▋         | 35/500 [00:33<11:57,  1.54s/it]  7%|▋         | 37/500 [00:33<08:29,  1.10s/it]  8%|▊         | 39/500 [00:33<06:03,  1.27it/s]  8%|▊         | 41/500 [00:39<11:16,  1.47s/it]  9%|▊         | 43/500 [00:39<08:01,  1.05s/it]  9%|▉         | 45/500 [00:39<05:44,  1.32it/s]  9%|▉         | 47/500 [00:39<04:09,  1.82it/s] 10%|▉         | 49/500 [00:40<03:02,  2.47it/s] 10%|█         | 51/500 [00:46<09:10,  1.23s/it] 11%|█         | 53/500 [00:46<06:33,  1.14it/s] 11%|█         | 55/500 [00:46<04:42,  1.57it/s] 11%|█▏        | 57/500 [00:46<03:26,  2.15it/s] 12%|█▏        | 59/500 [00:46<02:32,  2.89it/s] 12%|█▏        | 61/500 [00:53<08:35,  1.17s/it] 13%|█▎        | 63/500 [00:53<06:09,  1.18it/s] 13%|█▎        | 65/500 [00:53<04:25,  1.64it/s] 13%|█▎        | 67/500 [00:53<03:13,  2.24it/s] 14%|█▍        | 69/500 [00:53<02:23,  3.00it/s]Epoch:  1  	Training Loss: 0.49134331941604614
Test Loss:  6.371164321899414
Valid Loss:  6.3379411697387695
Epoch:  2  	Training Loss: 6.671712875366211
Test Loss:  14.469816207885742
Valid Loss:  14.789867401123047
Epoch:  3  	Training Loss: 13.456294059753418
Test Loss:  1.286909818649292
Valid Loss:  1.2094578742980957
Epoch:  4  	Training Loss: 1.5232924222946167
Test Loss:  0.9073531627655029
Valid Loss:  0.8257498741149902
Epoch:  5  	Training Loss: 1.1627559661865234
Test Loss:  0.7852382659912109
Valid Loss:  0.7036310434341431
Epoch:  6  	Training Loss: 1.0295624732971191
Test Loss:  0.712264895439148
Valid Loss:  0.6364233493804932
Epoch:  7  	Training Loss: 0.9534569978713989
Test Loss:  0.6602890491485596
Valid Loss:  0.5916401147842407
Epoch:  8  	Training Loss: 0.8996866941452026
Test Loss:  0.6215345859527588
Valid Loss:  0.5577036142349243
Epoch:  9  	Training Loss: 0.8594708442687988
Test Loss:  0.5908560752868652
Valid Loss:  0.5302135944366455
Epoch:  10  	Training Loss: 0.8266000151634216
Test Loss:  0.5655016303062439
Valid Loss:  0.5074999332427979
Epoch:  11  	Training Loss: 0.7985880374908447
Test Loss:  0.5438692569732666
Valid Loss:  0.4880642890930176
Epoch:  12  	Training Loss: 0.7743972539901733
Test Loss:  0.08306316286325455
Valid Loss:  0.07451105117797852
Epoch:  13  	Training Loss: 0.1270819902420044
Test Loss:  0.0729341208934784
Valid Loss:  0.0641622245311737
Epoch:  14  	Training Loss: 0.11572878062725067
Test Loss:  0.06781195104122162
Valid Loss:  0.0589292086660862
Epoch:  15  	Training Loss: 0.11061161756515503
Test Loss:  0.06519433856010437
Valid Loss:  0.056251443922519684
Epoch:  16  	Training Loss: 0.10776478052139282
Test Loss:  0.06390374898910522
Valid Loss:  0.05492880940437317
Epoch:  17  	Training Loss: 0.10617408901453018
Test Loss:  0.06330405175685883
Valid Loss:  0.05431437864899635
Epoch:  18  	Training Loss: 0.10527792572975159
Test Loss:  0.06305549293756485
Valid Loss:  0.05406077206134796
Epoch:  19  	Training Loss: 0.10476802289485931
Test Loss:  0.06297746300697327
Valid Loss:  0.05398126691579819
Epoch:  20  	Training Loss: 0.10447084903717041
Test Loss:  0.06297631561756134
Valid Loss:  0.053980011492967606
Epoch:  21  	Training Loss: 0.10429181158542633
Test Loss:  0.06300508975982666
Valid Loss:  0.05400920659303665
Epoch:  22  	Training Loss: 0.1041802316904068
Test Loss:  0.5070468187332153
Valid Loss:  0.5181611776351929
Epoch:  23  	Training Loss: 0.4690208435058594
Test Loss:  0.8023451566696167
Valid Loss:  0.7978135347366333
Epoch:  24  	Training Loss: 0.8063603639602661
Test Loss:  0.03703514486551285
Valid Loss:  0.033577729016542435
Epoch:  25  	Training Loss: 0.054423145949840546
Test Loss:  0.027428310364484787
Valid Loss:  0.02413424849510193
Epoch:  26  	Training Loss: 0.04561790078878403
Test Loss:  0.023514986038208008
Valid Loss:  0.020770559087395668
Epoch:  27  	Training Loss: 0.040056340396404266
Test Loss:  0.020893963053822517
Valid Loss:  0.018640724942088127
Epoch:  28  	Training Loss: 0.035867735743522644
Test Loss:  0.01900940202176571
Valid Loss:  0.01716894470155239
Epoch:  29  	Training Loss: 0.03264414519071579
Test Loss:  0.017829641699790955
Valid Loss:  0.016304319724440575
Epoch:  30  	Training Loss: 0.030424829572439194
Test Loss:  0.01712813973426819
Valid Loss:  0.01587657630443573
Epoch:  31  	Training Loss: 0.028820354491472244
Test Loss:  0.01709340699017048
Valid Loss:  0.015577033162117004
Epoch:  32  	Training Loss: 0.029676776379346848
Test Loss:  0.02340717986226082
Valid Loss:  0.024310167878866196
Epoch:  33  	Training Loss: 0.0248898696154356
Test Loss:  0.006505141966044903
Valid Loss:  0.006669210270047188
Epoch:  34  	Training Loss: 0.009319817647337914
Test Loss:  0.004672563634812832
Valid Loss:  0.004973104223608971
Epoch:  35  	Training Loss: 0.0056438148021698
Test Loss:  0.004153457935899496
Valid Loss:  0.0045849634334445
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.004721980541944504
Test Loss:  0.0038106609135866165
Valid Loss:  0.004278604872524738
Epoch:  37  	Training Loss: 0.0042481073178350925
Test Loss:  0.0035961661487817764
Valid Loss:  0.004102145321667194
Epoch:  38  	Training Loss: 0.003902279771864414
Test Loss:  0.0034185517579317093
Valid Loss:  0.003948331810534
Epoch:  39  	Training Loss: 0.0036363278049975634
Test Loss:  0.003285415004938841
Valid Loss:  0.003823927603662014
Epoch:  40  	Training Loss: 0.003415084909647703
Test Loss:  0.003184191882610321
Valid Loss:  0.0037298768293112516
Epoch:  41  	Training Loss: 0.0032507546711713076
Test Loss:  0.00308454898186028
Valid Loss:  0.0036332705058157444
Epoch:  42  	Training Loss: 0.0031266696751117706
Test Loss:  0.003049575723707676
Valid Loss:  0.003585816826671362
Epoch:  43  	Training Loss: 0.0030831231269985437
Test Loss:  0.0030471510253846645
Valid Loss:  0.003582917619496584
Epoch:  44  	Training Loss: 0.0030748052522540092
Test Loss:  0.0030449642799794674
Valid Loss:  0.003580354154109955
Epoch:  45  	Training Loss: 0.0030679763294756413
Test Loss:  0.0030443458817899227
Valid Loss:  0.0035793676506727934
Epoch:  46  	Training Loss: 0.0030631625559180975
Test Loss:  0.0030435603111982346
Valid Loss:  0.0035784649662673473
Epoch:  47  	Training Loss: 0.003059834474697709
Test Loss:  0.003043629229068756
Valid Loss:  0.0035778312012553215
Epoch:  48  	Training Loss: 0.0030568940564990044
Test Loss:  0.00304178218357265
Valid Loss:  0.0035764153581112623
Epoch:  49  	Training Loss: 0.0030542248860001564
Test Loss:  0.0030413297936320305
Valid Loss:  0.0035754526033997536
Epoch:  50  	Training Loss: 0.0030515955295413733
Test Loss:  0.0030390380416065454
Valid Loss:  0.0035736975260078907
Epoch:  51  	Training Loss: 0.003049258841201663
Test Loss:  0.0030379286035895348
Valid Loss:  0.0035723394248634577
Epoch:  52  	Training Loss: 0.0030467857141047716
Test Loss:  0.002911884570494294
Valid Loss:  0.0034429733641445637
Epoch:  53  	Training Loss: 0.002930890768766403
Test Loss:  0.002801931230351329
Valid Loss:  0.003332059131935239
Epoch:  54  	Training Loss: 0.0028243358246982098
Test Loss:  0.0027022352442145348
Valid Loss:  0.003232991322875023
Epoch:  55  	Training Loss: 0.0027293695602566004
Test Loss:  0.002610985655337572
Valid Loss:  0.0031415224075317383
Epoch:  56  	Training Loss: 0.002638669451698661
Test Loss:  0.002525328192859888
Valid Loss:  0.003055277746170759
Epoch:  57  	Training Loss: 0.0025513283908367157
Test Loss:  0.0024452246725559235
Valid Loss:  0.002973688067868352
Epoch:  58  	Training Loss: 0.002470059087499976
Test Loss:  0.0023685761261731386
Valid Loss:  0.002895502606406808
Epoch:  59  	Training Loss: 0.0023941039107739925
Test Loss:  0.0022957036271691322
Valid Loss:  0.002821884350851178
Epoch:  60  	Training Loss: 0.002323664491996169
Test Loss:  0.0022832455579191446
Valid Loss:  0.002819931600242853
Epoch:  61  	Training Loss: 0.002300499938428402
Test Loss:  0.002291145734488964
Valid Loss:  0.00282523175701499
Epoch:  62  	Training Loss: 0.002276054583489895
Test Loss:  0.002297012135386467
Valid Loss:  0.0028292988426983356
Epoch:  63  	Training Loss: 0.002267240546643734
Test Loss:  0.0022960135247558355
Valid Loss:  0.0028275162912905216
Epoch:  64  	Training Loss: 0.002262631431221962
Test Loss:  0.002291950397193432
Valid Loss:  0.00282298494130373
Epoch:  65  	Training Loss: 0.002258471678942442
Test Loss:  0.002286838833242655
Valid Loss:  0.0028174829203635454
Epoch:  66  	Training Loss: 0.0022543712984770536
Test Loss:  0.0022813475225120783
Valid Loss:  0.0028116717003285885
Epoch:  67  	Training Loss: 0.00225025019608438
Test Loss:  0.002275722101330757
Valid Loss:  0.0028057589661329985
Epoch:  68  	Training Loss: 0.0022461172193288803
Test Loss:  0.0022700652480125427
Valid Loss:  0.0027997884899377823
Epoch:  69  	Training Loss: 0.0022419809829443693
Test Loss:  0.002264410723000765
Valid Loss:  0.002793815452605486
Epoch:  70  	Training Loss: 0.0022378433495759964
Test Loss:  0.002258745953440666
Valid Loss:  0.002787830773741007
 14%|█▍        | 71/500 [00:59<08:26,  1.18s/it] 15%|█▍        | 73/500 [01:00<06:01,  1.18it/s] 15%|█▌        | 75/500 [01:00<04:20,  1.63it/s] 15%|█▌        | 77/500 [01:00<03:09,  2.23it/s] 16%|█▌        | 79/500 [01:00<02:20,  2.99it/s] 16%|█▌        | 81/500 [01:06<08:16,  1.19s/it] 17%|█▋        | 83/500 [01:06<05:54,  1.18it/s] 17%|█▋        | 85/500 [01:07<04:15,  1.63it/s] 17%|█▋        | 87/500 [01:07<03:05,  2.22it/s] 18%|█▊        | 89/500 [01:07<02:17,  2.99it/s] 18%|█▊        | 91/500 [01:13<08:00,  1.18s/it] 19%|█▊        | 93/500 [01:13<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:13<04:08,  1.63it/s] 19%|█▉        | 97/500 [01:14<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:14<02:14,  2.99it/s] 20%|██        | 101/500 [01:20<07:51,  1.18s/it] 21%|██        | 103/500 [01:20<05:37,  1.18it/s] 21%|██        | 105/500 [01:20<04:02,  1.63it/s] 21%|██▏       | 107/500 [01:20<02:57,  2.22it/s] 22%|██▏       | 109/500 [01:21<02:11,  2.98it/s] 22%|██▏       | 111/500 [01:27<07:38,  1.18s/it] 23%|██▎       | 113/500 [01:27<05:27,  1.18it/s] 23%|██▎       | 115/500 [01:27<03:55,  1.63it/s] 23%|██▎       | 117/500 [01:27<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:27<02:07,  2.99it/s] 24%|██▍       | 121/500 [01:34<07:25,  1.17s/it] 25%|██▍       | 123/500 [01:34<05:17,  1.19it/s] 25%|██▌       | 125/500 [01:34<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:34<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:34<02:03,  3.00it/s] 26%|██▌       | 131/500 [01:41<07:17,  1.18s/it] 27%|██▋       | 133/500 [01:41<05:13,  1.17it/s] 27%|██▋       | 135/500 [01:41<03:45,  1.62it/s] 27%|██▋       | 137/500 [01:41<02:43,  2.22it/s]Epoch:  71  	Training Loss: 0.0022336887195706367
Test Loss:  0.002253093756735325
Valid Loss:  0.002781826537102461
Epoch:  72  	Training Loss: 0.002229520818218589
Test Loss:  0.002253581304103136
Valid Loss:  0.0027785757556557655
Epoch:  73  	Training Loss: 0.0022045422811061144
Test Loss:  0.0022346151527017355
Valid Loss:  0.002757538575679064
Epoch:  74  	Training Loss: 0.002163123106583953
Test Loss:  0.002166714984923601
Valid Loss:  0.0026912176981568336
Epoch:  75  	Training Loss: 0.002091427333652973
Test Loss:  0.0021531064994633198
Valid Loss:  0.0026798085309565067
Epoch:  76  	Training Loss: 0.002071225317195058
Test Loss:  0.002146925777196884
Valid Loss:  0.0026764716021716595
Epoch:  77  	Training Loss: 0.0020547150634229183
Test Loss:  0.002141176024451852
Valid Loss:  0.0026722729671746492
Epoch:  78  	Training Loss: 0.002041418803855777
Test Loss:  0.0021368120796978474
Valid Loss:  0.002668417990207672
Epoch:  79  	Training Loss: 0.0020302997436374426
Test Loss:  0.002133612520992756
Valid Loss:  0.0026651257649064064
Epoch:  80  	Training Loss: 0.002021000487729907
Test Loss:  0.0021312604658305645
Valid Loss:  0.002662278711795807
Epoch:  81  	Training Loss: 0.0020132139325141907
Test Loss:  0.0021295633632689714
Valid Loss:  0.0026598256081342697
Epoch:  82  	Training Loss: 0.0020066893193870783
Test Loss:  0.0017816487234085798
Valid Loss:  0.00228239712305367
Epoch:  83  	Training Loss: 0.0017850338481366634
Test Loss:  0.0016052161809056997
Valid Loss:  0.0020862941164523363
Epoch:  84  	Training Loss: 0.001660320209339261
Test Loss:  0.0014873184263706207
Valid Loss:  0.0019519778434187174
Epoch:  85  	Training Loss: 0.0015794317005202174
Test Loss:  0.0013930493732914329
Valid Loss:  0.0018462392035871744
Epoch:  86  	Training Loss: 0.0015264989342540503
Test Loss:  0.001314955996349454
Valid Loss:  0.0017567130271345377
Epoch:  87  	Training Loss: 0.0014480437384918332
Test Loss:  0.0012546444777399302
Valid Loss:  0.0016875427681952715
Epoch:  88  	Training Loss: 0.0014205453917384148
Test Loss:  0.0011874211486428976
Valid Loss:  0.0016105463728308678
Epoch:  89  	Training Loss: 0.0013508154079318047
Test Loss:  0.0011456450447440147
Valid Loss:  0.0015615513548254967
Epoch:  90  	Training Loss: 0.001324355835095048
Test Loss:  0.0010853518033400178
Valid Loss:  0.001489783520810306
Epoch:  91  	Training Loss: 0.0012788631720468402
Test Loss:  0.0010566371493041515
Valid Loss:  0.001455766847357154
Epoch:  92  	Training Loss: 0.0012668655253946781
Test Loss:  0.001028824714012444
Valid Loss:  0.0014217458665370941
Epoch:  93  	Training Loss: 0.0012305027339607477
Test Loss:  0.0010024439543485641
Valid Loss:  0.001395995495840907
Epoch:  94  	Training Loss: 0.0012161843478679657
Test Loss:  0.0009960297029465437
Valid Loss:  0.0013808375224471092
Epoch:  95  	Training Loss: 0.0012041587615385652
Test Loss:  0.0009663586970418692
Valid Loss:  0.0013503157533705235
Epoch:  96  	Training Loss: 0.0011901991674676538
Test Loss:  0.0009582479251548648
Valid Loss:  0.0013349596410989761
Epoch:  97  	Training Loss: 0.0011802467051893473
Test Loss:  0.0009345874423161149
Valid Loss:  0.0013122889213263988
Epoch:  98  	Training Loss: 0.0011711877305060625
Test Loss:  0.0009301520185545087
Valid Loss:  0.0013003338826820254
Epoch:  99  	Training Loss: 0.0011627956992015243
Test Loss:  0.0009076045826077461
Valid Loss:  0.0012768009910359979
Epoch:  100  	Training Loss: 0.0011530889896675944
Test Loss:  0.0009017059346660972
Valid Loss:  0.0012652126606553793
Epoch:  101  	Training Loss: 0.0011459831148386002
Test Loss:  0.0008833634783513844
Valid Loss:  0.0012474334798753262
Epoch:  102  	Training Loss: 0.0011396894697099924
Test Loss:  0.0008801323128864169
Valid Loss:  0.0012368126772344112
Epoch:  103  	Training Loss: 0.001131321070715785
Test Loss:  0.0008771782740950584
Valid Loss:  0.0012340277899056673
Epoch:  104  	Training Loss: 0.0011277145240455866
Test Loss:  0.0008745414670556784
Valid Loss:  0.001231358153745532
Epoch:  105  	Training Loss: 0.0011243809713050723
Test Loss:  0.0008720334153622389
Valid Loss:  0.0012287129648029804
Epoch:  106  	Training Loss: 0.0011211424134671688
Test Loss:  0.0008695840369910002
Valid Loss:  0.0012263329699635506
Epoch:  107  	Training Loss: 0.0011182120069861412
Test Loss:  0.0008680423488840461
Valid Loss:  0.0012245899997651577
Epoch:  108  	Training Loss: 0.0011154402745887637
Test Loss:  0.00086635269690305
Valid Loss:  0.0012228070991113782
Epoch:  109  	Training Loss: 0.0011127101024612784
Test Loss:  0.0008646760252304375
Valid Loss:  0.001221020589582622
Epoch:  110  	Training Loss: 0.0011100105475634336
Test Loss:  0.0008630141383036971
Valid Loss:  0.001219244091771543
Epoch:  111  	Training Loss: 0.0011073520872741938
Test Loss:  0.0008613626705482602
Valid Loss:  0.0012174725998193026
Epoch:  112  	Training Loss: 0.001104731229133904
Test Loss:  0.0008310700068250299
Valid Loss:  0.0011800492648035288
Epoch:  113  	Training Loss: 0.0010884557850658894
Test Loss:  0.0008099855622276664
Valid Loss:  0.001152154291048646
Epoch:  114  	Training Loss: 0.0010763334576040506
Test Loss:  0.0007920149946585298
Valid Loss:  0.0011282197665423155
Epoch:  115  	Training Loss: 0.0010667664464563131
Test Loss:  0.0007771307718940079
Valid Loss:  0.0011080063413828611
Epoch:  116  	Training Loss: 0.0010591845493763685
Test Loss:  0.0007646766025573015
Valid Loss:  0.0010908134281635284
Epoch:  117  	Training Loss: 0.0010531635489314795
Test Loss:  0.0007542237872257829
Valid Loss:  0.0010761405574157834
Epoch:  118  	Training Loss: 0.0010483701480552554
Test Loss:  0.0007454092847183347
Valid Loss:  0.0010635729413479567
Epoch:  119  	Training Loss: 0.0010445381049066782
Test Loss:  0.0007379499729722738
Valid Loss:  0.00105277169495821
Epoch:  120  	Training Loss: 0.0010414678836241364
Test Loss:  0.0007316091796383262
Valid Loss:  0.0010434597497805953
Epoch:  121  	Training Loss: 0.0010389978997409344
Test Loss:  0.0007261986611410975
Valid Loss:  0.0010354011319577694
Epoch:  122  	Training Loss: 0.0010369999799877405
Test Loss:  0.0007105512777343392
Valid Loss:  0.0010188042651861906
Epoch:  123  	Training Loss: 0.0010121858213096857
Test Loss:  0.0006976473378017545
Valid Loss:  0.0010051681892946362
Epoch:  124  	Training Loss: 0.0009901864686980844
Test Loss:  0.0006855144165456295
Valid Loss:  0.0009908645879477262
Epoch:  125  	Training Loss: 0.0009696940542198718
Test Loss:  0.000674780341796577
Valid Loss:  0.0009782657725736499
Epoch:  126  	Training Loss: 0.0009505267953500152
Test Loss:  0.0006635532481595874
Valid Loss:  0.0009646095568314195
Epoch:  127  	Training Loss: 0.0009316564537584782
Test Loss:  0.000654897652566433
Valid Loss:  0.0009544927161186934
Epoch:  128  	Training Loss: 0.0009140166803263128
Test Loss:  0.0006443142192438245
Valid Loss:  0.0009402597788721323
Epoch:  129  	Training Loss: 0.0008972526993602514
Test Loss:  0.0006348181050270796
Valid Loss:  0.0009270445443689823
Epoch:  130  	Training Loss: 0.0008812641608528793
Test Loss:  0.0006272811442613602
Valid Loss:  0.000916631834115833
Epoch:  131  	Training Loss: 0.0008665149798616767
Test Loss:  0.0006172896828502417
Valid Loss:  0.0009037477429956198
Epoch:  132  	Training Loss: 0.0008523744763806462
Test Loss:  0.0006002906011417508
Valid Loss:  0.0008876269566826522
Epoch:  133  	Training Loss: 0.0008194257970899343
Test Loss:  0.0005935034714639187
Valid Loss:  0.0008782707154750824
Epoch:  134  	Training Loss: 0.0008026749128475785
Test Loss:  0.0005854947958141565
Valid Loss:  0.0008666717913001776
Epoch:  135  	Training Loss: 0.0007893154979683459
Test Loss:  0.0005786700057797134
Valid Loss:  0.0008568928460590541
Epoch:  136  	Training Loss: 0.0007772344397380948
Test Loss:  0.0005721029010601342
Valid Loss:  0.0008477285737171769
Epoch:  137  	Training Loss: 0.0007667079335078597
Test Loss:  0.0005667862133122981
Valid Loss:  0.0008393038879148662
Epoch:  138  	Training Loss: 0.000757286383304745
Test Loss:  0.0005605681799352169
Valid Loss:  0.0008310418925248086
Epoch:  139  	Training Loss: 0.000748902908526361
Test Loss:  0.0005566751351580024
Valid Loss:   28%|██▊       | 139/500 [01:41<02:01,  2.98it/s] 28%|██▊       | 141/500 [01:47<07:00,  1.17s/it] 29%|██▊       | 143/500 [01:47<05:00,  1.19it/s] 29%|██▉       | 145/500 [01:48<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:48<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:48<01:57,  2.98it/s] 30%|███       | 151/500 [01:54<06:50,  1.18s/it] 31%|███       | 153/500 [01:54<04:52,  1.19it/s] 31%|███       | 155/500 [01:54<03:32,  1.62it/s] 31%|███▏      | 157/500 [01:55<02:36,  2.19it/s] 32%|███▏      | 159/500 [01:55<01:57,  2.89it/s] 32%|███▏      | 161/500 [02:01<06:40,  1.18s/it] 33%|███▎      | 163/500 [02:01<04:45,  1.18it/s] 33%|███▎      | 165/500 [02:01<03:25,  1.63it/s] 33%|███▎      | 167/500 [02:01<02:29,  2.22it/s] 34%|███▍      | 169/500 [02:02<01:51,  2.98it/s] 34%|███▍      | 171/500 [02:08<06:28,  1.18s/it] 35%|███▍      | 173/500 [02:08<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:08<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:08<02:25,  2.23it/s] 36%|███▌      | 179/500 [02:08<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:15<06:13,  1.17s/it] 37%|███▋      | 183/500 [02:15<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:15<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:15<02:19,  2.25it/s] 38%|███▊      | 189/500 [02:15<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:22<06:06,  1.19s/it] 39%|███▊      | 193/500 [02:22<04:21,  1.18it/s] 39%|███▉      | 195/500 [02:22<03:07,  1.63it/s] 39%|███▉      | 197/500 [02:22<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:22<01:43,  2.92it/s] 40%|████      | 201/500 [02:28<05:48,  1.17s/it] 41%|████      | 203/500 [02:28<04:08,  1.19it/s] 41%|████      | 205/500 [02:29<02:58,  1.65it/s] 41%|████▏     | 207/500 [02:29<02:10,  2.25it/s]0.0008241389878094196
Epoch:  140  	Training Loss: 0.0007413517450913787
Test Loss:  0.0005508683971129358
Valid Loss:  0.0008164725149981678
Epoch:  141  	Training Loss: 0.0007347837090492249
Test Loss:  0.0005480139516294003
Valid Loss:  0.0008110399357974529
Epoch:  142  	Training Loss: 0.0007283454178832471
Test Loss:  0.0005466903676278889
Valid Loss:  0.0008092692587524652
Epoch:  143  	Training Loss: 0.0007236364763230085
Test Loss:  0.0005443633999675512
Valid Loss:  0.0008077567326836288
Epoch:  144  	Training Loss: 0.0007195511716417968
Test Loss:  0.0005422734539024532
Valid Loss:  0.0008064676076173782
Epoch:  145  	Training Loss: 0.0007159908418543637
Test Loss:  0.0005404850817285478
Valid Loss:  0.0008053734782151878
Epoch:  146  	Training Loss: 0.0007128799334168434
Test Loss:  0.000538958003744483
Valid Loss:  0.0008044494315981865
Epoch:  147  	Training Loss: 0.0007101543596945703
Test Loss:  0.0005376532790251076
Valid Loss:  0.00080367352347821
Epoch:  148  	Training Loss: 0.0007077617337927222
Test Loss:  0.0005365326069295406
Valid Loss:  0.0008030275930650532
Epoch:  149  	Training Loss: 0.0007056186441332102
Test Loss:  0.000535516650415957
Valid Loss:  0.0008024778799153864
Epoch:  150  	Training Loss: 0.0007034760201349854
Test Loss:  0.0005346076795831323
Valid Loss:  0.0008020170498639345
Epoch:  151  	Training Loss: 0.0007014324655756354
Test Loss:  0.0005338048213161528
Valid Loss:  0.0008016462670639157
Epoch:  152  	Training Loss: 0.000699436932336539
Test Loss:  0.0005301505443640053
Valid Loss:  0.0007981223752722144
Epoch:  153  	Training Loss: 0.0006985239451751113
Test Loss:  0.0005293972790241241
Valid Loss:  0.0007964527467265725
Epoch:  154  	Training Loss: 0.0006972930859774351
Test Loss:  0.000527324853464961
Valid Loss:  0.0007941577350720763
Epoch:  155  	Training Loss: 0.0006965161883272231
Test Loss:  0.0005260494071990252
Valid Loss:  0.0007923285593278706
Epoch:  156  	Training Loss: 0.0006958417361602187
Test Loss:  0.000524835311807692
Valid Loss:  0.0007906238897703588
Epoch:  157  	Training Loss: 0.0006952347466722131
Test Loss:  0.0005236858851276338
Valid Loss:  0.000789033540058881
Epoch:  158  	Training Loss: 0.0006946829962544143
Test Loss:  0.0005225995555520058
Valid Loss:  0.0007875461596995592
Epoch:  159  	Training Loss: 0.0006941794417798519
Test Loss:  0.0005215776618570089
Valid Loss:  0.000786157208494842
Epoch:  160  	Training Loss: 0.0006937149446457624
Test Loss:  0.0005206177593208849
Valid Loss:  0.000784851610660553
Epoch:  161  	Training Loss: 0.0006932808319106698
Test Loss:  0.0005202735774219036
Valid Loss:  0.0007839399040676653
Epoch:  162  	Training Loss: 0.0006929142982698977
Test Loss:  0.0005162777379155159
Valid Loss:  0.0007771665113978088
Epoch:  163  	Training Loss: 0.0006889872020110488
Test Loss:  0.0005117890541441739
Valid Loss:  0.0007699637208133936
Epoch:  164  	Training Loss: 0.0006862751906737685
Test Loss:  0.000508221797645092
Valid Loss:  0.0007640413241460919
Epoch:  165  	Training Loss: 0.0006841294816695154
Test Loss:  0.0005052677588537335
Valid Loss:  0.0007590233581140637
Epoch:  166  	Training Loss: 0.0006824217271059752
Test Loss:  0.0005028041778132319
Valid Loss:  0.0007547576678916812
Epoch:  167  	Training Loss: 0.0006810310296714306
Test Loss:  0.0005007327999919653
Valid Loss:  0.0007511136936955154
Epoch:  168  	Training Loss: 0.000679883174598217
Test Loss:  0.0004989757435396314
Valid Loss:  0.0007479832274839282
Epoch:  169  	Training Loss: 0.0006789194885641336
Test Loss:  0.000497471890412271
Valid Loss:  0.0007452772697433829
Epoch:  170  	Training Loss: 0.000678097945638001
Test Loss:  0.0004961729282513261
Valid Loss:  0.0007429199758917093
Epoch:  171  	Training Loss: 0.0006773834466002882
Test Loss:  0.0004950398579239845
Valid Loss:  0.0007408622186630964
Epoch:  172  	Training Loss: 0.0006767533486708999
Test Loss:  0.0004943569074384868
Valid Loss:  0.000739975250326097
Epoch:  173  	Training Loss: 0.0006734358612447977
Test Loss:  0.0004937257617712021
Valid Loss:  0.0007392530096694827
Epoch:  174  	Training Loss: 0.0006704832194373012
Test Loss:  0.0004931753501296043
Valid Loss:  0.0007385947974398732
Epoch:  175  	Training Loss: 0.0006678408244624734
Test Loss:  0.0004927577683702111
Valid Loss:  0.000737990252673626
Epoch:  176  	Training Loss: 0.000665467232465744
Test Loss:  0.0004923926899209619
Valid Loss:  0.0007374275010079145
Epoch:  177  	Training Loss: 0.0006632350268773735
Test Loss:  0.0004920622450299561
Valid Loss:  0.0007369053782895207
Epoch:  178  	Training Loss: 0.0006612067809328437
Test Loss:  0.000491762300953269
Valid Loss:  0.0007364156190305948
Epoch:  179  	Training Loss: 0.0006593600264750421
Test Loss:  0.0004914820310659707
Valid Loss:  0.0007359414594247937
Epoch:  180  	Training Loss: 0.0006576575106009841
Test Loss:  0.0004912050208076835
Valid Loss:  0.000735477777197957
Epoch:  181  	Training Loss: 0.000656081479974091
Test Loss:  0.0004909433191642165
Valid Loss:  0.0007350083906203508
Epoch:  182  	Training Loss: 0.0006546337972395122
Test Loss:  0.0004895926686003804
Valid Loss:  0.0007326494087465107
Epoch:  183  	Training Loss: 0.0006540417671203613
Test Loss:  0.0004886511014774442
Valid Loss:  0.0007308860076591372
Epoch:  184  	Training Loss: 0.0006535982829518616
Test Loss:  0.0004879111656919122
Valid Loss:  0.0007294355309568346
Epoch:  185  	Training Loss: 0.0006532170809805393
Test Loss:  0.00048728351248428226
Valid Loss:  0.0007281781290657818
Epoch:  186  	Training Loss: 0.0006528729572892189
Test Loss:  0.00048672963748686016
Valid Loss:  0.0007270511705428362
Epoch:  187  	Training Loss: 0.0006525566568598151
Test Loss:  0.00048622849863022566
Valid Loss:  0.0007260217680595815
Epoch:  188  	Training Loss: 0.000652263464871794
Test Loss:  0.00048576854169368744
Valid Loss:  0.0007250714115798473
Epoch:  189  	Training Loss: 0.0006519894232042134
Test Loss:  0.0004853415593970567
Valid Loss:  0.000724189099855721
Epoch:  190  	Training Loss: 0.000651732727419585
Test Loss:  0.00048494443763047457
Valid Loss:  0.0007233668002299964
Epoch:  191  	Training Loss: 0.0006514902925118804
Test Loss:  0.0004845723451580852
Valid Loss:  0.0007225992158055305
Epoch:  192  	Training Loss: 0.0006512600230053067
Test Loss:  0.0004843364004045725
Valid Loss:  0.0007221338455565274
Epoch:  193  	Training Loss: 0.0006508899386972189
Test Loss:  0.0004840445180889219
Valid Loss:  0.0007217354141175747
Epoch:  194  	Training Loss: 0.0006506338831968606
Test Loss:  0.0004837490268982947
Valid Loss:  0.0007213370408862829
Epoch:  195  	Training Loss: 0.0006503721233457327
Test Loss:  0.0004834526916965842
Valid Loss:  0.0007209352916106582
Epoch:  196  	Training Loss: 0.0006501009338535368
Test Loss:  0.0004831518745049834
Valid Loss:  0.0007205196307040751
Epoch:  197  	Training Loss: 0.0006498013390228152
Test Loss:  0.00048279622569680214
Valid Loss:  0.00072008854476735
Epoch:  198  	Training Loss: 0.0006494657136499882
Test Loss:  0.00048240122850984335
Valid Loss:  0.0007196464575827122
Epoch:  199  	Training Loss: 0.0006490454543381929
Test Loss:  0.00048196388524957
Valid Loss:  0.0007190797477960587
Epoch:  200  	Training Loss: 0.0006484024343080819
Test Loss:  0.00048117758706212044
Valid Loss:  0.0007182894623838365
Epoch:  201  	Training Loss: 0.0006474272813647985
Test Loss:  0.0004798907320946455
Valid Loss:  0.0007173009216785431
Epoch:  202  	Training Loss: 0.000646062137093395
Test Loss:  0.0004766408237628639
Valid Loss:  0.0007145687704905868
Epoch:  203  	Training Loss: 0.0006416663527488708
Test Loss:  0.0004741285229101777
Valid Loss:  0.0007121583912521601
Epoch:  204  	Training Loss: 0.000637690769508481
Test Loss:  0.0004714862734545022
Valid Loss:  0.0007095341570675373
Epoch:  205  	Training Loss: 0.00063429115107283
Test Loss:  0.0004696434480138123
Valid Loss:  0.0007072784937918186
Epoch:  206  	Training Loss: 0.000631560804322362
Test Loss:  0.0004679321718867868
Valid Loss:  0.0007051097927615047
Epoch:  207  	Training Loss: 0.0006291717290878296
Test Loss:  0.0004665425803977996
Valid Loss:  0.0007032476714812219
 42%|████▏     | 209/500 [02:29<01:36,  3.03it/s] 42%|████▏     | 211/500 [02:35<05:37,  1.17s/it] 43%|████▎     | 213/500 [02:35<04:00,  1.19it/s] 43%|████▎     | 215/500 [02:35<02:52,  1.65it/s] 43%|████▎     | 217/500 [02:36<02:06,  2.25it/s] 44%|████▍     | 219/500 [02:36<01:33,  3.00it/s] 44%|████▍     | 221/500 [02:42<05:27,  1.17s/it] 45%|████▍     | 223/500 [02:42<03:53,  1.19it/s] 45%|████▌     | 225/500 [02:42<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:42<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:43<01:30,  2.98it/s] 46%|████▌     | 231/500 [02:49<05:15,  1.17s/it] 47%|████▋     | 233/500 [02:49<03:45,  1.19it/s] 47%|████▋     | 235/500 [02:49<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:49<01:57,  2.24it/s] 48%|████▊     | 239/500 [02:49<01:27,  3.00it/s] 48%|████▊     | 241/500 [02:56<05:07,  1.19s/it] 49%|████▊     | 243/500 [02:56<03:40,  1.17it/s] 49%|████▉     | 245/500 [02:56<02:37,  1.61it/s] 49%|████▉     | 247/500 [02:56<01:54,  2.21it/s] 50%|████▉     | 249/500 [02:56<01:24,  2.96it/s] 50%|█████     | 251/500 [03:03<04:53,  1.18s/it] 51%|█████     | 253/500 [03:03<03:29,  1.18it/s] 51%|█████     | 255/500 [03:03<02:30,  1.63it/s] 51%|█████▏    | 257/500 [03:03<01:49,  2.22it/s] 52%|█████▏    | 259/500 [03:03<01:21,  2.97it/s] 52%|█████▏    | 261/500 [03:09<04:40,  1.17s/it] 53%|█████▎    | 263/500 [03:09<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:10<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:10<01:44,  2.23it/s] 54%|█████▍    | 269/500 [03:10<01:17,  2.99it/s] 54%|█████▍    | 271/500 [03:16<04:28,  1.17s/it] 55%|█████▍    | 273/500 [03:16<03:11,  1.19it/s] 55%|█████▌    | 275/500 [03:16<02:17,  1.64it/s]Epoch:  208  	Training Loss: 0.0006268429569900036
Test Loss:  0.0004652750212699175
Valid Loss:  0.0007014382863417268
Epoch:  209  	Training Loss: 0.0006246293196454644
Test Loss:  0.0004642183776013553
Valid Loss:  0.0006997332675382495
Epoch:  210  	Training Loss: 0.0006227284320630133
Test Loss:  0.00046320725232362747
Valid Loss:  0.0006980711477808654
Epoch:  211  	Training Loss: 0.0006208383711054921
Test Loss:  0.0004621830303221941
Valid Loss:  0.000696549832355231
Epoch:  212  	Training Loss: 0.0006184014491736889
Test Loss:  0.000462186464574188
Valid Loss:  0.000696512230206281
Epoch:  213  	Training Loss: 0.0006182835204526782
Test Loss:  0.00046216475311666727
Valid Loss:  0.0006964824278838933
Epoch:  214  	Training Loss: 0.0006181905628181994
Test Loss:  0.00046212482266128063
Valid Loss:  0.000696453033015132
Epoch:  215  	Training Loss: 0.0006181079661473632
Test Loss:  0.0004620602703653276
Valid Loss:  0.000696417992003262
Epoch:  216  	Training Loss: 0.0006180289201438427
Test Loss:  0.00046199627104215324
Valid Loss:  0.0006963823107071221
Epoch:  217  	Training Loss: 0.0006179518532007933
Test Loss:  0.00046192697482183576
Valid Loss:  0.0006963447667658329
Epoch:  218  	Training Loss: 0.0006178743788041174
Test Loss:  0.00046185165410861373
Valid Loss:  0.000696304312441498
Epoch:  219  	Training Loss: 0.0006177982431836426
Test Loss:  0.0004617663798853755
Valid Loss:  0.0006962620536796749
Epoch:  220  	Training Loss: 0.0006177208852022886
Test Loss:  0.00046168520930223167
Valid Loss:  0.0006962227635085583
Epoch:  221  	Training Loss: 0.0006176435854285955
Test Loss:  0.00046160444617271423
Valid Loss:  0.0006961805047467351
Epoch:  222  	Training Loss: 0.0006175646558403969
Test Loss:  0.00046005193144083023
Valid Loss:  0.0006940963212400675
Epoch:  223  	Training Loss: 0.0006152313435450196
Test Loss:  0.0004601365653797984
Valid Loss:  0.0006945795612409711
Epoch:  224  	Training Loss: 0.0006129628745839
Test Loss:  0.0004588079173117876
Valid Loss:  0.0006925257621333003
Epoch:  225  	Training Loss: 0.0006107313092797995
Test Loss:  0.00045816038618795574
Valid Loss:  0.0006912709795869887
Epoch:  226  	Training Loss: 0.0006087240180931985
Test Loss:  0.00045738782500848174
Valid Loss:  0.0006898177671246231
Epoch:  227  	Training Loss: 0.000606918940320611
Test Loss:  0.00045706931268796325
Valid Loss:  0.0006891530356369913
Epoch:  228  	Training Loss: 0.0006053283577784896
Test Loss:  0.00045629890519194305
Valid Loss:  0.0006876165280118585
Epoch:  229  	Training Loss: 0.0006038687424734235
Test Loss:  0.0004564200062304735
Valid Loss:  0.0006876828847452998
Epoch:  230  	Training Loss: 0.0006025935290381312
Test Loss:  0.0004555342602543533
Valid Loss:  0.0006859149434603751
Epoch:  231  	Training Loss: 0.0006012583617120981
Test Loss:  0.00045519458944909275
Valid Loss:  0.0006848823977634311
Epoch:  232  	Training Loss: 0.0006000564317218959
Test Loss:  0.0004547269199974835
Valid Loss:  0.0006837034015916288
Epoch:  233  	Training Loss: 0.000599594903178513
Test Loss:  0.00045417947694659233
Valid Loss:  0.00068247428862378
Epoch:  234  	Training Loss: 0.0005991978105157614
Test Loss:  0.00045370141742751
Valid Loss:  0.0006813844665884972
Epoch:  235  	Training Loss: 0.0005988494376651943
Test Loss:  0.0004532768507488072
Valid Loss:  0.0006804089061915874
Epoch:  236  	Training Loss: 0.0005985387251712382
Test Loss:  0.0004528939607553184
Valid Loss:  0.0006795295048505068
Epoch:  237  	Training Loss: 0.0005982554284855723
Test Loss:  0.00045254259021021426
Valid Loss:  0.0006787340389564633
Epoch:  238  	Training Loss: 0.0005979904672130942
Test Loss:  0.0004522157250903547
Valid Loss:  0.0006780051626265049
Epoch:  239  	Training Loss: 0.0005977369146421552
Test Loss:  0.0004519128706306219
Valid Loss:  0.0006773429922759533
Epoch:  240  	Training Loss: 0.0005974990781396627
Test Loss:  0.00045163073809817433
Valid Loss:  0.0006767397280782461
Epoch:  241  	Training Loss: 0.000597273581661284
Test Loss:  0.00045136059634387493
Valid Loss:  0.0006761816330254078
Epoch:  242  	Training Loss: 0.0005970501806586981
Test Loss:  0.0004523918323684484
Valid Loss:  0.0006759125972166657
Epoch:  243  	Training Loss: 0.0005964143783785403
Test Loss:  0.00045171432429924607
Valid Loss:  0.0006759282550774515
Epoch:  244  	Training Loss: 0.0005955438828095794
Test Loss:  0.0004522436938714236
Valid Loss:  0.0006757788942195475
Epoch:  245  	Training Loss: 0.0005953902727924287
Test Loss:  0.00045144627802073956
Valid Loss:  0.0006753058405593038
Epoch:  246  	Training Loss: 0.0005944713484495878
Test Loss:  0.0004512548621278256
Valid Loss:  0.0006746206199750304
Epoch:  247  	Training Loss: 0.000594001729041338
Test Loss:  0.00045085937017574906
Valid Loss:  0.0006743202684447169
Epoch:  248  	Training Loss: 0.0005935498629696667
Test Loss:  0.0004505775577854365
Valid Loss:  0.0006737461080774665
Epoch:  249  	Training Loss: 0.0005931309424340725
Test Loss:  0.0004504088428802788
Valid Loss:  0.000673457863740623
Epoch:  250  	Training Loss: 0.0005927809979766607
Test Loss:  0.0004502250230871141
Valid Loss:  0.0006731358007527888
Epoch:  251  	Training Loss: 0.0005924443830735981
Test Loss:  0.00045004149433225393
Valid Loss:  0.0006728137959726155
Epoch:  252  	Training Loss: 0.0005920581752434373
Test Loss:  0.000449760933406651
Valid Loss:  0.0006720808451063931
Epoch:  253  	Training Loss: 0.0005918306414969265
Test Loss:  0.00044960188097320497
Valid Loss:  0.0006715996423736215
Epoch:  254  	Training Loss: 0.0005916493246331811
Test Loss:  0.00044950476149097085
Valid Loss:  0.0006712564500048757
Epoch:  255  	Training Loss: 0.0005914918147027493
Test Loss:  0.00044944032561033964
Valid Loss:  0.0006709936424158514
Epoch:  256  	Training Loss: 0.0005913476343266666
Test Loss:  0.0004493955639190972
Valid Loss:  0.0006707783904857934
Epoch:  257  	Training Loss: 0.0005912176566198468
Test Loss:  0.00044937763595953584
Valid Loss:  0.0006706411950290203
Epoch:  258  	Training Loss: 0.0005910973413847387
Test Loss:  0.000449343235231936
Valid Loss:  0.0006704558618366718
Epoch:  259  	Training Loss: 0.0005909852334298193
Test Loss:  0.00044931884622201324
Valid Loss:  0.0006702906684949994
Epoch:  260  	Training Loss: 0.0005908823222853243
Test Loss:  0.0004492991720326245
Valid Loss:  0.0006701385136693716
Epoch:  261  	Training Loss: 0.0005907863960601389
Test Loss:  0.00044928217539563775
Valid Loss:  0.0006699971854686737
Epoch:  262  	Training Loss: 0.0005906977457925677
Test Loss:  0.00044958837679587305
Valid Loss:  0.0006701885140500963
Epoch:  263  	Training Loss: 0.0005905182915739715
Test Loss:  0.00044947362039238214
Valid Loss:  0.0006700711091980338
Epoch:  264  	Training Loss: 0.0005903887213207781
Test Loss:  0.00044943089596927166
Valid Loss:  0.0006700082449242473
Epoch:  265  	Training Loss: 0.0005902664852328598
Test Loss:  0.00044937687925994396
Valid Loss:  0.0006699376972392201
Epoch:  266  	Training Loss: 0.0005901483818888664
Test Loss:  0.0004493207670748234
Valid Loss:  0.0006698648794554174
Epoch:  267  	Training Loss: 0.0005900313844904304
Test Loss:  0.0004492648004088551
Valid Loss:  0.000669791828840971
Epoch:  268  	Training Loss: 0.000589919975027442
Test Loss:  0.0004492080770432949
Valid Loss:  0.0006697187782265246
Epoch:  269  	Training Loss: 0.0005898118251934648
Test Loss:  0.0004491482104640454
Valid Loss:  0.0006696415366604924
Epoch:  270  	Training Loss: 0.0005897021619603038
Test Loss:  0.00044908677227795124
Valid Loss:  0.0006695655174553394
Epoch:  271  	Training Loss: 0.0005895953509025276
Test Loss:  0.0004490247229114175
Valid Loss:  0.000669477041810751
Epoch:  272  	Training Loss: 0.0005894880159758031
Test Loss:  0.00044900854118168354
Valid Loss:  0.0006694565527141094
Epoch:  273  	Training Loss: 0.000589473289437592
Test Loss:  0.0004489962593652308
Valid Loss:  0.0006694401381537318
Epoch:  274  	Training Loss: 0.0005894583300687373
Test Loss:  0.00044898490887135267
Valid Loss:  0.0006694222684018314
Epoch:  275  	Training Loss: 0.0005894436035305262
Test Loss:  0.0004489736747927964
Valid Loss:  0.0006694059120491147
 55%|█████▌    | 277/500 [03:17<01:39,  2.23it/s] 56%|█████▌    | 279/500 [03:17<01:13,  2.99it/s] 56%|█████▌    | 281/500 [03:23<04:17,  1.18s/it] 57%|█████▋    | 283/500 [03:23<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:23<02:11,  1.63it/s] 57%|█████▋    | 287/500 [03:23<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:24<01:11,  2.94it/s] 58%|█████▊    | 291/500 [03:30<04:05,  1.17s/it] 59%|█████▊    | 293/500 [03:30<02:54,  1.18it/s] 59%|█████▉    | 295/500 [03:30<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:30<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:30<01:07,  2.99it/s] 60%|██████    | 301/500 [03:37<03:53,  1.17s/it] 61%|██████    | 303/500 [03:37<02:45,  1.19it/s] 61%|██████    | 305/500 [03:37<01:58,  1.64it/s] 61%|██████▏   | 307/500 [03:37<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:37<01:03,  3.00it/s] 62%|██████▏   | 311/500 [03:44<03:46,  1.20s/it] 63%|██████▎   | 313/500 [03:44<02:41,  1.16it/s] 63%|██████▎   | 315/500 [03:44<01:55,  1.60it/s] 63%|██████▎   | 317/500 [03:44<01:23,  2.19it/s] 64%|██████▍   | 319/500 [03:44<01:01,  2.94it/s] 64%|██████▍   | 321/500 [03:50<03:31,  1.18s/it] 65%|██████▍   | 323/500 [03:51<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:51<01:47,  1.62it/s] 65%|██████▌   | 327/500 [03:51<01:17,  2.22it/s] 66%|██████▌   | 329/500 [03:51<00:57,  2.99it/s] 66%|██████▌   | 331/500 [03:57<03:17,  1.17s/it] 67%|██████▋   | 333/500 [03:57<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:58<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:58<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:58<00:53,  3.01it/s] 68%|██████▊   | 341/500 [04:04<03:04,  1.16s/it] 69%|██████▊   | 343/500 [04:04<02:10,  1.20it/s]Epoch:  276  	Training Loss: 0.0005894288187846541
Test Loss:  0.0004489620914682746
Valid Loss:  0.0006693903123959899
Epoch:  277  	Training Loss: 0.0005894146743230522
Test Loss:  0.0004489516431931406
Valid Loss:  0.0006693738396279514
Epoch:  278  	Training Loss: 0.0005894001806154847
Test Loss:  0.00044894113671034575
Valid Loss:  0.0006693581817671657
Epoch:  279  	Training Loss: 0.0005893856287002563
Test Loss:  0.0004489296115934849
Valid Loss:  0.0006693399045616388
Epoch:  280  	Training Loss: 0.0005893713096156716
Test Loss:  0.00044891959987580776
Valid Loss:  0.0006693245959468186
Epoch:  281  	Training Loss: 0.0005893561756238341
Test Loss:  0.0004489090642891824
Valid Loss:  0.0006693075993098319
Epoch:  282  	Training Loss: 0.0005893420893698931
Test Loss:  0.0004489151469897479
Valid Loss:  0.0006694059120491147
Epoch:  283  	Training Loss: 0.0005892672343179584
Test Loss:  0.0004486717516556382
Valid Loss:  0.0006689368165098131
Epoch:  284  	Training Loss: 0.0005891555338166654
Test Loss:  0.0004485721583478153
Valid Loss:  0.0006686364067718387
Epoch:  285  	Training Loss: 0.0005890487227588892
Test Loss:  0.00044846103992313147
Valid Loss:  0.0006683403626084328
Epoch:  286  	Training Loss: 0.0005889537860639393
Test Loss:  0.000448519887868315
Valid Loss:  0.0006685309926979244
Epoch:  287  	Training Loss: 0.000588882714509964
Test Loss:  0.00044828388490714133
Valid Loss:  0.0006681026425212622
Epoch:  288  	Training Loss: 0.0005887721781618893
Test Loss:  0.00044819284812547266
Valid Loss:  0.0006678441422991455
Epoch:  289  	Training Loss: 0.0005886690341867507
Test Loss:  0.00044809066457673907
Valid Loss:  0.0006675858749076724
Epoch:  290  	Training Loss: 0.000588569208048284
Test Loss:  0.000447995204012841
Valid Loss:  0.0006673434982076287
Epoch:  291  	Training Loss: 0.0005884725833311677
Test Loss:  0.00044797256123274565
Valid Loss:  0.0006673387251794338
Epoch:  292  	Training Loss: 0.0005883846897631884
Test Loss:  0.0004477004404179752
Valid Loss:  0.0006671308656223118
Epoch:  293  	Training Loss: 0.0005881213000975549
Test Loss:  0.00044743664329871535
Valid Loss:  0.0006669270806014538
Epoch:  294  	Training Loss: 0.0005878660595044494
Test Loss:  0.00044718157732859254
Valid Loss:  0.0006667327252216637
Epoch:  295  	Training Loss: 0.0005876201903447509
Test Loss:  0.0004469332634471357
Valid Loss:  0.0006665473338216543
Epoch:  296  	Training Loss: 0.0005873790942132473
Test Loss:  0.00044668777263723314
Valid Loss:  0.0006663707899861038
Epoch:  297  	Training Loss: 0.000587127753533423
Test Loss:  0.00044644688023254275
Valid Loss:  0.0006661997176706791
Epoch:  298  	Training Loss: 0.0005868594162166119
Test Loss:  0.00044621151755563915
Valid Loss:  0.0006660321960225701
Epoch:  299  	Training Loss: 0.0005865611601620913
Test Loss:  0.00044597923988476396
Valid Loss:  0.0006658706697635353
Epoch:  300  	Training Loss: 0.0005862710531800985
Test Loss:  0.0004457529284991324
Valid Loss:  0.0006657118210569024
Epoch:  301  	Training Loss: 0.00058598758187145
Test Loss:  0.0004455304006114602
Valid Loss:  0.0006655575707554817
Epoch:  302  	Training Loss: 0.000585711735766381
Test Loss:  0.00044324330519884825
Valid Loss:  0.0006640059873461723
Epoch:  303  	Training Loss: 0.0005837653880007565
Test Loss:  0.0004422927158884704
Valid Loss:  0.0006634207675233483
Epoch:  304  	Training Loss: 0.0005832503084093332
Test Loss:  0.0004418174794409424
Valid Loss:  0.0006633963203057647
Epoch:  305  	Training Loss: 0.0005829071742482483
Test Loss:  0.0004413551068864763
Valid Loss:  0.0006629079580307007
Epoch:  306  	Training Loss: 0.0005826273700222373
Test Loss:  0.00044105335837230086
Valid Loss:  0.0006625039968639612
Epoch:  307  	Training Loss: 0.0005824110703542829
Test Loss:  0.00044081901432946324
Valid Loss:  0.0006621797219850123
Epoch:  308  	Training Loss: 0.000582203094381839
Test Loss:  0.0004406051884870976
Valid Loss:  0.000661880592815578
Epoch:  309  	Training Loss: 0.0005820184014737606
Test Loss:  0.0004405553045216948
Valid Loss:  0.0006620461354032159
Epoch:  310  	Training Loss: 0.0005818334175273776
Test Loss:  0.0004403460770845413
Valid Loss:  0.0006617270410060883
Epoch:  311  	Training Loss: 0.0005816336488351226
Test Loss:  0.00044014182640239596
Valid Loss:  0.0006614325102418661
Epoch:  312  	Training Loss: 0.0005814356845803559
Test Loss:  0.0004396227595862001
Valid Loss:  0.0006613390869461
Epoch:  313  	Training Loss: 0.0005801396328024566
Test Loss:  0.0004392133268993348
Valid Loss:  0.0006612958968617022
Epoch:  314  	Training Loss: 0.0005790729192085564
Test Loss:  0.0004388865199871361
Valid Loss:  0.000661159458104521
Epoch:  315  	Training Loss: 0.0005781719228252769
Test Loss:  0.0004386063083074987
Valid Loss:  0.0006607736577279866
Epoch:  316  	Training Loss: 0.0005773855373263359
Test Loss:  0.0004383592458907515
Valid Loss:  0.0006604120135307312
Epoch:  317  	Training Loss: 0.000576619990170002
Test Loss:  0.00043813305092044175
Valid Loss:  0.0006600485648959875
Epoch:  318  	Training Loss: 0.0005758191691711545
Test Loss:  0.00043802897562272847
Valid Loss:  0.0006597809260711074
Epoch:  319  	Training Loss: 0.0005750865675508976
Test Loss:  0.0004377482400741428
Valid Loss:  0.000659322424326092
Epoch:  320  	Training Loss: 0.0005743123474530876
Test Loss:  0.0004375348798930645
Valid Loss:  0.0006586407544091344
Epoch:  321  	Training Loss: 0.0005736153107136488
Test Loss:  0.00043733062921091914
Valid Loss:  0.0006580222398042679
Epoch:  322  	Training Loss: 0.00057299027685076
Test Loss:  0.00043722137343138456
Valid Loss:  0.0006575937150046229
Epoch:  323  	Training Loss: 0.0005724323564209044
Test Loss:  0.0004369972157292068
Valid Loss:  0.0006569455144926906
Epoch:  324  	Training Loss: 0.0005719892214983702
Test Loss:  0.0004367372312117368
Valid Loss:  0.0006562519702129066
Epoch:  325  	Training Loss: 0.0005715938750654459
Test Loss:  0.0004365000640973449
Valid Loss:  0.0006555848522111773
Epoch:  326  	Training Loss: 0.00057124940212816
Test Loss:  0.00043629988795146346
Valid Loss:  0.0006550039979629219
Epoch:  327  	Training Loss: 0.0005709730903618038
Test Loss:  0.0004361263709142804
Valid Loss:  0.0006544939242303371
Epoch:  328  	Training Loss: 0.0005707360105589032
Test Loss:  0.0004359797458164394
Valid Loss:  0.0006540293688885868
Epoch:  329  	Training Loss: 0.0005705279763787985
Test Loss:  0.0004358523292466998
Valid Loss:  0.000653619528748095
Epoch:  330  	Training Loss: 0.0005703447968699038
Test Loss:  0.0004357296274974942
Valid Loss:  0.0006532426923513412
Epoch:  331  	Training Loss: 0.0005701730842702091
Test Loss:  0.000435614085290581
Valid Loss:  0.0006528976373374462
Epoch:  332  	Training Loss: 0.0005700134788639843
Test Loss:  0.0004308368661440909
Valid Loss:  0.0006509085651487112
Epoch:  333  	Training Loss: 0.000566287781111896
Test Loss:  0.0004263919254299253
Valid Loss:  0.0006488524377346039
Epoch:  334  	Training Loss: 0.0005627684877254069
Test Loss:  0.00042234259308315814
Valid Loss:  0.0006466938648372889
Epoch:  335  	Training Loss: 0.0005595264956355095
Test Loss:  0.00041844017687253654
Valid Loss:  0.0006446648621931672
Epoch:  336  	Training Loss: 0.0005562673322856426
Test Loss:  0.00041477096965536475
Valid Loss:  0.0006426022155210376
Epoch:  337  	Training Loss: 0.000553214515093714
Test Loss:  0.0004113200702704489
Valid Loss:  0.000640019541606307
Epoch:  338  	Training Loss: 0.0005503150168806314
Test Loss:  0.00040799929411150515
Valid Loss:  0.0006369335460476577
Epoch:  339  	Training Loss: 0.0005474130157381296
Test Loss:  0.0004046860267408192
Valid Loss:  0.0006339368410408497
Epoch:  340  	Training Loss: 0.0005444948328658938
Test Loss:  0.0004014238074887544
Valid Loss:  0.0006309438613243401
Epoch:  341  	Training Loss: 0.0005416527856141329
Test Loss:  0.0003983778296969831
Valid Loss:  0.0006280667148530483
Epoch:  342  	Training Loss: 0.0005389563739299774
Test Loss:  0.000395694631151855
Valid Loss:  0.0006259016809053719
Epoch:  343  	Training Loss: 0.0005341955693438649
Test Loss:  0.00039223191561177373
Valid Loss:  0.0006221920484676957
 69%|██████▉   | 345/500 [04:04<01:33,  1.66it/s] 69%|██████▉   | 347/500 [04:04<01:07,  2.25it/s] 70%|██████▉   | 349/500 [04:05<00:49,  3.03it/s] 70%|███████   | 351/500 [04:11<02:53,  1.16s/it] 71%|███████   | 353/500 [04:11<02:02,  1.20it/s] 71%|███████   | 355/500 [04:11<01:27,  1.65it/s] 71%|███████▏  | 357/500 [04:11<01:03,  2.25it/s] 72%|███████▏  | 359/500 [04:11<00:46,  3.02it/s] 72%|███████▏  | 361/500 [04:18<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:18<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:18<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:18<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:18<00:43,  3.00it/s] 74%|███████▍  | 371/500 [04:24<02:30,  1.16s/it] 75%|███████▍  | 373/500 [04:24<01:46,  1.20it/s] 75%|███████▌  | 375/500 [04:25<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:25<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:25<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:31<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:31<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:32<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:32<00:51,  2.21it/s] 78%|███████▊  | 389/500 [04:32<00:37,  2.97it/s] 78%|███████▊  | 391/500 [04:38<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:38<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:38<01:04,  1.64it/s] 79%|███████▉  | 397/500 [04:38<00:46,  2.24it/s] 80%|███████▉  | 399/500 [04:39<00:33,  3.00it/s] 80%|████████  | 401/500 [04:45<01:55,  1.16s/it] 81%|████████  | 403/500 [04:45<01:21,  1.19it/s] 81%|████████  | 405/500 [04:45<00:57,  1.65it/s] 81%|████████▏ | 407/500 [04:45<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:45<00:30,  3.01it/s] 82%|████████▏ | 411/500 [04:52<01:43,  1.17s/it]Epoch:  344  	Training Loss: 0.0005305244121700525
Test Loss:  0.00038857152685523033
Valid Loss:  0.0006181765347719193
Epoch:  345  	Training Loss: 0.0005268696113489568
Test Loss:  0.0003849801141768694
Valid Loss:  0.0006141652120277286
Epoch:  346  	Training Loss: 0.0005232591647654772
Test Loss:  0.0003814874798990786
Valid Loss:  0.0006101129110902548
Epoch:  347  	Training Loss: 0.0005196029087528586
Test Loss:  0.0003779918479267508
Valid Loss:  0.0006060157320462167
Epoch:  348  	Training Loss: 0.0005159712163731456
Test Loss:  0.00037450616946443915
Valid Loss:  0.0006017810665071011
Epoch:  349  	Training Loss: 0.0005122963921166956
Test Loss:  0.00037106082891114056
Valid Loss:  0.0005975954700261354
Epoch:  350  	Training Loss: 0.0005086681921966374
Test Loss:  0.0003675950283650309
Valid Loss:  0.0005933993961662054
Epoch:  351  	Training Loss: 0.000505057570990175
Test Loss:  0.0003640771028585732
Valid Loss:  0.0005890853353776038
Epoch:  352  	Training Loss: 0.0005014229100197554
Test Loss:  0.00036350084701552987
Valid Loss:  0.0005880985409021378
Epoch:  353  	Training Loss: 0.0005009371088817716
Test Loss:  0.0003629979328252375
Valid Loss:  0.0005872037727385759
Epoch:  354  	Training Loss: 0.0005004981649108231
Test Loss:  0.0003625389072112739
Valid Loss:  0.0005863932892680168
Epoch:  355  	Training Loss: 0.000500061665661633
Test Loss:  0.00036210688995197415
Valid Loss:  0.000585649162530899
Epoch:  356  	Training Loss: 0.0004996281350031495
Test Loss:  0.00036171075771562755
Valid Loss:  0.0005849745939485729
Epoch:  357  	Training Loss: 0.0004992197500541806
Test Loss:  0.0003613447188399732
Valid Loss:  0.0005843586986884475
Epoch:  358  	Training Loss: 0.0004988145083189011
Test Loss:  0.0003609769628383219
Valid Loss:  0.0005837874487042427
Epoch:  359  	Training Loss: 0.0004984005354344845
Test Loss:  0.00036060885759070516
Valid Loss:  0.000583248445764184
Epoch:  360  	Training Loss: 0.0004979601362720132
Test Loss:  0.00036025818553753197
Valid Loss:  0.0005827503046020865
Epoch:  361  	Training Loss: 0.0004975303309038281
Test Loss:  0.0003599315823521465
Valid Loss:  0.0005822891253046691
Epoch:  362  	Training Loss: 0.0004971235175617039
Test Loss:  0.0003593733417801559
Valid Loss:  0.0005818473873659968
Epoch:  363  	Training Loss: 0.0004956392804160714
Test Loss:  0.0003586809034459293
Valid Loss:  0.0005811147857457399
Epoch:  364  	Training Loss: 0.0004945739055983722
Test Loss:  0.00035812941496260464
Valid Loss:  0.0005804456886835396
Epoch:  365  	Training Loss: 0.0004937035264447331
Test Loss:  0.00035763089545071125
Valid Loss:  0.0005797701887786388
Epoch:  366  	Training Loss: 0.0004929392016492784
Test Loss:  0.0003571679990272969
Valid Loss:  0.0005791041767224669
Epoch:  367  	Training Loss: 0.0004922556690871716
Test Loss:  0.00035680047585628927
Valid Loss:  0.0005785041721537709
Epoch:  368  	Training Loss: 0.0004916024627164006
Test Loss:  0.000356450880644843
Valid Loss:  0.0005778102204203606
Epoch:  369  	Training Loss: 0.0004909400013275445
Test Loss:  0.00035613615182228386
Valid Loss:  0.0005771496798843145
Epoch:  370  	Training Loss: 0.0004902990767732263
Test Loss:  0.0003558686003088951
Valid Loss:  0.0005764923989772797
Epoch:  371  	Training Loss: 0.000489679747261107
Test Loss:  0.0003556104493327439
Valid Loss:  0.0005758420447818935
Epoch:  372  	Training Loss: 0.000489071651827544
Test Loss:  0.00035549793392419815
Valid Loss:  0.0005756848258897662
Epoch:  373  	Training Loss: 0.0004888998810201883
Test Loss:  0.0003553838760126382
Valid Loss:  0.0005755283636972308
Epoch:  374  	Training Loss: 0.0004887296818196774
Test Loss:  0.00035526842111721635
Valid Loss:  0.0005753713776357472
Epoch:  375  	Training Loss: 0.0004885614034719765
Test Loss:  0.0003551550325937569
Valid Loss:  0.0005752135766670108
Epoch:  376  	Training Loss: 0.0004883969086222351
Test Loss:  0.00035504039260558784
Valid Loss:  0.0005750561831519008
Epoch:  377  	Training Loss: 0.00048823392717167735
Test Loss:  0.0003549241810105741
Valid Loss:  0.0005748978583142161
Epoch:  378  	Training Loss: 0.0004880714404862374
Test Loss:  0.00035480872611515224
Valid Loss:  0.000574739184230566
Epoch:  379  	Training Loss: 0.0004879087791778147
Test Loss:  0.0003546902444213629
Valid Loss:  0.0005745782982558012
Epoch:  380  	Training Loss: 0.0004877441970165819
Test Loss:  0.0003545714425854385
Valid Loss:  0.0005744172958657146
Epoch:  381  	Training Loss: 0.0004875783924944699
Test Loss:  0.0003544505452737212
Valid Loss:  0.0005742539069615304
Epoch:  382  	Training Loss: 0.00048741057980805635
Test Loss:  0.000353996641933918
Valid Loss:  0.0005730587290599942
Epoch:  383  	Training Loss: 0.00048709442489780486
Test Loss:  0.0003537944285199046
Valid Loss:  0.0005723071517422795
Epoch:  384  	Training Loss: 0.00048686820082366467
Test Loss:  0.0003536833974067122
Valid Loss:  0.0005717379390262067
Epoch:  385  	Training Loss: 0.00048667716328054667
Test Loss:  0.0003536128206178546
Valid Loss:  0.0005712634883821011
Epoch:  386  	Training Loss: 0.00048650981625542045
Test Loss:  0.00035356395528651774
Valid Loss:  0.000570851843804121
Epoch:  387  	Training Loss: 0.0004863618523813784
Test Loss:  0.000353531155269593
Valid Loss:  0.0005704838549718261
Epoch:  388  	Training Loss: 0.00048622977919876575
Test Loss:  0.00035350784310139716
Valid Loss:  0.0005701513728126884
Epoch:  389  	Training Loss: 0.00048611225793138146
Test Loss:  0.00035349244717508554
Valid Loss:  0.0005698504392057657
Epoch:  390  	Training Loss: 0.00048600698937661946
Test Loss:  0.0003534833376761526
Valid Loss:  0.0005695775616914034
Epoch:  391  	Training Loss: 0.00048591167433187366
Test Loss:  0.0003534791467245668
Valid Loss:  0.0005693285493180156
Epoch:  392  	Training Loss: 0.00048582570161670446
Test Loss:  0.0003483615000732243
Valid Loss:  0.0005639911978505552
Epoch:  393  	Training Loss: 0.00048079807311296463
Test Loss:  0.00034375209361314774
Valid Loss:  0.0005592271918430924
Epoch:  394  	Training Loss: 0.0004759261501021683
Test Loss:  0.00033927883487194777
Valid Loss:  0.0005544752348214388
Epoch:  395  	Training Loss: 0.0004712119116447866
Test Loss:  0.00033498043194413185
Valid Loss:  0.0005498415557667613
Epoch:  396  	Training Loss: 0.0004666113236453384
Test Loss:  0.00033074134262278676
Valid Loss:  0.000545188901014626
Epoch:  397  	Training Loss: 0.0004620642284862697
Test Loss:  0.0003266707935836166
Valid Loss:  0.00054062285926193
Epoch:  398  	Training Loss: 0.00045766582479700446
Test Loss:  0.0003227245470043272
Valid Loss:  0.0005361115909181535
Epoch:  399  	Training Loss: 0.0004533902392722666
Test Loss:  0.0003188989358022809
Valid Loss:  0.0005316600436344743
Epoch:  400  	Training Loss: 0.0004492286825552583
Test Loss:  0.00031518435571342707
Valid Loss:  0.0005272733396850526
Epoch:  401  	Training Loss: 0.0004451748973224312
Test Loss:  0.00031157222110778093
Valid Loss:  0.0005229543894529343
Epoch:  402  	Training Loss: 0.0004412254202179611
Test Loss:  0.00031021531322039664
Valid Loss:  0.0005199026199989021
Epoch:  403  	Training Loss: 0.0004392786358948797
Test Loss:  0.00030932939262129366
Valid Loss:  0.0005199947627261281
Epoch:  404  	Training Loss: 0.0004384650383144617
Test Loss:  0.00030872999923303723
Valid Loss:  0.0005181132582947612
Epoch:  405  	Training Loss: 0.00043738167732954025
Test Loss:  0.0003079967573285103
Valid Loss:  0.0005181811866350472
Epoch:  406  	Training Loss: 0.0004367831570561975
Test Loss:  0.0003073934349231422
Valid Loss:  0.0005162900197319686
Epoch:  407  	Training Loss: 0.0004357235156930983
Test Loss:  0.000306647561956197
Valid Loss:  0.000516196247190237
Epoch:  408  	Training Loss: 0.00043502042535692453
Test Loss:  0.00030611411784775555
Valid Loss:  0.0005144771421328187
Epoch:  409  	Training Loss: 0.0004341577587183565
Test Loss:  0.00030535587575286627
Valid Loss:  0.0005145766772329807
Epoch:  410  	Training Loss: 0.0004335028352215886
Test Loss:  0.00030473500373773277
Valid Loss:  0.0005126444739289582
Epoch:  411  	Training Loss: 0.0004324538167566061
Test Loss:  0.0003039789735339582
Valid Loss:  0.0005122612928971648
 83%|████████▎ | 413/500 [04:52<01:12,  1.19it/s] 83%|████████▎ | 415/500 [04:52<00:51,  1.65it/s] 83%|████████▎ | 417/500 [04:52<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:52<00:27,  2.97it/s] 84%|████████▍ | 421/500 [04:58<01:32,  1.18s/it] 85%|████████▍ | 423/500 [04:59<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:59<00:45,  1.63it/s] 85%|████████▌ | 427/500 [04:59<00:32,  2.23it/s] 86%|████████▌ | 429/500 [04:59<00:23,  2.99it/s] 86%|████████▌ | 431/500 [05:05<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:05<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:06<00:39,  1.64it/s] 87%|████████▋ | 437/500 [05:06<00:28,  2.24it/s] 88%|████████▊ | 439/500 [05:06<00:20,  3.01it/s] 88%|████████▊ | 441/500 [05:12<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:12<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:12<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:12<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:13<00:17,  3.00it/s] 90%|█████████ | 451/500 [05:19<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:19<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:19<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:19<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:19<00:13,  2.99it/s] 92%|█████████▏| 459/500 [05:31<00:13,  2.99it/s] 92%|█████████▏| 461/500 [05:32<01:22,  2.11s/it] 93%|█████████▎| 463/500 [05:32<00:55,  1.50s/it] 93%|█████████▎| 465/500 [05:32<00:37,  1.07s/it] 93%|█████████▎| 467/500 [05:32<00:25,  1.30it/s] 94%|█████████▍| 469/500 [05:32<00:17,  1.80it/s] 94%|█████████▍| 471/500 [05:39<00:38,  1.32s/it] 95%|█████████▍| 473/500 [05:39<00:25,  1.06it/s] 95%|█████████▌| 475/500 [05:39<00:17,  1.46it/s] 95%|█████████▌| 477/500 [05:39<00:11,  2.01it/s]Epoch:  412  	Training Loss: 0.000431634922279045
Test Loss:  0.0003029302170034498
Valid Loss:  0.0005084134754724801
Epoch:  413  	Training Loss: 0.0004297481500543654
Test Loss:  0.00030271182185970247
Valid Loss:  0.0005068735918030143
Epoch:  414  	Training Loss: 0.00042855957872234285
Test Loss:  0.000302034430205822
Valid Loss:  0.000503922812640667
Epoch:  415  	Training Loss: 0.00042760383803397417
Test Loss:  0.00030219112522900105
Valid Loss:  0.0005032957415096462
Epoch:  416  	Training Loss: 0.0004267580807209015
Test Loss:  0.0003017896960955113
Valid Loss:  0.0005011671455577016
Epoch:  417  	Training Loss: 0.00042605429189279675
Test Loss:  0.0003019078285433352
Valid Loss:  0.000500401365570724
Epoch:  418  	Training Loss: 0.0004254053928889334
Test Loss:  0.00030187307856976986
Valid Loss:  0.0004990531597286463
Epoch:  419  	Training Loss: 0.0004248027107678354
Test Loss:  0.0003019746800418943
Valid Loss:  0.0004982659593224525
Epoch:  420  	Training Loss: 0.00042424933053553104
Test Loss:  0.0003019941214006394
Valid Loss:  0.0004972870228812099
Epoch:  421  	Training Loss: 0.0004237453395035118
Test Loss:  0.0003020940930582583
Valid Loss:  0.0004966119886375964
Epoch:  422  	Training Loss: 0.00042327659321017563
Test Loss:  0.0002977328549604863
Valid Loss:  0.000492095248773694
Epoch:  423  	Training Loss: 0.00041859078919515014
Test Loss:  0.000293448509182781
Valid Loss:  0.000487478100694716
Epoch:  424  	Training Loss: 0.0004141166864428669
Test Loss:  0.0002896103833336383
Valid Loss:  0.0004832149134017527
Epoch:  425  	Training Loss: 0.00040987489046528935
Test Loss:  0.00028583145467564464
Valid Loss:  0.00047890644054859877
Epoch:  426  	Training Loss: 0.00040584971429780126
Test Loss:  0.00028239242965355515
Valid Loss:  0.0004748629580717534
Epoch:  427  	Training Loss: 0.000401986762881279
Test Loss:  0.0002790112339425832
Valid Loss:  0.000470768689410761
Epoch:  428  	Training Loss: 0.0003982929920312017
Test Loss:  0.0002760763163678348
Valid Loss:  0.0004669430782087147
Epoch:  429  	Training Loss: 0.00039480929262936115
Test Loss:  0.0002731492859311402
Valid Loss:  0.0004630945040844381
Epoch:  430  	Training Loss: 0.0003914929402526468
Test Loss:  0.0002705345395952463
Valid Loss:  0.0004594643251039088
Epoch:  431  	Training Loss: 0.0003883167519234121
Test Loss:  0.00026790646370500326
Valid Loss:  0.00045583356404677033
Epoch:  432  	Training Loss: 0.00038530403980985284
Test Loss:  0.0002679026802070439
Valid Loss:  0.00045544959721155465
Epoch:  433  	Training Loss: 0.00038503302494063973
Test Loss:  0.0002678283490240574
Valid Loss:  0.00045501365093514323
Epoch:  434  	Training Loss: 0.0003847909683827311
Test Loss:  0.0002677312877494842
Valid Loss:  0.00045457278611138463
Epoch:  435  	Training Loss: 0.0003845644532702863
Test Loss:  0.00026763087953440845
Valid Loss:  0.0004541405651252717
Epoch:  436  	Training Loss: 0.00038434311863966286
Test Loss:  0.0002675332361832261
Valid Loss:  0.0004537281929515302
Epoch:  437  	Training Loss: 0.0003841106372419745
Test Loss:  0.00026744272327050567
Valid Loss:  0.00045333572779782116
Epoch:  438  	Training Loss: 0.00038389023393392563
Test Loss:  0.0002673592825885862
Valid Loss:  0.00045296354801394045
Epoch:  439  	Training Loss: 0.00038367975503206253
Test Loss:  0.00026728183729574084
Valid Loss:  0.00045261025661602616
Epoch:  440  	Training Loss: 0.00038347786176018417
Test Loss:  0.00026720945606939495
Valid Loss:  0.00045226747170090675
Epoch:  441  	Training Loss: 0.0003832848451565951
Test Loss:  0.00026714178966358304
Valid Loss:  0.0004519387148320675
Epoch:  442  	Training Loss: 0.00038309942465275526
Test Loss:  0.0002668776432983577
Valid Loss:  0.00045106446486897767
Epoch:  443  	Training Loss: 0.0003827424661722034
Test Loss:  0.00026671012165024877
Valid Loss:  0.0004503649252001196
Epoch:  444  	Training Loss: 0.00038241740548983216
Test Loss:  0.0002665558713488281
Valid Loss:  0.0004497275222092867
Epoch:  445  	Training Loss: 0.00038211524952203035
Test Loss:  0.0002664050261955708
Valid Loss:  0.00044913782039657235
Epoch:  446  	Training Loss: 0.0003818307595793158
Test Loss:  0.0002662564511410892
Valid Loss:  0.0004485925892367959
Epoch:  447  	Training Loss: 0.00038156009395606816
Test Loss:  0.0002661060425452888
Valid Loss:  0.00044807669473811984
Epoch:  448  	Training Loss: 0.00038129393942654133
Test Loss:  0.00026595190865918994
Valid Loss:  0.0004475880414247513
Epoch:  449  	Training Loss: 0.000381030811695382
Test Loss:  0.0002657958830241114
Valid Loss:  0.0004471232241485268
Epoch:  450  	Training Loss: 0.00038077429053373635
Test Loss:  0.0002656384895090014
Valid Loss:  0.00044668311602436006
Epoch:  451  	Training Loss: 0.0003805240849032998
Test Loss:  0.000265480310190469
Valid Loss:  0.00044626183807849884
Epoch:  452  	Training Loss: 0.00038027839036658406
Test Loss:  0.0002653890987858176
Valid Loss:  0.0004463062505237758
Epoch:  453  	Training Loss: 0.0003802154096774757
Test Loss:  0.0002655457938089967
Valid Loss:  0.00044636958045884967
Epoch:  454  	Training Loss: 0.0003801957645919174
Test Loss:  0.00026551203336566687
Valid Loss:  0.0004463428631424904
Epoch:  455  	Training Loss: 0.00038019922794774175
Test Loss:  0.00026567408349364996
Valid Loss:  0.0004463359364308417
Epoch:  456  	Training Loss: 0.0003802041755989194
Test Loss:  0.00026546622393652797
Valid Loss:  0.0004462558717932552
Epoch:  457  	Training Loss: 0.00038021020009182394
Test Loss:  0.00026577964308671653
Valid Loss:  0.0004463031073100865
Epoch:  458  	Training Loss: 0.0003802235296461731
Test Loss:  0.0002654491690918803
Valid Loss:  0.0004461635835468769
Epoch:  459  	Training Loss: 0.00038021046202629805
Test Loss:  0.0002657693112269044
Valid Loss:  0.0004462395154405385
Epoch:  460  	Training Loss: 0.00038020056672394276
Test Loss:  0.00026548694586381316
Valid Loss:  0.00044612790225073695
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.00038020662032067776
Test Loss:  0.00026540321414358914
Valid Loss:  0.00044596995576284826
Epoch:  462  	Training Loss: 0.0003800535632763058
Test Loss:  0.0002654629643075168
Valid Loss:  0.0004458472249098122
Epoch:  463  	Training Loss: 0.0003799042315222323
Test Loss:  0.0002653617411851883
Valid Loss:  0.00044567821896634996
Epoch:  464  	Training Loss: 0.0003797879908233881
Test Loss:  0.0002652636030688882
Valid Loss:  0.00044551159953698516
Epoch:  465  	Training Loss: 0.00037967192474752665
Test Loss:  0.000265166541794315
Valid Loss:  0.0004453446308616549
Epoch:  466  	Training Loss: 0.0003795562661252916
Test Loss:  0.0002650531241670251
Valid Loss:  0.00044518665526993573
Epoch:  467  	Training Loss: 0.0003794416843447834
Test Loss:  0.00026497087674215436
Valid Loss:  0.0004450302803888917
Epoch:  468  	Training Loss: 0.0003793254727497697
Test Loss:  0.00026487739523872733
Valid Loss:  0.00044486860861070454
Epoch:  469  	Training Loss: 0.00037921039620414376
Test Loss:  0.0002647640649229288
Valid Loss:  0.0004447118262760341
Epoch:  470  	Training Loss: 0.0003790964838117361
Test Loss:  0.0002646832726895809
Valid Loss:  0.00044455970055423677
Epoch:  471  	Training Loss: 0.0003789811162278056
Test Loss:  0.0002645889762789011
Valid Loss:  0.0004444003861863166
Epoch:  472  	Training Loss: 0.00037886606878601015
Test Loss:  0.00026389857521280646
Valid Loss:  0.00044352226541377604
Epoch:  473  	Training Loss: 0.0003781171690206975
Test Loss:  0.0002633431286085397
Valid Loss:  0.0004430515691637993
Epoch:  474  	Training Loss: 0.0003776110243052244
Test Loss:  0.0002628478978294879
Valid Loss:  0.000442694581579417
Epoch:  475  	Training Loss: 0.0003771968185901642
Test Loss:  0.00026245100889354944
Valid Loss:  0.0004423951613716781
Epoch:  476  	Training Loss: 0.00037681363755837083
Test Loss:  0.00026209320640191436
Valid Loss:  0.000442138290964067
Epoch:  477  	Training Loss: 0.00037644690019078553
Test Loss:  0.00026189227355644107
Valid Loss:  0.0004420056357048452
Epoch:  478  	Training Loss: 0.0003762162523344159
Test Loss:  0.00026164506562054157
 96%|█████████▌| 479/500 [05:39<00:07,  2.72it/s] 96%|█████████▌| 481/500 [05:45<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:46<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:46<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:46<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:46<00:03,  2.99it/s] 98%|█████████▊| 491/500 [05:52<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:52<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:53<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:53<00:01,  2.23it/s]100%|█████████▉| 499/500 [05:53<00:00,  2.99it/s]100%|██████████| 500/500 [05:53<00:00,  1.41it/s]
Valid Loss:  0.0004418548196554184
Epoch:  479  	Training Loss: 0.0003760489053092897
Test Loss:  0.0002615076373331249
Valid Loss:  0.00044179960968904197
Epoch:  480  	Training Loss: 0.00037592079024761915
Test Loss:  0.00026131642516702414
Valid Loss:  0.0004416927113197744
Epoch:  481  	Training Loss: 0.00037582137156277895
Test Loss:  0.0002612520765978843
Valid Loss:  0.0004416396841406822
Epoch:  482  	Training Loss: 0.0003757451777346432
Test Loss:  0.00026116945082321763
Valid Loss:  0.00044146698201075196
Epoch:  483  	Training Loss: 0.0003756334481295198
Test Loss:  0.00026108516613021493
Valid Loss:  0.000441293406765908
Epoch:  484  	Training Loss: 0.0003755206707865
Test Loss:  0.0002610028604976833
Valid Loss:  0.000441121548647061
Epoch:  485  	Training Loss: 0.0003754092031158507
Test Loss:  0.00026091973995789886
Valid Loss:  0.0004409471875987947
Epoch:  486  	Training Loss: 0.0003752960474230349
Test Loss:  0.00026083720149472356
Valid Loss:  0.0004407728847581893
Epoch:  487  	Training Loss: 0.0003751832991838455
Test Loss:  0.00026075425557792187
Valid Loss:  0.00044059997890144587
Epoch:  488  	Training Loss: 0.00037507113302126527
Test Loss:  0.0002606726484373212
Valid Loss:  0.0004404272767715156
Epoch:  489  	Training Loss: 0.00037495853030122817
Test Loss:  0.0002605909830890596
Valid Loss:  0.000440255826106295
Epoch:  490  	Training Loss: 0.0003748468297999352
Test Loss:  0.00026050841552205384
Valid Loss:  0.0004400860343594104
Epoch:  491  	Training Loss: 0.0003747353912331164
Test Loss:  0.00026042835088446736
Valid Loss:  0.0004399172030389309
Epoch:  492  	Training Loss: 0.0003746241854969412
Test Loss:  0.0002593540120869875
Valid Loss:  0.0004384478088468313
Epoch:  493  	Training Loss: 0.0003735190839506686
Test Loss:  0.0002591729862615466
Valid Loss:  0.0004381075268611312
Epoch:  494  	Training Loss: 0.00037328674807213247
Test Loss:  0.00025909527903422713
Valid Loss:  0.00043786430615000427
Epoch:  495  	Training Loss: 0.0003730806056410074
Test Loss:  0.00025905395159497857
Valid Loss:  0.00043767987517639995
Epoch:  496  	Training Loss: 0.00037290487671270967
Test Loss:  0.00025903788628056645
Valid Loss:  0.00043757809908129275
Epoch:  497  	Training Loss: 0.0003727715229615569
Test Loss:  0.00025904588983394206
Valid Loss:  0.0004375415446702391
Epoch:  498  	Training Loss: 0.0003726670693140477
Test Loss:  0.0002590527292340994
Valid Loss:  0.00043748621828854084
Epoch:  499  	Training Loss: 0.0003725754504557699
Test Loss:  0.0002590494405012578
Valid Loss:  0.00043741639819927514
Epoch:  500  	Training Loss: 0.00037248776061460376
Test Loss:  0.00025905342772603035
Valid Loss:  0.00043733359780162573
seed is  17
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.29it/s]  1%|          | 4/500 [00:00<00:30, 16.41it/s]  1%|          | 6/500 [00:00<00:30, 16.31it/s]  2%|▏         | 8/500 [00:00<00:30, 16.25it/s]  2%|▏         | 10/500 [00:00<00:30, 16.17it/s]  2%|▏         | 12/500 [00:00<00:30, 16.18it/s]  3%|▎         | 14/500 [00:00<00:29, 16.24it/s]  3%|▎         | 16/500 [00:00<00:29, 16.36it/s]  4%|▎         | 18/500 [00:01<00:29, 16.42it/s]  4%|▍         | 20/500 [00:01<00:29, 16.43it/s]  4%|▍         | 22/500 [00:01<00:29, 16.37it/s]  5%|▍         | 24/500 [00:01<00:28, 16.43it/s]  5%|▌         | 26/500 [00:01<00:28, 16.36it/s]  6%|▌         | 28/500 [00:01<00:28, 16.42it/s]  6%|▌         | 30/500 [00:01<00:28, 16.46it/s]  6%|▋         | 32/500 [00:01<00:28, 16.46it/s]  7%|▋         | 34/500 [00:02<00:28, 16.48it/s]  7%|▋         | 36/500 [00:02<00:28, 16.47it/s]  8%|▊         | 38/500 [00:02<00:28, 16.50it/s]  8%|▊         | 40/500 [00:02<00:28, 16.41it/s]  8%|▊         | 42/500 [00:02<00:27, 16.41it/s]  9%|▉         | 44/500 [00:02<00:27, 16.43it/s]  9%|▉         | 46/500 [00:02<00:27, 16.37it/s] 10%|▉         | 48/500 [00:02<00:27, 16.45it/s] 10%|█         | 50/500 [00:03<00:27, 16.49it/s] 10%|█         | 52/500 [00:03<00:27, 16.49it/s] 11%|█         | 54/500 [00:03<00:27, 16.48it/s] 11%|█         | 56/500 [00:03<00:27, 16.41it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.43it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.30it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.32it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.38it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.36it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.33it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.38it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.39it/s] 15%|█▍        | 74/500 [00:04<00:25, 16.42it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.43it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.46it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.44it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.44it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.43it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.44it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.47it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.49it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.49it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.44it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.47it/s] 20%|█▉        | 98/500 [00:05<00:24, 16.50it/s] 20%|██        | 100/500 [00:06<00:24, 16.32it/s] 20%|██        | 102/500 [00:06<00:24, 16.29it/s] 21%|██        | 104/500 [00:06<00:24, 16.10it/s] 21%|██        | 106/500 [00:06<00:24, 16.06it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.11it/s] 22%|██▏       | 110/500 [00:06<00:24, 16.23it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.39it/s] 23%|██▎       | 114/500 [00:06<00:23, 16.40it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.14it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.19it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.02it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.09it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.06it/s]Epoch:  1  	Training Loss: 0.10098293423652649
Test Loss:  1579.64990234375
Valid Loss:  1582.14599609375
Epoch:  2  	Training Loss: 1564.9405517578125
Test Loss:  62711597629440.0
Valid Loss:  62743356899328.0
Epoch:  3  	Training Loss: 62887187972096.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:23, 15.88it/s] 26%|██▌       | 128/500 [00:07<00:23, 15.97it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.14it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.27it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.33it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.30it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.38it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.40it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.38it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.36it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.29it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.23it/s] 30%|███       | 150/500 [00:09<00:21, 16.07it/s] 30%|███       | 152/500 [00:09<00:21, 16.05it/s] 31%|███       | 154/500 [00:09<00:21, 16.16it/s] 31%|███       | 156/500 [00:09<00:21, 16.29it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.42it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.33it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.22it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.27it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.20it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.16it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.19it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.20it/s] 35%|███▍      | 174/500 [00:10<00:20, 16.01it/s] 35%|███▌      | 176/500 [00:10<00:20, 16.14it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.22it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.29it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.39it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.19it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.32it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.36it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.41it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.41it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.43it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.49it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.52it/s] 40%|████      | 200/500 [00:12<00:18, 16.52it/s] 40%|████      | 202/500 [00:12<00:18, 16.50it/s] 41%|████      | 204/500 [00:12<00:17, 16.49it/s] 41%|████      | 206/500 [00:12<00:17, 16.48it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.54it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.50it/s] 42%|████▏     | 212/500 [00:12<00:17, 16.34it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.26it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.37it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.43it/s] 44%|████▍     | 220/500 [00:13<00:16, 16.50it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.54it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.50it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.41it/s] 46%|████▌     | 228/500 [00:13<00:16, 16.39it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.26it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.13it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.13it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.23it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.32it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.43it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.45it/s] 49%|████▉     | 244/500 [00:14<00:15, 16.49it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.52it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.55it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.40it/s] 50%|█████     | 252/500 [00:15<00:15, 16.32it/s] 51%|█████     | 254/500 [00:15<00:15, 16.33it/s] 51%|█████     | 256/500 [00:15<00:15, 16.22it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.27it/s] 52%|█████▏    | 260/500 [00:15<00:15, 15.89it/s] 52%|█████▏    | 262/500 [00:16<00:15, 15.23it/s] 53%|█████▎    | 264/500 [00:16<00:15, 15.50it/s] 53%|█████▎    | 266/500 [00:16<00:14, 15.80it/s] 54%|█████▎    | 268/500 [00:16<00:15, 15.13it/s] 54%|█████▍    | 270/500 [00:16<00:15, 15.16it/s] 54%|█████▍    | 272/500 [00:16<00:14, 15.46it/s] 55%|█████▍    | 274/500 [00:16<00:14, 15.83it/s] 55%|█████▌    | 276/500 [00:16<00:14, 15.46it/s] 56%|█████▌    | 278/500 [00:17<00:15, 14.65it/s] 56%|█████▌    | 280/500 [00:17<00:14, 14.69it/s] 56%|█████▋    | 282/500 [00:17<00:14, 15.17it/s] 57%|█████▋    | 284/500 [00:17<00:13, 15.60it/s] 57%|█████▋    | 286/500 [00:17<00:13, 15.75it/s] 58%|█████▊    | 288/500 [00:17<00:13, 15.82it/s] 58%|█████▊    | 290/500 [00:17<00:13, 15.94it/s] 58%|█████▊    | 292/500 [00:17<00:12, 16.14it/s] 59%|█████▉    | 294/500 [00:18<00:13, 15.65it/s] 59%|█████▉    | 296/500 [00:18<00:12, 15.90it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.09it/s] 60%|██████    | 300/500 [00:18<00:12, 16.23it/s] 60%|██████    | 302/500 [00:18<00:12, 16.10it/s] 61%|██████    | 304/500 [00:18<00:12, 16.22it/s] 61%|██████    | 306/500 [00:18<00:11, 16.30it/s] 62%|██████▏   | 308/500 [00:18<00:11, 16.36it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.45it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.47it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.48it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.31it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.37it/s] 64%|██████▍   | 320/500 [00:19<00:11, 16.23it/s] 64%|██████▍   | 322/500 [00:19<00:11, 16.01it/s] 65%|██████▍   | 324/500 [00:19<00:11, 15.91it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.07it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.13it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.30it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.40it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.41it/s] 67%|██████▋   | 336/500 [00:20<00:09, 16.40it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.33it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.29it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.31it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.32it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.37it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.42it/s] 70%|███████   | 350/500 [00:21<00:09, 16.45it/s] 70%|███████   | 352/500 [00:21<00:08, 16.45it/s] 71%|███████   | 354/500 [00:21<00:08, 16.49it/s] 71%|███████   | 356/500 [00:21<00:08, 16.39it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.41it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.30it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.32it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.37it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.44it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.46it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.47it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.28it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.18it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.04it/s] 76%|███████▌  | 378/500 [00:23<00:08, 14.70it/s] 76%|███████▌  | 380/500 [00:23<00:08, 14.66it/s] 76%|███████▋  | 382/500 [00:23<00:07, 15.19it/s] 77%|███████▋  | 384/500 [00:23<00:07, 15.53it/s] 77%|███████▋  | 386/500 [00:23<00:07, 15.79it/s] 78%|███████▊  | 388/500 [00:23<00:07, 15.07it/s] 78%|███████▊  | 390/500 [00:24<00:07, 14.17it/s] 78%|███████▊  | 392/500 [00:24<00:07, 14.78it/s] 79%|███████▉  | 394/500 [00:24<00:06, 15.25it/s] 79%|███████▉  | 396/500 [00:24<00:06, 15.60it/s] 80%|███████▉  | 398/500 [00:24<00:06, 15.88it/s] 80%|████████  | 400/500 [00:24<00:06, 16.03it/s] 80%|████████  | 402/500 [00:24<00:06, 16.15it/s] 81%|████████  | 404/500 [00:24<00:05, 16.27it/s] 81%|████████  | 406/500 [00:25<00:05, 16.32it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.36it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.46it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.47it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.50it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.55it/s] 84%|████████▎ | 418/500 [00:25<00:04, 16.55it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.50it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.39it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.41it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.48it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.35it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.25it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.22it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.17it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.29it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.23it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.11it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.23it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.37it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.42it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.48it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.33it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.18it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.20it/s] 91%|█████████ | 456/500 [00:28<00:02, 14.81it/s] 92%|█████████▏| 458/500 [00:28<00:02, 15.10it/s] 92%|█████████▏| 460/500 [00:28<00:02, 15.55it/s] 92%|█████████▏| 462/500 [00:28<00:02, 15.81it/s] 93%|█████████▎| 464/500 [00:28<00:02, 15.75it/s] 93%|█████████▎| 466/500 [00:28<00:02, 15.99it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.05it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.08it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.23it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.20it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.21it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.27it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.34it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.29it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.18it/s] 97%|█████████▋| 486/500 [00:30<00:00, 15.92it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.11it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.25it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.31it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.38it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.41it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.41it/s]100%|██████████| 500/500 [00:30<00:00, 16.52it/s]100%|██████████| 500/500 [00:30<00:00, 16.18it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  17
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:09,  6.27s/it]  1%|          | 3/500 [00:06<13:54,  1.68s/it]  1%|          | 5/500 [00:06<07:01,  1.17it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.87it/s]  2%|▏         | 11/500 [00:13<10:50,  1.33s/it]  3%|▎         | 13/500 [00:13<07:23,  1.10it/s]  3%|▎         | 15/500 [00:19<13:11,  1.63s/it]  3%|▎         | 17/500 [00:19<09:10,  1.14s/it]  4%|▍         | 19/500 [00:19<06:27,  1.24it/s]  4%|▍         | 19/500 [00:31<06:27,  1.24it/s]  4%|▍         | 21/500 [00:32<19:43,  2.47s/it]  5%|▍         | 23/500 [00:32<13:49,  1.74s/it]  5%|▌         | 25/500 [00:38<17:09,  2.17s/it]  5%|▌         | 27/500 [00:38<12:05,  1.53s/it]  6%|▌         | 29/500 [00:39<08:33,  1.09s/it]  6%|▌         | 29/500 [00:51<08:33,  1.09s/it]  6%|▌         | 31/500 [00:51<20:35,  2.63s/it]  7%|▋         | 33/500 [00:51<14:29,  1.86s/it]  7%|▋         | 35/500 [00:57<17:15,  2.23s/it]  7%|▋         | 37/500 [00:57<12:11,  1.58s/it]  8%|▊         | 39/500 [00:58<08:39,  1.13s/it]  8%|▊         | 41/500 [01:10<20:14,  2.64s/it]  9%|▊         | 43/500 [01:10<14:15,  1.87s/it]  9%|▉         | 45/500 [01:16<16:59,  2.24s/it]  9%|▉         | 47/500 [01:16<12:00,  1.59s/it] 10%|▉         | 49/500 [01:17<08:30,  1.13s/it] 10%|█         | 51/500 [01:29<19:52,  2.66s/it] 11%|█         | 53/500 [01:29<14:01,  1.88s/it] 11%|█         | 55/500 [01:35<16:47,  2.26s/it] 11%|█▏        | 57/500 [01:36<11:51,  1.61s/it] 12%|█▏        | 59/500 [01:36<08:24,  1.14s/it] 12%|█▏        | 61/500 [01:48<19:26,  2.66s/it]Epoch:  1  	Training Loss: 0.10098293423652649
Test Loss:  0.5476311445236206
Valid Loss:  0.5398269891738892
Epoch:  2  	Training Loss: 0.5929611325263977
Test Loss:  0.11093921959400177
Valid Loss:  0.11251473426818848
Epoch:  3  	Training Loss: 0.0929938554763794
Test Loss:  0.10994505882263184
Valid Loss:  0.11149197816848755
Epoch:  4  	Training Loss: 0.09208980202674866
Test Loss:  0.10979098826646805
Valid Loss:  0.11133446544408798
Epoch:  5  	Training Loss: 0.09195604920387268
Test Loss:  0.10969460755586624
Valid Loss:  0.11123505979776382
Epoch:  6  	Training Loss: 0.09186740219593048
Test Loss:  0.10969401150941849
Valid Loss:  0.11123457551002502
Epoch:  7  	Training Loss: 0.09186696261167526
Test Loss:  0.10969388484954834
Valid Loss:  0.11123450845479965
Epoch:  8  	Training Loss: 0.0918668806552887
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  9  	Training Loss: 0.0918668583035469
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  10  	Training Loss: 0.09186684340238571
Test Loss:  0.10969386994838715
Valid Loss:  0.11123449355363846
Epoch:  11  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  12  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  13  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  14  	Training Loss: 0.09186683595180511
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  15  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  17  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  18  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  19  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  20  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  22  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  23  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  24  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  25  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  27  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  28  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  29  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  30  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  32  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  33  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  34  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  35  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  37  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  38  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  39  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  40  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  42  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  43  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  44  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  45  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  47  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  48  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  49  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  50  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  52  	Training Loss: 0.09186682850122452
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
Epoch:  53  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  54  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  55  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  57  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  58  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  59  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  60  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  62  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
 13%|█▎        | 63/500 [01:48<13:42,  1.88s/it] 13%|█▎        | 65/500 [01:55<16:28,  2.27s/it] 13%|█▎        | 67/500 [01:55<11:37,  1.61s/it] 14%|█▍        | 69/500 [01:55<08:14,  1.15s/it] 14%|█▍        | 71/500 [02:07<19:00,  2.66s/it] 15%|█▍        | 73/500 [02:07<13:23,  1.88s/it] 15%|█▌        | 75/500 [02:14<15:57,  2.25s/it] 15%|█▌        | 77/500 [02:14<11:16,  1.60s/it] 16%|█▌        | 79/500 [02:14<07:59,  1.14s/it] 16%|█▌        | 81/500 [02:26<18:38,  2.67s/it] 17%|█▋        | 83/500 [02:26<13:07,  1.89s/it] 17%|█▋        | 85/500 [02:33<15:32,  2.25s/it] 17%|█▋        | 87/500 [02:33<10:58,  1.59s/it] 18%|█▊        | 89/500 [02:33<07:46,  1.14s/it] 18%|█▊        | 91/500 [02:45<18:05,  2.65s/it] 19%|█▊        | 93/500 [02:45<12:44,  1.88s/it] 19%|█▉        | 95/500 [02:52<15:08,  2.24s/it] 19%|█▉        | 97/500 [02:52<10:40,  1.59s/it] 20%|█▉        | 99/500 [02:52<07:34,  1.13s/it] 20%|██        | 101/500 [03:04<17:46,  2.67s/it] 21%|██        | 103/500 [03:05<12:31,  1.89s/it] 21%|██        | 105/500 [03:11<14:59,  2.28s/it] 21%|██▏       | 107/500 [03:11<10:34,  1.61s/it] 22%|██▏       | 109/500 [03:11<07:29,  1.15s/it] 22%|██▏       | 111/500 [03:24<17:22,  2.68s/it] 23%|██▎       | 113/500 [03:24<12:14,  1.90s/it] 23%|██▎       | 115/500 [03:30<14:31,  2.26s/it] 23%|██▎       | 117/500 [03:30<10:15,  1.61s/it] 24%|██▍       | 119/500 [03:30<07:15,  1.14s/it] 24%|██▍       | 119/500 [03:41<07:15,  1.14s/it] 24%|██▍       | 121/500 [03:43<16:46,  2.65s/it]Epoch:  63  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  64  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  65  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  67  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  68  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  69  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  70  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  72  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  73  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  74  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  75  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  77  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  78  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  79  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  80  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  82  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  83  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  84  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  85  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  87  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  88  	Training Loss: 0.09186682105064392
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
Epoch:  89  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  90  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  92  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  93  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  94  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  95  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  97  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  98  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  99  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  100  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  102  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  103  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  104  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  105  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  107  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  108  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  109  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  110  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  112  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  113  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  114  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  115  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  117  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  118  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  119  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  120  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  122  	Training Loss: 0.09186682105064392
Test Loss:   25%|██▍       | 123/500 [03:43<11:48,  1.88s/it] 25%|██▌       | 125/500 [03:49<14:08,  2.26s/it] 25%|██▌       | 127/500 [03:49<09:58,  1.61s/it] 26%|██▌       | 129/500 [03:49<07:04,  1.14s/it] 26%|██▌       | 129/500 [04:01<07:04,  1.14s/it] 26%|██▌       | 131/500 [04:02<16:25,  2.67s/it] 27%|██▋       | 133/500 [04:02<11:33,  1.89s/it] 27%|██▋       | 135/500 [04:08<13:46,  2.26s/it] 27%|██▋       | 137/500 [04:08<09:43,  1.61s/it] 28%|██▊       | 139/500 [04:09<06:55,  1.15s/it] 28%|██▊       | 139/500 [04:21<06:55,  1.15s/it] 28%|██▊       | 141/500 [04:21<16:07,  2.70s/it] 29%|██▊       | 143/500 [04:21<11:20,  1.91s/it] 29%|██▉       | 145/500 [04:28<13:27,  2.27s/it] 29%|██▉       | 147/500 [04:28<09:29,  1.61s/it] 30%|██▉       | 149/500 [04:28<06:43,  1.15s/it] 30%|███       | 151/500 [04:40<15:40,  2.69s/it] 31%|███       | 153/500 [04:41<11:01,  1.91s/it] 31%|███       | 155/500 [04:47<13:11,  2.29s/it] 31%|███▏      | 157/500 [04:47<09:18,  1.63s/it] 32%|███▏      | 159/500 [04:47<06:35,  1.16s/it] 32%|███▏      | 161/500 [05:00<15:13,  2.69s/it] 33%|███▎      | 163/500 [05:00<10:42,  1.91s/it] 33%|███▎      | 165/500 [05:06<12:44,  2.28s/it] 33%|███▎      | 167/500 [05:06<08:58,  1.62s/it] 34%|███▍      | 169/500 [05:07<06:21,  1.15s/it] 34%|███▍      | 171/500 [05:19<14:36,  2.66s/it] 35%|███▍      | 173/500 [05:19<10:16,  1.89s/it] 35%|███▌      | 175/500 [05:25<12:15,  2.26s/it] 35%|███▌      | 177/500 [05:26<08:38,  1.60s/it] 36%|███▌      | 179/500 [05:26<06:06,  1.14s/it]0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  123  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  124  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  125  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  127  	Training Loss: 0.09186682105064392
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
Epoch:  128  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  129  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  130  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  132  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  133  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  134  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  135  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  137  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  138  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  139  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  140  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  142  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  143  	Training Loss: 0.09186682850122452
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
Epoch:  144  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  145  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.09186682105064392
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
Epoch:  147  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  148  	Training Loss: 0.09186682105064392
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
Epoch:  149  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  150  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447120189667
Epoch:  152  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386249780655
Valid Loss:  0.11123448610305786
Epoch:  153  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  154  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  155  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  157  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  158  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  159  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  160  	Training Loss: 0.09186682105064392
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  162  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  163  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  164  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  165  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.09186682105064392
Test Loss:  0.10969387739896774
Valid Loss:  0.11123447865247726
Epoch:  167  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  168  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  169  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  170  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  172  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386249780655
Valid Loss:  0.11123447865247726
Epoch:  173  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  174  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  175  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  177  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  178  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  179  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  180  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
 36%|███▌      | 181/500 [05:38<14:02,  2.64s/it] 37%|███▋      | 183/500 [05:38<09:53,  1.87s/it] 37%|███▋      | 185/500 [05:44<11:45,  2.24s/it] 37%|███▋      | 187/500 [05:44<08:19,  1.60s/it] 38%|███▊      | 189/500 [05:45<05:54,  1.14s/it] 38%|███▊      | 191/500 [05:57<13:36,  2.64s/it] 39%|███▊      | 193/500 [05:57<09:34,  1.87s/it] 39%|███▉      | 195/500 [06:03<11:24,  2.24s/it] 39%|███▉      | 197/500 [06:03<08:02,  1.59s/it] 40%|███▉      | 199/500 [06:04<05:41,  1.13s/it] 40%|████      | 201/500 [06:16<13:13,  2.65s/it] 41%|████      | 203/500 [06:16<09:17,  1.88s/it] 41%|████      | 205/500 [06:22<11:05,  2.26s/it] 41%|████▏     | 207/500 [06:23<07:48,  1.60s/it] 42%|████▏     | 209/500 [06:23<05:31,  1.14s/it] 42%|████▏     | 211/500 [06:35<12:48,  2.66s/it] 43%|████▎     | 213/500 [06:35<09:00,  1.88s/it] 43%|████▎     | 215/500 [06:41<10:41,  2.25s/it] 43%|████▎     | 217/500 [06:42<07:31,  1.60s/it] 44%|████▍     | 219/500 [06:42<05:19,  1.14s/it] 44%|████▍     | 221/500 [06:54<12:26,  2.68s/it] 45%|████▍     | 223/500 [06:54<08:44,  1.89s/it] 45%|████▌     | 225/500 [07:01<10:24,  2.27s/it] 45%|████▌     | 227/500 [07:01<07:20,  1.61s/it] 46%|████▌     | 229/500 [07:01<05:11,  1.15s/it] 46%|████▌     | 231/500 [07:13<12:01,  2.68s/it] 47%|████▋     | 233/500 [07:14<08:26,  1.90s/it] 47%|████▋     | 235/500 [07:20<10:03,  2.28s/it] 47%|████▋     | 237/500 [07:20<07:05,  1.62s/it] 48%|████▊     | 239/500 [07:20<05:00,  1.15s/it]Valid Loss:  0.11123448610305786
Epoch:  182  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  183  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  184  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  185  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  187  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  188  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  189  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  190  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  192  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  193  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  194  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  195  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  197  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  198  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  199  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  200  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  202  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  203  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  204  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  205  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  207  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  208  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  209  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  210  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  212  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  213  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  214  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  215  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  217  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  218  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  219  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  220  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  222  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  223  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  224  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  225  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  227  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  228  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  229  	Training Loss: 0.09186682105064392
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
Epoch:  230  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  232  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447120189667
Epoch:  233  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  234  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  235  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  237  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  238  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  239  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  240  	Training Loss: 0.09186682105064392
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
 48%|████▊     | 239/500 [07:31<05:00,  1.15s/it] 48%|████▊     | 241/500 [07:33<11:39,  2.70s/it] 49%|████▊     | 243/500 [07:33<08:11,  1.91s/it] 49%|████▉     | 245/500 [07:39<09:42,  2.28s/it] 49%|████▉     | 247/500 [07:39<06:49,  1.62s/it] 50%|████▉     | 249/500 [07:40<04:49,  1.15s/it] 50%|████▉     | 249/500 [07:51<04:49,  1.15s/it] 50%|█████     | 251/500 [07:52<11:06,  2.68s/it] 51%|█████     | 253/500 [07:52<07:48,  1.90s/it] 51%|█████     | 255/500 [07:58<09:16,  2.27s/it] 51%|█████▏    | 257/500 [07:59<06:32,  1.61s/it] 52%|█████▏    | 259/500 [07:59<04:36,  1.15s/it] 52%|█████▏    | 259/500 [08:11<04:36,  1.15s/it] 52%|█████▏    | 261/500 [08:11<10:37,  2.67s/it] 53%|█████▎    | 263/500 [08:11<07:27,  1.89s/it] 53%|█████▎    | 265/500 [08:18<08:50,  2.26s/it] 53%|█████▎    | 267/500 [08:18<06:13,  1.60s/it] 54%|█████▍    | 269/500 [08:18<04:23,  1.14s/it] 54%|█████▍    | 271/500 [08:30<10:08,  2.66s/it] 55%|█████▍    | 273/500 [08:30<07:06,  1.88s/it] 55%|█████▌    | 275/500 [08:37<08:26,  2.25s/it] 55%|█████▌    | 277/500 [08:37<05:56,  1.60s/it] 56%|█████▌    | 279/500 [08:37<04:11,  1.14s/it] 56%|█████▌    | 281/500 [08:49<09:44,  2.67s/it] 57%|█████▋    | 283/500 [08:49<06:49,  1.89s/it] 57%|█████▋    | 285/500 [08:56<08:07,  2.27s/it] 57%|█████▋    | 287/500 [08:56<05:42,  1.61s/it] 58%|█████▊    | 289/500 [08:56<04:01,  1.15s/it] 58%|█████▊    | 291/500 [09:08<09:17,  2.67s/it] 59%|█████▊    | 293/500 [09:09<06:30,  1.89s/it] 59%|█████▉    | 295/500 [09:15<07:44,  2.27s/it] 59%|█████▉    | 297/500 [09:15<05:26,  1.61s/it] 60%|█████▉    | 299/500 [09:15<03:50,  1.15s/it]**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  242  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  243  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  244  	Training Loss: 0.09186682105064392
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
Epoch:  245  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386249780655
Valid Loss:  0.11123448610305786
Epoch:  247  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  248  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  249  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  250  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  252  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  253  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  254  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  255  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.09186682105064392
Test Loss:  0.10969387739896774
Valid Loss:  0.11123447865247726
Epoch:  257  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  258  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  259  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  260  	Training Loss: 0.09186682850122452
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  262  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  263  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  264  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  265  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  267  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  268  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  269  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  270  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  272  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  273  	Training Loss: 0.09186682850122452
Test Loss:  0.10969387739896774
Valid Loss:  0.11123447865247726
Epoch:  274  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  275  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  277  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  278  	Training Loss: 0.09186682850122452
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
Epoch:  279  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  280  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  282  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  283  	Training Loss: 0.09186682850122452
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
Epoch:  284  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  285  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  287  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  288  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  289  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  290  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  292  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  293  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  294  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  295  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  297  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  298  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  299  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
 60%|██████    | 301/500 [09:28<08:50,  2.66s/it] 61%|██████    | 303/500 [09:28<06:11,  1.89s/it] 61%|██████    | 305/500 [09:34<07:20,  2.26s/it] 61%|██████▏   | 307/500 [09:34<05:09,  1.60s/it] 62%|██████▏   | 309/500 [09:34<03:37,  1.14s/it] 62%|██████▏   | 311/500 [09:47<08:21,  2.65s/it] 63%|██████▎   | 313/500 [09:47<05:51,  1.88s/it] 63%|██████▎   | 315/500 [09:53<06:58,  2.26s/it] 63%|██████▎   | 317/500 [09:53<04:54,  1.61s/it] 64%|██████▍   | 319/500 [09:53<03:27,  1.15s/it] 64%|██████▍   | 321/500 [10:06<07:55,  2.66s/it] 65%|██████▍   | 323/500 [10:06<05:32,  1.88s/it] 65%|██████▌   | 325/500 [10:12<06:34,  2.25s/it] 65%|██████▌   | 327/500 [10:12<04:36,  1.60s/it] 66%|██████▌   | 329/500 [10:12<03:14,  1.14s/it] 66%|██████▌   | 331/500 [10:25<07:28,  2.65s/it] 67%|██████▋   | 333/500 [10:25<05:13,  1.88s/it] 67%|██████▋   | 335/500 [10:31<06:11,  2.25s/it] 67%|██████▋   | 337/500 [10:31<04:20,  1.60s/it] 68%|██████▊   | 339/500 [10:31<03:03,  1.14s/it] 68%|██████▊   | 341/500 [10:44<07:04,  2.67s/it] 69%|██████▊   | 343/500 [10:44<04:56,  1.89s/it] 69%|██████▉   | 345/500 [10:50<05:48,  2.25s/it] 69%|██████▉   | 347/500 [10:50<04:04,  1.60s/it] 70%|██████▉   | 349/500 [10:51<02:51,  1.14s/it] 70%|██████▉   | 349/500 [11:01<02:51,  1.14s/it] 70%|███████   | 351/500 [11:03<06:36,  2.66s/it] 71%|███████   | 353/500 [11:03<04:36,  1.88s/it] 71%|███████   | 355/500 [11:09<05:26,  2.25s/it] 71%|███████▏  | 357/500 [11:10<03:49,  1.60s/it]Epoch:  300  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  302  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  303  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  304  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  305  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  307  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  308  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  309  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  310  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  312  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  313  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  314  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  315  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  317  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  318  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  319  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  320  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  322  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  323  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  324  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  325  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  327  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  328  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  329  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  330  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  332  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  333  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  334  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  335  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  337  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  338  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  339  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  340  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  342  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  343  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  344  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  345  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  347  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  348  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  349  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  350  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  352  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  353  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  354  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  355  	Training Loss: 0.09186682105064392
Test Loss:  0.10969387739896774
Valid Loss:  0.11123447865247726
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  357  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  358  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
 72%|███████▏  | 359/500 [11:10<02:40,  1.14s/it] 72%|███████▏  | 359/500 [11:21<02:40,  1.14s/it] 72%|███████▏  | 361/500 [11:22<06:09,  2.66s/it] 73%|███████▎  | 363/500 [11:22<04:17,  1.88s/it] 73%|███████▎  | 365/500 [11:28<05:04,  2.26s/it] 73%|███████▎  | 367/500 [11:29<03:33,  1.60s/it] 74%|███████▍  | 369/500 [11:29<02:29,  1.14s/it] 74%|███████▍  | 369/500 [11:41<02:29,  1.14s/it] 74%|███████▍  | 371/500 [11:41<05:42,  2.66s/it] 75%|███████▍  | 373/500 [11:41<03:59,  1.88s/it] 75%|███████▌  | 375/500 [11:48<04:41,  2.25s/it] 75%|███████▌  | 377/500 [11:48<03:16,  1.60s/it] 76%|███████▌  | 379/500 [11:48<02:17,  1.14s/it] 76%|███████▌  | 381/500 [12:00<05:15,  2.66s/it] 77%|███████▋  | 383/500 [12:00<03:40,  1.88s/it] 77%|███████▋  | 385/500 [12:07<04:19,  2.26s/it] 77%|███████▋  | 387/500 [12:07<03:00,  1.60s/it] 78%|███████▊  | 389/500 [12:07<02:06,  1.14s/it] 78%|███████▊  | 391/500 [12:19<04:52,  2.68s/it] 79%|███████▊  | 393/500 [12:20<03:23,  1.90s/it] 79%|███████▉  | 395/500 [12:26<03:58,  2.27s/it] 79%|███████▉  | 397/500 [12:26<02:45,  1.61s/it] 80%|███████▉  | 399/500 [12:26<01:55,  1.15s/it] 80%|████████  | 401/500 [12:38<04:21,  2.64s/it] 81%|████████  | 403/500 [12:39<03:01,  1.87s/it] 81%|████████  | 405/500 [12:45<03:33,  2.25s/it] 81%|████████▏ | 407/500 [12:45<02:28,  1.59s/it] 82%|████████▏ | 409/500 [12:45<01:43,  1.13s/it] 82%|████████▏ | 411/500 [12:57<03:56,  2.65s/it] 83%|████████▎ | 413/500 [12:58<02:43,  1.88s/it] 83%|████████▎ | 415/500 [13:04<03:11,  2.25s/it] 83%|████████▎ | 417/500 [13:04<02:12,  1.60s/it]Epoch:  359  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  360  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  362  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  363  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  364  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  365  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  367  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  368  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  369  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  370  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  372  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  373  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  374  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  375  	Training Loss: 0.09186682105064392
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.09186682850122452
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
Epoch:  377  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  378  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  379  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  380  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  382  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  383  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  384  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  385  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  387  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  388  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  389  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  390  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  392  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  393  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  394  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  395  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  397  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  398  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  399  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  400  	Training Loss: 0.09186682105064392
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  402  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  403  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  404  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  405  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  407  	Training Loss: 0.09186682105064392
Test Loss:  0.10969387739896774
Valid Loss:  0.11123447865247726
Epoch:  408  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  409  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  410  	Training Loss: 0.09186682850122452
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  412  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  413  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  414  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  415  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  417  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
 84%|████████▍ | 419/500 [13:04<01:32,  1.14s/it] 84%|████████▍ | 421/500 [13:16<03:29,  2.66s/it] 85%|████████▍ | 423/500 [13:17<02:24,  1.88s/it] 85%|████████▌ | 425/500 [13:23<02:48,  2.25s/it] 85%|████████▌ | 427/500 [13:23<01:56,  1.59s/it] 86%|████████▌ | 429/500 [13:23<01:20,  1.14s/it] 86%|████████▌ | 431/500 [13:35<03:03,  2.65s/it] 87%|████████▋ | 433/500 [13:36<02:05,  1.88s/it] 87%|████████▋ | 435/500 [13:42<02:26,  2.25s/it] 87%|████████▋ | 437/500 [13:42<01:40,  1.60s/it] 88%|████████▊ | 439/500 [13:42<01:09,  1.14s/it] 88%|████████▊ | 441/500 [13:55<02:36,  2.66s/it] 89%|████████▊ | 443/500 [13:55<01:47,  1.88s/it] 89%|████████▉ | 445/500 [14:01<02:04,  2.26s/it] 89%|████████▉ | 447/500 [14:01<01:25,  1.61s/it] 90%|████████▉ | 449/500 [14:01<00:58,  1.15s/it] 90%|█████████ | 451/500 [14:14<02:10,  2.66s/it] 91%|█████████ | 453/500 [14:14<01:28,  1.88s/it] 91%|█████████ | 455/500 [14:20<01:42,  2.27s/it] 91%|█████████▏| 457/500 [14:20<01:09,  1.61s/it] 92%|█████████▏| 459/500 [14:20<00:47,  1.15s/it] 92%|█████████▏| 459/500 [14:31<00:47,  1.15s/it] 92%|█████████▏| 461/500 [14:33<01:43,  2.66s/it] 93%|█████████▎| 463/500 [14:33<01:09,  1.89s/it] 93%|█████████▎| 465/500 [14:39<01:19,  2.26s/it] 93%|█████████▎| 467/500 [14:39<00:52,  1.60s/it] 94%|█████████▍| 469/500 [14:39<00:35,  1.14s/it] 94%|█████████▍| 469/500 [14:51<00:35,  1.14s/it] 94%|█████████▍| 471/500 [14:52<01:17,  2.66s/it] 95%|█████████▍| 473/500 [14:52<00:50,  1.88s/it] 95%|█████████▌| 475/500 [14:58<00:56,  2.25s/it]Epoch:  418  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  419  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  420  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  422  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  423  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  424  	Training Loss: 0.09186682850122452
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
Epoch:  425  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  427  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  428  	Training Loss: 0.09186682105064392
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
Epoch:  429  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  430  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  432  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  433  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  434  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  435  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  437  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  438  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  439  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  440  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  442  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  443  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  444  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  445  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  447  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  448  	Training Loss: 0.09186682105064392
Test Loss:  0.10969387739896774
Valid Loss:  0.11123447865247726
Epoch:  449  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  450  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  452  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  453  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  454  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  455  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  457  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  458  	Training Loss: 0.09186682105064392
Test Loss:  0.10969387739896774
Valid Loss:  0.11123447865247726
Epoch:  459  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  460  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  462  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  463  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  464  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  465  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  467  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  468  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  469  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  470  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  472  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123447865247726
Epoch:  473  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  474  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  475  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.09186682105064392
Test Loss:  0.10969387739896774
Valid Loss:  0.11123448610305786
 95%|█████████▌| 477/500 [14:58<00:36,  1.60s/it] 96%|█████████▌| 479/500 [14:59<00:23,  1.14s/it] 96%|█████████▌| 481/500 [15:11<00:50,  2.63s/it] 97%|█████████▋| 483/500 [15:11<00:31,  1.86s/it] 97%|█████████▋| 485/500 [15:17<00:33,  2.24s/it] 97%|█████████▋| 487/500 [15:17<00:20,  1.59s/it] 98%|█████████▊| 489/500 [15:17<00:12,  1.13s/it] 98%|█████████▊| 491/500 [15:30<00:23,  2.66s/it] 99%|█████████▊| 493/500 [15:30<00:13,  1.88s/it] 99%|█████████▉| 495/500 [15:36<00:11,  2.26s/it] 99%|█████████▉| 497/500 [15:36<00:04,  1.61s/it]100%|█████████▉| 499/500 [15:37<00:01,  1.14s/it]100%|██████████| 500/500 [15:43<00:00,  1.89s/it]
Epoch:  477  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  478  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  479  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  480  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  482  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  483  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  484  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  485  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  487  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  488  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  489  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  490  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  492  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  493  	Training Loss: 0.09186682850122452
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  494  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  495  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  497  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  498  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  499  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
Epoch:  500  	Training Loss: 0.09186682105064392
Test Loss:  0.10969386994838715
Valid Loss:  0.11123448610305786
**************************************************learning rate decay**************************************************
seed is  17
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:00,  6.13s/it]  1%|          | 3/500 [00:06<13:36,  1.64s/it]  1%|          | 5/500 [00:06<06:51,  1.20it/s]  1%|▏         | 7/500 [00:06<04:09,  1.97it/s]  2%|▏         | 9/500 [00:06<02:47,  2.93it/s]  2%|▏         | 11/500 [00:13<10:51,  1.33s/it]  3%|▎         | 13/500 [00:13<07:25,  1.09it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:46,  2.88it/s]  4%|▍         | 21/500 [00:19<09:41,  1.21s/it]  5%|▍         | 23/500 [00:20<06:52,  1.16it/s]  5%|▌         | 25/500 [00:20<04:55,  1.61it/s]  5%|▌         | 27/500 [00:20<03:34,  2.20it/s]  6%|▌         | 29/500 [00:20<02:39,  2.96it/s]  6%|▌         | 31/500 [00:26<09:12,  1.18s/it]  7%|▋         | 33/500 [00:26<06:34,  1.18it/s]  7%|▋         | 35/500 [00:27<04:43,  1.64it/s]  7%|▋         | 37/500 [00:27<03:26,  2.24it/s]  8%|▊         | 39/500 [00:27<02:33,  3.01it/s]  8%|▊         | 41/500 [00:33<09:05,  1.19s/it]  9%|▊         | 43/500 [00:33<06:29,  1.17it/s]  9%|▉         | 45/500 [00:33<04:40,  1.62it/s]  9%|▉         | 47/500 [00:34<03:24,  2.21it/s] 10%|▉         | 49/500 [00:34<02:32,  2.96it/s] 10%|█         | 51/500 [00:40<09:03,  1.21s/it] 11%|█         | 53/500 [00:40<06:28,  1.15it/s] 11%|█         | 55/500 [00:40<04:39,  1.59it/s] 11%|█▏        | 57/500 [00:41<03:23,  2.18it/s] 12%|█▏        | 59/500 [00:41<02:30,  2.93it/s] 12%|█▏        | 61/500 [00:47<08:34,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:07,  1.19it/s] 13%|█▎        | 65/500 [00:47<04:24,  1.64it/s] 13%|█▎        | 67/500 [00:47<03:13,  2.24it/s] 14%|█▍        | 69/500 [00:48<02:23,  3.01it/s]Epoch:  1  	Training Loss: 0.10098293423652649
Test Loss:  0.03568873554468155
Valid Loss:  0.032376181334257126
Epoch:  2  	Training Loss: 0.04644280672073364
Test Loss:  0.029669463634490967
Valid Loss:  0.029013704508543015
Epoch:  3  	Training Loss: 0.026183851063251495
Test Loss:  0.02273382619023323
Valid Loss:  0.02158702164888382
Epoch:  4  	Training Loss: 0.022336004301905632
Test Loss:  0.018791446462273598
Valid Loss:  0.017592554911971092
Epoch:  5  	Training Loss: 0.019383516162633896
Test Loss:  0.016005799174308777
Valid Loss:  0.014952359721064568
Epoch:  6  	Training Loss: 0.016582753509283066
Test Loss:  0.01384059339761734
Valid Loss:  0.012913936749100685
Epoch:  7  	Training Loss: 0.014484096318483353
Test Loss:  0.012467421591281891
Valid Loss:  0.01163469534367323
Epoch:  8  	Training Loss: 0.01312917098402977
Test Loss:  0.011287372559309006
Valid Loss:  0.010552603751420975
Epoch:  9  	Training Loss: 0.011900058947503567
Test Loss:  0.01003660261631012
Valid Loss:  0.009352510794997215
Epoch:  10  	Training Loss: 0.010809174738824368
Test Loss:  0.009300152771174908
Valid Loss:  0.008739849552512169
Epoch:  11  	Training Loss: 0.00986091885715723
Test Loss:  0.008062077686190605
Valid Loss:  0.0074823955073952675
Epoch:  12  	Training Loss: 0.009028268977999687
Test Loss:  0.0069465055130422115
Valid Loss:  0.006592952646315098
Epoch:  13  	Training Loss: 0.00745787750929594
Test Loss:  0.005746666342020035
Valid Loss:  0.005462288856506348
Epoch:  14  	Training Loss: 0.006064244545996189
Test Loss:  0.005069574806839228
Valid Loss:  0.004778683185577393
Epoch:  15  	Training Loss: 0.005438702646642923
Test Loss:  0.004574738908559084
Valid Loss:  0.004285084083676338
Epoch:  16  	Training Loss: 0.005066915415227413
Test Loss:  0.004262753762304783
Valid Loss:  0.004008231684565544
Epoch:  17  	Training Loss: 0.004807265941053629
Test Loss:  0.003977688029408455
Valid Loss:  0.0037519519682973623
Epoch:  18  	Training Loss: 0.004600691609084606
Test Loss:  0.0037741614505648613
Valid Loss:  0.003588475054129958
Epoch:  19  	Training Loss: 0.0044219642877578735
Test Loss:  0.0035798652097582817
Valid Loss:  0.003415830433368683
Epoch:  20  	Training Loss: 0.004263508133590221
Test Loss:  0.003431163728237152
Valid Loss:  0.0032940644305199385
Epoch:  21  	Training Loss: 0.004120158031582832
Test Loss:  0.003282960271462798
Valid Loss:  0.003163586836308241
Epoch:  22  	Training Loss: 0.003989792428910732
Test Loss:  0.002935892902314663
Valid Loss:  0.0028962704818695784
Epoch:  23  	Training Loss: 0.0035718390718102455
Test Loss:  0.002453562570735812
Valid Loss:  0.0023829611018300056
Epoch:  24  	Training Loss: 0.003239572048187256
Test Loss:  0.0023433419410139322
Valid Loss:  0.0023715358693152666
Epoch:  25  	Training Loss: 0.0029927913565188646
Test Loss:  0.002052060328423977
Valid Loss:  0.0020582841243594885
Epoch:  26  	Training Loss: 0.0027883420698344707
Test Loss:  0.001986087765544653
Valid Loss:  0.0020636534318327904
Epoch:  27  	Training Loss: 0.0026183617301285267
Test Loss:  0.0017946911975741386
Valid Loss:  0.001857710536569357
Epoch:  28  	Training Loss: 0.00247660162858665
Test Loss:  0.0017504498828202486
Valid Loss:  0.0018629815895110369
Epoch:  29  	Training Loss: 0.0023544500581920147
Test Loss:  0.001618687529116869
Valid Loss:  0.0017130895284935832
Epoch:  30  	Training Loss: 0.00224256026558578
Test Loss:  0.0015784212155267596
Valid Loss:  0.0017013242468237877
Epoch:  31  	Training Loss: 0.0021416922099888325
Test Loss:  0.0014803779777139425
Valid Loss:  0.0015884600579738617
Epoch:  32  	Training Loss: 0.0020503783598542213
Test Loss:  0.0013503546360880136
Valid Loss:  0.0014552314532920718
Epoch:  33  	Training Loss: 0.0018920351285487413
Test Loss:  0.001256522606126964
Valid Loss:  0.001363022136501968
Epoch:  34  	Training Loss: 0.0017732065171003342
Test Loss:  0.001179457176476717
Valid Loss:  0.0012836450478062034
Epoch:  35  	Training Loss: 0.0016745002940297127
Test Loss:  0.001118830987252295
Valid Loss:  0.001224995357915759
Epoch:  36  	Training Loss: 0.0015901671722531319
Test Loss:  0.001067384728230536
Valid Loss:  0.0011749445693567395
Epoch:  37  	Training Loss: 0.001517337397672236
Test Loss:  0.0010209549218416214
Valid Loss:  0.001133341109380126
Epoch:  38  	Training Loss: 0.0014528590254485607
Test Loss:  0.0009794803336262703
Valid Loss:  0.0010972830932587385
Epoch:  39  	Training Loss: 0.001395748695358634
Test Loss:  0.0009425220196135342
Valid Loss:  0.0010675754165276885
Epoch:  40  	Training Loss: 0.0013466320233419538
Test Loss:  0.0009061008458957076
Valid Loss:  0.001037725480273366
Epoch:  41  	Training Loss: 0.0013022520579397678
Test Loss:  0.0008763073128648102
Valid Loss:  0.0010145088890567422
Epoch:  42  	Training Loss: 0.001262458972632885
Test Loss:  0.0008534326334483922
Valid Loss:  0.0010140497470274568
Epoch:  43  	Training Loss: 0.001189276808872819
Test Loss:  0.0007992791943252087
Valid Loss:  0.0009649799903854728
Epoch:  44  	Training Loss: 0.0011414726031944156
Test Loss:  0.000784025527536869
Valid Loss:  0.0009629977867007256
Epoch:  45  	Training Loss: 0.0011039131786674261
Test Loss:  0.000741995987482369
Valid Loss:  0.0009246896952390671
Epoch:  46  	Training Loss: 0.0010682132560759783
Test Loss:  0.0007306888001039624
Valid Loss:  0.0009252784075215459
Epoch:  47  	Training Loss: 0.001032799482345581
Test Loss:  0.0006938262959010899
Valid Loss:  0.0008904710994102061
Epoch:  48  	Training Loss: 0.001001151860691607
Test Loss:  0.0006804167060181499
Valid Loss:  0.0008853088365867734
Epoch:  49  	Training Loss: 0.0009718555957078934
Test Loss:  0.0006528306985273957
Valid Loss:  0.0008603984024375677
Epoch:  50  	Training Loss: 0.0009464965551160276
Test Loss:  0.0006412687944248319
Valid Loss:  0.0008556381217204034
Epoch:  51  	Training Loss: 0.0009240885265171528
Test Loss:  0.0006189941195771098
Valid Loss:  0.0008377166232094169
Epoch:  52  	Training Loss: 0.0009045064798556268
Test Loss:  0.0006126626394689083
Valid Loss:  0.000839408952742815
Epoch:  53  	Training Loss: 0.0008889406453818083
Test Loss:  0.000597434991504997
Valid Loss:  0.0008300525951199234
Epoch:  54  	Training Loss: 0.0008750712731853127
Test Loss:  0.0005912567721679807
Valid Loss:  0.0008295660372823477
Epoch:  55  	Training Loss: 0.0008625132031738758
Test Loss:  0.0005796057521365583
Valid Loss:  0.0008219204610213637
Epoch:  56  	Training Loss: 0.0008514737128280103
Test Loss:  0.0005753720761276782
Valid Loss:  0.0008227295475080609
Epoch:  57  	Training Loss: 0.0008419075747951865
Test Loss:  0.0005642203614115715
Valid Loss:  0.0008122501312755048
Epoch:  58  	Training Loss: 0.0008355562458746135
Test Loss:  0.000566254137083888
Valid Loss:  0.0008208380895666778
Epoch:  59  	Training Loss: 0.000826212577521801
Test Loss:  0.0005510564078576863
Valid Loss:  0.0008072592318058014
Epoch:  60  	Training Loss: 0.0008179374854080379
Test Loss:  0.0005511856870725751
Valid Loss:  0.0008131506037898362
Epoch:  61  	Training Loss: 0.0008105558226816356
Test Loss:  0.0005399190122261643
Valid Loss:  0.0008028788724914193
Epoch:  62  	Training Loss: 0.0008045324357226491
Test Loss:  0.0005198088474571705
Valid Loss:  0.0007891173008829355
Epoch:  63  	Training Loss: 0.0007695106323808432
Test Loss:  0.0004939116188324988
Valid Loss:  0.0007681379793211818
Epoch:  64  	Training Loss: 0.0007386795477941632
Test Loss:  0.0004812141414731741
Valid Loss:  0.0007615075446665287
Epoch:  65  	Training Loss: 0.0007153223850764334
Test Loss:  0.00046662092790938914
Valid Loss:  0.0007472001016139984
Epoch:  66  	Training Loss: 0.0007005840889178216
Test Loss:  0.0004629000904969871
Valid Loss:  0.000748968857806176
Epoch:  67  	Training Loss: 0.0006910391384735703
Test Loss:  0.0004513450840022415
Valid Loss:  0.0007345678750425577
Epoch:  68  	Training Loss: 0.0006843875744380057
Test Loss:  0.00045319541823118925
Valid Loss:  0.0007397773442789912
Epoch:  69  	Training Loss: 0.0006799314869567752
Test Loss:  0.00044357162551023066
Valid Loss:  0.0007240972481667995
Epoch:  70  	Training Loss: 0.0006774942739866674
Test Loss:  0.0004512122250162065
 14%|█▍        | 71/500 [00:54<08:25,  1.18s/it] 15%|█▍        | 73/500 [00:54<06:01,  1.18it/s] 15%|█▌        | 75/500 [00:54<04:19,  1.63it/s] 15%|█▌        | 77/500 [00:54<03:09,  2.23it/s] 16%|█▌        | 79/500 [00:54<02:20,  3.00it/s] 16%|█▌        | 81/500 [01:01<08:14,  1.18s/it] 17%|█▋        | 83/500 [01:01<05:53,  1.18it/s] 17%|█▋        | 85/500 [01:01<04:14,  1.63it/s] 17%|█▋        | 87/500 [01:01<03:05,  2.23it/s] 18%|█▊        | 89/500 [01:01<02:17,  2.98it/s] 18%|█▊        | 91/500 [01:08<08:04,  1.18s/it] 19%|█▊        | 93/500 [01:08<05:46,  1.18it/s] 19%|█▉        | 95/500 [01:08<04:09,  1.62it/s] 19%|█▉        | 97/500 [01:08<03:01,  2.22it/s] 20%|█▉        | 99/500 [01:08<02:14,  2.98it/s] 20%|██        | 101/500 [01:14<07:50,  1.18s/it] 21%|██        | 103/500 [01:15<05:36,  1.18it/s] 21%|██        | 105/500 [01:15<04:01,  1.63it/s] 21%|██▏       | 107/500 [01:15<02:56,  2.23it/s] 22%|██▏       | 109/500 [01:15<02:10,  3.01it/s] 22%|██▏       | 111/500 [01:27<13:43,  2.12s/it] 23%|██▎       | 113/500 [01:28<09:41,  1.50s/it] 23%|██▎       | 115/500 [01:28<06:52,  1.07s/it] 23%|██▎       | 117/500 [01:28<04:54,  1.30it/s] 24%|██▍       | 119/500 [01:28<03:32,  1.79it/s] 24%|██▍       | 121/500 [01:34<08:22,  1.33s/it] 25%|██▍       | 123/500 [01:34<05:57,  1.05it/s] 25%|██▌       | 125/500 [01:35<04:17,  1.46it/s] 25%|██▌       | 127/500 [01:35<03:06,  2.00it/s] 26%|██▌       | 129/500 [01:35<02:17,  2.70it/s] 26%|██▌       | 131/500 [01:41<07:20,  1.19s/it] 27%|██▋       | 133/500 [01:41<05:14,  1.17it/s] 27%|██▋       | 135/500 [01:41<03:45,  1.62it/s] 27%|██▋       | 137/500 [01:41<02:44,  2.21it/s]Valid Loss:  0.0007363909389823675
Epoch:  71  	Training Loss: 0.0006767025915905833
Test Loss:  0.00044097969657741487
Valid Loss:  0.0007182109402492642
Epoch:  72  	Training Loss: 0.0006773367058485746
Test Loss:  0.00044456805335357785
Valid Loss:  0.0007216868689283729
Epoch:  73  	Training Loss: 0.000665998668409884
Test Loss:  0.0004226500750519335
Valid Loss:  0.0006951112300157547
Epoch:  74  	Training Loss: 0.000661080121062696
Test Loss:  0.00043333848589099944
Valid Loss:  0.0007080098148435354
Epoch:  75  	Training Loss: 0.0006557332235388458
Test Loss:  0.0004158198134973645
Valid Loss:  0.0006871935911476612
Epoch:  76  	Training Loss: 0.0006520408205688
Test Loss:  0.0004250874917488545
Valid Loss:  0.0006986051448620856
Epoch:  77  	Training Loss: 0.0006478497525677085
Test Loss:  0.0004105623811483383
Valid Loss:  0.0006817540852352977
Epoch:  78  	Training Loss: 0.0006442997837439179
Test Loss:  0.00041774980491027236
Valid Loss:  0.0006906862836331129
Epoch:  79  	Training Loss: 0.0006409766501747072
Test Loss:  0.00040632946183905005
Valid Loss:  0.0006773228524252772
Epoch:  80  	Training Loss: 0.0006379872211255133
Test Loss:  0.000411587388953194
Valid Loss:  0.0006839990383014083
Epoch:  81  	Training Loss: 0.0006349806790240109
Test Loss:  0.00040243612602353096
Valid Loss:  0.0006732029723934829
Epoch:  82  	Training Loss: 0.0006323004490695894
Test Loss:  0.0004019522457383573
Valid Loss:  0.0006764419376850128
Epoch:  83  	Training Loss: 0.0006273931358009577
Test Loss:  0.0003933804400730878
Valid Loss:  0.0006657554768025875
Epoch:  84  	Training Loss: 0.0006229919381439686
Test Loss:  0.00039364444091916084
Valid Loss:  0.0006697647040709853
Epoch:  85  	Training Loss: 0.0006188210099935532
Test Loss:  0.0003853218222502619
Valid Loss:  0.0006592159625142813
Epoch:  86  	Training Loss: 0.0006148553802631795
Test Loss:  0.00038589019095525146
Valid Loss:  0.000663894519675523
Epoch:  87  	Training Loss: 0.0006111509865149856
Test Loss:  0.0003777301753871143
Valid Loss:  0.0006530229584313929
Epoch:  88  	Training Loss: 0.0006077239522710443
Test Loss:  0.0003792982315644622
Valid Loss:  0.000659129407722503
Epoch:  89  	Training Loss: 0.0006046529160812497
Test Loss:  0.0003713014302775264
Valid Loss:  0.0006476856069639325
Epoch:  90  	Training Loss: 0.0006018035346642137
Test Loss:  0.00037347260513342917
Valid Loss:  0.0006550037651322782
Epoch:  91  	Training Loss: 0.00059899827465415
Test Loss:  0.0003653742605820298
Valid Loss:  0.0006428853375837207
Epoch:  92  	Training Loss: 0.0005962635623291135
Test Loss:  0.0003644463140517473
Valid Loss:  0.0006440095603466034
Epoch:  93  	Training Loss: 0.0005918329115957022
Test Loss:  0.00035910194856114686
Valid Loss:  0.0006376689416356385
Epoch:  94  	Training Loss: 0.0005886873113922775
Test Loss:  0.0003582158242352307
Valid Loss:  0.0006380279664881527
Epoch:  95  	Training Loss: 0.0005858276272192597
Test Loss:  0.00035449088318273425
Valid Loss:  0.0006339397514238954
Epoch:  96  	Training Loss: 0.000583507411647588
Test Loss:  0.0003535904106684029
Valid Loss:  0.0006338462699204683
Epoch:  97  	Training Loss: 0.0005811385344713926
Test Loss:  0.00035038861096836627
Valid Loss:  0.000630547059699893
Epoch:  98  	Training Loss: 0.0005789664573967457
Test Loss:  0.0003495891869533807
Valid Loss:  0.0006305925780907273
Epoch:  99  	Training Loss: 0.0005769373383373022
Test Loss:  0.0003464169567450881
Valid Loss:  0.0006272083846852183
Epoch:  100  	Training Loss: 0.0005749750998802483
Test Loss:  0.00034581171348690987
Valid Loss:  0.0006275050109252334
Epoch:  101  	Training Loss: 0.0005730428965762258
Test Loss:  0.0003428794152569026
Valid Loss:  0.0006241626106202602
Epoch:  102  	Training Loss: 0.0005712432321161032
Test Loss:  0.00034465454518795013
Valid Loss:  0.0006285023409873247
Epoch:  103  	Training Loss: 0.000567425275221467
Test Loss:  0.0003409668570384383
Valid Loss:  0.0006221706862561405
Epoch:  104  	Training Loss: 0.0005646899808198214
Test Loss:  0.0003442381857894361
Valid Loss:  0.0006275045452639461
Epoch:  105  	Training Loss: 0.0005625962512567639
Test Loss:  0.00033963131136260927
Valid Loss:  0.0006185100646689534
Epoch:  106  	Training Loss: 0.0005610756925307214
Test Loss:  0.0003448028292041272
Valid Loss:  0.0006266376003623009
Epoch:  107  	Training Loss: 0.0005599151481874287
Test Loss:  0.0003387111355550587
Valid Loss:  0.0006145612569525838
Epoch:  108  	Training Loss: 0.0005593735259026289
Test Loss:  0.00034766277531161904
Valid Loss:  0.0006279154913499951
Epoch:  109  	Training Loss: 0.0005595393013209105
Test Loss:  0.0003395983367227018
Valid Loss:  0.0006118690362200141
Epoch:  110  	Training Loss: 0.0005607721395790577
Test Loss:  0.0003551792469806969
Valid Loss:  0.0006337506929412484
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.0005635010311380029
Test Loss:  0.00033902813447639346
Valid Loss:  0.0006161798955872655
Epoch:  112  	Training Loss: 0.0005473271594382823
Test Loss:  0.0003328364691697061
Valid Loss:  0.0006082561449147761
Epoch:  113  	Training Loss: 0.0005429438897408545
Test Loss:  0.00033033330691978335
Valid Loss:  0.0006051236996427178
Epoch:  114  	Training Loss: 0.0005411729216575623
Test Loss:  0.0003285457787569612
Valid Loss:  0.0006030952790752053
Epoch:  115  	Training Loss: 0.0005397357163019478
Test Loss:  0.000326977256918326
Valid Loss:  0.0006014343816787004
Epoch:  116  	Training Loss: 0.0005383781972341239
Test Loss:  0.0003255265182815492
Valid Loss:  0.0005999412387609482
Epoch:  117  	Training Loss: 0.0005370773724280298
Test Loss:  0.00032416690373793244
Valid Loss:  0.000598515325691551
Epoch:  118  	Training Loss: 0.0005358085036277771
Test Loss:  0.00032287821522913873
Valid Loss:  0.0005971634527668357
Epoch:  119  	Training Loss: 0.0005345828831195831
Test Loss:  0.00032160806586034596
Valid Loss:  0.0005958310794085264
Epoch:  120  	Training Loss: 0.0005333813605830073
Test Loss:  0.00032033241586759686
Valid Loss:  0.000594483339227736
Epoch:  121  	Training Loss: 0.000532207079231739
Test Loss:  0.0003191062423866242
Valid Loss:  0.0005931961932219565
Epoch:  122  	Training Loss: 0.0005310517735779285
Test Loss:  0.000318813428748399
Valid Loss:  0.0005925059085711837
Epoch:  123  	Training Loss: 0.0005302379722706974
Test Loss:  0.0003183384542353451
Valid Loss:  0.0005914272041991353
Epoch:  124  	Training Loss: 0.0005295040900819004
Test Loss:  0.0003178533515892923
Valid Loss:  0.0005903209093958139
Epoch:  125  	Training Loss: 0.0005287836538627744
Test Loss:  0.00031737860990688205
Valid Loss:  0.0005892351036891341
Epoch:  126  	Training Loss: 0.0005280711920931935
Test Loss:  0.0003169167321175337
Valid Loss:  0.0005881779361516237
Epoch:  127  	Training Loss: 0.0005273682181723416
Test Loss:  0.00031648093136027455
Valid Loss:  0.000587153248488903
Epoch:  128  	Training Loss: 0.0005266816588118672
Test Loss:  0.0003160579362884164
Valid Loss:  0.0005861247191205621
Epoch:  129  	Training Loss: 0.0005260163452476263
Test Loss:  0.0003156572347506881
Valid Loss:  0.0005851410678587854
Epoch:  130  	Training Loss: 0.0005253564449958503
Test Loss:  0.00031527370447292924
Valid Loss:  0.0005841791862621903
Epoch:  131  	Training Loss: 0.0005247107474133372
Test Loss:  0.00031487992964684963
Valid Loss:  0.0005831958260387182
Epoch:  132  	Training Loss: 0.0005240825121290982
Test Loss:  0.00031459651654586196
Valid Loss:  0.0005825901171192527
Epoch:  133  	Training Loss: 0.0005232651019468904
Test Loss:  0.00031419791048392653
Valid Loss:  0.0005817720666527748
Epoch:  134  	Training Loss: 0.000522472953889519
Test Loss:  0.0003137534949928522
Valid Loss:  0.0005808917339891195
Epoch:  135  	Training Loss: 0.0005216894205659628
Test Loss:  0.00031329458579421043
Valid Loss:  0.0005800031358376145
Epoch:  136  	Training Loss: 0.0005209119990468025
Test Loss:  0.00031281838892027736
Valid Loss:  0.0005790800205431879
Epoch:  137  	Training Loss: 0.0005201503518037498
Test Loss:  0.0003123432397842407
Valid Loss:  0.000578156323172152
 28%|██▊       | 139/500 [01:42<02:01,  2.97it/s] 28%|██▊       | 141/500 [01:48<07:04,  1.18s/it] 29%|██▊       | 143/500 [01:48<05:03,  1.18it/s] 29%|██▉       | 145/500 [01:48<03:37,  1.63it/s] 29%|██▉       | 147/500 [01:48<02:38,  2.23it/s] 30%|██▉       | 149/500 [01:48<01:57,  2.99it/s] 30%|███       | 151/500 [01:55<06:54,  1.19s/it] 31%|███       | 153/500 [01:55<04:56,  1.17it/s] 31%|███       | 155/500 [01:55<03:35,  1.60it/s] 31%|███▏      | 157/500 [01:55<02:37,  2.18it/s] 32%|███▏      | 159/500 [01:55<01:56,  2.94it/s] 32%|███▏      | 161/500 [02:02<06:40,  1.18s/it] 33%|███▎      | 163/500 [02:02<04:45,  1.18it/s] 33%|███▎      | 165/500 [02:02<03:25,  1.63it/s] 33%|███▎      | 167/500 [02:02<02:29,  2.23it/s] 34%|███▍      | 169/500 [02:02<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:09<06:31,  1.19s/it] 35%|███▍      | 173/500 [02:09<04:38,  1.17it/s] 35%|███▌      | 175/500 [02:09<03:20,  1.62it/s] 35%|███▌      | 177/500 [02:09<02:25,  2.22it/s] 36%|███▌      | 179/500 [02:09<01:47,  2.98it/s] 36%|███▌      | 181/500 [02:15<06:20,  1.19s/it] 37%|███▋      | 183/500 [02:16<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:16<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:16<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:16<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:22<06:02,  1.17s/it] 39%|███▊      | 193/500 [02:22<04:18,  1.19it/s] 39%|███▉      | 195/500 [02:22<03:05,  1.64it/s] 39%|███▉      | 197/500 [02:23<02:14,  2.25it/s] 40%|███▉      | 199/500 [02:23<01:39,  3.01it/s] 40%|████      | 201/500 [02:29<05:52,  1.18s/it] 41%|████      | 203/500 [02:29<04:11,  1.18it/s]Epoch:  138  	Training Loss: 0.0005193926626816392
Test Loss:  0.0003118673921562731
Valid Loss:  0.0005772312288172543
Epoch:  139  	Training Loss: 0.0005186408525332808
Test Loss:  0.00031138997292146087
Valid Loss:  0.000576280988752842
Epoch:  140  	Training Loss: 0.0005179049330763519
Test Loss:  0.0003109401441179216
Valid Loss:  0.0005753397708758712
Epoch:  141  	Training Loss: 0.000517175649292767
Test Loss:  0.0003104926727246493
Valid Loss:  0.0005744016962125897
Epoch:  142  	Training Loss: 0.0005164506146684289
Test Loss:  0.0003079994930885732
Valid Loss:  0.0005718963220715523
Epoch:  143  	Training Loss: 0.000513420149218291
Test Loss:  0.00030559307197108865
Valid Loss:  0.0005696273292414844
Epoch:  144  	Training Loss: 0.0005105105228722095
Test Loss:  0.0003033268731087446
Valid Loss:  0.0005674958229064941
Epoch:  145  	Training Loss: 0.0005077557871118188
Test Loss:  0.0003011625958606601
Valid Loss:  0.0005654436536133289
Epoch:  146  	Training Loss: 0.0005051313200965524
Test Loss:  0.0002990590874105692
Valid Loss:  0.0005634751869365573
Epoch:  147  	Training Loss: 0.0005026601138524711
Test Loss:  0.0002970671630464494
Valid Loss:  0.0005616166745312512
Epoch:  148  	Training Loss: 0.0005003261612728238
Test Loss:  0.0002952489594463259
Valid Loss:  0.0005598440766334534
Epoch:  149  	Training Loss: 0.0004982082173228264
Test Loss:  0.0002935360244009644
Valid Loss:  0.0005581380682997406
Epoch:  150  	Training Loss: 0.0004962746752426028
Test Loss:  0.0002919841790571809
Valid Loss:  0.0005564811872318387
Epoch:  151  	Training Loss: 0.0004945185501128435
Test Loss:  0.0002905119035858661
Valid Loss:  0.0005549285560846329
Epoch:  152  	Training Loss: 0.0004928321577608585
Test Loss:  0.0002894129720516503
Valid Loss:  0.0005538428667932749
Epoch:  153  	Training Loss: 0.0004911554860882461
Test Loss:  0.0002883010311052203
Valid Loss:  0.0005528185283765197
Epoch:  154  	Training Loss: 0.0004895686870440841
Test Loss:  0.0002871877222787589
Valid Loss:  0.0005517986137419939
Epoch:  155  	Training Loss: 0.0004880460037384182
Test Loss:  0.00028610375011339784
Valid Loss:  0.0005507722962647676
Epoch:  156  	Training Loss: 0.00048660091124475
Test Loss:  0.00028508342802524567
Valid Loss:  0.0005497360252775252
Epoch:  157  	Training Loss: 0.00048524339217692614
Test Loss:  0.0002841103996615857
Valid Loss:  0.0005487017915584147
Epoch:  158  	Training Loss: 0.0004839361645281315
Test Loss:  0.00028317756368778646
Valid Loss:  0.000547662959434092
Epoch:  159  	Training Loss: 0.0004826750955544412
Test Loss:  0.0002822901587933302
Valid Loss:  0.0005466187139973044
Epoch:  160  	Training Loss: 0.00048144860193133354
Test Loss:  0.0002814368926919997
Valid Loss:  0.0005455794744193554
Epoch:  161  	Training Loss: 0.00048024317948147655
Test Loss:  0.00028059695614501834
Valid Loss:  0.0005445507704280317
Epoch:  162  	Training Loss: 0.0004790591774508357
Test Loss:  0.00027720347861759365
Valid Loss:  0.0005404680268839002
Epoch:  163  	Training Loss: 0.0004749148793052882
Test Loss:  0.00027526961639523506
Valid Loss:  0.0005376404151320457
Epoch:  164  	Training Loss: 0.0004726239712908864
Test Loss:  0.0002738102921284735
Valid Loss:  0.0005351916188374162
Epoch:  165  	Training Loss: 0.0004708566702902317
Test Loss:  0.00027252972358837724
Valid Loss:  0.0005329560954123735
Epoch:  166  	Training Loss: 0.000469293852802366
Test Loss:  0.0002714504371397197
Valid Loss:  0.0005309753469191492
Epoch:  167  	Training Loss: 0.000467884965473786
Test Loss:  0.0002704790676943958
Valid Loss:  0.0005291071138344705
Epoch:  168  	Training Loss: 0.0004665846354328096
Test Loss:  0.0002695686707738787
Valid Loss:  0.0005273859715089202
Epoch:  169  	Training Loss: 0.0004653795331250876
Test Loss:  0.0002687615342438221
Valid Loss:  0.0005257621523924172
Epoch:  170  	Training Loss: 0.00046429981011897326
Test Loss:  0.00026805861853063107
Valid Loss:  0.0005242405459284782
Epoch:  171  	Training Loss: 0.0004632820491679013
Test Loss:  0.00026743736816570163
Valid Loss:  0.0005228273803368211
Epoch:  172  	Training Loss: 0.0004623230779543519
Test Loss:  0.00026664466713555157
Valid Loss:  0.0005216669524088502
Epoch:  173  	Training Loss: 0.0004612964694388211
Test Loss:  0.00026605420862324536
Valid Loss:  0.0005208751535974443
Epoch:  174  	Training Loss: 0.00046032341197133064
Test Loss:  0.00026549719041213393
Valid Loss:  0.0005201377789489925
Epoch:  175  	Training Loss: 0.00045937029062770307
Test Loss:  0.00026494450867176056
Valid Loss:  0.0005194091936573386
Epoch:  176  	Training Loss: 0.0004584304988384247
Test Loss:  0.00026440504007041454
Valid Loss:  0.0005186739726923406
Epoch:  177  	Training Loss: 0.0004575125058181584
Test Loss:  0.00026388594415038824
Valid Loss:  0.0005179477739147842
Epoch:  178  	Training Loss: 0.0004566122079268098
Test Loss:  0.0002633546246215701
Valid Loss:  0.0005171761149540544
Epoch:  179  	Training Loss: 0.00045572349335998297
Test Loss:  0.00026282179169356823
Valid Loss:  0.0005163894384168088
Epoch:  180  	Training Loss: 0.0004548407450783998
Test Loss:  0.0002622860192786902
Valid Loss:  0.0005155978724360466
Epoch:  181  	Training Loss: 0.00045396541827358305
Test Loss:  0.00026175513630732894
Valid Loss:  0.0005148053751327097
Epoch:  182  	Training Loss: 0.0004530935548245907
Test Loss:  0.00026030384469777346
Valid Loss:  0.0005130417412146926
Epoch:  183  	Training Loss: 0.00045128041529096663
Test Loss:  0.0002589148934930563
Valid Loss:  0.0005112929502502084
Epoch:  184  	Training Loss: 0.0004496653564274311
Test Loss:  0.0002575689577497542
Valid Loss:  0.0005095467204228044
Epoch:  185  	Training Loss: 0.00044812040869146585
Test Loss:  0.0002563159796409309
Valid Loss:  0.0005078620743006468
Epoch:  186  	Training Loss: 0.0004466616956051439
Test Loss:  0.0002550825010985136
Valid Loss:  0.0005061989068053663
Epoch:  187  	Training Loss: 0.00044523636461235583
Test Loss:  0.00025390658993273973
Valid Loss:  0.0005046080332249403
Epoch:  188  	Training Loss: 0.00044383929343894124
Test Loss:  0.00025281670968979597
Valid Loss:  0.000503094051964581
Epoch:  189  	Training Loss: 0.0004424992366693914
Test Loss:  0.00025176635244861245
Valid Loss:  0.0005016233772039413
Epoch:  190  	Training Loss: 0.00044119427911937237
Test Loss:  0.00025078607723116875
Valid Loss:  0.0005002000834792852
Epoch:  191  	Training Loss: 0.00043991830898448825
Test Loss:  0.0002498484100215137
Valid Loss:  0.0004988051950931549
Epoch:  192  	Training Loss: 0.00043868247303180397
Test Loss:  0.00024944485630840063
Valid Loss:  0.0004979706718586385
Epoch:  193  	Training Loss: 0.000438162824138999
Test Loss:  0.0002491637715138495
Valid Loss:  0.0004973693867214024
Epoch:  194  	Training Loss: 0.00043766232556663454
Test Loss:  0.0002489204052835703
Valid Loss:  0.0004968229914084077
Epoch:  195  	Training Loss: 0.0004371721588540822
Test Loss:  0.00024868123000487685
Valid Loss:  0.0004962612874805927
Epoch:  196  	Training Loss: 0.0004366919456515461
Test Loss:  0.0002484520082361996
Valid Loss:  0.0004957132623530924
Epoch:  197  	Training Loss: 0.00043621420627459884
Test Loss:  0.0002482311974745244
Valid Loss:  0.0004951683222316206
Epoch:  198  	Training Loss: 0.0004357434227131307
Test Loss:  0.0002479910908732563
Valid Loss:  0.0004945970140397549
Epoch:  199  	Training Loss: 0.0004352827090770006
Test Loss:  0.00024775631027296185
Valid Loss:  0.0004940395592711866
Epoch:  200  	Training Loss: 0.00043482420733198524
Test Loss:  0.000247522460995242
Valid Loss:  0.000493482977617532
Epoch:  201  	Training Loss: 0.00043436771375127137
Test Loss:  0.0002472886408213526
Valid Loss:  0.000492926687002182
Epoch:  202  	Training Loss: 0.0004339120350778103
Test Loss:  0.00024743718677200377
Valid Loss:  0.0004928239504806697
Epoch:  203  	Training Loss: 0.0004334711702540517
Test Loss:  0.00024731477606110275
Valid Loss:  0.0004922644002363086
Epoch:  204  	Training Loss: 0.0004330941883381456
Test Loss:  0.00024715132894925773
Valid Loss:  0.0004916457692161202
Epoch:  205  	Training Loss: 0.0004327240167185664
Test Loss:  0.00024694931926205754
Valid Loss:   41%|████      | 205/500 [02:29<03:00,  1.63it/s] 41%|████▏     | 207/500 [02:29<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:30<01:36,  3.00it/s] 42%|████▏     | 211/500 [02:36<05:44,  1.19s/it] 43%|████▎     | 213/500 [02:36<04:05,  1.17it/s] 43%|████▎     | 215/500 [02:36<02:56,  1.62it/s] 43%|████▎     | 217/500 [02:36<02:08,  2.21it/s] 44%|████▍     | 219/500 [02:37<01:34,  2.98it/s] 44%|████▍     | 221/500 [02:43<05:26,  1.17s/it] 45%|████▍     | 223/500 [02:43<03:53,  1.19it/s] 45%|████▌     | 225/500 [02:43<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:43<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:43<01:29,  3.02it/s] 46%|████▌     | 231/500 [02:50<05:17,  1.18s/it] 47%|████▋     | 233/500 [02:50<03:45,  1.18it/s] 47%|████▋     | 235/500 [02:50<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:50<01:57,  2.23it/s] 48%|████▊     | 239/500 [02:50<01:27,  2.99it/s] 48%|████▊     | 241/500 [02:56<05:03,  1.17s/it] 49%|████▊     | 243/500 [02:57<03:36,  1.19it/s] 49%|████▉     | 245/500 [02:57<02:35,  1.64it/s] 49%|████▉     | 247/500 [02:57<01:52,  2.24it/s] 50%|████▉     | 249/500 [02:57<01:23,  3.01it/s] 50%|█████     | 251/500 [03:03<04:57,  1.19s/it] 51%|█████     | 253/500 [03:03<03:31,  1.17it/s] 51%|█████     | 255/500 [03:04<02:31,  1.62it/s] 51%|█████▏    | 257/500 [03:04<01:50,  2.21it/s] 52%|█████▏    | 259/500 [03:04<01:21,  2.97it/s] 52%|█████▏    | 261/500 [03:10<04:42,  1.18s/it] 53%|█████▎    | 263/500 [03:10<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:10<02:23,  1.63it/s] 53%|█████▎    | 267/500 [03:11<01:44,  2.23it/s] 54%|█████▍    | 269/500 [03:11<01:16,  3.00it/s] 54%|█████▍    | 271/500 [03:17<04:29,  1.18s/it]0.0004909553099423647
Epoch:  206  	Training Loss: 0.0004323595785535872
Test Loss:  0.0002468089514877647
Valid Loss:  0.0004903471563011408
Epoch:  207  	Training Loss: 0.00043199912761338055
Test Loss:  0.0002466249861754477
Valid Loss:  0.0004896777682006359
Epoch:  208  	Training Loss: 0.0004316439153626561
Test Loss:  0.0002464790304657072
Valid Loss:  0.0004890648415312171
Epoch:  209  	Training Loss: 0.00043129490222781897
Test Loss:  0.00024629931431263685
Valid Loss:  0.0004884017398580909
Epoch:  210  	Training Loss: 0.00043095945147797465
Test Loss:  0.0002461600233800709
Valid Loss:  0.0004877989995293319
Epoch:  211  	Training Loss: 0.00043063174234703183
Test Loss:  0.00024597864830866456
Valid Loss:  0.0004871399432886392
Epoch:  212  	Training Loss: 0.0004303070600144565
Test Loss:  0.0002446233993396163
Valid Loss:  0.00048533728113397956
Epoch:  213  	Training Loss: 0.00042911447235383093
Test Loss:  0.00024341160315088928
Valid Loss:  0.00048376782797276974
Epoch:  214  	Training Loss: 0.0004279693530406803
Test Loss:  0.00024227422545664012
Valid Loss:  0.000482321425806731
Epoch:  215  	Training Loss: 0.00042685220250859857
Test Loss:  0.00024117797147482634
Valid Loss:  0.00048094248631969094
Epoch:  216  	Training Loss: 0.00042575824772939086
Test Loss:  0.00024012156063690782
Valid Loss:  0.00047962958342395723
Epoch:  217  	Training Loss: 0.0004246831522323191
Test Loss:  0.0002390972076682374
Valid Loss:  0.00047837052261456847
Epoch:  218  	Training Loss: 0.0004236262175254524
Test Loss:  0.00023810143466107547
Valid Loss:  0.0004771582898683846
Epoch:  219  	Training Loss: 0.00042258488247171044
Test Loss:  0.00023712811525911093
Valid Loss:  0.00047598566743545234
Epoch:  220  	Training Loss: 0.0004215568769723177
Test Loss:  0.00023618910927325487
Valid Loss:  0.00047485780669376254
Epoch:  221  	Training Loss: 0.0004205585573799908
Test Loss:  0.0002352751325815916
Valid Loss:  0.0004737659473903477
Epoch:  222  	Training Loss: 0.00041957449866458774
Test Loss:  0.0002343710366403684
Valid Loss:  0.0004726784536615014
Epoch:  223  	Training Loss: 0.00041852600406855345
Test Loss:  0.00023349789262283593
Valid Loss:  0.0004716168041341007
Epoch:  224  	Training Loss: 0.0004174993373453617
Test Loss:  0.00023263978073373437
Valid Loss:  0.0004705792816821486
Epoch:  225  	Training Loss: 0.0004164826241321862
Test Loss:  0.0002317962935194373
Valid Loss:  0.0004695639945566654
Epoch:  226  	Training Loss: 0.0004154746711719781
Test Loss:  0.00023096706718206406
Valid Loss:  0.0004685704770963639
Epoch:  227  	Training Loss: 0.0004144747508689761
Test Loss:  0.00023015509941615164
Valid Loss:  0.0004675975360441953
Epoch:  228  	Training Loss: 0.0004134835908189416
Test Loss:  0.00022935462766326964
Valid Loss:  0.00046664002002216876
Epoch:  229  	Training Loss: 0.0004125004052184522
Test Loss:  0.00022856632131151855
Valid Loss:  0.0004656997334677726
Epoch:  230  	Training Loss: 0.0004115263291168958
Test Loss:  0.00022779124265071005
Valid Loss:  0.0004647756868507713
Epoch:  231  	Training Loss: 0.00041055885958485305
Test Loss:  0.0002270261466037482
Valid Loss:  0.00046386750182136893
Epoch:  232  	Training Loss: 0.00040959828766062856
Test Loss:  0.00022639345843344927
Valid Loss:  0.00046331901103258133
Epoch:  233  	Training Loss: 0.00040864411857910454
Test Loss:  0.00022574594186153263
Valid Loss:  0.0004627431044355035
Epoch:  234  	Training Loss: 0.0004077063058502972
Test Loss:  0.00022510031703859568
Valid Loss:  0.0004621570697054267
Epoch:  235  	Training Loss: 0.00040678150253370404
Test Loss:  0.00022444881324190646
Valid Loss:  0.0004615390789695084
Epoch:  236  	Training Loss: 0.00040587293915450573
Test Loss:  0.0002238005108665675
Valid Loss:  0.000460898969322443
Epoch:  237  	Training Loss: 0.00040497942245565355
Test Loss:  0.0002231515245512128
Valid Loss:  0.00046024861512705684
Epoch:  238  	Training Loss: 0.0004040973144583404
Test Loss:  0.00022245300351642072
Valid Loss:  0.0004595259088091552
Epoch:  239  	Training Loss: 0.00040315231308341026
Test Loss:  0.00022124263341538608
Valid Loss:  0.0004581147513817996
Epoch:  240  	Training Loss: 0.0004014606820419431
Test Loss:  0.00021932828531134874
Valid Loss:  0.0004560966044664383
Epoch:  241  	Training Loss: 0.000398773408960551
Test Loss:  0.00021868794283363968
Valid Loss:  0.00045534479431807995
Epoch:  242  	Training Loss: 0.0003977091400884092
Test Loss:  0.00021825486328452826
Valid Loss:  0.0004546851560007781
Epoch:  243  	Training Loss: 0.0003969146346207708
Test Loss:  0.0002178364957217127
Valid Loss:  0.0004540575318969786
Epoch:  244  	Training Loss: 0.00039612952969036996
Test Loss:  0.00021741248201578856
Valid Loss:  0.0004534131148830056
Epoch:  245  	Training Loss: 0.0003953513805754483
Test Loss:  0.00021698675118386745
Valid Loss:  0.00045276148011907935
Epoch:  246  	Training Loss: 0.00039458187529817224
Test Loss:  0.00021655240561813116
Valid Loss:  0.0004520899092312902
Epoch:  247  	Training Loss: 0.0003938262234441936
Test Loss:  0.00021611247211694717
Valid Loss:  0.0004514069587457925
Epoch:  248  	Training Loss: 0.00039308902341872454
Test Loss:  0.0002156650589313358
Valid Loss:  0.0004507111734710634
Epoch:  249  	Training Loss: 0.0003923655895050615
Test Loss:  0.00021522134193219244
Valid Loss:  0.00045002350816503167
Epoch:  250  	Training Loss: 0.00039164588088169694
Test Loss:  0.00021477523841895163
Valid Loss:  0.0004493350279517472
Epoch:  251  	Training Loss: 0.00039093010127544403
Test Loss:  0.00021432698122225702
Valid Loss:  0.0004486408724915236
Epoch:  252  	Training Loss: 0.00039021894917823374
Test Loss:  0.0002135752874892205
Valid Loss:  0.00044691719813272357
Epoch:  253  	Training Loss: 0.0003894215333275497
Test Loss:  0.0002129105560015887
Valid Loss:  0.00044535641791298985
Epoch:  254  	Training Loss: 0.0003887623024638742
Test Loss:  0.0002123235899489373
Valid Loss:  0.0004439741314854473
Epoch:  255  	Training Loss: 0.0003881799057126045
Test Loss:  0.00021180033218115568
Valid Loss:  0.0004427412059158087
Epoch:  256  	Training Loss: 0.00038765097269788384
Test Loss:  0.00021135012502782047
Valid Loss:  0.0004416336305439472
Epoch:  257  	Training Loss: 0.0003871744847856462
Test Loss:  0.00021094974363222718
Valid Loss:  0.00044064520625397563
Epoch:  258  	Training Loss: 0.00038673862582072616
Test Loss:  0.0002105841413140297
Valid Loss:  0.0004397529410198331
Epoch:  259  	Training Loss: 0.00038633300573565066
Test Loss:  0.00021024345187470317
Valid Loss:  0.0004389564855955541
Epoch:  260  	Training Loss: 0.00038594938814640045
Test Loss:  0.0002099253615597263
Valid Loss:  0.00043822190491482615
Epoch:  261  	Training Loss: 0.0003855808754451573
Test Loss:  0.00020962364214938134
Valid Loss:  0.00043754279613494873
Epoch:  262  	Training Loss: 0.00038522464456036687
Test Loss:  0.0002087878092424944
Valid Loss:  0.0004368078080005944
Epoch:  263  	Training Loss: 0.00038390449481084943
Test Loss:  0.00020834134193137288
Valid Loss:  0.00043636502232402563
Epoch:  264  	Training Loss: 0.0003830229979939759
Test Loss:  0.00020795156888198107
Valid Loss:  0.0004359442391432822
Epoch:  265  	Training Loss: 0.00038222302100621164
Test Loss:  0.00020758490427397192
Valid Loss:  0.0004355606506578624
Epoch:  266  	Training Loss: 0.00038150069303810596
Test Loss:  0.0002072236966341734
Valid Loss:  0.0004352039541117847
Epoch:  267  	Training Loss: 0.00038085883716121316
Test Loss:  0.00020685349591076374
Valid Loss:  0.0004348423099145293
Epoch:  268  	Training Loss: 0.000380234036128968
Test Loss:  0.00020648523059207946
Valid Loss:  0.00043446957715786994
Epoch:  269  	Training Loss: 0.00037961688940413296
Test Loss:  0.00020611178479157388
Valid Loss:  0.0004340942541602999
Epoch:  270  	Training Loss: 0.0003790099290199578
Test Loss:  0.00020572979701682925
Valid Loss:  0.00043370368075557053
Epoch:  271  	Training Loss: 0.00037840992445126176
Test Loss:  0.00020534350187517703
Valid Loss:  0.00043330457992851734
Epoch:  272  	Training Loss: 0.00037782033905386925
Test Loss:  0.00020398266497068107
Valid Loss:  0.00043119690963067114
 55%|█████▍    | 273/500 [03:17<03:11,  1.18it/s] 55%|█████▌    | 275/500 [03:17<02:17,  1.63it/s] 55%|█████▌    | 277/500 [03:17<01:39,  2.23it/s] 56%|█████▌    | 279/500 [03:18<01:13,  2.99it/s] 56%|█████▌    | 281/500 [03:24<04:17,  1.18s/it] 57%|█████▋    | 283/500 [03:24<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:24<02:11,  1.64it/s] 57%|█████▋    | 287/500 [03:24<01:35,  2.24it/s] 58%|█████▊    | 289/500 [03:24<01:10,  3.00it/s] 58%|█████▊    | 291/500 [03:31<04:03,  1.16s/it] 59%|█████▊    | 293/500 [03:31<02:53,  1.20it/s] 59%|█████▉    | 295/500 [03:31<02:04,  1.65it/s] 59%|█████▉    | 297/500 [03:31<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:31<01:06,  3.02it/s] 60%|██████    | 301/500 [03:37<03:53,  1.17s/it] 61%|██████    | 303/500 [03:38<02:45,  1.19it/s] 61%|██████    | 305/500 [03:38<01:58,  1.64it/s] 61%|██████▏   | 307/500 [03:38<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:38<01:03,  3.01it/s] 62%|██████▏   | 311/500 [03:44<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:44<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:44<01:52,  1.65it/s] 63%|██████▎   | 317/500 [03:45<01:21,  2.25it/s] 64%|██████▍   | 319/500 [03:45<00:59,  3.02it/s] 64%|██████▍   | 321/500 [03:51<03:32,  1.18s/it] 65%|██████▍   | 323/500 [03:51<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:51<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:51<01:17,  2.22it/s] 66%|██████▌   | 329/500 [03:52<00:57,  2.99it/s] 66%|██████▌   | 331/500 [03:58<03:17,  1.17s/it] 67%|██████▋   | 333/500 [03:58<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:58<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:58<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:58<00:53,  3.02it/s]Epoch:  273  	Training Loss: 0.0003759979736059904
Test Loss:  0.00020315259462222457
Valid Loss:  0.0004300299915485084
Epoch:  274  	Training Loss: 0.00037440843880176544
Test Loss:  0.00020233170653227717
Valid Loss:  0.00042877765372395515
Epoch:  275  	Training Loss: 0.00037295452784746885
Test Loss:  0.00020153974764980376
Valid Loss:  0.00042754909372888505
Epoch:  276  	Training Loss: 0.000371563684893772
Test Loss:  0.00020077175577171147
Valid Loss:  0.000426292244810611
Epoch:  277  	Training Loss: 0.00037021480966359377
Test Loss:  0.00020000195945613086
Valid Loss:  0.0004250025376677513
Epoch:  278  	Training Loss: 0.000368909677490592
Test Loss:  0.00019924409571103752
Valid Loss:  0.0004237156827002764
Epoch:  279  	Training Loss: 0.0003676433116197586
Test Loss:  0.00019850264652632177
Valid Loss:  0.00042245181975886226
Epoch:  280  	Training Loss: 0.0003664168471004814
Test Loss:  0.000197755653061904
Valid Loss:  0.00042118309647776186
Epoch:  281  	Training Loss: 0.0003652329323813319
Test Loss:  0.00019701517885550857
Valid Loss:  0.00041991635225713253
Epoch:  282  	Training Loss: 0.00036407768493518233
Test Loss:  0.00019675077055580914
Valid Loss:  0.00041919294744729996
Epoch:  283  	Training Loss: 0.0003635467146523297
Test Loss:  0.0001964215625775978
Valid Loss:  0.00041836866876110435
Epoch:  284  	Training Loss: 0.0003630319843068719
Test Loss:  0.00019608644652180374
Valid Loss:  0.0004175278590992093
Epoch:  285  	Training Loss: 0.0003625220851972699
Test Loss:  0.0001957656495505944
Valid Loss:  0.00041671181679703295
Epoch:  286  	Training Loss: 0.00036202374030835927
Test Loss:  0.00019545017858035862
Valid Loss:  0.0004159066593274474
Epoch:  287  	Training Loss: 0.00036153075052425265
Test Loss:  0.00019514947780407965
Valid Loss:  0.00041513313772156835
Epoch:  288  	Training Loss: 0.00036104375612922013
Test Loss:  0.00019486363453324884
Valid Loss:  0.000414366542827338
Epoch:  289  	Training Loss: 0.0003605678793974221
Test Loss:  0.00019458061433397233
Valid Loss:  0.00041362643241882324
Epoch:  290  	Training Loss: 0.00036009581526741385
Test Loss:  0.00019430652901064605
Valid Loss:  0.00041288573993369937
Epoch:  291  	Training Loss: 0.0003596282913349569
Test Loss:  0.0001940357033163309
Valid Loss:  0.0004121609381400049
Epoch:  292  	Training Loss: 0.0003591660060919821
Test Loss:  0.0001932185550685972
Valid Loss:  0.0004108103457838297
Epoch:  293  	Training Loss: 0.00035847892286255956
Test Loss:  0.0001927629637066275
Valid Loss:  0.00041023670928552747
Epoch:  294  	Training Loss: 0.00035784963984042406
Test Loss:  0.00019231850455980748
Valid Loss:  0.0004096854536328465
Epoch:  295  	Training Loss: 0.000357224082108587
Test Loss:  0.00019187715952284634
Valid Loss:  0.00040914039709605277
Epoch:  296  	Training Loss: 0.0003566002123989165
Test Loss:  0.0001914376625791192
Valid Loss:  0.00040860066656023264
Epoch:  297  	Training Loss: 0.00035598050453700125
Test Loss:  0.0001910025894176215
Valid Loss:  0.0004080619546584785
Epoch:  298  	Training Loss: 0.0003553684218786657
Test Loss:  0.00019057630561292171
Valid Loss:  0.00040752379572950304
Epoch:  299  	Training Loss: 0.0003547643427737057
Test Loss:  0.0001901536452351138
Valid Loss:  0.0004069899732712656
Epoch:  300  	Training Loss: 0.0003541626501828432
Test Loss:  0.0001897347392514348
Valid Loss:  0.00040645740227773786
Epoch:  301  	Training Loss: 0.0003535660507623106
Test Loss:  0.0001893234730232507
Valid Loss:  0.000405923870857805
Epoch:  302  	Training Loss: 0.00035297274007461965
Test Loss:  0.00018900007125921547
Valid Loss:  0.00040540550253354013
Epoch:  303  	Training Loss: 0.00035207008477300406
Test Loss:  0.00018843496218323708
Valid Loss:  0.00040441149030812085
Epoch:  304  	Training Loss: 0.00035120092798024416
Test Loss:  0.00018787733279168606
Valid Loss:  0.0004034271987620741
Epoch:  305  	Training Loss: 0.0003503364569041878
Test Loss:  0.00018731894670054317
Valid Loss:  0.00040244089905172586
Epoch:  306  	Training Loss: 0.00034947492531500757
Test Loss:  0.00018676590116228908
Valid Loss:  0.0004014624864794314
Epoch:  307  	Training Loss: 0.000348617642885074
Test Loss:  0.00018621320487000048
Valid Loss:  0.0004004854999948293
Epoch:  308  	Training Loss: 0.000347763707395643
Test Loss:  0.0001856615417636931
Valid Loss:  0.0003995091828983277
Epoch:  309  	Training Loss: 0.00034691428299993277
Test Loss:  0.0001851133129093796
Valid Loss:  0.000398537638830021
Epoch:  310  	Training Loss: 0.0003460684383753687
Test Loss:  0.00018456843099556863
Valid Loss:  0.00039757404010742903
Epoch:  311  	Training Loss: 0.0003452253295108676
Test Loss:  0.000184023316251114
Valid Loss:  0.000396607763832435
Epoch:  312  	Training Loss: 0.00034438568400219083
Test Loss:  0.0001837531162891537
Valid Loss:  0.0003960257745347917
Epoch:  313  	Training Loss: 0.00034383853198960423
Test Loss:  0.00018345779972150922
Valid Loss:  0.00039538118289783597
Epoch:  314  	Training Loss: 0.00034331175265833735
Test Loss:  0.00018319013179279864
Valid Loss:  0.0003947812947444618
Epoch:  315  	Training Loss: 0.0003427923657000065
Test Loss:  0.00018292226013727486
Valid Loss:  0.0003941842296626419
Epoch:  316  	Training Loss: 0.0003422783629503101
Test Loss:  0.00018263934180140495
Valid Loss:  0.00039356190245598555
Epoch:  317  	Training Loss: 0.00034176744520664215
Test Loss:  0.0001823866186896339
Valid Loss:  0.0003929989761672914
Epoch:  318  	Training Loss: 0.0003412593505345285
Test Loss:  0.0001821040641516447
Valid Loss:  0.0003923707699868828
Epoch:  319  	Training Loss: 0.00034075669827871025
Test Loss:  0.0001818396704038605
Valid Loss:  0.0003917836584150791
Epoch:  320  	Training Loss: 0.00034025771310552955
Test Loss:  0.00018155355064664036
Valid Loss:  0.0003911530948244035
Epoch:  321  	Training Loss: 0.0003397683030925691
Test Loss:  0.00018130273383576423
Valid Loss:  0.00039057046524249017
Epoch:  322  	Training Loss: 0.0003392892540432513
Test Loss:  0.00018067454220727086
Valid Loss:  0.0003893355606123805
Epoch:  323  	Training Loss: 0.0003386343887541443
Test Loss:  0.00018010208441410214
Valid Loss:  0.0003881946031469852
Epoch:  324  	Training Loss: 0.0003380256239324808
Test Loss:  0.00017958314856514335
Valid Loss:  0.00038714316906407475
Epoch:  325  	Training Loss: 0.0003374550142325461
Test Loss:  0.00017910957103595138
Valid Loss:  0.00038618064718320966
Epoch:  326  	Training Loss: 0.0003369194455444813
Test Loss:  0.00017866627604234964
Valid Loss:  0.00038529047742486
Epoch:  327  	Training Loss: 0.0003364085569046438
Test Loss:  0.00017825039685703814
Valid Loss:  0.00038446777034550905
Epoch:  328  	Training Loss: 0.00033592162071727216
Test Loss:  0.0001778555742930621
Valid Loss:  0.0003837015829049051
Epoch:  329  	Training Loss: 0.00033545278711244464
Test Loss:  0.00017747757374309003
Valid Loss:  0.0003829898196272552
Epoch:  330  	Training Loss: 0.00033499981509521604
Test Loss:  0.00017711392138153315
Valid Loss:  0.00038232363294810057
Epoch:  331  	Training Loss: 0.00033455845550633967
Test Loss:  0.00017676196875981987
Valid Loss:  0.00038169516483321786
Epoch:  332  	Training Loss: 0.00033412460470572114
Test Loss:  0.0001751618692651391
Valid Loss:  0.0003800565027631819
Epoch:  333  	Training Loss: 0.00033227604581043124
Test Loss:  0.00017439424118492752
Valid Loss:  0.00037905079079791903
Epoch:  334  	Training Loss: 0.00033111663651652634
Test Loss:  0.0001738049031700939
Valid Loss:  0.00037810206413269043
Epoch:  335  	Training Loss: 0.00033016089582815766
Test Loss:  0.00017323710198979825
Valid Loss:  0.0003771191113628447
Epoch:  336  	Training Loss: 0.0003292687179055065
Test Loss:  0.00017267708608414978
Valid Loss:  0.0003761574043892324
Epoch:  337  	Training Loss: 0.00032841262873262167
Test Loss:  0.0001721551234368235
Valid Loss:  0.0003752009943127632
Epoch:  338  	Training Loss: 0.00032758669112809
Test Loss:  0.00017164560267701745
Valid Loss:  0.00037425398477353156
Epoch:  339  	Training Loss: 0.0003267822612542659
Test Loss:  0.00017114848014898598
Valid Loss:  0.00037331803468987346
Epoch:  340  	Training Loss: 0.0003260001540184021
 68%|██████▊   | 341/500 [04:05<03:09,  1.19s/it] 69%|██████▊   | 343/500 [04:05<02:14,  1.17it/s] 69%|██████▉   | 345/500 [04:05<01:35,  1.62it/s] 69%|██████▉   | 347/500 [04:05<01:09,  2.21it/s] 70%|██████▉   | 349/500 [04:05<00:50,  2.97it/s] 70%|███████   | 351/500 [04:12<02:58,  1.20s/it] 71%|███████   | 353/500 [04:12<02:06,  1.16it/s] 71%|███████   | 355/500 [04:12<01:30,  1.61it/s] 71%|███████▏  | 357/500 [04:12<01:05,  2.20it/s] 72%|███████▏  | 359/500 [04:12<00:47,  2.96it/s] 72%|███████▏  | 361/500 [04:19<02:47,  1.20s/it] 73%|███████▎  | 363/500 [04:19<01:58,  1.16it/s] 73%|███████▎  | 365/500 [04:19<01:24,  1.60it/s] 73%|███████▎  | 367/500 [04:19<01:00,  2.18it/s] 74%|███████▍  | 369/500 [04:19<00:44,  2.94it/s] 74%|███████▍  | 371/500 [04:26<02:31,  1.18s/it] 75%|███████▍  | 373/500 [04:26<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:26<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:26<00:55,  2.24it/s] 76%|███████▌  | 379/500 [04:26<00:40,  3.01it/s] 76%|███████▌  | 381/500 [04:32<02:18,  1.16s/it] 77%|███████▋  | 383/500 [04:32<01:37,  1.20it/s] 77%|███████▋  | 385/500 [04:33<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:33<00:50,  2.25it/s] 78%|███████▊  | 389/500 [04:33<00:36,  3.02it/s] 78%|███████▊  | 391/500 [04:39<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:39<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:39<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:40<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:40<00:33,  2.98it/s] 80%|████████  | 401/500 [04:46<01:56,  1.18s/it] 81%|████████  | 403/500 [04:46<01:22,  1.18it/s] 81%|████████  | 405/500 [04:46<00:58,  1.63it/s]Test Loss:  0.00017065159045159817
Valid Loss:  0.0003723924746736884
Epoch:  341  	Training Loss: 0.00032523181289434433
Test Loss:  0.00017016736092045903
Valid Loss:  0.0003714795457199216
Epoch:  342  	Training Loss: 0.00032447572448290884
Test Loss:  0.00017005251720547676
Valid Loss:  0.0003713482292369008
Epoch:  343  	Training Loss: 0.00032364806975238025
Test Loss:  0.00016972905723378062
Valid Loss:  0.0003707935684360564
Epoch:  344  	Training Loss: 0.00032290309900417924
Test Loss:  0.00016933069855440408
Valid Loss:  0.00037010147934779525
Epoch:  345  	Training Loss: 0.00032217157422564924
Test Loss:  0.00016891025006771088
Valid Loss:  0.0003693668986670673
Epoch:  346  	Training Loss: 0.0003214470634702593
Test Loss:  0.0001684943272266537
Valid Loss:  0.0003686252748593688
Epoch:  347  	Training Loss: 0.0003207372792530805
Test Loss:  0.0001680883433436975
Valid Loss:  0.0003678819048218429
Epoch:  348  	Training Loss: 0.00032004137756302953
Test Loss:  0.00016770255751907825
Valid Loss:  0.0003671410377137363
Epoch:  349  	Training Loss: 0.00031936081359162927
Test Loss:  0.0001673250662861392
Valid Loss:  0.0003664114628918469
Epoch:  350  	Training Loss: 0.00031869433587417006
Test Loss:  0.0001669552002567798
Valid Loss:  0.00036569227813743055
Epoch:  351  	Training Loss: 0.00031803472666069865
Test Loss:  0.000166589132277295
Valid Loss:  0.00036498208646662533
Epoch:  352  	Training Loss: 0.0003173861186951399
Test Loss:  0.0001659987319726497
Valid Loss:  0.0003641057701315731
Epoch:  353  	Training Loss: 0.00031691999174654484
Test Loss:  0.00016554066678509116
Valid Loss:  0.00036345014814287424
Epoch:  354  	Training Loss: 0.0003165106172673404
Test Loss:  0.0001651491766097024
Valid Loss:  0.00036290459684096277
Epoch:  355  	Training Loss: 0.0003161233034916222
Test Loss:  0.0001648004981689155
Valid Loss:  0.0003624276432674378
Epoch:  356  	Training Loss: 0.0003157535393256694
Test Loss:  0.00016448282985948026
Valid Loss:  0.0003619933850131929
Epoch:  357  	Training Loss: 0.00031539585324935615
Test Loss:  0.00016419356688857079
Valid Loss:  0.00036159303272143006
Epoch:  358  	Training Loss: 0.00031505717197433114
Test Loss:  0.0001639184047235176
Valid Loss:  0.00036121573066338897
Epoch:  359  	Training Loss: 0.0003147292591165751
Test Loss:  0.00016365025658160448
Valid Loss:  0.00036085169995203614
Epoch:  360  	Training Loss: 0.00031440978636965156
Test Loss:  0.00016339194553438574
Valid Loss:  0.0003605046949815005
Epoch:  361  	Training Loss: 0.00031409948132932186
Test Loss:  0.00016314013919327408
Valid Loss:  0.00036017841193825006
Epoch:  362  	Training Loss: 0.0003137927851639688
Test Loss:  0.0001626667071832344
Valid Loss:  0.00035973062040284276
Epoch:  363  	Training Loss: 0.0003126278752461076
Test Loss:  0.00016198272351175547
Valid Loss:  0.00035882159136235714
Epoch:  364  	Training Loss: 0.0003115306899417192
Test Loss:  0.00016128069546539336
Valid Loss:  0.0003578917239792645
Epoch:  365  	Training Loss: 0.00031045806827023625
Test Loss:  0.00016060586494859308
Valid Loss:  0.00035699742147699
Epoch:  366  	Training Loss: 0.00030941865406930447
Test Loss:  0.00015995439025573432
Valid Loss:  0.00035610818304121494
Epoch:  367  	Training Loss: 0.0003084003401454538
Test Loss:  0.00015931794769130647
Valid Loss:  0.0003552233683876693
Epoch:  368  	Training Loss: 0.0003074081614613533
Test Loss:  0.00015870456991251558
Valid Loss:  0.00035435042809695005
Epoch:  369  	Training Loss: 0.0003064371121581644
Test Loss:  0.0001581018150318414
Valid Loss:  0.0003534819697961211
Epoch:  370  	Training Loss: 0.0003054873668588698
Test Loss:  0.00015751717728562653
Valid Loss:  0.00035262585151940584
Epoch:  371  	Training Loss: 0.0003045534831471741
Test Loss:  0.0001569545711390674
Valid Loss:  0.00035178326652385294
Epoch:  372  	Training Loss: 0.00030363688711076975
Test Loss:  0.00015629269182682037
Valid Loss:  0.00035067781573161483
Epoch:  373  	Training Loss: 0.0003029931103810668
Test Loss:  0.00015602765779476613
Valid Loss:  0.0003501668106764555
Epoch:  374  	Training Loss: 0.00030255611636675894
Test Loss:  0.0001558327057864517
Valid Loss:  0.0003497490251902491
Epoch:  375  	Training Loss: 0.00030218251049518585
Test Loss:  0.00015566061483696103
Valid Loss:  0.0003493640979286283
Epoch:  376  	Training Loss: 0.00030185352079570293
Test Loss:  0.0001555147609906271
Valid Loss:  0.0003490022791083902
Epoch:  377  	Training Loss: 0.0003015357651747763
Test Loss:  0.00015539544983766973
Valid Loss:  0.0003486483474262059
Epoch:  378  	Training Loss: 0.0003012464439962059
Test Loss:  0.000155280067701824
Valid Loss:  0.00034829575452022254
Epoch:  379  	Training Loss: 0.00030097446870058775
Test Loss:  0.00015516261919401586
Valid Loss:  0.00034793533268384635
Epoch:  380  	Training Loss: 0.0003007067716680467
Test Loss:  0.0001550475717522204
Valid Loss:  0.00034757444518618286
Epoch:  381  	Training Loss: 0.00030044338200241327
Test Loss:  0.00015492888633161783
Valid Loss:  0.0003472088137641549
Epoch:  382  	Training Loss: 0.00030018098186701536
Test Loss:  0.0001548182626720518
Valid Loss:  0.0003470315714366734
Epoch:  383  	Training Loss: 0.00029976473888382316
Test Loss:  0.00015464951866306365
Valid Loss:  0.0003466972557362169
Epoch:  384  	Training Loss: 0.0002993698581121862
Test Loss:  0.00015448941849172115
Valid Loss:  0.0003463673638179898
Epoch:  385  	Training Loss: 0.00029900053050369024
Test Loss:  0.00015433531370945275
Valid Loss:  0.00034604367101565003
Epoch:  386  	Training Loss: 0.00029865335091017187
Test Loss:  0.00015419075498357415
Valid Loss:  0.00034571660216897726
Epoch:  387  	Training Loss: 0.0002983277663588524
Test Loss:  0.0001540540106361732
Valid Loss:  0.00034540140768513083
Epoch:  388  	Training Loss: 0.00029803119832649827
Test Loss:  0.00015391081979032606
Valid Loss:  0.0003450697404332459
Epoch:  389  	Training Loss: 0.00029775628354400396
Test Loss:  0.00015376863302662969
Valid Loss:  0.00034474977292120457
Epoch:  390  	Training Loss: 0.00029749676468782127
Test Loss:  0.00015362928388640285
Valid Loss:  0.0003444282920099795
Epoch:  391  	Training Loss: 0.00029725380591116846
Test Loss:  0.00015348821762017906
Valid Loss:  0.0003440965083427727
Epoch:  392  	Training Loss: 0.00029701157473027706
Test Loss:  0.0001531506422907114
Valid Loss:  0.0003432774974498898
Epoch:  393  	Training Loss: 0.00029646206530742347
Test Loss:  0.00015276161138899624
Valid Loss:  0.0003423958842176944
Epoch:  394  	Training Loss: 0.00029593665385618806
Test Loss:  0.00015238739433698356
Valid Loss:  0.00034156261244788766
Epoch:  395  	Training Loss: 0.0002954258525278419
Test Loss:  0.0001520273508504033
Valid Loss:  0.0003407826879993081
Epoch:  396  	Training Loss: 0.0002949275658465922
Test Loss:  0.00015167972014751285
Valid Loss:  0.00034004609915427864
Epoch:  397  	Training Loss: 0.0002944387961179018
Test Loss:  0.00015134469140321016
Valid Loss:  0.00033935089595615864
Epoch:  398  	Training Loss: 0.00029395936871878803
Test Loss:  0.0001510166475782171
Valid Loss:  0.00033868823084048927
Epoch:  399  	Training Loss: 0.0002934866934083402
Test Loss:  0.0001506979315308854
Valid Loss:  0.0003380559792276472
Epoch:  400  	Training Loss: 0.00029301963513717055
Test Loss:  0.00015038475976325572
Valid Loss:  0.0003374519292265177
Epoch:  401  	Training Loss: 0.0002925579028669745
Test Loss:  0.0001500797225162387
Valid Loss:  0.0003368718025740236
Epoch:  402  	Training Loss: 0.00029210164211690426
Test Loss:  0.00014995087985880673
Valid Loss:  0.0003365808224771172
Epoch:  403  	Training Loss: 0.0002918767568189651
Test Loss:  0.00014982055290602148
Valid Loss:  0.0003362867864780128
Epoch:  404  	Training Loss: 0.0002916580706369132
Test Loss:  0.0001496950426371768
Valid Loss:  0.00033599193557165563
Epoch:  405  	Training Loss: 0.0002914482029154897
Test Loss:  0.00014958066458348185
Valid Loss:  0.0003356951056048274
Epoch:  406  	Training Loss: 0.00029124808497726917
Test Loss:  0.0001494675816502422
Valid Loss:  0.0003353982465341687
Epoch:  407  	Training Loss: 0.0002910543407779187
Test Loss:  0.00014935535728000104
Valid Loss:   81%|████████▏ | 407/500 [04:46<00:41,  2.23it/s] 82%|████████▏ | 409/500 [04:47<00:30,  2.98it/s] 82%|████████▏ | 411/500 [04:53<01:43,  1.17s/it] 83%|████████▎ | 413/500 [04:53<01:12,  1.19it/s] 83%|████████▎ | 415/500 [04:53<00:51,  1.65it/s] 83%|████████▎ | 417/500 [04:53<00:36,  2.25it/s] 84%|████████▍ | 419/500 [04:53<00:26,  3.02it/s] 84%|████████▍ | 421/500 [05:00<01:34,  1.19s/it] 85%|████████▍ | 423/500 [05:00<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:00<00:46,  1.62it/s] 85%|████████▌ | 427/500 [05:00<00:33,  2.21it/s] 86%|████████▌ | 429/500 [05:00<00:23,  2.97it/s] 86%|████████▌ | 431/500 [05:07<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:07<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:07<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:07<00:28,  2.21it/s] 88%|████████▊ | 439/500 [05:07<00:20,  2.97it/s] 88%|████████▊ | 441/500 [05:13<01:10,  1.19s/it] 89%|████████▊ | 443/500 [05:14<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:14<00:34,  1.62it/s] 89%|████████▉ | 447/500 [05:14<00:23,  2.21it/s] 90%|████████▉ | 449/500 [05:14<00:17,  2.96it/s] 90%|█████████ | 451/500 [05:20<00:58,  1.20s/it] 91%|█████████ | 453/500 [05:21<00:40,  1.16it/s] 91%|█████████ | 455/500 [05:21<00:28,  1.60it/s] 91%|█████████▏| 457/500 [05:21<00:19,  2.19it/s] 92%|█████████▏| 459/500 [05:21<00:13,  2.95it/s] 92%|█████████▏| 461/500 [05:27<00:47,  1.21s/it] 93%|█████████▎| 463/500 [05:28<00:32,  1.15it/s] 93%|█████████▎| 465/500 [05:28<00:21,  1.60it/s] 93%|█████████▎| 467/500 [05:28<00:15,  2.18it/s] 94%|█████████▍| 469/500 [05:28<00:10,  2.94it/s] 94%|█████████▍| 471/500 [05:34<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:34<00:22,  1.18it/s]0.0003351024352014065
Epoch:  408  	Training Loss: 0.000290866126306355
Test Loss:  0.00014924665447324514
Valid Loss:  0.00033482449362054467
Epoch:  409  	Training Loss: 0.00029067968716844916
Test Loss:  0.00014913547784090042
Valid Loss:  0.0003345488221384585
Epoch:  410  	Training Loss: 0.0002905009314417839
Test Loss:  0.00014902956900186837
Valid Loss:  0.0003342844429425895
Epoch:  411  	Training Loss: 0.0002903250278905034
Test Loss:  0.00014892316539771855
Valid Loss:  0.0003340125549584627
Epoch:  412  	Training Loss: 0.0002901583502534777
Test Loss:  0.0001487056870246306
Valid Loss:  0.0003340357216075063
Epoch:  413  	Training Loss: 0.00028939516050741076
Test Loss:  0.00014833948807790875
Valid Loss:  0.00033372390316799283
Epoch:  414  	Training Loss: 0.00028867670334875584
Test Loss:  0.0001479459460824728
Valid Loss:  0.0003333296626806259
Epoch:  415  	Training Loss: 0.0002879784442484379
Test Loss:  0.00014755353913642466
Valid Loss:  0.0003329142928123474
Epoch:  416  	Training Loss: 0.000287296628812328
Test Loss:  0.00014716555597260594
Valid Loss:  0.0003324884455651045
Epoch:  417  	Training Loss: 0.0002866281720343977
Test Loss:  0.00014678336447104812
Valid Loss:  0.00033205433283001184
Epoch:  418  	Training Loss: 0.0002859714441001415
Test Loss:  0.00014640518929809332
Valid Loss:  0.00033161393366754055
Epoch:  419  	Training Loss: 0.0002853245532605797
Test Loss:  0.0001460312050767243
Valid Loss:  0.00033116378472186625
Epoch:  420  	Training Loss: 0.00028468749951571226
Test Loss:  0.00014566075697075576
Valid Loss:  0.00033070973586291075
Epoch:  421  	Training Loss: 0.0002840584493242204
Test Loss:  0.000145292651723139
Valid Loss:  0.0003302493132650852
Epoch:  422  	Training Loss: 0.00028343650046736
Test Loss:  0.00014413287863135338
Valid Loss:  0.0003284284030087292
Epoch:  423  	Training Loss: 0.000281861110124737
Test Loss:  0.00014314211148303002
Valid Loss:  0.00032688333885744214
Epoch:  424  	Training Loss: 0.0002805010590236634
Test Loss:  0.00014232195098884404
Valid Loss:  0.00032550632022321224
Epoch:  425  	Training Loss: 0.0002793085004668683
Test Loss:  0.0001416073355358094
Valid Loss:  0.0003242192033212632
Epoch:  426  	Training Loss: 0.0002782123046927154
Test Loss:  0.0001409253163728863
Valid Loss:  0.0003230081347282976
Epoch:  427  	Training Loss: 0.0002771671861410141
Test Loss:  0.00014027363795321435
Valid Loss:  0.00032185640884563327
Epoch:  428  	Training Loss: 0.00027616185252554715
Test Loss:  0.00013964652316644788
Valid Loss:  0.00032075325725600123
Epoch:  429  	Training Loss: 0.000275191297987476
Test Loss:  0.00013903650688007474
Valid Loss:  0.000319699349347502
Epoch:  430  	Training Loss: 0.0002742433571256697
Test Loss:  0.00013844550994690508
Valid Loss:  0.0003186851099599153
Epoch:  431  	Training Loss: 0.0002733124711085111
Test Loss:  0.0001378736342303455
Valid Loss:  0.0003177073667757213
Epoch:  432  	Training Loss: 0.00027240003691986203
Test Loss:  0.00013771370868198574
Valid Loss:  0.000317612721119076
Epoch:  433  	Training Loss: 0.00027182360645383596
Test Loss:  0.0001374760759063065
Valid Loss:  0.00031734653748571873
Epoch:  434  	Training Loss: 0.00027128055808134377
Test Loss:  0.00013719566049985588
Valid Loss:  0.0003169831179548055
Epoch:  435  	Training Loss: 0.00027075206162407994
Test Loss:  0.00013690155174117535
Valid Loss:  0.00031658023362979293
Epoch:  436  	Training Loss: 0.0002702290948946029
Test Loss:  0.00013660005060955882
Valid Loss:  0.0003161572967655957
Epoch:  437  	Training Loss: 0.0002697107847779989
Test Loss:  0.00013629355817101896
Valid Loss:  0.00031571113504469395
Epoch:  438  	Training Loss: 0.00026919954689219594
Test Loss:  0.00013598811347037554
Valid Loss:  0.0003152616263832897
Epoch:  439  	Training Loss: 0.0002686938678380102
Test Loss:  0.00013568706344813108
Valid Loss:  0.00031479832250624895
Epoch:  440  	Training Loss: 0.00026819505728781223
Test Loss:  0.00013538992789108306
Valid Loss:  0.0003143373178318143
Epoch:  441  	Training Loss: 0.00026769874966703355
Test Loss:  0.00013509504788089544
Valid Loss:  0.0003138830070383847
Epoch:  442  	Training Loss: 0.00026720782625488937
Test Loss:  0.00013463429058901966
Valid Loss:  0.0003130770055577159
Epoch:  443  	Training Loss: 0.00026681122835725546
Test Loss:  0.0001343810436083004
Valid Loss:  0.00031261146068573
Epoch:  444  	Training Loss: 0.00026647921185940504
Test Loss:  0.00013419234892353415
Valid Loss:  0.0003122611087746918
Epoch:  445  	Training Loss: 0.00026616547256708145
Test Loss:  0.0001340295420959592
Valid Loss:  0.0003119528410024941
Epoch:  446  	Training Loss: 0.0002658574958331883
Test Loss:  0.0001338785223197192
Valid Loss:  0.00031165394466370344
Epoch:  447  	Training Loss: 0.00026555772637948394
Test Loss:  0.00013373230467550457
Valid Loss:  0.00031135446624830365
Epoch:  448  	Training Loss: 0.00026526275905780494
Test Loss:  0.00013358626165427268
Valid Loss:  0.0003110512043349445
Epoch:  449  	Training Loss: 0.00026496947975829244
Test Loss:  0.00013343819591682404
Valid Loss:  0.00031074241269379854
Epoch:  450  	Training Loss: 0.0002646779175847769
Test Loss:  0.00013328896602615714
Valid Loss:  0.00031042899354361
Epoch:  451  	Training Loss: 0.000264387228526175
Test Loss:  0.0001331344828940928
Valid Loss:  0.0003101108013652265
Epoch:  452  	Training Loss: 0.0002640932216309011
Test Loss:  0.00013270725321490318
Valid Loss:  0.00030891032656654716
Epoch:  453  	Training Loss: 0.0002635258133523166
Test Loss:  0.00013233999197836965
Valid Loss:  0.00030786669231019914
Epoch:  454  	Training Loss: 0.00026300325407646596
Test Loss:  0.00013200838293414563
Valid Loss:  0.0003069218364544213
Epoch:  455  	Training Loss: 0.000262522604316473
Test Loss:  0.0001317063724854961
Valid Loss:  0.0003060713643208146
Epoch:  456  	Training Loss: 0.0002620767627377063
Test Loss:  0.000131429813336581
Valid Loss:  0.0003053024993278086
Epoch:  457  	Training Loss: 0.0002616608398966491
Test Loss:  0.0001311751111643389
Valid Loss:  0.00030460438574664295
Epoch:  458  	Training Loss: 0.0002612702955957502
Test Loss:  0.0001309386861976236
Valid Loss:  0.00030397064983844757
Epoch:  459  	Training Loss: 0.0002609005896374583
Test Loss:  0.00013071663852315396
Valid Loss:  0.0003033920656889677
Epoch:  460  	Training Loss: 0.0002605492190923542
Test Loss:  0.00013050611596554518
Valid Loss:  0.00030286257970146835
Epoch:  461  	Training Loss: 0.0002602129243314266
Test Loss:  0.0001303071912843734
Valid Loss:  0.00030237826285883784
Epoch:  462  	Training Loss: 0.00025989030837081373
Test Loss:  0.00012997293379157782
Valid Loss:  0.0003019670839421451
Epoch:  463  	Training Loss: 0.00025941047351807356
Test Loss:  0.00012970861280336976
Valid Loss:  0.0003016444097738713
Epoch:  464  	Training Loss: 0.00025894780992530286
Test Loss:  0.00012946153583470732
Valid Loss:  0.00030132345273159444
Epoch:  465  	Training Loss: 0.00025849422672763467
Test Loss:  0.00012921320740133524
Valid Loss:  0.0003009933279827237
Epoch:  466  	Training Loss: 0.0002580443397164345
Test Loss:  0.00012896240514237434
Valid Loss:  0.0003006545011885464
Epoch:  467  	Training Loss: 0.0002575980615802109
Test Loss:  0.00012870696082245559
Valid Loss:  0.000300295592751354
Epoch:  468  	Training Loss: 0.000257152016274631
Test Loss:  0.00012845148739870638
Valid Loss:  0.0002999287680722773
Epoch:  469  	Training Loss: 0.0002567135379649699
Test Loss:  0.0001282005396205932
Valid Loss:  0.00029955070931464434
Epoch:  470  	Training Loss: 0.0002562857116572559
Test Loss:  0.00012795551447197795
Valid Loss:  0.0002991706132888794
Epoch:  471  	Training Loss: 0.00025587278651073575
Test Loss:  0.00012771799811162055
Valid Loss:  0.0002987935149576515
Epoch:  472  	Training Loss: 0.00025547557743266225
Test Loss:  0.00012776762014254928
Valid Loss:  0.00029864179668948054
Epoch:  473  	Training Loss: 0.0002547662006691098
Test Loss:  0.00012739213707391173
Valid Loss:  0.00029777418239973485
Epoch:  474  	Training Loss: 0.0002541230642236769
Test Loss:  0.00012706471898127347
Valid Loss:  0.00029700540471822023
 95%|█████████▌| 475/500 [05:35<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:35<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:35<00:06,  3.01it/s] 96%|█████████▌| 481/500 [05:41<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:41<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:41<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:41<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:42<00:03,  3.02it/s] 98%|█████████▊| 491/500 [05:48<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:48<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:48<00:03,  1.62it/s] 99%|█████████▉| 497/500 [05:48<00:01,  2.21it/s]100%|█████████▉| 499/500 [05:48<00:00,  2.97it/s]100%|██████████| 500/500 [05:49<00:00,  1.43it/s]
Epoch:  475  	Training Loss: 0.00025348877534270287
Test Loss:  0.00012673500168602914
Valid Loss:  0.0002962307189591229
Epoch:  476  	Training Loss: 0.00025286205345764756
Test Loss:  0.00012640884961001575
Valid Loss:  0.00029545812867581844
Epoch:  477  	Training Loss: 0.0002522410068195313
Test Loss:  0.00012608585529960692
Valid Loss:  0.0002946908352896571
Epoch:  478  	Training Loss: 0.00025162711972370744
Test Loss:  0.0001257659896509722
Valid Loss:  0.00029393157456070185
Epoch:  479  	Training Loss: 0.0002510146296117455
Test Loss:  0.00012544792843982577
Valid Loss:  0.0002931673952843994
Epoch:  480  	Training Loss: 0.00025040676700882614
Test Loss:  0.0001251318899448961
Valid Loss:  0.00029240711592137814
Epoch:  481  	Training Loss: 0.00024980359012261033
Test Loss:  0.00012481887824833393
Valid Loss:  0.0002916513476520777
Epoch:  482  	Training Loss: 0.0002492038765922189
Test Loss:  0.0001243896986125037
Valid Loss:  0.00029092023032717407
Epoch:  483  	Training Loss: 0.0002487488090991974
Test Loss:  0.0001240451238118112
Valid Loss:  0.000290318566840142
Epoch:  484  	Training Loss: 0.0002483209245838225
Test Loss:  0.00012374624202493578
Valid Loss:  0.0002897921949625015
Epoch:  485  	Training Loss: 0.00024790852330625057
Test Loss:  0.00012347596930339932
Valid Loss:  0.00028931634733453393
Epoch:  486  	Training Loss: 0.00024750822922214866
Test Loss:  0.00012322419206611812
Valid Loss:  0.00028887641383334994
Epoch:  487  	Training Loss: 0.00024711788864806294
Test Loss:  0.00012298289220780134
Valid Loss:  0.00028846479835920036
Epoch:  488  	Training Loss: 0.00024673592997714877
Test Loss:  0.00012275055632926524
Valid Loss:  0.00028807876515202224
Epoch:  489  	Training Loss: 0.0002463613636791706
Test Loss:  0.00012252561282366514
Valid Loss:  0.0002877094375435263
Epoch:  490  	Training Loss: 0.00024599352036602795
Test Loss:  0.0001223040308104828
Valid Loss:  0.00028735591331496835
Epoch:  491  	Training Loss: 0.00024563033366575837
Test Loss:  0.00012208793486934155
Valid Loss:  0.0002870180469471961
Epoch:  492  	Training Loss: 0.0002452752960380167
Test Loss:  0.00012193310249131173
Valid Loss:  0.00028713117353618145
Epoch:  493  	Training Loss: 0.0002447329752612859
Test Loss:  0.00012166965461801738
Valid Loss:  0.00028696071240119636
Epoch:  494  	Training Loss: 0.0002442560507915914
Test Loss:  0.00012139311002101749
Valid Loss:  0.0002866989525500685
Epoch:  495  	Training Loss: 0.0002438106166664511
Test Loss:  0.00012112872354919091
Valid Loss:  0.00028643017867580056
Epoch:  496  	Training Loss: 0.00024338958610314876
Test Loss:  0.00012088649964425713
Valid Loss:  0.0002861701068468392
Epoch:  497  	Training Loss: 0.00024298879725392908
Test Loss:  0.00012065340706612915
Valid Loss:  0.00028589152498170733
Epoch:  498  	Training Loss: 0.00024260036298073828
Test Loss:  0.00012042331218253821
Valid Loss:  0.00028559518977999687
Epoch:  499  	Training Loss: 0.00024222128558903933
Test Loss:  0.00012019976566080004
Valid Loss:  0.0002852855250239372
Epoch:  500  	Training Loss: 0.0002418479707557708
Test Loss:  0.0001199776743305847
Valid Loss:  0.00028496008599177003
seed is  18
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:31, 15.78it/s]  1%|          | 4/500 [00:00<00:30, 16.24it/s]  1%|          | 6/500 [00:00<00:30, 16.38it/s]  2%|▏         | 8/500 [00:00<00:32, 15.05it/s]  2%|▏         | 10/500 [00:00<00:31, 15.50it/s]  2%|▏         | 12/500 [00:00<00:30, 15.83it/s]  3%|▎         | 14/500 [00:00<00:30, 16.06it/s]  3%|▎         | 16/500 [00:01<00:29, 16.20it/s]  4%|▎         | 18/500 [00:01<00:29, 16.27it/s]  4%|▍         | 20/500 [00:01<00:29, 16.37it/s]  4%|▍         | 22/500 [00:01<00:29, 16.08it/s]  5%|▍         | 24/500 [00:01<00:29, 16.21it/s]  5%|▌         | 26/500 [00:01<00:29, 16.27it/s]  6%|▌         | 28/500 [00:01<00:28, 16.31it/s]  6%|▌         | 30/500 [00:01<00:28, 16.39it/s]  6%|▋         | 32/500 [00:01<00:28, 16.43it/s]  7%|▋         | 34/500 [00:02<00:28, 16.43it/s]  7%|▋         | 36/500 [00:02<00:28, 16.45it/s]  8%|▊         | 38/500 [00:02<00:28, 16.45it/s]  8%|▊         | 40/500 [00:02<00:28, 16.25it/s]  8%|▊         | 42/500 [00:02<00:28, 16.08it/s]  9%|▉         | 44/500 [00:02<00:28, 16.23it/s]  9%|▉         | 46/500 [00:02<00:27, 16.28it/s] 10%|▉         | 48/500 [00:02<00:27, 16.34it/s] 10%|█         | 50/500 [00:03<00:27, 16.36it/s] 10%|█         | 52/500 [00:03<00:27, 16.42it/s] 11%|█         | 54/500 [00:03<00:27, 16.48it/s] 11%|█         | 56/500 [00:03<00:26, 16.52it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.33it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.13it/s] 12%|█▏        | 62/500 [00:03<00:27, 16.22it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.26it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.36it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.11it/s] 14%|█▍        | 70/500 [00:04<00:28, 15.12it/s] 14%|█▍        | 72/500 [00:04<00:29, 14.70it/s] 15%|█▍        | 74/500 [00:04<00:28, 15.16it/s] 15%|█▌        | 76/500 [00:04<00:27, 15.46it/s] 16%|█▌        | 78/500 [00:04<00:27, 15.60it/s] 16%|█▌        | 80/500 [00:04<00:26, 15.67it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.75it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.91it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.01it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.16it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.26it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.34it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.42it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.42it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.44it/s] 20%|██        | 100/500 [00:06<00:24, 16.43it/s] 20%|██        | 102/500 [00:06<00:24, 16.39it/s] 21%|██        | 104/500 [00:06<00:24, 16.33it/s] 21%|██        | 106/500 [00:06<00:24, 16.27it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.34it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.36it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.40it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.50it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.34it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.38it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.47it/s] 24%|██▍       | 122/500 [00:07<00:24, 15.42it/s] 25%|██▍       | 124/500 [00:07<00:26, 14.33it/s]Epoch:  1  	Training Loss: 0.46929773688316345
Test Loss:  9950.7255859375
Valid Loss:  9945.7509765625
Epoch:  2  	Training Loss: 9921.6220703125
Test Loss:  9.92706915433374e+19
Valid Loss:  9.931563078258786e+19
Epoch:  3  	Training Loss: 9.957587199074291e+19
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:26, 14.06it/s] 26%|██▌       | 128/500 [00:08<00:27, 13.67it/s] 26%|██▌       | 130/500 [00:08<00:26, 13.94it/s] 26%|██▋       | 132/500 [00:08<00:25, 14.48it/s] 27%|██▋       | 134/500 [00:08<00:24, 14.98it/s] 27%|██▋       | 136/500 [00:08<00:23, 15.42it/s] 28%|██▊       | 138/500 [00:08<00:23, 15.73it/s] 28%|██▊       | 140/500 [00:08<00:22, 15.94it/s] 28%|██▊       | 142/500 [00:08<00:22, 16.09it/s] 29%|██▉       | 144/500 [00:09<00:22, 16.17it/s] 29%|██▉       | 146/500 [00:09<00:22, 15.86it/s] 30%|██▉       | 148/500 [00:09<00:23, 14.73it/s] 30%|███       | 150/500 [00:09<00:24, 14.06it/s] 30%|███       | 152/500 [00:09<00:23, 14.67it/s] 31%|███       | 154/500 [00:09<00:22, 15.16it/s] 31%|███       | 156/500 [00:09<00:22, 15.52it/s] 32%|███▏      | 158/500 [00:09<00:21, 15.79it/s] 32%|███▏      | 160/500 [00:10<00:21, 15.97it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.14it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.25it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.22it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.20it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.28it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.33it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.39it/s] 35%|███▌      | 176/500 [00:11<00:19, 16.41it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.44it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.14it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.20it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.28it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.24it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.27it/s] 38%|███▊      | 190/500 [00:11<00:19, 16.06it/s] 38%|███▊      | 192/500 [00:12<00:19, 15.96it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.79it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.92it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.05it/s] 40%|████      | 200/500 [00:12<00:18, 15.97it/s] 40%|████      | 202/500 [00:12<00:18, 15.75it/s] 41%|████      | 204/500 [00:12<00:18, 15.87it/s] 41%|████      | 206/500 [00:12<00:18, 16.07it/s] 42%|████▏     | 208/500 [00:13<00:18, 16.18it/s] 42%|████▏     | 210/500 [00:13<00:18, 16.08it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.13it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.11it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.26it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.30it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.28it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.32it/s] 45%|████▍     | 224/500 [00:14<00:16, 16.37it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.47it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.38it/s] 46%|████▌     | 230/500 [00:14<00:17, 15.28it/s] 46%|████▋     | 232/500 [00:14<00:17, 15.13it/s] 47%|████▋     | 234/500 [00:14<00:17, 15.53it/s] 47%|████▋     | 236/500 [00:14<00:16, 15.81it/s] 48%|████▊     | 238/500 [00:14<00:16, 15.83it/s] 48%|████▊     | 240/500 [00:15<00:16, 15.89it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.98it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.01it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.04it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.13it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.22it/s] 50%|█████     | 252/500 [00:15<00:15, 16.30it/s] 51%|█████     | 254/500 [00:15<00:15, 16.36it/s] 51%|█████     | 256/500 [00:16<00:14, 16.40it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.31it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.22it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.32it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.26it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.26it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.30it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.36it/s] 54%|█████▍    | 272/500 [00:17<00:14, 16.26it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.31it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.35it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.02it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.17it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.28it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.25it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.34it/s] 58%|█████▊    | 288/500 [00:18<00:12, 16.47it/s] 58%|█████▊    | 290/500 [00:18<00:12, 16.49it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.17it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.23it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.28it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.27it/s] 60%|██████    | 300/500 [00:18<00:12, 16.29it/s] 60%|██████    | 302/500 [00:18<00:12, 16.37it/s] 61%|██████    | 304/500 [00:18<00:11, 16.34it/s] 61%|██████    | 306/500 [00:19<00:11, 16.27it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.31it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.37it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.41it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.44it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.54it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.52it/s] 64%|██████▍   | 320/500 [00:19<00:10, 16.57it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.49it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.41it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.41it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.50it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.53it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.51it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.54it/s] 67%|██████▋   | 336/500 [00:20<00:09, 16.53it/s] 68%|██████▊   | 338/500 [00:21<00:09, 16.51it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.51it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.41it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.46it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.48it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.49it/s] 70%|███████   | 350/500 [00:21<00:09, 16.48it/s] 70%|███████   | 352/500 [00:21<00:09, 16.34it/s] 71%|███████   | 354/500 [00:22<00:08, 16.24it/s] 71%|███████   | 356/500 [00:22<00:08, 16.23it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.12it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.16it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.30it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.36it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.42it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.45it/s] 74%|███████▍  | 370/500 [00:23<00:07, 16.34it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.26it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.16it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.11it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.09it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.25it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.23it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.36it/s] 77%|███████▋  | 386/500 [00:24<00:06, 16.45it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.47it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.36it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.41it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.35it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.20it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.28it/s] 80%|████████  | 400/500 [00:24<00:06, 16.37it/s] 80%|████████  | 402/500 [00:24<00:06, 16.24it/s] 81%|████████  | 404/500 [00:25<00:05, 16.25it/s] 81%|████████  | 406/500 [00:25<00:05, 15.73it/s] 82%|████████▏ | 408/500 [00:25<00:05, 15.65it/s] 82%|████████▏ | 410/500 [00:25<00:05, 15.95it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.09it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.25it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.31it/s] 84%|████████▎ | 418/500 [00:25<00:05, 16.30it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.21it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.22it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.30it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.35it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.39it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.43it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.46it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.47it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.46it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.37it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.13it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.21it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.12it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.10it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.20it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.30it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.34it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.30it/s] 91%|█████████ | 456/500 [00:28<00:02, 15.72it/s] 92%|█████████▏| 458/500 [00:28<00:02, 14.71it/s] 92%|█████████▏| 460/500 [00:28<00:02, 13.81it/s] 92%|█████████▏| 462/500 [00:28<00:02, 13.21it/s] 93%|█████████▎| 464/500 [00:28<00:02, 12.81it/s] 93%|█████████▎| 466/500 [00:29<00:02, 12.96it/s] 94%|█████████▎| 468/500 [00:29<00:02, 13.82it/s] 94%|█████████▍| 470/500 [00:29<00:02, 14.51it/s] 94%|█████████▍| 472/500 [00:29<00:01, 14.94it/s] 95%|█████████▍| 474/500 [00:29<00:01, 15.32it/s] 95%|█████████▌| 476/500 [00:29<00:01, 15.64it/s] 96%|█████████▌| 478/500 [00:29<00:01, 15.76it/s] 96%|█████████▌| 480/500 [00:29<00:01, 15.89it/s] 96%|█████████▋| 482/500 [00:30<00:01, 16.12it/s] 97%|█████████▋| 484/500 [00:30<00:00, 16.23it/s] 97%|█████████▋| 486/500 [00:30<00:00, 16.28it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.33it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.37it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.42it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.45it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.36it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 16.45it/s]100%|██████████| 500/500 [00:31<00:00, 16.46it/s]100%|██████████| 500/500 [00:31<00:00, 16.02it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  18
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:02,  6.14s/it]  1%|          | 3/500 [00:06<13:37,  1.65s/it]  1%|          | 5/500 [00:06<06:52,  1.20it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:49,  1.33s/it]  3%|▎         | 13/500 [00:13<07:22,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:19<09:34,  1.20s/it]  5%|▍         | 23/500 [00:19<06:48,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:10,  1.17s/it]  7%|▋         | 33/500 [00:26<06:33,  1.19it/s]  7%|▋         | 35/500 [00:26<04:43,  1.64it/s]  7%|▋         | 37/500 [00:27<03:26,  2.24it/s]  8%|▊         | 39/500 [00:27<02:32,  3.02it/s]  8%|▊         | 41/500 [00:33<08:56,  1.17s/it]  9%|▊         | 43/500 [00:33<06:23,  1.19it/s]  9%|▉         | 45/500 [00:33<04:36,  1.64it/s]  9%|▉         | 47/500 [00:33<03:21,  2.25it/s] 10%|▉         | 49/500 [00:33<02:29,  3.02it/s] 10%|█         | 51/500 [00:40<08:50,  1.18s/it] 11%|█         | 53/500 [00:40<06:19,  1.18it/s] 11%|█         | 55/500 [00:40<04:33,  1.63it/s] 11%|█▏        | 57/500 [00:40<03:19,  2.23it/s] 12%|█▏        | 59/500 [00:40<02:27,  2.99it/s] 12%|█▏        | 61/500 [00:47<08:43,  1.19s/it] 13%|█▎        | 63/500 [00:47<06:14,  1.17it/s] 13%|█▎        | 65/500 [00:47<04:30,  1.61it/s] 13%|█▎        | 67/500 [00:47<03:16,  2.20it/s] 14%|█▍        | 69/500 [00:47<02:25,  2.96it/s] 14%|█▍        | 71/500 [00:54<08:26,  1.18s/it] 15%|█▍        | 73/500 [00:54<06:01,  1.18it/s]Epoch:  1  	Training Loss: 0.46929773688316345
Test Loss:  60.458106994628906
Valid Loss:  60.52605438232422
Epoch:  2  	Training Loss: 60.78912353515625
Test Loss:  0.3308143615722656
Valid Loss:  0.3356786072254181
Epoch:  3  	Training Loss: 0.29445621371269226
Test Loss:  0.3288796544075012
Valid Loss:  0.33372050523757935
Epoch:  4  	Training Loss: 0.29264944791793823
Test Loss:  0.32759496569633484
Valid Loss:  0.33242267370224
Epoch:  5  	Training Loss: 0.2914120554924011
Test Loss:  0.3275894522666931
Valid Loss:  0.3324170708656311
Epoch:  6  	Training Loss: 0.29140734672546387
Test Loss:  0.3275839686393738
Valid Loss:  0.3324114978313446
Epoch:  7  	Training Loss: 0.2914026379585266
Test Loss:  0.32757848501205444
Valid Loss:  0.3324058949947357
Epoch:  8  	Training Loss: 0.29139792919158936
Test Loss:  0.32757294178009033
Valid Loss:  0.3324003219604492
Epoch:  9  	Training Loss: 0.2913932502269745
Test Loss:  0.327567458152771
Valid Loss:  0.33239471912384033
Epoch:  10  	Training Loss: 0.29138854146003723
Test Loss:  0.32756197452545166
Valid Loss:  0.33238911628723145
Epoch:  11  	Training Loss: 0.29138386249542236
Test Loss:  0.3275564908981323
Valid Loss:  0.33238357305526733
Epoch:  12  	Training Loss: 0.2913791537284851
Test Loss:  0.32755395770072937
Valid Loss:  0.332381010055542
Epoch:  13  	Training Loss: 0.2913769483566284
Test Loss:  0.3275514245033264
Valid Loss:  0.33237844705581665
Epoch:  14  	Training Loss: 0.29137474298477173
Test Loss:  0.32754892110824585
Valid Loss:  0.3323758840560913
Epoch:  15  	Training Loss: 0.2913725674152374
Test Loss:  0.3275464177131653
Valid Loss:  0.33237332105636597
Epoch:  16  	Training Loss: 0.2913703918457031
Test Loss:  0.3275439143180847
Valid Loss:  0.332370787858963
Epoch:  17  	Training Loss: 0.29136818647384644
Test Loss:  0.3275413513183594
Valid Loss:  0.33236822485923767
Epoch:  18  	Training Loss: 0.29136598110198975
Test Loss:  0.3275388479232788
Valid Loss:  0.3323656916618347
Epoch:  19  	Training Loss: 0.29136380553245544
Test Loss:  0.32753634452819824
Valid Loss:  0.332363098859787
Epoch:  20  	Training Loss: 0.29136160016059875
Test Loss:  0.3275338411331177
Valid Loss:  0.33236056566238403
Epoch:  21  	Training Loss: 0.29135942459106445
Test Loss:  0.3275313377380371
Valid Loss:  0.3323580026626587
Epoch:  22  	Training Loss: 0.29135721921920776
Test Loss:  0.32752880454063416
Valid Loss:  0.33235543966293335
Epoch:  23  	Training Loss: 0.2913550138473511
Test Loss:  0.3275262713432312
Valid Loss:  0.3323529362678528
Epoch:  24  	Training Loss: 0.2913528382778168
Test Loss:  0.3275238275527954
Valid Loss:  0.33235034346580505
Epoch:  25  	Training Loss: 0.2913506329059601
Test Loss:  0.32752126455307007
Valid Loss:  0.3323477804660797
Epoch:  26  	Training Loss: 0.2913484573364258
Test Loss:  0.3275187611579895
Valid Loss:  0.33234524726867676
Epoch:  27  	Training Loss: 0.2913462519645691
Test Loss:  0.32751625776290894
Valid Loss:  0.3323426842689514
Epoch:  28  	Training Loss: 0.2913440465927124
Test Loss:  0.327513724565506
Valid Loss:  0.33234015107154846
Epoch:  29  	Training Loss: 0.2913418412208557
Test Loss:  0.3275112211704254
Valid Loss:  0.33233755826950073
Epoch:  30  	Training Loss: 0.291339635848999
Test Loss:  0.32750868797302246
Valid Loss:  0.33233505487442017
Epoch:  31  	Training Loss: 0.2913374602794647
Test Loss:  0.3275061845779419
Valid Loss:  0.3323324918746948
Epoch:  32  	Training Loss: 0.29133525490760803
Test Loss:  0.32750368118286133
Valid Loss:  0.3323299288749695
Epoch:  33  	Training Loss: 0.29133307933807373
Test Loss:  0.32750117778778076
Valid Loss:  0.33232739567756653
Epoch:  34  	Training Loss: 0.29133087396621704
Test Loss:  0.3274986743927002
Valid Loss:  0.3323248326778412
Epoch:  35  	Training Loss: 0.29132866859436035
Test Loss:  0.32749617099761963
Valid Loss:  0.33232229948043823
Epoch:  36  	Training Loss: 0.29132646322250366
Test Loss:  0.3274936378002167
Valid Loss:  0.3323197364807129
Epoch:  37  	Training Loss: 0.291324257850647
Test Loss:  0.3274911344051361
Valid Loss:  0.3323172330856323
Epoch:  38  	Training Loss: 0.29132211208343506
Test Loss:  0.32748863101005554
Valid Loss:  0.3323146402835846
Epoch:  39  	Training Loss: 0.29131990671157837
Test Loss:  0.32748615741729736
Valid Loss:  0.33231210708618164
Epoch:  40  	Training Loss: 0.2913177013397217
Test Loss:  0.3274836540222168
Valid Loss:  0.3323095738887787
Epoch:  41  	Training Loss: 0.2913155257701874
Test Loss:  0.32748115062713623
Valid Loss:  0.33230704069137573
Epoch:  42  	Training Loss: 0.2913133203983307
Test Loss:  0.3274785876274109
Valid Loss:  0.3323044776916504
Epoch:  43  	Training Loss: 0.2913110852241516
Test Loss:  0.3274760842323303
Valid Loss:  0.33230188488960266
Epoch:  44  	Training Loss: 0.29130885004997253
Test Loss:  0.3274734914302826
Valid Loss:  0.33229929208755493
Epoch:  45  	Training Loss: 0.29130661487579346
Test Loss:  0.327470988035202
Valid Loss:  0.3322967290878296
Epoch:  46  	Training Loss: 0.29130440950393677
Test Loss:  0.3274684548377991
Valid Loss:  0.33229416608810425
Epoch:  47  	Training Loss: 0.2913021445274353
Test Loss:  0.32746589183807373
Valid Loss:  0.3322915732860565
Epoch:  48  	Training Loss: 0.2912999391555786
Test Loss:  0.32746338844299316
Valid Loss:  0.3322889804840088
Epoch:  49  	Training Loss: 0.2912977337837219
Test Loss:  0.3274608254432678
Valid Loss:  0.33228641748428345
Epoch:  50  	Training Loss: 0.29129546880722046
Test Loss:  0.32745829224586487
Valid Loss:  0.3322838544845581
Epoch:  51  	Training Loss: 0.29129326343536377
Test Loss:  0.3274557292461395
Valid Loss:  0.3322812616825104
Epoch:  52  	Training Loss: 0.2912909984588623
Test Loss:  0.32745322585105896
Valid Loss:  0.3322787284851074
Epoch:  53  	Training Loss: 0.2912887930870056
Test Loss:  0.3274507224559784
Valid Loss:  0.3322761654853821
Epoch:  54  	Training Loss: 0.2912865877151489
Test Loss:  0.32744818925857544
Valid Loss:  0.3322736322879791
Epoch:  55  	Training Loss: 0.29128438234329224
Test Loss:  0.32744571566581726
Valid Loss:  0.33227109909057617
Epoch:  56  	Training Loss: 0.29128217697143555
Test Loss:  0.3274431824684143
Valid Loss:  0.33226853609085083
Epoch:  57  	Training Loss: 0.29127997159957886
Test Loss:  0.32744067907333374
Valid Loss:  0.3322659730911255
Epoch:  58  	Training Loss: 0.29127776622772217
Test Loss:  0.3274381756782532
Valid Loss:  0.33226343989372253
Epoch:  59  	Training Loss: 0.29127559065818787
Test Loss:  0.3274356722831726
Valid Loss:  0.3322609066963196
Epoch:  60  	Training Loss: 0.2912733554840088
Test Loss:  0.32743316888809204
Valid Loss:  0.33225834369659424
Epoch:  61  	Training Loss: 0.2912711501121521
Test Loss:  0.3274306654930115
Valid Loss:  0.3322557806968689
Epoch:  62  	Training Loss: 0.2912689447402954
Test Loss:  0.3274281322956085
Valid Loss:  0.33225321769714355
Epoch:  63  	Training Loss: 0.2912667393684387
Test Loss:  0.32742562890052795
Valid Loss:  0.332250714302063
Epoch:  64  	Training Loss: 0.29126453399658203
Test Loss:  0.327423095703125
Valid Loss:  0.33224815130233765
Epoch:  65  	Training Loss: 0.29126229882240295
Test Loss:  0.32742059230804443
Valid Loss:  0.3322456181049347
Epoch:  66  	Training Loss: 0.2912600636482239
Test Loss:  0.32741808891296387
Valid Loss:  0.33224305510520935
Epoch:  67  	Training Loss: 0.2912578582763672
Test Loss:  0.3274155855178833
Valid Loss:  0.332240492105484
Epoch:  68  	Training Loss: 0.2912556529045105
Test Loss:  0.32741305232048035
Valid Loss:  0.33223792910575867
Epoch:  69  	Training Loss: 0.2912534177303314
Test Loss:  0.3274105191230774
Valid Loss:  0.3322353959083557
Epoch:  70  	Training Loss: 0.2912512421607971
Test Loss:  0.3274080455303192
Valid Loss:  0.33223283290863037
Epoch:  71  	Training Loss: 0.29124903678894043
Test Loss:  0.32740551233291626
Valid Loss:  0.3322302997112274
Epoch:  72  	Training Loss: 0.29124680161476135
Test Loss:  0.3274030089378357
Valid Loss:  0.3322277367115021
Epoch:  73  	Training Loss: 0.2912445664405823
Test Loss:  0.32740047574043274
Valid Loss:  0.33222517371177673
Epoch:  74  	Training Loss: 0.2912423014640808
Test Loss:  0.3273979425430298
 15%|█▌        | 75/500 [00:54<04:20,  1.63it/s] 15%|█▌        | 77/500 [00:54<03:09,  2.23it/s] 16%|█▌        | 79/500 [00:54<02:20,  3.01it/s] 16%|█▌        | 81/500 [01:00<08:16,  1.18s/it] 17%|█▋        | 83/500 [01:01<05:54,  1.17it/s] 17%|█▋        | 85/500 [01:01<04:15,  1.62it/s] 17%|█▋        | 87/500 [01:01<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:01<02:18,  2.98it/s] 18%|█▊        | 91/500 [01:07<08:05,  1.19s/it] 19%|█▊        | 93/500 [01:07<05:47,  1.17it/s] 19%|█▉        | 95/500 [01:08<04:09,  1.62it/s] 19%|█▉        | 97/500 [01:08<03:01,  2.22it/s] 20%|█▉        | 99/500 [01:08<02:14,  2.98it/s] 20%|██        | 101/500 [01:14<07:57,  1.20s/it] 21%|██        | 103/500 [01:14<05:41,  1.16it/s] 21%|██        | 105/500 [01:15<04:05,  1.61it/s] 21%|██▏       | 107/500 [01:15<02:58,  2.20it/s] 22%|██▏       | 109/500 [01:15<02:12,  2.96it/s] 22%|██▏       | 111/500 [01:21<07:38,  1.18s/it] 23%|██▎       | 113/500 [01:21<05:27,  1.18it/s] 23%|██▎       | 115/500 [01:21<03:55,  1.63it/s] 23%|██▎       | 117/500 [01:22<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:22<02:06,  3.00it/s] 24%|██▍       | 121/500 [01:28<07:24,  1.17s/it] 25%|██▍       | 123/500 [01:28<05:17,  1.19it/s] 25%|██▌       | 125/500 [01:28<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:28<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:28<02:03,  3.01it/s] 26%|██▌       | 131/500 [01:35<07:21,  1.20s/it] 27%|██▋       | 133/500 [01:35<05:15,  1.17it/s] 27%|██▋       | 135/500 [01:35<03:46,  1.61it/s] 27%|██▋       | 137/500 [01:35<02:44,  2.20it/s] 28%|██▊       | 139/500 [01:35<02:01,  2.97it/s] 28%|██▊       | 141/500 [01:42<07:04,  1.18s/it] 29%|██▊       | 143/500 [01:42<05:03,  1.18it/s] 29%|██▉       | 145/500 [01:42<03:38,  1.63it/s] 29%|██▉       | 147/500 [01:42<02:38,  2.22it/s]Valid Loss:  0.332222580909729
Epoch:  75  	Training Loss: 0.2912400960922241
Test Loss:  0.3273954391479492
Valid Loss:  0.33222001791000366
Epoch:  76  	Training Loss: 0.29123786091804504
Test Loss:  0.32739290595054626
Valid Loss:  0.3322174549102783
Epoch:  77  	Training Loss: 0.29123562574386597
Test Loss:  0.3273903727531433
Valid Loss:  0.332214891910553
Epoch:  78  	Training Loss: 0.2912333607673645
Test Loss:  0.32738783955574036
Valid Loss:  0.33221235871315
Epoch:  79  	Training Loss: 0.2912311553955078
Test Loss:  0.3273853361606598
Valid Loss:  0.3322097659111023
Epoch:  80  	Training Loss: 0.29122889041900635
Test Loss:  0.32738280296325684
Valid Loss:  0.33220720291137695
Epoch:  81  	Training Loss: 0.29122668504714966
Test Loss:  0.3273802697658539
Valid Loss:  0.332204669713974
Epoch:  82  	Training Loss: 0.2912244498729706
Test Loss:  0.3273777365684509
Valid Loss:  0.33220207691192627
Epoch:  83  	Training Loss: 0.2912222146987915
Test Loss:  0.3273751735687256
Valid Loss:  0.3321995139122009
Epoch:  84  	Training Loss: 0.29121994972229004
Test Loss:  0.32737261056900024
Valid Loss:  0.3321969211101532
Epoch:  85  	Training Loss: 0.2912176847457886
Test Loss:  0.3273701071739197
Valid Loss:  0.33219432830810547
Epoch:  86  	Training Loss: 0.2912154495716095
Test Loss:  0.32736754417419434
Valid Loss:  0.33219173550605774
Epoch:  87  	Training Loss: 0.29121315479278564
Test Loss:  0.3273650109767914
Valid Loss:  0.33218914270401
Epoch:  88  	Training Loss: 0.29121091961860657
Test Loss:  0.3273624777793884
Valid Loss:  0.33218657970428467
Epoch:  89  	Training Loss: 0.2912086844444275
Test Loss:  0.3273599147796631
Valid Loss:  0.3321840167045593
Epoch:  90  	Training Loss: 0.291206419467926
Test Loss:  0.32735738158226013
Valid Loss:  0.332181453704834
Epoch:  91  	Training Loss: 0.29120415449142456
Test Loss:  0.3273548483848572
Valid Loss:  0.33217886090278625
Epoch:  92  	Training Loss: 0.2912018895149231
Test Loss:  0.3273523151874542
Valid Loss:  0.3321762681007385
Epoch:  93  	Training Loss: 0.2911996841430664
Test Loss:  0.32734978199005127
Valid Loss:  0.3321737051010132
Epoch:  94  	Training Loss: 0.29119741916656494
Test Loss:  0.3273472785949707
Valid Loss:  0.33217114210128784
Epoch:  95  	Training Loss: 0.29119518399238586
Test Loss:  0.32734474539756775
Valid Loss:  0.3321685791015625
Epoch:  96  	Training Loss: 0.2911929488182068
Test Loss:  0.3273422122001648
Valid Loss:  0.33216604590415955
Epoch:  97  	Training Loss: 0.2911906838417053
Test Loss:  0.32733970880508423
Valid Loss:  0.3321634829044342
Epoch:  98  	Training Loss: 0.29118844866752625
Test Loss:  0.3273371756076813
Valid Loss:  0.3321608901023865
Epoch:  99  	Training Loss: 0.29118621349334717
Test Loss:  0.3273346424102783
Valid Loss:  0.3321583569049835
Epoch:  100  	Training Loss: 0.2911839485168457
Test Loss:  0.32733213901519775
Valid Loss:  0.3321557939052582
Epoch:  101  	Training Loss: 0.2911817133426666
Test Loss:  0.3273296058177948
Valid Loss:  0.33215320110321045
Epoch:  102  	Training Loss: 0.29117947816848755
Test Loss:  0.32732701301574707
Valid Loss:  0.3321506381034851
Epoch:  103  	Training Loss: 0.2911771833896637
Test Loss:  0.3273244798183441
Valid Loss:  0.332148015499115
Epoch:  104  	Training Loss: 0.29117488861083984
Test Loss:  0.3273218870162964
Valid Loss:  0.33214542269706726
Epoch:  105  	Training Loss: 0.2911726236343384
Test Loss:  0.32731932401657104
Valid Loss:  0.33214282989501953
Epoch:  106  	Training Loss: 0.2911703288555145
Test Loss:  0.3273167610168457
Valid Loss:  0.3321402370929718
Epoch:  107  	Training Loss: 0.2911680340766907
Test Loss:  0.32731419801712036
Valid Loss:  0.3321376144886017
Epoch:  108  	Training Loss: 0.2911657392978668
Test Loss:  0.327311635017395
Valid Loss:  0.33213502168655396
Epoch:  109  	Training Loss: 0.29116347432136536
Test Loss:  0.3273090720176697
Valid Loss:  0.33213239908218384
Epoch:  110  	Training Loss: 0.2911611795425415
Test Loss:  0.32730650901794434
Valid Loss:  0.3321298360824585
Epoch:  111  	Training Loss: 0.29115888476371765
Test Loss:  0.327303946018219
Valid Loss:  0.3321272134780884
Epoch:  112  	Training Loss: 0.2911566197872162
Test Loss:  0.3273014426231384
Valid Loss:  0.33212465047836304
Epoch:  113  	Training Loss: 0.2911543548107147
Test Loss:  0.3272988796234131
Valid Loss:  0.3321220874786377
Epoch:  114  	Training Loss: 0.29115211963653564
Test Loss:  0.3272963762283325
Valid Loss:  0.33211952447891235
Epoch:  115  	Training Loss: 0.29114988446235657
Test Loss:  0.32729384303092957
Valid Loss:  0.332116961479187
Epoch:  116  	Training Loss: 0.2911475896835327
Test Loss:  0.327291339635849
Valid Loss:  0.33211439847946167
Epoch:  117  	Training Loss: 0.291145384311676
Test Loss:  0.32728880643844604
Valid Loss:  0.33211183547973633
Epoch:  118  	Training Loss: 0.2911430895328522
Test Loss:  0.3272862434387207
Valid Loss:  0.332109272480011
Epoch:  119  	Training Loss: 0.2911408543586731
Test Loss:  0.32728374004364014
Valid Loss:  0.33210670948028564
Epoch:  120  	Training Loss: 0.29113858938217163
Test Loss:  0.32728123664855957
Valid Loss:  0.3321041464805603
Epoch:  121  	Training Loss: 0.29113632440567017
Test Loss:  0.32727867364883423
Valid Loss:  0.33210158348083496
Epoch:  122  	Training Loss: 0.2911341190338135
Test Loss:  0.32727617025375366
Valid Loss:  0.3320990204811096
Epoch:  123  	Training Loss: 0.291131854057312
Test Loss:  0.3272736072540283
Valid Loss:  0.33209648728370667
Epoch:  124  	Training Loss: 0.29112958908081055
Test Loss:  0.32727110385894775
Valid Loss:  0.33209389448165894
Epoch:  125  	Training Loss: 0.2911273241043091
Test Loss:  0.3272686004638672
Valid Loss:  0.3320913314819336
Epoch:  126  	Training Loss: 0.2911250591278076
Test Loss:  0.32726603746414185
Valid Loss:  0.33208876848220825
Epoch:  127  	Training Loss: 0.29112279415130615
Test Loss:  0.3272635042667389
Valid Loss:  0.3320862054824829
Epoch:  128  	Training Loss: 0.2911205291748047
Test Loss:  0.32726097106933594
Valid Loss:  0.33208364248275757
Epoch:  129  	Training Loss: 0.2911182641983032
Test Loss:  0.32725846767425537
Valid Loss:  0.33208104968070984
Epoch:  130  	Training Loss: 0.29111599922180176
Test Loss:  0.32725590467453003
Valid Loss:  0.3320784866809845
Epoch:  131  	Training Loss: 0.2911137342453003
Test Loss:  0.3272533714771271
Valid Loss:  0.33207592368125916
Epoch:  132  	Training Loss: 0.29111146926879883
Test Loss:  0.32725080847740173
Valid Loss:  0.33207330107688904
Epoch:  133  	Training Loss: 0.2911091446876526
Test Loss:  0.327248215675354
Valid Loss:  0.3320706784725189
Epoch:  134  	Training Loss: 0.29110684990882874
Test Loss:  0.32724565267562866
Valid Loss:  0.3320680856704712
Epoch:  135  	Training Loss: 0.2911045551300049
Test Loss:  0.3272430896759033
Valid Loss:  0.3320654630661011
Epoch:  136  	Training Loss: 0.29110223054885864
Test Loss:  0.3272404968738556
Valid Loss:  0.33206284046173096
Epoch:  137  	Training Loss: 0.2910999357700348
Test Loss:  0.32723793387413025
Valid Loss:  0.3320602476596832
Epoch:  138  	Training Loss: 0.29109764099121094
Test Loss:  0.3272353410720825
Valid Loss:  0.3320576548576355
Epoch:  139  	Training Loss: 0.2910953462123871
Test Loss:  0.3272327780723572
Valid Loss:  0.3320550322532654
Epoch:  140  	Training Loss: 0.29109305143356323
Test Loss:  0.32723021507263184
Valid Loss:  0.33205240964889526
Epoch:  141  	Training Loss: 0.291090726852417
Test Loss:  0.3272276222705841
Valid Loss:  0.33204978704452515
Epoch:  142  	Training Loss: 0.29108840227127075
Test Loss:  0.32722511887550354
Valid Loss:  0.3320472538471222
Epoch:  143  	Training Loss: 0.2910861372947693
Test Loss:  0.3272225856781006
Valid Loss:  0.33204472064971924
Epoch:  144  	Training Loss: 0.2910839021205902
Test Loss:  0.32722008228302
Valid Loss:  0.3320421278476715
Epoch:  145  	Training Loss: 0.29108166694641113
Test Loss:  0.32721757888793945
Valid Loss:  0.33203959465026855
Epoch:  146  	Training Loss: 0.2910793721675873
Test Loss:  0.3272150456905365
Valid Loss:  0.3320370614528656
Epoch:  147  	Training Loss: 0.2910771369934082
Test Loss:  0.32721254229545593
Valid Loss:  0.33203449845314026
 30%|██▉       | 149/500 [01:42<01:57,  2.99it/s] 30%|███       | 151/500 [01:49<06:50,  1.18s/it] 31%|███       | 153/500 [01:49<04:52,  1.18it/s] 31%|███       | 155/500 [01:49<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:49<02:33,  2.24it/s] 32%|███▏      | 159/500 [01:49<01:53,  3.01it/s] 32%|███▏      | 161/500 [01:55<06:37,  1.17s/it] 33%|███▎      | 163/500 [01:55<04:44,  1.19it/s] 33%|███▎      | 165/500 [01:56<03:24,  1.64it/s] 33%|███▎      | 167/500 [01:56<02:28,  2.24it/s] 34%|███▍      | 169/500 [01:56<01:52,  2.93it/s] 34%|███▍      | 171/500 [02:02<06:24,  1.17s/it] 35%|███▍      | 173/500 [02:02<04:34,  1.19it/s] 35%|███▌      | 175/500 [02:02<03:17,  1.64it/s] 35%|███▌      | 177/500 [02:03<02:23,  2.25it/s] 36%|███▌      | 179/500 [02:03<01:46,  3.02it/s] 36%|███▌      | 181/500 [02:09<06:12,  1.17s/it] 37%|███▋      | 183/500 [02:09<04:25,  1.19it/s] 37%|███▋      | 185/500 [02:09<03:11,  1.65it/s] 37%|███▋      | 187/500 [02:09<02:19,  2.25it/s] 38%|███▊      | 189/500 [02:09<01:42,  3.02it/s] 38%|███▊      | 191/500 [02:16<06:01,  1.17s/it] 39%|███▊      | 193/500 [02:16<04:18,  1.19it/s] 39%|███▉      | 195/500 [02:16<03:05,  1.64it/s] 39%|███▉      | 197/500 [02:16<02:14,  2.25it/s] 40%|███▉      | 199/500 [02:16<01:39,  3.02it/s] 40%|████      | 201/500 [02:23<05:51,  1.17s/it] 41%|████      | 203/500 [02:23<04:10,  1.18it/s] 41%|████      | 205/500 [02:23<03:00,  1.64it/s] 41%|████▏     | 207/500 [02:23<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:23<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:29<05:37,  1.17s/it] 43%|████▎     | 213/500 [02:29<04:00,  1.19it/s] 43%|████▎     | 215/500 [02:30<02:52,  1.65it/s] 43%|████▎     | 217/500 [02:30<02:05,  2.25it/s] 44%|████▍     | 219/500 [02:30<01:33,  3.02it/s]Epoch:  148  	Training Loss: 0.29107487201690674
Test Loss:  0.327210009098053
Valid Loss:  0.3320319652557373
Epoch:  149  	Training Loss: 0.2910726070404053
Test Loss:  0.3272075057029724
Valid Loss:  0.33202940225601196
Epoch:  150  	Training Loss: 0.2910703420639038
Test Loss:  0.32720497250556946
Valid Loss:  0.3320268392562866
Epoch:  151  	Training Loss: 0.2910681366920471
Test Loss:  0.3272024989128113
Valid Loss:  0.3320242762565613
Epoch:  152  	Training Loss: 0.29106587171554565
Test Loss:  0.32719993591308594
Valid Loss:  0.33202171325683594
Epoch:  153  	Training Loss: 0.2910635769367218
Test Loss:  0.32719743251800537
Valid Loss:  0.3320191502571106
Epoch:  154  	Training Loss: 0.2910613417625427
Test Loss:  0.32719486951828003
Valid Loss:  0.33201658725738525
Epoch:  155  	Training Loss: 0.29105907678604126
Test Loss:  0.32719236612319946
Valid Loss:  0.3320140242576599
Epoch:  156  	Training Loss: 0.2910568118095398
Test Loss:  0.3271898031234741
Valid Loss:  0.33201146125793457
Epoch:  157  	Training Loss: 0.29105451703071594
Test Loss:  0.32718729972839355
Valid Loss:  0.33200886845588684
Epoch:  158  	Training Loss: 0.2910522222518921
Test Loss:  0.3271847367286682
Valid Loss:  0.3320063352584839
Epoch:  159  	Training Loss: 0.2910499572753906
Test Loss:  0.32718223333358765
Valid Loss:  0.33200377225875854
Epoch:  160  	Training Loss: 0.29104769229888916
Test Loss:  0.3271797001361847
Valid Loss:  0.3320011794567108
Epoch:  161  	Training Loss: 0.2910454273223877
Test Loss:  0.32717716693878174
Valid Loss:  0.33199864625930786
Epoch:  162  	Training Loss: 0.29104316234588623
Test Loss:  0.3271746039390564
Valid Loss:  0.33199605345726013
Epoch:  163  	Training Loss: 0.29104089736938477
Test Loss:  0.32717210054397583
Valid Loss:  0.3319934606552124
Epoch:  164  	Training Loss: 0.2910386025905609
Test Loss:  0.3271695375442505
Valid Loss:  0.33199092745780945
Epoch:  165  	Training Loss: 0.29103630781173706
Test Loss:  0.3271670341491699
Valid Loss:  0.3319883346557617
Epoch:  166  	Training Loss: 0.291034072637558
Test Loss:  0.3271644711494446
Valid Loss:  0.3319857716560364
Epoch:  167  	Training Loss: 0.29103177785873413
Test Loss:  0.327161967754364
Valid Loss:  0.33198320865631104
Epoch:  168  	Training Loss: 0.29102951288223267
Test Loss:  0.32715940475463867
Valid Loss:  0.3319805860519409
Epoch:  169  	Training Loss: 0.2910272181034088
Test Loss:  0.3271568715572357
Valid Loss:  0.33197808265686035
Epoch:  170  	Training Loss: 0.29102492332458496
Test Loss:  0.32715433835983276
Valid Loss:  0.3319754898548126
Epoch:  171  	Training Loss: 0.2910226583480835
Test Loss:  0.3271518051624298
Valid Loss:  0.3319728970527649
Epoch:  172  	Training Loss: 0.29102039337158203
Test Loss:  0.32714927196502686
Valid Loss:  0.33197033405303955
Epoch:  173  	Training Loss: 0.29101812839508057
Test Loss:  0.3271467089653015
Valid Loss:  0.3319677710533142
Epoch:  174  	Training Loss: 0.2910158336162567
Test Loss:  0.32714417576789856
Valid Loss:  0.3319651782512665
Epoch:  175  	Training Loss: 0.29101353883743286
Test Loss:  0.3271416425704956
Valid Loss:  0.33196261525154114
Epoch:  176  	Training Loss: 0.2910112738609314
Test Loss:  0.32713913917541504
Valid Loss:  0.3319600224494934
Epoch:  177  	Training Loss: 0.29100897908210754
Test Loss:  0.3271365761756897
Valid Loss:  0.33195745944976807
Epoch:  178  	Training Loss: 0.2910067141056061
Test Loss:  0.32713401317596436
Valid Loss:  0.3319548964500427
Epoch:  179  	Training Loss: 0.2910044193267822
Test Loss:  0.3271315097808838
Valid Loss:  0.331952303647995
Epoch:  180  	Training Loss: 0.29100215435028076
Test Loss:  0.32712894678115845
Valid Loss:  0.33194974064826965
Epoch:  181  	Training Loss: 0.2909998595714569
Test Loss:  0.3271264433860779
Valid Loss:  0.3319471478462219
Epoch:  182  	Training Loss: 0.29099756479263306
Test Loss:  0.3271239101886749
Valid Loss:  0.33194461464881897
Epoch:  183  	Training Loss: 0.2909952998161316
Test Loss:  0.327121376991272
Valid Loss:  0.331942081451416
Epoch:  184  	Training Loss: 0.2909930944442749
Test Loss:  0.327118843793869
Valid Loss:  0.3319394886493683
Epoch:  185  	Training Loss: 0.29099079966545105
Test Loss:  0.32711631059646606
Valid Loss:  0.33193695545196533
Epoch:  186  	Training Loss: 0.2909885346889496
Test Loss:  0.3271138072013855
Valid Loss:  0.33193439245224
Epoch:  187  	Training Loss: 0.2909862697124481
Test Loss:  0.32711130380630493
Valid Loss:  0.33193182945251465
Epoch:  188  	Training Loss: 0.29098403453826904
Test Loss:  0.32710880041122437
Valid Loss:  0.3319292664527893
Epoch:  189  	Training Loss: 0.2909817695617676
Test Loss:  0.3271062672138214
Valid Loss:  0.33192670345306396
Epoch:  190  	Training Loss: 0.2909795045852661
Test Loss:  0.32710376381874084
Valid Loss:  0.3319242000579834
Epoch:  191  	Training Loss: 0.29097723960876465
Test Loss:  0.3271012306213379
Valid Loss:  0.33192163705825806
Epoch:  192  	Training Loss: 0.2909749746322632
Test Loss:  0.3270987272262573
Valid Loss:  0.3319191038608551
Epoch:  193  	Training Loss: 0.2909727096557617
Test Loss:  0.32709622383117676
Valid Loss:  0.33191654086112976
Epoch:  194  	Training Loss: 0.29097044467926025
Test Loss:  0.3270936608314514
Valid Loss:  0.3319139778614044
Epoch:  195  	Training Loss: 0.2909682095050812
Test Loss:  0.32709118723869324
Valid Loss:  0.33191144466400146
Epoch:  196  	Training Loss: 0.2909659445285797
Test Loss:  0.3270886540412903
Valid Loss:  0.3319088816642761
Epoch:  197  	Training Loss: 0.29096370935440063
Test Loss:  0.3270861506462097
Valid Loss:  0.33190634846687317
Epoch:  198  	Training Loss: 0.29096144437789917
Test Loss:  0.32708364725112915
Valid Loss:  0.3319037854671478
Epoch:  199  	Training Loss: 0.2909591794013977
Test Loss:  0.3270811140537262
Valid Loss:  0.3319012224674225
Epoch:  200  	Training Loss: 0.29095691442489624
Test Loss:  0.32707861065864563
Valid Loss:  0.33189868927001953
Epoch:  201  	Training Loss: 0.2909546494483948
Test Loss:  0.32707610726356506
Valid Loss:  0.3318961262702942
Epoch:  202  	Training Loss: 0.2909524142742157
Test Loss:  0.3270735740661621
Valid Loss:  0.33189359307289124
Epoch:  203  	Training Loss: 0.29095011949539185
Test Loss:  0.32707104086875916
Valid Loss:  0.3318910002708435
Epoch:  204  	Training Loss: 0.29094788432121277
Test Loss:  0.3270685076713562
Valid Loss:  0.33188843727111816
Epoch:  205  	Training Loss: 0.2909455895423889
Test Loss:  0.32706600427627563
Valid Loss:  0.3318858742713928
Epoch:  206  	Training Loss: 0.29094332456588745
Test Loss:  0.3270634710788727
Valid Loss:  0.33188334107398987
Epoch:  207  	Training Loss: 0.290941059589386
Test Loss:  0.3270609378814697
Valid Loss:  0.3318807780742645
Epoch:  208  	Training Loss: 0.2909387946128845
Test Loss:  0.32705843448638916
Valid Loss:  0.3318781852722168
Epoch:  209  	Training Loss: 0.29093652963638306
Test Loss:  0.3270559012889862
Valid Loss:  0.33187565207481384
Epoch:  210  	Training Loss: 0.2909342646598816
Test Loss:  0.32705336809158325
Valid Loss:  0.3318730890750885
Epoch:  211  	Training Loss: 0.2909319996833801
Test Loss:  0.3270508348941803
Valid Loss:  0.33187052607536316
Epoch:  212  	Training Loss: 0.29092973470687866
Test Loss:  0.3270483613014221
Valid Loss:  0.3318679928779602
Epoch:  213  	Training Loss: 0.2909274697303772
Test Loss:  0.32704585790634155
Valid Loss:  0.33186548948287964
Epoch:  214  	Training Loss: 0.2909252643585205
Test Loss:  0.3270433843135834
Valid Loss:  0.3318629860877991
Epoch:  215  	Training Loss: 0.29092302918434143
Test Loss:  0.3270409107208252
Valid Loss:  0.33186042308807373
Epoch:  216  	Training Loss: 0.29092079401016235
Test Loss:  0.32703840732574463
Valid Loss:  0.33185791969299316
Epoch:  217  	Training Loss: 0.29091858863830566
Test Loss:  0.32703590393066406
Valid Loss:  0.3318554162979126
Epoch:  218  	Training Loss: 0.2909163236618042
Test Loss:  0.32703346014022827
Valid Loss:  0.33185288310050964
Epoch:  219  	Training Loss: 0.2909141182899475
Test Loss:  0.3270309567451477
Valid Loss:  0.3318503499031067
Epoch:  220  	Training Loss: 0.29091188311576843
Test Loss:  0.3270284831523895
Valid Loss:  0.3318478465080261
 44%|████▍     | 221/500 [02:36<05:29,  1.18s/it] 45%|████▍     | 223/500 [02:36<03:55,  1.18it/s] 45%|████▌     | 225/500 [02:36<02:50,  1.61it/s] 45%|████▌     | 227/500 [02:37<02:03,  2.20it/s] 46%|████▌     | 229/500 [02:37<01:31,  2.95it/s] 46%|████▌     | 231/500 [02:43<05:15,  1.17s/it] 47%|████▋     | 233/500 [02:43<03:45,  1.18it/s] 47%|████▋     | 235/500 [02:43<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:43<01:57,  2.24it/s] 48%|████▊     | 239/500 [02:44<01:26,  3.00it/s] 48%|████▊     | 241/500 [02:50<05:04,  1.18s/it] 49%|████▊     | 243/500 [02:50<03:37,  1.18it/s] 49%|████▉     | 245/500 [02:50<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:50<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:50<01:24,  2.98it/s] 50%|█████     | 251/500 [02:57<04:52,  1.18s/it] 51%|█████     | 253/500 [02:57<03:29,  1.18it/s] 51%|█████     | 255/500 [02:57<02:31,  1.62it/s] 51%|█████▏    | 257/500 [02:57<01:49,  2.21it/s] 52%|█████▏    | 259/500 [02:57<01:21,  2.97it/s] 52%|█████▏    | 261/500 [03:04<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:04<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:04<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:04<01:44,  2.23it/s] 54%|█████▍    | 269/500 [03:04<01:16,  3.00it/s] 54%|█████▍    | 271/500 [03:10<04:31,  1.18s/it] 55%|█████▍    | 273/500 [03:11<03:12,  1.18it/s] 55%|█████▌    | 275/500 [03:11<02:18,  1.63it/s] 55%|█████▌    | 277/500 [03:11<01:40,  2.22it/s] 56%|█████▌    | 279/500 [03:11<01:14,  2.98it/s] 56%|█████▌    | 281/500 [03:17<04:17,  1.18s/it] 57%|█████▋    | 283/500 [03:17<03:03,  1.19it/s] 57%|█████▋    | 285/500 [03:17<02:11,  1.64it/s] 57%|█████▋    | 287/500 [03:18<01:35,  2.24it/s] 58%|█████▊    | 289/500 [03:18<01:10,  2.99it/s] 58%|█████▊    | 291/500 [03:24<04:01,  1.16s/it] 59%|█████▊    | 293/500 [03:24<02:52,  1.20it/s]Epoch:  221  	Training Loss: 0.29090964794158936
Test Loss:  0.32702597975730896
Valid Loss:  0.33184531331062317
Epoch:  222  	Training Loss: 0.2909074127674103
Test Loss:  0.3270234763622284
Valid Loss:  0.3318427801132202
Epoch:  223  	Training Loss: 0.2909051775932312
Test Loss:  0.3270210027694702
Valid Loss:  0.33184027671813965
Epoch:  224  	Training Loss: 0.2909029424190521
Test Loss:  0.32701849937438965
Valid Loss:  0.3318377137184143
Epoch:  225  	Training Loss: 0.29090070724487305
Test Loss:  0.3270159959793091
Valid Loss:  0.33183521032333374
Epoch:  226  	Training Loss: 0.29089847207069397
Test Loss:  0.3270134925842285
Valid Loss:  0.3318326771259308
Epoch:  227  	Training Loss: 0.2908962368965149
Test Loss:  0.32701101899147034
Valid Loss:  0.33183014392852783
Epoch:  228  	Training Loss: 0.2908940315246582
Test Loss:  0.32700854539871216
Valid Loss:  0.3318276107311249
Epoch:  229  	Training Loss: 0.29089176654815674
Test Loss:  0.3270060122013092
Valid Loss:  0.3318250775337219
Epoch:  230  	Training Loss: 0.29088953137397766
Test Loss:  0.32700350880622864
Valid Loss:  0.33182254433631897
Epoch:  231  	Training Loss: 0.2908872961997986
Test Loss:  0.32700100541114807
Valid Loss:  0.331820011138916
Epoch:  232  	Training Loss: 0.2908850312232971
Test Loss:  0.32699859142303467
Valid Loss:  0.33181753754615784
Epoch:  233  	Training Loss: 0.2908828854560852
Test Loss:  0.3269961476325989
Valid Loss:  0.33181506395339966
Epoch:  234  	Training Loss: 0.2908806800842285
Test Loss:  0.3269937038421631
Valid Loss:  0.3318125605583191
Epoch:  235  	Training Loss: 0.2908784747123718
Test Loss:  0.3269912600517273
Valid Loss:  0.3318101167678833
Epoch:  236  	Training Loss: 0.2908763289451599
Test Loss:  0.3269888460636139
Valid Loss:  0.33180761337280273
Epoch:  237  	Training Loss: 0.2908741235733032
Test Loss:  0.3269863724708557
Valid Loss:  0.33180516958236694
Epoch:  238  	Training Loss: 0.2908719480037689
Test Loss:  0.3269839584827423
Valid Loss:  0.3318026661872864
Epoch:  239  	Training Loss: 0.2908697724342346
Test Loss:  0.3269815146923065
Valid Loss:  0.3318001925945282
Epoch:  240  	Training Loss: 0.2908675968647003
Test Loss:  0.3269790709018707
Valid Loss:  0.3317977488040924
Epoch:  241  	Training Loss: 0.29086539149284363
Test Loss:  0.3269766569137573
Valid Loss:  0.33179527521133423
Epoch:  242  	Training Loss: 0.2908632159233093
Test Loss:  0.32697412371635437
Valid Loss:  0.3317927122116089
Epoch:  243  	Training Loss: 0.29086101055145264
Test Loss:  0.3269716501235962
Valid Loss:  0.3317902088165283
Epoch:  244  	Training Loss: 0.29085874557495117
Test Loss:  0.326969176530838
Valid Loss:  0.33178770542144775
Epoch:  245  	Training Loss: 0.2908565402030945
Test Loss:  0.32696670293807983
Valid Loss:  0.3317851722240448
Epoch:  246  	Training Loss: 0.2908543348312378
Test Loss:  0.32696419954299927
Valid Loss:  0.33178263902664185
Epoch:  247  	Training Loss: 0.29085206985473633
Test Loss:  0.3269616961479187
Valid Loss:  0.3317801356315613
Epoch:  248  	Training Loss: 0.29084986448287964
Test Loss:  0.3269592225551605
Valid Loss:  0.3317776024341583
Epoch:  249  	Training Loss: 0.29084765911102295
Test Loss:  0.32695671916007996
Valid Loss:  0.33177506923675537
Epoch:  250  	Training Loss: 0.29084542393684387
Test Loss:  0.3269542455673218
Valid Loss:  0.3317725658416748
Epoch:  251  	Training Loss: 0.2908431887626648
Test Loss:  0.3269517421722412
Valid Loss:  0.33177003264427185
Epoch:  252  	Training Loss: 0.2908409535884857
Test Loss:  0.3269492983818054
Valid Loss:  0.33176755905151367
Epoch:  253  	Training Loss: 0.2908387780189514
Test Loss:  0.32694685459136963
Valid Loss:  0.3317650556564331
Epoch:  254  	Training Loss: 0.2908366024494171
Test Loss:  0.32694441080093384
Valid Loss:  0.3317625820636749
Epoch:  255  	Training Loss: 0.2908343970775604
Test Loss:  0.32694196701049805
Valid Loss:  0.33176010847091675
Epoch:  256  	Training Loss: 0.2908322513103485
Test Loss:  0.32693952322006226
Valid Loss:  0.33175763487815857
Epoch:  257  	Training Loss: 0.2908300757408142
Test Loss:  0.32693707942962646
Valid Loss:  0.3317551612854004
Epoch:  258  	Training Loss: 0.2908278703689575
Test Loss:  0.32693466544151306
Valid Loss:  0.3317526876926422
Epoch:  259  	Training Loss: 0.2908256947994232
Test Loss:  0.32693222165107727
Valid Loss:  0.33175021409988403
Epoch:  260  	Training Loss: 0.2908235192298889
Test Loss:  0.32692980766296387
Valid Loss:  0.33174774050712585
Epoch:  261  	Training Loss: 0.2908213436603546
Test Loss:  0.3269273638725281
Valid Loss:  0.3317452669143677
Epoch:  262  	Training Loss: 0.2908191680908203
Test Loss:  0.3269249200820923
Valid Loss:  0.3317428231239319
Epoch:  263  	Training Loss: 0.2908170223236084
Test Loss:  0.3269225060939789
Valid Loss:  0.3317403793334961
Epoch:  264  	Training Loss: 0.2908148765563965
Test Loss:  0.3269200921058655
Valid Loss:  0.3317379057407379
Epoch:  265  	Training Loss: 0.29081273078918457
Test Loss:  0.3269176483154297
Valid Loss:  0.3317354619503021
Epoch:  266  	Training Loss: 0.29081055521965027
Test Loss:  0.32691526412963867
Valid Loss:  0.33173301815986633
Epoch:  267  	Training Loss: 0.29080837965011597
Test Loss:  0.3269128203392029
Valid Loss:  0.33173054456710815
Epoch:  268  	Training Loss: 0.29080623388290405
Test Loss:  0.32691043615341187
Valid Loss:  0.33172813057899475
Epoch:  269  	Training Loss: 0.29080408811569214
Test Loss:  0.3269079923629761
Valid Loss:  0.3317256569862366
Epoch:  270  	Training Loss: 0.2908019721508026
Test Loss:  0.32690560817718506
Valid Loss:  0.3317232131958008
Epoch:  271  	Training Loss: 0.2907997965812683
Test Loss:  0.32690316438674927
Valid Loss:  0.331720769405365
Epoch:  272  	Training Loss: 0.2907976508140564
Test Loss:  0.32690075039863586
Valid Loss:  0.3317182660102844
Epoch:  273  	Training Loss: 0.2907955050468445
Test Loss:  0.3268983066082001
Valid Loss:  0.33171582221984863
Epoch:  274  	Training Loss: 0.2907933294773102
Test Loss:  0.32689589262008667
Valid Loss:  0.33171334862709045
Epoch:  275  	Training Loss: 0.2907911539077759
Test Loss:  0.3268934190273285
Valid Loss:  0.3317108750343323
Epoch:  276  	Training Loss: 0.2907889783382416
Test Loss:  0.3268910050392151
Valid Loss:  0.3317084014415741
Epoch:  277  	Training Loss: 0.2907868027687073
Test Loss:  0.3268885314464569
Valid Loss:  0.3317059278488159
Epoch:  278  	Training Loss: 0.29078465700149536
Test Loss:  0.3268861174583435
Valid Loss:  0.33170342445373535
Epoch:  279  	Training Loss: 0.29078245162963867
Test Loss:  0.3268836736679077
Valid Loss:  0.33170098066329956
Epoch:  280  	Training Loss: 0.29078027606010437
Test Loss:  0.3268812298774719
Valid Loss:  0.331698477268219
Epoch:  281  	Training Loss: 0.29077813029289246
Test Loss:  0.32687878608703613
Valid Loss:  0.3316960334777832
Epoch:  282  	Training Loss: 0.29077595472335815
Test Loss:  0.32687637209892273
Valid Loss:  0.33169353008270264
Epoch:  283  	Training Loss: 0.29077380895614624
Test Loss:  0.32687392830848694
Valid Loss:  0.33169105648994446
Epoch:  284  	Training Loss: 0.29077163338661194
Test Loss:  0.32687148451805115
Valid Loss:  0.3316885828971863
Epoch:  285  	Training Loss: 0.29076945781707764
Test Loss:  0.32686904072761536
Valid Loss:  0.3316861093044281
Epoch:  286  	Training Loss: 0.2907673120498657
Test Loss:  0.32686662673950195
Valid Loss:  0.3316836357116699
Epoch:  287  	Training Loss: 0.29076510667800903
Test Loss:  0.32686418294906616
Valid Loss:  0.33168119192123413
Epoch:  288  	Training Loss: 0.2907629609107971
Test Loss:  0.32686173915863037
Valid Loss:  0.33167871832847595
Epoch:  289  	Training Loss: 0.2907608151435852
Test Loss:  0.3268592953681946
Valid Loss:  0.3316762447357178
Epoch:  290  	Training Loss: 0.2907586395740509
Test Loss:  0.3268568515777588
Valid Loss:  0.3316737413406372
Epoch:  291  	Training Loss: 0.2907565236091614
Test Loss:  0.3268544375896454
Valid Loss:  0.3316712975502014
Epoch:  292  	Training Loss: 0.2907543480396271
Test Loss:  0.3268519639968872
Valid Loss:  0.33166882395744324
Epoch:  293  	Training Loss: 0.2907521724700928
Test Loss:  0.3268495202064514
Valid Loss:  0.33166635036468506
 59%|█████▉    | 295/500 [03:24<02:03,  1.66it/s] 59%|█████▉    | 297/500 [03:24<01:29,  2.27it/s] 60%|█████▉    | 299/500 [03:24<01:05,  3.05it/s] 60%|██████    | 301/500 [03:31<03:55,  1.18s/it] 61%|██████    | 303/500 [03:31<02:47,  1.18it/s] 61%|██████    | 305/500 [03:31<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:31<01:26,  2.23it/s] 62%|██████▏   | 309/500 [03:31<01:03,  2.99it/s] 62%|██████▏   | 311/500 [03:38<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:38<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:38<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:38<01:22,  2.21it/s] 64%|██████▍   | 319/500 [03:38<01:01,  2.95it/s] 64%|██████▍   | 321/500 [03:45<03:32,  1.19s/it] 65%|██████▍   | 323/500 [03:45<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:45<01:47,  1.62it/s] 65%|██████▌   | 327/500 [03:45<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:45<00:57,  2.97it/s] 66%|██████▌   | 331/500 [03:51<03:18,  1.17s/it] 67%|██████▋   | 333/500 [03:52<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:52<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:52<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:52<00:53,  3.01it/s] 68%|██████▊   | 341/500 [03:58<03:05,  1.17s/it] 69%|██████▊   | 343/500 [03:58<02:11,  1.19it/s] 69%|██████▉   | 345/500 [03:58<01:34,  1.65it/s] 69%|██████▉   | 347/500 [03:59<01:07,  2.25it/s] 70%|██████▉   | 349/500 [03:59<00:49,  3.02it/s] 70%|███████   | 351/500 [04:05<02:53,  1.17s/it] 71%|███████   | 353/500 [04:05<02:03,  1.19it/s] 71%|███████   | 355/500 [04:05<01:27,  1.65it/s] 71%|███████▏  | 357/500 [04:05<01:03,  2.26it/s] 72%|███████▏  | 359/500 [04:05<00:46,  3.03it/s] 72%|███████▏  | 361/500 [04:12<02:41,  1.16s/it] 73%|███████▎  | 363/500 [04:12<01:54,  1.20it/s] 73%|███████▎  | 365/500 [04:12<01:21,  1.65it/s]Epoch:  294  	Training Loss: 0.29074999690055847
Test Loss:  0.3268470764160156
Valid Loss:  0.3316638469696045
Epoch:  295  	Training Loss: 0.29074782133102417
Test Loss:  0.32684463262557983
Valid Loss:  0.3316613733768463
Epoch:  296  	Training Loss: 0.29074564576148987
Test Loss:  0.32684218883514404
Valid Loss:  0.33165889978408813
Epoch:  297  	Training Loss: 0.29074347019195557
Test Loss:  0.32683974504470825
Valid Loss:  0.33165639638900757
Epoch:  298  	Training Loss: 0.29074132442474365
Test Loss:  0.32683730125427246
Valid Loss:  0.331653892993927
Epoch:  299  	Training Loss: 0.29073914885520935
Test Loss:  0.32683485746383667
Valid Loss:  0.3316514194011688
Epoch:  300  	Training Loss: 0.29073697328567505
Test Loss:  0.3268324136734009
Valid Loss:  0.33164894580841064
Epoch:  301  	Training Loss: 0.29073482751846313
Test Loss:  0.3268299400806427
Valid Loss:  0.3316464424133301
Epoch:  302  	Training Loss: 0.29073262214660645
Test Loss:  0.3268275260925293
Valid Loss:  0.3316439688205719
Epoch:  303  	Training Loss: 0.29073047637939453
Test Loss:  0.3268250823020935
Valid Loss:  0.3316415250301361
Epoch:  304  	Training Loss: 0.2907283306121826
Test Loss:  0.3268226385116577
Valid Loss:  0.33163905143737793
Epoch:  305  	Training Loss: 0.2907261848449707
Test Loss:  0.3268202245235443
Valid Loss:  0.33163657784461975
Epoch:  306  	Training Loss: 0.2907240390777588
Test Loss:  0.3268178105354309
Valid Loss:  0.3316341042518616
Epoch:  307  	Training Loss: 0.2907218635082245
Test Loss:  0.3268153667449951
Valid Loss:  0.3316316604614258
Epoch:  308  	Training Loss: 0.29071974754333496
Test Loss:  0.3268129527568817
Valid Loss:  0.3316291570663452
Epoch:  309  	Training Loss: 0.29071757197380066
Test Loss:  0.3268105089664459
Valid Loss:  0.3316267132759094
Epoch:  310  	Training Loss: 0.29071542620658875
Test Loss:  0.3268080949783325
Valid Loss:  0.33162426948547363
Epoch:  311  	Training Loss: 0.29071325063705444
Test Loss:  0.32680565118789673
Valid Loss:  0.33162176609039307
Epoch:  312  	Training Loss: 0.2907111346721649
Test Loss:  0.32680314779281616
Valid Loss:  0.3316192626953125
Epoch:  313  	Training Loss: 0.2907089591026306
Test Loss:  0.326800674200058
Valid Loss:  0.33161675930023193
Epoch:  314  	Training Loss: 0.2907067537307739
Test Loss:  0.3267982006072998
Valid Loss:  0.33161425590515137
Epoch:  315  	Training Loss: 0.29070454835891724
Test Loss:  0.32679569721221924
Valid Loss:  0.3316117227077484
Epoch:  316  	Training Loss: 0.29070237278938293
Test Loss:  0.32679322361946106
Valid Loss:  0.33160918951034546
Epoch:  317  	Training Loss: 0.29070013761520386
Test Loss:  0.3267907500267029
Valid Loss:  0.3316066563129425
Epoch:  318  	Training Loss: 0.29069796204566956
Test Loss:  0.3267882466316223
Valid Loss:  0.33160412311553955
Epoch:  319  	Training Loss: 0.29069578647613525
Test Loss:  0.3267858028411865
Valid Loss:  0.331601619720459
Epoch:  320  	Training Loss: 0.29069358110427856
Test Loss:  0.32678329944610596
Valid Loss:  0.3315991163253784
Epoch:  321  	Training Loss: 0.2906913757324219
Test Loss:  0.3267807960510254
Valid Loss:  0.33159661293029785
Epoch:  322  	Training Loss: 0.2906892001628876
Test Loss:  0.3267782926559448
Valid Loss:  0.3315940499305725
Epoch:  323  	Training Loss: 0.2906869649887085
Test Loss:  0.32677581906318665
Valid Loss:  0.33159154653549194
Epoch:  324  	Training Loss: 0.2906848192214966
Test Loss:  0.32677334547042847
Valid Loss:  0.3315889835357666
Epoch:  325  	Training Loss: 0.2906825840473175
Test Loss:  0.3267708420753479
Valid Loss:  0.33158648014068604
Epoch:  326  	Training Loss: 0.2906803786754608
Test Loss:  0.32676833868026733
Valid Loss:  0.3315839171409607
Epoch:  327  	Training Loss: 0.2906782031059265
Test Loss:  0.32676583528518677
Valid Loss:  0.33158138394355774
Epoch:  328  	Training Loss: 0.2906759977340698
Test Loss:  0.3267633616924286
Valid Loss:  0.3315788507461548
Epoch:  329  	Training Loss: 0.29067379236221313
Test Loss:  0.3267608880996704
Valid Loss:  0.3315763473510742
Epoch:  330  	Training Loss: 0.29067161679267883
Test Loss:  0.32675838470458984
Valid Loss:  0.33157381415367126
Epoch:  331  	Training Loss: 0.29066941142082214
Test Loss:  0.3267558813095093
Valid Loss:  0.3315712809562683
Epoch:  332  	Training Loss: 0.29066720604896545
Test Loss:  0.3267534375190735
Valid Loss:  0.33156877756118774
Epoch:  333  	Training Loss: 0.29066503047943115
Test Loss:  0.3267509639263153
Valid Loss:  0.33156630396842957
Epoch:  334  	Training Loss: 0.29066288471221924
Test Loss:  0.3267485201358795
Valid Loss:  0.3315637707710266
Epoch:  335  	Training Loss: 0.2906607389450073
Test Loss:  0.32674604654312134
Valid Loss:  0.3315613269805908
Epoch:  336  	Training Loss: 0.2906585931777954
Test Loss:  0.32674360275268555
Valid Loss:  0.33155882358551025
Epoch:  337  	Training Loss: 0.2906564176082611
Test Loss:  0.32674112915992737
Valid Loss:  0.3315563201904297
Epoch:  338  	Training Loss: 0.2906542420387268
Test Loss:  0.3267386853694916
Valid Loss:  0.3315538167953491
Epoch:  339  	Training Loss: 0.2906520962715149
Test Loss:  0.3267362415790558
Valid Loss:  0.33155131340026855
Epoch:  340  	Training Loss: 0.290649950504303
Test Loss:  0.3267337679862976
Valid Loss:  0.331548810005188
Epoch:  341  	Training Loss: 0.2906477749347687
Test Loss:  0.32673129439353943
Valid Loss:  0.3315463066101074
Epoch:  342  	Training Loss: 0.2906455993652344
Test Loss:  0.32672882080078125
Valid Loss:  0.33154377341270447
Epoch:  343  	Training Loss: 0.2906434237957001
Test Loss:  0.3267263174057007
Valid Loss:  0.3315412402153015
Epoch:  344  	Training Loss: 0.29064124822616577
Test Loss:  0.32672378420829773
Valid Loss:  0.33153870701789856
Epoch:  345  	Training Loss: 0.2906390428543091
Test Loss:  0.32672131061553955
Valid Loss:  0.3315361738204956
Epoch:  346  	Training Loss: 0.2906368374824524
Test Loss:  0.3267187774181366
Valid Loss:  0.33153361082077026
Epoch:  347  	Training Loss: 0.2906346321105957
Test Loss:  0.3267163038253784
Valid Loss:  0.3315311074256897
Epoch:  348  	Training Loss: 0.2906324565410614
Test Loss:  0.32671380043029785
Valid Loss:  0.33152854442596436
Epoch:  349  	Training Loss: 0.2906302511692047
Test Loss:  0.3267112970352173
Valid Loss:  0.3315260112285614
Epoch:  350  	Training Loss: 0.290628045797348
Test Loss:  0.3267087936401367
Valid Loss:  0.33152347803115845
Epoch:  351  	Training Loss: 0.2906258702278137
Test Loss:  0.32670629024505615
Valid Loss:  0.3315209448337555
Epoch:  352  	Training Loss: 0.29062366485595703
Test Loss:  0.3267037868499756
Valid Loss:  0.33151838183403015
Epoch:  353  	Training Loss: 0.29062145948410034
Test Loss:  0.32670125365257263
Valid Loss:  0.3315158486366272
Epoch:  354  	Training Loss: 0.29061928391456604
Test Loss:  0.32669878005981445
Valid Loss:  0.33151328563690186
Epoch:  355  	Training Loss: 0.29061707854270935
Test Loss:  0.3266962766647339
Valid Loss:  0.3315107524394989
Epoch:  356  	Training Loss: 0.29061490297317505
Test Loss:  0.3266937732696533
Valid Loss:  0.33150818943977356
Epoch:  357  	Training Loss: 0.29061269760131836
Test Loss:  0.32669124007225037
Valid Loss:  0.3315056264400482
Epoch:  358  	Training Loss: 0.29061049222946167
Test Loss:  0.3266887366771698
Valid Loss:  0.33150309324264526
Epoch:  359  	Training Loss: 0.290608286857605
Test Loss:  0.32668620347976685
Valid Loss:  0.3315005302429199
Epoch:  360  	Training Loss: 0.2906060814857483
Test Loss:  0.3266837000846863
Valid Loss:  0.33149802684783936
Epoch:  361  	Training Loss: 0.2906038761138916
Test Loss:  0.3266811966896057
Valid Loss:  0.331495463848114
Epoch:  362  	Training Loss: 0.2906016707420349
Test Loss:  0.32667869329452515
Valid Loss:  0.33149293065071106
Epoch:  363  	Training Loss: 0.2905994951725006
Test Loss:  0.32667621970176697
Valid Loss:  0.3314904272556305
Epoch:  364  	Training Loss: 0.2905973494052887
Test Loss:  0.3266737461090088
Valid Loss:  0.33148789405822754
Epoch:  365  	Training Loss: 0.2905951738357544
Test Loss:  0.3266712725162506
Valid Loss:  0.3314853608608246
Epoch:  366  	Training Loss: 0.2905930280685425
Test Loss:  0.32666879892349243
Valid Loss:  0.33148282766342163 73%|███████▎  | 367/500 [04:12<00:58,  2.25it/s] 74%|███████▍  | 369/500 [04:12<00:43,  3.03it/s] 74%|███████▍  | 371/500 [04:18<02:31,  1.17s/it] 75%|███████▍  | 373/500 [04:19<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:19<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:19<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:19<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:25<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:26<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:26<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:26<00:50,  2.22it/s] 78%|███████▊  | 389/500 [04:26<00:37,  2.99it/s] 78%|███████▊  | 391/500 [04:32<02:09,  1.18s/it] 79%|███████▊  | 393/500 [04:32<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:33<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:33<00:46,  2.21it/s] 80%|███████▉  | 399/500 [04:33<00:33,  2.98it/s] 80%|████████  | 401/500 [04:39<01:55,  1.17s/it] 81%|████████  | 403/500 [04:39<01:21,  1.19it/s] 81%|████████  | 405/500 [04:39<00:57,  1.65it/s] 81%|████████▏ | 407/500 [04:39<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:40<00:30,  3.02it/s] 82%|████████▏ | 411/500 [04:46<01:45,  1.18s/it] 83%|████████▎ | 413/500 [04:46<01:14,  1.17it/s] 83%|████████▎ | 415/500 [04:46<00:52,  1.62it/s] 83%|████████▎ | 417/500 [04:46<00:37,  2.21it/s] 84%|████████▍ | 419/500 [04:46<00:27,  2.95it/s] 84%|████████▍ | 421/500 [04:53<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:53<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:53<00:45,  1.64it/s] 85%|████████▌ | 427/500 [04:53<00:32,  2.23it/s] 86%|████████▌ | 429/500 [04:53<00:23,  2.99it/s] 86%|████████▌ | 431/500 [05:00<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:00<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:00<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:00<00:28,  2.22it/s] 88%|████████▊ | 439/500 [05:00<00:20,  2.94it/s]
Epoch:  367  	Training Loss: 0.2905908226966858
Test Loss:  0.32666629552841187
Valid Loss:  0.33148032426834106
Epoch:  368  	Training Loss: 0.2905886471271515
Test Loss:  0.3266637921333313
Valid Loss:  0.3314777910709381
Epoch:  369  	Training Loss: 0.2905865013599396
Test Loss:  0.3266613483428955
Valid Loss:  0.33147525787353516
Epoch:  370  	Training Loss: 0.2905843257904053
Test Loss:  0.32665884494781494
Valid Loss:  0.3314727544784546
Epoch:  371  	Training Loss: 0.29058218002319336
Test Loss:  0.3266563415527344
Valid Loss:  0.331470251083374
Epoch:  372  	Training Loss: 0.29057997465133667
Test Loss:  0.3266538381576538
Valid Loss:  0.3314676880836487
Epoch:  373  	Training Loss: 0.29057782888412476
Test Loss:  0.326651394367218
Valid Loss:  0.3314651846885681
Epoch:  374  	Training Loss: 0.29057565331459045
Test Loss:  0.32664889097213745
Valid Loss:  0.3314626216888428
Epoch:  375  	Training Loss: 0.29057347774505615
Test Loss:  0.3266463875770569
Valid Loss:  0.3314601182937622
Epoch:  376  	Training Loss: 0.29057133197784424
Test Loss:  0.3266439139842987
Valid Loss:  0.33145761489868164
Epoch:  377  	Training Loss: 0.29056915640830994
Test Loss:  0.3266414403915405
Valid Loss:  0.3314550817012787
Epoch:  378  	Training Loss: 0.290567010641098
Test Loss:  0.3266389071941376
Valid Loss:  0.33145254850387573
Epoch:  379  	Training Loss: 0.2905648350715637
Test Loss:  0.3266364336013794
Valid Loss:  0.3314500153064728
Epoch:  380  	Training Loss: 0.2905626595020294
Test Loss:  0.32663393020629883
Valid Loss:  0.33144745230674744
Epoch:  381  	Training Loss: 0.2905604839324951
Test Loss:  0.32663142681121826
Valid Loss:  0.33144494891166687
Epoch:  382  	Training Loss: 0.2905582785606384
Test Loss:  0.3266289234161377
Valid Loss:  0.33144238591194153
Epoch:  383  	Training Loss: 0.2905561327934265
Test Loss:  0.32662642002105713
Valid Loss:  0.3314398527145386
Epoch:  384  	Training Loss: 0.2905539274215698
Test Loss:  0.32662391662597656
Valid Loss:  0.33143728971481323
Epoch:  385  	Training Loss: 0.2905517518520355
Test Loss:  0.326621413230896
Valid Loss:  0.3314347267150879
Epoch:  386  	Training Loss: 0.2905495762825012
Test Loss:  0.32661890983581543
Valid Loss:  0.3314322233200073
Epoch:  387  	Training Loss: 0.2905474007129669
Test Loss:  0.32661640644073486
Valid Loss:  0.3314296305179596
Epoch:  388  	Training Loss: 0.2905452251434326
Test Loss:  0.3266139030456543
Valid Loss:  0.33142709732055664
Epoch:  389  	Training Loss: 0.2905430793762207
Test Loss:  0.32661139965057373
Valid Loss:  0.3314245641231537
Epoch:  390  	Training Loss: 0.290540874004364
Test Loss:  0.32660889625549316
Valid Loss:  0.33142203092575073
Epoch:  391  	Training Loss: 0.2905387282371521
Test Loss:  0.3266063928604126
Valid Loss:  0.3314194679260254
Epoch:  392  	Training Loss: 0.2905365228652954
Test Loss:  0.32660382986068726
Valid Loss:  0.33141687512397766
Epoch:  393  	Training Loss: 0.29053428769111633
Test Loss:  0.3266012668609619
Valid Loss:  0.33141428232192993
Epoch:  394  	Training Loss: 0.29053208231925964
Test Loss:  0.3265987038612366
Valid Loss:  0.3314116597175598
Epoch:  395  	Training Loss: 0.29052984714508057
Test Loss:  0.32659611105918884
Valid Loss:  0.3314090669155121
Epoch:  396  	Training Loss: 0.2905275821685791
Test Loss:  0.3265935778617859
Valid Loss:  0.33140647411346436
Epoch:  397  	Training Loss: 0.2905253767967224
Test Loss:  0.32659101486206055
Valid Loss:  0.33140385150909424
Epoch:  398  	Training Loss: 0.2905231714248657
Test Loss:  0.3265884518623352
Valid Loss:  0.3314012289047241
Epoch:  399  	Training Loss: 0.29052090644836426
Test Loss:  0.32658588886260986
Valid Loss:  0.3313986659049988
Epoch:  400  	Training Loss: 0.29051870107650757
Test Loss:  0.3265833258628845
Valid Loss:  0.33139607310295105
Epoch:  401  	Training Loss: 0.2905164957046509
Test Loss:  0.3265807628631592
Valid Loss:  0.33139345049858093
Epoch:  402  	Training Loss: 0.2905142605304718
Test Loss:  0.32657814025878906
Valid Loss:  0.3313907980918884
Epoch:  403  	Training Loss: 0.29051196575164795
Test Loss:  0.32657551765441895
Valid Loss:  0.3313881456851959
Epoch:  404  	Training Loss: 0.29050973057746887
Test Loss:  0.32657289505004883
Valid Loss:  0.3313854932785034
Epoch:  405  	Training Loss: 0.290507435798645
Test Loss:  0.3265703022480011
Valid Loss:  0.3313828110694885
Epoch:  406  	Training Loss: 0.29050517082214355
Test Loss:  0.326567679643631
Valid Loss:  0.331380158662796
Epoch:  407  	Training Loss: 0.2905029058456421
Test Loss:  0.3265650272369385
Valid Loss:  0.3313775062561035
Epoch:  408  	Training Loss: 0.29050061106681824
Test Loss:  0.32656243443489075
Valid Loss:  0.3313748240470886
Epoch:  409  	Training Loss: 0.2904983460903168
Test Loss:  0.32655981183052063
Valid Loss:  0.3313722014427185
Epoch:  410  	Training Loss: 0.2904960811138153
Test Loss:  0.3265572190284729
Valid Loss:  0.3313695192337036
Epoch:  411  	Training Loss: 0.29049381613731384
Test Loss:  0.3265545666217804
Valid Loss:  0.3313668668270111
Epoch:  412  	Training Loss: 0.2904915511608124
Test Loss:  0.32655200362205505
Valid Loss:  0.3313642144203186
Epoch:  413  	Training Loss: 0.2904893159866333
Test Loss:  0.32654938101768494
Valid Loss:  0.3313615918159485
Epoch:  414  	Training Loss: 0.29048705101013184
Test Loss:  0.3265467882156372
Valid Loss:  0.33135896921157837
Epoch:  415  	Training Loss: 0.29048478603363037
Test Loss:  0.3265441656112671
Valid Loss:  0.3313562870025635
Epoch:  416  	Training Loss: 0.2904825210571289
Test Loss:  0.32654160261154175
Valid Loss:  0.33135366439819336
Epoch:  417  	Training Loss: 0.2904803156852722
Test Loss:  0.32653898000717163
Valid Loss:  0.33135104179382324
Epoch:  418  	Training Loss: 0.29047805070877075
Test Loss:  0.3265364170074463
Valid Loss:  0.33134838938713074
Epoch:  419  	Training Loss: 0.2904757857322693
Test Loss:  0.32653379440307617
Valid Loss:  0.3313457667827606
Epoch:  420  	Training Loss: 0.2904735505580902
Test Loss:  0.32653120160102844
Valid Loss:  0.3313431143760681
Epoch:  421  	Training Loss: 0.29047131538391113
Test Loss:  0.3265286087989807
Valid Loss:  0.331340491771698
Epoch:  422  	Training Loss: 0.29046905040740967
Test Loss:  0.3265259861946106
Valid Loss:  0.3313378095626831
Epoch:  423  	Training Loss: 0.2904667854309082
Test Loss:  0.3265233635902405
Valid Loss:  0.3313351273536682
Epoch:  424  	Training Loss: 0.29046452045440674
Test Loss:  0.326520711183548
Valid Loss:  0.3313324451446533
Epoch:  425  	Training Loss: 0.2904622554779053
Test Loss:  0.32651808857917786
Valid Loss:  0.3313297927379608
Epoch:  426  	Training Loss: 0.2904599905014038
Test Loss:  0.32651546597480774
Valid Loss:  0.3313271403312683
Epoch:  427  	Training Loss: 0.29045769572257996
Test Loss:  0.32651281356811523
Valid Loss:  0.3313244581222534
Epoch:  428  	Training Loss: 0.2904554307460785
Test Loss:  0.3265101909637451
Valid Loss:  0.3313217759132385
Epoch:  429  	Training Loss: 0.29045313596725464
Test Loss:  0.326507568359375
Valid Loss:  0.331319123506546
Epoch:  430  	Training Loss: 0.2904508709907532
Test Loss:  0.3265049457550049
Valid Loss:  0.33131641149520874
Epoch:  431  	Training Loss: 0.2904486060142517
Test Loss:  0.32650232315063477
Valid Loss:  0.3313137888908386
Epoch:  432  	Training Loss: 0.29044634103775024
Test Loss:  0.32649967074394226
Valid Loss:  0.33131104707717896
Epoch:  433  	Training Loss: 0.290444016456604
Test Loss:  0.32649698853492737
Valid Loss:  0.33130836486816406
Epoch:  434  	Training Loss: 0.29044172167778015
Test Loss:  0.32649433612823486
Valid Loss:  0.3313056230545044
Epoch:  435  	Training Loss: 0.2904394268989563
Test Loss:  0.32649168372154236
Valid Loss:  0.3313029408454895
Epoch:  436  	Training Loss: 0.29043716192245483
Test Loss:  0.32648903131484985
Valid Loss:  0.3313002586364746
Epoch:  437  	Training Loss: 0.2904348075389862
Test Loss:  0.32648634910583496
Valid Loss:  0.33129751682281494
Epoch:  438  	Training Loss: 0.29043254256248474
Test Loss:  0.32648369669914246
Valid Loss:  0.33129483461380005
Epoch:  439  	Training Loss: 0.2904302477836609
Test Loss:  0.32648101449012756
Valid Loss:  0.33129212260246277
 88%|████████▊ | 441/500 [05:07<01:11,  1.21s/it] 89%|████████▊ | 443/500 [05:07<00:49,  1.15it/s] 89%|████████▉ | 445/500 [05:07<00:34,  1.60it/s] 89%|████████▉ | 447/500 [05:07<00:24,  2.18it/s] 90%|████████▉ | 449/500 [05:07<00:17,  2.93it/s] 90%|█████████ | 451/500 [05:13<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:14<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:14<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:14<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:14<00:13,  2.97it/s] 92%|█████████▏| 461/500 [05:20<00:46,  1.18s/it] 93%|█████████▎| 463/500 [05:20<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:21<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:21<00:14,  2.21it/s] 94%|█████████▍| 469/500 [05:21<00:10,  2.94it/s] 94%|█████████▍| 471/500 [05:27<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:27<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:28<00:15,  1.61it/s] 95%|█████████▌| 477/500 [05:28<00:10,  2.20it/s] 96%|█████████▌| 479/500 [05:28<00:07,  2.96it/s] 96%|█████████▌| 481/500 [05:34<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:34<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:34<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:35<00:05,  2.21it/s] 98%|█████████▊| 489/500 [05:35<00:03,  2.97it/s] 98%|█████████▊| 491/500 [05:41<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:41<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:41<00:03,  1.62it/s] 99%|█████████▉| 497/500 [05:41<00:01,  2.21it/s]100%|█████████▉| 499/500 [05:42<00:00,  2.97it/s]100%|██████████| 500/500 [05:42<00:00,  1.46it/s]
Epoch:  440  	Training Loss: 0.29042792320251465
Test Loss:  0.32647836208343506
Valid Loss:  0.3312894105911255
Epoch:  441  	Training Loss: 0.2904256284236908
Test Loss:  0.32647567987442017
Valid Loss:  0.3312866985797882
Epoch:  442  	Training Loss: 0.29042333364486694
Test Loss:  0.32647305727005005
Valid Loss:  0.3312839865684509
Epoch:  443  	Training Loss: 0.2904210090637207
Test Loss:  0.32647037506103516
Valid Loss:  0.3312813341617584
Epoch:  444  	Training Loss: 0.29041874408721924
Test Loss:  0.32646769285202026
Valid Loss:  0.33127862215042114
Epoch:  445  	Training Loss: 0.290416419506073
Test Loss:  0.32646507024765015
Valid Loss:  0.3312758803367615
Epoch:  446  	Training Loss: 0.29041415452957153
Test Loss:  0.32646238803863525
Valid Loss:  0.3312731981277466
Epoch:  447  	Training Loss: 0.29041188955307007
Test Loss:  0.32645973563194275
Valid Loss:  0.3312705159187317
Epoch:  448  	Training Loss: 0.29040956497192383
Test Loss:  0.32645708322525024
Valid Loss:  0.3312678039073944
Epoch:  449  	Training Loss: 0.2904072701931
Test Loss:  0.32645440101623535
Valid Loss:  0.33126509189605713
Epoch:  450  	Training Loss: 0.2904049754142761
Test Loss:  0.32645177841186523
Valid Loss:  0.33126237988471985
Epoch:  451  	Training Loss: 0.29040271043777466
Test Loss:  0.32644912600517273
Valid Loss:  0.33125972747802734
Epoch:  452  	Training Loss: 0.2904004156589508
Test Loss:  0.32644644379615784
Valid Loss:  0.3312569856643677
Epoch:  453  	Training Loss: 0.29039812088012695
Test Loss:  0.32644376158714294
Valid Loss:  0.3312542736530304
Epoch:  454  	Training Loss: 0.2903958261013031
Test Loss:  0.32644110918045044
Valid Loss:  0.3312515616416931
Epoch:  455  	Training Loss: 0.29039353132247925
Test Loss:  0.32643842697143555
Valid Loss:  0.33124881982803345
Epoch:  456  	Training Loss: 0.290391206741333
Test Loss:  0.32643571496009827
Valid Loss:  0.33124613761901855
Epoch:  457  	Training Loss: 0.29038888216018677
Test Loss:  0.32643306255340576
Valid Loss:  0.3312433958053589
Epoch:  458  	Training Loss: 0.2903866171836853
Test Loss:  0.32643041014671326
Valid Loss:  0.3312406837940216
Epoch:  459  	Training Loss: 0.29038435220718384
Test Loss:  0.32642772793769836
Valid Loss:  0.3312379717826843
Epoch:  460  	Training Loss: 0.2903820276260376
Test Loss:  0.32642504572868347
Valid Loss:  0.33123522996902466
Epoch:  461  	Training Loss: 0.29037973284721375
Test Loss:  0.3264223635196686
Valid Loss:  0.33123254776000977
Epoch:  462  	Training Loss: 0.2903774380683899
Test Loss:  0.3264196813106537
Valid Loss:  0.3312298059463501
Epoch:  463  	Training Loss: 0.29037511348724365
Test Loss:  0.3264169692993164
Valid Loss:  0.33122706413269043
Epoch:  464  	Training Loss: 0.2903727889060974
Test Loss:  0.3264142870903015
Valid Loss:  0.33122432231903076
Epoch:  465  	Training Loss: 0.29037049412727356
Test Loss:  0.3264116048812866
Valid Loss:  0.3312215805053711
Epoch:  466  	Training Loss: 0.2903681993484497
Test Loss:  0.32640892267227173
Valid Loss:  0.3312188684940338
Epoch:  467  	Training Loss: 0.29036587476730347
Test Loss:  0.32640621066093445
Valid Loss:  0.33121612668037415
Epoch:  468  	Training Loss: 0.2903635501861572
Test Loss:  0.32640352845191956
Valid Loss:  0.3312133848667145
Epoch:  469  	Training Loss: 0.290361225605011
Test Loss:  0.32640084624290466
Valid Loss:  0.3312106132507324
Epoch:  470  	Training Loss: 0.29035890102386475
Test Loss:  0.3263981342315674
Valid Loss:  0.33120793104171753
Epoch:  471  	Training Loss: 0.2903566360473633
Test Loss:  0.3263954222202301
Valid Loss:  0.3312051594257355
Epoch:  472  	Training Loss: 0.29035431146621704
Test Loss:  0.3263927400112152
Valid Loss:  0.3312024474143982
Epoch:  473  	Training Loss: 0.2903519868850708
Test Loss:  0.3263900578022003
Valid Loss:  0.3311997056007385
Epoch:  474  	Training Loss: 0.29034966230392456
Test Loss:  0.32638734579086304
Valid Loss:  0.33119693398475647
Epoch:  475  	Training Loss: 0.2903473377227783
Test Loss:  0.32638466358184814
Valid Loss:  0.3311941921710968
Epoch:  476  	Training Loss: 0.29034504294395447
Test Loss:  0.3263819217681885
Valid Loss:  0.33119145035743713
Epoch:  477  	Training Loss: 0.29034268856048584
Test Loss:  0.3263792395591736
Valid Loss:  0.33118870854377747
Epoch:  478  	Training Loss: 0.2903404235839844
Test Loss:  0.3263765573501587
Valid Loss:  0.3311859667301178
Epoch:  479  	Training Loss: 0.29033809900283813
Test Loss:  0.3263738453388214
Valid Loss:  0.33118322491645813
Epoch:  480  	Training Loss: 0.2903357744216919
Test Loss:  0.3263711631298065
Valid Loss:  0.33118048310279846
Epoch:  481  	Training Loss: 0.29033344984054565
Test Loss:  0.32636845111846924
Valid Loss:  0.3311777114868164
Epoch:  482  	Training Loss: 0.2903311252593994
Test Loss:  0.32636573910713196
Valid Loss:  0.3311749994754791
Epoch:  483  	Training Loss: 0.2903288006782532
Test Loss:  0.3263630270957947
Valid Loss:  0.33117222785949707
Epoch:  484  	Training Loss: 0.2903265058994293
Test Loss:  0.3263603448867798
Valid Loss:  0.3311695456504822
Epoch:  485  	Training Loss: 0.29032421112060547
Test Loss:  0.3263576626777649
Valid Loss:  0.33116674423217773
Epoch:  486  	Training Loss: 0.29032188653945923
Test Loss:  0.3263549506664276
Valid Loss:  0.33116400241851807
Epoch:  487  	Training Loss: 0.2903195917606354
Test Loss:  0.32635223865509033
Valid Loss:  0.3311612606048584
Epoch:  488  	Training Loss: 0.29031726717948914
Test Loss:  0.32634955644607544
Valid Loss:  0.33115851879119873
Epoch:  489  	Training Loss: 0.2903149425983429
Test Loss:  0.32634684443473816
Valid Loss:  0.33115577697753906
Epoch:  490  	Training Loss: 0.29031261801719666
Test Loss:  0.3263441324234009
Valid Loss:  0.3311530351638794
Epoch:  491  	Training Loss: 0.2903103232383728
Test Loss:  0.326341450214386
Valid Loss:  0.3311502933502197
Epoch:  492  	Training Loss: 0.29030799865722656
Test Loss:  0.32633864879608154
Valid Loss:  0.3311474621295929
Epoch:  493  	Training Loss: 0.29030561447143555
Test Loss:  0.3263359069824219
Valid Loss:  0.33114463090896606
Epoch:  494  	Training Loss: 0.29030323028564453
Test Loss:  0.32633310556411743
Valid Loss:  0.3311418294906616
Epoch:  495  	Training Loss: 0.2903008460998535
Test Loss:  0.32633036375045776
Valid Loss:  0.3311390280723572
Epoch:  496  	Training Loss: 0.2902984917163849
Test Loss:  0.3263275623321533
Valid Loss:  0.33113616704940796
Epoch:  497  	Training Loss: 0.29029613733291626
Test Loss:  0.32632479071617126
Valid Loss:  0.3311333656311035
Epoch:  498  	Training Loss: 0.29029375314712524
Test Loss:  0.3263220191001892
Valid Loss:  0.3311305642127991
Epoch:  499  	Training Loss: 0.29029133915901184
Test Loss:  0.32631921768188477
Valid Loss:  0.33112773299217224
Epoch:  500  	Training Loss: 0.2902889549732208
Test Loss:  0.3263164758682251
Valid Loss:  0.3311249017715454
seed is  18
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:21,  6.18s/it]  1%|          | 3/500 [00:06<13:41,  1.65s/it]  1%|          | 5/500 [00:06<06:55,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:12<10:42,  1.31s/it]  3%|▎         | 13/500 [00:13<07:18,  1.11it/s]  3%|▎         | 15/500 [00:13<05:06,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  3.00it/s]  4%|▍         | 21/500 [00:19<09:35,  1.20s/it]  5%|▍         | 23/500 [00:19<06:48,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:12,  1.18s/it]  7%|▋         | 33/500 [00:26<06:36,  1.18it/s]  7%|▋         | 35/500 [00:26<04:46,  1.62it/s]  7%|▋         | 37/500 [00:27<03:28,  2.22it/s]  8%|▊         | 39/500 [00:27<02:34,  2.98it/s]  8%|▊         | 39/500 [00:37<02:34,  2.98it/s]  8%|▊         | 41/500 [00:39<16:13,  2.12s/it]  9%|▊         | 43/500 [00:39<11:29,  1.51s/it]  9%|▉         | 45/500 [00:40<08:09,  1.08s/it]  9%|▉         | 47/500 [00:40<05:50,  1.29it/s] 10%|▉         | 49/500 [00:40<04:16,  1.76it/s] 10%|█         | 51/500 [00:46<10:10,  1.36s/it] 11%|█         | 53/500 [00:46<07:15,  1.03it/s] 11%|█         | 55/500 [00:47<05:12,  1.43it/s] 11%|█▏        | 57/500 [00:47<03:46,  1.96it/s] 12%|█▏        | 59/500 [00:47<02:46,  2.65it/s] 12%|█▏        | 61/500 [00:53<08:50,  1.21s/it] 13%|█▎        | 63/500 [00:53<06:19,  1.15it/s] 13%|█▎        | 65/500 [00:53<04:33,  1.59it/s] 13%|█▎        | 67/500 [00:54<03:18,  2.18it/s] 14%|█▍        | 69/500 [00:54<02:26,  2.93it/s]Epoch:  1  	Training Loss: 0.46929773688316345
Test Loss:  2.8724279403686523
Valid Loss:  2.880399227142334
Epoch:  2  	Training Loss: 2.8451132774353027
Test Loss:  0.39795932173728943
Valid Loss:  0.4063035845756531
Epoch:  3  	Training Loss: 0.33605659008026123
Test Loss:  0.06975345313549042
Valid Loss:  0.0668555200099945
Epoch:  4  	Training Loss: 0.0714973583817482
Test Loss:  0.05381620675325394
Valid Loss:  0.0511394664645195
Epoch:  5  	Training Loss: 0.05757661163806915
Test Loss:  0.04297317564487457
Valid Loss:  0.04075349122285843
Epoch:  6  	Training Loss: 0.04682406038045883
Test Loss:  0.03455565869808197
Valid Loss:  0.03276496380567551
Epoch:  7  	Training Loss: 0.0382286012172699
Test Loss:  0.02789130061864853
Valid Loss:  0.026474563404917717
Epoch:  8  	Training Loss: 0.03134758025407791
Test Loss:  0.022598624229431152
Valid Loss:  0.021505074575543404
Epoch:  9  	Training Loss: 0.025836199522018433
Test Loss:  0.0183936208486557
Valid Loss:  0.017579611390829086
Epoch:  10  	Training Loss: 0.021419251337647438
Test Loss:  0.015052714385092258
Valid Loss:  0.014481067657470703
Epoch:  11  	Training Loss: 0.017873866483569145
Test Loss:  0.012391905300319195
Valid Loss:  0.012023324146866798
Epoch:  12  	Training Loss: 0.01501921284943819
Test Loss:  0.011645026504993439
Valid Loss:  0.0119255306199193
Epoch:  13  	Training Loss: 0.01266719400882721
Test Loss:  0.008437798358500004
Valid Loss:  0.008393753319978714
Epoch:  14  	Training Loss: 0.010716209188103676
Test Loss:  0.008332732133567333
Valid Loss:  0.008769317530095577
Epoch:  15  	Training Loss: 0.009374941699206829
Test Loss:  0.006415148731321096
Valid Loss:  0.00658104894682765
Epoch:  16  	Training Loss: 0.008366362191736698
Test Loss:  0.006424416322261095
Valid Loss:  0.006920200772583485
Epoch:  17  	Training Loss: 0.007581960875540972
Test Loss:  0.005174498073756695
Valid Loss:  0.0054706549271941185
Epoch:  18  	Training Loss: 0.006962263025343418
Test Loss:  0.005220277234911919
Valid Loss:  0.005790076218545437
Epoch:  19  	Training Loss: 0.006441236473619938
Test Loss:  0.004358853213489056
Valid Loss:  0.004773253574967384
Epoch:  20  	Training Loss: 0.006008642725646496
Test Loss:  0.004392837639898062
Valid Loss:  0.005030110478401184
Epoch:  21  	Training Loss: 0.005645192228257656
Test Loss:  0.0037983073852956295
Valid Loss:  0.004306481219828129
Epoch:  22  	Training Loss: 0.005350072868168354
Test Loss:  0.003554467111825943
Valid Loss:  0.004194994457066059
Epoch:  23  	Training Loss: 0.004861044697463512
Test Loss:  0.003204718232154846
Valid Loss:  0.003827467327937484
Epoch:  24  	Training Loss: 0.0045584579929709435
Test Loss:  0.0030196253210306168
Valid Loss:  0.003710520453751087
Epoch:  25  	Training Loss: 0.004283684305846691
Test Loss:  0.002791875973343849
Valid Loss:  0.003495065961033106
Epoch:  26  	Training Loss: 0.0040376149117946625
Test Loss:  0.0026343073695898056
Valid Loss:  0.003379340749233961
Epoch:  27  	Training Loss: 0.0038140760734677315
Test Loss:  0.002458496019244194
Valid Loss:  0.0032054849434643984
Epoch:  28  	Training Loss: 0.0036016996018588543
Test Loss:  0.0023216577246785164
Valid Loss:  0.003091456601396203
Epoch:  29  	Training Loss: 0.003392646787688136
Test Loss:  0.002177997725084424
Valid Loss:  0.0029484503902494907
Epoch:  30  	Training Loss: 0.0031964494846761227
Test Loss:  0.002060294384136796
Valid Loss:  0.0028416053391993046
Epoch:  31  	Training Loss: 0.003013123292475939
Test Loss:  0.0019488107645884156
Valid Loss:  0.0027193622663617134
Epoch:  32  	Training Loss: 0.0028477299492806196
Test Loss:  0.0017864508554339409
Valid Loss:  0.002577107632532716
Epoch:  33  	Training Loss: 0.0025609780568629503
Test Loss:  0.001636209897696972
Valid Loss:  0.0023862330708652735
Epoch:  34  	Training Loss: 0.002417220501229167
Test Loss:  0.0017820617649704218
Valid Loss:  0.0026152078062295914
Epoch:  35  	Training Loss: 0.0024160107132047415
Test Loss:  0.0020394609309732914
Valid Loss:  0.002738459035754204
Epoch:  36  	Training Loss: 0.002947283908724785
Test Loss:  0.004909909330308437
Valid Loss:  0.005906489212065935
Epoch:  37  	Training Loss: 0.005438767373561859
Test Loss:  0.012420780956745148
Valid Loss:  0.013092819601297379
Epoch:  38  	Training Loss: 0.01441805437207222
Test Loss:  0.03898843750357628
Valid Loss:  0.04140285402536392
Epoch:  39  	Training Loss: 0.04037237539887428
Test Loss:  0.05554048344492912
Valid Loss:  0.05558992177248001
Epoch:  40  	Training Loss: 0.059720732271671295
Test Loss:  0.04365551471710205
Valid Loss:  0.0462135411798954
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.04385275021195412
Test Loss:  0.005882233381271362
Valid Loss:  0.006757656577974558
Epoch:  42  	Training Loss: 0.007878366857767105
Test Loss:  0.005514650139957666
Valid Loss:  0.006367502734065056
Epoch:  43  	Training Loss: 0.007530545815825462
Test Loss:  0.00529269315302372
Valid Loss:  0.006174691021442413
Epoch:  44  	Training Loss: 0.007237826939672232
Test Loss:  0.0050926823168993
Valid Loss:  0.006000987254083157
Epoch:  45  	Training Loss: 0.006962871178984642
Test Loss:  0.004906349815428257
Valid Loss:  0.005836512427777052
Epoch:  46  	Training Loss: 0.006696739699691534
Test Loss:  0.004729266278445721
Valid Loss:  0.00568368099629879
Epoch:  47  	Training Loss: 0.006438162177801132
Test Loss:  0.004559047054499388
Valid Loss:  0.005533193238079548
Epoch:  48  	Training Loss: 0.006182980723679066
Test Loss:  0.004384388215839863
Valid Loss:  0.005390668287873268
Epoch:  49  	Training Loss: 0.005938544869422913
Test Loss:  0.0042242505587637424
Valid Loss:  0.005254141055047512
Epoch:  50  	Training Loss: 0.005712039768695831
Test Loss:  0.004080276936292648
Valid Loss:  0.005128915421664715
Epoch:  51  	Training Loss: 0.005507607012987137
Test Loss:  0.003955079708248377
Valid Loss:  0.005019523203372955
Epoch:  52  	Training Loss: 0.0053280796855688095
Test Loss:  0.0038174923975020647
Valid Loss:  0.004897648468613625
Epoch:  53  	Training Loss: 0.005122121423482895
Test Loss:  0.0037502944469451904
Valid Loss:  0.0048322901129722595
Epoch:  54  	Training Loss: 0.005029899533838034
Test Loss:  0.00368960527703166
Valid Loss:  0.0047802794724702835
Epoch:  55  	Training Loss: 0.004953053779900074
Test Loss:  0.003631412284448743
Valid Loss:  0.0047344909980893135
Epoch:  56  	Training Loss: 0.004879860207438469
Test Loss:  0.0035746656358242035
Valid Loss:  0.004689501598477364
Epoch:  57  	Training Loss: 0.0048072729259729385
Test Loss:  0.003516116412356496
Valid Loss:  0.004642725922167301
Epoch:  58  	Training Loss: 0.004734474699944258
Test Loss:  0.0034584638196974993
Valid Loss:  0.004595298785716295
Epoch:  59  	Training Loss: 0.0046625444665551186
Test Loss:  0.00340169295668602
Valid Loss:  0.004545882344245911
Epoch:  60  	Training Loss: 0.004592228680849075
Test Loss:  0.003346160752698779
Valid Loss:  0.004495317582041025
Epoch:  61  	Training Loss: 0.004523431416600943
Test Loss:  0.0032846361864358187
Valid Loss:  0.004434741102159023
Epoch:  62  	Training Loss: 0.004450281150639057
Test Loss:  0.0032539053354412317
Valid Loss:  0.0044032856822013855
Epoch:  63  	Training Loss: 0.004393113311380148
Test Loss:  0.0032255807891488075
Valid Loss:  0.004363131709396839
Epoch:  64  	Training Loss: 0.0043375324457883835
Test Loss:  0.003192862728610635
Valid Loss:  0.004318437539041042
Epoch:  65  	Training Loss: 0.004279956687241793
Test Loss:  0.003159297164529562
Valid Loss:  0.0042691659182310104
Epoch:  66  	Training Loss: 0.00422106496989727
Test Loss:  0.0031259115785360336
Valid Loss:  0.0042189378291368484
Epoch:  67  	Training Loss: 0.004162905737757683
Test Loss:  0.003093293635174632
Valid Loss:  0.004168328829109669
Epoch:  68  	Training Loss: 0.004103255458176136
Test Loss:  0.003061561845242977
Valid Loss:  0.004118805751204491
Epoch:  69  	Training Loss: 0.004045323468744755
Test Loss:  0.0030276095494627953
Valid Loss:  0.0040705278515815735
Epoch:  70  	Training Loss: 0.003988045267760754
Test Loss:  0.0029928816948086023
 14%|█▍        | 71/500 [01:00<08:28,  1.19s/it] 15%|█▍        | 73/500 [01:00<06:05,  1.17it/s] 15%|█▌        | 75/500 [01:00<04:22,  1.62it/s] 15%|█▌        | 77/500 [01:00<03:11,  2.21it/s] 16%|█▌        | 79/500 [01:01<02:21,  2.97it/s] 16%|█▌        | 81/500 [01:07<08:20,  1.20s/it] 17%|█▋        | 83/500 [01:07<05:57,  1.17it/s] 17%|█▋        | 85/500 [01:07<04:17,  1.61it/s] 17%|█▋        | 87/500 [01:07<03:07,  2.20it/s] 18%|█▊        | 89/500 [01:07<02:18,  2.96it/s] 18%|█▊        | 91/500 [01:14<08:01,  1.18s/it] 19%|█▊        | 93/500 [01:14<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:14<04:07,  1.63it/s] 19%|█▉        | 97/500 [01:14<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:14<02:14,  2.99it/s] 20%|██        | 101/500 [01:21<07:53,  1.19s/it] 21%|██        | 103/500 [01:21<05:38,  1.17it/s] 21%|██        | 105/500 [01:21<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:21<02:57,  2.22it/s] 22%|██▏       | 109/500 [01:21<02:11,  2.98it/s] 22%|██▏       | 111/500 [01:28<07:39,  1.18s/it] 23%|██▎       | 113/500 [01:28<05:28,  1.18it/s] 23%|██▎       | 115/500 [01:28<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:28<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:28<02:07,  3.00it/s] 24%|██▍       | 121/500 [01:34<07:25,  1.18s/it] 25%|██▍       | 123/500 [01:34<05:18,  1.18it/s] 25%|██▌       | 125/500 [01:35<03:49,  1.64it/s] 25%|██▌       | 127/500 [01:35<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:35<02:03,  3.01it/s] 26%|██▌       | 131/500 [01:41<07:14,  1.18s/it] 27%|██▋       | 133/500 [01:41<05:10,  1.18it/s] 27%|██▋       | 135/500 [01:41<03:43,  1.63it/s] 27%|██▋       | 137/500 [01:42<02:42,  2.23it/s]Valid Loss:  0.004022975917905569
Epoch:  71  	Training Loss: 0.0039314208552241325
Test Loss:  0.002956417854875326
Valid Loss:  0.0039759669452905655
Epoch:  72  	Training Loss: 0.0038729258812963963
Test Loss:  0.002864849753677845
Valid Loss:  0.003864432219415903
Epoch:  73  	Training Loss: 0.003774923738092184
Test Loss:  0.0027843283023685217
Valid Loss:  0.003762509673833847
Epoch:  74  	Training Loss: 0.003685323754325509
Test Loss:  0.002718111500144005
Valid Loss:  0.0036724084056913853
Epoch:  75  	Training Loss: 0.0036035410594195127
Test Loss:  0.002666170010343194
Valid Loss:  0.0035932990722358227
Epoch:  76  	Training Loss: 0.0035259081050753593
Test Loss:  0.0026150690391659737
Valid Loss:  0.0035204170271754265
Epoch:  77  	Training Loss: 0.0034511657431721687
Test Loss:  0.0025651075411587954
Valid Loss:  0.0034507717937231064
Epoch:  78  	Training Loss: 0.0033802236430346966
Test Loss:  0.0025159844662994146
Valid Loss:  0.0033833319321274757
Epoch:  79  	Training Loss: 0.003310102503746748
Test Loss:  0.0024678863119333982
Valid Loss:  0.0033208730164915323
Epoch:  80  	Training Loss: 0.003239498706534505
Test Loss:  0.002421729499474168
Valid Loss:  0.0032631224021315575
Epoch:  81  	Training Loss: 0.0031738050747662783
Test Loss:  0.002375582931563258
Valid Loss:  0.0032093855552375317
Epoch:  82  	Training Loss: 0.0031080888584256172
Test Loss:  0.0023723256308585405
Valid Loss:  0.003216695738956332
Epoch:  83  	Training Loss: 0.003097057808190584
Test Loss:  0.002370775444433093
Valid Loss:  0.003220482263714075
Epoch:  84  	Training Loss: 0.003089669393375516
Test Loss:  0.0023691444657742977
Valid Loss:  0.0032237570267170668
Epoch:  85  	Training Loss: 0.003083320800215006
Test Loss:  0.002367179375141859
Valid Loss:  0.003225996857509017
Epoch:  86  	Training Loss: 0.0030776620842516422
Test Loss:  0.002364974468946457
Valid Loss:  0.003227332839742303
Epoch:  87  	Training Loss: 0.0030723316594958305
Test Loss:  0.0023626619949936867
Valid Loss:  0.0032281368039548397
Epoch:  88  	Training Loss: 0.0030674654990434647
Test Loss:  0.0023605667520314455
Valid Loss:  0.0032286536879837513
Epoch:  89  	Training Loss: 0.0030628531239926815
Test Loss:  0.0023586582392454147
Valid Loss:  0.0032287559006363153
Epoch:  90  	Training Loss: 0.003058400936424732
Test Loss:  0.002356745069846511
Valid Loss:  0.003228676039725542
Epoch:  91  	Training Loss: 0.003054266097024083
Test Loss:  0.002354762051254511
Valid Loss:  0.0032283179461956024
Epoch:  92  	Training Loss: 0.003050224855542183
Test Loss:  0.0023428250569850206
Valid Loss:  0.0032226680777966976
Epoch:  93  	Training Loss: 0.0030295122414827347
Test Loss:  0.0023316871374845505
Valid Loss:  0.0032169059850275517
Epoch:  94  	Training Loss: 0.0030111137311905622
Test Loss:  0.0023211482912302017
Valid Loss:  0.0032115858048200607
Epoch:  95  	Training Loss: 0.0029951012693345547
Test Loss:  0.0023120229598134756
Valid Loss:  0.003206094726920128
Epoch:  96  	Training Loss: 0.0029822816140949726
Test Loss:  0.0023050042800605297
Valid Loss:  0.003200341947376728
Epoch:  97  	Training Loss: 0.00297180050984025
Test Loss:  0.002300112973898649
Valid Loss:  0.0031944599468261003
Epoch:  98  	Training Loss: 0.00296333828009665
Test Loss:  0.0022956100292503834
Valid Loss:  0.0031883600167930126
Epoch:  99  	Training Loss: 0.0029559247195720673
Test Loss:  0.002291003242135048
Valid Loss:  0.0031824344769120216
Epoch:  100  	Training Loss: 0.002949294401332736
Test Loss:  0.0022868458181619644
Valid Loss:  0.0031766952015459538
Epoch:  101  	Training Loss: 0.0029435029719024897
Test Loss:  0.002282913774251938
Valid Loss:  0.00317074335180223
Epoch:  102  	Training Loss: 0.0029381942003965378
Test Loss:  0.0021884103771299124
Valid Loss:  0.0030480078421533108
Epoch:  103  	Training Loss: 0.002845888491719961
Test Loss:  0.0021085224580019712
Valid Loss:  0.0029649948701262474
Epoch:  104  	Training Loss: 0.0027698599733412266
Test Loss:  0.0020451252348721027
Valid Loss:  0.002882149536162615
Epoch:  105  	Training Loss: 0.002696879208087921
Test Loss:  0.0019599921070039272
Valid Loss:  0.0027897809632122517
Epoch:  106  	Training Loss: 0.0026123144198209047
Test Loss:  0.0018884704913944006
Valid Loss:  0.0027026282623410225
Epoch:  107  	Training Loss: 0.002540234476327896
Test Loss:  0.0018159663304686546
Valid Loss:  0.002623432083055377
Epoch:  108  	Training Loss: 0.002469173865392804
Test Loss:  0.001751030096784234
Valid Loss:  0.0025448505766689777
Epoch:  109  	Training Loss: 0.0024019156116992235
Test Loss:  0.001680780784226954
Valid Loss:  0.00246538408100605
Epoch:  110  	Training Loss: 0.0023294053971767426
Test Loss:  0.0016194838099181652
Valid Loss:  0.0023906095884740353
Epoch:  111  	Training Loss: 0.002265944378450513
Test Loss:  0.0015630736015737057
Valid Loss:  0.0023225033655762672
Epoch:  112  	Training Loss: 0.0022041858173906803
Test Loss:  0.0015367295127362013
Valid Loss:  0.0022859941236674786
Epoch:  113  	Training Loss: 0.0021792773623019457
Test Loss:  0.0015155686996877193
Valid Loss:  0.0022559601347893476
Epoch:  114  	Training Loss: 0.002155244816094637
Test Loss:  0.0014938979875296354
Valid Loss:  0.0022209561429917812
Epoch:  115  	Training Loss: 0.002130486536771059
Test Loss:  0.0014671885874122381
Valid Loss:  0.0021821497939527035
Epoch:  116  	Training Loss: 0.0021027722395956516
Test Loss:  0.0014393606688827276
Valid Loss:  0.002144120167940855
Epoch:  117  	Training Loss: 0.00207599182613194
Test Loss:  0.0014266017824411392
Valid Loss:  0.002125903032720089
Epoch:  118  	Training Loss: 0.002056120429188013
Test Loss:  0.001409338554367423
Valid Loss:  0.0021030334755778313
Epoch:  119  	Training Loss: 0.0020375396125018597
Test Loss:  0.0013965519610792398
Valid Loss:  0.0020845159888267517
Epoch:  120  	Training Loss: 0.002019620733335614
Test Loss:  0.0013840205501765013
Valid Loss:  0.00206549558788538
Epoch:  121  	Training Loss: 0.002003087429329753
Test Loss:  0.0013733010273426771
Valid Loss:  0.0020473136100918055
Epoch:  122  	Training Loss: 0.001988037023693323
Test Loss:  0.0013772391248494387
Valid Loss:  0.002055795630440116
Epoch:  123  	Training Loss: 0.0019776285625994205
Test Loss:  0.001369962701573968
Valid Loss:  0.0020519718527793884
Epoch:  124  	Training Loss: 0.0019689719192683697
Test Loss:  0.001369379460811615
Valid Loss:  0.0020542754791677
Epoch:  125  	Training Loss: 0.001962442183867097
Test Loss:  0.001364995026960969
Valid Loss:  0.0020513664931058884
Epoch:  126  	Training Loss: 0.0019555920735001564
Test Loss:  0.0013648192398250103
Valid Loss:  0.0020528698805719614
Epoch:  127  	Training Loss: 0.0019502767827361822
Test Loss:  0.001360979164019227
Valid Loss:  0.002048723166808486
Epoch:  128  	Training Loss: 0.0019443496130406857
Test Loss:  0.001360980561003089
Valid Loss:  0.002048918977379799
Epoch:  129  	Training Loss: 0.0019388061482459307
Test Loss:  0.0013557937927544117
Valid Loss:  0.0020442965906113386
Epoch:  130  	Training Loss: 0.0019318069098517299
Test Loss:  0.0013547800481319427
Valid Loss:  0.0020443431567400694
Epoch:  131  	Training Loss: 0.0019257195526733994
Test Loss:  0.0013489631237462163
Valid Loss:  0.0020396611653268337
Epoch:  132  	Training Loss: 0.001918924506753683
Test Loss:  0.0013391079846769571
Valid Loss:  0.0020252144895493984
Epoch:  133  	Training Loss: 0.001911610015667975
Test Loss:  0.001345861586742103
Valid Loss:  0.002028781920671463
Epoch:  134  	Training Loss: 0.0019057434983551502
Test Loss:  0.001323432195931673
Valid Loss:  0.002005020622164011
Epoch:  135  	Training Loss: 0.001894298940896988
Test Loss:  0.0013250426854938269
Valid Loss:  0.002002660185098648
Epoch:  136  	Training Loss: 0.0018823747523128986
Test Loss:  0.0013027633540332317
Valid Loss:  0.0019820404704660177
Epoch:  137  	Training Loss: 0.0018695825710892677
Test Loss:  0.001299746916629374
Valid Loss:  0.001976284198462963
Epoch:  138  	Training Loss: 0.0018575832946226
Test Loss:  0.0012884598691016436
Valid Loss:  0.00196429924108088
Epoch:  139  	Training Loss: 0.0018480818253010511
Test Loss:  0.0012818003306165338
Valid Loss:  0.001955730374902487 28%|██▊       | 139/500 [01:42<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:48<07:00,  1.17s/it] 29%|██▊       | 143/500 [01:48<05:00,  1.19it/s] 29%|██▉       | 145/500 [01:48<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:48<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:49<01:56,  3.01it/s] 30%|███       | 151/500 [01:55<06:48,  1.17s/it] 31%|███       | 153/500 [01:55<04:51,  1.19it/s] 31%|███       | 155/500 [01:55<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:55<02:32,  2.24it/s] 32%|███▏      | 159/500 [01:55<01:52,  3.02it/s] 32%|███▏      | 161/500 [02:02<06:37,  1.17s/it] 33%|███▎      | 163/500 [02:02<04:44,  1.18it/s] 33%|███▎      | 165/500 [02:02<03:25,  1.63it/s] 33%|███▎      | 167/500 [02:02<02:29,  2.23it/s] 34%|███▍      | 169/500 [02:02<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:08<06:27,  1.18s/it] 35%|███▍      | 173/500 [02:09<04:36,  1.18it/s] 35%|███▌      | 175/500 [02:09<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:09<02:25,  2.23it/s] 36%|███▌      | 179/500 [02:09<01:47,  3.00it/s] 36%|███▌      | 181/500 [02:15<06:14,  1.17s/it] 37%|███▋      | 183/500 [02:15<04:27,  1.19it/s] 37%|███▋      | 185/500 [02:16<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:16<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:16<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:22<06:01,  1.17s/it] 39%|███▊      | 193/500 [02:22<04:17,  1.19it/s] 39%|███▉      | 195/500 [02:22<03:05,  1.64it/s] 39%|███▉      | 197/500 [02:22<02:15,  2.24it/s] 40%|███▉      | 199/500 [02:23<01:40,  2.99it/s] 40%|████      | 201/500 [02:29<05:52,  1.18s/it] 41%|████      | 203/500 [02:29<04:11,  1.18it/s] 41%|████      | 205/500 [02:29<03:00,  1.63it/s] 41%|████▏     | 207/500 [02:29<02:11,  2.23it/s]
Epoch:  140  	Training Loss: 0.001838888507336378
Test Loss:  0.0012735951459035277
Valid Loss:  0.0019457887392491102
Epoch:  141  	Training Loss: 0.0018300325609743595
Test Loss:  0.0012669690186157823
Valid Loss:  0.0019375644624233246
Epoch:  142  	Training Loss: 0.0018209954723715782
Test Loss:  0.001226153806783259
Valid Loss:  0.0018759452505037189
Epoch:  143  	Training Loss: 0.0017773809377104044
Test Loss:  0.0012027071788907051
Valid Loss:  0.0018318623770028353
Epoch:  144  	Training Loss: 0.001745650079101324
Test Loss:  0.0011844263644888997
Valid Loss:  0.0017922623082995415
Epoch:  145  	Training Loss: 0.0017173693049699068
Test Loss:  0.001172114396467805
Valid Loss:  0.001756632118485868
Epoch:  146  	Training Loss: 0.0016916985623538494
Test Loss:  0.001163311768323183
Valid Loss:  0.0017235097475349903
Epoch:  147  	Training Loss: 0.0016676344675943255
Test Loss:  0.001159514649771154
Valid Loss:  0.0016938264016062021
Epoch:  148  	Training Loss: 0.001645055366680026
Test Loss:  0.0011565389577299356
Valid Loss:  0.001666345982812345
Epoch:  149  	Training Loss: 0.0016238766256719828
Test Loss:  0.0011540019186213613
Valid Loss:  0.0016424314817413688
Epoch:  150  	Training Loss: 0.001605483004823327
Test Loss:  0.001151613425463438
Valid Loss:  0.0016217376105487347
Epoch:  151  	Training Loss: 0.0015888642519712448
Test Loss:  0.0011494207428768277
Valid Loss:  0.0016024450305849314
Epoch:  152  	Training Loss: 0.0015739330556243658
Test Loss:  0.001148028066381812
Valid Loss:  0.0015995379071682692
Epoch:  153  	Training Loss: 0.001572396489791572
Test Loss:  0.0011473697377368808
Valid Loss:  0.0015978568699210882
Epoch:  154  	Training Loss: 0.0015716323396191
Test Loss:  0.0011470100143924356
Valid Loss:  0.0015968035440891981
Epoch:  155  	Training Loss: 0.001571214059367776
Test Loss:  0.0011467741569504142
Valid Loss:  0.001596085261553526
Epoch:  156  	Training Loss: 0.0015709458384662867
Test Loss:  0.0011465975549072027
Valid Loss:  0.0015955602284520864
Epoch:  157  	Training Loss: 0.001570759224705398
Test Loss:  0.0011464387644082308
Valid Loss:  0.0015951622044667602
Epoch:  158  	Training Loss: 0.0015706141712144017
Test Loss:  0.0011462976690381765
Valid Loss:  0.0015948417130857706
Epoch:  159  	Training Loss: 0.0015704859979450703
Test Loss:  0.0011461564572528005
Valid Loss:  0.0015945695340633392
Epoch:  160  	Training Loss: 0.0015703665558248758
Test Loss:  0.0011460199020802975
Valid Loss:  0.001594342291355133
Epoch:  161  	Training Loss: 0.0015702536329627037
Test Loss:  0.0011458862572908401
Valid Loss:  0.0015941462479531765
Epoch:  162  	Training Loss: 0.0015701481606811285
Test Loss:  0.001141927670687437
Valid Loss:  0.001581748714670539
Epoch:  163  	Training Loss: 0.0015646594110876322
Test Loss:  0.0011401819065213203
Valid Loss:  0.0015737247886136174
Epoch:  164  	Training Loss: 0.0015598185127601027
Test Loss:  0.0011384227545931935
Valid Loss:  0.0015658156480640173
Epoch:  165  	Training Loss: 0.001555555034428835
Test Loss:  0.0011367665138095617
Valid Loss:  0.0015581955667585135
Epoch:  166  	Training Loss: 0.0015514073893427849
Test Loss:  0.0011352109722793102
Valid Loss:  0.0015508836368098855
Epoch:  167  	Training Loss: 0.0015473219100385904
Test Loss:  0.0011337382020428777
Valid Loss:  0.0015438488917425275
Epoch:  168  	Training Loss: 0.001543308375403285
Test Loss:  0.0011323685757815838
Valid Loss:  0.0015370359178632498
Epoch:  169  	Training Loss: 0.0015393494395539165
Test Loss:  0.0011310696136206388
Valid Loss:  0.0015303934924304485
Epoch:  170  	Training Loss: 0.0015354491770267487
Test Loss:  0.0011298427125439048
Valid Loss:  0.0015239249914884567
Epoch:  171  	Training Loss: 0.001531628193333745
Test Loss:  0.0011286756489425898
Valid Loss:  0.0015176417073234916
Epoch:  172  	Training Loss: 0.0015278421342372894
Test Loss:  0.0011261726031079888
Valid Loss:  0.0015084609622135758
Epoch:  173  	Training Loss: 0.0015072531532496214
Test Loss:  0.0011244718916714191
Valid Loss:  0.001499092555604875
Epoch:  174  	Training Loss: 0.0014957727398723364
Test Loss:  0.001124414848163724
Valid Loss:  0.0014958351384848356
Epoch:  175  	Training Loss: 0.0014855405315756798
Test Loss:  0.0011240937747061253
Valid Loss:  0.0014900860842317343
Epoch:  176  	Training Loss: 0.001476042321883142
Test Loss:  0.0011255082208663225
Valid Loss:  0.0014878461370244622
Epoch:  177  	Training Loss: 0.0014692354016005993
Test Loss:  0.0011254943674430251
Valid Loss:  0.0014827052364125848
Epoch:  178  	Training Loss: 0.0014635277912020683
Test Loss:  0.001125927665270865
Valid Loss:  0.001480049337260425
Epoch:  179  	Training Loss: 0.001458487007766962
Test Loss:  0.001125822775065899
Valid Loss:  0.0014751740964129567
Epoch:  180  	Training Loss: 0.0014535513473674655
Test Loss:  0.0011258965823799372
Valid Loss:  0.0014719986356794834
Epoch:  181  	Training Loss: 0.0014486964792013168
Test Loss:  0.0011260237079113722
Valid Loss:  0.0014682220062240958
Epoch:  182  	Training Loss: 0.0014441239181905985
Test Loss:  0.0011207256466150284
Valid Loss:  0.0014596352120861411
Epoch:  183  	Training Loss: 0.001436330028809607
Test Loss:  0.0011182227171957493
Valid Loss:  0.0014527235180139542
Epoch:  184  	Training Loss: 0.0014301069313660264
Test Loss:  0.0011161863803863525
Valid Loss:  0.0014466254506260157
Epoch:  185  	Training Loss: 0.0014244562480598688
Test Loss:  0.0011154597159475088
Valid Loss:  0.0014420552179217339
Epoch:  186  	Training Loss: 0.0014198586577549577
Test Loss:  0.0011145349126309156
Valid Loss:  0.0014378465712070465
Epoch:  187  	Training Loss: 0.0014158680569380522
Test Loss:  0.0011140730930492282
Valid Loss:  0.0014352670405060053
Epoch:  188  	Training Loss: 0.001412165118381381
Test Loss:  0.0011138585396111012
Valid Loss:  0.0014336092863231897
Epoch:  189  	Training Loss: 0.0014086966402828693
Test Loss:  0.0011138877598568797
Valid Loss:  0.001432144781574607
Epoch:  190  	Training Loss: 0.001405390677973628
Test Loss:  0.001114196260459721
Valid Loss:  0.001431984594091773
Epoch:  191  	Training Loss: 0.0014022679533809423
Test Loss:  0.001114401500672102
Valid Loss:  0.001431922777555883
Epoch:  192  	Training Loss: 0.0014000358060002327
Test Loss:  0.001107975491322577
Valid Loss:  0.0014235585695132613
Epoch:  193  	Training Loss: 0.0013959250645712018
Test Loss:  0.001102058100514114
Valid Loss:  0.001415948267094791
Epoch:  194  	Training Loss: 0.0013920626370236278
Test Loss:  0.0010965745896100998
Valid Loss:  0.0014090763870626688
Epoch:  195  	Training Loss: 0.0013883623760193586
Test Loss:  0.0010910710552707314
Valid Loss:  0.0014025894924998283
Epoch:  196  	Training Loss: 0.0013848589733242989
Test Loss:  0.0010859454050660133
Valid Loss:  0.0013967009726911783
Epoch:  197  	Training Loss: 0.0013815349666401744
Test Loss:  0.0010811457177624106
Valid Loss:  0.0013912941794842482
Epoch:  198  	Training Loss: 0.001378356129862368
Test Loss:  0.0010766484774649143
Valid Loss:  0.0013863119529560208
Epoch:  199  	Training Loss: 0.0013753438834100962
Test Loss:  0.0010723986197263002
Valid Loss:  0.0013816786231473088
Epoch:  200  	Training Loss: 0.001372355967760086
Test Loss:  0.0010682328138500452
Valid Loss:  0.0013771571684628725
Epoch:  201  	Training Loss: 0.0013693792279809713
Test Loss:  0.0010643552523106337
Valid Loss:  0.0013729333877563477
Epoch:  202  	Training Loss: 0.0013664864236488938
Test Loss:  0.0010660013649612665
Valid Loss:  0.0013762746239081025
Epoch:  203  	Training Loss: 0.0013641322730109096
Test Loss:  0.0010677191894501448
Valid Loss:  0.0013797827996313572
Epoch:  204  	Training Loss: 0.001362580806016922
Test Loss:  0.0010692926589399576
Valid Loss:  0.0013828753726556897
Epoch:  205  	Training Loss: 0.0013611381873488426
Test Loss:  0.0010707818437367678
Valid Loss:  0.0013857657322660089
Epoch:  206  	Training Loss: 0.001360344118438661
Test Loss:  0.0010715696262195706
Valid Loss:  0.0013873411808162928
Epoch:  207  	Training Loss: 0.0013600005768239498
Test Loss:  0.0010722491424530745
Valid Loss:  0.0013886346714571118
Epoch:  208  	Training Loss: 0.0013596778735518456
Test Loss:   42%|████▏     | 209/500 [02:29<01:37,  2.99it/s] 42%|████▏     | 211/500 [02:36<05:41,  1.18s/it] 43%|████▎     | 213/500 [02:36<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:36<02:55,  1.63it/s] 43%|████▎     | 217/500 [02:36<02:07,  2.22it/s] 44%|████▍     | 219/500 [02:36<01:34,  2.98it/s] 44%|████▍     | 221/500 [02:43<05:28,  1.18s/it] 45%|████▍     | 223/500 [02:43<03:53,  1.18it/s] 45%|████▌     | 225/500 [02:43<02:48,  1.64it/s] 45%|████▌     | 227/500 [02:43<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:43<01:30,  2.99it/s] 46%|████▌     | 231/500 [02:49<05:15,  1.17s/it] 47%|████▋     | 233/500 [02:50<03:45,  1.19it/s] 47%|████▋     | 235/500 [02:50<02:42,  1.64it/s] 47%|████▋     | 237/500 [02:50<01:57,  2.23it/s] 48%|████▊     | 239/500 [02:50<01:27,  3.00it/s] 48%|████▊     | 241/500 [02:56<05:07,  1.19s/it] 49%|████▊     | 243/500 [02:56<03:39,  1.17it/s] 49%|████▉     | 245/500 [02:57<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:57<01:54,  2.20it/s] 50%|████▉     | 249/500 [02:57<01:24,  2.96it/s] 50%|█████     | 251/500 [03:03<04:51,  1.17s/it] 51%|█████     | 253/500 [03:03<03:27,  1.19it/s] 51%|█████     | 255/500 [03:03<02:28,  1.65it/s] 51%|█████▏    | 257/500 [03:03<01:48,  2.25it/s] 52%|█████▏    | 259/500 [03:04<01:19,  3.02it/s] 52%|█████▏    | 261/500 [03:10<04:38,  1.17s/it] 53%|█████▎    | 263/500 [03:10<03:18,  1.20it/s] 53%|█████▎    | 265/500 [03:10<02:22,  1.65it/s] 53%|█████▎    | 267/500 [03:10<01:43,  2.26it/s] 54%|█████▍    | 269/500 [03:10<01:16,  3.03it/s] 54%|█████▍    | 271/500 [03:17<04:26,  1.16s/it] 55%|█████▍    | 273/500 [03:17<03:09,  1.20it/s] 55%|█████▌    | 275/500 [03:17<02:15,  1.66it/s]0.0010728834895417094
Valid Loss:  0.0013898394536226988
Epoch:  209  	Training Loss: 0.0013594701886177063
Test Loss:  0.0010731457732617855
Valid Loss:  0.001390367979183793
Epoch:  210  	Training Loss: 0.0013594524934887886
Test Loss:  0.0010730496142059565
Valid Loss:  0.001390209887176752
Epoch:  211  	Training Loss: 0.0013594485353678465
Test Loss:  0.001072938903234899
Valid Loss:  0.0013899910263717175
Epoch:  212  	Training Loss: 0.001359446789138019
Test Loss:  0.0010713839437812567
Valid Loss:  0.0013887890381738544
Epoch:  213  	Training Loss: 0.0013582853134721518
Test Loss:  0.0010699452832341194
Valid Loss:  0.001387823955155909
Epoch:  214  	Training Loss: 0.0013571289600804448
Test Loss:  0.001068474375642836
Valid Loss:  0.0013867862289771438
Epoch:  215  	Training Loss: 0.0013559771468862891
Test Loss:  0.001067024888470769
Valid Loss:  0.0013857835438102484
Epoch:  216  	Training Loss: 0.0013548312708735466
Test Loss:  0.001065767602995038
Valid Loss:  0.0013847778318449855
Epoch:  217  	Training Loss: 0.001353776315227151
Test Loss:  0.0010647719027474523
Valid Loss:  0.001383917755447328
Epoch:  218  	Training Loss: 0.001352913910523057
Test Loss:  0.0010637713130563498
Valid Loss:  0.001383039983920753
Epoch:  219  	Training Loss: 0.0013520526699721813
Test Loss:  0.0010627780575305223
Valid Loss:  0.0013821767643094063
Epoch:  220  	Training Loss: 0.0013511960860341787
Test Loss:  0.0010617885272949934
Valid Loss:  0.0013813141267746687
Epoch:  221  	Training Loss: 0.0013503422960639
Test Loss:  0.0010608043521642685
Valid Loss:  0.0013804604532197118
Epoch:  222  	Training Loss: 0.001349490717984736
Test Loss:  0.0010633848141878843
Valid Loss:  0.0013812645338475704
Epoch:  223  	Training Loss: 0.0013399310410022736
Test Loss:  0.0010578688234090805
Valid Loss:  0.0013783909380435944
Epoch:  224  	Training Loss: 0.00133789936080575
Test Loss:  0.0010598432272672653
Valid Loss:  0.0013783094473183155
Epoch:  225  	Training Loss: 0.0013375371927395463
Test Loss:  0.0010573802283033729
Valid Loss:  0.0013774679973721504
Epoch:  226  	Training Loss: 0.0013375256676226854
Test Loss:  0.0010587647557258606
Valid Loss:  0.0013775581028312445
Epoch:  227  	Training Loss: 0.0013372598914429545
Test Loss:  0.001058679074048996
Valid Loss:  0.001377555774524808
Epoch:  228  	Training Loss: 0.001337242079898715
Test Loss:  0.0010584471747279167
Valid Loss:  0.0013771773083135486
Epoch:  229  	Training Loss: 0.0013372275279834867
Test Loss:  0.0010583489201962948
Valid Loss:  0.0013770975638180971
Epoch:  230  	Training Loss: 0.001337213907390833
Test Loss:  0.0010581663809716702
Valid Loss:  0.001376759260892868
Epoch:  231  	Training Loss: 0.0013372029643505812
Test Loss:  0.001058103865943849
Valid Loss:  0.0013767017517238855
Epoch:  232  	Training Loss: 0.0013371873646974564
Test Loss:  0.0010479374323040247
Valid Loss:  0.0013650422915816307
Epoch:  233  	Training Loss: 0.001331623294390738
Test Loss:  0.0010425765067338943
Valid Loss:  0.0013578957878053188
Epoch:  234  	Training Loss: 0.0013261898420751095
Test Loss:  0.0010357381543144584
Valid Loss:  0.0013494044542312622
Epoch:  235  	Training Loss: 0.0013211830519139767
Test Loss:  0.0010310928337275982
Valid Loss:  0.0013429736718535423
Epoch:  236  	Training Loss: 0.0013161625247448683
Test Loss:  0.0010247090831398964
Valid Loss:  0.0013353214599192142
Epoch:  237  	Training Loss: 0.0013112316373735666
Test Loss:  0.00101886922493577
Valid Loss:  0.0013280565617606044
Epoch:  238  	Training Loss: 0.001306466176174581
Test Loss:  0.0010149478912353516
Valid Loss:  0.001322345808148384
Epoch:  239  	Training Loss: 0.001301764277741313
Test Loss:  0.001008726074360311
Valid Loss:  0.0013151959283277392
Epoch:  240  	Training Loss: 0.0012970652896910906
Test Loss:  0.0010037303436547518
Valid Loss:  0.001308865612372756
Epoch:  241  	Training Loss: 0.00129249831661582
Test Loss:  0.000999055802822113
Valid Loss:  0.0013029627734795213
Epoch:  242  	Training Loss: 0.001288019702769816
Test Loss:  0.0009992632549256086
Valid Loss:  0.0013034199364483356
Epoch:  243  	Training Loss: 0.00128786766435951
Test Loss:  0.0009994728025048971
Valid Loss:  0.0013038694160059094
Epoch:  244  	Training Loss: 0.0012877179542556405
Test Loss:  0.0009996606968343258
Valid Loss:  0.0013042499776929617
Epoch:  245  	Training Loss: 0.0012875762768089771
Test Loss:  0.000999907380901277
Valid Loss:  0.0013047514948993921
Epoch:  246  	Training Loss: 0.001287468709051609
Test Loss:  0.0010000085458159447
Valid Loss:  0.0013049389235675335
Epoch:  247  	Training Loss: 0.0012873692903667688
Test Loss:  0.00100040715187788
Valid Loss:  0.0013057454489171505
Epoch:  248  	Training Loss: 0.0012872654478996992
Test Loss:  0.0010004752548411489
Valid Loss:  0.0013058523181825876
Epoch:  249  	Training Loss: 0.001287169405259192
Test Loss:  0.0010007853852584958
Valid Loss:  0.0013064646627753973
Epoch:  250  	Training Loss: 0.0012870875652879477
Test Loss:  0.0010009398683905602
Valid Loss:  0.0013067662948742509
Epoch:  251  	Training Loss: 0.00128702144138515
Test Loss:  0.0010012165876105428
Valid Loss:  0.0013073247391730547
Epoch:  252  	Training Loss: 0.0012869576457887888
Test Loss:  0.0009952352847903967
Valid Loss:  0.0013015453005209565
Epoch:  253  	Training Loss: 0.0012743985280394554
Test Loss:  0.0009949628729373217
Valid Loss:  0.0013012213166803122
Epoch:  254  	Training Loss: 0.0012688827700912952
Test Loss:  0.00099336844868958
Valid Loss:  0.0012999679893255234
Epoch:  255  	Training Loss: 0.0012649287236854434
Test Loss:  0.0009926584316417575
Valid Loss:  0.0012991700787097216
Epoch:  256  	Training Loss: 0.001261199708096683
Test Loss:  0.0009905456099659204
Valid Loss:  0.0012970156967639923
Epoch:  257  	Training Loss: 0.0012576961889863014
Test Loss:  0.0009878560667857528
Valid Loss:  0.0012940646847710013
Epoch:  258  	Training Loss: 0.001254354603588581
Test Loss:  0.0009847348555922508
Valid Loss:  0.0012896673288196325
Epoch:  259  	Training Loss: 0.0012511801905930042
Test Loss:  0.0009817617246881127
Valid Loss:  0.0012850312050431967
Epoch:  260  	Training Loss: 0.0012481266167014837
Test Loss:  0.000979180564172566
Valid Loss:  0.001280664699152112
Epoch:  261  	Training Loss: 0.0012450586073100567
Test Loss:  0.000976372801233083
Valid Loss:  0.001275933813303709
Epoch:  262  	Training Loss: 0.001241861144080758
Test Loss:  0.0009756633080542088
Valid Loss:  0.0012748665176331997
Epoch:  263  	Training Loss: 0.0012414254015311599
Test Loss:  0.0009751495090313256
Valid Loss:  0.0012742129620164633
Epoch:  264  	Training Loss: 0.001241047284565866
Test Loss:  0.0009744348935782909
Valid Loss:  0.0012732227332890034
Epoch:  265  	Training Loss: 0.001240717014297843
Test Loss:  0.0009735633502714336
Valid Loss:  0.0012722292449325323
Epoch:  266  	Training Loss: 0.0012404269073158503
Test Loss:  0.0009728134609758854
Valid Loss:  0.0012712834868580103
Epoch:  267  	Training Loss: 0.0012401794083416462
Test Loss:  0.0009722471586428583
Valid Loss:  0.0012706732377409935
Epoch:  268  	Training Loss: 0.001239954144693911
Test Loss:  0.0009717360371723771
Valid Loss:  0.0012699216604232788
Epoch:  269  	Training Loss: 0.0012397507671266794
Test Loss:  0.000971268629655242
Valid Loss:  0.0012692323653027415
Epoch:  270  	Training Loss: 0.0012395550729706883
Test Loss:  0.0009708930156193674
Valid Loss:  0.0012686356203630567
Epoch:  271  	Training Loss: 0.0012393805664032698
Test Loss:  0.0009705569827929139
Valid Loss:  0.001268092542886734
Epoch:  272  	Training Loss: 0.0012392103672027588
Test Loss:  0.000969774613622576
Valid Loss:  0.0012665933463722467
Epoch:  273  	Training Loss: 0.0012389979092404246
Test Loss:  0.0009691649465821683
Valid Loss:  0.0012651653960347176
Epoch:  274  	Training Loss: 0.0012388218892738223
Test Loss:  0.0009686544653959572
Valid Loss:  0.0012638252228498459
Epoch:  275  	Training Loss: 0.0012386712478473783
Test Loss:  0.0009677279740571976
Valid Loss:  0.0012623686343431473
Epoch:  276  	Training Loss: 0.0012385428417474031
Test Loss:  0.0009671634179539979
Valid Loss:  0.0012611278798431158
 55%|█████▌    | 277/500 [03:17<01:38,  2.27it/s] 56%|█████▌    | 279/500 [03:17<01:12,  3.04it/s] 56%|█████▌    | 281/500 [03:23<04:17,  1.17s/it] 57%|█████▋    | 283/500 [03:24<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:24<02:11,  1.64it/s] 57%|█████▋    | 287/500 [03:24<01:35,  2.24it/s] 58%|█████▊    | 289/500 [03:24<01:10,  3.00it/s] 58%|█████▊    | 291/500 [03:30<04:05,  1.17s/it] 59%|█████▊    | 293/500 [03:30<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:30<02:04,  1.64it/s] 59%|█████▉    | 297/500 [03:31<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:31<01:06,  3.01it/s] 60%|██████    | 301/500 [03:37<03:52,  1.17s/it] 61%|██████    | 303/500 [03:37<02:45,  1.19it/s] 61%|██████    | 305/500 [03:37<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:37<01:25,  2.26it/s] 62%|██████▏   | 309/500 [03:38<01:02,  3.03it/s] 62%|██████▏   | 311/500 [03:44<03:47,  1.20s/it] 63%|██████▎   | 313/500 [03:44<02:41,  1.16it/s] 63%|██████▎   | 315/500 [03:44<01:55,  1.60it/s] 63%|██████▎   | 317/500 [03:44<01:23,  2.19it/s] 64%|██████▍   | 319/500 [03:45<01:01,  2.94it/s] 64%|██████▍   | 321/500 [03:51<03:29,  1.17s/it] 65%|██████▍   | 323/500 [03:51<02:28,  1.19it/s] 65%|██████▌   | 325/500 [03:51<01:46,  1.65it/s] 65%|██████▌   | 327/500 [03:51<01:16,  2.25it/s] 66%|██████▌   | 329/500 [03:51<00:56,  3.02it/s] 66%|██████▌   | 331/500 [03:58<03:17,  1.17s/it] 67%|██████▋   | 333/500 [03:58<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:58<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:58<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:58<00:53,  3.00it/s] 68%|██████▊   | 341/500 [04:04<03:07,  1.18s/it] 69%|██████▊   | 343/500 [04:05<02:12,  1.18it/s]Epoch:  277  	Training Loss: 0.0012384268920868635
Test Loss:  0.0009664305252954364
Valid Loss:  0.001259886659681797
Epoch:  278  	Training Loss: 0.0012383279390633106
Test Loss:  0.0009660128271207213
Valid Loss:  0.001258813077583909
Epoch:  279  	Training Loss: 0.001238244934938848
Test Loss:  0.0009651912841945887
Valid Loss:  0.0012576553272083402
Epoch:  280  	Training Loss: 0.0012381640262901783
Test Loss:  0.000964927370660007
Valid Loss:  0.0012567505473271012
Epoch:  281  	Training Loss: 0.0012381018605083227
Test Loss:  0.000964243954513222
Valid Loss:  0.0012557592708617449
Epoch:  282  	Training Loss: 0.0012380346888676286
Test Loss:  0.0009621588978916407
Valid Loss:  0.0012518686708062887
Epoch:  283  	Training Loss: 0.0012341064866632223
Test Loss:  0.0009595031151548028
Valid Loss:  0.0012486660853028297
Epoch:  284  	Training Loss: 0.0012299632653594017
Test Loss:  0.0009564091451466084
Valid Loss:  0.0012446065666154027
Epoch:  285  	Training Loss: 0.0012260848889127374
Test Loss:  0.000953446316998452
Valid Loss:  0.001240608049556613
Epoch:  286  	Training Loss: 0.001222290564328432
Test Loss:  0.0009501772001385689
Valid Loss:  0.001235162722878158
Epoch:  287  	Training Loss: 0.0012177713215351105
Test Loss:  0.0009468844509683549
Valid Loss:  0.0012298234505578876
Epoch:  288  	Training Loss: 0.0012131305411458015
Test Loss:  0.0009435092797502875
Valid Loss:  0.00122414855286479
Epoch:  289  	Training Loss: 0.0012086257338523865
Test Loss:  0.0009400701965205371
Valid Loss:  0.001218391116708517
Epoch:  290  	Training Loss: 0.001203754567541182
Test Loss:  0.0009357904782518744
Valid Loss:  0.001212362083606422
Epoch:  291  	Training Loss: 0.0011986312456429005
Test Loss:  0.0009311899775639176
Valid Loss:  0.0012062364257872105
Epoch:  292  	Training Loss: 0.0011932558845728636
Test Loss:  0.0009290211601182818
Valid Loss:  0.001202789368107915
Epoch:  293  	Training Loss: 0.0011925501748919487
Test Loss:  0.0009268780704587698
Valid Loss:  0.0011989518534392118
Epoch:  294  	Training Loss: 0.0011919676326215267
Test Loss:  0.0009251555893570185
Valid Loss:  0.001195955672301352
Epoch:  295  	Training Loss: 0.001191468327306211
Test Loss:  0.0009235439356416464
Valid Loss:  0.001193034229800105
Epoch:  296  	Training Loss: 0.001191034447401762
Test Loss:  0.0009221783839166164
Valid Loss:  0.0011905399151146412
Epoch:  297  	Training Loss: 0.0011906553991138935
Test Loss:  0.0009209307027049363
Valid Loss:  0.0011882138205692172
Epoch:  298  	Training Loss: 0.0011903176782652736
Test Loss:  0.0009198281913995743
Valid Loss:  0.0011861282400786877
Epoch:  299  	Training Loss: 0.0011900151148438454
Test Loss:  0.0009188452968373895
Valid Loss:  0.0011842329986393452
Epoch:  300  	Training Loss: 0.0011897401418536901
Test Loss:  0.0009179719490930438
Valid Loss:  0.0011825168039649725
Epoch:  301  	Training Loss: 0.0011894896160811186
Test Loss:  0.0009171892888844013
Valid Loss:  0.0011809570714831352
Epoch:  302  	Training Loss: 0.0011892584152519703
Test Loss:  0.0009111944818869233
Valid Loss:  0.001175625016912818
Epoch:  303  	Training Loss: 0.0011828135466203094
Test Loss:  0.0009042537421919405
Valid Loss:  0.00117082754150033
Epoch:  304  	Training Loss: 0.001175686134956777
Test Loss:  0.0008962079300545156
Valid Loss:  0.0011655392590910196
Epoch:  305  	Training Loss: 0.0011679311282932758
Test Loss:  0.0008874206687323749
Valid Loss:  0.0011599492281675339
Epoch:  306  	Training Loss: 0.0011598216369748116
Test Loss:  0.0008772382279857993
Valid Loss:  0.001153889112174511
Epoch:  307  	Training Loss: 0.001150405267253518
Test Loss:  0.0008664673659950495
Valid Loss:  0.0011474500643089414
Epoch:  308  	Training Loss: 0.0011395097244530916
Test Loss:  0.0008558070403523743
Valid Loss:  0.0011405244003981352
Epoch:  309  	Training Loss: 0.0011280339676886797
Test Loss:  0.0008452533511444926
Valid Loss:  0.0011326067615300417
Epoch:  310  	Training Loss: 0.0011168320197612047
Test Loss:  0.0008344685193151236
Valid Loss:  0.0011243654880672693
Epoch:  311  	Training Loss: 0.0011051304172724485
Test Loss:  0.0008244856144301593
Valid Loss:  0.001116172643378377
Epoch:  312  	Training Loss: 0.001093697501346469
Test Loss:  0.000816868559923023
Valid Loss:  0.0011068210005760193
Epoch:  313  	Training Loss: 0.0010885470546782017
Test Loss:  0.0008107213070616126
Valid Loss:  0.0010991193121299148
Epoch:  314  	Training Loss: 0.0010842622723430395
Test Loss:  0.0008060670224949718
Valid Loss:  0.0010931009892374277
Epoch:  315  	Training Loss: 0.0010805396595969796
Test Loss:  0.0008019382366910577
Valid Loss:  0.001087655546143651
Epoch:  316  	Training Loss: 0.0010770221706479788
Test Loss:  0.0007982003735378385
Valid Loss:  0.0010827252408489585
Epoch:  317  	Training Loss: 0.0010736030526459217
Test Loss:  0.0007946195546537638
Valid Loss:  0.001077916705980897
Epoch:  318  	Training Loss: 0.0010702398139983416
Test Loss:  0.0007911720895208418
Valid Loss:  0.0010732756927609444
Epoch:  319  	Training Loss: 0.0010669201146811247
Test Loss:  0.0007878381293267012
Valid Loss:  0.0010688335169106722
Epoch:  320  	Training Loss: 0.0010636360384523869
Test Loss:  0.0007846027729101479
Valid Loss:  0.0010645604925230145
Epoch:  321  	Training Loss: 0.0010603814153000712
Test Loss:  0.0007814563577994704
Valid Loss:  0.0010604390408843756
Epoch:  322  	Training Loss: 0.0010571361053735018
Test Loss:  0.0007705683819949627
Valid Loss:  0.0010466964449733496
Epoch:  323  	Training Loss: 0.001050912425853312
Test Loss:  0.000763511226978153
Valid Loss:  0.0010366595815867186
Epoch:  324  	Training Loss: 0.0010467597749084234
Test Loss:  0.000757924688514322
Valid Loss:  0.001028913538902998
Epoch:  325  	Training Loss: 0.0010434349533170462
Test Loss:  0.0007540318765677512
Valid Loss:  0.0010230601765215397
Epoch:  326  	Training Loss: 0.0010409599635750055
Test Loss:  0.0007510839495807886
Valid Loss:  0.001018877374008298
Epoch:  327  	Training Loss: 0.0010388708906248212
Test Loss:  0.0007486753747798502
Valid Loss:  0.0010153187904506922
Epoch:  328  	Training Loss: 0.0010371573735028505
Test Loss:  0.0007467537652701139
Valid Loss:  0.001012524589896202
Epoch:  329  	Training Loss: 0.0010357614373788238
Test Loss:  0.0007452975842170417
Valid Loss:  0.0010104987304657698
Epoch:  330  	Training Loss: 0.0010346261551603675
Test Loss:  0.000744226505048573
Valid Loss:  0.0010089441202580929
Epoch:  331  	Training Loss: 0.001033676671795547
Test Loss:  0.0007434368599206209
Valid Loss:  0.0010076840408146381
Epoch:  332  	Training Loss: 0.0010328269563615322
Test Loss:  0.0007416894659399986
Valid Loss:  0.0010063066147267818
Epoch:  333  	Training Loss: 0.0010310439392924309
Test Loss:  0.0007400952745229006
Valid Loss:  0.0010055024176836014
Epoch:  334  	Training Loss: 0.0010293049272149801
Test Loss:  0.0007385901408270001
Valid Loss:  0.00100440823007375
Epoch:  335  	Training Loss: 0.0010276518296450377
Test Loss:  0.0007373109692707658
Valid Loss:  0.0010035421000793576
Epoch:  336  	Training Loss: 0.0010261689312756062
Test Loss:  0.0007360297604463995
Valid Loss:  0.001002598786726594
Epoch:  337  	Training Loss: 0.0010247125755995512
Test Loss:  0.0007347536738961935
Valid Loss:  0.0010016795713454485
Epoch:  338  	Training Loss: 0.0010232721688225865
Test Loss:  0.0007334878901019692
Valid Loss:  0.0010007494129240513
Epoch:  339  	Training Loss: 0.0010218546958640218
Test Loss:  0.0007322246674448252
Valid Loss:  0.000999864423647523
Epoch:  340  	Training Loss: 0.0010204447899013758
Test Loss:  0.0007309624343179166
Valid Loss:  0.000998971052467823
Epoch:  341  	Training Loss: 0.0010190417524427176
Test Loss:  0.0007297036936506629
Valid Loss:  0.0009980762843042612
Epoch:  342  	Training Loss: 0.0010176531504839659
Test Loss:  0.0007193924393504858
Valid Loss:  0.0009912046371027827
Epoch:  343  	Training Loss: 0.001002988195978105
Test Loss:  0.0007096030749380589
Valid Loss:  0.0009851257782429457
Epoch:  344  	Training Loss: 0.0009891438530758023
Test Loss:  0.0006998615572229028
Valid Loss:  0.000976835610345006
Epoch:  345  	Training Loss: 0.000975934905000031
Test Loss:   69%|██████▉   | 345/500 [04:05<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:05<01:08,  2.23it/s] 70%|██████▉   | 349/500 [04:05<00:50,  3.00it/s] 70%|███████   | 351/500 [04:11<02:54,  1.17s/it] 71%|███████   | 353/500 [04:11<02:04,  1.18it/s] 71%|███████   | 355/500 [04:11<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:12<01:04,  2.20it/s] 72%|███████▏  | 359/500 [04:12<00:47,  2.96it/s] 72%|███████▏  | 361/500 [04:18<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:18<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:18<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:18<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:19<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:25<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:25<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:25<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:25<00:55,  2.20it/s] 76%|███████▌  | 379/500 [04:25<00:41,  2.94it/s] 76%|███████▌  | 381/500 [04:32<02:23,  1.20s/it] 77%|███████▋  | 383/500 [04:32<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:32<01:11,  1.60it/s] 77%|███████▋  | 387/500 [04:32<00:51,  2.18it/s] 78%|███████▊  | 389/500 [04:32<00:37,  2.94it/s] 78%|███████▊  | 391/500 [04:39<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:39<01:29,  1.19it/s] 79%|███████▉  | 395/500 [04:39<01:03,  1.64it/s] 79%|███████▉  | 397/500 [04:39<00:45,  2.24it/s] 80%|███████▉  | 399/500 [04:39<00:33,  3.01it/s] 80%|████████  | 401/500 [04:46<01:57,  1.18s/it] 81%|████████  | 403/500 [04:46<01:22,  1.18it/s] 81%|████████  | 405/500 [04:46<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:46<00:41,  2.22it/s] 82%|████████▏ | 409/500 [04:46<00:30,  2.99it/s] 82%|████████▏ | 411/500 [04:52<01:43,  1.17s/it] 83%|████████▎ | 413/500 [04:52<01:12,  1.19it/s]0.0006890030344948173
Valid Loss:  0.0009682035306468606
Epoch:  346  	Training Loss: 0.0009615441085770726
Test Loss:  0.0006775241927243769
Valid Loss:  0.0009585811640135944
Epoch:  347  	Training Loss: 0.0009457686683163047
Test Loss:  0.0006653494201600552
Valid Loss:  0.0009487975621595979
Epoch:  348  	Training Loss: 0.0009293355979025364
Test Loss:  0.0006509015802294016
Valid Loss:  0.0009366339072585106
Epoch:  349  	Training Loss: 0.0009107178193517029
Test Loss:  0.0006345076253637671
Valid Loss:  0.0009231397416442633
Epoch:  350  	Training Loss: 0.0008911625482141972
Test Loss:  0.0006185611709952354
Valid Loss:  0.000908549060113728
Epoch:  351  	Training Loss: 0.0008715818403288722
Test Loss:  0.0006026054034009576
Valid Loss:  0.0008930318290367723
Epoch:  352  	Training Loss: 0.0008513783686794341
Test Loss:  0.000598308106418699
Valid Loss:  0.0008870948804542422
Epoch:  353  	Training Loss: 0.000849677249789238
Test Loss:  0.0005955657106824219
Valid Loss:  0.0008830522419884801
Epoch:  354  	Training Loss: 0.0008487614104524255
Test Loss:  0.0005936367670074105
Valid Loss:  0.0008800596697255969
Epoch:  355  	Training Loss: 0.0008481874829158187
Test Loss:  0.0005921606789343059
Valid Loss:  0.0008776834001764655
Epoch:  356  	Training Loss: 0.00084776955191046
Test Loss:  0.0005909624742344022
Valid Loss:  0.0008756954921409488
Epoch:  357  	Training Loss: 0.0008474310161545873
Test Loss:  0.0005899429670535028
Valid Loss:  0.0008739721379242837
Epoch:  358  	Training Loss: 0.0008471371256746352
Test Loss:  0.0005890345200896263
Valid Loss:  0.0008724216604605317
Epoch:  359  	Training Loss: 0.0008468790911138058
Test Loss:  0.0005882229888811707
Valid Loss:  0.0008710251422598958
Epoch:  360  	Training Loss: 0.00084664486348629
Test Loss:  0.0005874847993254662
Valid Loss:  0.000869748299010098
Epoch:  361  	Training Loss: 0.0008464319398626685
Test Loss:  0.0005868111038580537
Valid Loss:  0.0008685736102052033
Epoch:  362  	Training Loss: 0.0008462347323074937
Test Loss:  0.0005860641831532121
Valid Loss:  0.0008665359928272665
Epoch:  363  	Training Loss: 0.0008451780304312706
Test Loss:  0.0005858585936948657
Valid Loss:  0.0008658828446641564
Epoch:  364  	Training Loss: 0.0008445843122899532
Test Loss:  0.0005853351322002709
Valid Loss:  0.0008645367342978716
Epoch:  365  	Training Loss: 0.000844145193696022
Test Loss:  0.0005849075387232006
Valid Loss:  0.0008636029670014977
Epoch:  366  	Training Loss: 0.0008437439100816846
Test Loss:  0.0005845014238730073
Valid Loss:  0.0008625100017525256
Epoch:  367  	Training Loss: 0.00084339315071702
Test Loss:  0.0005840748781338334
Valid Loss:  0.0008613918907940388
Epoch:  368  	Training Loss: 0.0008430847665295005
Test Loss:  0.0005834953626617789
Valid Loss:  0.0008598975837230682
Epoch:  369  	Training Loss: 0.0008428898872807622
Test Loss:  0.0005829507135786116
Valid Loss:  0.0008585813920944929
Epoch:  370  	Training Loss: 0.0008427205611951649
Test Loss:  0.0005824979161843657
Valid Loss:  0.0008574327803216875
Epoch:  371  	Training Loss: 0.0008425645646639168
Test Loss:  0.0005821124650537968
Valid Loss:  0.0008563889423385262
Epoch:  372  	Training Loss: 0.0008424174156971276
Test Loss:  0.0005753031582571566
Valid Loss:  0.0008489664178341627
Epoch:  373  	Training Loss: 0.0008375962497666478
Test Loss:  0.0005701147019863129
Valid Loss:  0.0008426898275502026
Epoch:  374  	Training Loss: 0.0008336781756952405
Test Loss:  0.0005659132730215788
Valid Loss:  0.000837537576444447
Epoch:  375  	Training Loss: 0.0008302634814754128
Test Loss:  0.0005620907177217305
Valid Loss:  0.000833128928206861
Epoch:  376  	Training Loss: 0.0008271278347820044
Test Loss:  0.0005588075146079063
Valid Loss:  0.000829347234684974
Epoch:  377  	Training Loss: 0.0008243879419751465
Test Loss:  0.0005561307771131396
Valid Loss:  0.0008260879549197853
Epoch:  378  	Training Loss: 0.0008219538722187281
Test Loss:  0.0005539433914236724
Valid Loss:  0.0008234733832068741
Epoch:  379  	Training Loss: 0.0008197558345273137
Test Loss:  0.0005519413389265537
Valid Loss:  0.0008213272085413337
Epoch:  380  	Training Loss: 0.0008176497649401426
Test Loss:  0.0005500800907611847
Valid Loss:  0.0008194213733077049
Epoch:  381  	Training Loss: 0.0008156882831826806
Test Loss:  0.0005484672728925943
Valid Loss:  0.0008177298586815596
Epoch:  382  	Training Loss: 0.0008138794219121337
Test Loss:  0.0005486772861331701
Valid Loss:  0.0008182969177141786
Epoch:  383  	Training Loss: 0.0008138242410495877
Test Loss:  0.0005488062743097544
Valid Loss:  0.0008185722399502993
Epoch:  384  	Training Loss: 0.0008137724944390357
Test Loss:  0.0005489610484801233
Valid Loss:  0.0008189553627744317
Epoch:  385  	Training Loss: 0.0008137283148244023
Test Loss:  0.0005490886396728456
Valid Loss:  0.000819256529211998
Epoch:  386  	Training Loss: 0.0008136855904012918
Test Loss:  0.0005492238560691476
Valid Loss:  0.0008195673581212759
Epoch:  387  	Training Loss: 0.0008136448450386524
Test Loss:  0.0005493465578183532
Valid Loss:  0.0008198381401598454
Epoch:  388  	Training Loss: 0.0008136110845953226
Test Loss:  0.0005494625074788928
Valid Loss:  0.000820101413410157
Epoch:  389  	Training Loss: 0.0008135770913213491
Test Loss:  0.000549571355804801
Valid Loss:  0.0008203373290598392
Epoch:  390  	Training Loss: 0.0008135456591844559
Test Loss:  0.0005496838712133467
Valid Loss:  0.0008205646881833673
Epoch:  391  	Training Loss: 0.0008135214447975159
Test Loss:  0.000549782533198595
Valid Loss:  0.0008207509526982903
Epoch:  392  	Training Loss: 0.0008135046809911728
Test Loss:  0.0005483282147906721
Valid Loss:  0.0008184029720723629
Epoch:  393  	Training Loss: 0.0008124462328851223
Test Loss:  0.0005470230244100094
Valid Loss:  0.0008158017881214619
Epoch:  394  	Training Loss: 0.0008115585660561919
Test Loss:  0.0005459751118905842
Valid Loss:  0.0008138373377732933
Epoch:  395  	Training Loss: 0.0008108151378110051
Test Loss:  0.0005451183533295989
Valid Loss:  0.0008122052531689405
Epoch:  396  	Training Loss: 0.0008101633284240961
Test Loss:  0.0005444561829790473
Valid Loss:  0.0008109413902275264
Epoch:  397  	Training Loss: 0.000809615885373205
Test Loss:  0.0005438848747871816
Valid Loss:  0.0008098820107989013
Epoch:  398  	Training Loss: 0.0008091139607131481
Test Loss:  0.0005434146150946617
Valid Loss:  0.0008089683251455426
Epoch:  399  	Training Loss: 0.0008086513262242079
Test Loss:  0.0005430534947663546
Valid Loss:  0.0008082723943516612
Epoch:  400  	Training Loss: 0.0008082480635493994
Test Loss:  0.0005427500000223517
Valid Loss:  0.0008077223901636899
Epoch:  401  	Training Loss: 0.0008078617975115776
Test Loss:  0.0005425066919997334
Valid Loss:  0.000807259522844106
Epoch:  402  	Training Loss: 0.0008075032383203506
Test Loss:  0.0005423779366537929
Valid Loss:  0.0008077836246229708
Epoch:  403  	Training Loss: 0.0008065278525464237
Test Loss:  0.0005427102441899478
Valid Loss:  0.0008098823600448668
Epoch:  404  	Training Loss: 0.0008057106169871986
Test Loss:  0.0005425676936283708
Valid Loss:  0.0008102574502117932
Epoch:  405  	Training Loss: 0.0008049389580264688
Test Loss:  0.0005427309079095721
Valid Loss:  0.0008117769611999393
Epoch:  406  	Training Loss: 0.0008042525150813162
Test Loss:  0.000542636786121875
Valid Loss:  0.0008120128186419606
Epoch:  407  	Training Loss: 0.0008036253275349736
Test Loss:  0.0005427702562883496
Valid Loss:  0.0008131100330501795
Epoch:  408  	Training Loss: 0.0008030626340769231
Test Loss:  0.0005425993003882468
Valid Loss:  0.00081259710714221
Epoch:  409  	Training Loss: 0.000802571710664779
Test Loss:  0.0005430192686617374
Valid Loss:  0.0008142800070345402
Epoch:  410  	Training Loss: 0.0008021219400689006
Test Loss:  0.0005429144948720932
Valid Loss:  0.00081363704521209
Epoch:  411  	Training Loss: 0.0008017141371965408
Test Loss:  0.0005432468606159091
Valid Loss:  0.0008148710476234555
Epoch:  412  	Training Loss: 0.0008013448095880449
Test Loss:  0.0005431530298665166
Valid Loss:  0.0008145796018652618
Epoch:  413  	Training Loss: 0.0008009611046873033
Test Loss:  0.0005431422032415867
Valid Loss:  0.0008144058519974351
 83%|████████▎ | 415/500 [04:53<00:51,  1.65it/s] 83%|████████▎ | 417/500 [04:53<00:36,  2.25it/s] 84%|████████▍ | 419/500 [04:53<00:26,  3.03it/s] 84%|████████▍ | 421/500 [04:59<01:31,  1.16s/it] 85%|████████▍ | 423/500 [04:59<01:04,  1.20it/s] 85%|████████▌ | 425/500 [04:59<00:45,  1.65it/s] 85%|████████▌ | 427/500 [04:59<00:32,  2.26it/s] 86%|████████▌ | 429/500 [05:00<00:23,  3.03it/s] 86%|████████▌ | 431/500 [05:06<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:06<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:06<00:39,  1.65it/s] 87%|████████▋ | 437/500 [05:06<00:27,  2.25it/s] 88%|████████▊ | 439/500 [05:06<00:20,  3.02it/s] 88%|████████▊ | 441/500 [05:13<01:08,  1.16s/it] 89%|████████▊ | 443/500 [05:13<00:47,  1.20it/s] 89%|████████▉ | 445/500 [05:13<00:33,  1.66it/s] 89%|████████▉ | 447/500 [05:13<00:23,  2.26it/s] 90%|████████▉ | 449/500 [05:13<00:16,  3.03it/s] 90%|█████████ | 451/500 [05:19<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:20<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:20<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:20<00:19,  2.22it/s] 92%|█████████▏| 459/500 [05:20<00:13,  2.99it/s] 92%|█████████▏| 461/500 [05:26<00:45,  1.16s/it] 93%|█████████▎| 463/500 [05:26<00:30,  1.20it/s] 93%|█████████▎| 465/500 [05:26<00:21,  1.65it/s] 93%|█████████▎| 467/500 [05:27<00:14,  2.26it/s] 94%|█████████▍| 469/500 [05:27<00:10,  3.04it/s] 94%|█████████▍| 471/500 [05:33<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:33<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:33<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:33<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:34<00:07,  3.00it/s] 96%|█████████▌| 481/500 [05:40<00:22,  1.16s/it]Epoch:  414  	Training Loss: 0.0008006321731954813
Test Loss:  0.0005431526224128902
Valid Loss:  0.0008143228478729725
Epoch:  415  	Training Loss: 0.0008003555703908205
Test Loss:  0.000543166184797883
Valid Loss:  0.0008142531150951982
Epoch:  416  	Training Loss: 0.00080009491648525
Test Loss:  0.0005431832978501916
Valid Loss:  0.0008142212172970176
Epoch:  417  	Training Loss: 0.0007998781511560082
Test Loss:  0.000543203903362155
Valid Loss:  0.0008142042788676918
Epoch:  418  	Training Loss: 0.000799679895862937
Test Loss:  0.0005432263715192676
Valid Loss:  0.000814188621006906
Epoch:  419  	Training Loss: 0.0007994961342774332
Test Loss:  0.0005432510515674949
Valid Loss:  0.0008141665020957589
Epoch:  420  	Training Loss: 0.0007993237813934684
Test Loss:  0.0005432745674625039
Valid Loss:  0.0008141524740494788
Epoch:  421  	Training Loss: 0.0007991615566425025
Test Loss:  0.0005432998295873404
Valid Loss:  0.00081415637396276
Epoch:  422  	Training Loss: 0.0007990040467120707
Test Loss:  0.0005434136837720871
Valid Loss:  0.0008144215680658817
Epoch:  423  	Training Loss: 0.0007989993318915367
Test Loss:  0.0005435147904790938
Valid Loss:  0.0008146624313667417
Epoch:  424  	Training Loss: 0.0007989951409399509
Test Loss:  0.000543606816790998
Valid Loss:  0.0008148768683895469
Epoch:  425  	Training Loss: 0.0007989916484802961
Test Loss:  0.0005436885985545814
Valid Loss:  0.0008150742505677044
Epoch:  426  	Training Loss: 0.0007989890873432159
Test Loss:  0.0005437627551145852
Valid Loss:  0.0008152499212883413
Epoch:  427  	Training Loss: 0.0007989866426214576
Test Loss:  0.0005438319640234113
Valid Loss:  0.0008154091774486005
Epoch:  428  	Training Loss: 0.0007989851292222738
Test Loss:  0.0005438927328214049
Valid Loss:  0.0008155524265021086
Epoch:  429  	Training Loss: 0.0007989841978996992
Test Loss:  0.0005439472151920199
Valid Loss:  0.000815682637039572
Epoch:  430  	Training Loss: 0.0007989822770468891
Test Loss:  0.0005439961678348482
Valid Loss:  0.0008158010896295309
Epoch:  431  	Training Loss: 0.0007989814039319754
Test Loss:  0.0005440422100946307
Valid Loss:  0.0008159060962498188
Epoch:  432  	Training Loss: 0.0007989808218553662
Test Loss:  0.0005440880777314305
Valid Loss:  0.0008160746656358242
Epoch:  433  	Training Loss: 0.0007983588147908449
Test Loss:  0.0005440945387817919
Valid Loss:  0.0008160561555996537
Epoch:  434  	Training Loss: 0.0007978151552379131
Test Loss:  0.000544064911082387
Valid Loss:  0.0008159513818100095
Epoch:  435  	Training Loss: 0.000797281158156693
Test Loss:  0.0005440022796392441
Valid Loss:  0.0008157803094945848
Epoch:  436  	Training Loss: 0.0007967542042024434
Test Loss:  0.0005439170054160058
Valid Loss:  0.0008155571995303035
Epoch:  437  	Training Loss: 0.0007962329545989633
Test Loss:  0.0005438470398075879
Valid Loss:  0.000815336243249476
Epoch:  438  	Training Loss: 0.0007957405177876353
Test Loss:  0.000543783011380583
Valid Loss:  0.0008151219226419926
Epoch:  439  	Training Loss: 0.0007952674059197307
Test Loss:  0.000543722533620894
Valid Loss:  0.0008148738415911794
Epoch:  440  	Training Loss: 0.000794807041529566
Test Loss:  0.0005436388310045004
Valid Loss:  0.0008144959574565291
Epoch:  441  	Training Loss: 0.0007944160024635494
Test Loss:  0.0005435190396383405
Valid Loss:  0.0008140256395563483
Epoch:  442  	Training Loss: 0.0007940554642118514
Test Loss:  0.0005275094881653786
Valid Loss:  0.0007977342465892434
Epoch:  443  	Training Loss: 0.0007700127316638827
Test Loss:  0.0005120332352817059
Valid Loss:  0.0007855591829866171
Epoch:  444  	Training Loss: 0.0007493208977393806
Test Loss:  0.0004975813208147883
Valid Loss:  0.0007696231477893889
Epoch:  445  	Training Loss: 0.0007296919939108193
Test Loss:  0.0004822907503694296
Valid Loss:  0.0007560992962680757
Epoch:  446  	Training Loss: 0.000709949410520494
Test Loss:  0.00046853930689394474
Valid Loss:  0.0007373795378953218
Epoch:  447  	Training Loss: 0.0006909032817929983
Test Loss:  0.0004547923745121807
Valid Loss:  0.0007222117274068296
Epoch:  448  	Training Loss: 0.0006725871935486794
Test Loss:  0.0004421065386850387
Valid Loss:  0.0007038788171485066
Epoch:  449  	Training Loss: 0.0006548783858306706
Test Loss:  0.0004293381643947214
Valid Loss:  0.0006881941808387637
Epoch:  450  	Training Loss: 0.0006376545061357319
Test Loss:  0.0004171126347500831
Valid Loss:  0.0006711183814331889
Epoch:  451  	Training Loss: 0.000620885519310832
Test Loss:  0.0004049244453199208
Valid Loss:  0.000655822514090687
Epoch:  452  	Training Loss: 0.0006046327180229127
Test Loss:  0.00040411227382719517
Valid Loss:  0.0006547609809786081
Epoch:  453  	Training Loss: 0.0006038675783202052
Test Loss:  0.00040303939022123814
Valid Loss:  0.0006529096281155944
Epoch:  454  	Training Loss: 0.0006034484831616282
Test Loss:  0.0004020235501229763
Valid Loss:  0.0006511292303912342
Epoch:  455  	Training Loss: 0.0006030772347003222
Test Loss:  0.0004010818956885487
Valid Loss:  0.0006494676927104592
Epoch:  456  	Training Loss: 0.0006027466151863337
Test Loss:  0.000400214281398803
Valid Loss:  0.0006479168077930808
Epoch:  457  	Training Loss: 0.0006024542963132262
Test Loss:  0.00039940536953508854
Valid Loss:  0.000646461034193635
Epoch:  458  	Training Loss: 0.000602194108068943
Test Loss:  0.0003986588562838733
Valid Loss:  0.0006451036315411329
Epoch:  459  	Training Loss: 0.0006019627908244729
Test Loss:  0.0003979697939939797
Valid Loss:  0.0006438388954848051
Epoch:  460  	Training Loss: 0.0006017570267431438
Test Loss:  0.00039733073208481073
Valid Loss:  0.0006426589097827673
Epoch:  461  	Training Loss: 0.0006015740800648928
Test Loss:  0.0003967408847529441
Valid Loss:  0.0006415567477233708
Epoch:  462  	Training Loss: 0.0006014105747453868
Test Loss:  0.00038537016371265054
Valid Loss:  0.0006281271926127374
Epoch:  463  	Training Loss: 0.0005851545138284564
Test Loss:  0.0003761578700505197
Valid Loss:  0.0006174007430672646
Epoch:  464  	Training Loss: 0.0005713447462767363
Test Loss:  0.00036754438770003617
Valid Loss:  0.0006073598051443696
Epoch:  465  	Training Loss: 0.0005584582686424255
Test Loss:  0.0003593177243601531
Valid Loss:  0.0005976887769065797
Epoch:  466  	Training Loss: 0.0005462754634208977
Test Loss:  0.00035147182643413544
Valid Loss:  0.0005883444100618362
Epoch:  467  	Training Loss: 0.000534741033334285
Test Loss:  0.00034403486642986536
Valid Loss:  0.0005793042946606874
Epoch:  468  	Training Loss: 0.0005238899611867964
Test Loss:  0.00033694319427013397
Valid Loss:  0.0005705817020498216
Epoch:  469  	Training Loss: 0.0005137413972988725
Test Loss:  0.00033018755493685603
Valid Loss:  0.0005624143523164093
Epoch:  470  	Training Loss: 0.000504191208165139
Test Loss:  0.00032376154558733106
Valid Loss:  0.0005546294269151986
Epoch:  471  	Training Loss: 0.0004951448645442724
Test Loss:  0.0003176479076500982
Valid Loss:  0.0005471552722156048
Epoch:  472  	Training Loss: 0.00048671261174604297
Test Loss:  0.0003133637655992061
Valid Loss:  0.000541035900823772
Epoch:  473  	Training Loss: 0.00048330044955946505
Test Loss:  0.000310820818413049
Valid Loss:  0.0005366250406950712
Epoch:  474  	Training Loss: 0.0004817555600311607
Test Loss:  0.0003087286604568362
Valid Loss:  0.0005329675041139126
Epoch:  475  	Training Loss: 0.00048053270438686013
Test Loss:  0.00030707198311574757
Valid Loss:  0.0005299366894178092
Epoch:  476  	Training Loss: 0.0004796012653969228
Test Loss:  0.0003056988352909684
Valid Loss:  0.0005273518618196249
Epoch:  477  	Training Loss: 0.0004788456717506051
Test Loss:  0.0003045931807719171
Valid Loss:  0.000525163603015244
Epoch:  478  	Training Loss: 0.0004782378673553467
Test Loss:  0.0003037024871446192
Valid Loss:  0.0005233623087406158
Epoch:  479  	Training Loss: 0.0004777586436830461
Test Loss:  0.0003029725339729339
Valid Loss:  0.0005218246951699257
Epoch:  480  	Training Loss: 0.00047736053238622844
Test Loss:  0.0003024377510882914
Valid Loss:  0.0005206920905038714
Epoch:  481  	Training Loss: 0.0004770618979819119
Test Loss:  0.0003019298892468214
Valid Loss:  0.0005196813144721091
 97%|█████████▋| 483/500 [05:40<00:14,  1.20it/s] 97%|█████████▋| 485/500 [05:40<00:09,  1.66it/s] 97%|█████████▋| 487/500 [05:40<00:05,  2.26it/s] 98%|█████████▊| 489/500 [05:40<00:03,  3.04it/s] 98%|█████████▊| 491/500 [05:47<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:47<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:47<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:47<00:01,  2.23it/s]100%|█████████▉| 499/500 [05:47<00:00,  3.00it/s]100%|██████████| 500/500 [05:47<00:00,  1.44it/s]
Epoch:  482  	Training Loss: 0.00047680403804406524
Test Loss:  0.0003017486596945673
Valid Loss:  0.000519283174071461
Epoch:  483  	Training Loss: 0.000476777961011976
Test Loss:  0.0003016683040186763
Valid Loss:  0.0005190506344661117
Epoch:  484  	Training Loss: 0.00047675654059275985
Test Loss:  0.0003016663249582052
Valid Loss:  0.0005189695511944592
Epoch:  485  	Training Loss: 0.00047675188397988677
Test Loss:  0.00030150427483022213
Valid Loss:  0.0005186366615816951
Epoch:  486  	Training Loss: 0.0004767489735968411
Test Loss:  0.00030154408887028694
Valid Loss:  0.0005186298512853682
Epoch:  487  	Training Loss: 0.00047674417146481574
Test Loss:  0.00030147802317515016
Valid Loss:  0.0005184815963730216
Epoch:  488  	Training Loss: 0.00047674274537712336
Test Loss:  0.000301446852972731
Valid Loss:  0.0005183876492083073
Epoch:  489  	Training Loss: 0.0004767409118358046
Test Loss:  0.00030141480965539813
Valid Loss:  0.0005183049943298101
Epoch:  490  	Training Loss: 0.0004767404461745173
Test Loss:  0.0003013873938471079
Valid Loss:  0.0005182272288948298
Epoch:  491  	Training Loss: 0.0004767386708408594
Test Loss:  0.00030135951237753034
Valid Loss:  0.0005181517917662859
Epoch:  492  	Training Loss: 0.0004767381469719112
Test Loss:  0.00029785375227220356
Valid Loss:  0.0005167014896869659
Epoch:  493  	Training Loss: 0.0004705960745923221
Test Loss:  0.000294926023343578
Valid Loss:  0.0005152575904503465
Epoch:  494  	Training Loss: 0.0004664426378440112
Test Loss:  0.00029308570083230734
Valid Loss:  0.0005134291131980717
Epoch:  495  	Training Loss: 0.00046357919927686453
Test Loss:  0.0002915054792538285
Valid Loss:  0.0005113787483423948
Epoch:  496  	Training Loss: 0.000461255491245538
Test Loss:  0.00028993896557949483
Valid Loss:  0.000509324949234724
Epoch:  497  	Training Loss: 0.0004591878969222307
Test Loss:  0.000288477836875245
Valid Loss:  0.0005071783089078963
Epoch:  498  	Training Loss: 0.0004572609323076904
Test Loss:  0.0002870069001801312
Valid Loss:  0.0005049521569162607
Epoch:  499  	Training Loss: 0.00045546924229711294
Test Loss:  0.0002855367201846093
Valid Loss:  0.0005028601735830307
Epoch:  500  	Training Loss: 0.00045373011380434036
Test Loss:  0.0002841771056409925
Valid Loss:  0.0005009402520954609
seed is  19
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:31, 16.03it/s]  1%|          | 4/500 [00:00<00:30, 16.46it/s]  1%|          | 6/500 [00:00<00:29, 16.63it/s]  2%|▏         | 8/500 [00:00<00:29, 16.66it/s]  2%|▏         | 10/500 [00:00<00:29, 16.54it/s]  2%|▏         | 12/500 [00:00<00:30, 16.27it/s]  3%|▎         | 14/500 [00:00<00:29, 16.26it/s]  3%|▎         | 16/500 [00:00<00:29, 16.27it/s]  4%|▎         | 18/500 [00:01<00:29, 16.37it/s]  4%|▍         | 20/500 [00:01<00:29, 16.39it/s]  4%|▍         | 22/500 [00:01<00:28, 16.54it/s]  5%|▍         | 24/500 [00:01<00:28, 16.62it/s]  5%|▌         | 26/500 [00:01<00:28, 16.53it/s]  6%|▌         | 28/500 [00:01<00:31, 15.05it/s]  6%|▌         | 30/500 [00:01<00:30, 15.21it/s]  6%|▋         | 32/500 [00:01<00:30, 15.51it/s]  7%|▋         | 34/500 [00:02<00:29, 15.76it/s]  7%|▋         | 36/500 [00:02<00:29, 15.92it/s]  8%|▊         | 38/500 [00:02<00:28, 16.18it/s]  8%|▊         | 40/500 [00:02<00:28, 16.37it/s]  8%|▊         | 42/500 [00:02<00:27, 16.48it/s]  9%|▉         | 44/500 [00:02<00:27, 16.61it/s]  9%|▉         | 46/500 [00:02<00:27, 16.69it/s] 10%|▉         | 48/500 [00:02<00:27, 16.57it/s] 10%|█         | 50/500 [00:03<00:27, 16.61it/s] 10%|█         | 52/500 [00:03<00:27, 16.54it/s] 11%|█         | 54/500 [00:03<00:26, 16.53it/s] 11%|█         | 56/500 [00:03<00:26, 16.60it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.63it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.66it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.70it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.73it/s] 13%|█▎        | 66/500 [00:04<00:25, 16.76it/s] 14%|█▎        | 68/500 [00:04<00:25, 16.65it/s] 14%|█▍        | 70/500 [00:04<00:25, 16.64it/s] 14%|█▍        | 72/500 [00:04<00:25, 16.67it/s] 15%|█▍        | 74/500 [00:04<00:25, 16.68it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.71it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.74it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.71it/s] 16%|█▋        | 82/500 [00:04<00:25, 16.54it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.59it/s] 17%|█▋        | 86/500 [00:05<00:24, 16.65it/s] 18%|█▊        | 88/500 [00:05<00:24, 16.70it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.73it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.71it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.48it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.37it/s] 20%|█▉        | 98/500 [00:05<00:24, 16.41it/s] 20%|██        | 100/500 [00:06<00:24, 16.54it/s] 20%|██        | 102/500 [00:06<00:24, 16.58it/s] 21%|██        | 104/500 [00:06<00:23, 16.68it/s] 21%|██        | 106/500 [00:06<00:23, 16.65it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.48it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.47it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.50it/s] 23%|██▎       | 114/500 [00:06<00:23, 16.57it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.54it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.55it/s] 24%|██▍       | 120/500 [00:07<00:22, 16.58it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.58it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.49it/s]Epoch:  1  	Training Loss: 0.03725326061248779
Test Loss:  663.5069580078125
Valid Loss:  664.6196899414062
Epoch:  2  	Training Loss: 656.8864135742188
Test Loss:  37000245673984.0
Valid Loss:  37013701001216.0
Epoch:  3  	Training Loss: 37124053139456.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.45it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.50it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.44it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.39it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.48it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.54it/s] 28%|██▊       | 138/500 [00:08<00:21, 16.59it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.69it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.75it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.70it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.60it/s] 30%|██▉       | 148/500 [00:08<00:21, 16.55it/s] 30%|███       | 150/500 [00:09<00:21, 16.49it/s] 30%|███       | 152/500 [00:09<00:21, 16.52it/s] 31%|███       | 154/500 [00:09<00:20, 16.59it/s] 31%|███       | 156/500 [00:09<00:20, 16.66it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.37it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.40it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.50it/s] 33%|███▎      | 164/500 [00:09<00:20, 16.56it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.60it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.52it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.48it/s] 34%|███▍      | 172/500 [00:10<00:19, 16.43it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.40it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.45it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.52it/s] 36%|███▌      | 180/500 [00:10<00:19, 16.42it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.24it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.33it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.45it/s] 38%|███▊      | 188/500 [00:11<00:18, 16.54it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.54it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.56it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.64it/s] 39%|███▉      | 196/500 [00:11<00:18, 16.58it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.56it/s] 40%|████      | 200/500 [00:12<00:18, 16.63it/s] 40%|████      | 202/500 [00:12<00:17, 16.64it/s] 41%|████      | 204/500 [00:12<00:17, 16.54it/s] 41%|████      | 206/500 [00:12<00:19, 14.99it/s] 42%|████▏     | 208/500 [00:12<00:19, 15.34it/s] 42%|████▏     | 210/500 [00:12<00:18, 15.70it/s] 42%|████▏     | 212/500 [00:12<00:18, 15.97it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.18it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.18it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.31it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.25it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.26it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.37it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.51it/s] 46%|████▌     | 228/500 [00:13<00:16, 16.56it/s] 46%|████▌     | 230/500 [00:13<00:16, 16.65it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.62it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.48it/s] 47%|████▋     | 236/500 [00:14<00:15, 16.54it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.44it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.38it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.42it/s] 49%|████▉     | 244/500 [00:14<00:15, 16.36it/s] 49%|████▉     | 246/500 [00:14<00:15, 16.28it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.43it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.55it/s] 50%|█████     | 252/500 [00:15<00:14, 16.64it/s] 51%|█████     | 254/500 [00:15<00:14, 16.69it/s] 51%|█████     | 256/500 [00:15<00:14, 16.70it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.61it/s] 52%|█████▏    | 260/500 [00:15<00:14, 16.64it/s] 52%|█████▏    | 262/500 [00:15<00:14, 16.48it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.42it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.47it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.57it/s] 54%|█████▍    | 270/500 [00:16<00:13, 16.64it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.58it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.55it/s] 55%|█████▌    | 276/500 [00:16<00:13, 16.62it/s] 56%|█████▌    | 278/500 [00:16<00:13, 16.64it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.64it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.50it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.40it/s] 57%|█████▋    | 286/500 [00:17<00:12, 16.52it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.58it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.63it/s] 58%|█████▊    | 292/500 [00:17<00:12, 16.67it/s] 59%|█████▉    | 294/500 [00:17<00:12, 16.70it/s] 59%|█████▉    | 296/500 [00:17<00:12, 16.63it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.52it/s] 60%|██████    | 300/500 [00:18<00:12, 16.60it/s] 60%|██████    | 302/500 [00:18<00:11, 16.60it/s] 61%|██████    | 304/500 [00:18<00:11, 16.53it/s] 61%|██████    | 306/500 [00:18<00:11, 16.49it/s] 62%|██████▏   | 308/500 [00:18<00:11, 16.61it/s] 62%|██████▏   | 310/500 [00:18<00:11, 16.68it/s] 62%|██████▏   | 312/500 [00:18<00:11, 16.74it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.69it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.70it/s] 64%|██████▎   | 318/500 [00:19<00:10, 16.72it/s] 64%|██████▍   | 320/500 [00:19<00:10, 16.70it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.73it/s] 65%|██████▍   | 324/500 [00:19<00:10, 16.64it/s] 65%|██████▌   | 326/500 [00:19<00:10, 16.66it/s] 66%|██████▌   | 328/500 [00:19<00:10, 16.67it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.53it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.36it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.34it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.10it/s] 68%|██████▊   | 338/500 [00:20<00:10, 15.95it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.10it/s] 68%|██████▊   | 342/500 [00:20<00:09, 16.27it/s] 69%|██████▉   | 344/500 [00:20<00:09, 16.40it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.47it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.55it/s] 70%|███████   | 350/500 [00:21<00:09, 16.50it/s] 70%|███████   | 352/500 [00:21<00:09, 16.37it/s] 71%|███████   | 354/500 [00:21<00:08, 16.48it/s] 71%|███████   | 356/500 [00:21<00:08, 16.53it/s] 72%|███████▏  | 358/500 [00:21<00:08, 16.39it/s] 72%|███████▏  | 360/500 [00:21<00:08, 16.22it/s] 72%|███████▏  | 362/500 [00:21<00:08, 16.38it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.53it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.59it/s] 74%|███████▎  | 368/500 [00:22<00:07, 16.62it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.59it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.46it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:22<00:07, 16.48it/s] 75%|███████▌  | 376/500 [00:22<00:07, 16.27it/s] 76%|███████▌  | 378/500 [00:22<00:08, 15.23it/s] 76%|███████▌  | 380/500 [00:23<00:08, 14.46it/s] 76%|███████▋  | 382/500 [00:23<00:07, 15.02it/s] 77%|███████▋  | 384/500 [00:23<00:07, 15.45it/s] 77%|███████▋  | 386/500 [00:23<00:07, 15.84it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.10it/s] 78%|███████▊  | 390/500 [00:23<00:06, 16.29it/s] 78%|███████▊  | 392/500 [00:23<00:06, 16.42it/s] 79%|███████▉  | 394/500 [00:23<00:06, 16.48it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.47it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.57it/s] 80%|████████  | 400/500 [00:24<00:06, 16.56it/s] 80%|████████  | 402/500 [00:24<00:05, 16.47it/s] 81%|████████  | 404/500 [00:24<00:05, 16.51it/s] 81%|████████  | 406/500 [00:24<00:05, 16.55it/s] 82%|████████▏ | 408/500 [00:24<00:05, 16.49it/s] 82%|████████▏ | 410/500 [00:24<00:05, 16.25it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.29it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.41it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.51it/s] 84%|████████▎ | 418/500 [00:25<00:04, 16.52it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.45it/s] 84%|████████▍ | 422/500 [00:25<00:04, 16.42it/s] 85%|████████▍ | 424/500 [00:25<00:04, 16.43it/s] 85%|████████▌ | 426/500 [00:25<00:04, 16.45it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.49it/s] 86%|████████▌ | 430/500 [00:26<00:04, 15.98it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.19it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.33it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.44it/s] 88%|████████▊ | 438/500 [00:26<00:03, 16.45it/s] 88%|████████▊ | 440/500 [00:26<00:03, 16.44it/s] 88%|████████▊ | 442/500 [00:26<00:03, 16.44it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.31it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.36it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.44it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.52it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.57it/s] 91%|█████████ | 454/500 [00:27<00:02, 16.43it/s] 91%|█████████ | 456/500 [00:27<00:02, 16.52it/s] 92%|█████████▏| 458/500 [00:27<00:02, 16.55it/s] 92%|█████████▏| 460/500 [00:27<00:02, 16.59it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.38it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.35it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.43it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.52it/s] 94%|█████████▍| 470/500 [00:28<00:01, 16.49it/s] 94%|█████████▍| 472/500 [00:28<00:01, 16.45it/s] 95%|█████████▍| 474/500 [00:28<00:01, 16.39it/s] 95%|█████████▌| 476/500 [00:28<00:01, 16.49it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.54it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.54it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.53it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.49it/s] 97%|█████████▋| 486/500 [00:29<00:00, 16.50it/s] 98%|█████████▊| 488/500 [00:29<00:00, 16.33it/s] 98%|█████████▊| 490/500 [00:29<00:00, 16.27it/s] 98%|█████████▊| 492/500 [00:29<00:00, 14.76it/s] 99%|█████████▉| 494/500 [00:30<00:00, 13.85it/s] 99%|█████████▉| 496/500 [00:30<00:00, 14.44it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 15.09it/s]100%|██████████| 500/500 [00:30<00:00, 15.42it/s]100%|██████████| 500/500 [00:30<00:00, 16.38it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  19
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:22,  6.18s/it]  1%|          | 3/500 [00:06<13:43,  1.66s/it]  1%|          | 5/500 [00:06<06:54,  1.19it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:47,  2.92it/s]  2%|▏         | 11/500 [00:12<10:44,  1.32s/it]  3%|▎         | 13/500 [00:13<07:18,  1.11it/s]  3%|▎         | 15/500 [00:13<05:06,  1.58it/s]  3%|▎         | 17/500 [00:13<03:38,  2.21it/s]  4%|▍         | 19/500 [00:13<02:40,  3.00it/s]  4%|▍         | 21/500 [00:19<09:35,  1.20s/it]  5%|▍         | 23/500 [00:19<06:48,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.63it/s]  5%|▌         | 27/500 [00:20<03:32,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.01it/s]  6%|▌         | 31/500 [00:26<09:09,  1.17s/it]  7%|▋         | 33/500 [00:26<06:32,  1.19it/s]  7%|▋         | 35/500 [00:26<04:42,  1.65it/s]  7%|▋         | 37/500 [00:26<03:25,  2.25it/s]  8%|▊         | 39/500 [00:27<02:32,  3.03it/s]  8%|▊         | 41/500 [00:33<08:53,  1.16s/it]  9%|▊         | 43/500 [00:33<06:21,  1.20it/s]  9%|▉         | 45/500 [00:33<04:34,  1.66it/s]  9%|▉         | 47/500 [00:33<03:20,  2.26it/s] 10%|▉         | 49/500 [00:33<02:28,  3.03it/s] 10%|█         | 51/500 [00:40<08:47,  1.17s/it] 11%|█         | 53/500 [00:40<06:16,  1.19it/s] 11%|█         | 55/500 [00:40<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.24it/s] 12%|█▏        | 59/500 [00:40<02:26,  3.02it/s] 12%|█▏        | 61/500 [00:47<08:41,  1.19s/it] 13%|█▎        | 63/500 [00:47<06:13,  1.17it/s] 13%|█▎        | 65/500 [00:47<04:28,  1.62it/s] 13%|█▎        | 67/500 [00:47<03:15,  2.21it/s] 14%|█▍        | 69/500 [00:47<02:24,  2.98it/s] 14%|█▍        | 71/500 [00:53<08:26,  1.18s/it]Epoch:  1  	Training Loss: 0.03725326061248779
Test Loss:  46.50048065185547
Valid Loss:  46.73155975341797
Epoch:  2  	Training Loss: 45.36187744140625
Test Loss:  779.0593872070312
Valid Loss:  780.5133056640625
Epoch:  3  	Training Loss: 780.6145629882812
Test Loss:  0.8626068234443665
Valid Loss:  0.8516082763671875
Epoch:  4  	Training Loss: 0.9286607503890991
Test Loss:  0.7627530097961426
Valid Loss:  0.7523224353790283
Epoch:  5  	Training Loss: 0.8243474960327148
Test Loss:  0.6744017004966736
Valid Loss:  0.6645107269287109
Epoch:  6  	Training Loss: 0.7318516969680786
Test Loss:  0.5962545871734619
Valid Loss:  0.5868761539459229
Epoch:  7  	Training Loss: 0.6498521566390991
Test Loss:  0.5271563529968262
Valid Loss:  0.5182638168334961
Epoch:  8  	Training Loss: 0.577171802520752
Test Loss:  0.46607887744903564
Valid Loss:  0.4576466679573059
Epoch:  9  	Training Loss: 0.5127630233764648
Test Loss:  0.41210800409317017
Valid Loss:  0.40411219000816345
Epoch:  10  	Training Loss: 0.4556935727596283
Test Loss:  0.36443185806274414
Valid Loss:  0.3568490147590637
Epoch:  11  	Training Loss: 0.4051346778869629
Test Loss:  0.32232925295829773
Valid Loss:  0.31513726711273193
Epoch:  12  	Training Loss: 0.3603496253490448
Test Loss:  0.2847059369087219
Valid Loss:  0.2778875231742859
Epoch:  13  	Training Loss: 0.3202018141746521
Test Loss:  0.2516058087348938
Valid Loss:  0.24513974785804749
Epoch:  14  	Training Loss: 0.2847572863101959
Test Loss:  0.22248508036136627
Valid Loss:  0.21635130047798157
Epoch:  15  	Training Loss: 0.25345852971076965
Test Loss:  0.19686558842658997
Valid Loss:  0.19104492664337158
Epoch:  16  	Training Loss: 0.2258148491382599
Test Loss:  0.17432740330696106
Valid Loss:  0.16880196332931519
Epoch:  17  	Training Loss: 0.20139476656913757
Test Loss:  0.15450090169906616
Valid Loss:  0.1492534577846527
Epoch:  18  	Training Loss: 0.17981800436973572
Test Loss:  0.1370604932308197
Valid Loss:  0.13207507133483887
Epoch:  19  	Training Loss: 0.16074936091899872
Test Loss:  0.12172020226716995
Valid Loss:  0.11698156595230103
Epoch:  20  	Training Loss: 0.143893763422966
Test Loss:  0.10822810232639313
Valid Loss:  0.1037219911813736
Epoch:  21  	Training Loss: 0.12899120151996613
Test Loss:  0.09636256098747253
Valid Loss:  0.0920754075050354
Epoch:  22  	Training Loss: 0.11581233888864517
Test Loss:  0.08590538799762726
Valid Loss:  0.08182482421398163
Epoch:  23  	Training Loss: 0.10412932932376862
Test Loss:  0.0767136961221695
Valid Loss:  0.07282768189907074
Epoch:  24  	Training Loss: 0.09379590302705765
Test Loss:  0.06863529235124588
Valid Loss:  0.06493246555328369
Epoch:  25  	Training Loss: 0.0846538320183754
Test Loss:  0.061536092311143875
Valid Loss:  0.05800576135516167
Epoch:  26  	Training Loss: 0.07656343281269073
Test Loss:  0.05529806390404701
Valid Loss:  0.05193014815449715
Epoch:  27  	Training Loss: 0.06940160691738129
Test Loss:  0.04981725662946701
Valid Loss:  0.0466022714972496
Epoch:  28  	Training Loss: 0.06305962055921555
Test Loss:  0.04500238597393036
Valid Loss:  0.04193142056465149
Epoch:  29  	Training Loss: 0.05744176357984543
Test Loss:  0.04077284783124924
Valid Loss:  0.03783751279115677
Epoch:  30  	Training Loss: 0.05246340483427048
Test Loss:  0.037057794630527496
Valid Loss:  0.03425021842122078
Epoch:  31  	Training Loss: 0.0480499342083931
Test Loss:  0.03379492461681366
Valid Loss:  0.031107651069760323
Epoch:  32  	Training Loss: 0.044135548174381256
Test Loss:  0.030935214832425117
Valid Loss:  0.028361089527606964
Epoch:  33  	Training Loss: 0.040669165551662445
Test Loss:  0.028422584757208824
Valid Loss:  0.02595510147511959
Epoch:  34  	Training Loss: 0.03759028762578964
Test Loss:  0.026214974001049995
Valid Loss:  0.023847993463277817
Epoch:  35  	Training Loss: 0.034854091703891754
Test Loss:  0.02427530288696289
Valid Loss:  0.022003065794706345
Epoch:  36  	Training Loss: 0.03242092579603195
Test Loss:  0.02257091924548149
Valid Loss:  0.020388003438711166
Epoch:  37  	Training Loss: 0.030255768448114395
Test Loss:  0.021073076874017715
Valid Loss:  0.018974414095282555
Epoch:  38  	Training Loss: 0.028327688574790955
Test Loss:  0.019756518304347992
Valid Loss:  0.017737310379743576
Epoch:  39  	Training Loss: 0.02660933881998062
Test Loss:  0.01859894022345543
Valid Loss:  0.01665470376610756
Epoch:  40  	Training Loss: 0.025076497346162796
Test Loss:  0.01758073829114437
Valid Loss:  0.015707246959209442
Epoch:  41  	Training Loss: 0.023707805201411247
Test Loss:  0.016684681177139282
Valid Loss:  0.01487797312438488
Epoch:  42  	Training Loss: 0.02248436212539673
Test Loss:  0.015895124524831772
Valid Loss:  0.014151505194604397
Epoch:  43  	Training Loss: 0.021388737484812737
Test Loss:  0.015199277549982071
Valid Loss:  0.013515246100723743
Epoch:  44  	Training Loss: 0.0204069335013628
Test Loss:  0.014585434459149837
Valid Loss:  0.012957731261849403
Epoch:  45  	Training Loss: 0.019525937736034393
Test Loss:  0.01404331624507904
Valid Loss:  0.01246882975101471
Epoch:  46  	Training Loss: 0.0187341570854187
Test Loss:  0.013563861139118671
Valid Loss:  0.01203970517963171
Epoch:  47  	Training Loss: 0.018021421507000923
Test Loss:  0.013139145448803902
Valid Loss:  0.01166258193552494
Epoch:  48  	Training Loss: 0.017378700897097588
Test Loss:  0.012762186117470264
Valid Loss:  0.01133066788315773
Epoch:  49  	Training Loss: 0.016797995194792747
Test Loss:  0.01242687739431858
Valid Loss:  0.011038004420697689
Epoch:  50  	Training Loss: 0.01627226546406746
Test Loss:  0.012127846479415894
Valid Loss:  0.010779364965856075
Epoch:  51  	Training Loss: 0.015795256942510605
Test Loss:  0.011860398575663567
Valid Loss:  0.010550186969339848
Epoch:  52  	Training Loss: 0.015361452475190163
Test Loss:  0.011620629578828812
Valid Loss:  0.01034664735198021
Epoch:  53  	Training Loss: 0.014966454356908798
Test Loss:  0.01140463538467884
Valid Loss:  0.010165031999349594
Epoch:  54  	Training Loss: 0.01460534892976284
Test Loss:  0.01120929978787899
Valid Loss:  0.010002313181757927
Epoch:  55  	Training Loss: 0.014274333603680134
Test Loss:  0.011031858623027802
Valid Loss:  0.009855860844254494
Epoch:  56  	Training Loss: 0.013970045372843742
Test Loss:  0.010869940742850304
Valid Loss:  0.00972337368875742
Epoch:  57  	Training Loss: 0.013689509592950344
Test Loss:  0.010721437633037567
Valid Loss:  0.009602869860827923
Epoch:  58  	Training Loss: 0.013430093415081501
Test Loss:  0.010584531351923943
Valid Loss:  0.009492587298154831
Epoch:  59  	Training Loss: 0.01318947970867157
Test Loss:  0.010457645170390606
Valid Loss:  0.00939104799181223
Epoch:  60  	Training Loss: 0.012965597212314606
Test Loss:  0.01033937931060791
Valid Loss:  0.009296935051679611
Epoch:  61  	Training Loss: 0.012756630778312683
Test Loss:  0.010228545404970646
Valid Loss:  0.009209120646119118
Epoch:  62  	Training Loss: 0.012560959905385971
Test Loss:  0.010124146938323975
Valid Loss:  0.009126689285039902
Epoch:  63  	Training Loss: 0.012377133592963219
Test Loss:  0.010025221854448318
Valid Loss:  0.009048746898770332
Epoch:  64  	Training Loss: 0.012203946709632874
Test Loss:  0.009931014850735664
Valid Loss:  0.008974572643637657
Epoch:  65  	Training Loss: 0.012040258385241032
Test Loss:  0.009840833023190498
Valid Loss:  0.008903546258807182
Epoch:  66  	Training Loss: 0.011885080486536026
Test Loss:  0.009754080325365067
Valid Loss:  0.008835121989250183
Epoch:  67  	Training Loss: 0.011737534776329994
Test Loss:  0.00967026874423027
Valid Loss:  0.008768860250711441
Epoch:  68  	Training Loss: 0.011596843600273132
Test Loss:  0.009588964283466339
Valid Loss:  0.008704361505806446
Epoch:  69  	Training Loss: 0.011462312191724777
Test Loss:  0.009509783238172531
Valid Loss:  0.008641312830150127
Epoch:  70  	Training Loss: 0.011333336122334003
Test Loss:  0.009432421997189522
Valid Loss:  0.008579432964324951
Epoch:  71  	Training Loss: 0.011209371499717236
Test Loss:  0.009356601163744926
Valid Loss:  0.00851848628371954
Epoch:  72  	Training Loss: 0.01108994334936142
Test Loss:  0.00928198080509901
Valid Loss:  0.008458145894110203
 15%|█▍        | 73/500 [00:54<06:02,  1.18it/s] 15%|█▌        | 75/500 [00:54<04:20,  1.63it/s] 15%|█▌        | 77/500 [00:54<03:09,  2.23it/s] 16%|█▌        | 79/500 [00:54<02:20,  2.99it/s] 16%|█▌        | 81/500 [01:00<08:09,  1.17s/it] 17%|█▋        | 83/500 [01:00<05:50,  1.19it/s] 17%|█▋        | 85/500 [01:00<04:12,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:03,  2.25it/s] 18%|█▊        | 89/500 [01:01<02:15,  3.03it/s] 18%|█▊        | 91/500 [01:07<07:56,  1.17s/it] 19%|█▊        | 93/500 [01:07<05:40,  1.20it/s] 19%|█▉        | 95/500 [01:07<04:05,  1.65it/s] 19%|█▉        | 97/500 [01:07<02:58,  2.26it/s] 20%|█▉        | 99/500 [01:07<02:12,  3.04it/s] 20%|██        | 101/500 [01:14<07:43,  1.16s/it] 21%|██        | 103/500 [01:14<05:30,  1.20it/s] 21%|██        | 105/500 [01:14<03:58,  1.66it/s] 21%|██▏       | 107/500 [01:14<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:14<02:12,  2.96it/s] 22%|██▏       | 111/500 [01:20<07:36,  1.17s/it] 23%|██▎       | 113/500 [01:21<05:26,  1.19it/s] 23%|██▎       | 115/500 [01:21<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:21<02:50,  2.24it/s] 24%|██▍       | 119/500 [01:21<02:06,  3.02it/s] 24%|██▍       | 121/500 [01:27<07:23,  1.17s/it] 25%|██▍       | 123/500 [01:27<05:17,  1.19it/s] 25%|██▌       | 125/500 [01:28<03:47,  1.65it/s] 25%|██▌       | 127/500 [01:28<02:46,  2.25it/s] 26%|██▌       | 129/500 [01:28<02:02,  3.02it/s] 26%|██▌       | 131/500 [01:34<07:13,  1.18s/it] 27%|██▋       | 133/500 [01:34<05:09,  1.18it/s] 27%|██▋       | 135/500 [01:34<03:42,  1.64it/s] 27%|██▋       | 137/500 [01:35<02:42,  2.24it/s] 28%|██▊       | 139/500 [01:35<01:59,  3.01it/s] 28%|██▊       | 141/500 [01:41<06:58,  1.17s/it]Epoch:  73  	Training Loss: 0.010974586009979248
Test Loss:  0.00920847337692976
Valid Loss:  0.008398391306400299
Epoch:  74  	Training Loss: 0.01086294837296009
Test Loss:  0.009135929867625237
Valid Loss:  0.008339086547493935
Epoch:  75  	Training Loss: 0.010754692368209362
Test Loss:  0.009064195677638054
Valid Loss:  0.008280133828520775
Epoch:  76  	Training Loss: 0.010649527423083782
Test Loss:  0.008993183262646198
Valid Loss:  0.008221440017223358
Epoch:  77  	Training Loss: 0.010547185316681862
Test Loss:  0.008922778069972992
Valid Loss:  0.008162938989698887
Epoch:  78  	Training Loss: 0.010447446256875992
Test Loss:  0.008852919563651085
Valid Loss:  0.008104574866592884
Epoch:  79  	Training Loss: 0.010350093245506287
Test Loss:  0.00878352951258421
Valid Loss:  0.008046315982937813
Epoch:  80  	Training Loss: 0.010254945605993271
Test Loss:  0.00871456228196621
Valid Loss:  0.00798812322318554
Epoch:  81  	Training Loss: 0.01016184315085411
Test Loss:  0.008645989000797272
Valid Loss:  0.007929990068078041
Epoch:  82  	Training Loss: 0.010070638731122017
Test Loss:  0.008577892556786537
Valid Loss:  0.007872035726904869
Epoch:  83  	Training Loss: 0.009981220588088036
Test Loss:  0.008510126732289791
Valid Loss:  0.007814116775989532
Epoch:  84  	Training Loss: 0.009893475100398064
Test Loss:  0.008442680351436138
Valid Loss:  0.007756230421364307
Epoch:  85  	Training Loss: 0.00980728305876255
Test Loss:  0.008375540375709534
Valid Loss:  0.007698387373238802
Epoch:  86  	Training Loss: 0.009722558781504631
Test Loss:  0.00830870121717453
Valid Loss:  0.00764058530330658
Epoch:  87  	Training Loss: 0.00963921844959259
Test Loss:  0.008242158219218254
Valid Loss:  0.007582853548228741
Epoch:  88  	Training Loss: 0.009557186625897884
Test Loss:  0.008175907656550407
Valid Loss:  0.007525190711021423
Epoch:  89  	Training Loss: 0.009476394392549992
Test Loss:  0.008109970018267632
Valid Loss:  0.007467617280781269
Epoch:  90  	Training Loss: 0.009396785870194435
Test Loss:  0.008044322021305561
Valid Loss:  0.007410139311105013
Epoch:  91  	Training Loss: 0.009318307973444462
Test Loss:  0.007978986017405987
Valid Loss:  0.007352781482040882
Epoch:  92  	Training Loss: 0.009240906685590744
Test Loss:  0.007913809269666672
Valid Loss:  0.00729538407176733
Epoch:  93  	Training Loss: 0.009164515882730484
Test Loss:  0.007848970592021942
Valid Loss:  0.007238149642944336
Epoch:  94  	Training Loss: 0.009089123457670212
Test Loss:  0.007784459739923477
Valid Loss:  0.007181085646152496
Epoch:  95  	Training Loss: 0.009014679118990898
Test Loss:  0.007720311172306538
Valid Loss:  0.007124226540327072
Epoch:  96  	Training Loss: 0.00894116796553135
Test Loss:  0.007656512316316366
Valid Loss:  0.007067588157951832
Epoch:  97  	Training Loss: 0.008868549019098282
Test Loss:  0.007593089248985052
Valid Loss:  0.007011179346591234
Epoch:  98  	Training Loss: 0.008796798065304756
Test Loss:  0.007530049420893192
Valid Loss:  0.0069550201296806335
Epoch:  99  	Training Loss: 0.008725901134312153
Test Loss:  0.007467391900718212
Valid Loss:  0.006899126805365086
Epoch:  100  	Training Loss: 0.008655823767185211
Test Loss:  0.007405132986605167
Valid Loss:  0.006843505427241325
Epoch:  101  	Training Loss: 0.008586553856730461
Test Loss:  0.007343281991779804
Valid Loss:  0.006788183934986591
Epoch:  102  	Training Loss: 0.008518066257238388
Test Loss:  0.007281879894435406
Valid Loss:  0.006733214948326349
Epoch:  103  	Training Loss: 0.008450360968708992
Test Loss:  0.007220902480185032
Valid Loss:  0.006678554229438305
Epoch:  104  	Training Loss: 0.008383411914110184
Test Loss:  0.007160350680351257
Valid Loss:  0.006624232977628708
Epoch:  105  	Training Loss: 0.00831720232963562
Test Loss:  0.007100232876837254
Valid Loss:  0.0065702516585588455
Epoch:  106  	Training Loss: 0.00825170986354351
Test Loss:  0.007040552794933319
Valid Loss:  0.006516618654131889
Epoch:  107  	Training Loss: 0.00818693172186613
Test Loss:  0.006981321610510349
Valid Loss:  0.006463342811912298
Epoch:  108  	Training Loss: 0.008122854866087437
Test Loss:  0.006922543980181217
Valid Loss:  0.006410443224012852
Epoch:  109  	Training Loss: 0.008059458807110786
Test Loss:  0.006864218972623348
Valid Loss:  0.00635792501270771
Epoch:  110  	Training Loss: 0.007996741682291031
Test Loss:  0.006806373596191406
Valid Loss:  0.006305794231593609
Epoch:  111  	Training Loss: 0.0079346913844347
Test Loss:  0.00674898736178875
Valid Loss:  0.006254065316170454
Epoch:  112  	Training Loss: 0.007873296737670898
Test Loss:  0.006692366674542427
Valid Loss:  0.006203050259500742
Epoch:  113  	Training Loss: 0.00781265925616026
Test Loss:  0.006636202335357666
Valid Loss:  0.006152432411909103
Epoch:  114  	Training Loss: 0.007752665318548679
Test Loss:  0.006580508314073086
Valid Loss:  0.006102211773395538
Epoch:  115  	Training Loss: 0.007693301886320114
Test Loss:  0.006525284610688686
Valid Loss:  0.006052393466234207
Epoch:  116  	Training Loss: 0.007634554989635944
Test Loss:  0.006470532156527042
Valid Loss:  0.006002999842166901
Epoch:  117  	Training Loss: 0.007576426491141319
Test Loss:  0.006416255608201027
Valid Loss:  0.0059540062211453915
Epoch:  118  	Training Loss: 0.00751890055835247
Test Loss:  0.006362454034388065
Valid Loss:  0.005905430763959885
Epoch:  119  	Training Loss: 0.007461973000317812
Test Loss:  0.006309125572443008
Valid Loss:  0.005857277195900679
Epoch:  120  	Training Loss: 0.007405639626085758
Test Loss:  0.006256275810301304
Valid Loss:  0.005809551104903221
Epoch:  121  	Training Loss: 0.007349882274866104
Test Loss:  0.006203897297382355
Valid Loss:  0.005762244574725628
Epoch:  122  	Training Loss: 0.007294708862900734
Test Loss:  0.006151778157800436
Valid Loss:  0.005715127103030682
Epoch:  123  	Training Loss: 0.007239995989948511
Test Loss:  0.006100141908973455
Valid Loss:  0.005668452009558678
Epoch:  124  	Training Loss: 0.00718584842979908
Test Loss:  0.006048991344869137
Valid Loss:  0.00562220998108387
Epoch:  125  	Training Loss: 0.007132252678275108
Test Loss:  0.005998323671519756
Valid Loss:  0.0055764103308320045
Epoch:  126  	Training Loss: 0.007079208269715309
Test Loss:  0.005948142148554325
Valid Loss:  0.005531053990125656
Epoch:  127  	Training Loss: 0.007026706822216511
Test Loss:  0.005898443516343832
Valid Loss:  0.005486142355948687
Epoch:  128  	Training Loss: 0.0069747441448271275
Test Loss:  0.005849224515259266
Valid Loss:  0.005441661924123764
Epoch:  129  	Training Loss: 0.0069233113899827
Test Loss:  0.005800485145300627
Valid Loss:  0.005397625267505646
Epoch:  130  	Training Loss: 0.006872407626360655
Test Loss:  0.005752219818532467
Valid Loss:  0.0053540244698524475
Epoch:  131  	Training Loss: 0.00682202260941267
Test Loss:  0.005704433657228947
Valid Loss:  0.005310865584760904
Epoch:  132  	Training Loss: 0.006772153079509735
Test Loss:  0.005657181143760681
Valid Loss:  0.005268205888569355
Epoch:  133  	Training Loss: 0.006722833961248398
Test Loss:  0.005610400810837746
Valid Loss:  0.005225985310971737
Epoch:  134  	Training Loss: 0.006674014497548342
Test Loss:  0.0055640824139118195
Valid Loss:  0.005184188485145569
Epoch:  135  	Training Loss: 0.0066257016733288765
Test Loss:  0.00551823154091835
Valid Loss:  0.005142820067703724
Epoch:  136  	Training Loss: 0.0065778763964772224
Test Loss:  0.005472834222018719
Valid Loss:  0.005101882852613926
Epoch:  137  	Training Loss: 0.0065305400639772415
Test Loss:  0.005427896045148373
Valid Loss:  0.005061365198343992
Epoch:  138  	Training Loss: 0.006483685225248337
Test Loss:  0.005383411422371864
Valid Loss:  0.005021268967539072
Epoch:  139  	Training Loss: 0.006437309086322784
Test Loss:  0.005339383147656918
Valid Loss:  0.004981593228876591
Epoch:  140  	Training Loss: 0.006391408387571573
Test Loss:  0.005295803304761648
Valid Loss:  0.004942331928759813
Epoch:  141  	Training Loss: 0.006345971021801233
Test Loss:  0.0052526649087667465
Valid Loss:  0.0049034892581403255
Epoch:  142  	Training Loss: 0.006301001645624638
Test Loss:  0.005210124887526035
Valid Loss:  0.0048652347177267075
 29%|██▊       | 143/500 [01:41<05:00,  1.19it/s] 29%|██▉       | 145/500 [01:41<03:38,  1.62it/s] 29%|██▉       | 147/500 [01:41<02:41,  2.19it/s] 30%|██▉       | 149/500 [01:42<02:00,  2.92it/s] 30%|███       | 151/500 [01:48<06:49,  1.17s/it] 31%|███       | 153/500 [01:48<04:52,  1.19it/s] 31%|███       | 155/500 [01:48<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:48<02:33,  2.24it/s] 32%|███▏      | 159/500 [01:48<01:53,  3.00it/s] 32%|███▏      | 161/500 [01:55<06:36,  1.17s/it] 33%|███▎      | 163/500 [01:55<04:43,  1.19it/s] 33%|███▎      | 165/500 [01:55<03:23,  1.64it/s] 33%|███▎      | 167/500 [01:55<02:28,  2.24it/s] 34%|███▍      | 169/500 [01:55<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:01<06:28,  1.18s/it] 35%|███▍      | 173/500 [02:02<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:02<03:18,  1.63it/s] 35%|███▌      | 177/500 [02:02<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:02<01:46,  3.00it/s] 36%|███▌      | 181/500 [02:08<06:17,  1.18s/it] 37%|███▋      | 183/500 [02:08<04:29,  1.17it/s] 37%|███▋      | 185/500 [02:09<03:13,  1.62it/s] 37%|███▋      | 187/500 [02:09<02:20,  2.22it/s] 38%|███▊      | 189/500 [02:09<01:44,  2.99it/s] 38%|███▊      | 191/500 [02:15<06:03,  1.18s/it] 39%|███▊      | 193/500 [02:15<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:15<03:06,  1.64it/s] 39%|███▉      | 197/500 [02:15<02:15,  2.24it/s] 40%|███▉      | 199/500 [02:16<01:40,  3.01it/s] 40%|████      | 201/500 [02:22<05:55,  1.19s/it] 41%|████      | 203/500 [02:22<04:12,  1.17it/s] 41%|████      | 205/500 [02:22<03:01,  1.62it/s] 41%|████▏     | 207/500 [02:22<02:12,  2.21it/s] 42%|████▏     | 209/500 [02:23<01:38,  2.96it/s] 42%|████▏     | 211/500 [02:29<05:44,  1.19s/it]Epoch:  143  	Training Loss: 0.006256550550460815
Test Loss:  0.005168022587895393
Valid Loss:  0.0048273769207298756
Epoch:  144  	Training Loss: 0.006212550215423107
Test Loss:  0.0051263486966490746
Valid Loss:  0.004789923317730427
Epoch:  145  	Training Loss: 0.006169004365801811
Test Loss:  0.005085106007754803
Valid Loss:  0.004752865992486477
Epoch:  146  	Training Loss: 0.006125898100435734
Test Loss:  0.005044274032115936
Valid Loss:  0.004716196097433567
Epoch:  147  	Training Loss: 0.006083233281970024
Test Loss:  0.005003865342587233
Valid Loss:  0.004679913632571697
Epoch:  148  	Training Loss: 0.006040999665856361
Test Loss:  0.004963872488588095
Valid Loss:  0.004644019529223442
Epoch:  149  	Training Loss: 0.0059992000460624695
Test Loss:  0.00492429081350565
Valid Loss:  0.004608515650033951
Epoch:  150  	Training Loss: 0.0059578255750238895
Test Loss:  0.004885124042630196
Valid Loss:  0.0045733884908258915
Epoch:  151  	Training Loss: 0.005916872527450323
Test Loss:  0.004846361931413412
Valid Loss:  0.004538639448583126
Epoch:  152  	Training Loss: 0.005876337178051472
Test Loss:  0.00480779679492116
Valid Loss:  0.004504050128161907
Epoch:  153  	Training Loss: 0.005836131516844034
Test Loss:  0.004769646562635899
Valid Loss:  0.004469851031899452
Epoch:  154  	Training Loss: 0.005796333774924278
Test Loss:  0.004731901455670595
Valid Loss:  0.004436027258634567
Epoch:  155  	Training Loss: 0.005756939761340618
Test Loss:  0.004694561939686537
Valid Loss:  0.0044025881215929985
Epoch:  156  	Training Loss: 0.005717951338738203
Test Loss:  0.004657618701457977
Valid Loss:  0.0043695177882909775
Epoch:  157  	Training Loss: 0.005679355934262276
Test Loss:  0.004621070344001055
Valid Loss:  0.004336819518357515
Epoch:  158  	Training Loss: 0.005641154479235411
Test Loss:  0.004584912210702896
Valid Loss:  0.0043044909834861755
Epoch:  159  	Training Loss: 0.005603343714028597
Test Loss:  0.004549138247966766
Valid Loss:  0.004272518679499626
Epoch:  160  	Training Loss: 0.0055659133940935135
Test Loss:  0.004513749852776527
Valid Loss:  0.00424091424793005
Epoch:  161  	Training Loss: 0.005528868641704321
Test Loss:  0.004478740971535444
Valid Loss:  0.004209664184600115
Epoch:  162  	Training Loss: 0.005492201074957848
Test Loss:  0.004444167949259281
Valid Loss:  0.004178834613412619
Epoch:  163  	Training Loss: 0.005455933045595884
Test Loss:  0.004409961402416229
Valid Loss:  0.004148351959884167
Epoch:  164  	Training Loss: 0.005420031026005745
Test Loss:  0.004376126453280449
Valid Loss:  0.004118213430047035
Epoch:  165  	Training Loss: 0.005384494084864855
Test Loss:  0.00434265099465847
Valid Loss:  0.0040884120389819145
Epoch:  166  	Training Loss: 0.005349320825189352
Test Loss:  0.0043095373548567295
Valid Loss:  0.004058951046317816
Epoch:  167  	Training Loss: 0.005314505659043789
Test Loss:  0.0042767697013914585
Valid Loss:  0.004029819276183844
Epoch:  168  	Training Loss: 0.005280044861137867
Test Loss:  0.004244361538439989
Valid Loss:  0.004001016728579998
Epoch:  169  	Training Loss: 0.005245933309197426
Test Loss:  0.004212298430502415
Valid Loss:  0.00397254154086113
Epoch:  170  	Training Loss: 0.005212170071899891
Test Loss:  0.00418057618662715
Valid Loss:  0.003944389522075653
Epoch:  171  	Training Loss: 0.0051787495613098145
Test Loss:  0.004149197600781918
Valid Loss:  0.003916552290320396
Epoch:  172  	Training Loss: 0.005145667120814323
Test Loss:  0.00411808118224144
Valid Loss:  0.0038889585994184017
Epoch:  173  	Training Loss: 0.005112889222800732
Test Loss:  0.0040873074904084206
Valid Loss:  0.003861682489514351
Epoch:  174  	Training Loss: 0.0050804466009140015
Test Loss:  0.0040568700060248375
Valid Loss:  0.00383472116664052
Epoch:  175  	Training Loss: 0.005048335064202547
Test Loss:  0.004026761278510094
Valid Loss:  0.00380807276815176
Epoch:  176  	Training Loss: 0.005016549490392208
Test Loss:  0.003996983636170626
Valid Loss:  0.003781729843467474
Epoch:  177  	Training Loss: 0.00498508894816041
Test Loss:  0.0039675235748291016
Valid Loss:  0.0037556884344667196
Epoch:  178  	Training Loss: 0.004953945055603981
Test Loss:  0.003938385285437107
Valid Loss:  0.0037299497053027153
Epoch:  179  	Training Loss: 0.004923120141029358
Test Loss:  0.0039095631800591946
Valid Loss:  0.00370451039634645
Epoch:  180  	Training Loss: 0.00489260908216238
Test Loss:  0.003881057957187295
Valid Loss:  0.0036793644540011883
Epoch:  181  	Training Loss: 0.004862408619374037
Test Loss:  0.003852865658700466
Valid Loss:  0.0036545121110975742
Epoch:  182  	Training Loss: 0.004832519218325615
Test Loss:  0.0038249248173087835
Valid Loss:  0.0036298902705311775
Epoch:  183  	Training Loss: 0.004802905023097992
Test Loss:  0.0037972957361489534
Valid Loss:  0.0036055585369467735
Epoch:  184  	Training Loss: 0.004773593507707119
Test Loss:  0.0037699684035032988
Valid Loss:  0.003581511788070202
Epoch:  185  	Training Loss: 0.004744581412523985
Test Loss:  0.0037429400254040956
Valid Loss:  0.003557748394086957
Epoch:  186  	Training Loss: 0.0047158654779195786
Test Loss:  0.0037162071093916893
Valid Loss:  0.0035342625342309475
Epoch:  187  	Training Loss: 0.0046874405816197395
Test Loss:  0.003689768724143505
Valid Loss:  0.0035110502503812313
Epoch:  188  	Training Loss: 0.004659304395318031
Test Loss:  0.0036636244039982557
Valid Loss:  0.003488109214231372
Epoch:  189  	Training Loss: 0.0046314578503370285
Test Loss:  0.003637762274593115
Valid Loss:  0.003465439425781369
Epoch:  190  	Training Loss: 0.004603893030434847
Test Loss:  0.00361218792386353
Valid Loss:  0.003443035064265132
Epoch:  191  	Training Loss: 0.004576610401272774
Test Loss:  0.0035868906415998936
Valid Loss:  0.0034208912402391434
Epoch:  192  	Training Loss: 0.004549603909254074
Test Loss:  0.003561893245205283
Valid Loss:  0.0033990347292274237
Epoch:  193  	Training Loss: 0.004522884264588356
Test Loss:  0.0035371696576476097
Valid Loss:  0.003377427812665701
Epoch:  194  	Training Loss: 0.004496434703469276
Test Loss:  0.003512715455144644
Valid Loss:  0.0033560823649168015
Epoch:  195  	Training Loss: 0.004470255691558123
Test Loss:  0.003488535527139902
Valid Loss:  0.003334989072754979
Epoch:  196  	Training Loss: 0.004444344434887171
Test Loss:  0.00346461683511734
Valid Loss:  0.0033141374588012695
Epoch:  197  	Training Loss: 0.004418699070811272
Test Loss:  0.003440961241722107
Valid Loss:  0.003293530084192753
Epoch:  198  	Training Loss: 0.004393311683088541
Test Loss:  0.0034175640903413296
Valid Loss:  0.0032731681130826473
Epoch:  199  	Training Loss: 0.004368182271718979
Test Loss:  0.0033944256138056517
Valid Loss:  0.0032530436292290688
Epoch:  200  	Training Loss: 0.004343310371041298
Test Loss:  0.0033715353347361088
Valid Loss:  0.0032331598922610283
Epoch:  201  	Training Loss: 0.004318689927458763
Test Loss:  0.00334890466183424
Valid Loss:  0.0032135038636624813
Epoch:  202  	Training Loss: 0.004294321406632662
Test Loss:  0.0033265165984630585
Valid Loss:  0.0031940864864736795
Epoch:  203  	Training Loss: 0.004270198289304972
Test Loss:  0.0033043785952031612
Valid Loss:  0.00317489355802536
Epoch:  204  	Training Loss: 0.004246321506798267
Test Loss:  0.0032824822701513767
Valid Loss:  0.003155933227390051
Epoch:  205  	Training Loss: 0.004222685005515814
Test Loss:  0.0032608257606625557
Valid Loss:  0.003137189894914627
Epoch:  206  	Training Loss: 0.004199291579425335
Test Loss:  0.003239409066736698
Valid Loss:  0.0031186705455183983
Epoch:  207  	Training Loss: 0.004176136571913958
Test Loss:  0.0032182277645915747
Valid Loss:  0.003100376110523939
Epoch:  208  	Training Loss: 0.004153216257691383
Test Loss:  0.0031972788274288177
Valid Loss:  0.0030822947155684233
Epoch:  209  	Training Loss: 0.004130530171096325
Test Loss:  0.00317656178958714
Valid Loss:  0.0030644258949905634
Epoch:  210  	Training Loss: 0.0041080741211771965
Test Loss:  0.0031560719944536686
Valid Loss:  0.0030467717442661524
Epoch:  211  	Training Loss: 0.004085845313966274
Test Loss:  0.0031358066480606794
Valid Loss:  0.0030293245799839497
Epoch:  212  	Training Loss: 0.004063844680786133
Test Loss:   43%|████▎     | 213/500 [02:29<04:05,  1.17it/s] 43%|████▎     | 215/500 [02:29<02:56,  1.61it/s] 43%|████▎     | 217/500 [02:29<02:08,  2.20it/s] 44%|████▍     | 219/500 [02:29<01:34,  2.97it/s] 44%|████▍     | 221/500 [02:36<05:27,  1.17s/it] 45%|████▍     | 223/500 [02:36<03:53,  1.19it/s] 45%|████▌     | 225/500 [02:36<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:36<02:01,  2.24it/s] 46%|████▌     | 229/500 [02:36<01:29,  3.02it/s] 46%|████▌     | 231/500 [02:43<05:19,  1.19s/it] 47%|████▋     | 233/500 [02:43<03:47,  1.17it/s] 47%|████▋     | 235/500 [02:43<02:43,  1.62it/s] 47%|████▋     | 237/500 [02:43<01:59,  2.21it/s] 48%|████▊     | 239/500 [02:43<01:28,  2.96it/s] 48%|████▊     | 241/500 [02:49<05:06,  1.18s/it] 49%|████▊     | 243/500 [02:50<03:38,  1.18it/s] 49%|████▉     | 245/500 [02:50<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:50<01:54,  2.22it/s] 50%|████▉     | 249/500 [02:50<01:24,  2.99it/s] 50%|█████     | 251/500 [02:56<04:58,  1.20s/it] 51%|█████     | 253/500 [02:57<03:32,  1.16it/s] 51%|█████     | 255/500 [02:57<02:32,  1.61it/s] 51%|█████▏    | 257/500 [02:57<01:50,  2.20it/s] 52%|█████▏    | 259/500 [02:57<01:21,  2.96it/s] 52%|█████▏    | 261/500 [03:03<04:40,  1.17s/it] 53%|█████▎    | 263/500 [03:03<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:04<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:04<01:44,  2.24it/s] 54%|█████▍    | 269/500 [03:04<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:10<04:32,  1.19s/it] 55%|█████▍    | 273/500 [03:10<03:14,  1.17it/s] 55%|█████▌    | 275/500 [03:10<02:19,  1.62it/s] 55%|█████▌    | 277/500 [03:11<01:40,  2.21it/s] 56%|█████▌    | 279/500 [03:11<01:14,  2.97it/s]0.003115816740319133
Valid Loss:  0.0030121407471597195
Epoch:  213  	Training Loss: 0.004042091779410839
Test Loss:  0.0030960484873503447
Valid Loss:  0.002995163667947054
Epoch:  214  	Training Loss: 0.004020564258098602
Test Loss:  0.003076495137065649
Valid Loss:  0.0029783830977976322
Epoch:  215  	Training Loss: 0.003999254200607538
Test Loss:  0.0030571583192795515
Valid Loss:  0.002961802762001753
Epoch:  216  	Training Loss: 0.0039781611412763596
Test Loss:  0.003038031281903386
Valid Loss:  0.0029454207979142666
Epoch:  217  	Training Loss: 0.003957281354814768
Test Loss:  0.0030191149562597275
Valid Loss:  0.0029292311519384384
Epoch:  218  	Training Loss: 0.003936614375561476
Test Loss:  0.003000411670655012
Valid Loss:  0.0029132352210581303
Epoch:  219  	Training Loss: 0.003916159272193909
Test Loss:  0.002981907920911908
Valid Loss:  0.0028974278829991817
Epoch:  220  	Training Loss: 0.0038959120865911245
Test Loss:  0.00296361418440938
Valid Loss:  0.0028818161226809025
Epoch:  221  	Training Loss: 0.0038758711889386177
Test Loss:  0.002945518586784601
Valid Loss:  0.002866381546482444
Epoch:  222  	Training Loss: 0.0038560337852686644
Test Loss:  0.002927579917013645
Valid Loss:  0.0028510906267911196
Epoch:  223  	Training Loss: 0.0038363803178071976
Test Loss:  0.002909841015934944
Valid Loss:  0.0028359820134937763
Epoch:  224  	Training Loss: 0.003816926386207342
Test Loss:  0.002892301417887211
Valid Loss:  0.002821059897542
Epoch:  225  	Training Loss: 0.003797671990469098
Test Loss:  0.002874957863241434
Valid Loss:  0.0028063145000487566
Epoch:  226  	Training Loss: 0.0037786124739795923
Test Loss:  0.0028578066267073154
Valid Loss:  0.002791751641780138
Epoch:  227  	Training Loss: 0.003759747836738825
Test Loss:  0.0028408472426235676
Valid Loss:  0.002777365269139409
Epoch:  228  	Training Loss: 0.003741075750440359
Test Loss:  0.002824079245328903
Valid Loss:  0.002763153286650777
Epoch:  229  	Training Loss: 0.003722590859979391
Test Loss:  0.002807494020089507
Valid Loss:  0.0027491110377013683
Epoch:  230  	Training Loss: 0.0037042954936623573
Test Loss:  0.0027910915669053793
Valid Loss:  0.0027352399192750454
Epoch:  231  	Training Loss: 0.00368618406355381
Test Loss:  0.0027748816646635532
Valid Loss:  0.002721545286476612
Epoch:  232  	Training Loss: 0.0036682600621134043
Test Loss:  0.002758949063718319
Valid Loss:  0.0027081232983618975
Epoch:  233  	Training Loss: 0.003650571685284376
Test Loss:  0.0027431955095380545
Valid Loss:  0.0026948642916977406
Epoch:  234  	Training Loss: 0.003633064217865467
Test Loss:  0.002727618208155036
Valid Loss:  0.0026817675679922104
Epoch:  235  	Training Loss: 0.003615736961364746
Test Loss:  0.002712205983698368
Valid Loss:  0.0026688184589147568
Epoch:  236  	Training Loss: 0.003598584095016122
Test Loss:  0.0026969665195792913
Valid Loss:  0.002656029537320137
Epoch:  237  	Training Loss: 0.003581605153158307
Test Loss:  0.0026818932965397835
Valid Loss:  0.002643392886966467
Epoch:  238  	Training Loss: 0.003564799204468727
Test Loss:  0.002666986547410488
Valid Loss:  0.002630908042192459
Epoch:  239  	Training Loss: 0.003548162756487727
Test Loss:  0.002652243245393038
Valid Loss:  0.0026185777969658375
Epoch:  240  	Training Loss: 0.0035316962748765945
Test Loss:  0.0026376619935035706
Valid Loss:  0.0026063891127705574
Epoch:  241  	Training Loss: 0.0035153967328369617
Test Loss:  0.0026232474483549595
Valid Loss:  0.002594352001324296
Epoch:  242  	Training Loss: 0.0034992636647075415
Test Loss:  0.0026088478043675423
Valid Loss:  0.0025823176838457584
Epoch:  243  	Training Loss: 0.0034832186065614223
Test Loss:  0.0025946227833628654
Valid Loss:  0.0025704321451485157
Epoch:  244  	Training Loss: 0.0034673367626965046
Test Loss:  0.0025805504992604256
Valid Loss:  0.002558699809014797
Epoch:  245  	Training Loss: 0.003451617667451501
Test Loss:  0.002566646784543991
Valid Loss:  0.0025471183471381664
Epoch:  246  	Training Loss: 0.0034360585268586874
Test Loss:  0.0025528990663588047
Valid Loss:  0.002535679843276739
Epoch:  247  	Training Loss: 0.0034206572454422712
Test Loss:  0.0025393087416887283
Valid Loss:  0.0025243882555514574
Epoch:  248  	Training Loss: 0.0034054145216941833
Test Loss:  0.002525873016566038
Valid Loss:  0.0025132386945188046
Epoch:  249  	Training Loss: 0.003390326863154769
Test Loss:  0.0025125902611762285
Valid Loss:  0.0025022311601787806
Epoch:  250  	Training Loss: 0.003375391708686948
Test Loss:  0.002499462105333805
Valid Loss:  0.0024913595989346504
Epoch:  251  	Training Loss: 0.0033606095239520073
Test Loss:  0.0024864831939339638
Valid Loss:  0.002480632159858942
Epoch:  252  	Training Loss: 0.003345977747812867
Test Loss:  0.002473680768162012
Valid Loss:  0.0024700709618628025
Epoch:  253  	Training Loss: 0.0033315112814307213
Test Loss:  0.0024610268883407116
Valid Loss:  0.00245964084751904
Epoch:  254  	Training Loss: 0.0033171912655234337
Test Loss:  0.0024485131725668907
Valid Loss:  0.002449344377964735
Epoch:  255  	Training Loss: 0.0033030170015990734
Test Loss:  0.0024361403193324804
Valid Loss:  0.0024391752667725086
Epoch:  256  	Training Loss: 0.0032889863941818476
Test Loss:  0.0024239090271294117
Valid Loss:  0.002429137472063303
Epoch:  257  	Training Loss: 0.003275099443271756
Test Loss:  0.0024118185974657536
Valid Loss:  0.002419223077595234
Epoch:  258  	Training Loss: 0.00326135428622365
Test Loss:  0.0023998678661882877
Valid Loss:  0.002409439068287611
Epoch:  259  	Training Loss: 0.0032477492932230234
Test Loss:  0.002388045657426119
Valid Loss:  0.0023997763637453318
Epoch:  260  	Training Loss: 0.0032342805061489344
Test Loss:  0.0023763608187437057
Valid Loss:  0.0023902340326458216
Epoch:  261  	Training Loss: 0.003220950486138463
Test Loss:  0.0023648091591894627
Valid Loss:  0.002380816265940666
Epoch:  262  	Training Loss: 0.0032077557407319546
Test Loss:  0.0023533832281827927
Valid Loss:  0.0023715069983154535
Epoch:  263  	Training Loss: 0.0031946953386068344
Test Loss:  0.0023420851211994886
Valid Loss:  0.002362313214689493
Epoch:  264  	Training Loss: 0.003181769046932459
Test Loss:  0.002330914605408907
Valid Loss:  0.0023532393388450146
Epoch:  265  	Training Loss: 0.003168974071741104
Test Loss:  0.0023198742419481277
Valid Loss:  0.0023442828096449375
Epoch:  266  	Training Loss: 0.0031563087832182646
Test Loss:  0.0023089556489139795
Valid Loss:  0.002335437573492527
Epoch:  267  	Training Loss: 0.003143772017210722
Test Loss:  0.002298167906701565
Valid Loss:  0.002326708287000656
Epoch:  268  	Training Loss: 0.0031313663348555565
Test Loss:  0.0022874989081174135
Valid Loss:  0.0023180919233709574
Epoch:  269  	Training Loss: 0.0031190821900963783
Test Loss:  0.0022769554052501917
Valid Loss:  0.002309586852788925
Epoch:  270  	Training Loss: 0.0031069249380379915
Test Loss:  0.002266530878841877
Valid Loss:  0.0023011905141174793
Epoch:  271  	Training Loss: 0.0030948915518820286
Test Loss:  0.002256224863231182
Valid Loss:  0.0022929038386791945
Epoch:  272  	Training Loss: 0.003082980401813984
Test Loss:  0.0022460485342890024
Valid Loss:  0.002284737303853035
Epoch:  273  	Training Loss: 0.003071190556511283
Test Loss:  0.0022359886206686497
Valid Loss:  0.0022766715846955776
Epoch:  274  	Training Loss: 0.003059523180127144
Test Loss:  0.0022260439582169056
Valid Loss:  0.002268712967634201
Epoch:  275  	Training Loss: 0.0030479738488793373
Test Loss:  0.0022162143141031265
Valid Loss:  0.0022608586587011814
Epoch:  276  	Training Loss: 0.0030365425627678633
Test Loss:  0.0022064978256821632
Valid Loss:  0.0022531081922352314
Epoch:  277  	Training Loss: 0.0030252267606556416
Test Loss:  0.0021968914661556482
Valid Loss:  0.0022454513236880302
Epoch:  278  	Training Loss: 0.003014028538018465
Test Loss:  0.0021873924415558577
Valid Loss:  0.0022378978319466114
Epoch:  279  	Training Loss: 0.0030029418412595987
Test Loss:  0.0021780082024633884
Valid Loss:  0.002230443060398102
Epoch:  280  	Training Loss: 0.0029919701628386974
Test Loss:  0.0021687280386686325
Valid Loss:  0.0022230856120586395
Epoch:  281  	Training Loss: 0.002981108147650957
Test Loss:   56%|█████▌    | 281/500 [03:17<04:18,  1.18s/it] 57%|█████▋    | 283/500 [03:17<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:17<02:11,  1.63it/s] 57%|█████▋    | 287/500 [03:17<01:35,  2.23it/s] 58%|█████▊    | 289/500 [03:18<01:10,  3.00it/s] 58%|█████▊    | 291/500 [03:24<04:05,  1.17s/it] 59%|█████▊    | 293/500 [03:24<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:24<02:05,  1.64it/s] 59%|█████▉    | 297/500 [03:24<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:24<01:06,  3.02it/s] 60%|██████    | 301/500 [03:31<03:53,  1.18s/it] 61%|██████    | 303/500 [03:31<02:46,  1.18it/s] 61%|██████    | 305/500 [03:31<01:59,  1.64it/s] 61%|██████▏   | 307/500 [03:31<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:31<01:03,  2.99it/s] 62%|██████▏   | 311/500 [03:37<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:38<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:38<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:38<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:38<01:00,  3.01it/s] 64%|██████▍   | 321/500 [03:44<03:29,  1.17s/it] 65%|██████▍   | 323/500 [03:44<02:29,  1.19it/s] 65%|██████▌   | 325/500 [03:45<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:45<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:45<00:57,  3.00it/s] 66%|██████▌   | 331/500 [03:51<03:18,  1.17s/it] 67%|██████▋   | 333/500 [03:51<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:51<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:51<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:52<00:53,  3.02it/s] 68%|██████▊   | 341/500 [03:58<03:07,  1.18s/it] 69%|██████▊   | 343/500 [03:58<02:13,  1.18it/s] 69%|██████▉   | 345/500 [03:58<01:35,  1.63it/s] 69%|██████▉   | 347/500 [03:58<01:08,  2.23it/s] 70%|██████▉   | 349/500 [03:58<00:50,  2.99it/s]0.0021595563739538193
Valid Loss:  0.002215822460129857
Epoch:  282  	Training Loss: 0.0029703581240028143
Test Loss:  0.0021505593322217464
Valid Loss:  0.0022087283432483673
Epoch:  283  	Training Loss: 0.002959760371595621
Test Loss:  0.00214166147634387
Valid Loss:  0.0022017238661646843
Epoch:  284  	Training Loss: 0.0029492699541151524
Test Loss:  0.0021328662987798452
Valid Loss:  0.002194807631894946
Epoch:  285  	Training Loss: 0.0029388880357146263
Test Loss:  0.002124170307070017
Valid Loss:  0.002187982900068164
Epoch:  286  	Training Loss: 0.0029286127537488937
Test Loss:  0.0021155732683837414
Valid Loss:  0.0021812436170876026
Epoch:  287  	Training Loss: 0.002918439218774438
Test Loss:  0.0021070768125355244
Valid Loss:  0.002174592111259699
Epoch:  288  	Training Loss: 0.0029083716217428446
Test Loss:  0.0020986744202673435
Valid Loss:  0.00216803140938282
Epoch:  289  	Training Loss: 0.0028984076343476772
Test Loss:  0.002090367255732417
Valid Loss:  0.0021615547593683004
Epoch:  290  	Training Loss: 0.0028885421343147755
Test Loss:  0.0020821611396968365
Valid Loss:  0.002155158668756485
Epoch:  291  	Training Loss: 0.0028787790797650814
Test Loss:  0.0020740414038300514
Valid Loss:  0.002148845698684454
Epoch:  292  	Training Loss: 0.002869116608053446
Test Loss:  0.0020659961737692356
Valid Loss:  0.0021425988525152206
Epoch:  293  	Training Loss: 0.0028595321346074343
Test Loss:  0.002058043610304594
Valid Loss:  0.0021364311687648296
Epoch:  294  	Training Loss: 0.0028500501066446304
Test Loss:  0.0020501832477748394
Valid Loss:  0.00213034451007843
Epoch:  295  	Training Loss: 0.002840663306415081
Test Loss:  0.002042412990704179
Valid Loss:  0.0021243400406092405
Epoch:  296  	Training Loss: 0.0028313705697655678
Test Loss:  0.002034731674939394
Valid Loss:  0.002118415432050824
Epoch:  297  	Training Loss: 0.0028221728280186653
Test Loss:  0.002027143258601427
Valid Loss:  0.0021125739440321922
Epoch:  298  	Training Loss: 0.0028130714781582355
Test Loss:  0.0020196386612951756
Valid Loss:  0.002106808125972748
Epoch:  299  	Training Loss: 0.0028040602337569
Test Loss:  0.002012224867939949
Valid Loss:  0.0021011182107031345
Epoch:  300  	Training Loss: 0.0027951407246291637
Test Loss:  0.0020048923324793577
Valid Loss:  0.002095504431053996
Epoch:  301  	Training Loss: 0.002786311786621809
Test Loss:  0.0019976533949375153
Valid Loss:  0.002089971676468849
Epoch:  302  	Training Loss: 0.0027775727212429047
Test Loss:  0.0019904847722500563
Valid Loss:  0.0020845048129558563
Epoch:  303  	Training Loss: 0.0027689184062182903
Test Loss:  0.001983404392376542
Valid Loss:  0.0020791145507246256
Epoch:  304  	Training Loss: 0.002760352334007621
Test Loss:  0.0019764024764299393
Valid Loss:  0.002073790179565549
Epoch:  305  	Training Loss: 0.0027518742717802525
Test Loss:  0.0019694846123456955
Valid Loss:  0.002068544505164027
Epoch:  306  	Training Loss: 0.002743480261415243
Test Loss:  0.0019626489374786615
Valid Loss:  0.0020633696112781763
Epoch:  307  	Training Loss: 0.002735174261033535
Test Loss:  0.0019558933563530445
Valid Loss:  0.0020582634024322033
Epoch:  308  	Training Loss: 0.002726950217038393
Test Loss:  0.001949213445186615
Valid Loss:  0.0020532305352389812
Epoch:  309  	Training Loss: 0.002718809526413679
Test Loss:  0.001942615257576108
Valid Loss:  0.0020482647232711315
Epoch:  310  	Training Loss: 0.00271075451746583
Test Loss:  0.0019360922742635012
Valid Loss:  0.002043372020125389
Epoch:  311  	Training Loss: 0.00270277913659811
Test Loss:  0.001929647522047162
Valid Loss:  0.0020385426469147205
Epoch:  312  	Training Loss: 0.0026948852464556694
Test Loss:  0.001923288800753653
Valid Loss:  0.0020337929017841816
Epoch:  313  	Training Loss: 0.0026870795991271734
Test Loss:  0.0019170099403709173
Valid Loss:  0.0020291106775403023
Epoch:  314  	Training Loss: 0.002679354976862669
Test Loss:  0.001910798018798232
Valid Loss:  0.0020244955085217953
Epoch:  315  	Training Loss: 0.002671708818525076
Test Loss:  0.0019046652596443892
Valid Loss:  0.002019939012825489
Epoch:  316  	Training Loss: 0.0026641390286386013
Test Loss:  0.001898603281006217
Valid Loss:  0.0020154514349997044
Epoch:  317  	Training Loss: 0.0026566467713564634
Test Loss:  0.0018926139455288649
Valid Loss:  0.002011026255786419
Epoch:  318  	Training Loss: 0.0026492325123399496
Test Loss:  0.0018866920145228505
Valid Loss:  0.0020066597498953342
Epoch:  319  	Training Loss: 0.002641889965161681
Test Loss:  0.0018808410968631506
Valid Loss:  0.0020023598335683346
Epoch:  320  	Training Loss: 0.002634625881910324
Test Loss:  0.001875060610473156
Valid Loss:  0.0019981174264103174
Epoch:  321  	Training Loss: 0.0026274346746504307
Test Loss:  0.001869349041953683
Valid Loss:  0.001993936952203512
Epoch:  322  	Training Loss: 0.0026203151792287827
Test Loss:  0.0018637157045304775
Valid Loss:  0.001989827724173665
Epoch:  323  	Training Loss: 0.002613276708871126
Test Loss:  0.001858153031207621
Valid Loss:  0.0019857785664498806
Epoch:  324  	Training Loss: 0.0026063094846904278
Test Loss:  0.001852653338573873
Valid Loss:  0.001981785986572504
Epoch:  325  	Training Loss: 0.002599412575364113
Test Loss:  0.0018472180236130953
Valid Loss:  0.001977851614356041
Epoch:  326  	Training Loss: 0.002592585515230894
Test Loss:  0.0018418508116155863
Valid Loss:  0.0019739714916795492
Epoch:  327  	Training Loss: 0.002585829235613346
Test Loss:  0.0018365434370934963
Valid Loss:  0.0019701472483575344
Epoch:  328  	Training Loss: 0.0025791400112211704
Test Loss:  0.001831302884966135
Valid Loss:  0.001966380048543215
Epoch:  329  	Training Loss: 0.002572520636022091
Test Loss:  0.0018261238001286983
Valid Loss:  0.0019626670982688665
Epoch:  330  	Training Loss: 0.0025659678503870964
Test Loss:  0.0018210073467344046
Valid Loss:  0.0019590058363974094
Epoch:  331  	Training Loss: 0.0025594825856387615
Test Loss:  0.00181595201138407
Valid Loss:  0.001955397892743349
Epoch:  332  	Training Loss: 0.002553062280640006
Test Loss:  0.0018109194934368134
Valid Loss:  0.0019518081098794937
Epoch:  333  	Training Loss: 0.0025466831866651773
Test Loss:  0.0018059499561786652
Valid Loss:  0.0019482721108943224
Epoch:  334  	Training Loss: 0.00254037044942379
Test Loss:  0.0018010413041338325
Valid Loss:  0.0019447884988039732
Epoch:  335  	Training Loss: 0.002534120809286833
Test Loss:  0.0017961915582418442
Valid Loss:  0.0019413568079471588
Epoch:  336  	Training Loss: 0.0025279358960688114
Test Loss:  0.0017913999035954475
Valid Loss:  0.00193797517567873
Epoch:  337  	Training Loss: 0.0025218110531568527
Test Loss:  0.0017866689013317227
Valid Loss:  0.0019346477929502726
Epoch:  338  	Training Loss: 0.0025157532654702663
Test Loss:  0.0017819968052208424
Valid Loss:  0.0019313717493787408
Epoch:  339  	Training Loss: 0.0025097536854445934
Test Loss:  0.0017773794243112206
Valid Loss:  0.0019281423883512616
Epoch:  340  	Training Loss: 0.0025038167368620634
Test Loss:  0.0017728200182318687
Valid Loss:  0.0019249639008194208
Epoch:  341  	Training Loss: 0.002497939858585596
Test Loss:  0.0017683173064142466
Valid Loss:  0.0019218336092308164
Epoch:  342  	Training Loss: 0.0024921242147684097
Test Loss:  0.0017638804856687784
Valid Loss:  0.0019187616417184472
Epoch:  343  	Training Loss: 0.0024863756261765957
Test Loss:  0.0017594974488019943
Valid Loss:  0.0019157393835484982
Epoch:  344  	Training Loss: 0.002480684779584408
Test Loss:  0.001755166333168745
Valid Loss:  0.0019127624109387398
Epoch:  345  	Training Loss: 0.0024750540032982826
Test Loss:  0.0017508896999061108
Valid Loss:  0.001909830840304494
Epoch:  346  	Training Loss: 0.0024694777093827724
Test Loss:  0.0017466674325987697
Valid Loss:  0.0019069459522143006
Epoch:  347  	Training Loss: 0.0024639589246362448
Test Loss:  0.0017424935940653086
Valid Loss:  0.0019041013438254595
Epoch:  348  	Training Loss: 0.0024584962520748377
Test Loss:  0.0017383737722411752
Valid Loss:  0.001901302020996809
Epoch:  349  	Training Loss: 0.0024530901573598385
Test Loss:  0.001734300865791738
Valid Loss:  0.0018985493807122111
Epoch:  350  	Training Loss: 0.002447736682370305
Test Loss:  70%|███████   | 351/500 [04:05<02:53,  1.17s/it] 71%|███████   | 353/500 [04:05<02:03,  1.19it/s] 71%|███████   | 355/500 [04:05<01:27,  1.65it/s] 71%|███████▏  | 357/500 [04:05<01:03,  2.26it/s] 72%|███████▏  | 359/500 [04:05<00:46,  3.04it/s] 72%|███████▏  | 361/500 [04:11<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:12<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:12<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:12<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:12<00:43,  3.00it/s] 74%|███████▍  | 371/500 [04:18<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:19<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:19<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:19<00:55,  2.20it/s] 76%|███████▌  | 379/500 [04:19<00:40,  2.95it/s] 76%|███████▌  | 381/500 [04:25<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:25<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:25<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:26<00:50,  2.24it/s] 78%|███████▊  | 389/500 [04:26<00:36,  3.01it/s] 78%|███████▊  | 391/500 [04:32<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:32<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:32<01:03,  1.64it/s] 79%|███████▉  | 397/500 [04:32<00:46,  2.24it/s] 80%|███████▉  | 399/500 [04:33<00:33,  3.00it/s] 80%|████████  | 401/500 [04:39<01:56,  1.18s/it] 81%|████████  | 403/500 [04:39<01:21,  1.18it/s] 81%|████████  | 405/500 [04:39<00:58,  1.64it/s] 81%|████████▏ | 407/500 [04:39<00:41,  2.24it/s] 82%|████████▏ | 409/500 [04:39<00:30,  3.01it/s] 82%|████████▏ | 411/500 [04:46<01:45,  1.18s/it] 83%|████████▎ | 413/500 [04:46<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:46<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:46<00:37,  2.23it/s] 0.0017302795313298702
Valid Loss:  0.0018958351574838161
Epoch:  351  	Training Loss: 0.0024424390867352486
Test Loss:  0.0017263083718717098
Valid Loss:  0.00189316482283175
Epoch:  352  	Training Loss: 0.0024371943436563015
Test Loss:  0.0017224197508767247
Valid Loss:  0.0018905737670138478
Epoch:  353  	Training Loss: 0.002432024572044611
Test Loss:  0.0017185795586556196
Valid Loss:  0.0018880153074860573
Epoch:  354  	Training Loss: 0.00242690765298903
Test Loss:  0.0017147809267044067
Valid Loss:  0.0018855055095627904
Epoch:  355  	Training Loss: 0.0024218400940299034
Test Loss:  0.0017110307235270739
Valid Loss:  0.0018830273766070604
Epoch:  356  	Training Loss: 0.0024168258532881737
Test Loss:  0.0017073266208171844
Valid Loss:  0.0018805889412760735
Epoch:  357  	Training Loss: 0.0024118623696267605
Test Loss:  0.0017036658246070147
Valid Loss:  0.0018781897379085422
Epoch:  358  	Training Loss: 0.0024069477804005146
Test Loss:  0.001700049382634461
Valid Loss:  0.0018758269725367427
Epoch:  359  	Training Loss: 0.002402083482593298
Test Loss:  0.0016964785754680634
Valid Loss:  0.0018734992481768131
Epoch:  360  	Training Loss: 0.0023972673807293177
Test Loss:  0.0016929515404626727
Valid Loss:  0.0018712127348408103
Epoch:  361  	Training Loss: 0.0023925008717924356
Test Loss:  0.0016894640866667032
Valid Loss:  0.00186895951628685
Epoch:  362  	Training Loss: 0.0023877834901213646
Test Loss:  0.0016860072501003742
Valid Loss:  0.0018667279509827495
Epoch:  363  	Training Loss: 0.002383109414950013
Test Loss:  0.001682597678154707
Valid Loss:  0.0018645350355654955
Epoch:  364  	Training Loss: 0.002378478180617094
Test Loss:  0.0016792266396805644
Valid Loss:  0.0018623764626681805
Epoch:  365  	Training Loss: 0.0023738951422274113
Test Loss:  0.0016758986748754978
Valid Loss:  0.0018602537456899881
Epoch:  366  	Training Loss: 0.002369359601289034
Test Loss:  0.0016726122703403234
Valid Loss:  0.0018581649055704474
Epoch:  367  	Training Loss: 0.0023648701608181
Test Loss:  0.0016693695215508342
Valid Loss:  0.0018561118049547076
Epoch:  368  	Training Loss: 0.0023604254238307476
Test Loss:  0.0016661651898175478
Valid Loss:  0.001854092814028263
Epoch:  369  	Training Loss: 0.0023560267873108387
Test Loss:  0.0016629998572170734
Valid Loss:  0.001852107816375792
Epoch:  370  	Training Loss: 0.002351672388613224
Test Loss:  0.0016598762013018131
Valid Loss:  0.0018501592567190528
Epoch:  371  	Training Loss: 0.0023473636247217655
Test Loss:  0.0016567911952733994
Valid Loss:  0.0018482403829693794
Epoch:  372  	Training Loss: 0.0023430949077010155
Test Loss:  0.0016537151532247663
Valid Loss:  0.0018463239539414644
Epoch:  373  	Training Loss: 0.002338852733373642
Test Loss:  0.0016506833489984274
Valid Loss:  0.001844445476308465
Epoch:  374  	Training Loss: 0.002334653865545988
Test Loss:  0.0016476870514452457
Valid Loss:  0.0018425995949655771
Epoch:  375  	Training Loss: 0.0023304959759116173
Test Loss:  0.0016447328962385654
Valid Loss:  0.0018407856114208698
Epoch:  376  	Training Loss: 0.0023263818584382534
Test Loss:  0.0016418141312897205
Valid Loss:  0.0018390030600130558
Epoch:  377  	Training Loss: 0.0023223089519888163
Test Loss:  0.0016389330849051476
Valid Loss:  0.0018372557824477553
Epoch:  378  	Training Loss: 0.0023182767909020185
Test Loss:  0.0016360925510525703
Valid Loss:  0.0018355390056967735
Epoch:  379  	Training Loss: 0.002314288169145584
Test Loss:  0.0016332853119820356
Valid Loss:  0.001833850983530283
Epoch:  380  	Training Loss: 0.0023103368002921343
Test Loss:  0.0016305169556289911
Valid Loss:  0.0018321978859603405
Epoch:  381  	Training Loss: 0.002306427573785186
Test Loss:  0.0016277865506708622
Valid Loss:  0.001830573775805533
Epoch:  382  	Training Loss: 0.0023025579284876585
Test Loss:  0.0016250812914222479
Valid Loss:  0.001828972715884447
Epoch:  383  	Training Loss: 0.0022987225092947483
Test Loss:  0.0016224111896008253
Valid Loss:  0.0018273992463946342
Epoch:  384  	Training Loss: 0.0022949252743273973
Test Loss:  0.0016197753138840199
Valid Loss:  0.001825856976211071
Epoch:  385  	Training Loss: 0.002291166689246893
Test Loss:  0.00161717738956213
Valid Loss:  0.0018243410158902407
Epoch:  386  	Training Loss: 0.002287447452545166
Test Loss:  0.0016146136913448572
Valid Loss:  0.0018228561384603381
Epoch:  387  	Training Loss: 0.0022837664000689983
Test Loss:  0.0016120816580951214
Valid Loss:  0.0018214036244899035
Epoch:  388  	Training Loss: 0.0022801205050200224
Test Loss:  0.0016095838509500027
Valid Loss:  0.0018199739279225469
Epoch:  389  	Training Loss: 0.0022765123285353184
Test Loss:  0.0016071174759417772
Valid Loss:  0.0018185710068792105
Epoch:  390  	Training Loss: 0.0022729411721229553
Test Loss:  0.0016046847449615598
Valid Loss:  0.0018171966075897217
Epoch:  391  	Training Loss: 0.002269407268613577
Test Loss:  0.0016022840281948447
Valid Loss:  0.0018158475868403912
Epoch:  392  	Training Loss: 0.002265907358378172
Test Loss:  0.0015999269671738148
Valid Loss:  0.001814540708437562
Epoch:  393  	Training Loss: 0.002262452617287636
Test Loss:  0.0015975991263985634
Valid Loss:  0.0018132508266717196
Epoch:  394  	Training Loss: 0.0022590328007936478
Test Loss:  0.0015953057445585728
Valid Loss:  0.0018119888845831156
Epoch:  395  	Training Loss: 0.0022556474432349205
Test Loss:  0.0015930365771055222
Valid Loss:  0.0018107554642483592
Epoch:  396  	Training Loss: 0.002252297243103385
Test Loss:  0.001590799423865974
Valid Loss:  0.0018095425330102444
Epoch:  397  	Training Loss: 0.0022489805705845356
Test Loss:  0.0015885932371020317
Valid Loss:  0.0018083571922034025
Epoch:  398  	Training Loss: 0.0022456992883235216
Test Loss:  0.0015864151064306498
Valid Loss:  0.0018071915255859494
Epoch:  399  	Training Loss: 0.0022424478083848953
Test Loss:  0.0015842663124203682
Valid Loss:  0.001806055661290884
Epoch:  400  	Training Loss: 0.0022392328828573227
Test Loss:  0.0015821458073332906
Valid Loss:  0.001804938307031989
Epoch:  401  	Training Loss: 0.0022360472939908504
Test Loss:  0.001580054173246026
Valid Loss:  0.0018038444686681032
Epoch:  402  	Training Loss: 0.0022328984923660755
Test Loss:  0.0015779954846948385
Valid Loss:  0.0018027771729975939
Epoch:  403  	Training Loss: 0.002229781821370125
Test Loss:  0.0015759647358208895
Valid Loss:  0.0018017326947301626
Epoch:  404  	Training Loss: 0.002226699609309435
Test Loss:  0.0015739597147330642
Valid Loss:  0.001800709287635982
Epoch:  405  	Training Loss: 0.0022236471995711327
Test Loss:  0.001571984263136983
Valid Loss:  0.001799713121727109
Epoch:  406  	Training Loss: 0.0022206257563084364
Test Loss:  0.0015700319781899452
Valid Loss:  0.0017987326718866825
Epoch:  407  	Training Loss: 0.0022176350466907024
Test Loss:  0.0015681080985814333
Valid Loss:  0.0017977732932195067
Epoch:  408  	Training Loss: 0.0022146757692098618
Test Loss:  0.001566207269206643
Valid Loss:  0.0017968356842175126
Epoch:  409  	Training Loss: 0.0022117451298981905
Test Loss:  0.0015643329825252295
Valid Loss:  0.0017959179822355509
Epoch:  410  	Training Loss: 0.0022088438272476196
Test Loss:  0.0015624850057065487
Valid Loss:  0.0017950200708582997
Epoch:  411  	Training Loss: 0.002205971162766218
Test Loss:  0.0015606610104441643
Valid Loss:  0.0017941456753760576
Epoch:  412  	Training Loss: 0.0022031301632523537
Test Loss:  0.0015588459791615605
Valid Loss:  0.0017932720948010683
Epoch:  413  	Training Loss: 0.002200308023020625
Test Loss:  0.0015570602845400572
Valid Loss:  0.0017924208659678698
Epoch:  414  	Training Loss: 0.002197511959820986
Test Loss:  0.0015552975237369537
Valid Loss:  0.0017915877979248762
Epoch:  415  	Training Loss: 0.0021947468630969524
Test Loss:  0.0015535596758127213
Valid Loss:  0.0017907784786075354
Epoch:  416  	Training Loss: 0.002192009473219514
Test Loss:  0.0015518437139689922
Valid Loss:  0.0017899865051731467
Epoch:  417  	Training Loss: 0.0021892976947128773
Test Loss:  0.001550155458971858
Valid Loss:  0.0017892119940370321
Epoch:  418  	Training Loss: 0.00218661455437541
Test Loss:  0.0015484873438253999
Valid Loss:  0.0017884589033201337
 84%|████████▍ | 419/500 [04:46<00:27,  2.98it/s] 84%|████████▍ | 421/500 [04:52<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:53<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:53<00:45,  1.65it/s] 85%|████████▌ | 427/500 [04:53<00:32,  2.24it/s] 86%|████████▌ | 429/500 [04:53<00:23,  3.01it/s] 86%|████████▌ | 431/500 [04:59<01:20,  1.16s/it] 87%|████████▋ | 433/500 [04:59<00:56,  1.20it/s] 87%|████████▋ | 435/500 [04:59<00:39,  1.65it/s] 87%|████████▋ | 437/500 [05:00<00:27,  2.26it/s] 88%|████████▊ | 439/500 [05:00<00:20,  3.01it/s] 88%|████████▊ | 441/500 [05:06<01:08,  1.17s/it] 89%|████████▊ | 443/500 [05:06<00:47,  1.20it/s] 89%|████████▉ | 445/500 [05:06<00:33,  1.65it/s] 89%|████████▉ | 447/500 [05:06<00:23,  2.24it/s] 90%|████████▉ | 449/500 [05:07<00:16,  3.02it/s] 90%|█████████ | 451/500 [05:13<00:56,  1.16s/it] 91%|█████████ | 453/500 [05:13<00:39,  1.20it/s] 91%|█████████ | 455/500 [05:13<00:27,  1.66it/s] 91%|█████████▏| 457/500 [05:13<00:19,  2.25it/s] 92%|█████████▏| 459/500 [05:13<00:13,  3.02it/s] 92%|█████████▏| 461/500 [05:19<00:45,  1.16s/it] 93%|█████████▎| 463/500 [05:20<00:30,  1.20it/s] 93%|█████████▎| 465/500 [05:20<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:20<00:14,  2.22it/s] 94%|█████████▍| 469/500 [05:20<00:10,  2.97it/s] 94%|█████████▍| 471/500 [05:26<00:33,  1.16s/it] 95%|█████████▍| 473/500 [05:26<00:22,  1.20it/s] 95%|█████████▌| 475/500 [05:27<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:27<00:10,  2.25it/s] 96%|█████████▌| 479/500 [05:27<00:06,  3.03it/s] 96%|█████████▌| 481/500 [05:33<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:33<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:33<00:09,  1.63it/s]Epoch:  419  	Training Loss: 0.0021839607506990433
Test Loss:  0.0015468441415578127
Valid Loss:  0.001787722110748291
Epoch:  420  	Training Loss: 0.002181332092732191
Test Loss:  0.0015452266670763493
Valid Loss:  0.0017870061565190554
Epoch:  421  	Training Loss: 0.0021787327714264393
Test Loss:  0.0015436281682923436
Valid Loss:  0.001786309527233243
Epoch:  422  	Training Loss: 0.00217615719884634
Test Loss:  0.001542065991088748
Valid Loss:  0.0017856393242254853
Epoch:  423  	Training Loss: 0.0021736184135079384
Test Loss:  0.0015405244193971157
Valid Loss:  0.0017849882133305073
Epoch:  424  	Training Loss: 0.0021711038425564766
Test Loss:  0.0015390027547255158
Valid Loss:  0.0017843530513346195
Epoch:  425  	Training Loss: 0.0021686148829758167
Test Loss:  0.0015375030925497413
Valid Loss:  0.0017837315099313855
Epoch:  426  	Training Loss: 0.002166152000427246
Test Loss:  0.0015360270626842976
Valid Loss:  0.0017831299919635057
Epoch:  427  	Training Loss: 0.0021637137979269028
Test Loss:  0.001534568378701806
Valid Loss:  0.0017825408140197396
Epoch:  428  	Training Loss: 0.0021612984128296375
Test Loss:  0.0015331314643844962
Valid Loss:  0.001781968749128282
Epoch:  429  	Training Loss: 0.00215891026891768
Test Loss:  0.0015317145735025406
Valid Loss:  0.0017814126331359148
Epoch:  430  	Training Loss: 0.002156546339392662
Test Loss:  0.0015303201507776976
Valid Loss:  0.0017808726988732815
Epoch:  431  	Training Loss: 0.0021542049944400787
Test Loss:  0.001528942259028554
Valid Loss:  0.0017803485970944166
Epoch:  432  	Training Loss: 0.00215188879519701
Test Loss:  0.0015275913756340742
Valid Loss:  0.0017798439366742969
Epoch:  433  	Training Loss: 0.002149601001292467
Test Loss:  0.0015262594679370522
Valid Loss:  0.0017793540610000491
Epoch:  434  	Training Loss: 0.0021473357919603586
Test Loss:  0.00152494793292135
Valid Loss:  0.0017788793193176389
Epoch:  435  	Training Loss: 0.002145093400031328
Test Loss:  0.0015236509498208761
Valid Loss:  0.0017784172669053078
Epoch:  436  	Training Loss: 0.002142874989658594
Test Loss:  0.0015223773662000895
Valid Loss:  0.0017779733752831817
Epoch:  437  	Training Loss: 0.0021406784653663635
Test Loss:  0.0015211203135550022
Valid Loss:  0.0017775369342416525
Epoch:  438  	Training Loss: 0.0021385028958320618
Test Loss:  0.0015198790933936834
Valid Loss:  0.0017771183047443628
Epoch:  439  	Training Loss: 0.0021363515406847
Test Loss:  0.0015186583623290062
Valid Loss:  0.001776710618287325
Epoch:  440  	Training Loss: 0.0021342223044484854
Test Loss:  0.0015174552099779248
Valid Loss:  0.0017763194628059864
Epoch:  441  	Training Loss: 0.0021321121603250504
Test Loss:  0.001516270451247692
Valid Loss:  0.0017759401816874743
Epoch:  442  	Training Loss: 0.002130026463419199
Test Loss:  0.0015150983817875385
Valid Loss:  0.0017755706794559956
Epoch:  443  	Training Loss: 0.0021279570646584034
Test Loss:  0.0015139428433030844
Valid Loss:  0.001775213168002665
Epoch:  444  	Training Loss: 0.0021259114146232605
Test Loss:  0.0015128054656088352
Valid Loss:  0.0017748742830008268
Epoch:  445  	Training Loss: 0.00212388439103961
Test Loss:  0.001511685666628182
Valid Loss:  0.0017745406366884708
Epoch:  446  	Training Loss: 0.0021218794863671064
Test Loss:  0.0015105822822079062
Valid Loss:  0.0017742239870131016
Epoch:  447  	Training Loss: 0.0021198957692831755
Test Loss:  0.0015094953123480082
Valid Loss:  0.0017739171162247658
Epoch:  448  	Training Loss: 0.0021179290488362312
Test Loss:  0.0015084219630807638
Valid Loss:  0.0017736225854605436
Epoch:  449  	Training Loss: 0.002115984447300434
Test Loss:  0.001507366425357759
Valid Loss:  0.0017733373679220676
Epoch:  450  	Training Loss: 0.002114060102030635
Test Loss:  0.00150632718577981
Valid Loss:  0.0017730682156980038
Epoch:  451  	Training Loss: 0.0021121534518897533
Test Loss:  0.0015053043607622385
Valid Loss:  0.0017728100065141916
Epoch:  452  	Training Loss: 0.0021102656610310078
Test Loss:  0.001504292944446206
Valid Loss:  0.0017725606448948383
Epoch:  453  	Training Loss: 0.0021083978936076164
Test Loss:  0.0015032998053357005
Valid Loss:  0.0017723222263157368
Epoch:  454  	Training Loss: 0.0021065499167889357
Test Loss:  0.001502322033047676
Valid Loss:  0.0017720930045470595
Epoch:  455  	Training Loss: 0.00210472010076046
Test Loss:  0.0015013563679531217
Valid Loss:  0.0017718784511089325
Epoch:  456  	Training Loss: 0.002102910540997982
Test Loss:  0.0015004058368504047
Valid Loss:  0.0017716760048642755
Epoch:  457  	Training Loss: 0.0021011168137192726
Test Loss:  0.001499470672570169
Valid Loss:  0.0017714810092002153
Epoch:  458  	Training Loss: 0.00209934264421463
Test Loss:  0.0014985516900196671
Valid Loss:  0.0017712980043143034
Epoch:  459  	Training Loss: 0.0020975854713469744
Test Loss:  0.0014976469101384282
Valid Loss:  0.0017711251275613904
Epoch:  460  	Training Loss: 0.0020958473905920982
Test Loss:  0.0014967554016038775
Valid Loss:  0.0017709616804495454
Epoch:  461  	Training Loss: 0.00209412700496614
Test Loss:  0.001495877979323268
Valid Loss:  0.0017708069644868374
Epoch:  462  	Training Loss: 0.002092424314469099
Test Loss:  0.0014950153417885303
Valid Loss:  0.0017706695944070816
Epoch:  463  	Training Loss: 0.0020907383877784014
Test Loss:  0.0014941631816327572
Valid Loss:  0.0017705357167869806
Epoch:  464  	Training Loss: 0.002089068992063403
Test Loss:  0.0014933288330212235
Valid Loss:  0.001770412316545844
Epoch:  465  	Training Loss: 0.002087418455630541
Test Loss:  0.0014925047289580107
Valid Loss:  0.0017703005578368902
Epoch:  466  	Training Loss: 0.002085784450173378
Test Loss:  0.0014916937798261642
Valid Loss:  0.0017701978795230389
Epoch:  467  	Training Loss: 0.0020841644145548344
Test Loss:  0.0014908977318555117
Valid Loss:  0.0017701054457575083
Epoch:  468  	Training Loss: 0.002082563703879714
Test Loss:  0.0014901149552315474
Valid Loss:  0.0017700190655887127
Epoch:  469  	Training Loss: 0.002080977661535144
Test Loss:  0.001489344285801053
Valid Loss:  0.0017699424643069506
Epoch:  470  	Training Loss: 0.002079409547150135
Test Loss:  0.0014885851414874196
Valid Loss:  0.0017698772717267275
Epoch:  471  	Training Loss: 0.00207785633392632
Test Loss:  0.0014878383371978998
Valid Loss:  0.0017698202282190323
Epoch:  472  	Training Loss: 0.0020763184875249863
Test Loss:  0.001487101661041379
Valid Loss:  0.0017697681905701756
Epoch:  473  	Training Loss: 0.0020747953094542027
Test Loss:  0.001486379187554121
Valid Loss:  0.0017697252333164215
Epoch:  474  	Training Loss: 0.0020732874982059
Test Loss:  0.0014856685884296894
Valid Loss:  0.0017696907743811607
Epoch:  475  	Training Loss: 0.002071795053780079
Test Loss:  0.0014849640429019928
Valid Loss:  0.0017696651630103588
Epoch:  476  	Training Loss: 0.002070315647870302
Test Loss:  0.0014842778909951448
Valid Loss:  0.0017696460708975792
Epoch:  477  	Training Loss: 0.002068853937089443
Test Loss:  0.0014836021000519395
Valid Loss:  0.0017696375725790858
Epoch:  478  	Training Loss: 0.002067405730485916
Test Loss:  0.0014829389983788133
Valid Loss:  0.0017696380382403731
Epoch:  479  	Training Loss: 0.0020659747533500195
Test Loss:  0.001482284627854824
Valid Loss:  0.0017696451395750046
Epoch:  480  	Training Loss: 0.0020645561162382364
Test Loss:  0.001481642248108983
Valid Loss:  0.0017696587601676583
Epoch:  481  	Training Loss: 0.0020631528459489346
Test Loss:  0.0014810117427259684
Valid Loss:  0.001769679132848978
Epoch:  482  	Training Loss: 0.0020617626141756773
Test Loss:  0.001480394508689642
Valid Loss:  0.0017697124276310205
Epoch:  483  	Training Loss: 0.0020603931043297052
Test Loss:  0.0014797889161854982
Valid Loss:  0.0017697543371468782
Epoch:  484  	Training Loss: 0.0020590368658304214
Test Loss:  0.0014791935682296753
Valid Loss:  0.0017697997391223907
Epoch:  485  	Training Loss: 0.002057694597169757
Test Loss:  0.0014786097453907132
Valid Loss:  0.0017698544543236494
Epoch:  486  	Training Loss: 0.0020563649013638496
Test Loss:  0.0014780348865315318
Valid Loss:  0.0017699161544442177
Epoch:  487  	Training Loss: 0.002055048942565918
Test Loss:  0.001477470388635993
Valid Loss:   97%|█████████▋| 487/500 [05:34<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:34<00:03,  2.99it/s] 98%|█████████▊| 491/500 [05:40<00:10,  1.16s/it] 99%|█████████▊| 493/500 [05:40<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:40<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:40<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:40<00:00,  3.00it/s]100%|██████████| 500/500 [05:41<00:00,  1.47it/s]
0.001769982511177659
Epoch:  488  	Training Loss: 0.0020537476520985365
Test Loss:  0.0014769129920750856
Valid Loss:  0.001770055154338479
Epoch:  489  	Training Loss: 0.0020524587016552687
Test Loss:  0.001476369914598763
Valid Loss:  0.001770136645063758
Epoch:  490  	Training Loss: 0.002051182556897402
Test Loss:  0.0014758319593966007
Valid Loss:  0.0017702197656035423
Epoch:  491  	Training Loss: 0.0020499182865023613
Test Loss:  0.0014753055293112993
Valid Loss:  0.0017703159246593714
Epoch:  492  	Training Loss: 0.002048669382929802
Test Loss:  0.0014747916720807552
Valid Loss:  0.0017704174388200045
Epoch:  493  	Training Loss: 0.002047433750703931
Test Loss:  0.0014742875937372446
Valid Loss:  0.0017705251229926944
Epoch:  494  	Training Loss: 0.002046210691332817
Test Loss:  0.0014737923629581928
Valid Loss:  0.001770639792084694
Epoch:  495  	Training Loss: 0.0020449995063245296
Test Loss:  0.0014733036514371634
Valid Loss:  0.0017707555089145899
Epoch:  496  	Training Loss: 0.002043800661340356
Test Loss:  0.0014728243695572019
Valid Loss:  0.0017708775121718645
Epoch:  497  	Training Loss: 0.002042612060904503
Test Loss:  0.0014723559143021703
Valid Loss:  0.001771008362993598
Epoch:  498  	Training Loss: 0.0020414383616298437
Test Loss:  0.0014718933962285519
Valid Loss:  0.0017711466643959284
Epoch:  499  	Training Loss: 0.002040275139734149
Test Loss:  0.0014714443823322654
Valid Loss:  0.0017712842673063278
Epoch:  500  	Training Loss: 0.0020391230937093496
Test Loss:  0.0014709983952343464
Valid Loss:  0.0017714288551360369
seed is  19
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:08,  6.15s/it]  1%|          | 3/500 [00:06<13:37,  1.64s/it]  1%|          | 5/500 [00:06<06:52,  1.20it/s]  1%|▏         | 7/500 [00:06<04:09,  1.97it/s]  2%|▏         | 9/500 [00:06<02:47,  2.93it/s]  2%|▏         | 11/500 [00:12<10:45,  1.32s/it]  3%|▎         | 13/500 [00:13<07:19,  1.11it/s]  3%|▎         | 15/500 [00:13<05:06,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.21it/s]  4%|▍         | 19/500 [00:13<02:39,  3.01it/s]  4%|▍         | 21/500 [00:19<09:29,  1.19s/it]  5%|▍         | 23/500 [00:19<06:44,  1.18it/s]  5%|▌         | 25/500 [00:19<04:50,  1.64it/s]  5%|▌         | 27/500 [00:20<03:31,  2.24it/s]  6%|▌         | 29/500 [00:20<02:38,  2.97it/s]  6%|▌         | 31/500 [00:32<16:33,  2.12s/it]  7%|▋         | 33/500 [00:32<11:41,  1.50s/it]  7%|▋         | 35/500 [00:33<08:17,  1.07s/it]  7%|▋         | 37/500 [00:33<05:55,  1.30it/s]  8%|▊         | 39/500 [00:33<04:16,  1.80it/s]  8%|▊         | 41/500 [00:39<10:09,  1.33s/it]  9%|▊         | 43/500 [00:39<07:14,  1.05it/s]  9%|▉         | 45/500 [00:39<05:11,  1.46it/s]  9%|▉         | 47/500 [00:39<03:45,  2.00it/s] 10%|▉         | 49/500 [00:40<02:46,  2.70it/s] 10%|█         | 51/500 [00:46<08:57,  1.20s/it] 11%|█         | 53/500 [00:46<06:24,  1.16it/s] 11%|█         | 55/500 [00:46<04:36,  1.61it/s] 11%|█▏        | 57/500 [00:46<03:21,  2.20it/s] 12%|█▏        | 59/500 [00:46<02:29,  2.95it/s] 12%|█▏        | 61/500 [00:59<15:28,  2.11s/it] 13%|█▎        | 63/500 [00:59<10:56,  1.50s/it] 13%|█▎        | 65/500 [00:59<07:46,  1.07s/it] 13%|█▎        | 67/500 [00:59<05:33,  1.30it/s]Epoch:  1  	Training Loss: 0.03725326061248779
Test Loss:  1.917278528213501
Valid Loss:  1.9211543798446655
Epoch:  2  	Training Loss: 1.89799165725708
Test Loss:  97.48896026611328
Valid Loss:  97.87776184082031
Epoch:  3  	Training Loss: 96.23186492919922
Test Loss:  0.10468536615371704
Valid Loss:  0.10142053663730621
Epoch:  4  	Training Loss: 0.1199735477566719
Test Loss:  0.10468478500843048
Valid Loss:  0.10142000764608383
Epoch:  5  	Training Loss: 0.11997294425964355
Test Loss:  0.10468419641256332
Valid Loss:  0.10141947865486145
Epoch:  6  	Training Loss: 0.1199723482131958
Test Loss:  0.10468362271785736
Valid Loss:  0.10141894221305847
Epoch:  7  	Training Loss: 0.11997174471616745
Test Loss:  0.1046830490231514
Valid Loss:  0.10141842067241669
Epoch:  8  	Training Loss: 0.1199711486697197
Test Loss:  0.10468248277902603
Valid Loss:  0.1014179140329361
Epoch:  9  	Training Loss: 0.11997054517269135
Test Loss:  0.10468190908432007
Valid Loss:  0.10141739249229431
Epoch:  10  	Training Loss: 0.11996996402740479
Test Loss:  0.10468132793903351
Valid Loss:  0.10141687095165253
Epoch:  11  	Training Loss: 0.11996936798095703
Test Loss:  0.10468075424432755
Valid Loss:  0.10141634941101074
Epoch:  12  	Training Loss: 0.11996876448392868
Test Loss:  0.021463830024003983
Valid Loss:  0.021967370063066483
Epoch:  13  	Training Loss: 0.019434280693531036
Test Loss:  0.005346084479242563
Valid Loss:  0.004885182715952396
Epoch:  14  	Training Loss: 0.006731416564434767
Test Loss:  0.005480553954839706
Valid Loss:  0.005197911523282528
Epoch:  15  	Training Loss: 0.006237436551600695
Test Loss:  0.005192111246287823
Valid Loss:  0.004901298321783543
Epoch:  16  	Training Loss: 0.006035187281668186
Test Loss:  0.005018707364797592
Valid Loss:  0.0047475132159888744
Epoch:  17  	Training Loss: 0.005842799786478281
Test Loss:  0.0048349350690841675
Valid Loss:  0.004581079818308353
Epoch:  18  	Training Loss: 0.00565617810934782
Test Loss:  0.004659205675125122
Valid Loss:  0.004421659745275974
Epoch:  19  	Training Loss: 0.005471125245094299
Test Loss:  0.0044883135706186295
Valid Loss:  0.004265712108463049
Epoch:  20  	Training Loss: 0.005289985798299313
Test Loss:  0.004325338639318943
Valid Loss:  0.004117846488952637
Epoch:  21  	Training Loss: 0.0051161181181669235
Test Loss:  0.004164965357631445
Valid Loss:  0.003977854270488024
Epoch:  22  	Training Loss: 0.004949949681758881
Test Loss:  0.0026995264925062656
Valid Loss:  0.0026112254709005356
Epoch:  23  	Training Loss: 0.003662087954580784
Test Loss:  0.0024739052169024944
Valid Loss:  0.0025813730899244547
Epoch:  24  	Training Loss: 0.0030825233552604914
Test Loss:  0.006488506682217121
Valid Loss:  0.00627165287733078
Epoch:  25  	Training Loss: 0.008302925154566765
Test Loss:  0.1011933982372284
Valid Loss:  0.10280594229698181
Epoch:  26  	Training Loss: 0.1002957820892334
Test Loss:  0.6902415752410889
Valid Loss:  0.6828854084014893
Epoch:  27  	Training Loss: 0.7355340719223022
Test Loss:  0.46310481429100037
Valid Loss:  0.4661808907985687
Epoch:  28  	Training Loss: 0.4614190459251404
Test Loss:  0.20647749304771423
Valid Loss:  0.20900490880012512
Epoch:  29  	Training Loss: 0.19854304194450378
Test Loss:  0.14434754848480225
Valid Loss:  0.14649426937103271
Epoch:  30  	Training Loss: 0.1359454095363617
Test Loss:  0.14431682229042053
Valid Loss:  0.14646334946155548
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.13587510585784912
Test Loss:  0.013979228213429451
Valid Loss:  0.014230689965188503
Epoch:  32  	Training Loss: 0.012666653841733932
Test Loss:  0.011694952845573425
Valid Loss:  0.011924048885703087
Epoch:  33  	Training Loss: 0.010763287544250488
Test Loss:  0.010000329464673996
Valid Loss:  0.010213177651166916
Epoch:  34  	Training Loss: 0.009339665994048119
Test Loss:  0.008699541911482811
Valid Loss:  0.00890374556183815
Epoch:  35  	Training Loss: 0.008247869089245796
Test Loss:  0.0075879753567278385
Valid Loss:  0.007786889560520649
Epoch:  36  	Training Loss: 0.00730579998344183
Test Loss:  0.006635753437876701
Valid Loss:  0.006833256222307682
Epoch:  37  	Training Loss: 0.006491550710052252
Test Loss:  0.005835353396832943
Valid Loss:  0.006050969939678907
Epoch:  38  	Training Loss: 0.005808861460536718
Test Loss:  0.005168270785361528
Valid Loss:  0.00541060883551836
Epoch:  39  	Training Loss: 0.0052419425919651985
Test Loss:  0.004633541218936443
Valid Loss:  0.0048817843198776245
Epoch:  40  	Training Loss: 0.00477255042642355
Test Loss:  0.004216700792312622
Valid Loss:  0.004437084309756756
Epoch:  41  	Training Loss: 0.004383566789329052
Test Loss:  0.0038935737684369087
Valid Loss:  0.004065818153321743
Epoch:  42  	Training Loss: 0.004061433486640453
Test Loss:  0.0019961060024797916
Valid Loss:  0.0018396684899926186
Epoch:  43  	Training Loss: 0.002643405459821224
Test Loss:  0.0018864544108510017
Valid Loss:  0.0017647967906668782
Epoch:  44  	Training Loss: 0.0024532845709472895
Test Loss:  0.0017471048049628735
Valid Loss:  0.0016303022857755423
Epoch:  45  	Training Loss: 0.0022936323657631874
Test Loss:  0.0016268363688141108
Valid Loss:  0.0015172166749835014
Epoch:  46  	Training Loss: 0.002149091102182865
Test Loss:  0.0015189603436738253
Valid Loss:  0.0014157791156321764
Epoch:  47  	Training Loss: 0.002017819322645664
Test Loss:  0.0014238429721444845
Valid Loss:  0.0013255466474220157
Epoch:  48  	Training Loss: 0.0018988150404766202
Test Loss:  0.0013383611803874373
Valid Loss:  0.0012449186760932207
Epoch:  49  	Training Loss: 0.001790716778486967
Test Loss:  0.0012613487197086215
Valid Loss:  0.0011736443266272545
Epoch:  50  	Training Loss: 0.0016923327930271626
Test Loss:  0.0011928805615752935
Valid Loss:  0.0011102005373686552
Epoch:  51  	Training Loss: 0.0016028910176828504
Test Loss:  0.0011305158259347081
Valid Loss:  0.001053245970979333
Epoch:  52  	Training Loss: 0.0015210527926683426
Test Loss:  0.0011222040047869086
Valid Loss:  0.001081446884199977
Epoch:  53  	Training Loss: 0.0014078381936997175
Test Loss:  0.0009904270991683006
Valid Loss:  0.0008932821801863611
Epoch:  54  	Training Loss: 0.0014080676482990384
Test Loss:  0.0013613677583634853
Valid Loss:  0.0013744105817750096
Epoch:  55  	Training Loss: 0.001540687051601708
Test Loss:  0.0014731609262526035
Valid Loss:  0.0013193112099543214
Epoch:  56  	Training Loss: 0.002104592276737094
Test Loss:  0.002677356591448188
Valid Loss:  0.002761286683380604
Epoch:  57  	Training Loss: 0.0027252151630818844
Test Loss:  0.0014390527503564954
Valid Loss:  0.0014204357285052538
Epoch:  58  	Training Loss: 0.0015971928369253874
Test Loss:  0.0012471701484173536
Valid Loss:  0.0012157815508544445
Epoch:  59  	Training Loss: 0.0014396952465176582
Test Loss:  0.0011240653693675995
Valid Loss:  0.001084119314327836
Epoch:  60  	Training Loss: 0.00134062091819942
Test Loss:  0.0010423678904771805
Valid Loss:  0.0009937616996467113
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.0012736134231090546
Test Loss:  0.0010192146291956306
Valid Loss:  0.0009883353486657143
Epoch:  62  	Training Loss: 0.0012278362410143018
Test Loss:  0.0009621464414522052
Valid Loss:  0.000924882770050317
Epoch:  63  	Training Loss: 0.001173574011772871
Test Loss:  0.0009096289868466556
Valid Loss:  0.0008451418834738433
Epoch:  64  	Training Loss: 0.0011871966999024153
Test Loss:  0.000990066328085959
Valid Loss:  0.0009682822274044156
Epoch:  65  	Training Loss: 0.0011968915350735188
Test Loss:  0.0008213638793677092
Valid Loss:  0.0007542652310803533
Epoch:  66  	Training Loss: 0.0011105187004432082
Test Loss:  0.000868401606567204
Valid Loss:  0.0008253193227574229
Epoch:  67  	Training Loss: 0.001112865749746561
Test Loss:  0.0008109257905744016
Valid Loss:  0.0007435333100147545
Epoch:  68  	Training Loss: 0.0010917207691818476
Test Loss:  0.0008194437250494957
Valid Loss:  0.0007594295311719179
Epoch:  69  	Training Loss: 0.0010881104972213507
Test Loss:   14%|█▍        | 69/500 [00:59<04:01,  1.79it/s] 14%|█▍        | 71/500 [01:12<16:13,  2.27s/it] 15%|█▍        | 73/500 [01:12<11:27,  1.61s/it] 15%|█▌        | 75/500 [01:12<08:07,  1.15s/it] 15%|█▌        | 77/500 [01:12<05:47,  1.22it/s] 16%|█▌        | 79/500 [01:13<04:10,  1.68it/s] 16%|█▌        | 81/500 [01:19<09:28,  1.36s/it] 17%|█▋        | 83/500 [01:19<06:45,  1.03it/s] 17%|█▋        | 85/500 [01:19<04:50,  1.43it/s] 17%|█▋        | 87/500 [01:19<03:30,  1.97it/s] 18%|█▊        | 89/500 [01:19<02:34,  2.67it/s] 18%|█▊        | 91/500 [01:26<08:09,  1.20s/it] 19%|█▊        | 93/500 [01:26<05:49,  1.16it/s] 19%|█▉        | 95/500 [01:26<04:11,  1.61it/s] 19%|█▉        | 97/500 [01:26<03:02,  2.20it/s] 20%|█▉        | 99/500 [01:26<02:15,  2.96it/s] 20%|██        | 101/500 [01:32<07:51,  1.18s/it] 21%|██        | 103/500 [01:33<05:36,  1.18it/s] 21%|██        | 105/500 [01:33<04:01,  1.63it/s] 21%|██▏       | 107/500 [01:33<02:55,  2.23it/s] 22%|██▏       | 109/500 [01:33<02:09,  3.01it/s] 22%|██▏       | 111/500 [01:39<07:31,  1.16s/it] 23%|██▎       | 113/500 [01:39<05:22,  1.20it/s] 23%|██▎       | 115/500 [01:39<03:52,  1.66it/s] 23%|██▎       | 117/500 [01:40<02:50,  2.25it/s] 24%|██▍       | 119/500 [01:40<02:06,  3.02it/s] 24%|██▍       | 121/500 [01:46<07:18,  1.16s/it] 25%|██▍       | 123/500 [01:46<05:14,  1.20it/s] 25%|██▌       | 125/500 [01:46<03:46,  1.66it/s] 25%|██▌       | 127/500 [01:46<02:45,  2.25it/s] 26%|██▌       | 129/500 [01:46<02:03,  3.01it/s] 26%|██▌       | 131/500 [01:53<07:10,  1.17s/it] 27%|██▋       | 133/500 [01:53<05:07,  1.19it/s] 27%|██▋       | 135/500 [01:53<03:41,  1.65it/s]0.0008106596069410443
Valid Loss:  0.0007463187212124467
Epoch:  70  	Training Loss: 0.0010847477242350578
Test Loss:  0.0008102216525003314
Valid Loss:  0.0007468606345355511
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.001081885420717299
Test Loss:  0.0007968287682160735
Valid Loss:  0.0007333523244597018
Epoch:  72  	Training Loss: 0.0010684487642720342
Test Loss:  0.0007800052408128977
Valid Loss:  0.0007177118095569313
Epoch:  73  	Training Loss: 0.001048650941811502
Test Loss:  0.0007647571619600058
Valid Loss:  0.0007037966279312968
Epoch:  74  	Training Loss: 0.0010306814219802618
Test Loss:  0.0007512459997087717
Valid Loss:  0.0006910361698828638
Epoch:  75  	Training Loss: 0.0010143803665414453
Test Loss:  0.0007390017854049802
Valid Loss:  0.0006795268272981048
Epoch:  76  	Training Loss: 0.0009992970153689384
Test Loss:  0.0007277911063283682
Valid Loss:  0.0006691234884783626
Epoch:  77  	Training Loss: 0.0009851268259808421
Test Loss:  0.0007175215287134051
Valid Loss:  0.0006593684665858746
Epoch:  78  	Training Loss: 0.0009717404609546065
Test Loss:  0.0007077952614054084
Valid Loss:  0.0006501892348751426
Epoch:  79  	Training Loss: 0.0009591706329956651
Test Loss:  0.0006985426880419254
Valid Loss:  0.0006416374817490578
Epoch:  80  	Training Loss: 0.0009473090176470578
Test Loss:  0.0006896930281072855
Valid Loss:  0.0006335198413580656
Epoch:  81  	Training Loss: 0.000935872201807797
Test Loss:  0.0006811664206907153
Valid Loss:  0.0006258792127482593
Epoch:  82  	Training Loss: 0.0009247668785974383
Test Loss:  0.0006752199260517955
Valid Loss:  0.0006210540304891765
Epoch:  83  	Training Loss: 0.0009177867323160172
Test Loss:  0.0006691849557682872
Valid Loss:  0.0006159052136354148
Epoch:  84  	Training Loss: 0.000910166883841157
Test Loss:  0.0006626088870689273
Valid Loss:  0.0006105093052610755
Epoch:  85  	Training Loss: 0.0009020429570227861
Test Loss:  0.0006556071457453072
Valid Loss:  0.0006051707314327359
Epoch:  86  	Training Loss: 0.0008936762460507452
Test Loss:  0.0006486887577921152
Valid Loss:  0.0005998686538077891
Epoch:  87  	Training Loss: 0.0008853008621372283
Test Loss:  0.0006420001736842096
Valid Loss:  0.0005947793833911419
Epoch:  88  	Training Loss: 0.0008771350840106606
Test Loss:  0.0006356069352477789
Valid Loss:  0.0005900579271838069
Epoch:  89  	Training Loss: 0.0008693495183251798
Test Loss:  0.0006297780782915652
Valid Loss:  0.0005857666255906224
Epoch:  90  	Training Loss: 0.0008622240275144577
Test Loss:  0.0006244548712857068
Valid Loss:  0.0005819539655931294
Epoch:  91  	Training Loss: 0.0008558165864087641
Test Loss:  0.0006193533190526068
Valid Loss:  0.0005784862441942096
Epoch:  92  	Training Loss: 0.00084981246618554
Test Loss:  0.000605975859798491
Valid Loss:  0.0005678484449163079
Epoch:  93  	Training Loss: 0.0008304279763251543
Test Loss:  0.0005940242554061115
Valid Loss:  0.0005583284655585885
Epoch:  94  	Training Loss: 0.0008135671378113329
Test Loss:  0.000580707797780633
Valid Loss:  0.0005466286092996597
Epoch:  95  	Training Loss: 0.0007963228272274137
Test Loss:  0.0005717931780964136
Valid Loss:  0.0005404553958214819
Epoch:  96  	Training Loss: 0.000780391157604754
Test Loss:  0.0005600415170192719
Valid Loss:  0.0005307598621584475
Epoch:  97  	Training Loss: 0.0007650249172002077
Test Loss:  0.0005504164146259427
Valid Loss:  0.0005231216782703996
Epoch:  98  	Training Loss: 0.0007505076937377453
Test Loss:  0.0005409791483543813
Valid Loss:  0.0005152275552973151
Epoch:  99  	Training Loss: 0.0007366317440755665
Test Loss:  0.0005322449724189937
Valid Loss:  0.0005080732516944408
Epoch:  100  	Training Loss: 0.0007235888624563813
Test Loss:  0.0005238003213889897
Valid Loss:  0.0005011672037653625
Epoch:  101  	Training Loss: 0.0007110839360393584
Test Loss:  0.0005154345417395234
Valid Loss:  0.0004943513195030391
Epoch:  102  	Training Loss: 0.0006991842528805137
Test Loss:  0.000512988306581974
Valid Loss:  0.000492217717692256
Epoch:  103  	Training Loss: 0.0006966610089875758
Test Loss:  0.0005106740281917155
Valid Loss:  0.0004902869695797563
Epoch:  104  	Training Loss: 0.0006942999316379428
Test Loss:  0.0005084800068289042
Valid Loss:  0.0004885050584562123
Epoch:  105  	Training Loss: 0.0006920496234670281
Test Loss:  0.0005064142169430852
Valid Loss:  0.0004868440446443856
Epoch:  106  	Training Loss: 0.0006898692809045315
Test Loss:  0.0005044472636654973
Valid Loss:  0.00048529973719269037
Epoch:  107  	Training Loss: 0.0006877487758174539
Test Loss:  0.00050258485134691
Valid Loss:  0.0004838624154217541
Epoch:  108  	Training Loss: 0.000685709179379046
Test Loss:  0.0005008277366869152
Valid Loss:  0.0004825454670935869
Epoch:  109  	Training Loss: 0.0006837635301053524
Test Loss:  0.0004991540918126702
Valid Loss:  0.00048132811207324266
Epoch:  110  	Training Loss: 0.0006818837719038129
Test Loss:  0.0004975764895789325
Valid Loss:  0.00048018922097980976
Epoch:  111  	Training Loss: 0.0006800753180868924
Test Loss:  0.0004960668738931417
Valid Loss:  0.0004791382816620171
Epoch:  112  	Training Loss: 0.000678319251164794
Test Loss:  0.000481330236652866
Valid Loss:  0.0004651016788557172
Epoch:  113  	Training Loss: 0.0006609061965718865
Test Loss:  0.0004698033444583416
Valid Loss:  0.00045544994645752013
Epoch:  114  	Training Loss: 0.0006460109143517911
Test Loss:  0.00046084600035101175
Valid Loss:  0.0004487888654693961
Epoch:  115  	Training Loss: 0.0006325223948806524
Test Loss:  0.0004526660777628422
Valid Loss:  0.00044259708374738693
Epoch:  116  	Training Loss: 0.0006200492498464882
Test Loss:  0.00044555720523931086
Valid Loss:  0.00043775636004284024
Epoch:  117  	Training Loss: 0.0006084431661292911
Test Loss:  0.000438576505985111
Valid Loss:  0.00043297320371493697
Epoch:  118  	Training Loss: 0.0005975468084216118
Test Loss:  0.00043154688319191337
Valid Loss:  0.0004280355351511389
Epoch:  119  	Training Loss: 0.0005871907342225313
Test Loss:  0.00042441688128747046
Valid Loss:  0.00042285106610506773
Epoch:  120  	Training Loss: 0.0005772057920694351
Test Loss:  0.0004173959023319185
Valid Loss:  0.00041766048525460064
Epoch:  121  	Training Loss: 0.0005676241125911474
Test Loss:  0.00041173520730808377
Valid Loss:  0.0004138544900342822
Epoch:  122  	Training Loss: 0.0005585580365732312
Test Loss:  0.0004113965842407197
Valid Loss:  0.0004135930212214589
Epoch:  123  	Training Loss: 0.0005580541910603642
Test Loss:  0.00041105871787294745
Valid Loss:  0.00041333408444188535
Epoch:  124  	Training Loss: 0.0005575511022470891
Test Loss:  0.0004107214044779539
Valid Loss:  0.0004130867891944945
Epoch:  125  	Training Loss: 0.0005570491775870323
Test Loss:  0.0004103851970285177
Valid Loss:  0.00041284074541181326
Epoch:  126  	Training Loss: 0.0005565480678342283
Test Loss:  0.00041004951344802976
Valid Loss:  0.0004125946434214711
Epoch:  127  	Training Loss: 0.0005560492863878608
Test Loss:  0.00040971662383526564
Valid Loss:  0.00041235011303797364
Epoch:  128  	Training Loss: 0.0005555528332479298
Test Loss:  0.00040938437450677156
Valid Loss:  0.0004121063102502376
Epoch:  129  	Training Loss: 0.0005550570785999298
Test Loss:  0.0004090529982931912
Valid Loss:  0.0004118632059544325
Epoch:  130  	Training Loss: 0.0005545623134821653
Test Loss:  0.0004087164415977895
Valid Loss:  0.0004116209747735411
Epoch:  131  	Training Loss: 0.0005540699930861592
Test Loss:  0.0004083827661816031
Valid Loss:  0.00041138072265312076
Epoch:  132  	Training Loss: 0.0005535822128877044
Test Loss:  0.000404655555030331
Valid Loss:  0.0004080852959305048
Epoch:  133  	Training Loss: 0.0005492034833878279
Test Loss:  0.0004011966520920396
Valid Loss:  0.00040486245416104794
Epoch:  134  	Training Loss: 0.0005450395401567221
Test Loss:  0.0003979258763138205
Valid Loss:  0.0004017122555524111
Epoch:  135  	Training Loss: 0.0005410577286966145
Test Loss:  0.00039471470518037677
Valid Loss:  0.0003986500669270754
Epoch:  136  	Training Loss: 0.0005372239975258708
Test Loss:  0.000391598092392087
Valid Loss:  0.00039568718057125807 27%|██▋       | 137/500 [01:53<02:41,  2.25it/s] 28%|██▊       | 139/500 [01:53<01:59,  3.02it/s] 28%|██▊       | 141/500 [01:59<06:58,  1.17s/it] 29%|██▊       | 143/500 [02:00<04:59,  1.19it/s] 29%|██▉       | 145/500 [02:00<03:34,  1.65it/s] 29%|██▉       | 147/500 [02:00<02:36,  2.26it/s] 30%|██▉       | 149/500 [02:00<01:55,  3.03it/s] 30%|███       | 151/500 [02:06<06:52,  1.18s/it] 31%|███       | 153/500 [02:06<04:54,  1.18it/s] 31%|███       | 155/500 [02:07<03:32,  1.62it/s] 31%|███▏      | 157/500 [02:07<02:34,  2.22it/s] 32%|███▏      | 159/500 [02:07<01:54,  2.98it/s] 32%|███▏      | 161/500 [02:13<06:35,  1.17s/it] 33%|███▎      | 163/500 [02:13<04:42,  1.19it/s] 33%|███▎      | 165/500 [02:13<03:22,  1.65it/s] 33%|███▎      | 167/500 [02:13<02:27,  2.26it/s] 34%|███▍      | 169/500 [02:14<01:49,  3.03it/s] 34%|███▍      | 171/500 [02:20<06:22,  1.16s/it] 35%|███▍      | 173/500 [02:20<04:32,  1.20it/s] 35%|███▌      | 175/500 [02:20<03:16,  1.66it/s] 35%|███▌      | 177/500 [02:20<02:22,  2.26it/s] 36%|███▌      | 179/500 [02:20<01:45,  3.04it/s] 36%|███▌      | 181/500 [02:27<06:12,  1.17s/it] 37%|███▋      | 183/500 [02:27<04:25,  1.19it/s] 37%|███▋      | 185/500 [02:27<03:11,  1.65it/s] 37%|███▋      | 187/500 [02:27<02:19,  2.25it/s] 38%|███▊      | 189/500 [02:27<01:42,  3.02it/s] 38%|███▊      | 191/500 [02:33<06:06,  1.19s/it] 39%|███▊      | 193/500 [02:34<04:21,  1.17it/s] 39%|███▉      | 195/500 [02:34<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:34<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:34<01:40,  2.99it/s] 40%|████      | 201/500 [02:40<05:48,  1.17s/it] 41%|████      | 203/500 [02:40<04:08,  1.19it/s]
Epoch:  137  	Training Loss: 0.0005335220484994352
Test Loss:  0.00038856820901855826
Valid Loss:  0.0003927808138541877
Epoch:  138  	Training Loss: 0.0005299389595165849
Test Loss:  0.0003855927789118141
Valid Loss:  0.00039001231198199093
Epoch:  139  	Training Loss: 0.00052642886294052
Test Loss:  0.00038273463724181056
Valid Loss:  0.0003873719833791256
Epoch:  140  	Training Loss: 0.0005229900125414133
Test Loss:  0.00037997786421328783
Valid Loss:  0.0003847772313747555
Epoch:  141  	Training Loss: 0.0005196527927182615
Test Loss:  0.00037728640018031
Valid Loss:  0.00038224057061597705
Epoch:  142  	Training Loss: 0.0005164321046322584
Test Loss:  0.0003741954278666526
Valid Loss:  0.0003803363651968539
Epoch:  143  	Training Loss: 0.0005114777595736086
Test Loss:  0.0003712428151629865
Valid Loss:  0.0003782683634199202
Epoch:  144  	Training Loss: 0.0005069065955467522
Test Loss:  0.00036841953988187015
Valid Loss:  0.0003760826075449586
Epoch:  145  	Training Loss: 0.0005026640137657523
Test Loss:  0.00036563165485858917
Valid Loss:  0.00037380357389338315
Epoch:  146  	Training Loss: 0.0004986001295037568
Test Loss:  0.00036282517248764634
Valid Loss:  0.00037146941758692265
Epoch:  147  	Training Loss: 0.0004947014385834336
Test Loss:  0.0003600042255129665
Valid Loss:  0.00036913593066856265
Epoch:  148  	Training Loss: 0.0004909259150736034
Test Loss:  0.000357212673407048
Valid Loss:  0.0003668328863568604
Epoch:  149  	Training Loss: 0.0004873092984780669
Test Loss:  0.00035450540599413216
Valid Loss:  0.0003645270480774343
Epoch:  150  	Training Loss: 0.0004837638116441667
Test Loss:  0.00035183606087230146
Valid Loss:  0.0003622311051003635
Epoch:  151  	Training Loss: 0.0004803478950634599
Test Loss:  0.0003491981769911945
Valid Loss:  0.00035995757207274437
Epoch:  152  	Training Loss: 0.00047702339361421764
Test Loss:  0.00034026982029899955
Valid Loss:  0.00035267716157250106
Epoch:  153  	Training Loss: 0.00046880843001417816
Test Loss:  0.00033355935011059046
Valid Loss:  0.0003476566052995622
Epoch:  154  	Training Loss: 0.0004631541669368744
Test Loss:  0.00032821999047882855
Valid Loss:  0.00034355040406808257
Epoch:  155  	Training Loss: 0.000458849361166358
Test Loss:  0.00032418788759969175
Valid Loss:  0.00033989327494055033
Epoch:  156  	Training Loss: 0.0004553673788905144
Test Loss:  0.0003212040173821151
Valid Loss:  0.0003368154284544289
Epoch:  157  	Training Loss: 0.0004525930853560567
Test Loss:  0.00031857684371061623
Valid Loss:  0.0003342687268741429
Epoch:  158  	Training Loss: 0.0004501255170907825
Test Loss:  0.0003161331987939775
Valid Loss:  0.00033208300010301173
Epoch:  159  	Training Loss: 0.00044787503429688513
Test Loss:  0.00031407378264702857
Valid Loss:  0.0003301632823422551
Epoch:  160  	Training Loss: 0.00044597743544727564
Test Loss:  0.00031241547549143434
Valid Loss:  0.00032847432885318995
Epoch:  161  	Training Loss: 0.00044435454765334725
Test Loss:  0.0003110846155323088
Valid Loss:  0.0003270969318691641
Epoch:  162  	Training Loss: 0.0004429356486070901
Test Loss:  0.0003091075050178915
Valid Loss:  0.00032513251062482595
Epoch:  163  	Training Loss: 0.000440865580458194
Test Loss:  0.0003071778337471187
Valid Loss:  0.0003232339513488114
Epoch:  164  	Training Loss: 0.00043884565820917487
Test Loss:  0.0003052933607250452
Valid Loss:  0.00032140008988790214
Epoch:  165  	Training Loss: 0.0004368761437945068
Test Loss:  0.00030345533741638064
Valid Loss:  0.0003196272882632911
Epoch:  166  	Training Loss: 0.000434952526120469
Test Loss:  0.0003016602131538093
Valid Loss:  0.00031789811328053474
Epoch:  167  	Training Loss: 0.0004330697120167315
Test Loss:  0.0002999132848344743
Valid Loss:  0.00031621012021787465
Epoch:  168  	Training Loss: 0.00043122240458615124
Test Loss:  0.00029820308554917574
Valid Loss:  0.00031457451405003667
Epoch:  169  	Training Loss: 0.0004294097307138145
Test Loss:  0.00029653258388862014
Valid Loss:  0.0003129758988507092
Epoch:  170  	Training Loss: 0.0004276291001588106
Test Loss:  0.00029490538872778416
Valid Loss:  0.0003114202991127968
Epoch:  171  	Training Loss: 0.00042589200893417
Test Loss:  0.00029331748373806477
Valid Loss:  0.00030991522362455726
Epoch:  172  	Training Loss: 0.00042419967940077186
Test Loss:  0.0002933283685706556
Valid Loss:  0.0003103173803538084
Epoch:  173  	Training Loss: 0.00042173080146312714
Test Loss:  0.0002936609380412847
Valid Loss:  0.0003109747776761651
Epoch:  174  	Training Loss: 0.00042003372800536454
Test Loss:  0.00029415416065603495
Valid Loss:  0.00031173962634056807
Epoch:  175  	Training Loss: 0.00041886381222866476
Test Loss:  0.00029470984009094536
Valid Loss:  0.0003125232760794461
Epoch:  176  	Training Loss: 0.0004180536197964102
Test Loss:  0.0002952681388705969
Valid Loss:  0.0003132737474516034
Epoch:  177  	Training Loss: 0.00041748894727788866
Test Loss:  0.00029579701367765665
Valid Loss:  0.0003139647305943072
Epoch:  178  	Training Loss: 0.0004170921165496111
Test Loss:  0.00029627728508785367
Valid Loss:  0.0003145832451991737
Epoch:  179  	Training Loss: 0.0004168095183558762
Test Loss:  0.00029670310323126614
Valid Loss:  0.000315127894282341
Epoch:  180  	Training Loss: 0.00041660520946606994
Test Loss:  0.00029707312933169305
Valid Loss:  0.00031560022034682333
Epoch:  181  	Training Loss: 0.0004164542770013213
Test Loss:  0.0002973890514113009
Valid Loss:  0.00031600528745912015
Epoch:  182  	Training Loss: 0.00041633954970166087
Test Loss:  0.0002911498595494777
Valid Loss:  0.0003089342499151826
Epoch:  183  	Training Loss: 0.0004091084119863808
Test Loss:  0.00028367622871883214
Valid Loss:  0.000301526888506487
Epoch:  184  	Training Loss: 0.00040135611197911203
Test Loss:  0.0002767775731626898
Valid Loss:  0.000294794503133744
Epoch:  185  	Training Loss: 0.00039425314753316343
Test Loss:  0.00027063177549280226
Valid Loss:  0.0002888136077672243
Epoch:  186  	Training Loss: 0.00038790953112766147
Test Loss:  0.0002650411333888769
Valid Loss:  0.0002833606267813593
Epoch:  187  	Training Loss: 0.00038212761864997447
Test Loss:  0.0002601536107249558
Valid Loss:  0.0002786885015666485
Epoch:  188  	Training Loss: 0.0003770673356484622
Test Loss:  0.00025586708215996623
Valid Loss:  0.00027470680652186275
Epoch:  189  	Training Loss: 0.0003727234434336424
Test Loss:  0.00025228344020433724
Valid Loss:  0.00027158812736161053
Epoch:  190  	Training Loss: 0.00036903825821354985
Test Loss:  0.00024915955145843327
Valid Loss:  0.0002689971588551998
Epoch:  191  	Training Loss: 0.0003658940549939871
Test Loss:  0.0002465955913066864
Valid Loss:  0.00026694059488363564
Epoch:  192  	Training Loss: 0.0003633514861576259
Test Loss:  0.00024490460054948926
Valid Loss:  0.0002674242714419961
Epoch:  193  	Training Loss: 0.0003553324786480516
Test Loss:  0.00024624817888252437
Valid Loss:  0.00026925679412670434
Epoch:  194  	Training Loss: 0.0003523103951010853
Test Loss:  0.0002474366337992251
Valid Loss:  0.00027083655004389584
Epoch:  195  	Training Loss: 0.00035130578908137977
Test Loss:  0.0002479200775269419
Valid Loss:  0.00027164723724126816
Epoch:  196  	Training Loss: 0.0003509141388349235
Test Loss:  0.00024800980463624
Valid Loss:  0.00027196365408599377
Epoch:  197  	Training Loss: 0.0003506019420456141
Test Loss:  0.00024800622486509383
Valid Loss:  0.0002721766650211066
Epoch:  198  	Training Loss: 0.0003503045008983463
Test Loss:  0.0002479449613019824
Valid Loss:  0.00027231586864218116
Epoch:  199  	Training Loss: 0.0003500143066048622
Test Loss:  0.000247840624069795
Valid Loss:  0.0002724032965488732
Epoch:  200  	Training Loss: 0.00034973156289197505
Test Loss:  0.00024781632237136364
Valid Loss:  0.00027259712805971503
Epoch:  201  	Training Loss: 0.00034945711377076805
Test Loss:  0.0002477410598658025
Valid Loss:  0.00027272957959212363
Epoch:  202  	Training Loss: 0.0003491886309348047
Test Loss:  0.00024387918529100716
Valid Loss:  0.00026939628878608346
Epoch:  203  	Training Loss: 0.00034512276761233807
Test Loss:  0.0002406086859991774
Valid Loss:  0.00026665240875445306
Epoch:  204  	Training Loss: 0.00034170655999332666
Test Loss:   41%|████      | 205/500 [02:40<02:58,  1.65it/s] 41%|████▏     | 207/500 [02:41<02:09,  2.26it/s] 42%|████▏     | 209/500 [02:41<01:35,  3.03it/s] 42%|████▏     | 211/500 [02:47<05:33,  1.15s/it] 43%|████▎     | 213/500 [02:47<03:58,  1.21it/s] 43%|████▎     | 215/500 [02:47<02:51,  1.66it/s] 43%|████▎     | 217/500 [02:47<02:04,  2.27it/s] 44%|████▍     | 219/500 [02:47<01:32,  3.04it/s] 44%|████▍     | 221/500 [02:54<05:27,  1.17s/it] 45%|████▍     | 223/500 [02:54<03:53,  1.19it/s] 45%|████▌     | 225/500 [02:54<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:54<02:01,  2.24it/s] 46%|████▌     | 229/500 [02:54<01:30,  3.00it/s] 46%|████▌     | 231/500 [03:00<05:13,  1.17s/it] 47%|████▋     | 233/500 [03:01<03:44,  1.19it/s] 47%|████▋     | 235/500 [03:01<02:42,  1.63it/s] 47%|████▋     | 237/500 [03:01<01:59,  2.20it/s] 48%|████▊     | 239/500 [03:01<01:28,  2.94it/s] 48%|████▊     | 241/500 [03:07<05:06,  1.18s/it] 49%|████▊     | 243/500 [03:08<03:38,  1.18it/s] 49%|████▉     | 245/500 [03:08<02:36,  1.63it/s] 49%|████▉     | 247/500 [03:08<01:53,  2.22it/s] 50%|████▉     | 249/500 [03:08<01:23,  2.99it/s] 50%|█████     | 251/500 [03:14<04:53,  1.18s/it] 51%|█████     | 253/500 [03:14<03:28,  1.18it/s] 51%|█████     | 255/500 [03:15<02:29,  1.64it/s] 51%|█████▏    | 257/500 [03:15<01:48,  2.24it/s] 52%|█████▏    | 259/500 [03:15<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:21<04:39,  1.17s/it] 53%|█████▎    | 263/500 [03:21<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:21<02:22,  1.65it/s] 53%|█████▎    | 267/500 [03:21<01:43,  2.25it/s] 54%|█████▍    | 269/500 [03:22<01:16,  3.03it/s]0.00023755989968776703
Valid Loss:  0.00026414793683215976
Epoch:  205  	Training Loss: 0.0003386106400284916
Test Loss:  0.00023470901942346245
Valid Loss:  0.0002617452119011432
Epoch:  206  	Training Loss: 0.00033569178776815534
Test Loss:  0.00023216634872369468
Valid Loss:  0.0002594418474473059
Epoch:  207  	Training Loss: 0.00033296472975052893
Test Loss:  0.00022986176190897822
Valid Loss:  0.0002572873781900853
Epoch:  208  	Training Loss: 0.000330403505358845
Test Loss:  0.00022770563373342156
Valid Loss:  0.000255277962423861
Epoch:  209  	Training Loss: 0.00032791501143947244
Test Loss:  0.00022560489014722407
Valid Loss:  0.0002533577790018171
Epoch:  210  	Training Loss: 0.0003254999755881727
Test Loss:  0.00022354937391355634
Valid Loss:  0.0002515092783141881
Epoch:  211  	Training Loss: 0.00032319859019480646
Test Loss:  0.00022164052643347532
Valid Loss:  0.0002497437526471913
Epoch:  212  	Training Loss: 0.0003210070717614144
Test Loss:  0.0002201300667366013
Valid Loss:  0.00025025231298059225
Epoch:  213  	Training Loss: 0.0003146221279166639
Test Loss:  0.00021867427858524024
Valid Loss:  0.00024986674543470144
Epoch:  214  	Training Loss: 0.00031141459476202726
Test Loss:  0.00021685184037778527
Valid Loss:  0.0002490474726073444
Epoch:  215  	Training Loss: 0.00030863587744534016
Test Loss:  0.00021494698012247682
Valid Loss:  0.0002479902468621731
Epoch:  216  	Training Loss: 0.00030603245249949396
Test Loss:  0.00021282833768054843
Valid Loss:  0.00024644832592457533
Epoch:  217  	Training Loss: 0.0003035444242414087
Test Loss:  0.00021080850274302065
Valid Loss:  0.0002450032043270767
Epoch:  218  	Training Loss: 0.00030111963860690594
Test Loss:  0.00020886104903183877
Valid Loss:  0.0002436177310300991
Epoch:  219  	Training Loss: 0.00029875364270992577
Test Loss:  0.00020697861327789724
Valid Loss:  0.00024227367248386145
Epoch:  220  	Training Loss: 0.00029644768801517785
Test Loss:  0.0002050590410362929
Valid Loss:  0.00024081851006485522
Epoch:  221  	Training Loss: 0.0002941935381386429
Test Loss:  0.00020322881755419075
Valid Loss:  0.00023945339489728212
Epoch:  222  	Training Loss: 0.00029198284028097987
Test Loss:  0.00020082817354705185
Valid Loss:  0.00023759208852425218
Epoch:  223  	Training Loss: 0.00028917312738485634
Test Loss:  0.0001985150738619268
Valid Loss:  0.00023577290994580835
Epoch:  224  	Training Loss: 0.0002863343106582761
Test Loss:  0.00019601010717451572
Valid Loss:  0.00023389280249830335
Epoch:  225  	Training Loss: 0.0002830671437550336
Test Loss:  0.00019332027295604348
Valid Loss:  0.00023192580556496978
Epoch:  226  	Training Loss: 0.00027927180053666234
Test Loss:  0.0001907055702758953
Valid Loss:  0.00022984185488894582
Epoch:  227  	Training Loss: 0.00027546321507543325
Test Loss:  0.0001881241041701287
Valid Loss:  0.00022763200104236603
Epoch:  228  	Training Loss: 0.0002714392321649939
Test Loss:  0.0001855137525126338
Valid Loss:  0.00022523084771819413
Epoch:  229  	Training Loss: 0.000267079274635762
Test Loss:  0.00018282697419635952
Valid Loss:  0.0002227053337264806
Epoch:  230  	Training Loss: 0.0002625717024784535
Test Loss:  0.00017963569553103298
Valid Loss:  0.0002202031755587086
Epoch:  231  	Training Loss: 0.00025809009093791246
Test Loss:  0.0001764904154697433
Valid Loss:  0.00021778645168524235
Epoch:  232  	Training Loss: 0.0002536815300118178
Test Loss:  0.0001757464779075235
Valid Loss:  0.00021719792857766151
Epoch:  233  	Training Loss: 0.00025313004152849317
Test Loss:  0.000175107445102185
Valid Loss:  0.00021665608801413327
Epoch:  234  	Training Loss: 0.0002526315220165998
Test Loss:  0.00017453600594308227
Valid Loss:  0.00021613815624732524
Epoch:  235  	Training Loss: 0.00025219100643880665
Test Loss:  0.000173975684447214
Valid Loss:  0.00021561843459494412
Epoch:  236  	Training Loss: 0.00025179210933856666
Test Loss:  0.00017348524124827236
Valid Loss:  0.0002151756052626297
Epoch:  237  	Training Loss: 0.00025140869547612965
Test Loss:  0.0001730435760691762
Valid Loss:  0.00021478038979694247
Epoch:  238  	Training Loss: 0.00025103730149567127
Test Loss:  0.00017260928871110082
Valid Loss:  0.00021438785188365728
Epoch:  239  	Training Loss: 0.00025069390540011227
Test Loss:  0.00017218866560142487
Valid Loss:  0.00021401987760327756
Epoch:  240  	Training Loss: 0.00025036209262907505
Test Loss:  0.0001718110725050792
Valid Loss:  0.00021366422879509628
Epoch:  241  	Training Loss: 0.00025004686904139817
Test Loss:  0.00017143839795608073
Valid Loss:  0.00021329056471586227
Epoch:  242  	Training Loss: 0.0002497505920473486
Test Loss:  0.000169475213624537
Valid Loss:  0.00021138375450391322
Epoch:  243  	Training Loss: 0.0002475541550666094
Test Loss:  0.00016770599177107215
Valid Loss:  0.00020959184621460736
Epoch:  244  	Training Loss: 0.00024546124041080475
Test Loss:  0.00016612658509984612
Valid Loss:  0.0002079760452033952
Epoch:  245  	Training Loss: 0.0002434659982100129
Test Loss:  0.00016458990285173059
Valid Loss:  0.0002065296284854412
Epoch:  246  	Training Loss: 0.0002414966293144971
Test Loss:  0.00016308338672388345
Valid Loss:  0.00020517935627140105
Epoch:  247  	Training Loss: 0.00023955509823281318
Test Loss:  0.00016162553220055997
Valid Loss:  0.00020387147378642112
Epoch:  248  	Training Loss: 0.00023768242681398988
Test Loss:  0.0001601874828338623
Valid Loss:  0.0002025812427746132
Epoch:  249  	Training Loss: 0.0002358672791160643
Test Loss:  0.0001588795566931367
Valid Loss:  0.00020134111400693655
Epoch:  250  	Training Loss: 0.00023412828159052879
Test Loss:  0.00015760758833494037
Valid Loss:  0.0002001166867557913
Epoch:  251  	Training Loss: 0.00023240908922161907
Test Loss:  0.00015635130694136024
Valid Loss:  0.0001989211596082896
Epoch:  252  	Training Loss: 0.00023072113981470466
Test Loss:  0.00015610757691320032
Valid Loss:  0.0001987282303161919
Epoch:  253  	Training Loss: 0.0002301354834344238
Test Loss:  0.00015583026106469333
Valid Loss:  0.00019850165699608624
Epoch:  254  	Training Loss: 0.000229576020501554
Test Loss:  0.00015552258992101997
Valid Loss:  0.00019824437913484871
Epoch:  255  	Training Loss: 0.00022903595527168363
Test Loss:  0.00015519291628152132
Valid Loss:  0.00019796501146629453
Epoch:  256  	Training Loss: 0.0002285133086843416
Test Loss:  0.00015484403411392123
Valid Loss:  0.00019766534387599677
Epoch:  257  	Training Loss: 0.0002280002663610503
Test Loss:  0.0001544778933748603
Valid Loss:  0.0001973487960640341
Epoch:  258  	Training Loss: 0.00022749355412088335
Test Loss:  0.00015409811749123037
Valid Loss:  0.0001970316661754623
Epoch:  259  	Training Loss: 0.00022699098917655647
Test Loss:  0.00015370930486824363
Valid Loss:  0.00019670295296236873
Epoch:  260  	Training Loss: 0.0002264936629217118
Test Loss:  0.0001533202885184437
Valid Loss:  0.00019636866636574268
Epoch:  261  	Training Loss: 0.00022600403463002294
Test Loss:  0.00015292526222765446
Valid Loss:  0.00019602850079536438
Epoch:  262  	Training Loss: 0.00022551696747541428
Test Loss:  0.00015188666293397546
Valid Loss:  0.00019508216064423323
Epoch:  263  	Training Loss: 0.0002244748902739957
Test Loss:  0.0001508947607362643
Valid Loss:  0.00019417940347921103
Epoch:  264  	Training Loss: 0.00022345615434460342
Test Loss:  0.0001499298377893865
Valid Loss:  0.00019326392794027925
Epoch:  265  	Training Loss: 0.00022247343440540135
Test Loss:  0.0001488991256337613
Valid Loss:  0.00019224334391765296
Epoch:  266  	Training Loss: 0.00022151667508296669
Test Loss:  0.00014793124864809215
Valid Loss:  0.00019128262647427619
Epoch:  267  	Training Loss: 0.0002205850469181314
Test Loss:  0.00014701590407639742
Valid Loss:  0.0001903706870507449
Epoch:  268  	Training Loss: 0.0002196742279920727
Test Loss:  0.00014614377869293094
Valid Loss:  0.00018949923105537891
Epoch:  269  	Training Loss: 0.0002187812642659992
Test Loss:  0.00014530889166053385
Valid Loss:  0.0001886612008092925
Epoch:  270  	Training Loss: 0.00021790381288155913
Test Loss:  0.00014450529124587774
Valid Loss:  0.0001878522161860019
Epoch:  271  	Training Loss: 0.00021703980746679008
Test Loss:  0.00014372846635524184
 54%|█████▍    | 271/500 [03:28<04:26,  1.16s/it] 55%|█████▍    | 273/500 [03:28<03:09,  1.20it/s] 55%|█████▌    | 275/500 [03:28<02:15,  1.66it/s] 55%|█████▌    | 277/500 [03:28<01:38,  2.26it/s] 56%|█████▌    | 279/500 [03:28<01:12,  3.04it/s] 56%|█████▌    | 281/500 [03:35<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:35<03:01,  1.19it/s] 57%|█████▋    | 285/500 [03:35<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:35<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:35<01:09,  3.03it/s] 58%|█████▊    | 291/500 [03:41<04:08,  1.19s/it] 59%|█████▊    | 293/500 [03:42<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:42<02:06,  1.63it/s] 59%|█████▉    | 297/500 [03:42<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:42<01:07,  2.98it/s] 60%|██████    | 301/500 [03:48<03:53,  1.17s/it] 61%|██████    | 303/500 [03:48<02:46,  1.19it/s] 61%|██████    | 305/500 [03:49<01:58,  1.64it/s] 61%|██████▏   | 307/500 [03:49<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:49<01:03,  3.02it/s] 62%|██████▏   | 311/500 [03:55<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:55<02:37,  1.18it/s] 63%|██████▎   | 315/500 [03:55<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:55<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:56<00:59,  3.02it/s] 64%|██████▍   | 321/500 [04:02<03:30,  1.17s/it] 65%|██████▍   | 323/500 [04:02<02:29,  1.19it/s] 65%|██████▌   | 325/500 [04:02<01:46,  1.64it/s] 65%|██████▌   | 327/500 [04:02<01:17,  2.24it/s] 66%|██████▌   | 329/500 [04:02<00:56,  3.01it/s] 66%|██████▌   | 331/500 [04:09<03:17,  1.17s/it] 67%|██████▋   | 333/500 [04:09<02:19,  1.19it/s] 67%|██████▋   | 335/500 [04:09<01:40,  1.65it/s] 67%|██████▋   | 337/500 [04:09<01:12,  2.25it/s]Valid Loss:  0.00018706692208070308
Epoch:  272  	Training Loss: 0.00021618817117996514
Test Loss:  0.0001433532015653327
Valid Loss:  0.000186533376108855
Epoch:  273  	Training Loss: 0.00021602098422590643
Test Loss:  0.00014300864131655544
Valid Loss:  0.00018603152420837432
Epoch:  274  	Training Loss: 0.0002158689749194309
Test Loss:  0.00014269653183873743
Valid Loss:  0.00018556317081674933
Epoch:  275  	Training Loss: 0.0002157319977413863
Test Loss:  0.0001424118527211249
Valid Loss:  0.00018512451788410544
Epoch:  276  	Training Loss: 0.00021560722962021828
Test Loss:  0.00014215159171726555
Valid Loss:  0.00018471339717507362
Epoch:  277  	Training Loss: 0.00021549286611843854
Test Loss:  0.00014191358059179038
Valid Loss:  0.00018432589422445744
Epoch:  278  	Training Loss: 0.0002153875248041004
Test Loss:  0.00014169476344250143
Valid Loss:  0.000183960422873497
Epoch:  279  	Training Loss: 0.00021528956131078303
Test Loss:  0.00014149301568977535
Valid Loss:  0.000183614669367671
Epoch:  280  	Training Loss: 0.00021519840811379254
Test Loss:  0.00014130644558463246
Valid Loss:  0.00018328760052099824
Epoch:  281  	Training Loss: 0.00021511274098884314
Test Loss:  0.0001411341509083286
Valid Loss:  0.0001829768589232117
Epoch:  282  	Training Loss: 0.00021503210882656276
Test Loss:  0.00013978529023006558
Valid Loss:  0.00018274009926244617
Epoch:  283  	Training Loss: 0.0002122951264027506
Test Loss:  0.00013877463061362505
Valid Loss:  0.00018240622011944652
Epoch:  284  	Training Loss: 0.00021018856205046177
Test Loss:  0.00013769253564532846
Valid Loss:  0.00018181343330070376
Epoch:  285  	Training Loss: 0.00020838502678088844
Test Loss:  0.00013658360694535077
Valid Loss:  0.00018111997633241117
Epoch:  286  	Training Loss: 0.00020668255456257612
Test Loss:  0.00013544816465582699
Valid Loss:  0.00018034808454103768
Epoch:  287  	Training Loss: 0.00020504105486907065
Test Loss:  0.00013429211685433984
Valid Loss:  0.00017951789777725935
Epoch:  288  	Training Loss: 0.0002034399367403239
Test Loss:  0.00013312336523085833
Valid Loss:  0.0001786475913831964
Epoch:  289  	Training Loss: 0.00020186910114716738
Test Loss:  0.00013195184874348342
Valid Loss:  0.00017775138258002698
Epoch:  290  	Training Loss: 0.0002003235276788473
Test Loss:  0.00013078103074803948
Valid Loss:  0.0001768392394296825
Epoch:  291  	Training Loss: 0.00019880001491401345
Test Loss:  0.00012961370521225035
Valid Loss:  0.00017591995128896087
Epoch:  292  	Training Loss: 0.00019729773339349777
Test Loss:  0.00012812280328944325
Valid Loss:  0.00017471537285018712
Epoch:  293  	Training Loss: 0.00019565220281947404
Test Loss:  0.00012671345029957592
Valid Loss:  0.00017344977823086083
Epoch:  294  	Training Loss: 0.00019409204833209515
Test Loss:  0.0001254130620509386
Valid Loss:  0.0001722615270409733
Epoch:  295  	Training Loss: 0.00019263269496150315
Test Loss:  0.00012415250239428133
Valid Loss:  0.00017106998711824417
Epoch:  296  	Training Loss: 0.00019122791127301753
Test Loss:  0.00012293267354834825
Valid Loss:  0.00016995312762446702
Epoch:  297  	Training Loss: 0.0001898693444672972
Test Loss:  0.00012173704453743994
Valid Loss:  0.00016888997924979776
Epoch:  298  	Training Loss: 0.00018853058281820267
Test Loss:  0.0001205647859023884
Valid Loss:  0.00016790466906968504
Epoch:  299  	Training Loss: 0.000187232275493443
Test Loss:  0.00011948496830882505
Valid Loss:  0.00016698600666131824
Epoch:  300  	Training Loss: 0.00018599450413603336
Test Loss:  0.00011844650725834072
Valid Loss:  0.00016611213504802436
Epoch:  301  	Training Loss: 0.00018479306891094893
Test Loss:  0.00011746316158678383
Valid Loss:  0.00016528161359019578
Epoch:  302  	Training Loss: 0.00018363166600465775
Test Loss:  0.00011696325964294374
Valid Loss:  0.00016478913312312216
Epoch:  303  	Training Loss: 0.00018296719645150006
Test Loss:  0.00011646043276414275
Valid Loss:  0.00016429398965556175
Epoch:  304  	Training Loss: 0.00018230907153338194
Test Loss:  0.00011595578689593822
Valid Loss:  0.00016379753651563078
Epoch:  305  	Training Loss: 0.0001816561707528308
Test Loss:  0.00011545008601387963
Valid Loss:  0.00016330037033185363
Epoch:  306  	Training Loss: 0.0001810086250770837
Test Loss:  0.00011494392674649134
Valid Loss:  0.00016280384443234652
Epoch:  307  	Training Loss: 0.00018036547407973558
Test Loss:  0.0001144381967606023
Valid Loss:  0.00016230701294261962
Epoch:  308  	Training Loss: 0.00017972709611058235
Test Loss:  0.00011393395834602416
Valid Loss:  0.00016181264072656631
Epoch:  309  	Training Loss: 0.00017909356392920017
Test Loss:  0.0001134314079536125
Valid Loss:  0.00016131979646161199
Epoch:  310  	Training Loss: 0.00017846468836069107
Test Loss:  0.00011293102579656988
Valid Loss:  0.00016082962974905968
Epoch:  311  	Training Loss: 0.00017784097872208804
Test Loss:  0.00011243340850342065
Valid Loss:  0.0001603426062501967
Epoch:  312  	Training Loss: 0.00017722207121551037
Test Loss:  0.000112360023194924
Valid Loss:  0.0001602327247383073
Epoch:  313  	Training Loss: 0.00017714727437123656
Test Loss:  0.00011228708899579942
Valid Loss:  0.00016012425476219505
Epoch:  314  	Training Loss: 0.00017707307415548712
Test Loss:  0.00011221530439797789
Valid Loss:  0.0001600163523107767
Epoch:  315  	Training Loss: 0.00017699931049719453
Test Loss:  0.00011214373080292717
Valid Loss:  0.00015990930842235684
Epoch:  316  	Training Loss: 0.0001769258378772065
Test Loss:  0.00011207300121895969
Valid Loss:  0.00015980436000972986
Epoch:  317  	Training Loss: 0.0001768528891261667
Test Loss:  0.00011200310837011784
Valid Loss:  0.00015970015374477953
Epoch:  318  	Training Loss: 0.0001767801441019401
Test Loss:  0.00011193343380000442
Valid Loss:  0.0001595968205947429
Epoch:  319  	Training Loss: 0.00017670798115432262
Test Loss:  0.0001118645304813981
Valid Loss:  0.00015949390945024788
Epoch:  320  	Training Loss: 0.00017663583275862038
Test Loss:  0.00011179596185684204
Valid Loss:  0.00015939175500534475
Epoch:  321  	Training Loss: 0.00017656452837400138
Test Loss:  0.00011172825179528445
Valid Loss:  0.00015929047367535532
Epoch:  322  	Training Loss: 0.00017649339861236513
Test Loss:  0.00010998646030202508
Valid Loss:  0.0001576741342432797
Epoch:  323  	Training Loss: 0.00017488494631834328
Test Loss:  0.00010851243132492527
Valid Loss:  0.00015631207497790456
Epoch:  324  	Training Loss: 0.00017339240002911538
Test Loss:  0.00010723306331783533
Valid Loss:  0.00015511224046349525
Epoch:  325  	Training Loss: 0.00017200264846906066
Test Loss:  0.00010607097647152841
Valid Loss:  0.00015392230125144124
Epoch:  326  	Training Loss: 0.0001707329211058095
Test Loss:  0.00010501807264517993
Valid Loss:  0.00015280951629392803
Epoch:  327  	Training Loss: 0.00016951491124927998
Test Loss:  0.00010399477469036356
Valid Loss:  0.0001517145719844848
Epoch:  328  	Training Loss: 0.00016833136032801121
Test Loss:  0.0001030186249408871
Valid Loss:  0.00015071843517944217
Epoch:  329  	Training Loss: 0.0001671690697548911
Test Loss:  0.00010210761683993042
Valid Loss:  0.00014975431258790195
Epoch:  330  	Training Loss: 0.00016607472207397223
Test Loss:  0.00010123842366738245
Valid Loss:  0.00014883209951221943
Epoch:  331  	Training Loss: 0.00016501828213222325
Test Loss:  0.00010040058987215161
Valid Loss:  0.0001479018828831613
Epoch:  332  	Training Loss: 0.00016399490414187312
Test Loss:  0.00010013888822868466
Valid Loss:  0.00014750316040590405
Epoch:  333  	Training Loss: 0.00016356934793293476
Test Loss:  9.98652249109e-05
Valid Loss:  0.00014706388174090534
Epoch:  334  	Training Loss: 0.00016315214452333748
Test Loss:  9.957073780242354e-05
Valid Loss:  0.00014660254237242043
Epoch:  335  	Training Loss: 0.00016273558139801025
Test Loss:  9.926512575475499e-05
Valid Loss:  0.00014612215454690158
Epoch:  336  	Training Loss: 0.00016232021152973175
Test Loss:  9.895798575598747e-05
Valid Loss:  0.0001456390309613198
Epoch:  337  	Training Loss: 0.00016191577014978975
Test Loss:  9.859182318905368e-05
Valid Loss:  0.00014505743456538767
Epoch:  338  	Training Loss: 0.00016152762691490352
Test Loss:  9.826681343838573e-05
 68%|██████▊   | 339/500 [04:09<00:53,  3.02it/s] 68%|██████▊   | 341/500 [04:15<03:06,  1.17s/it] 69%|██████▊   | 343/500 [04:16<02:12,  1.19it/s] 69%|██████▉   | 345/500 [04:16<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:16<01:08,  2.24it/s] 70%|██████▉   | 349/500 [04:16<00:50,  3.02it/s] 70%|███████   | 351/500 [04:22<02:54,  1.17s/it] 71%|███████   | 353/500 [04:22<02:03,  1.19it/s] 71%|███████   | 355/500 [04:23<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:23<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:23<00:46,  3.01it/s] 72%|███████▏  | 361/500 [04:29<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:29<01:57,  1.17it/s] 73%|███████▎  | 365/500 [04:29<01:23,  1.61it/s] 73%|███████▎  | 367/500 [04:30<01:00,  2.20it/s] 74%|███████▍  | 369/500 [04:30<00:45,  2.91it/s] 74%|███████▍  | 371/500 [04:36<02:36,  1.22s/it] 75%|███████▍  | 373/500 [04:36<01:50,  1.15it/s] 75%|███████▌  | 375/500 [04:37<01:18,  1.59it/s] 75%|███████▌  | 377/500 [04:37<00:56,  2.17it/s] 76%|███████▌  | 379/500 [04:37<00:41,  2.93it/s] 76%|███████▌  | 381/500 [04:43<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:43<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:43<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:43<00:50,  2.24it/s] 78%|███████▊  | 389/500 [04:44<00:36,  3.01it/s] 78%|███████▊  | 391/500 [04:50<02:08,  1.17s/it] 79%|███████▊  | 393/500 [04:50<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:50<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:50<00:46,  2.23it/s] 80%|███████▉  | 399/500 [04:50<00:33,  3.00it/s] 80%|████████  | 401/500 [04:57<01:55,  1.17s/it] 81%|████████  | 403/500 [04:57<01:21,  1.19it/s] 81%|████████  | 405/500 [04:57<00:57,  1.64it/s]Valid Loss:  0.00014453966286964715
Epoch:  339  	Training Loss: 0.00016116263577714562
Test Loss:  9.797050734050572e-05
Valid Loss:  0.0001440848282072693
Epoch:  340  	Training Loss: 0.00016082177171483636
Test Loss:  9.770387259777635e-05
Valid Loss:  0.00014366887626238167
Epoch:  341  	Training Loss: 0.00016049314581323415
Test Loss:  9.746276191435754e-05
Valid Loss:  0.0001432864519301802
Epoch:  342  	Training Loss: 0.0001601874828338623
Test Loss:  9.66246152529493e-05
Valid Loss:  0.0001423466601409018
Epoch:  343  	Training Loss: 0.0001593426859471947
Test Loss:  9.585770749254152e-05
Valid Loss:  0.00014152744552120566
Epoch:  344  	Training Loss: 0.00015853179502300918
Test Loss:  9.515601414022967e-05
Valid Loss:  0.00014077508240006864
Epoch:  345  	Training Loss: 0.00015776361397001892
Test Loss:  9.451953519601375e-05
Valid Loss:  0.00014008567086420953
Epoch:  346  	Training Loss: 0.0001570469030411914
Test Loss:  9.394385415362194e-05
Valid Loss:  0.000139433701406233
Epoch:  347  	Training Loss: 0.00015634422015864402
Test Loss:  9.339537064079195e-05
Valid Loss:  0.00013881760241929442
Epoch:  348  	Training Loss: 0.0001556562929181382
Test Loss:  9.287653665523976e-05
Valid Loss:  0.0001382620830554515
Epoch:  349  	Training Loss: 0.0001550028391648084
Test Loss:  9.238917846232653e-05
Valid Loss:  0.00013773844693787396
Epoch:  350  	Training Loss: 0.00015437783440575004
Test Loss:  9.191683784592897e-05
Valid Loss:  0.00013723110896535218
Epoch:  351  	Training Loss: 0.000153760687680915
Test Loss:  9.146376396529377e-05
Valid Loss:  0.00013674420188181102
Epoch:  352  	Training Loss: 0.00015316643111873418
Test Loss:  9.102584590436891e-05
Valid Loss:  0.00013628549640998244
Epoch:  353  	Training Loss: 0.0001528091379441321
Test Loss:  9.061051969183609e-05
Valid Loss:  0.00013585356646217406
Epoch:  354  	Training Loss: 0.00015246668772306293
Test Loss:  9.021642472362146e-05
Valid Loss:  0.00013544727698899806
Epoch:  355  	Training Loss: 0.0001521371741546318
Test Loss:  8.984166925074533e-05
Valid Loss:  0.0001350638340227306
Epoch:  356  	Training Loss: 0.0001518191274954006
Test Loss:  8.94840486580506e-05
Valid Loss:  0.00013470131671056151
Epoch:  357  	Training Loss: 0.00015151129628065974
Test Loss:  8.914215140976012e-05
Valid Loss:  0.00013435818254947662
Epoch:  358  	Training Loss: 0.00015121244359761477
Test Loss:  8.881479152478278e-05
Valid Loss:  0.00013403160846792161
Epoch:  359  	Training Loss: 0.00015092160901986063
Test Loss:  8.850015001371503e-05
Valid Loss:  0.00013372153625823557
Epoch:  360  	Training Loss: 0.00015063781756907701
Test Loss:  8.81976739037782e-05
Valid Loss:  0.00013342603051569313
Epoch:  361  	Training Loss: 0.00015036051627248526
Test Loss:  8.790603169472888e-05
Valid Loss:  0.00013314349052961916
Epoch:  362  	Training Loss: 0.00015008893387857825
Test Loss:  8.756706665735692e-05
Valid Loss:  0.000132823406602256
Epoch:  363  	Training Loss: 0.00014973625366110355
Test Loss:  8.723316568648443e-05
Valid Loss:  0.00013250860502012074
Epoch:  364  	Training Loss: 0.0001493884774390608
Test Loss:  8.690472168382257e-05
Valid Loss:  0.00013219844549894333
Epoch:  365  	Training Loss: 0.00014904572162777185
Test Loss:  8.658083970658481e-05
Valid Loss:  0.00013189291348680854
Epoch:  366  	Training Loss: 0.0001487075787736103
Test Loss:  8.626169437775388e-05
Valid Loss:  0.00013159250374883413
Epoch:  367  	Training Loss: 0.0001483740343246609
Test Loss:  8.594760583946481e-05
Valid Loss:  0.00013129653234500438
Epoch:  368  	Training Loss: 0.00014804514648858458
Test Loss:  8.563828305341303e-05
Valid Loss:  0.0001310049556195736
Epoch:  369  	Training Loss: 0.00014772085705772042
Test Loss:  8.533369691576809e-05
Valid Loss:  0.00013071791909169406
Epoch:  370  	Training Loss: 0.0001474008458899334
Test Loss:  8.503350545652211e-05
Valid Loss:  0.00013043516082689166
Epoch:  371  	Training Loss: 0.00014708508388139307
Test Loss:  8.473741036141291e-05
Valid Loss:  0.00013015695731155574
Epoch:  372  	Training Loss: 0.00014677370199933648
Test Loss:  8.325940871145576e-05
Valid Loss:  0.0001292633533012122
Epoch:  373  	Training Loss: 0.00014399390784092247
Test Loss:  8.182349120033905e-05
Valid Loss:  0.00012834963854402304
Epoch:  374  	Training Loss: 0.00014129109331406653
Test Loss:  8.037511724978685e-05
Valid Loss:  0.00012737305951304734
Epoch:  375  	Training Loss: 0.00013860122999176383
Test Loss:  7.89815530879423e-05
Valid Loss:  0.00012631542631424963
Epoch:  376  	Training Loss: 0.00013609416782855988
Test Loss:  7.761303277220577e-05
Valid Loss:  0.0001251126523129642
Epoch:  377  	Training Loss: 0.00013364595361053944
Test Loss:  7.626652222825214e-05
Valid Loss:  0.00012389663606882095
Epoch:  378  	Training Loss: 0.00013125651457812637
Test Loss:  7.493203156627715e-05
Valid Loss:  0.00012266120756976306
Epoch:  379  	Training Loss: 0.0001288983621634543
Test Loss:  7.357246795436367e-05
Valid Loss:  0.00012142582272645086
Epoch:  380  	Training Loss: 0.00012662459630519152
Test Loss:  7.21906399121508e-05
Valid Loss:  0.0001201346967718564
Epoch:  381  	Training Loss: 0.0001244211889570579
Test Loss:  7.083137461449951e-05
Valid Loss:  0.00011883171100635082
Epoch:  382  	Training Loss: 0.000122296332847327
Test Loss:  7.048103725537658e-05
Valid Loss:  0.00011835499026346952
Epoch:  383  	Training Loss: 0.00012195901945233345
Test Loss:  7.016348536126316e-05
Valid Loss:  0.00011793035810114816
Epoch:  384  	Training Loss: 0.0001216366799781099
Test Loss:  6.986033986322582e-05
Valid Loss:  0.00011752828868338838
Epoch:  385  	Training Loss: 0.00012131803669035435
Test Loss:  6.957102596061304e-05
Valid Loss:  0.00011714713036781177
Epoch:  386  	Training Loss: 0.00012100531603209674
Test Loss:  6.929325900273398e-05
Valid Loss:  0.0001167833834188059
Epoch:  387  	Training Loss: 0.00012069750664522871
Test Loss:  6.902537279529497e-05
Valid Loss:  0.00011643493780866265
Epoch:  388  	Training Loss: 0.00012039244757033885
Test Loss:  6.876378029119223e-05
Valid Loss:  0.0001160977190011181
Epoch:  389  	Training Loss: 0.00012008646444883198
Test Loss:  6.850772479083389e-05
Valid Loss:  0.00011577118129935116
Epoch:  390  	Training Loss: 0.00011978035763604566
Test Loss:  6.82579557178542e-05
Valid Loss:  0.00011545654706424102
Epoch:  391  	Training Loss: 0.00011947710299864411
Test Loss:  6.801400741096586e-05
Valid Loss:  0.00011515044025145471
Epoch:  392  	Training Loss: 0.00011917619849555194
Test Loss:  6.705821579089388e-05
Valid Loss:  0.00011424660624470562
Epoch:  393  	Training Loss: 0.00011816305050160736
Test Loss:  6.619632040383294e-05
Valid Loss:  0.00011340533819748089
Epoch:  394  	Training Loss: 0.0001172334305010736
Test Loss:  6.5403881308157e-05
Valid Loss:  0.0001126087736338377
Epoch:  395  	Training Loss: 0.00011635004193522036
Test Loss:  6.465238402597606e-05
Valid Loss:  0.00011184994218638167
Epoch:  396  	Training Loss: 0.00011551626812433824
Test Loss:  6.39707432128489e-05
Valid Loss:  0.00011113961227238178
Epoch:  397  	Training Loss: 0.00011473183985799551
Test Loss:  6.335688522085547e-05
Valid Loss:  0.00011046552390325814
Epoch:  398  	Training Loss: 0.00011399232607800514
Test Loss:  6.278090586420149e-05
Valid Loss:  0.00010984964319504797
Epoch:  399  	Training Loss: 0.0001133075202233158
Test Loss:  6.226486584637314e-05
Valid Loss:  0.00010928013944067061
Epoch:  400  	Training Loss: 0.00011265421926509589
Test Loss:  6.177561590448022e-05
Valid Loss:  0.00010873620340134948
Epoch:  401  	Training Loss: 0.00011202757013961673
Test Loss:  6.130327528808266e-05
Valid Loss:  0.00010823256889125332
Epoch:  402  	Training Loss: 0.0001114218175644055
Test Loss:  5.992053775116801e-05
Valid Loss:  0.0001069398713298142
Epoch:  403  	Training Loss: 0.00010880781337618828
Test Loss:  5.8603436627890915e-05
Valid Loss:  0.00010572616884019226
Epoch:  404  	Training Loss: 0.00010646157898008823
Test Loss:  5.731966666644439e-05
Valid Loss:  0.0001045443641487509
Epoch:  405  	Training Loss: 0.00010429473331896588
Test Loss:  5.6040789786493406e-05
Valid Loss:  0.0001033790031215176
 81%|████████▏ | 407/500 [04:57<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:57<00:30,  3.02it/s] 82%|████████▏ | 411/500 [05:03<01:43,  1.16s/it] 83%|████████▎ | 413/500 [05:04<01:12,  1.20it/s] 83%|████████▎ | 415/500 [05:04<00:51,  1.66it/s] 83%|████████▎ | 417/500 [05:04<00:36,  2.26it/s] 84%|████████▍ | 419/500 [05:04<00:26,  3.04it/s] 84%|████████▍ | 421/500 [05:10<01:33,  1.18s/it] 85%|████████▍ | 423/500 [05:10<01:05,  1.18it/s] 85%|████████▌ | 425/500 [05:11<00:45,  1.63it/s] 85%|████████▌ | 427/500 [05:11<00:32,  2.23it/s] 86%|████████▌ | 429/500 [05:11<00:23,  2.98it/s] 86%|████████▌ | 431/500 [05:17<01:22,  1.20s/it] 87%|████████▋ | 433/500 [05:17<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:18<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:18<00:28,  2.20it/s] 88%|████████▊ | 439/500 [05:18<00:20,  2.97it/s] 88%|████████▊ | 441/500 [05:24<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:24<00:48,  1.19it/s] 89%|████████▉ | 445/500 [05:24<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:24<00:23,  2.24it/s] 90%|████████▉ | 449/500 [05:25<00:16,  3.02it/s] 90%|█████████ | 451/500 [05:31<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:31<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:31<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:31<00:19,  2.24it/s] 92%|█████████▏| 459/500 [05:31<00:13,  2.98it/s] 92%|█████████▏| 461/500 [05:38<00:46,  1.18s/it] 93%|█████████▎| 463/500 [05:38<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:38<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:38<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:38<00:10,  3.00it/s] 94%|█████████▍| 471/500 [05:44<00:33,  1.16s/it] 95%|█████████▍| 473/500 [05:45<00:22,  1.20it/s]Epoch:  406  	Training Loss: 0.00010225956793874502
Test Loss:  5.477332160808146e-05
Valid Loss:  0.00010224104335065931
Epoch:  407  	Training Loss: 0.00010034987644758075
Test Loss:  5.35231338290032e-05
Valid Loss:  0.0001011205167742446
Epoch:  408  	Training Loss: 9.852482617134228e-05
Test Loss:  5.231436080066487e-05
Valid Loss:  0.00010003271017922089
Epoch:  409  	Training Loss: 9.680413495516405e-05
Test Loss:  5.11466059833765e-05
Valid Loss:  9.897044219542295e-05
Epoch:  410  	Training Loss: 9.515984129393473e-05
Test Loss:  5.003988553653471e-05
Valid Loss:  9.793799108592793e-05
Epoch:  411  	Training Loss: 9.358866373077035e-05
Test Loss:  4.8970134230330586e-05
Valid Loss:  9.69357934081927e-05
Epoch:  412  	Training Loss: 9.208361007040367e-05
Test Loss:  4.798592271981761e-05
Valid Loss:  9.59879980655387e-05
Epoch:  413  	Training Loss: 9.075505658984184e-05
Test Loss:  4.7040521167218685e-05
Valid Loss:  9.50760004343465e-05
Epoch:  414  	Training Loss: 8.948340837378055e-05
Test Loss:  4.613343480741605e-05
Valid Loss:  9.420275455340743e-05
Epoch:  415  	Training Loss: 8.826897828839719e-05
Test Loss:  4.527026612777263e-05
Valid Loss:  9.336874063592404e-05
Epoch:  416  	Training Loss: 8.710313704796135e-05
Test Loss:  4.443572470336221e-05
Valid Loss:  9.256128396373242e-05
Epoch:  417  	Training Loss: 8.59831488924101e-05
Test Loss:  4.363925472716801e-05
Valid Loss:  9.179094922728837e-05
Epoch:  418  	Training Loss: 8.491695916745812e-05
Test Loss:  4.2868843593169004e-05
Valid Loss:  9.104319906327873e-05
Epoch:  419  	Training Loss: 8.389333379454911e-05
Test Loss:  4.213150896248408e-05
Valid Loss:  9.032143134390935e-05
Epoch:  420  	Training Loss: 8.290811092592776e-05
Test Loss:  4.142943362239748e-05
Valid Loss:  8.964239532360807e-05
Epoch:  421  	Training Loss: 8.19640772533603e-05
Test Loss:  4.0759234252618626e-05
Valid Loss:  8.901947876438498e-05
Epoch:  422  	Training Loss: 8.106259338092059e-05
Test Loss:  4.02348414354492e-05
Valid Loss:  8.83156608324498e-05
Epoch:  423  	Training Loss: 8.038785017561167e-05
Test Loss:  3.977968663093634e-05
Valid Loss:  8.769211126491427e-05
Epoch:  424  	Training Loss: 7.976105553098023e-05
Test Loss:  3.937532164854929e-05
Valid Loss:  8.714248542673886e-05
Epoch:  425  	Training Loss: 7.916990580270067e-05
Test Loss:  3.899438524967991e-05
Valid Loss:  8.664345659781247e-05
Epoch:  426  	Training Loss: 7.860233017709106e-05
Test Loss:  3.8643462175969034e-05
Valid Loss:  8.617273124400526e-05
Epoch:  427  	Training Loss: 7.805238419678062e-05
Test Loss:  3.830693458439782e-05
Valid Loss:  8.571771468268707e-05
Epoch:  428  	Training Loss: 7.751873636152595e-05
Test Loss:  3.7993897421984e-05
Valid Loss:  8.528187026968226e-05
Epoch:  429  	Training Loss: 7.701106369495392e-05
Test Loss:  3.769889008253813e-05
Valid Loss:  8.486822480335832e-05
Epoch:  430  	Training Loss: 7.65168369980529e-05
Test Loss:  3.74048795492854e-05
Valid Loss:  8.446421998087317e-05
Epoch:  431  	Training Loss: 7.603933772770688e-05
Test Loss:  3.711705721798353e-05
Valid Loss:  8.407283894484863e-05
Epoch:  432  	Training Loss: 7.557302888017148e-05
Test Loss:  3.6880079278489575e-05
Valid Loss:  8.366553811356425e-05
Epoch:  433  	Training Loss: 7.522455416619778e-05
Test Loss:  3.666172779048793e-05
Valid Loss:  8.326840179506689e-05
Epoch:  434  	Training Loss: 7.488847768399864e-05
Test Loss:  3.645831748144701e-05
Valid Loss:  8.288767276098952e-05
Epoch:  435  	Training Loss: 7.456481398548931e-05
Test Loss:  3.626638499554247e-05
Valid Loss:  8.252602856373414e-05
Epoch:  436  	Training Loss: 7.425463991239667e-05
Test Loss:  3.608848055591807e-05
Valid Loss:  8.21786088636145e-05
Epoch:  437  	Training Loss: 7.39540409995243e-05
Test Loss:  3.592230859794654e-05
Valid Loss:  8.184849139070138e-05
Epoch:  438  	Training Loss: 7.366509089479223e-05
Test Loss:  3.576548624550924e-05
Valid Loss:  8.153545786626637e-05
Epoch:  439  	Training Loss: 7.338742580031976e-05
Test Loss:  3.561750054359436e-05
Valid Loss:  8.123315637931228e-05
Epoch:  440  	Training Loss: 7.311810622923076e-05
Test Loss:  3.547775122569874e-05
Valid Loss:  8.09433258837089e-05
Epoch:  441  	Training Loss: 7.28575250832364e-05
Test Loss:  3.5344059142516926e-05
Valid Loss:  8.066261216299608e-05
Epoch:  442  	Training Loss: 7.260324491653591e-05
Test Loss:  3.520706377457827e-05
Valid Loss:  8.065110887400806e-05
Epoch:  443  	Training Loss: 7.243415166158229e-05
Test Loss:  3.51084818248637e-05
Valid Loss:  8.06227617431432e-05
Epoch:  444  	Training Loss: 7.230982009787112e-05
Test Loss:  3.504069900372997e-05
Valid Loss:  8.057466766331345e-05
Epoch:  445  	Training Loss: 7.2216906119138e-05
Test Loss:  3.497445868561044e-05
Valid Loss:  8.051800250541419e-05
Epoch:  446  	Training Loss: 7.213413482531905e-05
Test Loss:  3.491119059617631e-05
Valid Loss:  8.045809954637662e-05
Epoch:  447  	Training Loss: 7.205609290394932e-05
Test Loss:  3.485346678644419e-05
Valid Loss:  8.039260865189135e-05
Epoch:  448  	Training Loss: 7.198353705462068e-05
Test Loss:  3.479341103229672e-05
Valid Loss:  8.032357436604798e-05
Epoch:  449  	Training Loss: 7.191740587586537e-05
Test Loss:  3.473474134807475e-05
Valid Loss:  8.025623537832871e-05
Epoch:  450  	Training Loss: 7.185425783973187e-05
Test Loss:  3.467521310085431e-05
Valid Loss:  8.018734661163762e-05
Epoch:  451  	Training Loss: 7.179444946814328e-05
Test Loss:  3.461724554654211e-05
Valid Loss:  8.012026955839247e-05
Epoch:  452  	Training Loss: 7.173549965955317e-05
Test Loss:  3.4533339203335345e-05
Valid Loss:  7.999686931725591e-05
Epoch:  453  	Training Loss: 7.15728965587914e-05
Test Loss:  3.444345929892734e-05
Valid Loss:  7.987070421222597e-05
Epoch:  454  	Training Loss: 7.141300739021972e-05
Test Loss:  3.434753307374194e-05
Valid Loss:  7.973915489856154e-05
Epoch:  455  	Training Loss: 7.12576656951569e-05
Test Loss:  3.424960232223384e-05
Valid Loss:  7.960850780364126e-05
Epoch:  456  	Training Loss: 7.110722071956843e-05
Test Loss:  3.4155105822719634e-05
Valid Loss:  7.948313577799127e-05
Epoch:  457  	Training Loss: 7.096091576386243e-05
Test Loss:  3.406120231375098e-05
Valid Loss:  7.935612666187808e-05
Epoch:  458  	Training Loss: 7.08201332599856e-05
Test Loss:  3.396982720005326e-05
Valid Loss:  7.923332304926589e-05
Epoch:  459  	Training Loss: 7.06806022208184e-05
Test Loss:  3.3882177376654e-05
Valid Loss:  7.911265129223466e-05
Epoch:  460  	Training Loss: 7.054251909721643e-05
Test Loss:  3.379932604730129e-05
Valid Loss:  7.899417687440291e-05
Epoch:  461  	Training Loss: 7.04064586898312e-05
Test Loss:  3.371929415152408e-05
Valid Loss:  7.887856918387115e-05
Epoch:  462  	Training Loss: 7.027386163827032e-05
Test Loss:  3.3616728615015745e-05
Valid Loss:  7.879926124587655e-05
Epoch:  463  	Training Loss: 7.013457070570439e-05
Test Loss:  3.351407212903723e-05
Valid Loss:  7.871491834521294e-05
Epoch:  464  	Training Loss: 7.000230834819376e-05
Test Loss:  3.34153555741068e-05
Valid Loss:  7.862960046622902e-05
Epoch:  465  	Training Loss: 6.987251981627196e-05
Test Loss:  3.3316777262371033e-05
Valid Loss:  7.85442825872451e-05
Epoch:  466  	Training Loss: 6.974535062909126e-05
Test Loss:  3.3215852454304695e-05
Valid Loss:  7.8455479524564e-05
Epoch:  467  	Training Loss: 6.962275801924989e-05
Test Loss:  3.3116630220320076e-05
Valid Loss:  7.836804434191436e-05
Epoch:  468  	Training Loss: 6.950206443434581e-05
Test Loss:  3.3016734960256144e-05
Valid Loss:  7.827900117263198e-05
Epoch:  469  	Training Loss: 6.938505975995213e-05
Test Loss:  3.291930988780223e-05
Valid Loss:  7.819155871402472e-05
Epoch:  470  	Training Loss: 6.926981586730108e-05
Test Loss:  3.2824344089021906e-05
Valid Loss:  7.81054695835337e-05
Epoch:  471  	Training Loss: 6.915575067978352e-05
Test Loss:  3.2731128158047795e-05
Valid Loss:  7.802087930031121e-05
Epoch:  472  	Training Loss: 6.904323527123779e-05
Test Loss:  3.2476906199008226e-05
Valid Loss:  7.752761302981526e-05
Epoch:  473  	Training Loss: 6.837162072770298e-05
Test Loss:  3.2235646358458325e-05
Valid Loss:  7.708382327109575e-05
 95%|█████████▌| 475/500 [05:45<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:45<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:45<00:06,  3.00it/s] 96%|█████████▌| 481/500 [05:51<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:51<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:51<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:52<00:05,  2.25it/s] 98%|█████████▊| 489/500 [05:52<00:03,  3.03it/s] 98%|█████████▊| 491/500 [05:58<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:58<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:58<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:58<00:01,  2.23it/s]100%|█████████▉| 499/500 [05:59<00:00,  2.99it/s]100%|██████████| 500/500 [05:59<00:00,  1.39it/s]
Epoch:  474  	Training Loss: 6.77494244882837e-05
Test Loss:  3.200566425221041e-05
Valid Loss:  7.667334284633398e-05
Epoch:  475  	Training Loss: 6.717047654092312e-05
Test Loss:  3.178323822794482e-05
Valid Loss:  7.62823037803173e-05
Epoch:  476  	Training Loss: 6.662975647486746e-05
Test Loss:  3.1572682928526774e-05
Valid Loss:  7.590861059725285e-05
Epoch:  477  	Training Loss: 6.612317520193756e-05
Test Loss:  3.137217936455272e-05
Valid Loss:  7.554787589469925e-05
Epoch:  478  	Training Loss: 6.564032810274512e-05
Test Loss:  3.11751791741699e-05
Valid Loss:  7.519879727624357e-05
Epoch:  479  	Training Loss: 6.517951260320842e-05
Test Loss:  3.098026354564354e-05
Valid Loss:  7.487105904147029e-05
Epoch:  480  	Training Loss: 6.473629036918283e-05
Test Loss:  3.0788753065280616e-05
Valid Loss:  7.45535216992721e-05
Epoch:  481  	Training Loss: 6.43125458736904e-05
Test Loss:  3.0599316232837737e-05
Valid Loss:  7.424376963172108e-05
Epoch:  482  	Training Loss: 6.390178168658167e-05
Test Loss:  3.0447237804764882e-05
Valid Loss:  7.400407048407942e-05
Epoch:  483  	Training Loss: 6.364426371874288e-05
Test Loss:  3.029978324775584e-05
Valid Loss:  7.376866415143013e-05
Epoch:  484  	Training Loss: 6.339215906336904e-05
Test Loss:  3.0157101718941703e-05
Valid Loss:  7.353865657933056e-05
Epoch:  485  	Training Loss: 6.314528582151979e-05
Test Loss:  3.0018847610335797e-05
Valid Loss:  7.331308734137565e-05
Epoch:  486  	Training Loss: 6.29035203019157e-05
Test Loss:  2.9885139156249352e-05
Valid Loss:  7.309217471629381e-05
Epoch:  487  	Training Loss: 6.266686978051439e-05
Test Loss:  2.9755714422208257e-05
Valid Loss:  7.287556218216196e-05
Epoch:  488  	Training Loss: 6.243507232284173e-05
Test Loss:  2.9630398785229772e-05
Valid Loss:  7.266367174452171e-05
Epoch:  489  	Training Loss: 6.220980867510661e-05
Test Loss:  2.9511156753869727e-05
Valid Loss:  7.245736196637154e-05
Epoch:  490  	Training Loss: 6.19920901954174e-05
Test Loss:  2.9395698220469058e-05
Valid Loss:  7.225571607705206e-05
Epoch:  491  	Training Loss: 6.177916657179594e-05
Test Loss:  2.9285916752996854e-05
Valid Loss:  7.205954170785844e-05
Epoch:  492  	Training Loss: 6.157442112453282e-05
Test Loss:  2.9061826353427023e-05
Valid Loss:  7.189333700807765e-05
Epoch:  493  	Training Loss: 6.141645280877128e-05
Test Loss:  2.887176742660813e-05
Valid Loss:  7.174766506068408e-05
Epoch:  494  	Training Loss: 6.127048982307315e-05
Test Loss:  2.870862590498291e-05
Valid Loss:  7.161733810789883e-05
Epoch:  495  	Training Loss: 6.11322684562765e-05
Test Loss:  2.8564903914229944e-05
Valid Loss:  7.14976922608912e-05
Epoch:  496  	Training Loss: 6.099917663959786e-05
Test Loss:  2.843840411514975e-05
Valid Loss:  7.138768705772236e-05
Epoch:  497  	Training Loss: 6.08717164141126e-05
Test Loss:  2.832467362168245e-05
Valid Loss:  7.128503057174385e-05
Epoch:  498  	Training Loss: 6.0747843235731125e-05
Test Loss:  2.8222118999110535e-05
Valid Loss:  7.118853682186455e-05
Epoch:  499  	Training Loss: 6.0627757193287835e-05
Test Loss:  2.8127888072049245e-05
Valid Loss:  7.109626312740147e-05
Epoch:  500  	Training Loss: 6.050957381376065e-05
Test Loss:  2.8041091354680248e-05
Valid Loss:  7.100741640897468e-05
seed is  20
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.21it/s]  1%|          | 4/500 [00:00<00:29, 16.54it/s]  1%|          | 6/500 [00:00<00:29, 16.71it/s]  2%|▏         | 8/500 [00:00<00:29, 16.79it/s]  2%|▏         | 10/500 [00:00<00:29, 16.79it/s]  2%|▏         | 12/500 [00:00<00:29, 16.79it/s]  3%|▎         | 14/500 [00:00<00:28, 16.77it/s]  3%|▎         | 16/500 [00:00<00:31, 15.31it/s]  4%|▎         | 18/500 [00:01<00:30, 15.67it/s]  4%|▍         | 20/500 [00:01<00:30, 15.96it/s]  4%|▍         | 22/500 [00:01<00:29, 16.25it/s]  5%|▍         | 24/500 [00:01<00:28, 16.45it/s]  5%|▌         | 26/500 [00:01<00:28, 16.49it/s]  6%|▌         | 28/500 [00:01<00:28, 16.52it/s]  6%|▌         | 30/500 [00:01<00:28, 16.65it/s]  6%|▋         | 32/500 [00:01<00:28, 16.71it/s]  7%|▋         | 34/500 [00:02<00:27, 16.73it/s]  7%|▋         | 36/500 [00:02<00:27, 16.76it/s]  8%|▊         | 38/500 [00:02<00:27, 16.80it/s]  8%|▊         | 40/500 [00:02<00:27, 16.84it/s]  8%|▊         | 42/500 [00:02<00:27, 16.75it/s]  9%|▉         | 44/500 [00:02<00:27, 16.80it/s]  9%|▉         | 46/500 [00:02<00:27, 16.81it/s] 10%|▉         | 48/500 [00:02<00:27, 16.68it/s] 10%|█         | 50/500 [00:03<00:27, 16.49it/s] 10%|█         | 52/500 [00:03<00:27, 16.43it/s] 11%|█         | 54/500 [00:03<00:26, 16.52it/s] 11%|█         | 56/500 [00:03<00:26, 16.62it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.49it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.47it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.60it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.62it/s] 13%|█▎        | 66/500 [00:03<00:26, 16.61it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.45it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.45it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.46it/s] 15%|█▍        | 74/500 [00:04<00:25, 16.48it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.35it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.14it/s] 16%|█▌        | 80/500 [00:04<00:27, 15.55it/s] 16%|█▋        | 82/500 [00:05<00:29, 14.37it/s] 17%|█▋        | 84/500 [00:05<00:30, 13.56it/s] 17%|█▋        | 86/500 [00:05<00:29, 14.19it/s] 18%|█▊        | 88/500 [00:05<00:27, 14.80it/s] 18%|█▊        | 90/500 [00:05<00:27, 14.66it/s] 18%|█▊        | 92/500 [00:05<00:28, 14.37it/s] 19%|█▉        | 94/500 [00:05<00:29, 13.62it/s] 19%|█▉        | 96/500 [00:06<00:30, 13.25it/s] 20%|█▉        | 98/500 [00:06<00:31, 12.92it/s] 20%|██        | 100/500 [00:06<00:31, 12.75it/s] 20%|██        | 102/500 [00:06<00:30, 13.23it/s] 21%|██        | 104/500 [00:06<00:28, 14.14it/s] 21%|██        | 106/500 [00:06<00:26, 14.79it/s] 22%|██▏       | 108/500 [00:06<00:25, 15.26it/s] 22%|██▏       | 110/500 [00:07<00:25, 15.50it/s] 22%|██▏       | 112/500 [00:07<00:24, 15.86it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.14it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.30it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.46it/s] 24%|██▍       | 120/500 [00:07<00:22, 16.56it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.59it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.67it/s]Epoch:  1  	Training Loss: 0.1977379322052002
Test Loss:  3175.4150390625
Valid Loss:  3175.52099609375
Epoch:  2  	Training Loss: 3180.53857421875
Test Loss:  12422373965824.0
Valid Loss:  12428102336512.0
Epoch:  3  	Training Loss: 12459541790720.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.62it/s] 26%|██▌       | 128/500 [00:08<00:22, 16.66it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.68it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.47it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.57it/s] 27%|██▋       | 136/500 [00:08<00:21, 16.66it/s] 28%|██▊       | 138/500 [00:08<00:21, 16.71it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.76it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.77it/s] 29%|██▉       | 144/500 [00:09<00:21, 16.79it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.76it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.75it/s] 30%|███       | 150/500 [00:09<00:21, 16.59it/s] 30%|███       | 152/500 [00:09<00:21, 16.39it/s] 31%|███       | 154/500 [00:09<00:21, 16.37it/s] 31%|███       | 156/500 [00:09<00:21, 16.24it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.31it/s] 32%|███▏      | 160/500 [00:10<00:20, 16.42it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.37it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.41it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.54it/s] 34%|███▎      | 168/500 [00:10<00:19, 16.65it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.48it/s] 34%|███▍      | 172/500 [00:10<00:19, 16.44it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.41it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.24it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.34it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.27it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.35it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.48it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.53it/s] 38%|███▊      | 188/500 [00:11<00:18, 16.46it/s] 38%|███▊      | 190/500 [00:11<00:19, 16.31it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.23it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.37it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.40it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.53it/s] 40%|████      | 200/500 [00:12<00:18, 16.45it/s] 40%|████      | 202/500 [00:12<00:18, 16.55it/s] 41%|████      | 204/500 [00:12<00:17, 16.54it/s] 41%|████      | 206/500 [00:12<00:17, 16.63it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.57it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.60it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.56it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.41it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.56it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.58it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.37it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.50it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.57it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.50it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.43it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.47it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.57it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.55it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.38it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.51it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.59it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.67it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.72it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.72it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.76it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:14, 16.74it/s] 50%|█████     | 252/500 [00:15<00:14, 16.73it/s] 51%|█████     | 254/500 [00:15<00:14, 16.78it/s] 51%|█████     | 256/500 [00:15<00:14, 16.72it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.55it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.49it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.61it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.51it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.59it/s] 54%|█████▎    | 268/500 [00:16<00:13, 16.64it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.42it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.37it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.24it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.23it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.32it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.51it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.58it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.56it/s] 57%|█████▋    | 286/500 [00:17<00:12, 16.52it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.62it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.60it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.52it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.47it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.42it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.49it/s] 60%|██████    | 300/500 [00:18<00:12, 16.60it/s] 60%|██████    | 302/500 [00:18<00:11, 16.50it/s] 61%|██████    | 304/500 [00:18<00:11, 16.54it/s] 61%|██████    | 306/500 [00:18<00:11, 16.58it/s] 62%|██████▏   | 308/500 [00:18<00:11, 16.65it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.54it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.64it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.58it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.50it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.28it/s] 64%|██████▍   | 320/500 [00:19<00:10, 16.39it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.50it/s] 65%|██████▍   | 324/500 [00:19<00:10, 16.47it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.61it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.71it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.79it/s] 66%|██████▋   | 332/500 [00:20<00:09, 16.81it/s] 67%|██████▋   | 334/500 [00:20<00:09, 16.72it/s] 67%|██████▋   | 336/500 [00:20<00:09, 16.75it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.79it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.82it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.75it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.74it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.75it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.76it/s] 70%|███████   | 350/500 [00:21<00:08, 16.76it/s] 70%|███████   | 352/500 [00:21<00:08, 16.54it/s] 71%|███████   | 354/500 [00:21<00:08, 16.58it/s] 71%|███████   | 356/500 [00:21<00:08, 16.66it/s] 72%|███████▏  | 358/500 [00:21<00:08, 16.67it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.71it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.72it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.50it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.19it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.37it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.50it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.57it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:22<00:07, 16.61it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.52it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.44it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.53it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.46it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.39it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.34it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.36it/s] 78%|███████▊  | 390/500 [00:23<00:06, 16.47it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.54it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.63it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.60it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.68it/s] 80%|████████  | 400/500 [00:24<00:06, 16.62it/s] 80%|████████  | 402/500 [00:24<00:05, 16.52it/s] 81%|████████  | 404/500 [00:24<00:05, 16.40it/s] 81%|████████  | 406/500 [00:24<00:05, 16.31it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.26it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.12it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.33it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.52it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.64it/s] 84%|████████▎ | 418/500 [00:25<00:04, 16.68it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.73it/s] 84%|████████▍ | 422/500 [00:25<00:04, 16.51it/s] 85%|████████▍ | 424/500 [00:25<00:04, 16.39it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.49it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.43it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.54it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.61it/s] 87%|████████▋ | 434/500 [00:26<00:03, 16.64it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.68it/s] 88%|████████▊ | 438/500 [00:26<00:03, 16.52it/s] 88%|████████▊ | 440/500 [00:26<00:03, 16.57it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.62it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.58it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.53it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.46it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.57it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.65it/s] 91%|█████████ | 454/500 [00:27<00:02, 16.67it/s] 91%|█████████ | 456/500 [00:27<00:02, 16.71it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.36it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.50it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.60it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.70it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.73it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.78it/s] 94%|█████████▍| 470/500 [00:28<00:01, 16.74it/s] 94%|█████████▍| 472/500 [00:28<00:01, 16.60it/s] 95%|█████████▍| 474/500 [00:28<00:01, 16.64it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.63it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.67it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.72it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.79it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.74it/s] 97%|█████████▋| 486/500 [00:29<00:00, 16.73it/s] 98%|█████████▊| 488/500 [00:29<00:00, 16.63it/s] 98%|█████████▊| 490/500 [00:29<00:00, 16.59it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.54it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.66it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.73it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.72it/s]100%|██████████| 500/500 [00:30<00:00, 16.61it/s]100%|██████████| 500/500 [00:30<00:00, 16.36it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  20
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:18,  6.17s/it]  1%|          | 3/500 [00:06<13:40,  1.65s/it]  1%|          | 5/500 [00:06<06:53,  1.20it/s]  1%|▏         | 7/500 [00:06<04:10,  1.97it/s]  2%|▏         | 9/500 [00:06<02:47,  2.93it/s]  2%|▏         | 11/500 [00:13<10:52,  1.33s/it]  3%|▎         | 13/500 [00:13<07:24,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.56it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:43,  2.94it/s]  4%|▍         | 21/500 [00:19<09:31,  1.19s/it]  5%|▍         | 23/500 [00:19<06:46,  1.17it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:31,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.01it/s]  6%|▌         | 31/500 [00:26<09:03,  1.16s/it]  7%|▋         | 33/500 [00:26<06:28,  1.20it/s]  7%|▋         | 35/500 [00:26<04:39,  1.66it/s]  7%|▋         | 37/500 [00:26<03:23,  2.27it/s]  8%|▊         | 39/500 [00:27<02:30,  3.06it/s]  8%|▊         | 41/500 [00:33<08:50,  1.16s/it]  9%|▊         | 43/500 [00:33<06:19,  1.20it/s]  9%|▉         | 45/500 [00:33<04:33,  1.66it/s]  9%|▉         | 47/500 [00:33<03:19,  2.27it/s] 10%|▉         | 49/500 [00:33<02:27,  3.06it/s] 10%|█         | 51/500 [00:40<08:46,  1.17s/it] 11%|█         | 53/500 [00:40<06:16,  1.19it/s] 11%|█         | 55/500 [00:40<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.24it/s] 12%|█▏        | 59/500 [00:40<02:26,  3.01it/s] 12%|█▏        | 61/500 [00:46<08:39,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:11,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:26,  1.63it/s] 13%|█▎        | 67/500 [00:47<03:14,  2.23it/s] 14%|█▍        | 69/500 [00:47<02:24,  2.99it/s] 14%|█▍        | 71/500 [00:53<08:21,  1.17s/it] 15%|█▍        | 73/500 [00:53<05:58,  1.19it/s]Epoch:  1  	Training Loss: 0.1977379322052002
Test Loss:  349.9269104003906
Valid Loss:  350.7793884277344
Epoch:  2  	Training Loss: 348.685546875
Test Loss:  0.9255090951919556
Valid Loss:  0.9359667301177979
Epoch:  3  	Training Loss: 0.8680872321128845
Test Loss:  0.8376611471176147
Valid Loss:  0.8473600149154663
Epoch:  4  	Training Loss: 0.7839658260345459
Test Loss:  0.758394181728363
Valid Loss:  0.7673901319503784
Epoch:  5  	Training Loss: 0.7081713080406189
Test Loss:  0.6868552565574646
Valid Loss:  0.6951999068260193
Epoch:  6  	Training Loss: 0.6398699283599854
Test Loss:  0.6222782731056213
Valid Loss:  0.630018949508667
Epoch:  7  	Training Loss: 0.578312873840332
Test Loss:  0.5639742016792297
Valid Loss:  0.5711545944213867
Epoch:  8  	Training Loss: 0.5228272080421448
Test Loss:  0.5113237500190735
Valid Loss:  0.5179839134216309
Epoch:  9  	Training Loss: 0.4728081226348877
Test Loss:  0.4637693166732788
Valid Loss:  0.4699465036392212
Epoch:  10  	Training Loss: 0.4277116656303406
Test Loss:  0.4208095967769623
Valid Loss:  0.4265379011631012
Epoch:  11  	Training Loss: 0.3870489299297333
Test Loss:  0.3819931745529175
Valid Loss:  0.3873041868209839
Epoch:  12  	Training Loss: 0.35037994384765625
Test Loss:  0.35370662808418274
Valid Loss:  0.35868769884109497
Epoch:  13  	Training Loss: 0.3240088224411011
Test Loss:  0.32755357027053833
Valid Loss:  0.3322256803512573
Epoch:  14  	Training Loss: 0.29965198040008545
Test Loss:  0.30337297916412354
Valid Loss:  0.30775564908981323
Epoch:  15  	Training Loss: 0.27715617418289185
Test Loss:  0.2810157537460327
Valid Loss:  0.2851272523403168
Epoch:  16  	Training Loss: 0.25637972354888916
Test Loss:  0.2603442966938019
Valid Loss:  0.2642016112804413
Epoch:  17  	Training Loss: 0.23719167709350586
Test Loss:  0.2412310242652893
Valid Loss:  0.2448500394821167
Epoch:  18  	Training Loss: 0.21947094798088074
Test Loss:  0.22355817258358002
Valid Loss:  0.22695378959178925
Epoch:  19  	Training Loss: 0.2031056433916092
Test Loss:  0.20721682906150818
Valid Loss:  0.2104029357433319
Epoch:  20  	Training Loss: 0.18799236416816711
Test Loss:  0.1921061873435974
Valid Loss:  0.1950957477092743
Epoch:  21  	Training Loss: 0.17403544485569
Test Loss:  0.17813321948051453
Valid Loss:  0.18093836307525635
Epoch:  22  	Training Loss: 0.1611466407775879
Test Loss:  0.16459782421588898
Valid Loss:  0.1672222763299942
Epoch:  23  	Training Loss: 0.14864784479141235
Test Loss:  0.15213583409786224
Valid Loss:  0.1545909196138382
Epoch:  24  	Training Loss: 0.13715949654579163
Test Loss:  0.1406613141298294
Valid Loss:  0.14295759797096252
Epoch:  25  	Training Loss: 0.1265997290611267
Test Loss:  0.13009515404701233
Valid Loss:  0.13224253058433533
Epoch:  26  	Training Loss: 0.11689332872629166
Test Loss:  0.12036466598510742
Valid Loss:  0.12237241119146347
Epoch:  27  	Training Loss: 0.10797113180160522
Test Loss:  0.11140301823616028
Valid Loss:  0.11327974498271942
Epoch:  28  	Training Loss: 0.09976959228515625
Test Loss:  0.10314871370792389
Valid Loss:  0.10503236204385757
Epoch:  29  	Training Loss: 0.09235142171382904
Test Loss:  0.09584829211235046
Valid Loss:  0.0979725643992424
Epoch:  30  	Training Loss: 0.08589494228363037
Test Loss:  0.08957928419113159
Valid Loss:  0.09188003838062286
Epoch:  31  	Training Loss: 0.08024269342422485
Test Loss:  0.08453074097633362
Valid Loss:  0.0866052582859993
Epoch:  32  	Training Loss: 0.07540881633758545
Test Loss:  0.08131854236125946
Valid Loss:  0.08298139274120331
Epoch:  33  	Training Loss: 0.07216279208660126
Test Loss:  0.07845640927553177
Valid Loss:  0.07981650531291962
Epoch:  34  	Training Loss: 0.06925526261329651
Test Loss:  0.0759347528219223
Valid Loss:  0.07703529298305511
Epoch:  35  	Training Loss: 0.06663284450769424
Test Loss:  0.07373752444982529
Valid Loss:  0.07457701861858368
Epoch:  36  	Training Loss: 0.06423982977867126
Test Loss:  0.07173498719930649
Valid Loss:  0.07242302596569061
Epoch:  37  	Training Loss: 0.062081288546323776
Test Loss:  0.0698615312576294
Valid Loss:  0.07046299427747726
Epoch:  38  	Training Loss: 0.06014181673526764
Test Loss:  0.06813515722751617
Valid Loss:  0.06871723383665085
Epoch:  39  	Training Loss: 0.05843503773212433
Test Loss:  0.06655874848365784
Valid Loss:  0.06710367649793625
Epoch:  40  	Training Loss: 0.0569019615650177
Test Loss:  0.06509841978549957
Valid Loss:  0.0656505823135376
Epoch:  41  	Training Loss: 0.05550984665751457
Test Loss:  0.06374453008174896
Valid Loss:  0.06427095830440521
Epoch:  42  	Training Loss: 0.0541941374540329
Test Loss:  0.062246955931186676
Valid Loss:  0.06275433301925659
Epoch:  43  	Training Loss: 0.05275719240307808
Test Loss:  0.06088559329509735
Valid Loss:  0.061441570520401
Epoch:  44  	Training Loss: 0.051470883190631866
Test Loss:  0.059640269726514816
Valid Loss:  0.06024416536092758
Epoch:  45  	Training Loss: 0.05029353126883507
Test Loss:  0.05853614956140518
Valid Loss:  0.05920138955116272
Epoch:  46  	Training Loss: 0.049289487302303314
Test Loss:  0.0575212687253952
Valid Loss:  0.05824832618236542
Epoch:  47  	Training Loss: 0.048392925411462784
Test Loss:  0.0565790981054306
Valid Loss:  0.05734545737504959
Epoch:  48  	Training Loss: 0.04756397008895874
Test Loss:  0.055724695324897766
Valid Loss:  0.05648377910256386
Epoch:  49  	Training Loss: 0.046799130737781525
Test Loss:  0.05494401231408119
Valid Loss:  0.05568242818117142
Epoch:  50  	Training Loss: 0.04609300196170807
Test Loss:  0.054192669689655304
Valid Loss:  0.05492495745420456
Epoch:  51  	Training Loss: 0.04541913792490959
Test Loss:  0.05347658321261406
Valid Loss:  0.0542103536427021
Epoch:  52  	Training Loss: 0.04479020833969116
Test Loss:  0.05285653471946716
Valid Loss:  0.05361752212047577
Epoch:  53  	Training Loss: 0.04426448792219162
Test Loss:  0.05236034467816353
Valid Loss:  0.05313432589173317
Epoch:  54  	Training Loss: 0.043814767152071
Test Loss:  0.05197569355368614
Valid Loss:  0.052724748849868774
Epoch:  55  	Training Loss: 0.04343024641275406
Test Loss:  0.05165480077266693
Valid Loss:  0.05236475169658661
Epoch:  56  	Training Loss: 0.0430942103266716
Test Loss:  0.05138571560382843
Valid Loss:  0.05206266790628433
Epoch:  57  	Training Loss: 0.04279965162277222
Test Loss:  0.05115637183189392
Valid Loss:  0.05180890113115311
Epoch:  58  	Training Loss: 0.042538344860076904
Test Loss:  0.05094694718718529
Valid Loss:  0.05159039795398712
Epoch:  59  	Training Loss: 0.042305491864681244
Test Loss:  0.05075783282518387
Valid Loss:  0.05139782279729843
Epoch:  60  	Training Loss: 0.04210707172751427
Test Loss:  0.050591640174388885
Valid Loss:  0.05122481659054756
Epoch:  61  	Training Loss: 0.04193597659468651
Test Loss:  0.050448693335056305
Valid Loss:  0.051067616790533066
Epoch:  62  	Training Loss: 0.04178377985954285
Test Loss:  0.05030546337366104
Valid Loss:  0.050904564559459686
Epoch:  63  	Training Loss: 0.04162824526429176
Test Loss:  0.05017586052417755
Valid Loss:  0.05075196921825409
Epoch:  64  	Training Loss: 0.04148951545357704
Test Loss:  0.05005943775177002
Valid Loss:  0.050619542598724365
Epoch:  65  	Training Loss: 0.04136760160326958
Test Loss:  0.049956634640693665
Valid Loss:  0.05050097033381462
Epoch:  66  	Training Loss: 0.04125778004527092
Test Loss:  0.0498628243803978
Valid Loss:  0.05039508640766144
Epoch:  67  	Training Loss: 0.041163042187690735
Test Loss:  0.04977995902299881
Valid Loss:  0.050301939249038696
Epoch:  68  	Training Loss: 0.04108244180679321
Test Loss:  0.04970346391201019
Valid Loss:  0.05021677166223526
Epoch:  69  	Training Loss: 0.04101073369383812
Test Loss:  0.049631036818027496
Valid Loss:  0.05013790726661682
Epoch:  70  	Training Loss: 0.04094378650188446
Test Loss:  0.049563512206077576
Valid Loss:  0.05006234720349312
Epoch:  71  	Training Loss: 0.040880586951971054
Test Loss:  0.0495038703083992
Valid Loss:  0.04999155551195145
Epoch:  72  	Training Loss: 0.04082438349723816
Test Loss:  0.04945484548807144
Valid Loss:  0.04993373900651932
Epoch:  73  	Training Loss: 0.04077862948179245
Test Loss:  0.04940728843212128
Valid Loss:  0.04987843334674835
 15%|█▌        | 75/500 [00:53<04:18,  1.65it/s] 15%|█▌        | 77/500 [00:54<03:07,  2.25it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.03it/s] 16%|█▌        | 81/500 [01:00<08:08,  1.17s/it] 17%|█▋        | 83/500 [01:00<05:49,  1.19it/s] 17%|█▋        | 85/500 [01:00<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:00<03:03,  2.25it/s] 18%|█▊        | 89/500 [01:01<02:17,  2.98it/s] 18%|█▊        | 91/500 [01:07<07:52,  1.16s/it] 19%|█▊        | 93/500 [01:07<05:38,  1.20it/s] 19%|█▉        | 95/500 [01:07<04:03,  1.66it/s] 19%|█▉        | 97/500 [01:07<02:57,  2.27it/s] 20%|█▉        | 99/500 [01:07<02:11,  3.06it/s] 20%|██        | 101/500 [01:13<07:39,  1.15s/it] 21%|██        | 103/500 [01:14<05:28,  1.21it/s] 21%|██        | 105/500 [01:14<03:56,  1.67it/s] 21%|██▏       | 107/500 [01:14<02:52,  2.28it/s] 22%|██▏       | 109/500 [01:14<02:07,  3.06it/s] 22%|██▏       | 111/500 [01:20<07:33,  1.17s/it] 23%|██▎       | 113/500 [01:20<05:23,  1.19it/s] 23%|██▎       | 115/500 [01:20<03:52,  1.65it/s] 23%|██▎       | 117/500 [01:21<02:49,  2.26it/s] 24%|██▍       | 119/500 [01:21<02:05,  3.04it/s] 24%|██▍       | 121/500 [01:27<07:21,  1.17s/it] 25%|██▍       | 123/500 [01:27<05:15,  1.19it/s] 25%|██▌       | 125/500 [01:27<03:47,  1.65it/s] 25%|██▌       | 127/500 [01:27<02:45,  2.25it/s] 26%|██▌       | 129/500 [01:27<02:02,  3.03it/s] 26%|██▌       | 131/500 [01:34<07:16,  1.18s/it] 27%|██▋       | 133/500 [01:34<05:11,  1.18it/s] 27%|██▋       | 135/500 [01:34<03:44,  1.63it/s] 27%|██▋       | 137/500 [01:34<02:43,  2.22it/s] 28%|██▊       | 139/500 [01:34<02:00,  2.99it/s] 28%|██▊       | 141/500 [01:41<07:02,  1.18s/it] 29%|██▊       | 143/500 [01:41<05:01,  1.18it/s]Epoch:  74  	Training Loss: 0.04073416441679001
Test Loss:  0.04936067759990692
Valid Loss:  0.049824509769678116
Epoch:  75  	Training Loss: 0.040690828114748
Test Loss:  0.04931465536355972
Valid Loss:  0.04977245628833771
Epoch:  76  	Training Loss: 0.04064854979515076
Test Loss:  0.049271270632743835
Valid Loss:  0.04972207546234131
Epoch:  77  	Training Loss: 0.04060883820056915
Test Loss:  0.04922977462410927
Valid Loss:  0.049674633890390396
Epoch:  78  	Training Loss: 0.040570713579654694
Test Loss:  0.04919014871120453
Valid Loss:  0.04962918162345886
Epoch:  79  	Training Loss: 0.040533825755119324
Test Loss:  0.04915175214409828
Valid Loss:  0.04958567023277283
Epoch:  80  	Training Loss: 0.04049770161509514
Test Loss:  0.04911381006240845
Valid Loss:  0.04954379051923752
Epoch:  81  	Training Loss: 0.04046248272061348
Test Loss:  0.04907684773206711
Valid Loss:  0.04950312525033951
Epoch:  82  	Training Loss: 0.04042859375476837
Test Loss:  0.049043118953704834
Valid Loss:  0.04946619272232056
Epoch:  83  	Training Loss: 0.040397778153419495
Test Loss:  0.04901020601391792
Valid Loss:  0.04942958801984787
Epoch:  84  	Training Loss: 0.04036726802587509
Test Loss:  0.048977598547935486
Valid Loss:  0.04939388483762741
Epoch:  85  	Training Loss: 0.04033739119768143
Test Loss:  0.04894585907459259
Valid Loss:  0.04935935139656067
Epoch:  86  	Training Loss: 0.04030875116586685
Test Loss:  0.04891439527273178
Valid Loss:  0.04932602494955063
Epoch:  87  	Training Loss: 0.04028043523430824
Test Loss:  0.04888337105512619
Valid Loss:  0.049293261021375656
Epoch:  88  	Training Loss: 0.04025283455848694
Test Loss:  0.04885329678654671
Valid Loss:  0.049260951578617096
Epoch:  89  	Training Loss: 0.04022594541311264
Test Loss:  0.04882402718067169
Valid Loss:  0.04922938346862793
Epoch:  90  	Training Loss: 0.04019993916153908
Test Loss:  0.04879656806588173
Valid Loss:  0.0491982102394104
Epoch:  91  	Training Loss: 0.040174562484025955
Test Loss:  0.048770226538181305
Valid Loss:  0.04916772618889809
Epoch:  92  	Training Loss: 0.04015019163489342
Test Loss:  0.048744797706604004
Valid Loss:  0.04913802444934845
Epoch:  93  	Training Loss: 0.0401267409324646
Test Loss:  0.048719797283411026
Valid Loss:  0.049108944833278656
Epoch:  94  	Training Loss: 0.04010400176048279
Test Loss:  0.04869535565376282
Valid Loss:  0.04908072203397751
Epoch:  95  	Training Loss: 0.040082067251205444
Test Loss:  0.048671506345272064
Valid Loss:  0.04905262589454651
Epoch:  96  	Training Loss: 0.04006059467792511
Test Loss:  0.048647984862327576
Valid Loss:  0.04902514070272446
Epoch:  97  	Training Loss: 0.04003962129354477
Test Loss:  0.04862464219331741
Valid Loss:  0.048997968435287476
Epoch:  98  	Training Loss: 0.04001913219690323
Test Loss:  0.04860153794288635
Valid Loss:  0.048971209675073624
Epoch:  99  	Training Loss: 0.03999902307987213
Test Loss:  0.04857857897877693
Valid Loss:  0.04894472658634186
Epoch:  100  	Training Loss: 0.039979152381420135
Test Loss:  0.04855578392744064
Valid Loss:  0.048918500542640686
Epoch:  101  	Training Loss: 0.03995951637625694
Test Loss:  0.048533059656620026
Valid Loss:  0.04889260232448578
Epoch:  102  	Training Loss: 0.03993996977806091
Test Loss:  0.0485098622739315
Valid Loss:  0.04886607453227043
Epoch:  103  	Training Loss: 0.03991994634270668
Test Loss:  0.048486754298210144
Valid Loss:  0.04883967339992523
Epoch:  104  	Training Loss: 0.039900150150060654
Test Loss:  0.04846395552158356
Valid Loss:  0.04881379008293152
Epoch:  105  	Training Loss: 0.03988080471754074
Test Loss:  0.0484413281083107
Valid Loss:  0.048788174986839294
Epoch:  106  	Training Loss: 0.039861634373664856
Test Loss:  0.04841877520084381
Valid Loss:  0.04876267537474632
Epoch:  107  	Training Loss: 0.03984253481030464
Test Loss:  0.04839630424976349
Valid Loss:  0.0487372949719429
Epoch:  108  	Training Loss: 0.039823565632104874
Test Loss:  0.048373993486166
Valid Loss:  0.04871237277984619
Epoch:  109  	Training Loss: 0.03980477899312973
Test Loss:  0.048351749777793884
Valid Loss:  0.0486876517534256
Epoch:  110  	Training Loss: 0.03978607431054115
Test Loss:  0.048329584300518036
Valid Loss:  0.04866303503513336
Epoch:  111  	Training Loss: 0.03976747393608093
Test Loss:  0.048307567834854126
Valid Loss:  0.048638634383678436
Epoch:  112  	Training Loss: 0.039749037474393845
Test Loss:  0.04828520119190216
Valid Loss:  0.04861360788345337
Epoch:  113  	Training Loss: 0.039730362594127655
Test Loss:  0.048262953758239746
Valid Loss:  0.048588719218969345
Epoch:  114  	Training Loss: 0.039711810648441315
Test Loss:  0.04824090749025345
Valid Loss:  0.04856445640325546
Epoch:  115  	Training Loss: 0.039693478494882584
Test Loss:  0.04821896553039551
Valid Loss:  0.04854033142328262
Epoch:  116  	Training Loss: 0.03967532515525818
Test Loss:  0.04819754138588905
Valid Loss:  0.0485166534781456
Epoch:  117  	Training Loss: 0.03965749591588974
Test Loss:  0.048176348209381104
Valid Loss:  0.0484934076666832
Epoch:  118  	Training Loss: 0.03964003920555115
Test Loss:  0.048155322670936584
Valid Loss:  0.048470448702573776
Epoch:  119  	Training Loss: 0.03962275758385658
Test Loss:  0.048134367913007736
Valid Loss:  0.048447586596012115
Epoch:  120  	Training Loss: 0.03960553556680679
Test Loss:  0.048113465309143066
Valid Loss:  0.04842480644583702
Epoch:  121  	Training Loss: 0.039588361978530884
Test Loss:  0.04809261113405228
Valid Loss:  0.048402078449726105
Epoch:  122  	Training Loss: 0.039571233093738556
Test Loss:  0.04807153344154358
Valid Loss:  0.048379093408584595
Epoch:  123  	Training Loss: 0.03955394774675369
Test Loss:  0.048050493001937866
Valid Loss:  0.04835617542266846
Epoch:  124  	Training Loss: 0.039536699652671814
Test Loss:  0.048029523342847824
Valid Loss:  0.04833334684371948
Epoch:  125  	Training Loss: 0.039519499987363815
Test Loss:  0.04800860583782196
Valid Loss:  0.048310600221157074
Epoch:  126  	Training Loss: 0.0395023450255394
Test Loss:  0.04798778519034386
Valid Loss:  0.048288024961948395
Epoch:  127  	Training Loss: 0.039485298097133636
Test Loss:  0.047967080026865005
Valid Loss:  0.04826562851667404
Epoch:  128  	Training Loss: 0.03946838527917862
Test Loss:  0.04794654995203018
Valid Loss:  0.04824355989694595
Epoch:  129  	Training Loss: 0.039451587945222855
Test Loss:  0.04792606830596924
Valid Loss:  0.048221562057733536
Epoch:  130  	Training Loss: 0.03943483158946037
Test Loss:  0.04790562018752098
Valid Loss:  0.048199620097875595
Epoch:  131  	Training Loss: 0.039418093860149384
Test Loss:  0.0478852204978466
Valid Loss:  0.04817774146795273
Epoch:  132  	Training Loss: 0.03940138220787048
Test Loss:  0.047865353524684906
Valid Loss:  0.04815641790628433
Epoch:  133  	Training Loss: 0.03938513249158859
Test Loss:  0.04784567281603813
Valid Loss:  0.048135243356227875
Epoch:  134  	Training Loss: 0.03936893120408058
Test Loss:  0.04782615602016449
Valid Loss:  0.04811412841081619
Epoch:  135  	Training Loss: 0.03935279697179794
Test Loss:  0.04780679941177368
Valid Loss:  0.048093296587467194
Epoch:  136  	Training Loss: 0.03933677822351456
Test Loss:  0.0477876290678978
Valid Loss:  0.0480729341506958
Epoch:  137  	Training Loss: 0.039320871233940125
Test Loss:  0.047768477350473404
Valid Loss:  0.048052601516246796
Epoch:  138  	Training Loss: 0.03930496796965599
Test Loss:  0.04774938523769379
Valid Loss:  0.04803238809108734
Epoch:  139  	Training Loss: 0.03928910195827484
Test Loss:  0.04773030802607536
Valid Loss:  0.048012230545282364
Epoch:  140  	Training Loss: 0.03927326202392578
Test Loss:  0.0477113276720047
Valid Loss:  0.04799232631921768
Epoch:  141  	Training Loss: 0.0392574816942215
Test Loss:  0.047692377120256424
Valid Loss:  0.04797246307134628
Epoch:  142  	Training Loss: 0.03924170508980751
Test Loss:  0.04767247661948204
Valid Loss:  0.04795162379741669
Epoch:  143  	Training Loss: 0.03922513499855995
Test Loss:  0.047652579843997955
Valid Loss:  0.047930821776390076
Epoch:  144  	Training Loss: 0.03920857608318329
Test Loss:  0.047632697969675064
Valid Loss:  0.04791003465652466
Epoch:  145  	Training Loss: 0.039192020893096924
Test Loss:   29%|██▉       | 145/500 [01:41<03:37,  1.63it/s] 29%|██▉       | 147/500 [01:41<02:38,  2.23it/s] 30%|██▉       | 149/500 [01:41<01:57,  3.00it/s] 30%|███       | 151/500 [01:47<06:46,  1.17s/it] 31%|███       | 153/500 [01:48<04:50,  1.19it/s] 31%|███       | 155/500 [01:48<03:28,  1.65it/s] 31%|███▏      | 157/500 [01:48<02:32,  2.25it/s] 32%|███▏      | 159/500 [01:48<01:52,  3.02it/s] 32%|███▏      | 161/500 [01:54<06:36,  1.17s/it] 33%|███▎      | 163/500 [01:54<04:43,  1.19it/s] 33%|███▎      | 165/500 [01:54<03:24,  1.64it/s] 33%|███▎      | 167/500 [01:55<02:28,  2.24it/s] 34%|███▍      | 169/500 [01:55<01:49,  3.01it/s] 34%|███▍      | 171/500 [02:01<06:28,  1.18s/it] 35%|███▍      | 173/500 [02:01<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:01<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:01<02:25,  2.21it/s] 36%|███▌      | 179/500 [02:02<01:48,  2.97it/s] 36%|███▌      | 181/500 [02:08<06:12,  1.17s/it] 37%|███▋      | 183/500 [02:08<04:25,  1.19it/s] 37%|███▋      | 185/500 [02:08<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:08<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:08<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:15<06:03,  1.18s/it] 39%|███▊      | 193/500 [02:15<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:15<03:06,  1.64it/s] 39%|███▉      | 197/500 [02:15<02:15,  2.23it/s] 40%|███▉      | 199/500 [02:15<01:40,  3.00it/s] 40%|████      | 201/500 [02:22<05:53,  1.18s/it] 41%|████      | 203/500 [02:22<04:11,  1.18it/s] 41%|████      | 205/500 [02:22<03:00,  1.63it/s] 41%|████▏     | 207/500 [02:22<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:22<01:36,  3.00it/s] 42%|████▏     | 211/500 [02:28<05:40,  1.18s/it] 43%|████▎     | 213/500 [02:28<04:02,  1.18it/s] 43%|████▎     | 215/500 [02:29<02:54,  1.63it/s]0.047612834721803665
Valid Loss:  0.04788929224014282
Epoch:  146  	Training Loss: 0.039175476878881454
Test Loss:  0.04759299010038376
Valid Loss:  0.04786857217550278
Epoch:  147  	Training Loss: 0.03915894031524658
Test Loss:  0.047573160380125046
Valid Loss:  0.04784787446260452
Epoch:  148  	Training Loss: 0.0391424223780632
Test Loss:  0.047553375363349915
Valid Loss:  0.04782729223370552
Epoch:  149  	Training Loss: 0.03912591561675072
Test Loss:  0.047533612698316574
Valid Loss:  0.04780673235654831
Epoch:  150  	Training Loss: 0.039109423756599426
Test Loss:  0.047513850033283234
Valid Loss:  0.047786206007003784
Epoch:  151  	Training Loss: 0.039092935621738434
Test Loss:  0.04749411344528198
Valid Loss:  0.04776570200920105
Epoch:  152  	Training Loss: 0.039076462388038635
Test Loss:  0.047475315630435944
Valid Loss:  0.04774618148803711
Epoch:  153  	Training Loss: 0.039060771465301514
Test Loss:  0.04745654761791229
Valid Loss:  0.04772668331861496
Epoch:  154  	Training Loss: 0.039045095443725586
Test Loss:  0.047437794506549835
Valid Loss:  0.04770722985267639
Epoch:  155  	Training Loss: 0.039029426872730255
Test Loss:  0.04741905629634857
Valid Loss:  0.04768778756260872
Epoch:  156  	Training Loss: 0.039013784378767014
Test Loss:  0.0474003404378891
Valid Loss:  0.04766838252544403
Epoch:  157  	Training Loss: 0.03899814933538437
Test Loss:  0.04738166183233261
Valid Loss:  0.04764901101589203
Epoch:  158  	Training Loss: 0.03898252919316292
Test Loss:  0.04736299067735672
Valid Loss:  0.04762967675924301
Epoch:  159  	Training Loss: 0.03896692395210266
Test Loss:  0.04734434932470322
Valid Loss:  0.04761043190956116
Epoch:  160  	Training Loss: 0.038951318711042404
Test Loss:  0.04732570797204971
Valid Loss:  0.047591134905815125
Epoch:  161  	Training Loss: 0.03893573582172394
Test Loss:  0.04730710759758949
Valid Loss:  0.04757195711135864
Epoch:  162  	Training Loss: 0.03892016410827637
Test Loss:  0.04728853702545166
Valid Loss:  0.04755289852619171
Epoch:  163  	Training Loss: 0.0389045886695385
Test Loss:  0.04726998135447502
Valid Loss:  0.04753386601805687
Epoch:  164  	Training Loss: 0.038889020681381226
Test Loss:  0.04725145921111107
Valid Loss:  0.0475149005651474
Epoch:  165  	Training Loss: 0.03887345269322395
Test Loss:  0.04723292589187622
Valid Loss:  0.04749591648578644
Epoch:  166  	Training Loss: 0.038857899606227875
Test Loss:  0.04721439629793167
Valid Loss:  0.04747693985700607
Epoch:  167  	Training Loss: 0.03884235396981239
Test Loss:  0.047195881605148315
Valid Loss:  0.047457970678806305
Epoch:  168  	Training Loss: 0.03882680833339691
Test Loss:  0.04717741161584854
Valid Loss:  0.04743911325931549
Epoch:  169  	Training Loss: 0.03881128132343292
Test Loss:  0.04715893045067787
Valid Loss:  0.04742018133401871
Epoch:  170  	Training Loss: 0.03879575803875923
Test Loss:  0.047140464186668396
Valid Loss:  0.04740128293633461
Epoch:  171  	Training Loss: 0.03878023475408554
Test Loss:  0.047122009098529816
Valid Loss:  0.0473824068903923
Epoch:  172  	Training Loss: 0.03876473754644394
Test Loss:  0.047103315591812134
Valid Loss:  0.04736330732703209
Epoch:  173  	Training Loss: 0.03874904662370682
Test Loss:  0.047084640711545944
Valid Loss:  0.04734421148896217
Epoch:  174  	Training Loss: 0.0387333519756794
Test Loss:  0.04706597328186035
Valid Loss:  0.047325145453214645
Epoch:  175  	Training Loss: 0.03871767222881317
Test Loss:  0.04704733192920685
Valid Loss:  0.04730609804391861
Epoch:  176  	Training Loss: 0.03870201110839844
Test Loss:  0.04702870920300484
Valid Loss:  0.04728708788752556
Epoch:  177  	Training Loss: 0.0386863574385643
Test Loss:  0.04701010137796402
Valid Loss:  0.0472681000828743
Epoch:  178  	Training Loss: 0.03867071866989136
Test Loss:  0.04699152708053589
Valid Loss:  0.04724913090467453
Epoch:  179  	Training Loss: 0.03865509107708931
Test Loss:  0.04697295278310776
Valid Loss:  0.04723018407821655
Epoch:  180  	Training Loss: 0.03863947093486786
Test Loss:  0.04695439338684082
Valid Loss:  0.047211263328790665
Epoch:  181  	Training Loss: 0.0386238768696785
Test Loss:  0.046935874968767166
Valid Loss:  0.047192368656396866
Epoch:  182  	Training Loss: 0.03860829398036003
Test Loss:  0.0469173863530159
Valid Loss:  0.04717353731393814
Epoch:  183  	Training Loss: 0.03859274089336395
Test Loss:  0.046898916363716125
Valid Loss:  0.047154705971479416
Epoch:  184  	Training Loss: 0.038577206432819366
Test Loss:  0.04688045382499695
Valid Loss:  0.04713590815663338
Epoch:  185  	Training Loss: 0.03856167197227478
Test Loss:  0.04686201363801956
Valid Loss:  0.047117117792367935
Epoch:  186  	Training Loss: 0.03854614868760109
Test Loss:  0.04684358090162277
Valid Loss:  0.04709835350513458
Epoch:  187  	Training Loss: 0.038530632853507996
Test Loss:  0.04682515561580658
Valid Loss:  0.04707961156964302
Epoch:  188  	Training Loss: 0.0385151244699955
Test Loss:  0.04680674523115158
Valid Loss:  0.04706086590886116
Epoch:  189  	Training Loss: 0.0384996235370636
Test Loss:  0.04678835719823837
Valid Loss:  0.047042157500982285
Epoch:  190  	Training Loss: 0.038484133780002594
Test Loss:  0.046769969165325165
Valid Loss:  0.047023456543684006
Epoch:  191  	Training Loss: 0.038468655198812485
Test Loss:  0.04675160348415375
Valid Loss:  0.04700477421283722
Epoch:  192  	Training Loss: 0.03845318406820297
Test Loss:  0.04673440754413605
Valid Loss:  0.04698731750249863
Epoch:  193  	Training Loss: 0.03843867778778076
Test Loss:  0.046717215329408646
Valid Loss:  0.04696986451745033
Epoch:  194  	Training Loss: 0.03842417523264885
Test Loss:  0.04670003801584244
Valid Loss:  0.04695242643356323
Epoch:  195  	Training Loss: 0.038409680128097534
Test Loss:  0.046682871878147125
Valid Loss:  0.04693499580025673
Epoch:  196  	Training Loss: 0.03839518502354622
Test Loss:  0.04666568338871002
Valid Loss:  0.046917516738176346
Epoch:  197  	Training Loss: 0.0383807048201561
Test Loss:  0.0466485470533371
Valid Loss:  0.04690011963248253
Epoch:  198  	Training Loss: 0.03836623951792717
Test Loss:  0.04663136601448059
Valid Loss:  0.04688265919685364
Epoch:  199  	Training Loss: 0.03835175931453705
Test Loss:  0.04661421477794647
Valid Loss:  0.04686521366238594
Epoch:  200  	Training Loss: 0.03833729773759842
Test Loss:  0.04659710079431534
Valid Loss:  0.04684785380959511
Epoch:  201  	Training Loss: 0.03832283616065979
Test Loss:  0.046579960733652115
Valid Loss:  0.046830445528030396
Epoch:  202  	Training Loss: 0.03830838203430176
Test Loss:  0.046561822295188904
Valid Loss:  0.04681200534105301
Epoch:  203  	Training Loss: 0.038293108344078064
Test Loss:  0.04654368758201599
Valid Loss:  0.04679358750581741
Epoch:  204  	Training Loss: 0.03827782720327377
Test Loss:  0.046525560319423676
Valid Loss:  0.04677516594529152
Epoch:  205  	Training Loss: 0.03826255351305008
Test Loss:  0.04650745540857315
Valid Loss:  0.04675678163766861
Epoch:  206  	Training Loss: 0.03824729844927788
Test Loss:  0.04648938775062561
Valid Loss:  0.04673847183585167
Epoch:  207  	Training Loss: 0.038232043385505676
Test Loss:  0.04647131264209747
Valid Loss:  0.046720124781131744
Epoch:  208  	Training Loss: 0.03821680694818497
Test Loss:  0.046453237533569336
Valid Loss:  0.046701788902282715
Epoch:  209  	Training Loss: 0.038201577961444855
Test Loss:  0.046435169875621796
Valid Loss:  0.04668346047401428
Epoch:  210  	Training Loss: 0.038186341524124146
Test Loss:  0.04641711711883545
Valid Loss:  0.04666514694690704
Epoch:  211  	Training Loss: 0.03817112371325493
Test Loss:  0.04639907553792
Valid Loss:  0.0466468520462513
Epoch:  212  	Training Loss: 0.03815590217709541
Test Loss:  0.04638134688138962
Valid Loss:  0.04662887006998062
Epoch:  213  	Training Loss: 0.03814094513654709
Test Loss:  0.04636362940073013
Valid Loss:  0.046610914170742035
Epoch:  214  	Training Loss: 0.03812599927186966
Test Loss:  0.04634593054652214
Valid Loss:  0.04659298434853554
Epoch:  215  	Training Loss: 0.038111068308353424
Test Loss:  0.046328239142894745
Valid Loss:  0.046575065702199936
Epoch:  216  	Training Loss: 0.03809613734483719
Test Loss:  0.04631056264042854
Valid Loss:  0.046557165682315826
 43%|████▎     | 217/500 [02:29<02:08,  2.21it/s] 44%|████▍     | 219/500 [02:29<01:35,  2.95it/s] 44%|████▍     | 221/500 [02:35<05:30,  1.19s/it] 45%|████▍     | 223/500 [02:35<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:36<02:50,  1.62it/s] 45%|████▌     | 227/500 [02:36<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:36<01:30,  2.98it/s] 46%|████▌     | 231/500 [02:42<05:14,  1.17s/it] 47%|████▋     | 233/500 [02:42<03:45,  1.19it/s] 47%|████▋     | 235/500 [02:42<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:42<01:57,  2.25it/s] 48%|████▊     | 239/500 [02:43<01:26,  3.02it/s] 48%|████▊     | 241/500 [02:49<05:03,  1.17s/it] 49%|████▊     | 243/500 [02:49<03:36,  1.19it/s] 49%|████▉     | 245/500 [02:49<02:35,  1.64it/s] 49%|████▉     | 247/500 [02:49<01:54,  2.21it/s] 50%|████▉     | 249/500 [02:49<01:25,  2.93it/s] 50%|█████     | 251/500 [02:56<04:54,  1.18s/it] 51%|█████     | 253/500 [02:56<03:29,  1.18it/s] 51%|█████     | 255/500 [02:56<02:30,  1.63it/s] 51%|█████▏    | 257/500 [02:56<01:48,  2.23it/s] 52%|█████▏    | 259/500 [02:56<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:03<04:39,  1.17s/it] 53%|█████▎    | 263/500 [03:03<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:03<02:22,  1.65it/s] 53%|█████▎    | 267/500 [03:03<01:43,  2.25it/s] 54%|█████▍    | 269/500 [03:03<01:16,  3.03it/s] 54%|█████▍    | 271/500 [03:09<04:31,  1.18s/it] 55%|█████▍    | 273/500 [03:10<03:12,  1.18it/s] 55%|█████▌    | 275/500 [03:10<02:18,  1.62it/s] 55%|█████▌    | 277/500 [03:10<01:40,  2.22it/s] 56%|█████▌    | 279/500 [03:10<01:13,  2.99it/s] 56%|█████▌    | 281/500 [03:16<04:18,  1.18s/it] 57%|█████▋    | 283/500 [03:16<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:16<02:11,  1.63it/s] 57%|█████▋    | 287/500 [03:17<01:35,  2.23it/s]Epoch:  217  	Training Loss: 0.038081228733062744
Test Loss:  0.04629288986325264
Valid Loss:  0.04653926566243172
Epoch:  218  	Training Loss: 0.038066308945417404
Test Loss:  0.04627523571252823
Valid Loss:  0.046521395444869995
Epoch:  219  	Training Loss: 0.038051411509513855
Test Loss:  0.04625759273767471
Valid Loss:  0.04650353640317917
Epoch:  220  	Training Loss: 0.038036517798900604
Test Loss:  0.04623996093869209
Valid Loss:  0.04648569971323013
Epoch:  221  	Training Loss: 0.03802163153886795
Test Loss:  0.046222347766160965
Valid Loss:  0.04646787792444229
Epoch:  222  	Training Loss: 0.03800676017999649
Test Loss:  0.046204306185245514
Valid Loss:  0.04644963890314102
Epoch:  223  	Training Loss: 0.037991538643836975
Test Loss:  0.04618627578020096
Valid Loss:  0.046431392431259155
Epoch:  224  	Training Loss: 0.03797631338238716
Test Loss:  0.046168260276317596
Valid Loss:  0.046413175761699677
Epoch:  225  	Training Loss: 0.037961095571517944
Test Loss:  0.04615025967359543
Valid Loss:  0.04639497399330139
Epoch:  226  	Training Loss: 0.03794589638710022
Test Loss:  0.04613226279616356
Valid Loss:  0.0463767871260643
Epoch:  227  	Training Loss: 0.03793070465326309
Test Loss:  0.04611426964402199
Valid Loss:  0.046358607709407806
Epoch:  228  	Training Loss: 0.037915509194135666
Test Loss:  0.046096302568912506
Valid Loss:  0.0463404506444931
Epoch:  229  	Training Loss: 0.03790033608675003
Test Loss:  0.04607832804322243
Valid Loss:  0.0463222935795784
Epoch:  230  	Training Loss: 0.0378851555287838
Test Loss:  0.046060286462306976
Valid Loss:  0.04630393534898758
Epoch:  231  	Training Loss: 0.03786996752023697
Test Loss:  0.04604226350784302
Valid Loss:  0.046285584568977356
Epoch:  232  	Training Loss: 0.03785479813814163
Test Loss:  0.046024903655052185
Valid Loss:  0.046267956495285034
Epoch:  233  	Training Loss: 0.03784017264842987
Test Loss:  0.046007562428712845
Valid Loss:  0.04625033214688301
Epoch:  234  	Training Loss: 0.0378255620598793
Test Loss:  0.04599028080701828
Valid Loss:  0.04623290151357651
Epoch:  235  	Training Loss: 0.03781094774603844
Test Loss:  0.04597295820713043
Valid Loss:  0.04621531441807747
Epoch:  236  	Training Loss: 0.03779635578393936
Test Loss:  0.04595565423369408
Valid Loss:  0.046197742223739624
Epoch:  237  	Training Loss: 0.037781767547130585
Test Loss:  0.04593835026025772
Valid Loss:  0.04618016630411148
Epoch:  238  	Training Loss: 0.037767186760902405
Test Loss:  0.045921072363853455
Valid Loss:  0.04616262763738632
Epoch:  239  	Training Loss: 0.03775261342525482
Test Loss:  0.04590379446744919
Valid Loss:  0.046145081520080566
Epoch:  240  	Training Loss: 0.037738047540187836
Test Loss:  0.04588652029633522
Valid Loss:  0.04612758010625839
Epoch:  241  	Training Loss: 0.03772348910570145
Test Loss:  0.04586927592754364
Valid Loss:  0.04611007124185562
Epoch:  242  	Training Loss: 0.03770893067121506
Test Loss:  0.045852065086364746
Valid Loss:  0.04609263688325882
Epoch:  243  	Training Loss: 0.037694431841373444
Test Loss:  0.04583487659692764
Valid Loss:  0.046075206249952316
Epoch:  244  	Training Loss: 0.03767992928624153
Test Loss:  0.04581770300865173
Valid Loss:  0.046057794243097305
Epoch:  245  	Training Loss: 0.03766544163227081
Test Loss:  0.04580055922269821
Valid Loss:  0.046040404587984085
Epoch:  246  	Training Loss: 0.03765096515417099
Test Loss:  0.0457833856344223
Valid Loss:  0.04602302610874176
Epoch:  247  	Training Loss: 0.037636496126651764
Test Loss:  0.04576624184846878
Valid Loss:  0.046005673706531525
Epoch:  248  	Training Loss: 0.037622030824422836
Test Loss:  0.04574912041425705
Valid Loss:  0.045988328754901886
Epoch:  249  	Training Loss: 0.0376075804233551
Test Loss:  0.04573199525475502
Valid Loss:  0.045970991253852844
Epoch:  250  	Training Loss: 0.03759312629699707
Test Loss:  0.045714884996414185
Valid Loss:  0.045953672379255295
Epoch:  251  	Training Loss: 0.03757868707180023
Test Loss:  0.04569780454039574
Valid Loss:  0.04593639075756073
Epoch:  252  	Training Loss: 0.03756426274776459
Test Loss:  0.045680414885282516
Valid Loss:  0.045918792486190796
Epoch:  253  	Training Loss: 0.037549592554569244
Test Loss:  0.045663051307201385
Valid Loss:  0.04590122401714325
Epoch:  254  	Training Loss: 0.0375349335372448
Test Loss:  0.04564569145441055
Valid Loss:  0.045883651822805405
Epoch:  255  	Training Loss: 0.03752027451992035
Test Loss:  0.04562831670045853
Valid Loss:  0.045866113156080246
Epoch:  256  	Training Loss: 0.0375056192278862
Test Loss:  0.045610975474119186
Valid Loss:  0.045848578214645386
Epoch:  257  	Training Loss: 0.03749097138643265
Test Loss:  0.04559364169836044
Valid Loss:  0.04583105444908142
Epoch:  258  	Training Loss: 0.03747634217143059
Test Loss:  0.045576296746730804
Valid Loss:  0.04581347852945328
Epoch:  259  	Training Loss: 0.03746171295642853
Test Loss:  0.045558951795101166
Valid Loss:  0.04579590633511543
Epoch:  260  	Training Loss: 0.03744708001613617
Test Loss:  0.045541614294052124
Valid Loss:  0.04577835649251938
Epoch:  261  	Training Loss: 0.037432461977005005
Test Loss:  0.04552429914474487
Valid Loss:  0.04576081037521362
Epoch:  262  	Training Loss: 0.03741785138845444
Test Loss:  0.045507509261369705
Valid Loss:  0.04574382305145264
Epoch:  263  	Training Loss: 0.03740368038415909
Test Loss:  0.045490752905607224
Valid Loss:  0.045726872980594635
Epoch:  264  	Training Loss: 0.03738952800631523
Test Loss:  0.04547399282455444
Valid Loss:  0.04570990800857544
Epoch:  265  	Training Loss: 0.03737538307905197
Test Loss:  0.04545724764466286
Valid Loss:  0.045692987740039825
Epoch:  266  	Training Loss: 0.03736124187707901
Test Loss:  0.04544050991535187
Valid Loss:  0.045676056295633316
Epoch:  267  	Training Loss: 0.03734710440039635
Test Loss:  0.04542378708720207
Valid Loss:  0.04565916582942009
Epoch:  268  	Training Loss: 0.03733298182487488
Test Loss:  0.04540707916021347
Valid Loss:  0.04564227908849716
Epoch:  269  	Training Loss: 0.037318866699934006
Test Loss:  0.04539036750793457
Valid Loss:  0.045625410974025726
Epoch:  270  	Training Loss: 0.03730475902557373
Test Loss:  0.04537368565797806
Valid Loss:  0.04560854658484459
Epoch:  271  	Training Loss: 0.037290655076503754
Test Loss:  0.045357007533311844
Valid Loss:  0.04559170454740524
Epoch:  272  	Training Loss: 0.03727656230330467
Test Loss:  0.04533981531858444
Valid Loss:  0.04557432606816292
Epoch:  273  	Training Loss: 0.03726205229759216
Test Loss:  0.04532264173030853
Valid Loss:  0.04555698111653328
Epoch:  274  	Training Loss: 0.03724755346775055
Test Loss:  0.04530548304319382
Valid Loss:  0.04553965851664543
Epoch:  275  	Training Loss: 0.037233058363199234
Test Loss:  0.045288316905498505
Valid Loss:  0.04552232846617699
Epoch:  276  	Training Loss: 0.037218570709228516
Test Loss:  0.045271169394254684
Valid Loss:  0.045505017042160034
Epoch:  277  	Training Loss: 0.0372040793299675
Test Loss:  0.045254047960042953
Valid Loss:  0.04548773169517517
Epoch:  278  	Training Loss: 0.03718961030244827
Test Loss:  0.04523691534996033
Valid Loss:  0.045470453798770905
Epoch:  279  	Training Loss: 0.03717515245079994
Test Loss:  0.04521980881690979
Valid Loss:  0.04545317962765694
Epoch:  280  	Training Loss: 0.037160687148571014
Test Loss:  0.04520270228385925
Valid Loss:  0.045435935258865356
Epoch:  281  	Training Loss: 0.037146247923374176
Test Loss:  0.04518561810255051
Valid Loss:  0.04541872441768646
Epoch:  282  	Training Loss: 0.037131816148757935
Test Loss:  0.04516823589801788
Valid Loss:  0.04540117830038071
Epoch:  283  	Training Loss: 0.0371171236038208
Test Loss:  0.04515083506703377
Valid Loss:  0.04538363963365555
Epoch:  284  	Training Loss: 0.03710243105888367
Test Loss:  0.045133449137210846
Valid Loss:  0.045366108417510986
Epoch:  285  	Training Loss: 0.03708773851394653
Test Loss:  0.04511604458093643
Valid Loss:  0.04534851014614105
Epoch:  286  	Training Loss: 0.0370730422437191
Test Loss:  0.04509865492582321
Valid Loss:  0.045330941677093506
Epoch:  287  	Training Loss: 0.03705836832523346
Test Loss:  0.04508128762245178
Valid Loss:  0.04531344026327133
 58%|█████▊    | 289/500 [03:17<01:10,  3.00it/s] 58%|█████▊    | 291/500 [03:23<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:23<02:53,  1.19it/s] 59%|█████▉    | 295/500 [03:23<02:04,  1.65it/s] 59%|█████▉    | 297/500 [03:23<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:24<01:06,  3.03it/s] 60%|██████    | 301/500 [03:30<03:50,  1.16s/it] 61%|██████    | 303/500 [03:30<02:44,  1.20it/s] 61%|██████    | 305/500 [03:30<01:57,  1.66it/s] 61%|██████▏   | 307/500 [03:30<01:25,  2.27it/s] 62%|██████▏   | 309/500 [03:30<01:02,  3.04it/s] 62%|██████▏   | 311/500 [03:37<03:40,  1.17s/it] 63%|██████▎   | 313/500 [03:37<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:37<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:37<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:37<01:00,  3.01it/s] 64%|██████▍   | 321/500 [03:43<03:30,  1.17s/it] 65%|██████▍   | 323/500 [03:43<02:29,  1.19it/s] 65%|██████▌   | 325/500 [03:44<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:44<01:17,  2.24it/s] 66%|██████▌   | 329/500 [03:44<00:56,  3.01it/s] 66%|██████▌   | 331/500 [03:50<03:17,  1.17s/it] 67%|██████▋   | 333/500 [03:50<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:50<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:51<01:12,  2.23it/s] 68%|██████▊   | 339/500 [03:51<00:53,  3.00it/s] 68%|██████▊   | 341/500 [03:57<03:07,  1.18s/it] 69%|██████▊   | 343/500 [03:57<02:13,  1.18it/s] 69%|██████▉   | 345/500 [03:57<01:35,  1.63it/s] 69%|██████▉   | 347/500 [03:57<01:09,  2.22it/s] 70%|██████▉   | 349/500 [03:58<00:50,  2.98it/s] 70%|███████   | 351/500 [04:04<02:54,  1.17s/it] 71%|███████   | 353/500 [04:04<02:03,  1.19it/s] 71%|███████   | 355/500 [04:04<01:28,  1.65it/s] 71%|███████▏  | 357/500 [04:04<01:03,  2.25it/s]Epoch:  288  	Training Loss: 0.03704369068145752
Test Loss:  0.04506392031908035
Valid Loss:  0.04529590904712677
Epoch:  289  	Training Loss: 0.037029024213552475
Test Loss:  0.04504656791687012
Valid Loss:  0.04527841880917549
Epoch:  290  	Training Loss: 0.03701435402035713
Test Loss:  0.04502920061349869
Valid Loss:  0.045260898768901825
Epoch:  291  	Training Loss: 0.03699970245361328
Test Loss:  0.04501185566186905
Valid Loss:  0.045243389904499054
Epoch:  292  	Training Loss: 0.03698504716157913
Test Loss:  0.04499461501836777
Valid Loss:  0.04522600769996643
Epoch:  293  	Training Loss: 0.03697048872709274
Test Loss:  0.044977422803640366
Valid Loss:  0.04520868882536888
Epoch:  294  	Training Loss: 0.036955952644348145
Test Loss:  0.04496021568775177
Valid Loss:  0.04519132152199745
Epoch:  295  	Training Loss: 0.03694140166044235
Test Loss:  0.04494299739599228
Valid Loss:  0.04517395794391632
Epoch:  296  	Training Loss: 0.03692687302827835
Test Loss:  0.04492579400539398
Valid Loss:  0.04515661299228668
Epoch:  297  	Training Loss: 0.036912329494953156
Test Loss:  0.044908586889505386
Valid Loss:  0.045139264315366745
Epoch:  298  	Training Loss: 0.03689779341220856
Test Loss:  0.04489142447710037
Valid Loss:  0.04512200877070427
Epoch:  299  	Training Loss: 0.03688327223062515
Test Loss:  0.04487423971295357
Valid Loss:  0.04510469734668732
Epoch:  300  	Training Loss: 0.036868758499622345
Test Loss:  0.04485707730054855
Valid Loss:  0.04508739337325096
Epoch:  301  	Training Loss: 0.03685424476861954
Test Loss:  0.04483991116285324
Valid Loss:  0.045070089399814606
Epoch:  302  	Training Loss: 0.03683973848819733
Test Loss:  0.04482285678386688
Valid Loss:  0.045052915811538696
Epoch:  303  	Training Loss: 0.036825329065322876
Test Loss:  0.04480580613017082
Valid Loss:  0.04503575339913368
Epoch:  304  	Training Loss: 0.036810919642448425
Test Loss:  0.04478878527879715
Valid Loss:  0.04501861333847046
Epoch:  305  	Training Loss: 0.03679651767015457
Test Loss:  0.04477177932858467
Valid Loss:  0.045001477003097534
Epoch:  306  	Training Loss: 0.03678213804960251
Test Loss:  0.0447547510266304
Valid Loss:  0.0449843630194664
Epoch:  307  	Training Loss: 0.036767758429050446
Test Loss:  0.044737767428159714
Valid Loss:  0.04496725648641586
Epoch:  308  	Training Loss: 0.03675337880849838
Test Loss:  0.04472078010439873
Valid Loss:  0.04495015740394592
Epoch:  309  	Training Loss: 0.03673901408910751
Test Loss:  0.04470379650592804
Valid Loss:  0.044933073222637177
Epoch:  310  	Training Loss: 0.036724649369716644
Test Loss:  0.04468682035803795
Valid Loss:  0.04491598159074783
Epoch:  311  	Training Loss: 0.03671029210090637
Test Loss:  0.044669847935438156
Valid Loss:  0.04489893093705177
Epoch:  312  	Training Loss: 0.0366959385573864
Test Loss:  0.04465329647064209
Valid Loss:  0.044882286339998245
Epoch:  313  	Training Loss: 0.036681920289993286
Test Loss:  0.04463673382997513
Valid Loss:  0.04486563801765442
Epoch:  314  	Training Loss: 0.03666791319847107
Test Loss:  0.04462018981575966
Valid Loss:  0.04484888166189194
Epoch:  315  	Training Loss: 0.036653947085142136
Test Loss:  0.04460364207625389
Valid Loss:  0.044832129031419754
Epoch:  316  	Training Loss: 0.0366399884223938
Test Loss:  0.04458709806203842
Valid Loss:  0.04481537640094757
Epoch:  317  	Training Loss: 0.03662604093551636
Test Loss:  0.04457056522369385
Valid Loss:  0.044798653572797775
Epoch:  318  	Training Loss: 0.03661210089921951
Test Loss:  0.04455403983592987
Valid Loss:  0.04478193819522858
Epoch:  319  	Training Loss: 0.03659815341234207
Test Loss:  0.04453751817345619
Valid Loss:  0.044765226542949677
Epoch:  320  	Training Loss: 0.036584220826625824
Test Loss:  0.044521018862724304
Valid Loss:  0.04474852234125137
Epoch:  321  	Training Loss: 0.036570288240909576
Test Loss:  0.044504523277282715
Valid Loss:  0.04473184049129486
Epoch:  322  	Training Loss: 0.036556363105773926
Test Loss:  0.04448747634887695
Valid Loss:  0.044714611023664474
Epoch:  323  	Training Loss: 0.03654199466109276
Test Loss:  0.04447042569518089
Valid Loss:  0.04469737410545349
Epoch:  324  	Training Loss: 0.03652763366699219
Test Loss:  0.04445340111851692
Valid Loss:  0.0446801483631134
Epoch:  325  	Training Loss: 0.03651326894760132
Test Loss:  0.044436387717723846
Valid Loss:  0.044662948697805405
Epoch:  326  	Training Loss: 0.03649892285466194
Test Loss:  0.04441937059164047
Valid Loss:  0.044645756483078
Epoch:  327  	Training Loss: 0.036484573036432266
Test Loss:  0.04440236836671829
Valid Loss:  0.04462852701544762
Epoch:  328  	Training Loss: 0.03647024556994438
Test Loss:  0.04438536986708641
Valid Loss:  0.044611357152462006
Epoch:  329  	Training Loss: 0.0364559181034565
Test Loss:  0.044368378818035126
Valid Loss:  0.04459415376186371
Epoch:  330  	Training Loss: 0.03644160181283951
Test Loss:  0.04435140639543533
Valid Loss:  0.04457702115178108
Epoch:  331  	Training Loss: 0.03642728552222252
Test Loss:  0.044334448873996735
Valid Loss:  0.04455990344285965
Epoch:  332  	Training Loss: 0.036412980407476425
Test Loss:  0.044317569583654404
Valid Loss:  0.044542811810970306
Epoch:  333  	Training Loss: 0.036398738622665405
Test Loss:  0.044300682842731476
Valid Loss:  0.044525790959596634
Epoch:  334  	Training Loss: 0.036384500563144684
Test Loss:  0.044283825904130936
Valid Loss:  0.04450873285531998
Epoch:  335  	Training Loss: 0.03637028485536575
Test Loss:  0.04426697641611099
Valid Loss:  0.04449169337749481
Epoch:  336  	Training Loss: 0.036356084048748016
Test Loss:  0.04425014927983284
Valid Loss:  0.044474728405475616
Epoch:  337  	Training Loss: 0.03634187579154968
Test Loss:  0.044233329594135284
Valid Loss:  0.044457726180553436
Epoch:  338  	Training Loss: 0.03632768243551254
Test Loss:  0.04421652853488922
Valid Loss:  0.044440798461437225
Epoch:  339  	Training Loss: 0.0363135039806366
Test Loss:  0.04419972002506256
Valid Loss:  0.04442381486296654
Epoch:  340  	Training Loss: 0.03629932552576065
Test Loss:  0.044182926416397095
Valid Loss:  0.04440685361623764
Epoch:  341  	Training Loss: 0.036285169422626495
Test Loss:  0.044166140258312225
Valid Loss:  0.04438994824886322
Epoch:  342  	Training Loss: 0.03627099469304085
Test Loss:  0.04414984583854675
Valid Loss:  0.044373493641614914
Epoch:  343  	Training Loss: 0.03625722974538803
Test Loss:  0.04413354769349098
Valid Loss:  0.0443570539355278
Epoch:  344  	Training Loss: 0.036243464797735214
Test Loss:  0.044117242097854614
Valid Loss:  0.04434051364660263
Epoch:  345  	Training Loss: 0.03622972220182419
Test Loss:  0.04410092160105705
Valid Loss:  0.04432392120361328
Epoch:  346  	Training Loss: 0.03621597960591316
Test Loss:  0.04408460482954979
Valid Loss:  0.04430735111236572
Epoch:  347  	Training Loss: 0.03620225191116333
Test Loss:  0.044068314135074615
Valid Loss:  0.04429079219698906
Epoch:  348  	Training Loss: 0.03618853539228439
Test Loss:  0.044052042067050934
Valid Loss:  0.044274311512708664
Epoch:  349  	Training Loss: 0.03617481514811516
Test Loss:  0.04403577744960785
Valid Loss:  0.04425778239965439
Epoch:  350  	Training Loss: 0.03616110980510712
Test Loss:  0.044019490480422974
Valid Loss:  0.04424125701189041
Epoch:  351  	Training Loss: 0.03614739328622818
Test Loss:  0.044003214687108994
Valid Loss:  0.044224757701158524
Epoch:  352  	Training Loss: 0.03613368794322014
Test Loss:  0.04398681968450546
Valid Loss:  0.0442080944776535
Epoch:  353  	Training Loss: 0.03611987456679344
Test Loss:  0.04397042840719223
Valid Loss:  0.04419146478176117
Epoch:  354  	Training Loss: 0.03610606491565704
Test Loss:  0.043954037129879
Valid Loss:  0.04417484626173973
Epoch:  355  	Training Loss: 0.03609226644039154
Test Loss:  0.043937671929597855
Valid Loss:  0.044158242642879486
Epoch:  356  	Training Loss: 0.03607848286628723
Test Loss:  0.04392131045460701
Valid Loss:  0.04414166137576103
Epoch:  357  	Training Loss: 0.03606469929218292
Test Loss:  0.04390496760606766
Valid Loss:  0.044125087559223175
Epoch:  358  	Training Loss: 0.03605093061923981
Test Loss:  0.043888624757528305
Valid Loss:  0.04410853609442711
 72%|███████▏  | 359/500 [04:04<00:46,  3.03it/s] 72%|███████▏  | 361/500 [04:11<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:11<01:54,  1.20it/s] 73%|███████▎  | 365/500 [04:11<01:21,  1.65it/s] 73%|███████▎  | 367/500 [04:11<00:58,  2.25it/s] 74%|███████▍  | 369/500 [04:11<00:43,  3.03it/s] 74%|███████▍  | 371/500 [04:17<02:30,  1.16s/it] 75%|███████▍  | 373/500 [04:17<01:46,  1.20it/s] 75%|███████▌  | 375/500 [04:18<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:18<00:54,  2.26it/s] 76%|███████▌  | 379/500 [04:18<00:39,  3.04it/s] 76%|███████▌  | 381/500 [04:24<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:24<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:24<01:09,  1.64it/s] 77%|███████▋  | 387/500 [04:24<00:50,  2.25it/s] 78%|███████▊  | 389/500 [04:25<00:36,  3.02it/s] 78%|███████▊  | 391/500 [04:31<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:31<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:31<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:31<00:46,  2.24it/s] 80%|███████▉  | 399/500 [04:31<00:33,  3.01it/s] 80%|████████  | 401/500 [04:38<01:56,  1.18s/it] 81%|████████  | 403/500 [04:38<01:22,  1.18it/s] 81%|████████  | 405/500 [04:38<00:58,  1.64it/s] 81%|████████▏ | 407/500 [04:38<00:41,  2.22it/s] 82%|████████▏ | 409/500 [04:38<00:31,  2.93it/s] 82%|████████▏ | 411/500 [04:45<01:46,  1.20s/it] 83%|████████▎ | 413/500 [04:45<01:14,  1.16it/s] 83%|████████▎ | 415/500 [04:45<00:52,  1.61it/s] 83%|████████▎ | 417/500 [04:45<00:37,  2.21it/s] 84%|████████▍ | 419/500 [04:45<00:27,  2.96it/s] 84%|████████▍ | 421/500 [04:52<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:52<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:52<00:45,  1.64it/s] 85%|████████▌ | 427/500 [04:52<00:32,  2.23it/s] 86%|████████▌ | 429/500 [04:52<00:23,  3.00it/s]Epoch:  359  	Training Loss: 0.03603716567158699
Test Loss:  0.043872296810150146
Valid Loss:  0.044091999530792236
Epoch:  360  	Training Loss: 0.03602340444922447
Test Loss:  0.043855972588062286
Valid Loss:  0.04407547786831856
Epoch:  361  	Training Loss: 0.03600965440273285
Test Loss:  0.04383965954184532
Valid Loss:  0.044058941304683685
Epoch:  362  	Training Loss: 0.035995904356241226
Test Loss:  0.04382289573550224
Valid Loss:  0.044041965156793594
Epoch:  363  	Training Loss: 0.03598177433013916
Test Loss:  0.04380612447857857
Valid Loss:  0.04402497410774231
Epoch:  364  	Training Loss: 0.035967640578746796
Test Loss:  0.043789349496364594
Valid Loss:  0.044008005410432816
Epoch:  365  	Training Loss: 0.03595351055264473
Test Loss:  0.04377258941531181
Valid Loss:  0.04399106651544571
Epoch:  366  	Training Loss: 0.03593939542770386
Test Loss:  0.04375584423542023
Valid Loss:  0.04397410899400711
Epoch:  367  	Training Loss: 0.03592527657747269
Test Loss:  0.043739113956689835
Valid Loss:  0.043957196176052094
Epoch:  368  	Training Loss: 0.03591118007898331
Test Loss:  0.043722402304410934
Valid Loss:  0.04394027963280678
Epoch:  369  	Training Loss: 0.035897091031074524
Test Loss:  0.04370563477277756
Valid Loss:  0.04392320662736893
Epoch:  370  	Training Loss: 0.035882990807294846
Test Loss:  0.043688878417015076
Valid Loss:  0.04390612989664078
Epoch:  371  	Training Loss: 0.03586890920996666
Test Loss:  0.04367218166589737
Valid Loss:  0.04388926923274994
Epoch:  372  	Training Loss: 0.03585483506321907
Test Loss:  0.04365580901503563
Valid Loss:  0.04387259855866432
Epoch:  373  	Training Loss: 0.035841044038534164
Test Loss:  0.04363945126533508
Valid Loss:  0.043855950236320496
Epoch:  374  	Training Loss: 0.03582727164030075
Test Loss:  0.043623097240924835
Valid Loss:  0.04383943974971771
Epoch:  375  	Training Loss: 0.03581347316503525
Test Loss:  0.0436067134141922
Valid Loss:  0.043822795152664185
Epoch:  376  	Training Loss: 0.03579968214035034
Test Loss:  0.043590351939201355
Valid Loss:  0.043806158006191254
Epoch:  377  	Training Loss: 0.03578590601682663
Test Loss:  0.04357399046421051
Valid Loss:  0.04378952085971832
Epoch:  378  	Training Loss: 0.03577211871743202
Test Loss:  0.043557628989219666
Valid Loss:  0.04377289116382599
Epoch:  379  	Training Loss: 0.03575833886861801
Test Loss:  0.043541304767131805
Valid Loss:  0.04375642165541649
Epoch:  380  	Training Loss: 0.0357445552945137
Test Loss:  0.043524958193302155
Valid Loss:  0.04373982548713684
Epoch:  381  	Training Loss: 0.03573077917098999
Test Loss:  0.043508581817150116
Valid Loss:  0.04372319579124451
Epoch:  382  	Training Loss: 0.03571699187159538
Test Loss:  0.043492332100868225
Valid Loss:  0.04370670020580292
Epoch:  383  	Training Loss: 0.035703305155038834
Test Loss:  0.04347609728574753
Valid Loss:  0.043690215796232224
Epoch:  384  	Training Loss: 0.03568962961435318
Test Loss:  0.04345986247062683
Valid Loss:  0.04367373511195183
Epoch:  385  	Training Loss: 0.03567595034837723
Test Loss:  0.043443627655506134
Valid Loss:  0.04365728050470352
Epoch:  386  	Training Loss: 0.03566228970885277
Test Loss:  0.04342740774154663
Valid Loss:  0.04364082217216492
Epoch:  387  	Training Loss: 0.03564862534403801
Test Loss:  0.04341121017932892
Valid Loss:  0.043624378740787506
Epoch:  388  	Training Loss: 0.03563496842980385
Test Loss:  0.04339500516653061
Valid Loss:  0.043607957661151886
Epoch:  389  	Training Loss: 0.03562133014202118
Test Loss:  0.043378815054893494
Valid Loss:  0.043591536581516266
Epoch:  390  	Training Loss: 0.035607676953077316
Test Loss:  0.04336262866854668
Valid Loss:  0.043575137853622437
Epoch:  391  	Training Loss: 0.035594046115875244
Test Loss:  0.04334646463394165
Valid Loss:  0.0435587540268898
Epoch:  392  	Training Loss: 0.03558041900396347
Test Loss:  0.04333032667636871
Valid Loss:  0.04354240745306015
Epoch:  393  	Training Loss: 0.035566817969083786
Test Loss:  0.04331421107053757
Valid Loss:  0.043526068329811096
Epoch:  394  	Training Loss: 0.035553231835365295
Test Loss:  0.04329809918999672
Valid Loss:  0.04350976645946503
Epoch:  395  	Training Loss: 0.0355396494269371
Test Loss:  0.04328199848532677
Valid Loss:  0.04349347576498985
Epoch:  396  	Training Loss: 0.035526078194379807
Test Loss:  0.04326590523123741
Valid Loss:  0.043477192521095276
Epoch:  397  	Training Loss: 0.03551251068711281
Test Loss:  0.04324982687830925
Valid Loss:  0.043460920453071594
Epoch:  398  	Training Loss: 0.035498954355716705
Test Loss:  0.04323376715183258
Valid Loss:  0.0434446856379509
Epoch:  399  	Training Loss: 0.035485416650772095
Test Loss:  0.04321771115064621
Valid Loss:  0.0434284433722496
Epoch:  400  	Training Loss: 0.03547187149524689
Test Loss:  0.043201666325330734
Valid Loss:  0.0434122160077095
Epoch:  401  	Training Loss: 0.03545834869146347
Test Loss:  0.04318563640117645
Valid Loss:  0.04339601472020149
Epoch:  402  	Training Loss: 0.03544481843709946
Test Loss:  0.04316973313689232
Valid Loss:  0.04337992146611214
Epoch:  403  	Training Loss: 0.0354313924908638
Test Loss:  0.04315381497144699
Valid Loss:  0.043363798409700394
Epoch:  404  	Training Loss: 0.03541797026991844
Test Loss:  0.04313790798187256
Valid Loss:  0.04334767907857895
Epoch:  405  	Training Loss: 0.03540455549955368
Test Loss:  0.04312201589345932
Valid Loss:  0.0433315709233284
Epoch:  406  	Training Loss: 0.035391148179769516
Test Loss:  0.04310612380504608
Valid Loss:  0.04331549257040024
Epoch:  407  	Training Loss: 0.035377755761146545
Test Loss:  0.04309023916721344
Valid Loss:  0.043299414217472076
Epoch:  408  	Training Loss: 0.03536434844136238
Test Loss:  0.0430743582546711
Valid Loss:  0.043283335864543915
Epoch:  409  	Training Loss: 0.03535095602273941
Test Loss:  0.043058495968580246
Valid Loss:  0.04326726496219635
Epoch:  410  	Training Loss: 0.03533756360411644
Test Loss:  0.0430426150560379
Valid Loss:  0.043251194059848785
Epoch:  411  	Training Loss: 0.03532416373491287
Test Loss:  0.043026749044656754
Valid Loss:  0.04323514550924301
Epoch:  412  	Training Loss: 0.0353107824921608
Test Loss:  0.043011486530303955
Valid Loss:  0.043219707906246185
Epoch:  413  	Training Loss: 0.03529788553714752
Test Loss:  0.04299623519182205
Valid Loss:  0.04320429265499115
Epoch:  414  	Training Loss: 0.03528500348329544
Test Loss:  0.04298098757863045
Valid Loss:  0.043188877403736115
Epoch:  415  	Training Loss: 0.03527212142944336
Test Loss:  0.04296574741601944
Valid Loss:  0.04317347705364227
Epoch:  416  	Training Loss: 0.035259246826171875
Test Loss:  0.04295052960515022
Valid Loss:  0.043158091604709625
Epoch:  417  	Training Loss: 0.035246387124061584
Test Loss:  0.04293530434370041
Valid Loss:  0.043142709881067276
Epoch:  418  	Training Loss: 0.035233527421951294
Test Loss:  0.04292012006044388
Valid Loss:  0.04312737286090851
Epoch:  419  	Training Loss: 0.0352206826210022
Test Loss:  0.04290493577718735
Valid Loss:  0.043112028390169144
Epoch:  420  	Training Loss: 0.035207852721214294
Test Loss:  0.04288975149393082
Valid Loss:  0.04309670627117157
Epoch:  421  	Training Loss: 0.03519502654671669
Test Loss:  0.04287461191415787
Valid Loss:  0.04308140277862549
Epoch:  422  	Training Loss: 0.03518221527338028
Test Loss:  0.04285865277051926
Valid Loss:  0.043065279722213745
Epoch:  423  	Training Loss: 0.03516874462366104
Test Loss:  0.04284270852804184
Valid Loss:  0.043049171566963196
Epoch:  424  	Training Loss: 0.0351552814245224
Test Loss:  0.04282677546143532
Valid Loss:  0.04303307831287384
Epoch:  425  	Training Loss: 0.035141829401254654
Test Loss:  0.04281086474657059
Valid Loss:  0.04301699623465538
Epoch:  426  	Training Loss: 0.03512837737798691
Test Loss:  0.04279494285583496
Valid Loss:  0.043000925332307816
Epoch:  427  	Training Loss: 0.035114940255880356
Test Loss:  0.04277905449271202
Valid Loss:  0.04298487305641174
Epoch:  428  	Training Loss: 0.0351015105843544
Test Loss:  0.04276314750313759
Valid Loss:  0.04296882078051567
Epoch:  429  	Training Loss: 0.03508808836340904
Test Loss:  0.04274725914001465
Valid Loss:  0.04295279085636139
 86%|████████▌ | 431/500 [04:58<01:21,  1.18s/it] 87%|████████▋ | 433/500 [04:59<00:56,  1.18it/s] 87%|████████▋ | 435/500 [04:59<00:39,  1.63it/s] 87%|████████▋ | 437/500 [04:59<00:28,  2.23it/s] 88%|████████▊ | 439/500 [04:59<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:05<01:08,  1.17s/it] 89%|████████▊ | 443/500 [05:05<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:05<00:33,  1.65it/s] 89%|████████▉ | 447/500 [05:06<00:23,  2.25it/s] 90%|████████▉ | 449/500 [05:06<00:16,  3.02it/s] 90%|█████████ | 451/500 [05:12<00:56,  1.16s/it] 91%|█████████ | 453/500 [05:12<00:39,  1.20it/s] 91%|█████████ | 455/500 [05:12<00:27,  1.66it/s] 91%|█████████▏| 457/500 [05:12<00:18,  2.27it/s] 92%|█████████▏| 459/500 [05:12<00:13,  3.05it/s] 92%|█████████▏| 461/500 [05:19<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:19<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:19<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:19<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:19<00:10,  3.02it/s] 94%|█████████▍| 471/500 [05:25<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:26<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:26<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:26<00:10,  2.25it/s] 96%|█████████▌| 479/500 [05:26<00:06,  3.02it/s] 96%|█████████▌| 481/500 [05:32<00:22,  1.16s/it] 97%|█████████▋| 483/500 [05:32<00:14,  1.20it/s] 97%|█████████▋| 485/500 [05:32<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:33<00:05,  2.25it/s] 98%|█████████▊| 489/500 [05:33<00:03,  3.02it/s] 98%|█████████▊| 491/500 [05:39<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:39<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:39<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:39<00:01,  2.25it/s]100%|█████████▉| 499/500 [05:40<00:00,  3.01it/s]100%|██████████| 500/500 [05:40<00:00,  1.47it/s]
Epoch:  430  	Training Loss: 0.03507467359304428
Test Loss:  0.042731404304504395
Valid Loss:  0.042936772108078
Epoch:  431  	Training Loss: 0.03506125509738922
Test Loss:  0.04271552339196205
Valid Loss:  0.04292074590921402
Epoch:  432  	Training Loss: 0.03504784405231476
Test Loss:  0.042699605226516724
Valid Loss:  0.04290468990802765
Epoch:  433  	Training Loss: 0.035034388303756714
Test Loss:  0.042683690786361694
Valid Loss:  0.042888641357421875
Epoch:  434  	Training Loss: 0.035020943731069565
Test Loss:  0.04266779497265816
Valid Loss:  0.0428726002573967
Epoch:  435  	Training Loss: 0.03500751033425331
Test Loss:  0.04265189915895462
Valid Loss:  0.042856574058532715
Epoch:  436  	Training Loss: 0.03499407693743706
Test Loss:  0.042636021971702576
Valid Loss:  0.04284055531024933
Epoch:  437  	Training Loss: 0.0349806472659111
Test Loss:  0.042620155960321426
Valid Loss:  0.04282456636428833
Epoch:  438  	Training Loss: 0.034967225044965744
Test Loss:  0.042604297399520874
Valid Loss:  0.042808569967746735
Epoch:  439  	Training Loss: 0.034953806549310684
Test Loss:  0.04258840158581734
Valid Loss:  0.04279255121946335
Epoch:  440  	Training Loss: 0.03494037687778473
Test Loss:  0.04257253557443619
Valid Loss:  0.042776547372341156
Epoch:  441  	Training Loss: 0.034926947206258774
Test Loss:  0.04255664721131325
Valid Loss:  0.042760543525218964
Epoch:  442  	Training Loss: 0.03491351753473282
Test Loss:  0.04254211112856865
Valid Loss:  0.042745910584926605
Epoch:  443  	Training Loss: 0.034901197999715805
Test Loss:  0.04252757132053375
Valid Loss:  0.04273128882050514
Epoch:  444  	Training Loss: 0.034888871014118195
Test Loss:  0.04251305013895035
Valid Loss:  0.042716674506664276
Epoch:  445  	Training Loss: 0.03487655520439148
Test Loss:  0.04249854385852814
Valid Loss:  0.0427020788192749
Epoch:  446  	Training Loss: 0.03486425429582596
Test Loss:  0.04248404502868652
Valid Loss:  0.04268749803304672
Epoch:  447  	Training Loss: 0.034851957112550735
Test Loss:  0.04246955364942551
Valid Loss:  0.042672932147979736
Epoch:  448  	Training Loss: 0.03483967110514641
Test Loss:  0.04245508462190628
Valid Loss:  0.042658381164073944
Epoch:  449  	Training Loss: 0.034827396273612976
Test Loss:  0.04244063049554825
Valid Loss:  0.04264383763074875
Epoch:  450  	Training Loss: 0.034815140068531036
Test Loss:  0.04242618381977081
Valid Loss:  0.04262932017445564
Epoch:  451  	Training Loss: 0.0348028838634491
Test Loss:  0.04241175204515457
Valid Loss:  0.04261482506990433
Epoch:  452  	Training Loss: 0.03479064255952835
Test Loss:  0.04239589348435402
Valid Loss:  0.04259882867336273
Epoch:  453  	Training Loss: 0.03477722033858299
Test Loss:  0.04238004609942436
Valid Loss:  0.042582884430885315
Epoch:  454  	Training Loss: 0.03476380556821823
Test Loss:  0.042364198714494705
Valid Loss:  0.042566929012537
Epoch:  455  	Training Loss: 0.03475039824843407
Test Loss:  0.042348362505435944
Valid Loss:  0.04255098104476929
Epoch:  456  	Training Loss: 0.0347369946539402
Test Loss:  0.042332522571086884
Valid Loss:  0.042535051703453064
Epoch:  457  	Training Loss: 0.03472359478473663
Test Loss:  0.04231670871376991
Valid Loss:  0.042519137263298035
Epoch:  458  	Training Loss: 0.03471020981669426
Test Loss:  0.04230087995529175
Valid Loss:  0.04250321537256241
Epoch:  459  	Training Loss: 0.03469681739807129
Test Loss:  0.04228508099913597
Valid Loss:  0.04248729720711708
Epoch:  460  	Training Loss: 0.03468344360589981
Test Loss:  0.04226928576827049
Valid Loss:  0.04247141629457474
Epoch:  461  	Training Loss: 0.03467006981372833
Test Loss:  0.04225349426269531
Valid Loss:  0.0424555279314518
Epoch:  462  	Training Loss: 0.03465670719742775
Test Loss:  0.042238056659698486
Valid Loss:  0.042439915239810944
Epoch:  463  	Training Loss: 0.03464367985725403
Test Loss:  0.04222261160612106
Valid Loss:  0.04242430254817009
Epoch:  464  	Training Loss: 0.0346306636929512
Test Loss:  0.042207200080156326
Valid Loss:  0.04240870848298073
Epoch:  465  	Training Loss: 0.034617651253938675
Test Loss:  0.04219178110361099
Valid Loss:  0.04239312931895256
Epoch:  466  	Training Loss: 0.034604646265506744
Test Loss:  0.04217637702822685
Valid Loss:  0.04237755388021469
Epoch:  467  	Training Loss: 0.03459164500236511
Test Loss:  0.04216097667813301
Valid Loss:  0.04236198961734772
Epoch:  468  	Training Loss: 0.03457865118980408
Test Loss:  0.04214559495449066
Valid Loss:  0.042346447706222534
Epoch:  469  	Training Loss: 0.034565672278404236
Test Loss:  0.04213021695613861
Valid Loss:  0.04233090579509735
Epoch:  470  	Training Loss: 0.034552689641714096
Test Loss:  0.04211484640836716
Valid Loss:  0.04231538251042366
Epoch:  471  	Training Loss: 0.03453971445560455
Test Loss:  0.0420994907617569
Valid Loss:  0.042299866676330566
Epoch:  472  	Training Loss: 0.0345267578959465
Test Loss:  0.04208309203386307
Valid Loss:  0.042283300310373306
Epoch:  473  	Training Loss: 0.03451294079422951
Test Loss:  0.04206670820713043
Valid Loss:  0.04226674139499664
Epoch:  474  	Training Loss: 0.03449912741780281
Test Loss:  0.04205033555626869
Valid Loss:  0.042250197380781174
Epoch:  475  	Training Loss: 0.03448532894253731
Test Loss:  0.042033977806568146
Valid Loss:  0.0422336645424366
Epoch:  476  	Training Loss: 0.0344715379178524
Test Loss:  0.0420176200568676
Valid Loss:  0.042217135429382324
Epoch:  477  	Training Loss: 0.03445775434374809
Test Loss:  0.04200126975774765
Valid Loss:  0.04220064356923103
Epoch:  478  	Training Loss: 0.034443970769643784
Test Loss:  0.0419849269092083
Valid Loss:  0.04218413680791855
Epoch:  479  	Training Loss: 0.03443019092082977
Test Loss:  0.041968606412410736
Valid Loss:  0.04216765984892845
Epoch:  480  	Training Loss: 0.03441641852259636
Test Loss:  0.041952282190322876
Valid Loss:  0.042151182889938354
Epoch:  481  	Training Loss: 0.03440265730023384
Test Loss:  0.04193596914410591
Valid Loss:  0.04213470220565796
Epoch:  482  	Training Loss: 0.034388892352581024
Test Loss:  0.04192068427801132
Valid Loss:  0.04211927205324173
Epoch:  483  	Training Loss: 0.03437601029872894
Test Loss:  0.04190542921423912
Valid Loss:  0.0421038456261158
Epoch:  484  	Training Loss: 0.034363143146038055
Test Loss:  0.04189017415046692
Valid Loss:  0.04208843782544136
Epoch:  485  	Training Loss: 0.03435027599334717
Test Loss:  0.04187494516372681
Valid Loss:  0.04207306355237961
Epoch:  486  	Training Loss: 0.03433743119239807
Test Loss:  0.04185972735285759
Valid Loss:  0.042057693004608154
Epoch:  487  	Training Loss: 0.034324586391448975
Test Loss:  0.04184451699256897
Valid Loss:  0.042042333632707596
Epoch:  488  	Training Loss: 0.034311749041080475
Test Loss:  0.041829317808151245
Valid Loss:  0.04202699661254883
Epoch:  489  	Training Loss: 0.03429893031716347
Test Loss:  0.04181414470076561
Valid Loss:  0.04201168566942215
Epoch:  490  	Training Loss: 0.03428611904382706
Test Loss:  0.041798967868089676
Valid Loss:  0.04199638217687607
Epoch:  491  	Training Loss: 0.03427332267165184
Test Loss:  0.04178382456302643
Valid Loss:  0.041981086134910583
Epoch:  492  	Training Loss: 0.034260526299476624
Test Loss:  0.04176841303706169
Valid Loss:  0.0419655442237854
Epoch:  493  	Training Loss: 0.03424752503633499
Test Loss:  0.041753023862838745
Valid Loss:  0.041950009763240814
Epoch:  494  	Training Loss: 0.03423453867435455
Test Loss:  0.041737645864486694
Valid Loss:  0.041934505105018616
Epoch:  495  	Training Loss: 0.034221552312374115
Test Loss:  0.041722267866134644
Valid Loss:  0.04191898554563522
Epoch:  496  	Training Loss: 0.034208569675683975
Test Loss:  0.04170689359307289
Valid Loss:  0.041903503239154816
Epoch:  497  	Training Loss: 0.03419560194015503
Test Loss:  0.041691552847623825
Valid Loss:  0.041888024657964706
Epoch:  498  	Training Loss: 0.03418263792991638
Test Loss:  0.04167620465159416
Valid Loss:  0.0418725460767746
Epoch:  499  	Training Loss: 0.034169673919677734
Test Loss:  0.041660867631435394
Valid Loss:  0.04185707867145538
Epoch:  500  	Training Loss: 0.034156717360019684
Test Loss:  0.041645534336566925
Valid Loss:  0.04184163361787796
seed is  20
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<50:58,  6.13s/it]  1%|          | 3/500 [00:06<13:33,  1.64s/it]  1%|          | 5/500 [00:06<06:50,  1.21it/s]  1%|▏         | 7/500 [00:06<04:09,  1.98it/s]  2%|▏         | 9/500 [00:06<02:46,  2.95it/s]  2%|▏         | 11/500 [00:12<10:45,  1.32s/it]  3%|▎         | 13/500 [00:13<07:19,  1.11it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:19<09:33,  1.20s/it]  5%|▍         | 23/500 [00:19<06:46,  1.17it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:32,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.00it/s]  6%|▌         | 31/500 [00:26<09:10,  1.17s/it]  7%|▋         | 33/500 [00:26<06:33,  1.19it/s]  7%|▋         | 35/500 [00:33<12:09,  1.57s/it]  7%|▋         | 37/500 [00:33<08:38,  1.12s/it]  8%|▊         | 39/500 [00:33<06:09,  1.25it/s]  8%|▊         | 41/500 [00:39<11:29,  1.50s/it]  9%|▊         | 43/500 [00:39<08:10,  1.07s/it]  9%|▉         | 45/500 [00:40<05:50,  1.30it/s]  9%|▉         | 47/500 [00:40<04:13,  1.79it/s] 10%|▉         | 49/500 [00:40<03:05,  2.43it/s] 10%|█         | 51/500 [00:46<09:18,  1.24s/it] 11%|█         | 53/500 [00:46<06:38,  1.12it/s] 11%|█         | 55/500 [00:53<11:37,  1.57s/it] 11%|█▏        | 57/500 [00:53<08:15,  1.12s/it] 12%|█▏        | 59/500 [00:53<05:53,  1.25it/s] 12%|█▏        | 61/500 [00:59<10:56,  1.50s/it] 13%|█▎        | 63/500 [00:59<07:47,  1.07s/it] 13%|█▎        | 65/500 [00:59<05:33,  1.30it/s] 13%|█▎        | 67/500 [00:59<04:01,  1.79it/s] 14%|█▍        | 69/500 [01:00<02:56,  2.44it/s]Epoch:  1  	Training Loss: 0.1977379322052002
Test Loss:  19.63701629638672
Valid Loss:  19.737581253051758
Epoch:  2  	Training Loss: 19.139333724975586
Test Loss:  36.015785217285156
Valid Loss:  36.20511245727539
Epoch:  3  	Training Loss: 35.71063995361328
Test Loss:  0.6779909133911133
Valid Loss:  0.6676044464111328
Epoch:  4  	Training Loss: 0.7027326822280884
Test Loss:  0.6755508184432983
Valid Loss:  0.6647883653640747
Epoch:  5  	Training Loss: 0.7000544667243958
Test Loss:  0.6725607514381409
Valid Loss:  0.6616337895393372
Epoch:  6  	Training Loss: 0.6967133283615112
Test Loss:  0.6685882210731506
Valid Loss:  0.6575067043304443
Epoch:  7  	Training Loss: 0.6922585368156433
Test Loss:  0.6623779535293579
Valid Loss:  0.6513136029243469
Epoch:  8  	Training Loss: 0.6853231191635132
Test Loss:  0.653017520904541
Valid Loss:  0.6418296098709106
Epoch:  9  	Training Loss: 0.6751235723495483
Test Loss:  0.6417534351348877
Valid Loss:  0.6305275559425354
Epoch:  10  	Training Loss: 0.6632828712463379
Test Loss:  0.6305667161941528
Valid Loss:  0.6193820238113403
Epoch:  11  	Training Loss: 0.6515403985977173
Test Loss:  0.6196743845939636
Valid Loss:  0.6084944009780884
Epoch:  12  	Training Loss: 0.640072762966156
Test Loss:  6.437262535095215
Valid Loss:  6.445067405700684
Epoch:  13  	Training Loss: 6.714047431945801
Test Loss:  0.34711772203445435
Valid Loss:  0.33945074677467346
Epoch:  14  	Training Loss: 0.35893765091896057
Test Loss:  0.336460143327713
Valid Loss:  0.3287092447280884
Epoch:  15  	Training Loss: 0.3486631214618683
Test Loss:  0.33153945207595825
Valid Loss:  0.3237617015838623
Epoch:  16  	Training Loss: 0.3435347080230713
Test Loss:  0.32684242725372314
Valid Loss:  0.3190220594406128
Epoch:  17  	Training Loss: 0.33864009380340576
Test Loss:  0.3222738206386566
Valid Loss:  0.31443628668785095
Epoch:  18  	Training Loss: 0.33390921354293823
Test Loss:  0.3177851140499115
Valid Loss:  0.3099987506866455
Epoch:  19  	Training Loss: 0.3292713761329651
Test Loss:  0.31339192390441895
Valid Loss:  0.3057352900505066
Epoch:  20  	Training Loss: 0.3247428834438324
Test Loss:  0.3090638518333435
Valid Loss:  0.3015901446342468
Epoch:  21  	Training Loss: 0.320283442735672
Test Loss:  0.3048017919063568
Valid Loss:  0.2975348234176636
Epoch:  22  	Training Loss: 0.3159005641937256
Test Loss:  0.062173858284950256
Valid Loss:  0.05492322891950607
Epoch:  23  	Training Loss: 0.08235931396484375
Test Loss:  0.030764896422624588
Valid Loss:  0.025921421125531197
Epoch:  24  	Training Loss: 0.04387938231229782
Test Loss:  0.017328515648841858
Valid Loss:  0.014030039310455322
Epoch:  25  	Training Loss: 0.02631678432226181
Test Loss:  0.012927998788654804
Valid Loss:  0.010555459186434746
Epoch:  26  	Training Loss: 0.01962490938603878
Test Loss:  0.011698858812451363
Valid Loss:  0.009885667823255062
Epoch:  27  	Training Loss: 0.017083507031202316
Test Loss:  0.011501019820570946
Valid Loss:  0.010028278455138206
Epoch:  28  	Training Loss: 0.016115210950374603
Test Loss:  0.011588891968131065
Valid Loss:  0.010324455797672272
Epoch:  29  	Training Loss: 0.015742994844913483
Test Loss:  0.011720366775989532
Valid Loss:  0.010583879426121712
Epoch:  30  	Training Loss: 0.01559661328792572
Test Loss:  0.011828598566353321
Valid Loss:  0.010770982131361961
Epoch:  31  	Training Loss: 0.01553578581660986
Test Loss:  0.011903542093932629
Valid Loss:  0.010894743725657463
Epoch:  32  	Training Loss: 0.01550737302750349
Test Loss:  0.01577046513557434
Valid Loss:  0.015393898822367191
Epoch:  33  	Training Loss: 0.016766251996159554
Test Loss:  0.02544664964079857
Valid Loss:  0.026502717286348343
Epoch:  34  	Training Loss: 0.023284895345568657
Test Loss:  0.011786924675107002
Valid Loss:  0.011605897918343544
Epoch:  35  	Training Loss: 0.011994762346148491
Test Loss:  0.0019843706395477057
Valid Loss:  0.002562646521255374
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.0022194022312760353
Test Loss:  0.001275191898457706
Valid Loss:  0.0018272189190611243
Epoch:  37  	Training Loss: 0.0016971360892057419
Test Loss:  0.0011403183452785015
Valid Loss:  0.001685725525021553
Epoch:  38  	Training Loss: 0.0016106229741126299
Test Loss:  0.0011060405522584915
Valid Loss:  0.0016489406116306782
Epoch:  39  	Training Loss: 0.0015915576368570328
Test Loss:  0.001091877929866314
Valid Loss:  0.0016296722460538149
Epoch:  40  	Training Loss: 0.001578848110511899
Test Loss:  0.0010867118835449219
Valid Loss:  0.001624018419533968
Epoch:  41  	Training Loss: 0.0015775759238749743
Test Loss:  0.0010853526182472706
Valid Loss:  0.0016225356375798583
Epoch:  42  	Training Loss: 0.0015774259809404612
Test Loss:  0.0010904909577220678
Valid Loss:  0.0017173143569380045
Epoch:  43  	Training Loss: 0.0015159908216446638
Test Loss:  0.0010842193150892854
Valid Loss:  0.0017105273436754942
Epoch:  44  	Training Loss: 0.0014991720672696829
Test Loss:  0.0010767672210931778
Valid Loss:  0.0017154344823211432
Epoch:  45  	Training Loss: 0.0014870625454932451
Test Loss:  0.001063136151060462
Valid Loss:  0.0016954324673861265
Epoch:  46  	Training Loss: 0.0014749844558537006
Test Loss:  0.0010465867817401886
Valid Loss:  0.0016801883466541767
Epoch:  47  	Training Loss: 0.0014556918758898973
Test Loss:  0.0010508751729503274
Valid Loss:  0.0016961765941232443
Epoch:  48  	Training Loss: 0.0014578721020370722
Test Loss:  0.0010418685851618648
Valid Loss:  0.0016875272849574685
Epoch:  49  	Training Loss: 0.0014491870533674955
Test Loss:  0.0010516452603042126
Valid Loss:  0.0016994659090414643
Epoch:  50  	Training Loss: 0.0014548685867339373
Test Loss:  0.0010397473815828562
Valid Loss:  0.0016867638332769275
Epoch:  51  	Training Loss: 0.0014456813223659992
Test Loss:  0.001044969423674047
Valid Loss:  0.00169134302996099
Epoch:  52  	Training Loss: 0.0014479898381978273
Test Loss:  0.0010280790738761425
Valid Loss:  0.001652001403272152
Epoch:  53  	Training Loss: 0.0014393008314073086
Test Loss:  0.001020577852614224
Valid Loss:  0.0016396943246945739
Epoch:  54  	Training Loss: 0.001438083709217608
Test Loss:  0.0010204862337559462
Valid Loss:  0.0016337214037775993
Epoch:  55  	Training Loss: 0.001437272410839796
Test Loss:  0.0010145006235688925
Valid Loss:  0.0016276331152766943
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.001434776815585792
Test Loss:  0.000995334004983306
Valid Loss:  0.00160309043712914
Epoch:  57  	Training Loss: 0.0014206244377419353
Test Loss:  0.0009892306989058852
Valid Loss:  0.001593051478266716
Epoch:  58  	Training Loss: 0.0014171776128932834
Test Loss:  0.0009847867768257856
Valid Loss:  0.0015851003117859364
Epoch:  59  	Training Loss: 0.0014148784102872014
Test Loss:  0.0009809317998588085
Valid Loss:  0.0015781576512381434
Epoch:  60  	Training Loss: 0.0014130373019725084
Test Loss:  0.0009781112894415855
Valid Loss:  0.0015726913698017597
Epoch:  61  	Training Loss: 0.0014118845574557781
Test Loss:  0.000975780189037323
Valid Loss:  0.001568224048241973
Epoch:  62  	Training Loss: 0.0014110738411545753
Test Loss:  0.0009631974389776587
Valid Loss:  0.0015636204043403268
Epoch:  63  	Training Loss: 0.0013710784260183573
Test Loss:  0.0009224391542375088
Valid Loss:  0.0015259475912898779
Epoch:  64  	Training Loss: 0.0012944781919941306
Test Loss:  0.0009186930255964398
Valid Loss:  0.0015194916632026434
Epoch:  65  	Training Loss: 0.001290236134082079
Test Loss:  0.0009161243797279894
Valid Loss:  0.0015142961638048291
Epoch:  66  	Training Loss: 0.0012890222715213895
Test Loss:  0.0009139523026533425
Valid Loss:  0.001509738271124661
Epoch:  67  	Training Loss: 0.0012880184222012758
Test Loss:  0.0009118854068219662
Valid Loss:  0.0015055742114782333
Epoch:  68  	Training Loss: 0.001287166029214859
Test Loss:  0.0009099125163629651
Valid Loss:  0.0015017425175756216
Epoch:  69  	Training Loss: 0.001286424114368856
Test Loss:  0.0009080973686650395
Valid Loss:  0.0014981855638325214
 14%|█▍        | 71/500 [01:06<08:47,  1.23s/it] 15%|█▍        | 73/500 [01:06<06:16,  1.14it/s] 15%|█▌        | 75/500 [01:06<04:30,  1.57it/s] 15%|█▌        | 77/500 [01:06<03:16,  2.15it/s] 16%|█▌        | 79/500 [01:06<02:25,  2.90it/s] 16%|█▌        | 81/500 [01:13<08:11,  1.17s/it] 17%|█▋        | 83/500 [01:13<05:51,  1.19it/s] 17%|█▋        | 85/500 [01:13<04:13,  1.64it/s] 17%|█▋        | 87/500 [01:13<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:13<02:16,  3.01it/s] 18%|█▊        | 91/500 [01:20<08:04,  1.18s/it] 19%|█▊        | 93/500 [01:20<05:46,  1.18it/s] 19%|█▉        | 95/500 [01:20<04:08,  1.63it/s] 19%|█▉        | 97/500 [01:20<03:01,  2.22it/s] 20%|█▉        | 99/500 [01:20<02:14,  2.98it/s] 20%|██        | 101/500 [01:26<07:44,  1.16s/it] 21%|██        | 103/500 [01:26<05:31,  1.20it/s] 21%|██        | 105/500 [01:27<03:59,  1.65it/s] 21%|██▏       | 107/500 [01:27<02:54,  2.26it/s] 22%|██▏       | 109/500 [01:27<02:09,  3.03it/s] 22%|██▏       | 111/500 [01:33<07:32,  1.16s/it] 23%|██▎       | 113/500 [01:33<05:24,  1.19it/s] 23%|██▎       | 115/500 [01:33<03:53,  1.65it/s] 23%|██▎       | 117/500 [01:33<02:49,  2.25it/s] 24%|██▍       | 119/500 [01:34<02:05,  3.03it/s] 24%|██▍       | 121/500 [01:40<07:24,  1.17s/it] 25%|██▍       | 123/500 [01:40<05:18,  1.19it/s] 25%|██▌       | 125/500 [01:40<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:40<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:40<02:03,  3.00it/s] 26%|██▌       | 131/500 [01:47<07:13,  1.17s/it] 27%|██▋       | 133/500 [01:47<05:09,  1.19it/s] 27%|██▋       | 135/500 [01:47<03:42,  1.64it/s] 27%|██▋       | 137/500 [01:47<02:42,  2.24it/s]Epoch:  70  	Training Loss: 0.0012858007103204727
Test Loss:  0.0009071692475117743
Valid Loss:  0.0014954896178096533
Epoch:  71  	Training Loss: 0.001285223988816142
Test Loss:  0.0009053547400981188
Valid Loss:  0.0014923738781362772
Epoch:  72  	Training Loss: 0.0012846823083236814
Test Loss:  0.0008926857262849808
Valid Loss:  0.0014449803857132792
Epoch:  73  	Training Loss: 0.001275021699257195
Test Loss:  0.0008883122354745865
Valid Loss:  0.0014415576588362455
Epoch:  74  	Training Loss: 0.001272240187972784
Test Loss:  0.0008845824049785733
Valid Loss:  0.0014369869604706764
Epoch:  75  	Training Loss: 0.0012703477405011654
Test Loss:  0.0008823776734061539
Valid Loss:  0.0014365757815539837
Epoch:  76  	Training Loss: 0.001269063213840127
Test Loss:  0.0008792508160695434
Valid Loss:  0.0014307762030512094
Epoch:  77  	Training Loss: 0.001268214313313365
Test Loss:  0.0008781451033428311
Valid Loss:  0.0014316471060737967
Epoch:  78  	Training Loss: 0.0012674652971327305
Test Loss:  0.0008763298392295837
Valid Loss:  0.0014288874808698893
Epoch:  79  	Training Loss: 0.0012669673888012767
Test Loss:  0.0008745127124711871
Valid Loss:  0.0014257984003052115
Epoch:  80  	Training Loss: 0.0012665285030379891
Test Loss:  0.0008728020475246012
Valid Loss:  0.0014228342333808541
Epoch:  81  	Training Loss: 0.001266135717742145
Test Loss:  0.0008712072158232331
Valid Loss:  0.0014200488803908229
Epoch:  82  	Training Loss: 0.0012657851912081242
Test Loss:  0.0008710834663361311
Valid Loss:  0.0014198897406458855
Epoch:  83  	Training Loss: 0.0012657528277486563
Test Loss:  0.0008709620451554656
Valid Loss:  0.001419728621840477
Epoch:  84  	Training Loss: 0.0012657209299504757
Test Loss:  0.0008708388777449727
Valid Loss:  0.0014195675030350685
Epoch:  85  	Training Loss: 0.0012656890321522951
Test Loss:  0.0008707183296792209
Valid Loss:  0.001419405685737729
Epoch:  86  	Training Loss: 0.0012656582985073328
Test Loss:  0.000870599178597331
Valid Loss:  0.0014192400267347693
Epoch:  87  	Training Loss: 0.001265628612600267
Test Loss:  0.0008704796200618148
Valid Loss:  0.0014190758811309934
Epoch:  88  	Training Loss: 0.0012655986938625574
Test Loss:  0.0008703600615262985
Valid Loss:  0.0014189067296683788
Epoch:  89  	Training Loss: 0.0012655701721087098
Test Loss:  0.0008702421910129488
Valid Loss:  0.0014187418855726719
Epoch:  90  	Training Loss: 0.0012655416503548622
Test Loss:  0.0008701249025762081
Valid Loss:  0.0014185712207108736
Epoch:  91  	Training Loss: 0.0012655123136937618
Test Loss:  0.0008700062171556056
Valid Loss:  0.0014184038154780865
Epoch:  92  	Training Loss: 0.001265485305339098
Test Loss:  0.0008681052131578326
Valid Loss:  0.0014147022739052773
Epoch:  93  	Training Loss: 0.0012649367563426495
Test Loss:  0.0008665072964504361
Valid Loss:  0.0014116279780864716
Epoch:  94  	Training Loss: 0.001264500431716442
Test Loss:  0.0008651238749735057
Valid Loss:  0.0014089434407651424
Epoch:  95  	Training Loss: 0.00126415747217834
Test Loss:  0.0008640177547931671
Valid Loss:  0.001406766241416335
Epoch:  96  	Training Loss: 0.0012639433844015002
Test Loss:  0.00086308887694031
Valid Loss:  0.001405058428645134
Epoch:  97  	Training Loss: 0.0012637816835194826
Test Loss:  0.0008622791501693428
Valid Loss:  0.0014036367647349834
Epoch:  98  	Training Loss: 0.0012636530445888638
Test Loss:  0.0008615322876721621
Valid Loss:  0.001402377849444747
Epoch:  99  	Training Loss: 0.0012635348830372095
Test Loss:  0.0008608254138380289
Valid Loss:  0.0014011947205290198
Epoch:  100  	Training Loss: 0.0012634268496185541
Test Loss:  0.0008601911831647158
Valid Loss:  0.001400102861225605
Epoch:  101  	Training Loss: 0.0012633446604013443
Test Loss:  0.0008596291299909353
Valid Loss:  0.0013991274172440171
Epoch:  102  	Training Loss: 0.0012633505975827575
Test Loss:  0.0008554705418646336
Valid Loss:  0.0013971258886158466
Epoch:  103  	Training Loss: 0.0012569468235597014
Test Loss:  0.0008495883084833622
Valid Loss:  0.0013944590464234352
Epoch:  104  	Training Loss: 0.001250407425686717
Test Loss:  0.0008438681252300739
Valid Loss:  0.0013908122200518847
Epoch:  105  	Training Loss: 0.0012440430000424385
Test Loss:  0.0008377967751584947
Valid Loss:  0.0013855746947228909
Epoch:  106  	Training Loss: 0.0012378338724374771
Test Loss:  0.000832241668831557
Valid Loss:  0.001380373490974307
Epoch:  107  	Training Loss: 0.0012317767832428217
Test Loss:  0.0008263932541012764
Valid Loss:  0.0013737162807956338
Epoch:  108  	Training Loss: 0.0012255634646862745
Test Loss:  0.0008204604382626712
Valid Loss:  0.0013665349688380957
Epoch:  109  	Training Loss: 0.0012174840085208416
Test Loss:  0.0008133290684781969
Valid Loss:  0.0013584103435277939
Epoch:  110  	Training Loss: 0.0012075519189238548
Test Loss:  0.0008064174908213317
Valid Loss:  0.0013499446213245392
Epoch:  111  	Training Loss: 0.0011971377534791827
Test Loss:  0.0007992247701622546
Valid Loss:  0.0013414688874036074
Epoch:  112  	Training Loss: 0.0011870642192661762
Test Loss:  0.0007596137002110481
Valid Loss:  0.0012910689692944288
Epoch:  113  	Training Loss: 0.0011522967834025621
Test Loss:  0.0007422899943776429
Valid Loss:  0.0012696966296061873
Epoch:  114  	Training Loss: 0.0011388373095542192
Test Loss:  0.0007340017473325133
Valid Loss:  0.001258803647942841
Epoch:  115  	Training Loss: 0.0011332053691148758
Test Loss:  0.0007291643414646387
Valid Loss:  0.0012505786726251245
Epoch:  116  	Training Loss: 0.0011296269949525595
Test Loss:  0.0007258108234964311
Valid Loss:  0.0012444329913705587
Epoch:  117  	Training Loss: 0.001126944087445736
Test Loss:  0.0007229632465168834
Valid Loss:  0.0012391686905175447
Epoch:  118  	Training Loss: 0.001124645583331585
Test Loss:  0.0007207215530797839
Valid Loss:  0.00123464479111135
Epoch:  119  	Training Loss: 0.0011226821225136518
Test Loss:  0.0007187443552538753
Valid Loss:  0.0012304981937631965
Epoch:  120  	Training Loss: 0.0011208716314285994
Test Loss:  0.0007169669261202216
Valid Loss:  0.001226693158969283
Epoch:  121  	Training Loss: 0.0011191797675564885
Test Loss:  0.0007153521873988211
Valid Loss:  0.0012231505243107677
Epoch:  122  	Training Loss: 0.0011175619438290596
Test Loss:  0.0007066662656143308
Valid Loss:  0.0012045155744999647
Epoch:  123  	Training Loss: 0.001110337907448411
Test Loss:  0.0007069494458846748
Valid Loss:  0.001205169828608632
Epoch:  124  	Training Loss: 0.0011087084421887994
Test Loss:  0.0007072881562635303
Valid Loss:  0.0012062911409884691
Epoch:  125  	Training Loss: 0.0011071774642914534
Test Loss:  0.000707543920725584
Valid Loss:  0.001207222230732441
Epoch:  126  	Training Loss: 0.0011057017836719751
Test Loss:  0.0007077064947225153
Valid Loss:  0.0012079138541594148
Epoch:  127  	Training Loss: 0.0011042730184271932
Test Loss:  0.0007077871123328805
Valid Loss:  0.0012083856854587793
Epoch:  128  	Training Loss: 0.0011028825538232923
Test Loss:  0.0007077923510223627
Valid Loss:  0.0012086706701666117
Epoch:  129  	Training Loss: 0.0011015981435775757
Test Loss:  0.0007069904822856188
Valid Loss:  0.0012064727488905191
Epoch:  130  	Training Loss: 0.0011003408581018448
Test Loss:  0.0007070262217894197
Valid Loss:  0.001207271357998252
Epoch:  131  	Training Loss: 0.0010990032460540533
Test Loss:  0.0007069403654895723
Valid Loss:  0.0012073740363121033
Epoch:  132  	Training Loss: 0.001097796019166708
Test Loss:  0.000709103886038065
Valid Loss:  0.0012134109856560826
Epoch:  133  	Training Loss: 0.001097528263926506
Test Loss:  0.0007088491693139076
Valid Loss:  0.0012123803608119488
Epoch:  134  	Training Loss: 0.0010974227916449308
Test Loss:  0.0007098644273355603
Valid Loss:  0.0012149960966780782
Epoch:  135  	Training Loss: 0.001097327098250389
Test Loss:  0.000709789339452982
Valid Loss:  0.0012144986540079117
Epoch:  136  	Training Loss: 0.0010972385061904788
Test Loss:  0.0007105469703674316
Valid Loss:  0.0012164164800196886
Epoch:  137  	Training Loss: 0.0010971587616950274
Test Loss:  0.0007105778786353767
Valid Loss:  0.0012162441853433847
Epoch:  138  	Training Loss: 0.001097083673812449
Test Loss:  0.0007111504091881216
Valid Loss:   28%|██▊       | 139/500 [01:47<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:53<06:59,  1.17s/it] 29%|██▊       | 143/500 [01:54<04:59,  1.19it/s] 29%|██▉       | 145/500 [01:54<03:35,  1.65it/s] 29%|██▉       | 147/500 [01:54<02:37,  2.25it/s] 30%|██▉       | 149/500 [01:54<01:56,  3.00it/s] 30%|███       | 151/500 [02:00<06:49,  1.17s/it] 31%|███       | 153/500 [02:00<04:53,  1.18it/s] 31%|███       | 155/500 [02:01<03:30,  1.64it/s] 31%|███▏      | 157/500 [02:01<02:33,  2.23it/s] 32%|███▏      | 159/500 [02:01<01:53,  3.00it/s] 32%|███▏      | 161/500 [02:07<06:43,  1.19s/it] 33%|███▎      | 163/500 [02:07<04:49,  1.16it/s] 33%|███▎      | 165/500 [02:08<03:29,  1.60it/s] 33%|███▎      | 167/500 [02:08<02:32,  2.19it/s] 34%|███▍      | 169/500 [02:08<01:52,  2.94it/s] 34%|███▍      | 171/500 [02:14<06:29,  1.18s/it] 35%|███▍      | 173/500 [02:14<04:38,  1.18it/s] 35%|███▌      | 175/500 [02:14<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:14<02:25,  2.22it/s] 36%|███▌      | 179/500 [02:15<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:21<06:15,  1.18s/it] 37%|███▋      | 183/500 [02:21<04:27,  1.18it/s] 37%|███▋      | 185/500 [02:21<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:21<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:21<01:43,  3.02it/s] 38%|███▊      | 191/500 [02:28<06:02,  1.17s/it] 39%|███▊      | 193/500 [02:28<04:18,  1.19it/s] 39%|███▉      | 195/500 [02:28<03:05,  1.64it/s] 39%|███▉      | 197/500 [02:28<02:15,  2.24it/s] 40%|███▉      | 199/500 [02:28<01:40,  3.00it/s] 40%|████      | 201/500 [02:35<05:53,  1.18s/it] 41%|████      | 203/500 [02:35<04:12,  1.18it/s] 41%|████      | 205/500 [02:35<03:01,  1.63it/s]0.0012176670134067535
Epoch:  139  	Training Loss: 0.0010970147559419274
Test Loss:  0.0007112369639798999
Valid Loss:  0.0012176859891042113
Epoch:  140  	Training Loss: 0.0010969501454383135
Test Loss:  0.0007116785272955894
Valid Loss:  0.0012187587562948465
Epoch:  141  	Training Loss: 0.0010968883289024234
Test Loss:  0.0007117909844964743
Valid Loss:  0.0012188852997496724
Epoch:  142  	Training Loss: 0.0010968303540721536
Test Loss:  0.0007010027766227722
Valid Loss:  0.0012256450718268752
Epoch:  143  	Training Loss: 0.0010647689923644066
Test Loss:  0.0006954984273761511
Valid Loss:  0.0012300285743549466
Epoch:  144  	Training Loss: 0.0010463886428624392
Test Loss:  0.0006898660794831812
Valid Loss:  0.0012246121186763048
Epoch:  145  	Training Loss: 0.001029171864502132
Test Loss:  0.0006926287896931171
Valid Loss:  0.0012307234574109316
Epoch:  146  	Training Loss: 0.0010241959244012833
Test Loss:  0.0006915610283613205
Valid Loss:  0.0012329870369285345
Epoch:  147  	Training Loss: 0.0010202833218500018
Test Loss:  0.0006897320272400975
Valid Loss:  0.0012323223054409027
Epoch:  148  	Training Loss: 0.0010167015716433525
Test Loss:  0.0006885341135784984
Valid Loss:  0.0012311526807025075
Epoch:  149  	Training Loss: 0.0010135696502402425
Test Loss:  0.0006860371795482934
Valid Loss:  0.0012285819975659251
Epoch:  150  	Training Loss: 0.0010100739309564233
Test Loss:  0.000684011378325522
Valid Loss:  0.0012259013019502163
Epoch:  151  	Training Loss: 0.0010068099945783615
Test Loss:  0.0006812806241214275
Valid Loss:  0.001222941093146801
Epoch:  152  	Training Loss: 0.0010039121843874454
Test Loss:  0.0006699220975860953
Valid Loss:  0.0011853799223899841
Epoch:  153  	Training Loss: 0.0010018873726949096
Test Loss:  0.0006603387300856411
Valid Loss:  0.0011649689404293895
Epoch:  154  	Training Loss: 0.0009724791161715984
Test Loss:  0.0006587844109162688
Valid Loss:  0.0011844842229038477
Epoch:  155  	Training Loss: 0.0009672380983829498
Test Loss:  0.0006602115463465452
Valid Loss:  0.0011827184353023767
Epoch:  156  	Training Loss: 0.0009653407614678144
Test Loss:  0.0006616267492063344
Valid Loss:  0.0011905727442353964
Epoch:  157  	Training Loss: 0.0009651447180658579
Test Loss:  0.0006614153971895576
Valid Loss:  0.001184264663606882
Epoch:  158  	Training Loss: 0.0009650961728766561
Test Loss:  0.0006614916492253542
Valid Loss:  0.0011914661154150963
Epoch:  159  	Training Loss: 0.0009650849970057607
Test Loss:  0.0006612491561099887
Valid Loss:  0.0011828950373455882
Epoch:  160  	Training Loss: 0.0009651795262470841
Test Loss:  0.0006610013078898191
Valid Loss:  0.0011907289735972881
Epoch:  161  	Training Loss: 0.0009647418046370149
Test Loss:  0.0006609660340473056
Valid Loss:  0.0011837012134492397
Epoch:  162  	Training Loss: 0.000964712118729949
Test Loss:  0.000647597829811275
Valid Loss:  0.001171325333416462
Epoch:  163  	Training Loss: 0.0009560271282680333
Test Loss:  0.0006410209462046623
Valid Loss:  0.0011638852301985025
Epoch:  164  	Training Loss: 0.0009513961849734187
Test Loss:  0.0006346239824779332
Valid Loss:  0.0011571352370083332
Epoch:  165  	Training Loss: 0.0009483360918238759
Test Loss:  0.0006324616260826588
Valid Loss:  0.0011516786180436611
Epoch:  166  	Training Loss: 0.0009454631363041699
Test Loss:  0.0006277890643104911
Valid Loss:  0.0011450306046754122
Epoch:  167  	Training Loss: 0.0009424755116924644
Test Loss:  0.0006237181951291859
Valid Loss:  0.0011387361446395516
Epoch:  168  	Training Loss: 0.0009404282900504768
Test Loss:  0.0006213535089045763
Valid Loss:  0.0011334895389154553
Epoch:  169  	Training Loss: 0.0009385306038893759
Test Loss:  0.0006178681505843997
Valid Loss:  0.001127653056755662
Epoch:  170  	Training Loss: 0.0009365472360514104
Test Loss:  0.0006145506631582975
Valid Loss:  0.001121977111324668
Epoch:  171  	Training Loss: 0.0009350399486720562
Test Loss:  0.000612774514593184
Valid Loss:  0.0011175742838531733
Epoch:  172  	Training Loss: 0.0009337843512184918
Test Loss:  0.0006145866354927421
Valid Loss:  0.0011246101930737495
Epoch:  173  	Training Loss: 0.000931649177800864
Test Loss:  0.0006151295965537429
Valid Loss:  0.0011274521239101887
Epoch:  174  	Training Loss: 0.0009299969533458352
Test Loss:  0.0006152894347906113
Valid Loss:  0.0011289555113762617
Epoch:  175  	Training Loss: 0.000928591878619045
Test Loss:  0.0006153248832561076
Valid Loss:  0.0011299512116238475
Epoch:  176  	Training Loss: 0.0009273677133023739
Test Loss:  0.0006152971182018518
Valid Loss:  0.0011306765954941511
Epoch:  177  	Training Loss: 0.0009262837702408433
Test Loss:  0.0006152194691821933
Valid Loss:  0.0011312119895592332
Epoch:  178  	Training Loss: 0.0009253067546524107
Test Loss:  0.0006150939734652638
Valid Loss:  0.0011315826559439301
Epoch:  179  	Training Loss: 0.0009244148968718946
Test Loss:  0.0006149164400994778
Valid Loss:  0.0011318064061924815
Epoch:  180  	Training Loss: 0.0009235889883711934
Test Loss:  0.0006146900122985244
Valid Loss:  0.0011319015175104141
Epoch:  181  	Training Loss: 0.0009228148264810443
Test Loss:  0.0006144169019535184
Valid Loss:  0.0011318773031234741
Epoch:  182  	Training Loss: 0.0009220823994837701
Test Loss:  0.0005902748089283705
Valid Loss:  0.0010976712219417095
Epoch:  183  	Training Loss: 0.0009024458704516292
Test Loss:  0.0005790904397144914
Valid Loss:  0.0010719472775235772
Epoch:  184  	Training Loss: 0.0008899631211534142
Test Loss:  0.0005686662625521421
Valid Loss:  0.0010502245277166367
Epoch:  185  	Training Loss: 0.00087933917529881
Test Loss:  0.0005608260398730636
Valid Loss:  0.0010319799184799194
Epoch:  186  	Training Loss: 0.0008700966718606651
Test Loss:  0.0005537469405680895
Valid Loss:  0.001016323221847415
Epoch:  187  	Training Loss: 0.0008616730920039117
Test Loss:  0.0005481332773342729
Valid Loss:  0.0010025633964687586
Epoch:  188  	Training Loss: 0.0008537393296137452
Test Loss:  0.0005425299168564379
Valid Loss:  0.0009901875164359808
Epoch:  189  	Training Loss: 0.0008462761179544032
Test Loss:  0.0005378404748626053
Valid Loss:  0.0009786660084500909
Epoch:  190  	Training Loss: 0.0008390698349103332
Test Loss:  0.000533021055161953
Valid Loss:  0.0009677767520770431
Epoch:  191  	Training Loss: 0.0008320902707055211
Test Loss:  0.0005288943066261709
Valid Loss:  0.0009574571740813553
Epoch:  192  	Training Loss: 0.0008253059349954128
Test Loss:  0.0005271414993330836
Valid Loss:  0.0009534528362564743
Epoch:  193  	Training Loss: 0.0008249066886492074
Test Loss:  0.00052599236369133
Valid Loss:  0.0009507301729172468
Epoch:  194  	Training Loss: 0.000824710528831929
Test Loss:  0.0005252286209724844
Valid Loss:  0.0009488614741712809
Epoch:  195  	Training Loss: 0.0008246152428910136
Test Loss:  0.00052471092203632
Valid Loss:  0.0009475724073126912
Epoch:  196  	Training Loss: 0.0008245676290243864
Test Loss:  0.0005243576597422361
Valid Loss:  0.0009466794435866177
Epoch:  197  	Training Loss: 0.000824544345960021
Test Loss:  0.0005241159233264625
Valid Loss:  0.0009460578439757228
Epoch:  198  	Training Loss: 0.0008245339849963784
Test Loss:  0.0005239470629021525
Valid Loss:  0.0009456230327486992
Epoch:  199  	Training Loss: 0.0008245279313996434
Test Loss:  0.0005238314624875784
Valid Loss:  0.000945322506595403
Epoch:  200  	Training Loss: 0.0008245257195085287
Test Loss:  0.0005237489240244031
Valid Loss:  0.0009451097575947642
Epoch:  201  	Training Loss: 0.0008245240314863622
Test Loss:  0.0005236933939158916
Valid Loss:  0.0009449594072066247
Epoch:  202  	Training Loss: 0.0008245231583714485
Test Loss:  0.0005235677235759795
Valid Loss:  0.0009448176133446395
Epoch:  203  	Training Loss: 0.0008244994096457958
Test Loss:  0.0005234415293671191
Valid Loss:  0.0009446165058761835
Epoch:  204  	Training Loss: 0.0008244838682003319
Test Loss:  0.0005233151605352759
Valid Loss:  0.0009443835588172078
Epoch:  205  	Training Loss: 0.0008244731579907238
Test Loss:  0.000523190654348582
Valid Loss:  0.0009441368747502565
Epoch:  206  	Training Loss: 0.0008244635537266731
Test Loss:  0.0005230678361840546
Valid Loss:  0.0009438837878406048
 41%|████▏     | 207/500 [02:35<02:11,  2.22it/s] 42%|████▏     | 209/500 [02:35<01:37,  2.99it/s] 42%|████▏     | 211/500 [02:41<05:37,  1.17s/it] 43%|████▎     | 213/500 [02:41<04:00,  1.19it/s] 43%|████▎     | 215/500 [02:42<02:52,  1.65it/s] 43%|████▎     | 217/500 [02:42<02:05,  2.25it/s] 44%|████▍     | 219/500 [02:42<01:32,  3.03it/s] 44%|████▍     | 221/500 [02:48<05:22,  1.16s/it] 45%|████▍     | 223/500 [02:48<03:50,  1.20it/s] 45%|████▌     | 225/500 [02:48<02:45,  1.66it/s] 45%|████▌     | 227/500 [02:48<02:00,  2.27it/s] 46%|████▌     | 229/500 [02:49<01:28,  3.05it/s] 46%|████▌     | 231/500 [02:55<05:18,  1.18s/it] 47%|████▋     | 233/500 [02:55<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:55<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:55<01:58,  2.22it/s] 48%|████▊     | 239/500 [02:55<01:28,  2.95it/s] 48%|████▊     | 241/500 [03:02<05:02,  1.17s/it] 49%|████▊     | 243/500 [03:02<03:35,  1.19it/s] 49%|████▉     | 245/500 [03:02<02:34,  1.65it/s] 49%|████▉     | 247/500 [03:02<01:52,  2.25it/s] 50%|████▉     | 249/500 [03:02<01:22,  3.03it/s] 50%|█████     | 251/500 [03:08<04:50,  1.17s/it] 51%|█████     | 253/500 [03:09<03:27,  1.19it/s] 51%|█████     | 255/500 [03:09<02:28,  1.65it/s] 51%|█████▏    | 257/500 [03:09<01:47,  2.25it/s] 52%|█████▏    | 259/500 [03:09<01:19,  3.02it/s] 52%|█████▏    | 261/500 [03:15<04:40,  1.18s/it] 53%|█████▎    | 263/500 [03:15<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:16<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:16<01:43,  2.24it/s] 54%|█████▍    | 269/500 [03:16<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:22<04:26,  1.16s/it] 55%|█████▍    | 273/500 [03:22<03:09,  1.20it/s]Epoch:  207  	Training Loss: 0.0008244571508839726
Test Loss:  0.0005229489179328084
Valid Loss:  0.0009436277905479074
Epoch:  208  	Training Loss: 0.0008244494092650712
Test Loss:  0.0005228332011029124
Valid Loss:  0.0009433791856281459
Epoch:  209  	Training Loss: 0.000824444112367928
Test Loss:  0.0005227238871157169
Valid Loss:  0.000943140359595418
Epoch:  210  	Training Loss: 0.0008244384080171585
Test Loss:  0.0005226189969107509
Valid Loss:  0.0009429068304598331
Epoch:  211  	Training Loss: 0.0008244339842349291
Test Loss:  0.0005225175991654396
Valid Loss:  0.0009426833712495863
Epoch:  212  	Training Loss: 0.0008244294440373778
Test Loss:  0.0005224401247687638
Valid Loss:  0.0009425000753253698
Epoch:  213  	Training Loss: 0.0008242449839599431
Test Loss:  0.0005223671905696392
Valid Loss:  0.0009423249284736812
Epoch:  214  	Training Loss: 0.0008240630268119276
Test Loss:  0.0005222987965680659
Valid Loss:  0.0009421603754162788
Epoch:  215  	Training Loss: 0.000823882466647774
Test Loss:  0.0005222295876592398
Valid Loss:  0.0009420029236935079
Epoch:  216  	Training Loss: 0.0008237045258283615
Test Loss:  0.0005221642786636949
Valid Loss:  0.0009418509434908628
Epoch:  217  	Training Loss: 0.0008235284476540983
Test Loss:  0.000522100308444351
Valid Loss:  0.00094170356169343
Epoch:  218  	Training Loss: 0.0008233533590100706
Test Loss:  0.0005220395978540182
Valid Loss:  0.0009415607200935483
Epoch:  219  	Training Loss: 0.0008231803076341748
Test Loss:  0.0005219787126407027
Valid Loss:  0.0009414209052920341
Epoch:  220  	Training Loss: 0.0008230102830566466
Test Loss:  0.0005219195154495537
Valid Loss:  0.0009412852232344449
Epoch:  221  	Training Loss: 0.0008228399092331529
Test Loss:  0.0005218609003350139
Valid Loss:  0.0009411501814611256
Epoch:  222  	Training Loss: 0.0008226730860769749
Test Loss:  0.0005218307487666607
Valid Loss:  0.0009410759666934609
Epoch:  223  	Training Loss: 0.000822501489892602
Test Loss:  0.0005217987345531583
Valid Loss:  0.0009410008206032217
Epoch:  224  	Training Loss: 0.0008221740135923028
Test Loss:  0.0005217672442086041
Valid Loss:  0.0009409253252670169
Epoch:  225  	Training Loss: 0.0008218504372052848
Test Loss:  0.0005217338330112398
Valid Loss:  0.0009408469777554274
Epoch:  226  	Training Loss: 0.0008215246489271522
Test Loss:  0.0005217017605900764
Valid Loss:  0.0009407680481672287
Epoch:  227  	Training Loss: 0.0008209926309064031
Test Loss:  0.0005216675344854593
Valid Loss:  0.0009406828321516514
Epoch:  228  	Training Loss: 0.0008204698096960783
Test Loss:  0.0005216301651671529
Valid Loss:  0.0009405955788679421
Epoch:  229  	Training Loss: 0.0008198829600587487
Test Loss:  0.000521593727171421
Valid Loss:  0.0009405035525560379
Epoch:  230  	Training Loss: 0.0008191111846826971
Test Loss:  0.000521552748978138
Valid Loss:  0.0009404026786796749
Epoch:  231  	Training Loss: 0.0008183550671674311
Test Loss:  0.0005215093842707574
Valid Loss:  0.0009402970317751169
Epoch:  232  	Training Loss: 0.0008175137336365879
Test Loss:  0.0005200319574214518
Valid Loss:  0.0009372734348289669
Epoch:  233  	Training Loss: 0.000816253712400794
Test Loss:  0.0005187881179153919
Valid Loss:  0.0009348486200906336
Epoch:  234  	Training Loss: 0.0008150344947353005
Test Loss:  0.0005176748381927609
Valid Loss:  0.0009327477309852839
Epoch:  235  	Training Loss: 0.0008138394914567471
Test Loss:  0.0005166385089978576
Valid Loss:  0.0009308360749855638
Epoch:  236  	Training Loss: 0.0008126659085974097
Test Loss:  0.0005156544502824545
Valid Loss:  0.0009290411835536361
Epoch:  237  	Training Loss: 0.0008115123491734266
Test Loss:  0.0005147070623934269
Valid Loss:  0.0009273262112401426
Epoch:  238  	Training Loss: 0.0008103761356323957
Test Loss:  0.0005137889529578388
Valid Loss:  0.0009256725898012519
Epoch:  239  	Training Loss: 0.0008092594216577709
Test Loss:  0.0005128978518769145
Valid Loss:  0.0009240657091140747
Epoch:  240  	Training Loss: 0.0008081598207354546
Test Loss:  0.0005120302084833384
Valid Loss:  0.0009225045796483755
Epoch:  241  	Training Loss: 0.0008070773910731077
Test Loss:  0.0005111828213557601
Valid Loss:  0.000920982682146132
Epoch:  242  	Training Loss: 0.0008060111431404948
Test Loss:  0.0005112062208354473
Valid Loss:  0.0009210461284965277
Epoch:  243  	Training Loss: 0.0008060096297413111
Test Loss:  0.000511227990500629
Valid Loss:  0.0009211067808791995
Epoch:  244  	Training Loss: 0.0008060086402110755
Test Loss:  0.0005112505750730634
Valid Loss:  0.0009211624274030328
Epoch:  245  	Training Loss: 0.00080600765068084
Test Loss:  0.0005112706567160785
Valid Loss:  0.0009212173754349351
Epoch:  246  	Training Loss: 0.0008060068357735872
Test Loss:  0.0005112904473207891
Valid Loss:  0.0009212697623297572
Epoch:  247  	Training Loss: 0.0008060066029429436
Test Loss:  0.0005113092483952641
Valid Loss:  0.0009213192970491946
Epoch:  248  	Training Loss: 0.0008060059044510126
Test Loss:  0.0005113257793709636
Valid Loss:  0.0009213655721396208
Epoch:  249  	Training Loss: 0.0008060052641667426
Test Loss:  0.0005113435909152031
Valid Loss:  0.000921409809961915
Epoch:  250  	Training Loss: 0.0008060041582211852
Test Loss:  0.0005113602965138853
Valid Loss:  0.0009214511374011636
Epoch:  251  	Training Loss: 0.0008060035761445761
Test Loss:  0.0005113756051287055
Valid Loss:  0.0009214929305016994
Epoch:  252  	Training Loss: 0.0008060033433139324
Test Loss:  0.0005163198802620173
Valid Loss:  0.0009378017857670784
Epoch:  253  	Training Loss: 0.0008014504564926028
Test Loss:  0.000513691280502826
Valid Loss:  0.0009334404021501541
Epoch:  254  	Training Loss: 0.0007982265669852495
Test Loss:  0.0005153392557986081
Valid Loss:  0.0009390844497829676
Epoch:  255  	Training Loss: 0.0007958184578455985
Test Loss:  0.0005155153921805322
Valid Loss:  0.0009402403375133872
Epoch:  256  	Training Loss: 0.0007939260685816407
Test Loss:  0.000516488857101649
Valid Loss:  0.0009430625941604376
Epoch:  257  	Training Loss: 0.0007924485253170133
Test Loss:  0.0005173181416466832
Valid Loss:  0.0009451853111386299
Epoch:  258  	Training Loss: 0.000791263475548476
Test Loss:  0.0005181425949558616
Valid Loss:  0.0009471004013903439
Epoch:  259  	Training Loss: 0.0007903561927378178
Test Loss:  0.0005189317744225264
Valid Loss:  0.000948814325965941
Epoch:  260  	Training Loss: 0.000789655139669776
Test Loss:  0.0005196647252887487
Valid Loss:  0.000950323767028749
Epoch:  261  	Training Loss: 0.0007891059503890574
Test Loss:  0.0005203292239457369
Valid Loss:  0.000951644906308502
Epoch:  262  	Training Loss: 0.0007886698585934937
Test Loss:  0.0005190797382965684
Valid Loss:  0.0009509214432910085
Epoch:  263  	Training Loss: 0.0007876735180616379
Test Loss:  0.0005174065008759499
Valid Loss:  0.0009464834583923221
Epoch:  264  	Training Loss: 0.0007865456282161176
Test Loss:  0.0005171042284928262
Valid Loss:  0.0009480701992288232
Epoch:  265  	Training Loss: 0.0007853402057662606
Test Loss:  0.0005144666647538543
Valid Loss:  0.0009415253298357129
Epoch:  266  	Training Loss: 0.0007843804196454585
Test Loss:  0.0005146689945831895
Valid Loss:  0.0009442336740903556
Epoch:  267  	Training Loss: 0.0007833824492990971
Test Loss:  0.0005121103022247553
Valid Loss:  0.0009371933992952108
Epoch:  268  	Training Loss: 0.0007824912900105119
Test Loss:  0.000512884056661278
Valid Loss:  0.0009413997759111226
Epoch:  269  	Training Loss: 0.0007814452983438969
Test Loss:  0.0005098007386550307
Valid Loss:  0.0009330734610557556
Epoch:  270  	Training Loss: 0.0007806352223269641
Test Loss:  0.0005108973709866405
Valid Loss:  0.0009380600531585515
Epoch:  271  	Training Loss: 0.0007797249127179384
Test Loss:  0.0005079255788587034
Valid Loss:  0.0009295117342844605
Epoch:  272  	Training Loss: 0.0007790166418999434
Test Loss:  0.0005079304100945592
Valid Loss:  0.0009295308846049011
Epoch:  273  	Training Loss: 0.0007790161180309951
Test Loss:  0.0005079373950138688
Valid Loss:  0.0009295496274717152
Epoch:  274  	Training Loss: 0.0007790158269926906
Test Loss:  0.0005079415859654546
Valid Loss:  0.0009295659838244319
Epoch:  275  	Training Loss: 0.0007790153613314033
 55%|█████▌    | 275/500 [03:22<02:15,  1.65it/s] 55%|█████▌    | 277/500 [03:22<01:38,  2.26it/s] 56%|█████▌    | 279/500 [03:23<01:12,  3.04it/s] 56%|█████▌    | 279/500 [03:34<01:12,  3.04it/s] 56%|█████▌    | 281/500 [03:35<07:35,  2.08s/it] 57%|█████▋    | 283/500 [03:35<05:20,  1.48s/it] 57%|█████▋    | 285/500 [03:35<03:46,  1.05s/it] 57%|█████▋    | 287/500 [03:35<02:41,  1.32it/s] 58%|█████▊    | 289/500 [03:35<01:55,  1.82it/s] 58%|█████▊    | 291/500 [03:42<04:38,  1.33s/it] 59%|█████▊    | 293/500 [03:42<03:17,  1.05it/s] 59%|█████▉    | 295/500 [03:42<02:20,  1.46it/s] 59%|█████▉    | 297/500 [03:42<01:41,  2.00it/s] 60%|█████▉    | 299/500 [03:42<01:14,  2.71it/s] 60%|██████    | 301/500 [03:49<03:57,  1.19s/it] 61%|██████    | 303/500 [03:49<02:48,  1.17it/s] 61%|██████    | 305/500 [03:49<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:49<01:27,  2.20it/s] 62%|██████▏   | 309/500 [03:49<01:04,  2.96it/s] 62%|██████▏   | 311/500 [03:55<03:40,  1.17s/it] 63%|██████▎   | 313/500 [03:55<02:36,  1.19it/s] 63%|██████▎   | 315/500 [03:56<01:52,  1.65it/s] 63%|██████▎   | 317/500 [03:56<01:21,  2.25it/s] 64%|██████▍   | 319/500 [03:56<01:00,  3.01it/s] 64%|██████▍   | 321/500 [04:02<03:29,  1.17s/it] 65%|██████▍   | 323/500 [04:02<02:28,  1.19it/s] 65%|██████▌   | 325/500 [04:02<01:46,  1.64it/s] 65%|██████▌   | 327/500 [04:02<01:17,  2.25it/s] 66%|██████▌   | 329/500 [04:03<00:56,  3.01it/s] 66%|██████▌   | 331/500 [04:09<03:16,  1.16s/it] 67%|██████▋   | 333/500 [04:09<02:19,  1.20it/s] 67%|██████▋   | 335/500 [04:09<01:39,  1.65it/s] 67%|██████▋   | 337/500 [04:09<01:12,  2.25it/s] 68%|██████▊   | 339/500 [04:09<00:53,  3.02it/s] 68%|██████▊   | 341/500 [04:16<03:06,  1.17s/it]Test Loss:  0.0005079472321085632
Valid Loss:  0.0009295856580138206
Epoch:  276  	Training Loss: 0.0007790152449160814
Test Loss:  0.0005079512484371662
Valid Loss:  0.000929602945689112
Epoch:  277  	Training Loss: 0.0007790153613314033
Test Loss:  0.0005079579423181713
Valid Loss:  0.0009296189527958632
Epoch:  278  	Training Loss: 0.0007790146628394723
Test Loss:  0.0005079632392153144
Valid Loss:  0.0009296353673562407
Epoch:  279  	Training Loss: 0.0007790140807628632
Test Loss:  0.0005079662660136819
Valid Loss:  0.0009296530624851584
Epoch:  280  	Training Loss: 0.0007790137315168977
Test Loss:  0.0005079724942333996
Valid Loss:  0.0009296700591221452
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.0007790133822709322
Test Loss:  0.0005070460611023009
Valid Loss:  0.0009289992740377784
Epoch:  282  	Training Loss: 0.0007786067435517907
Test Loss:  0.0005071517080068588
Valid Loss:  0.0009284559055231512
Epoch:  283  	Training Loss: 0.0007767691859044135
Test Loss:  0.0005071664345450699
Valid Loss:  0.0009275801130570471
Epoch:  284  	Training Loss: 0.0007750060176476836
Test Loss:  0.0005071155610494316
Valid Loss:  0.0009264715481549501
Epoch:  285  	Training Loss: 0.0007732998346909881
Test Loss:  0.0005070205079391599
Valid Loss:  0.0009252064628526568
Epoch:  286  	Training Loss: 0.000771643128246069
Test Loss:  0.0005068975151516497
Valid Loss:  0.0009238375350832939
Epoch:  287  	Training Loss: 0.0007700287387706339
Test Loss:  0.0005067588062956929
Valid Loss:  0.0009224052191711962
Epoch:  288  	Training Loss: 0.0007684020092710853
Test Loss:  0.0005066301673650742
Valid Loss:  0.000920914055313915
Epoch:  289  	Training Loss: 0.0007666748133487999
Test Loss:  0.0005064972792752087
Valid Loss:  0.0009193893638439476
Epoch:  290  	Training Loss: 0.0007649906910955906
Test Loss:  0.0005063643911853433
Valid Loss:  0.0009178472100757062
Epoch:  291  	Training Loss: 0.0007633473724126816
Test Loss:  0.0005062343552708626
Valid Loss:  0.0009163027280010283
Epoch:  292  	Training Loss: 0.0007617411902174354
Test Loss:  0.000502834445796907
Valid Loss:  0.0009118556627072394
Epoch:  293  	Training Loss: 0.0007594112539663911
Test Loss:  0.0005008443258702755
Valid Loss:  0.0009091541287489235
Epoch:  294  	Training Loss: 0.000758221372961998
Test Loss:  0.0004996795323677361
Valid Loss:  0.0009079754236154258
Epoch:  295  	Training Loss: 0.0007576305652037263
Test Loss:  0.0004988026339560747
Valid Loss:  0.000907278445083648
Epoch:  296  	Training Loss: 0.0007572488393634558
Test Loss:  0.0004981862148270011
Valid Loss:  0.0009068532381206751
Epoch:  297  	Training Loss: 0.000757005880586803
Test Loss:  0.0004976969212293625
Valid Loss:  0.0009065065532922745
Epoch:  298  	Training Loss: 0.0007568283472210169
Test Loss:  0.0004973025061190128
Valid Loss:  0.0009062136523425579
Epoch:  299  	Training Loss: 0.0007566956337541342
Test Loss:  0.0004969755536876619
Valid Loss:  0.0009059568983502686
Epoch:  300  	Training Loss: 0.000756608322262764
Test Loss:  0.0004967461572960019
Valid Loss:  0.0009057404240593314
Epoch:  301  	Training Loss: 0.0007565582054667175
Test Loss:  0.0004965870757587254
Valid Loss:  0.0009055514237843454
Epoch:  302  	Training Loss: 0.0007565190317109227
Test Loss:  0.0004950210568495095
Valid Loss:  0.0009020561701618135
Epoch:  303  	Training Loss: 0.0007559129735454917
Test Loss:  0.0004937658086419106
Valid Loss:  0.0008991692448034883
Epoch:  304  	Training Loss: 0.00075547955930233
Test Loss:  0.0004927471745759249
Valid Loss:  0.0008967643370851874
Epoch:  305  	Training Loss: 0.0007551659946329892
Test Loss:  0.0004919074126519263
Valid Loss:  0.0008947474998421967
Epoch:  306  	Training Loss: 0.0007549357251264155
Test Loss:  0.0004912035074084997
Valid Loss:  0.0008930431795306504
Epoch:  307  	Training Loss: 0.0007547630812041461
Test Loss:  0.0004906104295514524
Valid Loss:  0.0008915863581933081
Epoch:  308  	Training Loss: 0.0007546301931142807
Test Loss:  0.0004901007050648332
Valid Loss:  0.0008903333800844848
Epoch:  309  	Training Loss: 0.0007545262342318892
Test Loss:  0.0004896579775959253
Valid Loss:  0.0008892468176782131
Epoch:  310  	Training Loss: 0.0007544396794401109
Test Loss:  0.000489268742967397
Valid Loss:  0.0008882980910129845
Epoch:  311  	Training Loss: 0.0007543675019405782
Test Loss:  0.0004889232804998755
Valid Loss:  0.0008874607738107443
Epoch:  312  	Training Loss: 0.0007543061510659754
Test Loss:  0.0004875964659731835
Valid Loss:  0.0008846612181514502
Epoch:  313  	Training Loss: 0.0007534564938396215
Test Loss:  0.0004864863003604114
Valid Loss:  0.0008824171382002532
Epoch:  314  	Training Loss: 0.0007526605040766299
Test Loss:  0.0004855229053646326
Valid Loss:  0.0008805595571175218
Epoch:  315  	Training Loss: 0.0007518933271057904
Test Loss:  0.00048466023872606456
Valid Loss:  0.0008789669955149293
Epoch:  316  	Training Loss: 0.000751143554225564
Test Loss:  0.00048386535490863025
Valid Loss:  0.0008775603491812944
Epoch:  317  	Training Loss: 0.0007504067616537213
Test Loss:  0.00048311788123100996
Valid Loss:  0.0008762849611230195
Epoch:  318  	Training Loss: 0.0007496786420233548
Test Loss:  0.0004824084753636271
Valid Loss:  0.0008751045679673553
Epoch:  319  	Training Loss: 0.0007489575073122978
Test Loss:  0.00048172418610192835
Valid Loss:  0.000873989425599575
Epoch:  320  	Training Loss: 0.0007482428336516023
Test Loss:  0.0004810599493794143
Valid Loss:  0.0008729257970117033
Epoch:  321  	Training Loss: 0.0007475352613255382
Test Loss:  0.0004804119234904647
Valid Loss:  0.0008719000034034252
Epoch:  322  	Training Loss: 0.0007468346739187837
Test Loss:  0.00047877305769361556
Valid Loss:  0.0008620527805760503
Epoch:  323  	Training Loss: 0.0007381540490314364
Test Loss:  0.00047682924196124077
Valid Loss:  0.0008633745601400733
Epoch:  324  	Training Loss: 0.0007357154390774667
Test Loss:  0.0004764005134347826
Valid Loss:  0.0008644405170343816
Epoch:  325  	Training Loss: 0.0007345324847847223
Test Loss:  0.0004762224853038788
Valid Loss:  0.0008650521049275994
Epoch:  326  	Training Loss: 0.0007336291600950062
Test Loss:  0.00047601613914594054
Valid Loss:  0.0008653007680550218
Epoch:  327  	Training Loss: 0.0007328467909246683
Test Loss:  0.0004757970164064318
Valid Loss:  0.0008653074619360268
Epoch:  328  	Training Loss: 0.0007321340381167829
Test Loss:  0.0004755633417516947
Valid Loss:  0.0008651390671730042
Epoch:  329  	Training Loss: 0.0007314555696211755
Test Loss:  0.00047534643090330064
Valid Loss:  0.0008648596704006195
Epoch:  330  	Training Loss: 0.0007308018975891173
Test Loss:  0.00047513871686533093
Valid Loss:  0.0008644971530884504
Epoch:  331  	Training Loss: 0.0007301460718736053
Test Loss:  0.00047496019396930933
Valid Loss:  0.0008640041342005134
Epoch:  332  	Training Loss: 0.0007294109091162682
Test Loss:  0.00047338363947346807
Valid Loss:  0.0008624764159321785
Epoch:  333  	Training Loss: 0.0007266525644809008
Test Loss:  0.000471682520583272
Valid Loss:  0.0008608194766566157
Epoch:  334  	Training Loss: 0.0007235623197630048
Test Loss:  0.00047001667553558946
Valid Loss:  0.0008591841906309128
Epoch:  335  	Training Loss: 0.0007204186404123902
Test Loss:  0.00046823639422655106
Valid Loss:  0.0008574287639930844
Epoch:  336  	Training Loss: 0.0007169249001890421
Test Loss:  0.0004664949083235115
Valid Loss:  0.0008556979591958225
Epoch:  337  	Training Loss: 0.0007135173655115068
Test Loss:  0.0004642977728508413
Valid Loss:  0.0008539954433217645
Epoch:  338  	Training Loss: 0.0007101929513737559
Test Loss:  0.00046209938591346145
Valid Loss:  0.0008523169672116637
Epoch:  339  	Training Loss: 0.0007067866390570998
Test Loss:  0.0004596056242007762
Valid Loss:  0.0008504051947966218
Epoch:  340  	Training Loss: 0.0007024839287623763
Test Loss:  0.0004570902674458921
Valid Loss:  0.0008484609425067902
Epoch:  341  	Training Loss: 0.0006980395410209894
Test Loss:  0.0004546371928881854
Valid Loss:  0.0008465478895232081
Epoch:  342  	Training Loss: 0.0006936828722245991
Test Loss:   69%|██████▊   | 343/500 [04:16<02:11,  1.19it/s] 69%|██████▉   | 345/500 [04:16<01:34,  1.65it/s] 69%|██████▉   | 347/500 [04:16<01:07,  2.25it/s] 70%|██████▉   | 349/500 [04:16<00:49,  3.03it/s] 70%|███████   | 351/500 [04:22<02:53,  1.17s/it] 71%|███████   | 353/500 [04:22<02:03,  1.19it/s] 71%|███████   | 355/500 [04:23<01:27,  1.65it/s] 71%|███████▏  | 357/500 [04:23<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:23<00:46,  3.01it/s] 72%|███████▏  | 361/500 [04:29<02:44,  1.18s/it] 73%|███████▎  | 363/500 [04:29<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:29<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:30<01:00,  2.20it/s] 74%|███████▍  | 369/500 [04:30<00:44,  2.97it/s] 74%|███████▍  | 371/500 [04:36<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:36<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:36<01:17,  1.62it/s] 75%|███████▌  | 377/500 [04:37<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:37<00:40,  2.97it/s] 76%|███████▌  | 381/500 [04:49<04:08,  2.09s/it] 77%|███████▋  | 383/500 [04:49<02:53,  1.48s/it] 77%|███████▋  | 385/500 [04:49<02:01,  1.06s/it] 77%|███████▋  | 387/500 [04:49<01:25,  1.32it/s] 78%|███████▊  | 389/500 [04:50<01:01,  1.81it/s] 78%|███████▊  | 391/500 [04:56<02:25,  1.33s/it] 79%|███████▊  | 393/500 [04:56<01:42,  1.05it/s] 79%|███████▉  | 395/500 [04:56<01:12,  1.45it/s] 79%|███████▉  | 397/500 [04:56<00:51,  2.00it/s] 80%|███████▉  | 399/500 [04:56<00:37,  2.70it/s] 80%|████████  | 401/500 [05:03<01:58,  1.19s/it] 81%|████████  | 403/500 [05:03<01:23,  1.17it/s] 81%|████████  | 405/500 [05:03<00:58,  1.61it/s] 81%|████████▏ | 407/500 [05:03<00:42,  2.21it/s]0.0004494876484386623
Valid Loss:  0.0008390649454668164
Epoch:  343  	Training Loss: 0.0006894727703183889
Test Loss:  0.0004454496083781123
Valid Loss:  0.0008325679809786379
Epoch:  344  	Training Loss: 0.0006861252477392554
Test Loss:  0.00044220522977411747
Valid Loss:  0.0008269225945696235
Epoch:  345  	Training Loss: 0.0006833963561803102
Test Loss:  0.00043949432438239455
Valid Loss:  0.0008219610899686813
Epoch:  346  	Training Loss: 0.0006810639752075076
Test Loss:  0.00043716939399018884
Valid Loss:  0.000817556050606072
Epoch:  347  	Training Loss: 0.0006790043553337455
Test Loss:  0.00043512083357200027
Valid Loss:  0.0008136110263876617
Epoch:  348  	Training Loss: 0.0006771201151423156
Test Loss:  0.0004332768148742616
Valid Loss:  0.0008100474951788783
Epoch:  349  	Training Loss: 0.000675358809530735
Test Loss:  0.00043161064968444407
Valid Loss:  0.0008068017777986825
Epoch:  350  	Training Loss: 0.0006736870273016393
Test Loss:  0.0004301245789974928
Valid Loss:  0.0008038951782509685
Epoch:  351  	Training Loss: 0.0006721211830154061
Test Loss:  0.0004287872579880059
Valid Loss:  0.0008012513862922788
Epoch:  352  	Training Loss: 0.0006706125568598509
Test Loss:  0.0004280675493646413
Valid Loss:  0.0007997400243766606
Epoch:  353  	Training Loss: 0.0006703402032144368
Test Loss:  0.00042745433165691793
Valid Loss:  0.0007984164403751493
Epoch:  354  	Training Loss: 0.0006701254169456661
Test Loss:  0.00042692729039117694
Valid Loss:  0.000797254906501621
Epoch:  355  	Training Loss: 0.0006699548684991896
Test Loss:  0.00042647134978324175
Valid Loss:  0.0007962314994074404
Epoch:  356  	Training Loss: 0.0006698197685182095
Test Loss:  0.00042607757495716214
Valid Loss:  0.0007953271851874888
Epoch:  357  	Training Loss: 0.0006697132484987378
Test Loss:  0.00042573659447953105
Valid Loss:  0.000794524559751153
Epoch:  358  	Training Loss: 0.0006696287891827524
Test Loss:  0.0004254360101185739
Valid Loss:  0.0007938138442113996
Epoch:  359  	Training Loss: 0.0006695614429190755
Test Loss:  0.00042517349356785417
Valid Loss:  0.0007931808358989656
Epoch:  360  	Training Loss: 0.0006695070769637823
Test Loss:  0.00042494104127399623
Valid Loss:  0.0007926119724288583
Epoch:  361  	Training Loss: 0.0006694640032947063
Test Loss:  0.0004247348406352103
Valid Loss:  0.0007921045180410147
Epoch:  362  	Training Loss: 0.000669429893605411
Test Loss:  0.0004247339675202966
Valid Loss:  0.0007920981151983142
Epoch:  363  	Training Loss: 0.0006694274488836527
Test Loss:  0.0004247328033670783
Valid Loss:  0.0007920929929241538
Epoch:  364  	Training Loss: 0.0006694251205772161
Test Loss:  0.00042473175562918186
Valid Loss:  0.000792088801972568
Epoch:  365  	Training Loss: 0.0006694239564239979
Test Loss:  0.00042473000939935446
Valid Loss:  0.000792083446867764
Epoch:  366  	Training Loss: 0.0006694228504784405
Test Loss:  0.00042473006760701537
Valid Loss:  0.0007920789648778737
Epoch:  367  	Training Loss: 0.0006694210460409522
Test Loss:  0.00042472872883081436
Valid Loss:  0.0007920755306258798
Epoch:  368  	Training Loss: 0.0006694194162264466
Test Loss:  0.00042472881614230573
Valid Loss:  0.0007920721545815468
Epoch:  369  	Training Loss: 0.0006694188341498375
Test Loss:  0.0004247267497703433
Valid Loss:  0.000792068662121892
Epoch:  370  	Training Loss: 0.000669417146127671
Test Loss:  0.0004247280885465443
Valid Loss:  0.000792065926361829
Epoch:  371  	Training Loss: 0.0006694162730127573
Test Loss:  0.000424726284109056
Valid Loss:  0.0007920616772025824
Epoch:  372  	Training Loss: 0.0006694154581055045
Test Loss:  0.00042472570203244686
Valid Loss:  0.0007920606294646859
Epoch:  373  	Training Loss: 0.0006694152252748609
Test Loss:  0.0004247264005243778
Valid Loss:  0.0007920616772025824
Epoch:  374  	Training Loss: 0.0006694148760288954
Test Loss:  0.0004247274191584438
Valid Loss:  0.0007920613279566169
Epoch:  375  	Training Loss: 0.0006694148760288954
Test Loss:  0.000424726284109056
Valid Loss:  0.0007920596981421113
Epoch:  376  	Training Loss: 0.0006694145849905908
Test Loss:  0.0004247275646775961
Valid Loss:  0.0007920608040876687
Epoch:  377  	Training Loss: 0.0006694145267829299
Test Loss:  0.00042472672066651285
Valid Loss:  0.0007920601638033986
Epoch:  378  	Training Loss: 0.0006694141775369644
Test Loss:  0.00042472657514736056
Valid Loss:  0.0007920591160655022
Epoch:  379  	Training Loss: 0.0006694145267829299
Test Loss:  0.0004247264878358692
Valid Loss:  0.0007920591160655022
Epoch:  380  	Training Loss: 0.0006694145267829299
Test Loss:  0.000424726604251191
Valid Loss:  0.0007920594653114676
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.000669414468575269
Test Loss:  0.00042409446905367076
Valid Loss:  0.0007912280852906406
Epoch:  382  	Training Loss: 0.0006676766788586974
Test Loss:  0.0004239415575284511
Valid Loss:  0.0007908220286481082
Epoch:  383  	Training Loss: 0.0006676670745946467
Test Loss:  0.00042381748789921403
Valid Loss:  0.0007904930971562862
Epoch:  384  	Training Loss: 0.0006676615448668599
Test Loss:  0.0004237180110067129
Valid Loss:  0.0007902249344624579
Epoch:  385  	Training Loss: 0.0006676572957076132
Test Loss:  0.00042363585089333355
Valid Loss:  0.0007900081109255552
Epoch:  386  	Training Loss: 0.0006676549091935158
Test Loss:  0.000423569290433079
Valid Loss:  0.0007898284820839763
Epoch:  387  	Training Loss: 0.0006676513585262001
Test Loss:  0.00042351469164714217
Valid Loss:  0.0007896850001998246
Epoch:  388  	Training Loss: 0.0006676499033346772
Test Loss:  0.00042347010457888246
Valid Loss:  0.0007895634043961763
Epoch:  389  	Training Loss: 0.0006676492630504072
Test Loss:  0.00042343413224443793
Valid Loss:  0.0007894663140177727
Epoch:  390  	Training Loss: 0.0006676478078588843
Test Loss:  0.0004234018560964614
Valid Loss:  0.0007893833098933101
Epoch:  391  	Training Loss: 0.0006676476332359016
Test Loss:  0.0004233774379827082
Valid Loss:  0.0007893159054219723
Epoch:  392  	Training Loss: 0.0006676461780443788
Test Loss:  0.00042293925071135163
Valid Loss:  0.0007885448867455125
Epoch:  393  	Training Loss: 0.0006671062437817454
Test Loss:  0.000422529672505334
Valid Loss:  0.0007878386531956494
Epoch:  394  	Training Loss: 0.0006666185799986124
Test Loss:  0.00042215059511363506
Valid Loss:  0.0007872316054999828
Epoch:  395  	Training Loss: 0.0006661898223683238
Test Loss:  0.00042180257150903344
Valid Loss:  0.0007866347441449761
Epoch:  396  	Training Loss: 0.000665784755256027
Test Loss:  0.0004214847576804459
Valid Loss:  0.0007860745536163449
Epoch:  397  	Training Loss: 0.0006654034950770438
Test Loss:  0.0004211945051793009
Valid Loss:  0.0007855704170651734
Epoch:  398  	Training Loss: 0.0006650473223999143
Test Loss:  0.0004209181643091142
Valid Loss:  0.0007850849069654942
Epoch:  399  	Training Loss: 0.0006647140253335238
Test Loss:  0.00042065634625032544
Valid Loss:  0.0007846163352951407
Epoch:  400  	Training Loss: 0.0006643974920734763
Test Loss:  0.0004203965072520077
Valid Loss:  0.0007841577753424644
Epoch:  401  	Training Loss: 0.0006640859646722674
Test Loss:  0.0004201408592052758
Valid Loss:  0.0007837052689865232
Epoch:  402  	Training Loss: 0.0006637779297307134
Test Loss:  0.00042016879888251424
Valid Loss:  0.0007838086457923055
Epoch:  403  	Training Loss: 0.0006637686747126281
Test Loss:  0.00042019918328151107
Valid Loss:  0.00078390579437837
Epoch:  404  	Training Loss: 0.0006637604674324393
Test Loss:  0.000420227472204715
Valid Loss:  0.0007839989848434925
Epoch:  405  	Training Loss: 0.0006637530168518424
Test Loss:  0.00042025191942229867
Valid Loss:  0.0007840898470021784
Epoch:  406  	Training Loss: 0.0006637455662712455
Test Loss:  0.0004202776472084224
Valid Loss:  0.0007841721526347101
Epoch:  407  	Training Loss: 0.0006637389305979013
Test Loss:  0.00042030104668810964
Valid Loss:  0.0007842537015676498
Epoch:  408  	Training Loss: 0.0006637320038862526
Test Loss:  0.00042032438796013594
Valid Loss:  0.0007843308267183602
Epoch:  409  	Training Loss: 0.000663725717458874
Test Loss:   82%|████████▏ | 409/500 [05:03<00:30,  2.96it/s] 82%|████████▏ | 411/500 [05:09<01:43,  1.17s/it] 83%|████████▎ | 413/500 [05:10<01:12,  1.19it/s] 83%|████████▎ | 415/500 [05:10<00:51,  1.65it/s] 83%|████████▎ | 417/500 [05:10<00:36,  2.25it/s] 84%|████████▍ | 419/500 [05:10<00:26,  3.02it/s] 84%|████████▍ | 421/500 [05:16<01:34,  1.20s/it] 85%|████████▍ | 423/500 [05:17<01:06,  1.16it/s] 85%|████████▌ | 425/500 [05:17<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:17<00:33,  2.19it/s] 86%|████████▌ | 429/500 [05:17<00:24,  2.95it/s] 86%|████████▌ | 431/500 [05:23<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:23<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:23<00:39,  1.65it/s] 87%|████████▋ | 437/500 [05:24<00:28,  2.25it/s] 88%|████████▊ | 439/500 [05:24<00:20,  3.02it/s] 88%|████████▊ | 441/500 [05:30<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:30<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:30<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:30<00:23,  2.25it/s] 90%|████████▉ | 449/500 [05:30<00:16,  3.02it/s] 90%|█████████ | 451/500 [05:37<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:37<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:37<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:37<00:19,  2.24it/s] 92%|█████████▏| 459/500 [05:37<00:13,  3.01it/s] 92%|█████████▏| 461/500 [05:44<00:45,  1.18s/it] 93%|█████████▎| 463/500 [05:44<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:44<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:44<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:44<00:10,  3.01it/s] 94%|█████████▍| 471/500 [05:50<00:33,  1.16s/it] 95%|█████████▍| 473/500 [05:50<00:22,  1.20it/s] 95%|█████████▌| 475/500 [05:51<00:15,  1.66it/s]0.00042034557554870844
Valid Loss:  0.0007844041683711112
Epoch:  410  	Training Loss: 0.0006637201295234263
Test Loss:  0.00042036702507175505
Valid Loss:  0.000784472853410989
Epoch:  411  	Training Loss: 0.000663714250549674
Test Loss:  0.0004203863500151783
Valid Loss:  0.0007845405489206314
Epoch:  412  	Training Loss: 0.00066370953572914
Test Loss:  0.000420133292209357
Valid Loss:  0.0007840966572985053
Epoch:  413  	Training Loss: 0.0006634590099565685
Test Loss:  0.0004198836977593601
Valid Loss:  0.0007836561999283731
Epoch:  414  	Training Loss: 0.0006632091826759279
Test Loss:  0.00041963375406339765
Valid Loss:  0.000783219700679183
Epoch:  415  	Training Loss: 0.0006629615090787411
Test Loss:  0.00041938660433515906
Valid Loss:  0.0007827867520973086
Epoch:  416  	Training Loss: 0.0006627142429351807
Test Loss:  0.0004191421321593225
Valid Loss:  0.0007823583437129855
Epoch:  417  	Training Loss: 0.0006624679663218558
Test Loss:  0.0004188980383332819
Valid Loss:  0.0007819323800504208
Epoch:  418  	Training Loss: 0.0006622228538617492
Test Loss:  0.0004186550504527986
Valid Loss:  0.0007815099670551717
Epoch:  419  	Training Loss: 0.0006619802443310618
Test Loss:  0.0004184143908787519
Valid Loss:  0.0007810893002897501
Epoch:  420  	Training Loss: 0.0006617368198931217
Test Loss:  0.00041817675810307264
Valid Loss:  0.0007806729408912361
Epoch:  421  	Training Loss: 0.0006614956073462963
Test Loss:  0.00041794072603806853
Valid Loss:  0.0007802598993293941
Epoch:  422  	Training Loss: 0.0006612555589526892
Test Loss:  0.0004188853781670332
Valid Loss:  0.00078280468005687
Epoch:  423  	Training Loss: 0.0006608468247577548
Test Loss:  0.0004196325899101794
Valid Loss:  0.0007847506203688681
Epoch:  424  	Training Loss: 0.000660530524328351
Test Loss:  0.00042022173875011504
Valid Loss:  0.0007862441125325859
Epoch:  425  	Training Loss: 0.0006602681241929531
Test Loss:  0.00042068870970979333
Valid Loss:  0.0007874007569625974
Epoch:  426  	Training Loss: 0.000660040182992816
Test Loss:  0.000421062926761806
Valid Loss:  0.0007883049547672272
Epoch:  427  	Training Loss: 0.0006598351756110787
Test Loss:  0.0004213660431560129
Valid Loss:  0.000789016718044877
Epoch:  428  	Training Loss: 0.0006596450693905354
Test Loss:  0.0004216152592562139
Valid Loss:  0.0007895282469689846
Epoch:  429  	Training Loss: 0.0006594681181013584
Test Loss:  0.00042182530160062015
Valid Loss:  0.0007899377960711718
Epoch:  430  	Training Loss: 0.0006593010621145368
Test Loss:  0.00042200495954602957
Valid Loss:  0.0007902715587988496
Epoch:  431  	Training Loss: 0.0006591424462385476
Test Loss:  0.000422162062022835
Valid Loss:  0.0007905433885753155
Epoch:  432  	Training Loss: 0.0006589915137737989
Test Loss:  0.0004210839979350567
Valid Loss:  0.0007882012287154794
Epoch:  433  	Training Loss: 0.0006573896971531212
Test Loss:  0.00042003634735010564
Valid Loss:  0.0007857693126425147
Epoch:  434  	Training Loss: 0.0006559046451002359
Test Loss:  0.0004190397448837757
Valid Loss:  0.0007832759874872863
Epoch:  435  	Training Loss: 0.0006544751231558621
Test Loss:  0.0004180834221187979
Valid Loss:  0.0007807666552253067
Epoch:  436  	Training Loss: 0.0006530809914693236
Test Loss:  0.00041717765270732343
Valid Loss:  0.0007782659376971424
Epoch:  437  	Training Loss: 0.000651744136121124
Test Loss:  0.0004162801196798682
Valid Loss:  0.0007758115534670651
Epoch:  438  	Training Loss: 0.0006504440098069608
Test Loss:  0.0004154053167439997
Valid Loss:  0.0007733896491117775
Epoch:  439  	Training Loss: 0.0006491843378171325
Test Loss:  0.0004145703569520265
Valid Loss:  0.0007709864876233041
Epoch:  440  	Training Loss: 0.0006479471339844167
Test Loss:  0.00041375949513167143
Valid Loss:  0.0007686207536607981
Epoch:  441  	Training Loss: 0.0006467345519922674
Test Loss:  0.0004129641456529498
Valid Loss:  0.0007662835414521396
Epoch:  442  	Training Loss: 0.0006455341354012489
Test Loss:  0.00041279610013589263
Valid Loss:  0.0007659459370188415
Epoch:  443  	Training Loss: 0.0006453664391301572
Test Loss:  0.00041266082553192973
Valid Loss:  0.0007656592060811818
Epoch:  444  	Training Loss: 0.0006452280795201659
Test Loss:  0.00041255028918385506
Valid Loss:  0.0007654116488993168
Epoch:  445  	Training Loss: 0.000645109626930207
Test Loss:  0.00041245680768042803
Valid Loss:  0.0007651951164007187
Epoch:  446  	Training Loss: 0.0006450052605941892
Test Loss:  0.0004123742110095918
Valid Loss:  0.0007649966864846647
Epoch:  447  	Training Loss: 0.0006449098000302911
Test Loss:  0.00041230276110582054
Valid Loss:  0.0007648178143426776
Epoch:  448  	Training Loss: 0.0006448223139159381
Test Loss:  0.0004122388199903071
Valid Loss:  0.0007646539597772062
Epoch:  449  	Training Loss: 0.0006447416380979121
Test Loss:  0.00041218107799068093
Valid Loss:  0.0007644986035302281
Epoch:  450  	Training Loss: 0.000644659623503685
Test Loss:  0.00041212659562006593
Valid Loss:  0.0007643448188900948
Epoch:  451  	Training Loss: 0.0006445798790082335
Test Loss:  0.0004120746743865311
Valid Loss:  0.000764190626796335
Epoch:  452  	Training Loss: 0.0006444976897910237
Test Loss:  0.00041210275958292186
Valid Loss:  0.0007637470844201744
Epoch:  453  	Training Loss: 0.0006437029805965722
Test Loss:  0.00041212444193661213
Valid Loss:  0.0007632836932316422
Epoch:  454  	Training Loss: 0.000642919447273016
Test Loss:  0.00041214225348085165
Valid Loss:  0.000762802199460566
Epoch:  455  	Training Loss: 0.0006421484285965562
Test Loss:  0.00041215543751604855
Valid Loss:  0.0007623094134032726
Epoch:  456  	Training Loss: 0.0006413875380530953
Test Loss:  0.00041216399404220283
Valid Loss:  0.0007618031231686473
Epoch:  457  	Training Loss: 0.0006406375905498862
Test Loss:  0.00041216897079721093
Valid Loss:  0.0007612843764945865
Epoch:  458  	Training Loss: 0.0006398982368409634
Test Loss:  0.00041217170655727386
Valid Loss:  0.0007607571897096932
Epoch:  459  	Training Loss: 0.0006391673814505339
Test Loss:  0.00041217083344236016
Valid Loss:  0.0007602210389450192
Epoch:  460  	Training Loss: 0.0006384467706084251
Test Loss:  0.0004121663805563003
Valid Loss:  0.0007596747018396854
Epoch:  461  	Training Loss: 0.0006377359386533499
Test Loss:  0.0004121594247408211
Valid Loss:  0.0007591231260448694
Epoch:  462  	Training Loss: 0.0006370336632244289
Test Loss:  0.0004118474025744945
Valid Loss:  0.0007586024003103375
Epoch:  463  	Training Loss: 0.0006367609021253884
Test Loss:  0.00041153538040816784
Valid Loss:  0.0007580857491120696
Epoch:  464  	Training Loss: 0.0006364895380102098
Test Loss:  0.0004112266469746828
Valid Loss:  0.0007575708441436291
Epoch:  465  	Training Loss: 0.0006362208514474332
Test Loss:  0.0004109185829292983
Valid Loss:  0.0007570604793727398
Epoch:  466  	Training Loss: 0.0006359530962072313
Test Loss:  0.0004106124397367239
Valid Loss:  0.0007565509877167642
Epoch:  467  	Training Loss: 0.0006356883095577359
Test Loss:  0.00041030929423868656
Valid Loss:  0.000756049295887351
Epoch:  468  	Training Loss: 0.0006354243960231543
Test Loss:  0.0004100074584130198
Valid Loss:  0.000755547487642616
Epoch:  469  	Training Loss: 0.0006351617630571127
Test Loss:  0.0004097064374946058
Valid Loss:  0.000755042303353548
Epoch:  470  	Training Loss: 0.0006349020986817777
Test Loss:  0.0004094074247404933
Valid Loss:  0.0007545154076069593
Epoch:  471  	Training Loss: 0.0006346431910060346
Test Loss:  0.00040911228279583156
Valid Loss:  0.0007539895595982671
Epoch:  472  	Training Loss: 0.0006343862041831017
Test Loss:  0.0004089799476787448
Valid Loss:  0.000753680826164782
Epoch:  473  	Training Loss: 0.0006343659479171038
Test Loss:  0.00040885506314225495
Valid Loss:  0.000753386237192899
Epoch:  474  	Training Loss: 0.0006343478453345597
Test Loss:  0.0004087363777216524
Valid Loss:  0.0007531085284426808
Epoch:  475  	Training Loss: 0.0006343304994516075
Test Loss:  0.0004086216795258224
Valid Loss:  0.0007528415881097317
Epoch:  476  	Training Loss: 0.0006343135610222816
Test Loss:  0.00040851131780073047
Valid Loss:  0.0007525843102484941
Epoch:  477  	Training Loss: 0.0006342977285385132
Test Loss:  0.00040840631118044257
 95%|█████████▌| 477/500 [05:51<00:10,  2.26it/s] 96%|█████████▌| 479/500 [05:51<00:06,  3.04it/s] 96%|█████████▌| 481/500 [05:57<00:22,  1.16s/it] 97%|█████████▋| 483/500 [05:57<00:14,  1.20it/s] 97%|█████████▋| 485/500 [05:57<00:09,  1.66it/s] 97%|█████████▋| 487/500 [05:57<00:05,  2.27it/s] 98%|█████████▊| 489/500 [05:58<00:03,  3.03it/s] 98%|█████████▊| 491/500 [06:04<00:10,  1.18s/it] 99%|█████████▊| 493/500 [06:04<00:05,  1.18it/s] 99%|█████████▉| 495/500 [06:04<00:03,  1.63it/s] 99%|█████████▉| 497/500 [06:04<00:01,  2.23it/s]100%|█████████▉| 499/500 [06:04<00:00,  3.00it/s]100%|██████████| 500/500 [06:04<00:00,  1.37it/s]
Valid Loss:  0.000752337509766221
Epoch:  478  	Training Loss: 0.0006342823035083711
Test Loss:  0.0004083047970198095
Valid Loss:  0.0007521012448705733
Epoch:  479  	Training Loss: 0.0006342678098008037
Test Loss:  0.00040820654248818755
Valid Loss:  0.0007518724887631834
Epoch:  480  	Training Loss: 0.0006342529086396098
Test Loss:  0.0004081113147549331
Valid Loss:  0.0007516519981436431
Epoch:  481  	Training Loss: 0.0006342392880469561
Test Loss:  0.00040802068542689085
Valid Loss:  0.0007514393073506653
Epoch:  482  	Training Loss: 0.0006342263077385724
Test Loss:  0.00040758823161013424
Valid Loss:  0.0007506613619625568
Epoch:  483  	Training Loss: 0.0006338634993880987
Test Loss:  0.0004071617149747908
Valid Loss:  0.0007498907507397234
Epoch:  484  	Training Loss: 0.0006335055222734809
Test Loss:  0.00040673924377188087
Valid Loss:  0.0007491280557587743
Epoch:  485  	Training Loss: 0.0006331518525257707
Test Loss:  0.00040632227319292724
Valid Loss:  0.0007483722874894738
Epoch:  486  	Training Loss: 0.0006328006274998188
Test Loss:  0.00040590958087705076
Valid Loss:  0.000747617450542748
Epoch:  487  	Training Loss: 0.0006324525456875563
Test Loss:  0.00040550011908635497
Valid Loss:  0.0007468671537935734
Epoch:  488  	Training Loss: 0.0006321081891655922
Test Loss:  0.00040509633254259825
Valid Loss:  0.0007461258792318404
Epoch:  489  	Training Loss: 0.0006317683728411794
Test Loss:  0.0004046956601087004
Valid Loss:  0.0007453905418515205
Epoch:  490  	Training Loss: 0.0006314320489764214
Test Loss:  0.0004043017979711294
Valid Loss:  0.0007446614326909184
Epoch:  491  	Training Loss: 0.0006310989847406745
Test Loss:  0.00040391000220552087
Valid Loss:  0.0007439391338266432
Epoch:  492  	Training Loss: 0.0006307682488113642
Test Loss:  0.00040344649460166693
Valid Loss:  0.0007430887781083584
Epoch:  493  	Training Loss: 0.000630012946203351
Test Loss:  0.0004033462319057435
Valid Loss:  0.0007427805103361607
Epoch:  494  	Training Loss: 0.00062964903190732
Test Loss:  0.0004033554287161678
Valid Loss:  0.0007426330703310668
Epoch:  495  	Training Loss: 0.0006294709164649248
Test Loss:  0.0004033742588944733
Valid Loss:  0.0007425393559969962
Epoch:  496  	Training Loss: 0.0006293351761996746
Test Loss:  0.0004033928853459656
Valid Loss:  0.0007424794603139162
Epoch:  497  	Training Loss: 0.0006292214384302497
Test Loss:  0.00040341081330552697
Valid Loss:  0.0007424371433444321
Epoch:  498  	Training Loss: 0.0006291174213401973
Test Loss:  0.00040342798456549644
Valid Loss:  0.0007424093200825155
Epoch:  499  	Training Loss: 0.0006290209712460637
Test Loss:  0.00040344445733353496
Valid Loss:  0.0007423879578709602
Epoch:  500  	Training Loss: 0.0006289222510531545
Test Loss:  0.000403459242079407
Valid Loss:  0.0007423640345223248
